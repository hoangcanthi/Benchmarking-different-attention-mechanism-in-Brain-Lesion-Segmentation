
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-30 12:28:28.656558: do_dummy_2d_data_aug: False 
2025-08-30 12:28:28.664878: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-30 12:28:28.670671: The split file contains 5 splits. 
2025-08-30 12:28:28.674266: Desired fold for training: 0 
2025-08-30 12:28:28.678750: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-30 12:28:34.872233: Unable to plot network architecture: 
2025-08-30 12:28:34.881484: No module named 'hiddenlayer' 
2025-08-30 12:28:34.946200:  
2025-08-30 12:28:34.960862: Epoch 0 
2025-08-30 12:28:34.971233: Current learning rate: 0.001 
2025-08-30 12:29:05.748177: train_loss 0.1031 
2025-08-30 12:29:05.748177: val_loss 0.0145 
2025-08-30 12:29:05.758987: Pseudo dice [np.float32(0.0)] 
2025-08-30 12:29:05.764383: Epoch time: 30.8 s 
2025-08-30 12:29:05.769481: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-30 12:29:06.518416:  
2025-08-30 12:29:06.525490: Epoch 1 
2025-08-30 12:29:06.531797: Current learning rate: 0.001 
2025-08-30 12:29:32.533467: train_loss -0.0023 
2025-08-30 12:29:32.545271: val_loss -0.0093 
2025-08-30 12:29:32.552432: Pseudo dice [np.float32(0.0)] 
2025-08-30 12:29:32.557757: Epoch time: 26.02 s 
2025-08-30 12:29:33.258866:  
2025-08-30 12:29:33.263035: Epoch 2 
2025-08-30 12:29:33.271685: Current learning rate: 0.001 
2025-08-30 12:29:59.635065: train_loss -0.0461 
2025-08-30 12:29:59.643095: val_loss -0.0407 
2025-08-30 12:29:59.647614: Pseudo dice [np.float32(0.0)] 
2025-08-30 12:29:59.653310: Epoch time: 26.38 s 
2025-08-30 12:30:00.274043:  
2025-08-30 12:30:00.281165: Epoch 3 
2025-08-30 12:30:00.286433: Current learning rate: 0.001 
2025-08-30 12:30:25.953844: train_loss -0.086 
2025-08-30 12:30:25.953844: val_loss -0.0629 
2025-08-30 12:30:25.961840: Pseudo dice [np.float32(0.0)] 
2025-08-30 12:30:25.967268: Epoch time: 25.68 s 
2025-08-30 12:30:26.567545:  
2025-08-30 12:30:26.567545: Epoch 4 
2025-08-30 12:30:26.575786: Current learning rate: 0.001 
2025-08-30 12:30:52.901005: train_loss -0.1344 
2025-08-30 12:30:52.901005: val_loss -0.1997 
2025-08-30 12:30:52.910704: Pseudo dice [np.float32(0.4036)] 
2025-08-30 12:30:52.915926: Epoch time: 26.34 s 
2025-08-30 12:30:52.922337: Yayy! New best EMA pseudo Dice: 0.04039999842643738 
2025-08-30 12:30:53.752237:  
2025-08-30 12:30:53.753234: Epoch 5 
2025-08-30 12:30:53.763600: Current learning rate: 0.001 
2025-08-30 12:31:19.994606: train_loss -0.141 
2025-08-30 12:31:19.994606: val_loss -0.1984 
2025-08-30 12:31:20.004465: Pseudo dice [np.float32(0.4994)] 
2025-08-30 12:31:20.009869: Epoch time: 26.24 s 
2025-08-30 12:31:20.015704: Yayy! New best EMA pseudo Dice: 0.08630000054836273 
2025-08-30 12:31:20.818765:  
2025-08-30 12:31:20.827079: Epoch 6 
2025-08-30 12:31:20.833418: Current learning rate: 0.00099 
2025-08-30 12:31:47.751357: train_loss -0.1826 
2025-08-30 12:31:47.751357: val_loss -0.2476 
2025-08-30 12:31:47.762083: Pseudo dice [np.float32(0.4887)] 
2025-08-30 12:31:47.768568: Epoch time: 26.93 s 
2025-08-30 12:31:47.776051: Yayy! New best EMA pseudo Dice: 0.1264999955892563 
2025-08-30 12:31:48.629379:  
2025-08-30 12:31:48.636619: Epoch 7 
2025-08-30 12:31:48.643618: Current learning rate: 0.00099 
2025-08-30 12:32:15.777961: train_loss -0.1964 
2025-08-30 12:32:15.787793: val_loss -0.341 
2025-08-30 12:32:15.792220: Pseudo dice [np.float32(0.5577)] 
2025-08-30 12:32:15.798154: Epoch time: 27.15 s 
2025-08-30 12:32:15.808543: Yayy! New best EMA pseudo Dice: 0.1695999950170517 
2025-08-30 12:32:16.723562:  
2025-08-30 12:32:16.734036: Epoch 8 
2025-08-30 12:32:16.750836: Current learning rate: 0.00099 
2025-08-30 12:32:43.073750: train_loss -0.2172 
2025-08-30 12:32:43.073750: val_loss -0.2384 
2025-08-30 12:32:43.081930: Pseudo dice [np.float32(0.5347)] 
2025-08-30 12:32:43.087636: Epoch time: 26.35 s 
2025-08-30 12:32:43.094399: Yayy! New best EMA pseudo Dice: 0.2061000019311905 
2025-08-30 12:32:43.923440:  
2025-08-30 12:32:43.931790: Epoch 9 
2025-08-30 12:32:43.938139: Current learning rate: 0.00099 
2025-08-30 12:33:09.854017: train_loss -0.2382 
2025-08-30 12:33:09.862321: val_loss -0.278 
2025-08-30 12:33:09.866495: Pseudo dice [np.float32(0.4968)] 
2025-08-30 12:33:09.875482: Epoch time: 25.93 s 
2025-08-30 12:33:09.877480: Yayy! New best EMA pseudo Dice: 0.23520000278949738 
2025-08-30 12:33:10.676299:  
2025-08-30 12:33:10.683477: Epoch 10 
2025-08-30 12:33:10.690811: Current learning rate: 0.00099 
2025-08-30 12:33:36.847555: train_loss -0.2345 
2025-08-30 12:33:36.847555: val_loss -0.3315 
2025-08-30 12:33:36.857306: Pseudo dice [np.float32(0.5907)] 
2025-08-30 12:33:36.863185: Epoch time: 26.17 s 
2025-08-30 12:33:36.868073: Yayy! New best EMA pseudo Dice: 0.27070000767707825 
2025-08-30 12:33:37.669881:  
2025-08-30 12:33:37.678197: Epoch 11 
2025-08-30 12:33:37.684387: Current learning rate: 0.00099 
2025-08-30 12:34:03.786953: train_loss -0.2826 
2025-08-30 12:34:03.795266: val_loss -0.3286 
2025-08-30 12:34:03.799393: Pseudo dice [np.float32(0.5725)] 
2025-08-30 12:34:03.807437: Epoch time: 26.12 s 
2025-08-30 12:34:03.812592: Yayy! New best EMA pseudo Dice: 0.30090001225471497 
2025-08-30 12:34:04.602984:  
2025-08-30 12:34:04.610239: Epoch 12 
2025-08-30 12:34:04.616395: Current learning rate: 0.00099 
2025-08-30 12:34:30.943201: train_loss -0.2805 
2025-08-30 12:34:30.951528: val_loss -0.3248 
2025-08-30 12:34:30.955720: Pseudo dice [np.float32(0.5495)] 
2025-08-30 12:34:30.963669: Epoch time: 26.34 s 
2025-08-30 12:34:30.967924: Yayy! New best EMA pseudo Dice: 0.32580000162124634 
2025-08-30 12:34:31.786364:  
2025-08-30 12:34:31.794676: Epoch 13 
2025-08-30 12:34:31.800844: Current learning rate: 0.00099 
2025-08-30 12:34:58.265887: train_loss -0.2751 
2025-08-30 12:34:58.278413: val_loss -0.1879 
2025-08-30 12:34:58.282589: Pseudo dice [np.float32(0.3963)] 
2025-08-30 12:34:58.289319: Epoch time: 26.48 s 
2025-08-30 12:34:58.295390: Yayy! New best EMA pseudo Dice: 0.3328000009059906 
2025-08-30 12:34:59.091568:  
2025-08-30 12:34:59.099917: Epoch 14 
2025-08-30 12:34:59.106355: Current learning rate: 0.00099 
2025-08-30 12:35:25.172207: train_loss -0.2755 
2025-08-30 12:35:25.180600: val_loss -0.3637 
2025-08-30 12:35:25.188580: Pseudo dice [np.float32(0.5766)] 
2025-08-30 12:35:25.192741: Epoch time: 26.08 s 
2025-08-30 12:35:25.197931: Yayy! New best EMA pseudo Dice: 0.3571999967098236 
2025-08-30 12:35:26.029926:  
2025-08-30 12:35:26.038292: Epoch 15 
2025-08-30 12:35:26.046905: Current learning rate: 0.00099 
2025-08-30 12:35:52.524600: train_loss -0.2952 
2025-08-30 12:35:52.532842: val_loss -0.2482 
2025-08-30 12:35:52.541281: Pseudo dice [np.float32(0.4405)] 
2025-08-30 12:35:52.546730: Epoch time: 26.5 s 
2025-08-30 12:35:52.551687: Yayy! New best EMA pseudo Dice: 0.36550000309944153 
2025-08-30 12:35:53.363523:  
2025-08-30 12:35:53.370782: Epoch 16 
2025-08-30 12:35:53.377033: Current learning rate: 0.00099 
2025-08-30 12:36:23.872561: train_loss -0.2641 
2025-08-30 12:36:23.881644: val_loss -0.4099 
2025-08-30 12:36:23.885022: Pseudo dice [np.float32(0.6287)] 
2025-08-30 12:36:23.892959: Epoch time: 30.51 s 
2025-08-30 12:36:23.898862: Yayy! New best EMA pseudo Dice: 0.3919000029563904 
2025-08-30 12:36:24.923280:  
2025-08-30 12:36:24.932666: Epoch 17 
2025-08-30 12:36:24.939849: Current learning rate: 0.00098 
2025-08-30 12:36:55.258087: train_loss -0.3036 
2025-08-30 12:36:55.266415: val_loss -0.3833 
2025-08-30 12:36:55.270660: Pseudo dice [np.float32(0.6274)] 
2025-08-30 12:36:55.276795: Epoch time: 30.34 s 
2025-08-30 12:36:55.282590: Yayy! New best EMA pseudo Dice: 0.4153999984264374 
2025-08-30 12:36:56.289595:  
2025-08-30 12:36:56.296112: Epoch 18 
2025-08-30 12:36:56.303449: Current learning rate: 0.00098 
2025-08-30 12:37:25.430172: train_loss -0.2965 
2025-08-30 12:37:25.438142: val_loss -0.3847 
2025-08-30 12:37:25.442215: Pseudo dice [np.float32(0.5998)] 
2025-08-30 12:37:25.450808: Epoch time: 29.14 s 
2025-08-30 12:37:25.455294: Yayy! New best EMA pseudo Dice: 0.43380001187324524 
2025-08-30 12:37:26.521995:  
2025-08-30 12:37:26.531485: Epoch 19 
2025-08-30 12:37:26.538707: Current learning rate: 0.00098 
2025-08-30 12:37:55.017161: train_loss -0.35 
2025-08-30 12:37:55.032665: val_loss -0.3759 
2025-08-30 12:37:55.038986: Pseudo dice [np.float32(0.6525)] 
2025-08-30 12:37:55.045271: Epoch time: 28.5 s 
2025-08-30 12:37:55.050523: Yayy! New best EMA pseudo Dice: 0.45570001006126404 
2025-08-30 12:37:55.972147:  
2025-08-30 12:37:55.978905: Epoch 20 
2025-08-30 12:37:55.984777: Current learning rate: 0.00098 
2025-08-30 12:38:25.360417: train_loss -0.3549 
2025-08-30 12:38:25.360417: val_loss -0.4216 
2025-08-30 12:38:25.369118: Pseudo dice [np.float32(0.6115)] 
2025-08-30 12:38:25.374918: Epoch time: 29.39 s 
2025-08-30 12:38:25.381206: Yayy! New best EMA pseudo Dice: 0.47130000591278076 
2025-08-30 12:38:26.264959:  
2025-08-30 12:38:26.274327: Epoch 21 
2025-08-30 12:38:26.281458: Current learning rate: 0.00098 
2025-08-30 12:38:59.439769: train_loss -0.3718 
2025-08-30 12:38:59.448052: val_loss -0.2592 
2025-08-30 12:38:59.452560: Pseudo dice [np.float32(0.5279)] 
2025-08-30 12:38:59.458128: Epoch time: 33.18 s 
2025-08-30 12:38:59.462302: Yayy! New best EMA pseudo Dice: 0.47690001130104065 
2025-08-30 12:39:00.463891:  
2025-08-30 12:39:00.474156: Epoch 22 
2025-08-30 12:39:00.480358: Current learning rate: 0.00098 
2025-08-30 12:39:31.163457: train_loss -0.3282 
2025-08-30 12:39:31.171355: val_loss -0.324 
2025-08-30 12:39:31.175894: Pseudo dice [np.float32(0.6295)] 
2025-08-30 12:39:31.182418: Epoch time: 30.7 s 
2025-08-30 12:39:31.188478: Yayy! New best EMA pseudo Dice: 0.49219998717308044 
2025-08-30 12:39:32.122161:  
2025-08-30 12:39:32.133659: Epoch 23 
2025-08-30 12:39:32.143046: Current learning rate: 0.00098 
2025-08-30 12:40:01.009867: train_loss -0.324 
2025-08-30 12:40:01.018267: val_loss -0.3782 
2025-08-30 12:40:01.026617: Pseudo dice [np.float32(0.5757)] 
2025-08-30 12:40:01.031848: Epoch time: 28.89 s 
2025-08-30 12:40:01.037558: Yayy! New best EMA pseudo Dice: 0.5005000233650208 
2025-08-30 12:40:01.893267:  
2025-08-30 12:40:01.901962: Epoch 24 
2025-08-30 12:40:01.909318: Current learning rate: 0.00098 
2025-08-30 12:40:31.177721: train_loss -0.2863 
2025-08-30 12:40:31.185782: val_loss -0.401 
2025-08-30 12:40:31.189955: Pseudo dice [np.float32(0.647)] 
2025-08-30 12:40:31.197203: Epoch time: 29.29 s 
2025-08-30 12:40:31.202451: Yayy! New best EMA pseudo Dice: 0.5152000188827515 
2025-08-30 12:40:32.242589:  
2025-08-30 12:40:32.251966: Epoch 25 
2025-08-30 12:40:32.259256: Current learning rate: 0.00098 
2025-08-30 12:41:01.507883: train_loss -0.3299 
2025-08-30 12:41:01.515923: val_loss -0.3447 
2025-08-30 12:41:01.524274: Pseudo dice [np.float32(0.62)] 
2025-08-30 12:41:01.528761: Epoch time: 29.27 s 
2025-08-30 12:41:01.534550: Yayy! New best EMA pseudo Dice: 0.5256999731063843 
2025-08-30 12:41:02.406933:  
2025-08-30 12:41:02.415768: Epoch 26 
2025-08-30 12:41:02.421817: Current learning rate: 0.00098 
2025-08-30 12:41:31.520844: train_loss -0.3313 
2025-08-30 12:41:31.529185: val_loss -0.3305 
2025-08-30 12:41:31.533386: Pseudo dice [np.float32(0.5589)] 
2025-08-30 12:41:31.540711: Epoch time: 29.12 s 
2025-08-30 12:41:31.545886: Yayy! New best EMA pseudo Dice: 0.5289999842643738 
2025-08-30 12:41:32.426649:  
2025-08-30 12:41:32.435938: Epoch 27 
2025-08-30 12:41:32.442109: Current learning rate: 0.00098 
2025-08-30 12:42:00.251212: train_loss -0.4023 
2025-08-30 12:42:00.251212: val_loss -0.4291 
2025-08-30 12:42:00.259490: Pseudo dice [np.float32(0.6785)] 
2025-08-30 12:42:00.265861: Epoch time: 27.83 s 
2025-08-30 12:42:00.271596: Yayy! New best EMA pseudo Dice: 0.5439000129699707 
2025-08-30 12:42:01.155314:  
2025-08-30 12:42:01.162556: Epoch 28 
2025-08-30 12:42:01.168197: Current learning rate: 0.00097 
2025-08-30 12:42:27.468343: train_loss -0.3661 
2025-08-30 12:42:27.468343: val_loss -0.3848 
2025-08-30 12:42:27.476319: Pseudo dice [np.float32(0.633)] 
2025-08-30 12:42:27.482232: Epoch time: 26.31 s 
2025-08-30 12:42:27.488060: Yayy! New best EMA pseudo Dice: 0.5529000163078308 
2025-08-30 12:42:28.277088:  
2025-08-30 12:42:28.282664: Epoch 29 
2025-08-30 12:42:28.290684: Current learning rate: 0.00097 
2025-08-30 12:42:53.352090: train_loss -0.3799 
2025-08-30 12:42:53.352090: val_loss -0.4276 
2025-08-30 12:42:53.360435: Pseudo dice [np.float32(0.6663)] 
2025-08-30 12:42:53.366222: Epoch time: 25.08 s 
2025-08-30 12:42:53.372057: Yayy! New best EMA pseudo Dice: 0.5641999840736389 
2025-08-30 12:42:54.221046:  
2025-08-30 12:42:54.229044: Epoch 30 
2025-08-30 12:42:54.236329: Current learning rate: 0.00097 
2025-08-30 12:43:20.200020: train_loss -0.3843 
2025-08-30 12:43:20.208375: val_loss -0.3821 
2025-08-30 12:43:20.217151: Pseudo dice [np.float32(0.6048)] 
2025-08-30 12:43:20.222171: Epoch time: 25.98 s 
2025-08-30 12:43:20.236615: Yayy! New best EMA pseudo Dice: 0.5683000087738037 
2025-08-30 12:43:21.209044:  
2025-08-30 12:43:21.214727: Epoch 31 
2025-08-30 12:43:21.223058: Current learning rate: 0.00097 
2025-08-30 12:43:46.626374: train_loss -0.4105 
2025-08-30 12:43:46.634788: val_loss -0.411 
2025-08-30 12:43:46.638881: Pseudo dice [np.float32(0.6814)] 
2025-08-30 12:43:46.647497: Epoch time: 25.42 s 
2025-08-30 12:43:46.651765: Yayy! New best EMA pseudo Dice: 0.5795999765396118 
2025-08-30 12:43:47.444630:  
2025-08-30 12:43:47.452960: Epoch 32 
2025-08-30 12:43:47.457491: Current learning rate: 0.00097 
2025-08-30 12:44:13.432259: train_loss -0.3889 
2025-08-30 12:44:13.440611: val_loss -0.4017 
2025-08-30 12:44:13.444836: Pseudo dice [np.float32(0.6499)] 
2025-08-30 12:44:13.453332: Epoch time: 25.99 s 
2025-08-30 12:44:13.457684: Yayy! New best EMA pseudo Dice: 0.5866000056266785 
2025-08-30 12:44:14.271807:  
2025-08-30 12:44:14.280027: Epoch 33 
2025-08-30 12:44:14.283885: Current learning rate: 0.00097 
2025-08-30 12:44:39.841950: train_loss -0.3674 
2025-08-30 12:44:39.850360: val_loss -0.3865 
2025-08-30 12:44:39.858708: Pseudo dice [np.float32(0.6973)] 
2025-08-30 12:44:39.864066: Epoch time: 25.57 s 
2025-08-30 12:44:39.868961: Yayy! New best EMA pseudo Dice: 0.5976999998092651 
2025-08-30 12:44:40.693922:  
2025-08-30 12:44:40.701871: Epoch 34 
2025-08-30 12:44:40.706471: Current learning rate: 0.00097 
2025-08-30 12:45:07.244331: train_loss -0.3842 
2025-08-30 12:45:07.252633: val_loss -0.4091 
2025-08-30 12:45:07.261040: Pseudo dice [np.float32(0.6727)] 
2025-08-30 12:45:07.266457: Epoch time: 26.55 s 
2025-08-30 12:45:07.269730: Yayy! New best EMA pseudo Dice: 0.6051999926567078 
2025-08-30 12:45:08.083714:  
2025-08-30 12:45:08.092015: Epoch 35 
2025-08-30 12:45:08.096393: Current learning rate: 0.00097 
2025-08-30 12:45:33.845784: train_loss -0.3685 
2025-08-30 12:45:33.854134: val_loss -0.426 
2025-08-30 12:45:33.862933: Pseudo dice [np.float32(0.6906)] 
2025-08-30 12:45:33.867952: Epoch time: 25.76 s 
2025-08-30 12:45:33.873820: Yayy! New best EMA pseudo Dice: 0.6136999726295471 
2025-08-30 12:45:34.679647:  
2025-08-30 12:45:34.685294: Epoch 36 
2025-08-30 12:45:34.694068: Current learning rate: 0.00097 
2025-08-30 12:46:00.793482: train_loss -0.3972 
2025-08-30 12:46:00.801818: val_loss -0.4433 
2025-08-30 12:46:00.810248: Pseudo dice [np.float32(0.6559)] 
2025-08-30 12:46:00.815611: Epoch time: 26.12 s 
2025-08-30 12:46:00.821265: Yayy! New best EMA pseudo Dice: 0.617900013923645 
2025-08-30 12:46:01.791055:  
2025-08-30 12:46:01.799438: Epoch 37 
2025-08-30 12:46:01.803641: Current learning rate: 0.00097 
2025-08-30 12:46:28.479492: train_loss -0.3848 
2025-08-30 12:46:28.487834: val_loss -0.3906 
2025-08-30 12:46:28.492208: Pseudo dice [np.float32(0.6209)] 
2025-08-30 12:46:28.499988: Epoch time: 26.69 s 
2025-08-30 12:46:28.504580: Yayy! New best EMA pseudo Dice: 0.6182000041007996 
2025-08-30 12:46:29.375851:  
2025-08-30 12:46:29.381403: Epoch 38 
2025-08-30 12:46:29.388361: Current learning rate: 0.00097 
2025-08-30 12:46:58.717981: train_loss -0.3754 
2025-08-30 12:46:58.730563: val_loss -0.4018 
2025-08-30 12:46:58.734774: Pseudo dice [np.float32(0.5895)] 
2025-08-30 12:46:58.742612: Epoch time: 29.34 s 
2025-08-30 12:46:59.498643:  
2025-08-30 12:46:59.505898: Epoch 39 
2025-08-30 12:46:59.511584: Current learning rate: 0.00096 
2025-08-30 12:47:31.562821: train_loss -0.3881 
2025-08-30 12:47:31.562821: val_loss -0.4976 
2025-08-30 12:47:31.571898: Pseudo dice [np.float32(0.7111)] 
2025-08-30 12:47:31.576968: Epoch time: 32.07 s 
2025-08-30 12:47:31.582941: Yayy! New best EMA pseudo Dice: 0.6248999834060669 
2025-08-30 12:47:32.478354:  
2025-08-30 12:47:32.485674: Epoch 40 
2025-08-30 12:47:32.490337: Current learning rate: 0.00096 
2025-08-30 12:48:01.903370: train_loss -0.3979 
2025-08-30 12:48:01.910173: val_loss -0.4857 
2025-08-30 12:48:01.918591: Pseudo dice [np.float32(0.664)] 
2025-08-30 12:48:01.923025: Epoch time: 29.43 s 
2025-08-30 12:48:01.927401: Yayy! New best EMA pseudo Dice: 0.6287999749183655 
2025-08-30 12:48:02.875203:  
2025-08-30 12:48:02.883054: Epoch 41 
2025-08-30 12:48:02.887160: Current learning rate: 0.00096 
2025-08-30 12:48:31.356225: train_loss -0.3903 
2025-08-30 12:48:31.364603: val_loss -0.4799 
2025-08-30 12:48:31.368718: Pseudo dice [np.float32(0.7406)] 
2025-08-30 12:48:31.375087: Epoch time: 28.48 s 
2025-08-30 12:48:31.381368: Yayy! New best EMA pseudo Dice: 0.6399999856948853 
2025-08-30 12:48:32.332853:  
2025-08-30 12:48:32.341570: Epoch 42 
2025-08-30 12:48:32.348494: Current learning rate: 0.00096 
2025-08-30 12:49:02.120154: train_loss -0.396 
2025-08-30 12:49:02.132744: val_loss -0.3875 
2025-08-30 12:49:02.136919: Pseudo dice [np.float32(0.7128)] 
2025-08-30 12:49:02.144810: Epoch time: 29.79 s 
2025-08-30 12:49:02.149611: Yayy! New best EMA pseudo Dice: 0.6473000049591064 
2025-08-30 12:49:03.206653:  
2025-08-30 12:49:03.214128: Epoch 43 
2025-08-30 12:49:03.218246: Current learning rate: 0.00096 
2025-08-30 12:49:32.367095: train_loss -0.4267 
2025-08-30 12:49:32.375432: val_loss -0.3379 
2025-08-30 12:49:32.383807: Pseudo dice [np.float32(0.5353)] 
2025-08-30 12:49:32.389198: Epoch time: 29.16 s 
2025-08-30 12:49:33.043904:  
2025-08-30 12:49:33.051754: Epoch 44 
2025-08-30 12:49:33.055959: Current learning rate: 0.00096 
2025-08-30 12:50:01.329192: train_loss -0.3797 
2025-08-30 12:50:01.341787: val_loss -0.4692 
2025-08-30 12:50:01.345978: Pseudo dice [np.float32(0.7016)] 
2025-08-30 12:50:01.352326: Epoch time: 28.29 s 
2025-08-30 12:50:01.989384:  
2025-08-30 12:50:01.997783: Epoch 45 
2025-08-30 12:50:02.001936: Current learning rate: 0.00096 
2025-08-30 12:50:31.508898: train_loss -0.3731 
2025-08-30 12:50:31.517614: val_loss -0.4979 
2025-08-30 12:50:31.521777: Pseudo dice [np.float32(0.6874)] 
2025-08-30 12:50:31.529802: Epoch time: 29.52 s 
2025-08-30 12:50:32.159554:  
2025-08-30 12:50:32.167928: Epoch 46 
2025-08-30 12:50:32.173232: Current learning rate: 0.00096 
2025-08-30 12:51:01.109685: train_loss -0.3865 
2025-08-30 12:51:01.118024: val_loss -0.4435 
2025-08-30 12:51:01.122204: Pseudo dice [np.float32(0.6768)] 
2025-08-30 12:51:01.130804: Epoch time: 28.95 s 
2025-08-30 12:51:01.136837: Yayy! New best EMA pseudo Dice: 0.6500999927520752 
2025-08-30 12:51:02.108212:  
2025-08-30 12:51:02.115978: Epoch 47 
2025-08-30 12:51:02.122807: Current learning rate: 0.00096 
2025-08-30 12:51:30.155298: train_loss -0.3701 
2025-08-30 12:51:30.155298: val_loss -0.3845 
2025-08-30 12:51:30.163631: Pseudo dice [np.float32(0.6754)] 
2025-08-30 12:51:30.171576: Epoch time: 28.05 s 
2025-08-30 12:51:30.178174: Yayy! New best EMA pseudo Dice: 0.6525999903678894 
2025-08-30 12:51:30.963993:  
2025-08-30 12:51:30.970171: Epoch 48 
2025-08-30 12:51:30.976509: Current learning rate: 0.00096 
2025-08-30 12:51:57.782998: train_loss -0.3906 
2025-08-30 12:51:57.791166: val_loss -0.3711 
2025-08-30 12:51:57.798832: Pseudo dice [np.float32(0.6012)] 
2025-08-30 12:51:57.805016: Epoch time: 26.82 s 
2025-08-30 12:51:58.414566:  
2025-08-30 12:51:58.422717: Epoch 49 
2025-08-30 12:51:58.429970: Current learning rate: 0.00096 
2025-08-30 12:52:25.647697: train_loss -0.4186 
2025-08-30 12:52:25.647697: val_loss -0.4734 
2025-08-30 12:52:25.656815: Pseudo dice [np.float32(0.6984)] 
2025-08-30 12:52:25.662871: Epoch time: 27.24 s 
2025-08-30 12:52:26.615309:  
2025-08-30 12:52:26.623666: Epoch 50 
2025-08-30 12:52:26.629528: Current learning rate: 0.00095 
2025-08-30 12:52:52.066109: train_loss -0.3767 
2025-08-30 12:52:52.074085: val_loss -0.4271 
2025-08-30 12:52:52.078242: Pseudo dice [np.float32(0.6984)] 
2025-08-30 12:52:52.084067: Epoch time: 25.45 s 
2025-08-30 12:52:52.088785: Yayy! New best EMA pseudo Dice: 0.6571000218391418 
2025-08-30 12:52:52.884315:  
2025-08-30 12:52:52.892651: Epoch 51 
2025-08-30 12:52:52.897265: Current learning rate: 0.00095 
2025-08-30 12:53:18.763527: train_loss -0.4187 
2025-08-30 12:53:18.771922: val_loss -0.419 
2025-08-30 12:53:18.780676: Pseudo dice [np.float32(0.7171)] 
2025-08-30 12:53:18.786732: Epoch time: 25.88 s 
2025-08-30 12:53:18.792682: Yayy! New best EMA pseudo Dice: 0.663100004196167 
2025-08-30 12:53:19.615117:  
2025-08-30 12:53:19.623448: Epoch 52 
2025-08-30 12:53:19.630725: Current learning rate: 0.00095 
2025-08-30 12:53:45.373520: train_loss -0.3773 
2025-08-30 12:53:45.381762: val_loss -0.3821 
2025-08-30 12:53:45.385951: Pseudo dice [np.float32(0.617)] 
2025-08-30 12:53:45.392315: Epoch time: 25.76 s 
2025-08-30 12:53:45.990327:  
2025-08-30 12:53:45.995630: Epoch 53 
2025-08-30 12:53:46.003945: Current learning rate: 0.00095 
2025-08-30 12:54:12.112746: train_loss -0.3967 
2025-08-30 12:54:12.124728: val_loss -0.4636 
2025-08-30 12:54:12.129268: Pseudo dice [np.float32(0.6567)] 
2025-08-30 12:54:12.135700: Epoch time: 26.13 s 
2025-08-30 12:54:12.743098:  
2025-08-30 12:54:12.747305: Epoch 54 
2025-08-30 12:54:12.755636: Current learning rate: 0.00095 
2025-08-30 12:54:39.080785: train_loss -0.3871 
2025-08-30 12:54:39.089093: val_loss -0.455 
2025-08-30 12:54:39.093262: Pseudo dice [np.float32(0.6508)] 
2025-08-30 12:54:39.100052: Epoch time: 26.34 s 
2025-08-30 12:54:39.706409:  
2025-08-30 12:54:39.711952: Epoch 55 
2025-08-30 12:54:39.719973: Current learning rate: 0.00095 
2025-08-30 12:55:05.828676: train_loss -0.4144 
2025-08-30 12:55:05.841187: val_loss -0.4931 
2025-08-30 12:55:05.845367: Pseudo dice [np.float32(0.7281)] 
2025-08-30 12:55:05.853599: Epoch time: 26.13 s 
2025-08-30 12:55:05.857819: Yayy! New best EMA pseudo Dice: 0.6646000146865845 
2025-08-30 12:55:06.814021:  
2025-08-30 12:55:06.822055: Epoch 56 
2025-08-30 12:55:06.826175: Current learning rate: 0.00095 
2025-08-30 12:55:33.260190: train_loss -0.4666 
2025-08-30 12:55:33.268507: val_loss -0.4463 
2025-08-30 12:55:33.272620: Pseudo dice [np.float32(0.7114)] 
2025-08-30 12:55:33.280648: Epoch time: 26.45 s 
2025-08-30 12:55:33.285178: Yayy! New best EMA pseudo Dice: 0.6693000197410583 
2025-08-30 12:55:34.090882:  
2025-08-30 12:55:34.098133: Epoch 57 
2025-08-30 12:55:34.103397: Current learning rate: 0.00095 
2025-08-30 12:55:59.389998: train_loss -0.3841 
2025-08-30 12:55:59.403527: val_loss -0.4183 
2025-08-30 12:55:59.406706: Pseudo dice [np.float32(0.6518)] 
2025-08-30 12:55:59.415571: Epoch time: 25.3 s 
2025-08-30 12:56:00.023968:  
2025-08-30 12:56:00.032327: Epoch 58 
2025-08-30 12:56:00.037591: Current learning rate: 0.00095 
2025-08-30 12:56:27.972890: train_loss -0.4603 
2025-08-30 12:56:27.981023: val_loss -0.4982 
2025-08-30 12:56:27.985229: Pseudo dice [np.float32(0.7019)] 
2025-08-30 12:56:27.991981: Epoch time: 27.95 s 
2025-08-30 12:56:27.998117: Yayy! New best EMA pseudo Dice: 0.6710000038146973 
2025-08-30 12:56:28.845486:  
2025-08-30 12:56:28.853825: Epoch 59 
2025-08-30 12:56:28.858055: Current learning rate: 0.00095 
2025-08-30 12:56:58.770464: train_loss -0.4252 
2025-08-30 12:56:58.774223: val_loss -0.4346 
2025-08-30 12:56:58.783461: Pseudo dice [np.float32(0.6756)] 
2025-08-30 12:56:58.790320: Epoch time: 29.93 s 
2025-08-30 12:56:58.796656: Yayy! New best EMA pseudo Dice: 0.671500027179718 
2025-08-30 12:56:59.831452:  
2025-08-30 12:56:59.839794: Epoch 60 
2025-08-30 12:56:59.846153: Current learning rate: 0.00095 
2025-08-30 12:57:29.146280: train_loss -0.4155 
2025-08-30 12:57:29.154842: val_loss -0.4793 
2025-08-30 12:57:29.158702: Pseudo dice [np.float32(0.651)] 
2025-08-30 12:57:29.167439: Epoch time: 29.32 s 
2025-08-30 12:57:29.805209:  
2025-08-30 12:57:29.810472: Epoch 61 
2025-08-30 12:57:29.817742: Current learning rate: 0.00094 
2025-08-30 12:57:58.972085: train_loss -0.447 
2025-08-30 12:57:58.980548: val_loss -0.515 
2025-08-30 12:57:58.984683: Pseudo dice [np.float32(0.7229)] 
2025-08-30 12:57:58.993172: Epoch time: 29.17 s 
2025-08-30 12:57:58.997638: Yayy! New best EMA pseudo Dice: 0.6747999787330627 
2025-08-30 12:58:00.006178:  
2025-08-30 12:58:00.014523: Epoch 62 
2025-08-30 12:58:00.020091: Current learning rate: 0.00094 
2025-08-30 12:58:28.835208: train_loss -0.4352 
2025-08-30 12:58:28.839491: val_loss -0.4643 
2025-08-30 12:58:28.847851: Pseudo dice [np.float32(0.6862)] 
2025-08-30 12:58:28.853129: Epoch time: 28.83 s 
2025-08-30 12:58:28.856118: Yayy! New best EMA pseudo Dice: 0.6758999824523926 
2025-08-30 12:58:29.703490:  
2025-08-30 12:58:29.711864: Epoch 63 
2025-08-30 12:58:29.716010: Current learning rate: 0.00094 
2025-08-30 12:58:58.748488: train_loss -0.4523 
2025-08-30 12:58:58.760537: val_loss -0.4268 
2025-08-30 12:58:58.765162: Pseudo dice [np.float32(0.6338)] 
2025-08-30 12:58:58.770504: Epoch time: 29.04 s 
2025-08-30 12:58:59.412324:  
2025-08-30 12:58:59.420632: Epoch 64 
2025-08-30 12:58:59.424769: Current learning rate: 0.00094 
2025-08-30 12:59:28.358272: train_loss -0.472 
2025-08-30 12:59:28.365486: val_loss -0.3924 
2025-08-30 12:59:28.369741: Pseudo dice [np.float32(0.6769)] 
2025-08-30 12:59:28.377565: Epoch time: 28.95 s 
2025-08-30 12:59:29.040773:  
2025-08-30 12:59:29.046374: Epoch 65 
2025-08-30 12:59:29.053254: Current learning rate: 0.00094 
2025-08-30 12:59:57.561153: train_loss -0.3949 
2025-08-30 12:59:57.569620: val_loss -0.4545 
2025-08-30 12:59:57.573766: Pseudo dice [np.float32(0.7084)] 
2025-08-30 12:59:57.580040: Epoch time: 28.52 s 
2025-08-30 12:59:58.241818:  
2025-08-30 12:59:58.253238: Epoch 66 
2025-08-30 12:59:58.258518: Current learning rate: 0.00094 
2025-08-30 13:00:27.053079: train_loss -0.4895 
2025-08-30 13:00:27.061433: val_loss -0.5364 
2025-08-30 13:00:27.065557: Pseudo dice [np.float32(0.7727)] 
2025-08-30 13:00:27.074095: Epoch time: 28.81 s 
2025-08-30 13:00:27.078454: Yayy! New best EMA pseudo Dice: 0.6855000257492065 
2025-08-30 13:00:27.934289:  
2025-08-30 13:00:27.942283: Epoch 67 
2025-08-30 13:00:27.946416: Current learning rate: 0.00094 
2025-08-30 13:00:58.154582: train_loss -0.4086 
2025-08-30 13:00:58.163247: val_loss -0.5238 
2025-08-30 13:00:58.167411: Pseudo dice [np.float32(0.7289)] 
2025-08-30 13:00:58.173934: Epoch time: 30.22 s 
2025-08-30 13:00:58.180052: Yayy! New best EMA pseudo Dice: 0.6898999810218811 
2025-08-30 13:00:59.303108:  
2025-08-30 13:00:59.310997: Epoch 68 
2025-08-30 13:00:59.318249: Current learning rate: 0.00094 
2025-08-30 13:01:27.968161: train_loss -0.4633 
2025-08-30 13:01:27.968161: val_loss -0.4781 
2025-08-30 13:01:27.977677: Pseudo dice [np.float32(0.7286)] 
2025-08-30 13:01:27.982736: Epoch time: 28.67 s 
2025-08-30 13:01:27.998241: Yayy! New best EMA pseudo Dice: 0.6937000155448914 
2025-08-30 13:01:28.895040:  
2025-08-30 13:01:28.903042: Epoch 69 
2025-08-30 13:01:28.907150: Current learning rate: 0.00094 
2025-08-30 13:01:58.089787: train_loss -0.4275 
2025-08-30 13:01:58.097683: val_loss -0.3947 
2025-08-30 13:01:58.102173: Pseudo dice [np.float32(0.632)] 
2025-08-30 13:01:58.107616: Epoch time: 29.19 s 
2025-08-30 13:01:58.795324:  
2025-08-30 13:01:58.807828: Epoch 70 
2025-08-30 13:01:58.812031: Current learning rate: 0.00094 
2025-08-30 13:02:27.732524: train_loss -0.4762 
2025-08-30 13:02:27.740163: val_loss -0.4141 
2025-08-30 13:02:27.744334: Pseudo dice [np.float32(0.606)] 
2025-08-30 13:02:27.749660: Epoch time: 28.94 s 
2025-08-30 13:02:28.408531:  
2025-08-30 13:02:28.416887: Epoch 71 
2025-08-30 13:02:28.421021: Current learning rate: 0.00094 
2025-08-30 13:02:58.671066: train_loss -0.4157 
2025-08-30 13:02:58.683572: val_loss -0.4934 
2025-08-30 13:02:58.691442: Pseudo dice [np.float32(0.6661)] 
2025-08-30 13:02:58.697511: Epoch time: 30.26 s 
2025-08-30 13:02:59.426600:  
2025-08-30 13:02:59.434960: Epoch 72 
2025-08-30 13:02:59.439108: Current learning rate: 0.00093 
2025-08-30 13:03:28.634794: train_loss -0.4526 
2025-08-30 13:03:28.642555: val_loss -0.4136 
2025-08-30 13:03:28.646764: Pseudo dice [np.float32(0.677)] 
2025-08-30 13:03:28.654048: Epoch time: 29.21 s 
2025-08-30 13:03:29.302218:  
2025-08-30 13:03:29.310581: Epoch 73 
2025-08-30 13:03:29.314755: Current learning rate: 0.00093 
2025-08-30 13:03:58.359665: train_loss -0.4007 
2025-08-30 13:03:58.368043: val_loss -0.4024 
2025-08-30 13:03:58.372197: Pseudo dice [np.float32(0.706)] 
2025-08-30 13:03:58.380157: Epoch time: 29.06 s 
2025-08-30 13:03:59.082749:  
2025-08-30 13:03:59.094010: Epoch 74 
2025-08-30 13:03:59.098929: Current learning rate: 0.00093 
2025-08-30 13:04:28.055852: train_loss -0.4478 
2025-08-30 13:04:28.064239: val_loss -0.4395 
2025-08-30 13:04:28.072555: Pseudo dice [np.float32(0.6919)] 
2025-08-30 13:04:28.077987: Epoch time: 28.97 s 
2025-08-30 13:04:28.760458:  
2025-08-30 13:04:28.765687: Epoch 75 
2025-08-30 13:04:28.774046: Current learning rate: 0.00093 
2025-08-30 13:04:58.357011: train_loss -0.4447 
2025-08-30 13:04:58.365341: val_loss -0.4995 
2025-08-30 13:04:58.373269: Pseudo dice [np.float32(0.646)] 
2025-08-30 13:04:58.377977: Epoch time: 29.6 s 
2025-08-30 13:04:59.095944:  
2025-08-30 13:04:59.107341: Epoch 76 
2025-08-30 13:04:59.112636: Current learning rate: 0.00093 
2025-08-30 13:05:27.882374: train_loss -0.4674 
2025-08-30 13:05:27.890619: val_loss -0.4803 
2025-08-30 13:05:27.898556: Pseudo dice [np.float32(0.6853)] 
2025-08-30 13:05:27.903239: Epoch time: 28.79 s 
2025-08-30 13:05:28.604516:  
2025-08-30 13:05:28.611757: Epoch 77 
2025-08-30 13:05:28.618010: Current learning rate: 0.00093 
2025-08-30 13:05:57.791234: train_loss -0.4639 
2025-08-30 13:05:57.799629: val_loss -0.4933 
2025-08-30 13:05:57.807544: Pseudo dice [np.float32(0.6938)] 
2025-08-30 13:05:57.812314: Epoch time: 29.19 s 
2025-08-30 13:05:58.496830:  
2025-08-30 13:05:58.505531: Epoch 78 
2025-08-30 13:05:58.509315: Current learning rate: 0.00093 
2025-08-30 13:06:27.696061: train_loss -0.4508 
2025-08-30 13:06:27.696061: val_loss -0.4913 
2025-08-30 13:06:27.705848: Pseudo dice [np.float32(0.7271)] 
2025-08-30 13:06:27.712375: Epoch time: 29.2 s 
2025-08-30 13:06:28.422522:  
2025-08-30 13:06:28.430848: Epoch 79 
2025-08-30 13:06:28.438088: Current learning rate: 0.00093 
2025-08-30 13:06:57.409069: train_loss -0.4373 
2025-08-30 13:06:57.417418: val_loss -0.4925 
2025-08-30 13:06:57.425803: Pseudo dice [np.float32(0.7121)] 
2025-08-30 13:06:57.431133: Epoch time: 28.99 s 
2025-08-30 13:06:58.231376:  
2025-08-30 13:06:58.239727: Epoch 80 
2025-08-30 13:06:58.244703: Current learning rate: 0.00093 
2025-08-30 13:07:27.764631: train_loss -0.4565 
2025-08-30 13:07:27.776427: val_loss -0.5551 
2025-08-30 13:07:27.780982: Pseudo dice [np.float32(0.7079)] 
2025-08-30 13:07:27.787360: Epoch time: 29.53 s 
2025-08-30 13:07:28.449347:  
2025-08-30 13:07:28.457352: Epoch 81 
2025-08-30 13:07:28.461487: Current learning rate: 0.00093 
2025-08-30 13:07:57.177072: train_loss -0.4847 
2025-08-30 13:07:57.185309: val_loss -0.4452 
2025-08-30 13:07:57.189394: Pseudo dice [np.float32(0.6762)] 
2025-08-30 13:07:57.197411: Epoch time: 28.73 s 
2025-08-30 13:07:57.879138:  
2025-08-30 13:07:57.886736: Epoch 82 
2025-08-30 13:07:57.893977: Current learning rate: 0.00093 
2025-08-30 13:08:26.597546: train_loss -0.4356 
2025-08-30 13:08:26.606323: val_loss -0.5142 
2025-08-30 13:08:26.610479: Pseudo dice [np.float32(0.7647)] 
2025-08-30 13:08:26.619136: Epoch time: 28.72 s 
2025-08-30 13:08:26.622953: Yayy! New best EMA pseudo Dice: 0.6960999965667725 
2025-08-30 13:08:27.473421:  
2025-08-30 13:08:27.481817: Epoch 83 
2025-08-30 13:08:27.487072: Current learning rate: 0.00092 
2025-08-30 13:08:56.390154: train_loss -0.4436 
2025-08-30 13:08:56.398541: val_loss -0.4221 
2025-08-30 13:08:56.402609: Pseudo dice [np.float32(0.6572)] 
2025-08-30 13:08:56.410628: Epoch time: 28.92 s 
2025-08-30 13:08:57.037318:  
2025-08-30 13:08:57.045693: Epoch 84 
2025-08-30 13:08:57.052930: Current learning rate: 0.00092 
2025-08-30 13:09:25.836105: train_loss -0.4729 
2025-08-30 13:09:25.848628: val_loss -0.483 
2025-08-30 13:09:25.852789: Pseudo dice [np.float32(0.7301)] 
2025-08-30 13:09:25.858259: Epoch time: 28.8 s 
2025-08-30 13:09:26.500041:  
2025-08-30 13:09:26.508407: Epoch 85 
2025-08-30 13:09:26.512916: Current learning rate: 0.00092 
2025-08-30 13:09:54.965190: train_loss -0.4665 
2025-08-30 13:09:54.973606: val_loss -0.5373 
2025-08-30 13:09:54.977772: Pseudo dice [np.float32(0.7893)] 
2025-08-30 13:09:54.985055: Epoch time: 28.47 s 
2025-08-30 13:09:54.990071: Yayy! New best EMA pseudo Dice: 0.705299973487854 
2025-08-30 13:09:55.908870:  
2025-08-30 13:09:55.917218: Epoch 86 
2025-08-30 13:09:55.921073: Current learning rate: 0.00092 
2025-08-30 13:10:25.379301: train_loss -0.4138 
2025-08-30 13:10:25.387255: val_loss -0.486 
2025-08-30 13:10:25.395603: Pseudo dice [np.float32(0.6882)] 
2025-08-30 13:10:25.399905: Epoch time: 29.47 s 
2025-08-30 13:10:26.226279:  
2025-08-30 13:10:26.234603: Epoch 87 
2025-08-30 13:10:26.238781: Current learning rate: 0.00092 
2025-08-30 13:10:54.821142: train_loss -0.4886 
2025-08-30 13:10:54.821142: val_loss -0.503 
2025-08-30 13:10:54.829467: Pseudo dice [np.float32(0.745)] 
2025-08-30 13:10:54.835472: Epoch time: 28.6 s 
2025-08-30 13:10:54.841582: Yayy! New best EMA pseudo Dice: 0.7077999711036682 
2025-08-30 13:10:55.701699:  
2025-08-30 13:10:55.708732: Epoch 88 
2025-08-30 13:10:55.714002: Current learning rate: 0.00092 
2025-08-30 13:11:24.504416: train_loss -0.4701 
2025-08-30 13:11:24.516683: val_loss -0.4626 
2025-08-30 13:11:24.521110: Pseudo dice [np.float32(0.6926)] 
2025-08-30 13:11:24.527546: Epoch time: 28.81 s 
2025-08-30 13:11:25.175620:  
2025-08-30 13:11:25.180902: Epoch 89 
2025-08-30 13:11:25.188138: Current learning rate: 0.00092 
2025-08-30 13:11:54.222094: train_loss -0.4178 
2025-08-30 13:11:54.229993: val_loss -0.446 
2025-08-30 13:11:54.234161: Pseudo dice [np.float32(0.7434)] 
2025-08-30 13:11:54.241417: Epoch time: 29.05 s 
2025-08-30 13:11:54.247147: Yayy! New best EMA pseudo Dice: 0.7099999785423279 
2025-08-30 13:11:55.139956:  
2025-08-30 13:11:55.147161: Epoch 90 
2025-08-30 13:11:55.152460: Current learning rate: 0.00092 
2025-08-30 13:12:23.650559: train_loss -0.456 
2025-08-30 13:12:23.659332: val_loss -0.4305 
2025-08-30 13:12:23.663535: Pseudo dice [np.float32(0.689)] 
2025-08-30 13:12:23.671439: Epoch time: 28.51 s 
2025-08-30 13:12:24.306492:  
2025-08-30 13:12:24.314860: Epoch 91 
2025-08-30 13:12:24.319028: Current learning rate: 0.00092 
2025-08-30 13:12:53.868583: train_loss -0.4822 
2025-08-30 13:12:53.877022: val_loss -0.4769 
2025-08-30 13:12:53.881161: Pseudo dice [np.float32(0.7334)] 
2025-08-30 13:12:53.888395: Epoch time: 29.56 s 
2025-08-30 13:12:53.894199: Yayy! New best EMA pseudo Dice: 0.7103999853134155 
2025-08-30 13:12:54.744111:  
2025-08-30 13:12:54.752450: Epoch 92 
2025-08-30 13:12:54.757723: Current learning rate: 0.00092 
2025-08-30 13:13:23.377024: train_loss -0.4673 
2025-08-30 13:13:23.385467: val_loss -0.4971 
2025-08-30 13:13:23.393517: Pseudo dice [np.float32(0.7471)] 
2025-08-30 13:13:23.398384: Epoch time: 28.64 s 
2025-08-30 13:13:23.404253: Yayy! New best EMA pseudo Dice: 0.7141000032424927 
2025-08-30 13:13:24.400518:  
2025-08-30 13:13:24.408806: Epoch 93 
2025-08-30 13:13:24.415356: Current learning rate: 0.00092 
2025-08-30 13:13:53.032808: train_loss -0.4774 
2025-08-30 13:13:53.040060: val_loss -0.4429 
2025-08-30 13:13:53.044298: Pseudo dice [np.float32(0.6852)] 
2025-08-30 13:13:53.050623: Epoch time: 28.63 s 
2025-08-30 13:13:53.683775:  
2025-08-30 13:13:53.690363: Epoch 94 
2025-08-30 13:13:53.695643: Current learning rate: 0.00091 
2025-08-30 13:14:22.678002: train_loss -0.4943 
2025-08-30 13:14:22.686336: val_loss -0.5209 
2025-08-30 13:14:22.690618: Pseudo dice [np.float32(0.7242)] 
2025-08-30 13:14:22.699029: Epoch time: 29.0 s 
2025-08-30 13:14:23.337696:  
2025-08-30 13:14:23.346012: Epoch 95 
2025-08-30 13:14:23.350243: Current learning rate: 0.00091 
2025-08-30 13:14:51.531742: train_loss -0.4918 
2025-08-30 13:14:51.535969: val_loss -0.446 
2025-08-30 13:14:51.544338: Pseudo dice [np.float32(0.6759)] 
2025-08-30 13:14:51.550649: Epoch time: 28.19 s 
2025-08-30 13:14:52.186183:  
2025-08-30 13:14:52.194532: Epoch 96 
2025-08-30 13:14:52.199813: Current learning rate: 0.00091 
2025-08-30 13:15:21.244735: train_loss -0.4937 
2025-08-30 13:15:21.244735: val_loss -0.4696 
2025-08-30 13:15:21.253112: Pseudo dice [np.float32(0.7581)] 
2025-08-30 13:15:21.261858: Epoch time: 29.06 s 
2025-08-30 13:15:21.904409:  
2025-08-30 13:15:21.912809: Epoch 97 
2025-08-30 13:15:21.921116: Current learning rate: 0.00091 
2025-08-30 13:15:51.353528: train_loss -0.4783 
2025-08-30 13:15:51.358144: val_loss -0.481 
2025-08-30 13:15:51.366870: Pseudo dice [np.float32(0.6779)] 
2025-08-30 13:15:51.371813: Epoch time: 29.45 s 
2025-08-30 13:15:52.020838:  
2025-08-30 13:15:52.026138: Epoch 98 
2025-08-30 13:15:52.030267: Current learning rate: 0.00091 
2025-08-30 13:16:20.787330: train_loss -0.4659 
2025-08-30 13:16:20.799541: val_loss -0.4791 
2025-08-30 13:16:20.804059: Pseudo dice [np.float32(0.7362)] 
2025-08-30 13:16:20.810568: Epoch time: 28.77 s 
2025-08-30 13:16:21.451287:  
2025-08-30 13:16:21.459615: Epoch 99 
2025-08-30 13:16:21.464155: Current learning rate: 0.00091 
2025-08-30 13:16:50.441920: train_loss -0.4556 
2025-08-30 13:16:50.449940: val_loss -0.4388 
2025-08-30 13:16:50.454520: Pseudo dice [np.float32(0.753)] 
2025-08-30 13:16:50.460792: Epoch time: 28.99 s 
2025-08-30 13:16:50.867344: Yayy! New best EMA pseudo Dice: 0.7167999744415283 
2025-08-30 13:16:51.726210:  
2025-08-30 13:16:51.734555: Epoch 100 
2025-08-30 13:16:51.739748: Current learning rate: 0.00091 
2025-08-30 13:17:20.684685: train_loss -0.4962 
2025-08-30 13:17:20.693000: val_loss -0.4352 
2025-08-30 13:17:20.700942: Pseudo dice [np.float32(0.7409)] 
2025-08-30 13:17:20.705621: Epoch time: 28.96 s 
2025-08-30 13:17:20.709832: Yayy! New best EMA pseudo Dice: 0.7192000150680542 
2025-08-30 13:17:21.548726:  
2025-08-30 13:17:21.557061: Epoch 101 
2025-08-30 13:17:21.564299: Current learning rate: 0.00091 
2025-08-30 13:17:50.168417: train_loss -0.4877 
2025-08-30 13:17:50.176550: val_loss -0.5022 
2025-08-30 13:17:50.184931: Pseudo dice [np.float32(0.7253)] 
2025-08-30 13:17:50.190276: Epoch time: 28.62 s 
2025-08-30 13:17:50.193609: Yayy! New best EMA pseudo Dice: 0.7197999954223633 
2025-08-30 13:17:51.044811:  
2025-08-30 13:17:51.053140: Epoch 102 
2025-08-30 13:17:51.057339: Current learning rate: 0.00091 
2025-08-30 13:18:20.035469: train_loss -0.465 
2025-08-30 13:18:20.043911: val_loss -0.489 
2025-08-30 13:18:20.048047: Pseudo dice [np.float32(0.686)] 
2025-08-30 13:18:20.056502: Epoch time: 28.99 s 
2025-08-30 13:18:20.698286:  
2025-08-30 13:18:20.703550: Epoch 103 
2025-08-30 13:18:20.710781: Current learning rate: 0.00091 
2025-08-30 13:18:49.719191: train_loss -0.5142 
2025-08-30 13:18:49.727514: val_loss -0.4607 
2025-08-30 13:18:49.731693: Pseudo dice [np.float32(0.7541)] 
2025-08-30 13:18:49.739716: Epoch time: 29.02 s 
2025-08-30 13:18:49.744255: Yayy! New best EMA pseudo Dice: 0.7202000021934509 
2025-08-30 13:18:50.616682:  
2025-08-30 13:18:50.623944: Epoch 104 
2025-08-30 13:18:50.629225: Current learning rate: 0.00091 
2025-08-30 13:19:18.668610: train_loss -0.4907 
2025-08-30 13:19:18.677211: val_loss -0.4965 
2025-08-30 13:19:18.685605: Pseudo dice [np.float32(0.7463)] 
2025-08-30 13:19:18.690055: Epoch time: 28.06 s 
2025-08-30 13:19:18.695767: Yayy! New best EMA pseudo Dice: 0.7228000164031982 
2025-08-30 13:19:19.533015:  
2025-08-30 13:19:19.541422: Epoch 105 
2025-08-30 13:19:19.548658: Current learning rate: 0.0009 
2025-08-30 13:19:49.082603: train_loss -0.4864 
2025-08-30 13:19:49.091023: val_loss -0.539 
2025-08-30 13:19:49.095126: Pseudo dice [np.float32(0.7119)] 
2025-08-30 13:19:49.103081: Epoch time: 29.55 s 
2025-08-30 13:19:49.896649:  
2025-08-30 13:19:49.903881: Epoch 106 
2025-08-30 13:19:49.909547: Current learning rate: 0.0009 
2025-08-30 13:20:17.611577: train_loss -0.4849 
2025-08-30 13:20:17.611577: val_loss -0.5289 
2025-08-30 13:20:17.622105: Pseudo dice [np.float32(0.7597)] 
2025-08-30 13:20:17.627844: Epoch time: 27.72 s 
2025-08-30 13:20:17.634086: Yayy! New best EMA pseudo Dice: 0.7254999876022339 
2025-08-30 13:20:18.495994:  
2025-08-30 13:20:18.504361: Epoch 107 
2025-08-30 13:20:18.508516: Current learning rate: 0.0009 
2025-08-30 13:20:46.535802: train_loss -0.4911 
2025-08-30 13:20:46.544123: val_loss -0.541 
2025-08-30 13:20:46.548325: Pseudo dice [np.float32(0.7757)] 
2025-08-30 13:20:46.556528: Epoch time: 28.04 s 
2025-08-30 13:20:46.560760: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2025-08-30 13:20:47.433153:  
2025-08-30 13:20:47.441562: Epoch 108 
2025-08-30 13:20:47.449886: Current learning rate: 0.0009 
2025-08-30 13:21:15.401615: train_loss -0.4963 
2025-08-30 13:21:15.410388: val_loss -0.4767 
2025-08-30 13:21:15.414579: Pseudo dice [np.float32(0.749)] 
2025-08-30 13:21:15.422910: Epoch time: 27.97 s 
2025-08-30 13:21:15.427045: Yayy! New best EMA pseudo Dice: 0.7324000000953674 
2025-08-30 13:21:16.286925:  
2025-08-30 13:21:16.295274: Epoch 109 
2025-08-30 13:21:16.299809: Current learning rate: 0.0009 
2025-08-30 13:21:44.036459: train_loss -0.4572 
2025-08-30 13:21:44.043111: val_loss -0.527 
2025-08-30 13:21:44.047307: Pseudo dice [np.float32(0.7613)] 
2025-08-30 13:21:44.055674: Epoch time: 27.75 s 
2025-08-30 13:21:44.059961: Yayy! New best EMA pseudo Dice: 0.7353000044822693 
2025-08-30 13:21:44.903007:  
2025-08-30 13:21:44.910218: Epoch 110 
2025-08-30 13:21:44.915481: Current learning rate: 0.0009 
2025-08-30 13:22:13.159593: train_loss -0.4713 
2025-08-30 13:22:13.167970: val_loss -0.5283 
2025-08-30 13:22:13.176362: Pseudo dice [np.float32(0.7277)] 
2025-08-30 13:22:13.180661: Epoch time: 28.26 s 
2025-08-30 13:22:13.827654:  
2025-08-30 13:22:13.835993: Epoch 111 
2025-08-30 13:22:13.840932: Current learning rate: 0.0009 
2025-08-30 13:22:41.833646: train_loss -0.5003 
2025-08-30 13:22:41.838241: val_loss -0.4165 
2025-08-30 13:22:41.846635: Pseudo dice [np.float32(0.6552)] 
2025-08-30 13:22:41.850952: Epoch time: 28.01 s 
2025-08-30 13:22:42.639696:  
2025-08-30 13:22:42.648052: Epoch 112 
2025-08-30 13:22:42.652238: Current learning rate: 0.0009 
2025-08-30 13:23:10.566845: train_loss -0.4729 
2025-08-30 13:23:10.575258: val_loss -0.4237 
2025-08-30 13:23:10.583616: Pseudo dice [np.float32(0.6914)] 
2025-08-30 13:23:10.589890: Epoch time: 27.93 s 
2025-08-30 13:23:11.230715:  
2025-08-30 13:23:11.237970: Epoch 113 
2025-08-30 13:23:11.243865: Current learning rate: 0.0009 
2025-08-30 13:23:39.524865: train_loss -0.4641 
2025-08-30 13:23:39.533257: val_loss -0.4804 
2025-08-30 13:23:39.537494: Pseudo dice [np.float32(0.7162)] 
2025-08-30 13:23:39.546095: Epoch time: 28.3 s 
2025-08-30 13:23:40.205448:  
2025-08-30 13:23:40.213836: Epoch 114 
2025-08-30 13:23:40.218326: Current learning rate: 0.0009 
2025-08-30 13:24:08.253489: train_loss -0.4681 
2025-08-30 13:24:08.261964: val_loss -0.5359 
2025-08-30 13:24:08.266116: Pseudo dice [np.float32(0.7662)] 
2025-08-30 13:24:08.274547: Epoch time: 28.05 s 
2025-08-30 13:24:08.916304:  
2025-08-30 13:24:08.924656: Epoch 115 
2025-08-30 13:24:08.929965: Current learning rate: 0.0009 
2025-08-30 13:24:36.869584: train_loss -0.4829 
2025-08-30 13:24:36.877941: val_loss -0.4852 
2025-08-30 13:24:36.882082: Pseudo dice [np.float32(0.6915)] 
2025-08-30 13:24:36.890665: Epoch time: 27.96 s 
2025-08-30 13:24:37.579339:  
2025-08-30 13:24:37.579339: Epoch 116 
2025-08-30 13:24:37.586616: Current learning rate: 0.00089 
2025-08-30 13:25:05.397627: train_loss -0.4715 
2025-08-30 13:25:05.397627: val_loss -0.512 
2025-08-30 13:25:05.407613: Pseudo dice [np.float32(0.729)] 
2025-08-30 13:25:05.412669: Epoch time: 27.82 s 
2025-08-30 13:25:06.070221:  
2025-08-30 13:25:06.077468: Epoch 117 
2025-08-30 13:25:06.083473: Current learning rate: 0.00089 
2025-08-30 13:25:33.989400: train_loss -0.4889 
2025-08-30 13:25:33.997294: val_loss -0.5141 
2025-08-30 13:25:34.001495: Pseudo dice [np.float32(0.72)] 
2025-08-30 13:25:34.007892: Epoch time: 27.92 s 
2025-08-30 13:25:34.674548:  
2025-08-30 13:25:34.682132: Epoch 118 
2025-08-30 13:25:34.689386: Current learning rate: 0.00089 
2025-08-30 13:26:02.075478: train_loss -0.4532 
2025-08-30 13:26:02.083764: val_loss -0.4238 
2025-08-30 13:26:02.091677: Pseudo dice [np.float32(0.6545)] 
2025-08-30 13:26:02.096362: Epoch time: 27.4 s 
2025-08-30 13:26:02.960275:  
2025-08-30 13:26:02.971704: Epoch 119 
2025-08-30 13:26:02.977014: Current learning rate: 0.00089 
2025-08-30 13:26:30.849870: train_loss -0.5171 
2025-08-30 13:26:30.858257: val_loss -0.4969 
2025-08-30 13:26:30.862364: Pseudo dice [np.float32(0.7468)] 
2025-08-30 13:26:30.869664: Epoch time: 27.89 s 
2025-08-30 13:26:31.522670:  
2025-08-30 13:26:31.530442: Epoch 120 
2025-08-30 13:26:31.537694: Current learning rate: 0.00089 
2025-08-30 13:26:59.736635: train_loss -0.4536 
2025-08-30 13:26:59.742083: val_loss -0.4809 
2025-08-30 13:26:59.749612: Pseudo dice [np.float32(0.7212)] 
2025-08-30 13:26:59.755923: Epoch time: 28.21 s 
2025-08-30 13:27:00.560083:  
2025-08-30 13:27:00.568113: Epoch 121 
2025-08-30 13:27:00.574990: Current learning rate: 0.00089 
2025-08-30 13:27:28.215042: train_loss -0.4832 
2025-08-30 13:27:28.223745: val_loss -0.5395 
2025-08-30 13:27:28.227883: Pseudo dice [np.float32(0.7401)] 
2025-08-30 13:27:28.234257: Epoch time: 27.66 s 
2025-08-30 13:27:28.891831:  
2025-08-30 13:27:28.900139: Epoch 122 
2025-08-30 13:27:28.904649: Current learning rate: 0.00089 
2025-08-30 13:27:56.643733: train_loss -0.493 
2025-08-30 13:27:56.652166: val_loss -0.456 
2025-08-30 13:27:56.660890: Pseudo dice [np.float32(0.7209)] 
2025-08-30 13:27:56.665803: Epoch time: 27.75 s 
2025-08-30 13:27:57.320590:  
2025-08-30 13:27:57.327441: Epoch 123 
2025-08-30 13:27:57.332708: Current learning rate: 0.00089 
2025-08-30 13:28:24.859420: train_loss -0.478 
2025-08-30 13:28:24.867802: val_loss -0.5037 
2025-08-30 13:28:24.876143: Pseudo dice [np.float32(0.7506)] 
2025-08-30 13:28:24.881500: Epoch time: 27.54 s 
2025-08-30 13:28:25.524153:  
2025-08-30 13:28:25.531648: Epoch 124 
2025-08-30 13:28:25.535817: Current learning rate: 0.00089 
2025-08-30 13:28:52.962452: train_loss -0.5015 
2025-08-30 13:28:52.970809: val_loss -0.5024 
2025-08-30 13:28:52.975005: Pseudo dice [np.float32(0.6979)] 
2025-08-30 13:28:52.981260: Epoch time: 27.44 s 
2025-08-30 13:28:53.771213:  
2025-08-30 13:28:53.776451: Epoch 125 
2025-08-30 13:28:53.783730: Current learning rate: 0.00089 
2025-08-30 13:29:21.611834: train_loss -0.5278 
2025-08-30 13:29:21.611834: val_loss -0.5414 
2025-08-30 13:29:21.621567: Pseudo dice [np.float32(0.7723)] 
2025-08-30 13:29:21.626517: Epoch time: 27.84 s 
2025-08-30 13:29:22.271513:  
2025-08-30 13:29:22.279841: Epoch 126 
2025-08-30 13:29:22.284822: Current learning rate: 0.00089 
2025-08-30 13:29:50.048560: train_loss -0.5131 
2025-08-30 13:29:50.056914: val_loss -0.5672 
2025-08-30 13:29:50.061086: Pseudo dice [np.float32(0.7709)] 
2025-08-30 13:29:50.068975: Epoch time: 27.78 s 
2025-08-30 13:29:50.720751:  
2025-08-30 13:29:50.729091: Epoch 127 
2025-08-30 13:29:50.736343: Current learning rate: 0.00088 
2025-08-30 13:30:18.101569: train_loss -0.4971 
2025-08-30 13:30:18.109838: val_loss -0.5807 
2025-08-30 13:30:18.113942: Pseudo dice [np.float32(0.7571)] 
2025-08-30 13:30:18.122483: Epoch time: 27.38 s 
2025-08-30 13:30:18.811251:  
2025-08-30 13:30:18.818479: Epoch 128 
2025-08-30 13:30:18.824641: Current learning rate: 0.00088 
2025-08-30 13:30:46.654956: train_loss -0.4826 
2025-08-30 13:30:46.663347: val_loss -0.5118 
2025-08-30 13:30:46.667549: Pseudo dice [np.float32(0.7581)] 
2025-08-30 13:30:46.674760: Epoch time: 27.84 s 
2025-08-30 13:30:46.680502: Yayy! New best EMA pseudo Dice: 0.736299991607666 
2025-08-30 13:30:47.665040:  
2025-08-30 13:30:47.674258: Epoch 129 
2025-08-30 13:30:47.680598: Current learning rate: 0.00088 
2025-08-30 13:31:15.150235: train_loss -0.4736 
2025-08-30 13:31:15.162606: val_loss -0.4689 
2025-08-30 13:31:15.166752: Pseudo dice [np.float32(0.7329)] 
2025-08-30 13:31:15.175127: Epoch time: 27.49 s 
2025-08-30 13:31:15.838949:  
2025-08-30 13:31:15.847279: Epoch 130 
2025-08-30 13:31:15.851793: Current learning rate: 0.00088 
2025-08-30 13:31:43.357333: train_loss -0.4621 
2025-08-30 13:31:43.365348: val_loss -0.4583 
2025-08-30 13:31:43.369917: Pseudo dice [np.float32(0.6937)] 
2025-08-30 13:31:43.376190: Epoch time: 27.52 s 
2025-08-30 13:31:44.166391:  
2025-08-30 13:31:44.170692: Epoch 131 
2025-08-30 13:31:44.179085: Current learning rate: 0.00088 
2025-08-30 13:32:12.090787: train_loss -0.5295 
2025-08-30 13:32:12.098537: val_loss -0.4789 
2025-08-30 13:32:12.106482: Pseudo dice [np.float32(0.7059)] 
2025-08-30 13:32:12.111742: Epoch time: 27.93 s 
2025-08-30 13:32:12.749067:  
2025-08-30 13:32:12.757088: Epoch 132 
2025-08-30 13:32:12.761711: Current learning rate: 0.00088 
2025-08-30 13:32:40.426844: train_loss -0.4722 
2025-08-30 13:32:40.435107: val_loss -0.4934 
2025-08-30 13:32:40.439337: Pseudo dice [np.float32(0.722)] 
2025-08-30 13:32:40.447302: Epoch time: 27.68 s 
2025-08-30 13:32:41.089876:  
2025-08-30 13:32:41.098320: Epoch 133 
2025-08-30 13:32:41.106535: Current learning rate: 0.00088 
2025-08-30 13:33:08.805076: train_loss -0.4886 
2025-08-30 13:33:08.817485: val_loss -0.553 
2025-08-30 13:33:08.821636: Pseudo dice [np.float32(0.7602)] 
2025-08-30 13:33:08.827167: Epoch time: 27.72 s 
2025-08-30 13:33:09.464063:  
2025-08-30 13:33:09.472431: Epoch 134 
2025-08-30 13:33:09.476606: Current learning rate: 0.00088 
2025-08-30 13:33:37.221936: train_loss -0.5035 
2025-08-30 13:33:37.229268: val_loss -0.5654 
2025-08-30 13:33:37.233418: Pseudo dice [np.float32(0.7695)] 
2025-08-30 13:33:37.241467: Epoch time: 27.76 s 
2025-08-30 13:33:37.891975:  
2025-08-30 13:33:37.900366: Epoch 135 
2025-08-30 13:33:37.904935: Current learning rate: 0.00088 
2025-08-30 13:34:05.595613: train_loss -0.5297 
2025-08-30 13:34:05.595613: val_loss -0.532 
2025-08-30 13:34:05.607168: Pseudo dice [np.float32(0.7592)] 
2025-08-30 13:34:05.612167: Epoch time: 27.71 s 
2025-08-30 13:34:05.619480: Yayy! New best EMA pseudo Dice: 0.7378000020980835 
2025-08-30 13:34:06.574754:  
2025-08-30 13:34:06.583446: Epoch 136 
2025-08-30 13:34:06.587580: Current learning rate: 0.00088 
2025-08-30 13:34:34.152258: train_loss -0.4938 
2025-08-30 13:34:34.160905: val_loss -0.4632 
2025-08-30 13:34:34.165077: Pseudo dice [np.float32(0.7192)] 
2025-08-30 13:34:34.172603: Epoch time: 27.58 s 
2025-08-30 13:34:34.819894:  
2025-08-30 13:34:34.828364: Epoch 137 
2025-08-30 13:34:34.832586: Current learning rate: 0.00088 
2025-08-30 13:35:03.001856: train_loss -0.4715 
2025-08-30 13:35:03.006368: val_loss -0.5006 
2025-08-30 13:35:03.014691: Pseudo dice [np.float32(0.7212)] 
2025-08-30 13:35:03.021092: Epoch time: 28.18 s 
2025-08-30 13:35:03.873553:  
2025-08-30 13:35:03.885245: Epoch 138 
2025-08-30 13:35:03.895081: Current learning rate: 0.00087 
2025-08-30 13:35:31.960277: train_loss -0.4616 
2025-08-30 13:35:31.968657: val_loss -0.4716 
2025-08-30 13:35:31.977059: Pseudo dice [np.float32(0.723)] 
2025-08-30 13:35:31.981804: Epoch time: 28.09 s 
2025-08-30 13:35:32.627770:  
2025-08-30 13:35:32.636026: Epoch 139 
2025-08-30 13:35:32.640164: Current learning rate: 0.00087 
2025-08-30 13:36:00.267742: train_loss -0.4691 
2025-08-30 13:36:00.276028: val_loss -0.5161 
2025-08-30 13:36:00.280275: Pseudo dice [np.float32(0.729)] 
2025-08-30 13:36:00.289483: Epoch time: 27.64 s 
2025-08-30 13:36:01.135226:  
2025-08-30 13:36:01.143580: Epoch 140 
2025-08-30 13:36:01.147737: Current learning rate: 0.00087 
2025-08-30 13:36:30.498035: train_loss -0.4785 
2025-08-30 13:36:30.506161: val_loss -0.4934 
2025-08-30 13:36:30.514109: Pseudo dice [np.float32(0.6925)] 
2025-08-30 13:36:30.520175: Epoch time: 29.36 s 
2025-08-30 13:36:31.227713:  
2025-08-30 13:36:31.236122: Epoch 141 
2025-08-30 13:36:31.240313: Current learning rate: 0.00087 
2025-08-30 13:37:00.231601: train_loss -0.4893 
2025-08-30 13:37:00.235809: val_loss -0.5474 
2025-08-30 13:37:00.243743: Pseudo dice [np.float32(0.7881)] 
2025-08-30 13:37:00.248025: Epoch time: 29.0 s 
2025-08-30 13:37:00.894828:  
2025-08-30 13:37:00.903201: Epoch 142 
2025-08-30 13:37:00.907356: Current learning rate: 0.00087 
2025-08-30 13:37:28.334725: train_loss -0.5116 
2025-08-30 13:37:28.343042: val_loss -0.5186 
2025-08-30 13:37:28.347248: Pseudo dice [np.float32(0.6773)] 
2025-08-30 13:37:28.353353: Epoch time: 27.44 s 
2025-08-30 13:37:29.010336:  
2025-08-30 13:37:29.018711: Epoch 143 
2025-08-30 13:37:29.022874: Current learning rate: 0.00087 
2025-08-30 13:37:56.879402: train_loss -0.5131 
2025-08-30 13:37:56.888049: val_loss -0.5374 
2025-08-30 13:37:56.892229: Pseudo dice [np.float32(0.7555)] 
2025-08-30 13:37:56.898854: Epoch time: 27.87 s 
2025-08-30 13:37:57.697266:  
2025-08-30 13:37:57.705656: Epoch 144 
2025-08-30 13:37:57.709752: Current learning rate: 0.00087 
2025-08-30 13:38:25.816879: train_loss -0.4909 
2025-08-30 13:38:25.825254: val_loss -0.4218 
2025-08-30 13:38:25.829398: Pseudo dice [np.float32(0.6414)] 
2025-08-30 13:38:25.837602: Epoch time: 28.12 s 
2025-08-30 13:38:26.484282:  
2025-08-30 13:38:26.492697: Epoch 145 
2025-08-30 13:38:26.496845: Current learning rate: 0.00087 
2025-08-30 13:38:54.315809: train_loss -0.4545 
2025-08-30 13:38:54.315809: val_loss -0.4645 
2025-08-30 13:38:54.320333: Pseudo dice [np.float32(0.6684)] 
2025-08-30 13:38:54.329311: Epoch time: 27.84 s 
2025-08-30 13:38:54.983612:  
2025-08-30 13:38:54.991513: Epoch 146 
2025-08-30 13:38:54.996106: Current learning rate: 0.00087 
2025-08-30 13:39:22.798772: train_loss -0.5042 
2025-08-30 13:39:22.807177: val_loss -0.5217 
2025-08-30 13:39:22.811396: Pseudo dice [np.float32(0.7935)] 
2025-08-30 13:39:22.818367: Epoch time: 27.82 s 
2025-08-30 13:39:23.461611:  
2025-08-30 13:39:23.470236: Epoch 147 
2025-08-30 13:39:23.474365: Current learning rate: 0.00087 
2025-08-30 13:39:51.368993: train_loss -0.4962 
2025-08-30 13:39:51.377301: val_loss -0.5024 
2025-08-30 13:39:51.385662: Pseudo dice [np.float32(0.6928)] 
2025-08-30 13:39:51.391848: Epoch time: 27.91 s 
2025-08-30 13:39:52.044209:  
2025-08-30 13:39:52.052915: Epoch 148 
2025-08-30 13:39:52.061258: Current learning rate: 0.00087 
2025-08-30 13:40:19.813563: train_loss -0.5101 
2025-08-30 13:40:19.822260: val_loss -0.5568 
2025-08-30 13:40:19.826432: Pseudo dice [np.float32(0.7979)] 
2025-08-30 13:40:19.834625: Epoch time: 27.77 s 
2025-08-30 13:40:20.485572:  
2025-08-30 13:40:20.493900: Epoch 149 
2025-08-30 13:40:20.498032: Current learning rate: 0.00086 
2025-08-30 13:40:48.329802: train_loss -0.4873 
2025-08-30 13:40:48.338165: val_loss -0.557 
2025-08-30 13:40:48.342410: Pseudo dice [np.float32(0.7932)] 
2025-08-30 13:40:48.349676: Epoch time: 27.84 s 
2025-08-30 13:40:49.430999:  
2025-08-30 13:40:49.439363: Epoch 150 
2025-08-30 13:40:49.443489: Current learning rate: 0.00086 
2025-08-30 13:41:17.225280: train_loss -0.4938 
2025-08-30 13:41:17.233664: val_loss -0.5577 
2025-08-30 13:41:17.241968: Pseudo dice [np.float32(0.719)] 
2025-08-30 13:41:17.247521: Epoch time: 27.79 s 
2025-08-30 13:41:17.896991:  
2025-08-30 13:41:17.905232: Epoch 151 
2025-08-30 13:41:17.909473: Current learning rate: 0.00086 
2025-08-30 13:41:45.195157: train_loss -0.5199 
2025-08-30 13:41:45.207498: val_loss -0.5221 
2025-08-30 13:41:45.211649: Pseudo dice [np.float32(0.7564)] 
2025-08-30 13:41:45.217027: Epoch time: 27.3 s 
2025-08-30 13:41:45.866441:  
2025-08-30 13:41:45.874843: Epoch 152 
2025-08-30 13:41:45.878958: Current learning rate: 0.00086 
2025-08-30 13:42:13.881471: train_loss -0.5111 
2025-08-30 13:42:13.890145: val_loss -0.5558 
2025-08-30 13:42:13.893969: Pseudo dice [np.float32(0.7818)] 
2025-08-30 13:42:13.900920: Epoch time: 28.02 s 
2025-08-30 13:42:13.906474: Yayy! New best EMA pseudo Dice: 0.7408000230789185 
2025-08-30 13:42:14.766021:  
2025-08-30 13:42:14.774397: Epoch 153 
2025-08-30 13:42:14.778521: Current learning rate: 0.00086 
2025-08-30 13:42:42.936875: train_loss -0.4916 
2025-08-30 13:42:42.948438: val_loss -0.4748 
2025-08-30 13:42:42.954224: Pseudo dice [np.float32(0.6946)] 
2025-08-30 13:42:42.959456: Epoch time: 28.17 s 
2025-08-30 13:42:43.631981:  
2025-08-30 13:42:43.636459: Epoch 154 
2025-08-30 13:42:43.644801: Current learning rate: 0.00086 
2025-08-30 13:43:11.760459: train_loss -0.5136 
2025-08-30 13:43:11.768788: val_loss -0.5185 
2025-08-30 13:43:11.772966: Pseudo dice [np.float32(0.7998)] 
2025-08-30 13:43:11.779104: Epoch time: 28.13 s 
2025-08-30 13:43:11.785017: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2025-08-30 13:43:12.753083:  
2025-08-30 13:43:12.761463: Epoch 155 
2025-08-30 13:43:12.765622: Current learning rate: 0.00086 
2025-08-30 13:43:40.111208: train_loss -0.5265 
2025-08-30 13:43:40.112207: val_loss -0.521 
2025-08-30 13:43:40.122719: Pseudo dice [np.float32(0.7683)] 
2025-08-30 13:43:40.126650: Epoch time: 27.36 s 
2025-08-30 13:43:40.133803: Yayy! New best EMA pseudo Dice: 0.7451000213623047 
2025-08-30 13:43:40.997860:  
2025-08-30 13:43:41.006301: Epoch 156 
2025-08-30 13:43:41.010438: Current learning rate: 0.00086 
2025-08-30 13:44:08.942151: train_loss -0.522 
2025-08-30 13:44:08.950394: val_loss -0.5122 
2025-08-30 13:44:08.954858: Pseudo dice [np.float32(0.7514)] 
2025-08-30 13:44:08.961393: Epoch time: 27.94 s 
2025-08-30 13:44:08.967535: Yayy! New best EMA pseudo Dice: 0.7458000183105469 
2025-08-30 13:44:09.830802:  
2025-08-30 13:44:09.839104: Epoch 157 
2025-08-30 13:44:09.843361: Current learning rate: 0.00086 
2025-08-30 13:44:37.420853: train_loss -0.4944 
2025-08-30 13:44:37.429118: val_loss -0.5637 
2025-08-30 13:44:37.437604: Pseudo dice [np.float32(0.7909)] 
2025-08-30 13:44:37.442853: Epoch time: 27.59 s 
2025-08-30 13:44:37.450005: Yayy! New best EMA pseudo Dice: 0.7502999901771545 
2025-08-30 13:44:38.309184:  
2025-08-30 13:44:38.317535: Epoch 158 
2025-08-30 13:44:38.321755: Current learning rate: 0.00086 
2025-08-30 13:45:05.853479: train_loss -0.4709 
2025-08-30 13:45:05.861757: val_loss -0.5019 
2025-08-30 13:45:05.870075: Pseudo dice [np.float32(0.6835)] 
2025-08-30 13:45:05.874894: Epoch time: 27.54 s 
2025-08-30 13:45:06.578654:  
2025-08-30 13:45:06.587336: Epoch 159 
2025-08-30 13:45:06.595699: Current learning rate: 0.00086 
2025-08-30 13:45:34.394243: train_loss -0.5245 
2025-08-30 13:45:34.402609: val_loss -0.5356 
2025-08-30 13:45:34.406866: Pseudo dice [np.float32(0.7738)] 
2025-08-30 13:45:34.415055: Epoch time: 27.82 s 
2025-08-30 13:45:35.090792:  
2025-08-30 13:45:35.099216: Epoch 160 
2025-08-30 13:45:35.103285: Current learning rate: 0.00085 
2025-08-30 13:46:03.210604: train_loss -0.5025 
2025-08-30 13:46:03.218894: val_loss -0.461 
2025-08-30 13:46:03.223011: Pseudo dice [np.float32(0.6723)] 
2025-08-30 13:46:03.231052: Epoch time: 28.12 s 
2025-08-30 13:46:04.031805:  
2025-08-30 13:46:04.036296: Epoch 161 
2025-08-30 13:46:04.044321: Current learning rate: 0.00085 
2025-08-30 13:46:31.571723: train_loss -0.5109 
2025-08-30 13:46:31.580403: val_loss -0.503 
2025-08-30 13:46:31.584561: Pseudo dice [np.float32(0.7428)] 
2025-08-30 13:46:31.589483: Epoch time: 27.54 s 
2025-08-30 13:46:32.251919:  
2025-08-30 13:46:32.256261: Epoch 162 
2025-08-30 13:46:32.264527: Current learning rate: 0.00085 
2025-08-30 13:46:59.679292: train_loss -0.5075 
2025-08-30 13:46:59.687709: val_loss -0.5391 
2025-08-30 13:46:59.695628: Pseudo dice [np.float32(0.7138)] 
2025-08-30 13:46:59.699895: Epoch time: 27.43 s 
2025-08-30 13:47:00.354588:  
2025-08-30 13:47:00.359213: Epoch 163 
2025-08-30 13:47:00.367445: Current learning rate: 0.00085 
2025-08-30 13:47:28.191033: train_loss -0.5047 
2025-08-30 13:47:28.199357: val_loss -0.5496 
2025-08-30 13:47:28.207701: Pseudo dice [np.float32(0.7848)] 
2025-08-30 13:47:28.212628: Epoch time: 27.84 s 
2025-08-30 13:47:28.870914:  
2025-08-30 13:47:28.875169: Epoch 164 
2025-08-30 13:47:28.883068: Current learning rate: 0.00085 
2025-08-30 13:47:56.106426: train_loss -0.5076 
2025-08-30 13:47:56.106426: val_loss -0.5293 
2025-08-30 13:47:56.114803: Pseudo dice [np.float32(0.7684)] 
2025-08-30 13:47:56.122892: Epoch time: 27.24 s 
2025-08-30 13:47:56.769202:  
2025-08-30 13:47:56.777520: Epoch 165 
2025-08-30 13:47:56.781679: Current learning rate: 0.00085 
2025-08-30 13:48:24.576084: train_loss -0.5165 
2025-08-30 13:48:24.588905: val_loss -0.5029 
2025-08-30 13:48:24.593073: Pseudo dice [np.float32(0.7443)] 
2025-08-30 13:48:24.599628: Epoch time: 27.81 s 
2025-08-30 13:48:25.256316:  
2025-08-30 13:48:25.264687: Epoch 166 
2025-08-30 13:48:25.268856: Current learning rate: 0.00085 
2025-08-30 13:48:53.138206: train_loss -0.5009 
2025-08-30 13:48:53.146557: val_loss -0.4929 
2025-08-30 13:48:53.150376: Pseudo dice [np.float32(0.7419)] 
2025-08-30 13:48:53.158813: Epoch time: 27.88 s 
2025-08-30 13:48:53.959929:  
2025-08-30 13:48:53.968329: Epoch 167 
2025-08-30 13:48:53.972462: Current learning rate: 0.00085 
2025-08-30 13:49:21.370610: train_loss -0.5084 
2025-08-30 13:49:21.379005: val_loss -0.4791 
2025-08-30 13:49:21.383055: Pseudo dice [np.float32(0.7485)] 
2025-08-30 13:49:21.392172: Epoch time: 27.41 s 
2025-08-30 13:49:22.033393:  
2025-08-30 13:49:22.042066: Epoch 168 
2025-08-30 13:49:22.050061: Current learning rate: 0.00085 
2025-08-30 13:49:49.402760: train_loss -0.4662 
2025-08-30 13:49:49.411075: val_loss -0.4363 
2025-08-30 13:49:49.419468: Pseudo dice [np.float32(0.6932)] 
2025-08-30 13:49:49.424850: Epoch time: 27.37 s 
2025-08-30 13:49:50.082516:  
2025-08-30 13:49:50.090555: Epoch 169 
2025-08-30 13:49:50.095114: Current learning rate: 0.00085 
2025-08-30 13:50:17.743696: train_loss -0.4823 
2025-08-30 13:50:17.751910: val_loss -0.4422 
2025-08-30 13:50:17.756010: Pseudo dice [np.float32(0.6197)] 
2025-08-30 13:50:17.763182: Epoch time: 27.67 s 
2025-08-30 13:50:18.414581:  
2025-08-30 13:50:18.422920: Epoch 170 
2025-08-30 13:50:18.427104: Current learning rate: 0.00085 
2025-08-30 13:50:46.176410: train_loss -0.5015 
2025-08-30 13:50:46.184260: val_loss -0.5078 
2025-08-30 13:50:46.188113: Pseudo dice [np.float32(0.7424)] 
2025-08-30 13:50:46.196528: Epoch time: 27.76 s 
2025-08-30 13:50:46.847517:  
2025-08-30 13:50:46.855899: Epoch 171 
2025-08-30 13:50:46.860011: Current learning rate: 0.00084 
2025-08-30 13:51:14.404168: train_loss -0.52 
2025-08-30 13:51:14.412525: val_loss -0.5011 
2025-08-30 13:51:14.416608: Pseudo dice [np.float32(0.6662)] 
2025-08-30 13:51:14.423941: Epoch time: 27.56 s 
2025-08-30 13:51:15.079405:  
2025-08-30 13:51:15.083913: Epoch 172 
2025-08-30 13:51:15.091933: Current learning rate: 0.00084 
2025-08-30 13:51:43.111935: train_loss -0.4827 
2025-08-30 13:51:43.120293: val_loss -0.572 
2025-08-30 13:51:43.128663: Pseudo dice [np.float32(0.7648)] 
2025-08-30 13:51:43.133922: Epoch time: 28.04 s 
2025-08-30 13:51:43.950294:  
2025-08-30 13:51:43.958679: Epoch 173 
2025-08-30 13:51:43.962791: Current learning rate: 0.00084 
2025-08-30 13:52:11.803061: train_loss -0.5386 
2025-08-30 13:52:11.811408: val_loss -0.4708 
2025-08-30 13:52:11.819330: Pseudo dice [np.float32(0.7081)] 
2025-08-30 13:52:11.824642: Epoch time: 27.85 s 
2025-08-30 13:52:12.482478:  
2025-08-30 13:52:12.486976: Epoch 174 
2025-08-30 13:52:12.495318: Current learning rate: 0.00084 
2025-08-30 13:52:40.009938: train_loss -0.4891 
2025-08-30 13:52:40.009938: val_loss -0.5437 
2025-08-30 13:52:40.019861: Pseudo dice [np.float32(0.6753)] 
2025-08-30 13:52:40.024218: Epoch time: 27.53 s 
2025-08-30 13:52:40.677676:  
2025-08-30 13:52:40.686021: Epoch 175 
2025-08-30 13:52:40.690208: Current learning rate: 0.00084 
2025-08-30 13:53:08.276015: train_loss -0.461 
2025-08-30 13:53:08.284409: val_loss -0.4973 
2025-08-30 13:53:08.288550: Pseudo dice [np.float32(0.7366)] 
2025-08-30 13:53:08.301170: Epoch time: 27.6 s 
2025-08-30 13:53:08.997480:  
2025-08-30 13:53:09.005864: Epoch 176 
2025-08-30 13:53:09.009688: Current learning rate: 0.00084 
2025-08-30 13:53:36.850425: train_loss -0.5141 
2025-08-30 13:53:36.862908: val_loss -0.5888 
2025-08-30 13:53:36.866970: Pseudo dice [np.float32(0.7773)] 
2025-08-30 13:53:36.874410: Epoch time: 27.85 s 
2025-08-30 13:53:37.530129:  
2025-08-30 13:53:37.538474: Epoch 177 
2025-08-30 13:53:37.542634: Current learning rate: 0.00084 
2025-08-30 13:54:05.376230: train_loss -0.5125 
2025-08-30 13:54:05.382902: val_loss -0.4188 
2025-08-30 13:54:05.387049: Pseudo dice [np.float32(0.6802)] 
2025-08-30 13:54:05.396019: Epoch time: 27.85 s 
2025-08-30 13:54:06.050301:  
2025-08-30 13:54:06.058714: Epoch 178 
2025-08-30 13:54:06.063515: Current learning rate: 0.00084 
2025-08-30 13:54:33.915220: train_loss -0.5147 
2025-08-30 13:54:33.928000: val_loss -0.4783 
2025-08-30 13:54:33.932169: Pseudo dice [np.float32(0.7102)] 
2025-08-30 13:54:33.939328: Epoch time: 27.87 s 
2025-08-30 13:54:34.591286:  
2025-08-30 13:54:34.599602: Epoch 179 
2025-08-30 13:54:34.607948: Current learning rate: 0.00084 
2025-08-30 13:55:02.477378: train_loss -0.486 
2025-08-30 13:55:02.485682: val_loss -0.5239 
2025-08-30 13:55:02.494153: Pseudo dice [np.float32(0.7646)] 
2025-08-30 13:55:02.498930: Epoch time: 27.89 s 
2025-08-30 13:55:03.153085:  
2025-08-30 13:55:03.161451: Epoch 180 
2025-08-30 13:55:03.165602: Current learning rate: 0.00084 
2025-08-30 13:55:30.200842: train_loss -0.4985 
2025-08-30 13:55:30.213374: val_loss -0.5891 
2025-08-30 13:55:30.217594: Pseudo dice [np.float32(0.7582)] 
2025-08-30 13:55:30.224618: Epoch time: 27.05 s 
2025-08-30 13:55:30.880723:  
2025-08-30 13:55:30.888699: Epoch 181 
2025-08-30 13:55:30.893229: Current learning rate: 0.00084 
2025-08-30 13:55:58.385818: train_loss -0.5061 
2025-08-30 13:55:58.391498: val_loss -0.5192 
2025-08-30 13:55:58.399899: Pseudo dice [np.float32(0.7389)] 
2025-08-30 13:55:58.404708: Epoch time: 27.51 s 
2025-08-30 13:55:59.054658:  
2025-08-30 13:55:59.063044: Epoch 182 
2025-08-30 13:55:59.067142: Current learning rate: 0.00083 
2025-08-30 13:56:26.957387: train_loss -0.4795 
2025-08-30 13:56:26.965740: val_loss -0.5186 
2025-08-30 13:56:26.974074: Pseudo dice [np.float32(0.7307)] 
2025-08-30 13:56:26.979511: Epoch time: 27.9 s 
2025-08-30 13:56:27.658141:  
2025-08-30 13:56:27.666528: Epoch 183 
2025-08-30 13:56:27.670740: Current learning rate: 0.00083 
2025-08-30 13:56:55.431679: train_loss -0.4946 
2025-08-30 13:56:55.440046: val_loss -0.4775 
2025-08-30 13:56:55.444180: Pseudo dice [np.float32(0.6571)] 
2025-08-30 13:56:55.452212: Epoch time: 27.77 s 
2025-08-30 13:56:56.099001:  
2025-08-30 13:56:56.103223: Epoch 184 
2025-08-30 13:56:56.111634: Current learning rate: 0.00083 
2025-08-30 13:57:23.860358: train_loss -0.5043 
2025-08-30 13:57:23.860358: val_loss -0.5134 
2025-08-30 13:57:23.870706: Pseudo dice [np.float32(0.7667)] 
2025-08-30 13:57:23.876241: Epoch time: 27.77 s 
2025-08-30 13:57:24.664893:  
2025-08-30 13:57:24.672948: Epoch 185 
2025-08-30 13:57:24.677454: Current learning rate: 0.00083 
2025-08-30 13:57:52.283784: train_loss -0.4647 
2025-08-30 13:57:52.288304: val_loss -0.5806 
2025-08-30 13:57:52.296864: Pseudo dice [np.float32(0.7908)] 
2025-08-30 13:57:52.300581: Epoch time: 27.62 s 
2025-08-30 13:57:52.955686:  
2025-08-30 13:57:52.964130: Epoch 186 
2025-08-30 13:57:52.968268: Current learning rate: 0.00083 
2025-08-30 13:58:20.513027: train_loss -0.5324 
2025-08-30 13:58:20.520698: val_loss -0.5142 
2025-08-30 13:58:20.524854: Pseudo dice [np.float32(0.7251)] 
2025-08-30 13:58:20.531234: Epoch time: 27.56 s 
2025-08-30 13:58:21.187997:  
2025-08-30 13:58:21.196370: Epoch 187 
2025-08-30 13:58:21.200623: Current learning rate: 0.00083 
2025-08-30 13:58:48.639999: train_loss -0.5297 
2025-08-30 13:58:48.648347: val_loss -0.505 
2025-08-30 13:58:48.652478: Pseudo dice [np.float32(0.7385)] 
2025-08-30 13:58:48.660928: Epoch time: 27.45 s 
2025-08-30 13:58:49.303576:  
2025-08-30 13:58:49.311910: Epoch 188 
2025-08-30 13:58:49.316064: Current learning rate: 0.00083 
2025-08-30 13:59:17.139261: train_loss -0.4965 
2025-08-30 13:59:17.147939: val_loss -0.5654 
2025-08-30 13:59:17.152098: Pseudo dice [np.float32(0.7751)] 
2025-08-30 13:59:17.159309: Epoch time: 27.84 s 
2025-08-30 13:59:17.819484:  
2025-08-30 13:59:17.827852: Epoch 189 
2025-08-30 13:59:17.835767: Current learning rate: 0.00083 
2025-08-30 13:59:45.288510: train_loss -0.5019 
2025-08-30 13:59:45.296935: val_loss -0.5044 
2025-08-30 13:59:45.301057: Pseudo dice [np.float32(0.7539)] 
2025-08-30 13:59:45.309019: Epoch time: 27.47 s 
2025-08-30 13:59:45.976329:  
2025-08-30 13:59:45.985003: Epoch 190 
2025-08-30 13:59:45.989208: Current learning rate: 0.00083 
2025-08-30 14:00:13.366554: train_loss -0.5412 
2025-08-30 14:00:13.374933: val_loss -0.5656 
2025-08-30 14:00:13.379074: Pseudo dice [np.float32(0.7471)] 
2025-08-30 14:00:13.387075: Epoch time: 27.39 s 
2025-08-30 14:00:14.058485:  
2025-08-30 14:00:14.063090: Epoch 191 
2025-08-30 14:00:14.071471: Current learning rate: 0.00083 
2025-08-30 14:00:41.586365: train_loss -0.5327 
2025-08-30 14:00:41.598897: val_loss -0.5825 
2025-08-30 14:00:41.603083: Pseudo dice [np.float32(0.7995)] 
2025-08-30 14:00:41.610485: Epoch time: 27.53 s 
2025-08-30 14:00:42.432890:  
2025-08-30 14:00:42.440944: Epoch 192 
2025-08-30 14:00:42.445468: Current learning rate: 0.00083 
2025-08-30 14:01:10.335859: train_loss -0.5259 
2025-08-30 14:01:10.344267: val_loss -0.4979 
2025-08-30 14:01:10.348415: Pseudo dice [np.float32(0.7445)] 
2025-08-30 14:01:10.357465: Epoch time: 27.9 s 
2025-08-30 14:01:11.019868:  
2025-08-30 14:01:11.028241: Epoch 193 
2025-08-30 14:01:11.036581: Current learning rate: 0.00082 
2025-08-30 14:01:37.533691: train_loss -0.5179 
2025-08-30 14:01:37.542096: val_loss -0.5568 
2025-08-30 14:01:37.550101: Pseudo dice [np.float32(0.7539)] 
2025-08-30 14:01:37.555990: Epoch time: 26.51 s 
2025-08-30 14:01:38.213638:  
2025-08-30 14:01:38.222013: Epoch 194 
2025-08-30 14:01:38.226159: Current learning rate: 0.00082 
2025-08-30 14:02:05.373615: train_loss -0.4618 
2025-08-30 14:02:05.373615: val_loss -0.4909 
2025-08-30 14:02:05.382380: Pseudo dice [np.float32(0.6919)] 
2025-08-30 14:02:05.388007: Epoch time: 27.16 s 
2025-08-30 14:02:06.062207:  
2025-08-30 14:02:06.066443: Epoch 195 
2025-08-30 14:02:06.074791: Current learning rate: 0.00082 
2025-08-30 14:02:33.827422: train_loss -0.5253 
2025-08-30 14:02:33.839956: val_loss -0.4678 
2025-08-30 14:02:33.844110: Pseudo dice [np.float32(0.7013)] 
2025-08-30 14:02:33.851207: Epoch time: 27.77 s 
2025-08-30 14:02:34.515731:  
2025-08-30 14:02:34.523992: Epoch 196 
2025-08-30 14:02:34.528155: Current learning rate: 0.00082 
2025-08-30 14:03:01.913763: train_loss -0.5006 
2025-08-30 14:03:01.922143: val_loss -0.5875 
2025-08-30 14:03:01.926282: Pseudo dice [np.float32(0.7804)] 
2025-08-30 14:03:01.933649: Epoch time: 27.4 s 
2025-08-30 14:03:02.743661:  
2025-08-30 14:03:02.752034: Epoch 197 
2025-08-30 14:03:02.755854: Current learning rate: 0.00082 
2025-08-30 14:03:29.949953: train_loss -0.5 
2025-08-30 14:03:29.958417: val_loss -0.4764 
2025-08-30 14:03:29.966828: Pseudo dice [np.float32(0.7187)] 
2025-08-30 14:03:29.971615: Epoch time: 27.21 s 
2025-08-30 14:03:30.644258:  
2025-08-30 14:03:30.650676: Epoch 198 
2025-08-30 14:03:30.659025: Current learning rate: 0.00082 
2025-08-30 14:03:58.161566: train_loss -0.5288 
2025-08-30 14:03:58.169743: val_loss -0.5254 
2025-08-30 14:03:58.173906: Pseudo dice [np.float32(0.7335)] 
2025-08-30 14:03:58.178948: Epoch time: 27.52 s 
2025-08-30 14:03:58.849889:  
2025-08-30 14:03:58.853919: Epoch 199 
2025-08-30 14:03:58.862273: Current learning rate: 0.00082 
2025-08-30 14:04:25.550963: train_loss -0.5283 
2025-08-30 14:04:25.563405: val_loss -0.5272 
2025-08-30 14:04:25.567923: Pseudo dice [np.float32(0.7526)] 
2025-08-30 14:04:25.574236: Epoch time: 26.71 s 
2025-08-30 14:04:26.480999:  
2025-08-30 14:04:26.489751: Epoch 200 
2025-08-30 14:04:26.493933: Current learning rate: 0.00082 
2025-08-30 14:04:53.316070: train_loss -0.538 
2025-08-30 14:04:53.324795: val_loss -0.5251 
2025-08-30 14:04:53.332777: Pseudo dice [np.float32(0.7558)] 
2025-08-30 14:04:53.338127: Epoch time: 26.84 s 
2025-08-30 14:04:54.000525:  
2025-08-30 14:04:54.008902: Epoch 201 
2025-08-30 14:04:54.017196: Current learning rate: 0.00082 
2025-08-30 14:05:21.477957: train_loss -0.5716 
2025-08-30 14:05:21.486436: val_loss -0.5432 
2025-08-30 14:05:21.490452: Pseudo dice [np.float32(0.7489)] 
2025-08-30 14:05:21.496538: Epoch time: 27.48 s 
2025-08-30 14:05:22.165685:  
2025-08-30 14:05:22.174024: Epoch 202 
2025-08-30 14:05:22.178201: Current learning rate: 0.00082 
2025-08-30 14:05:50.018843: train_loss -0.5279 
2025-08-30 14:05:50.027251: val_loss -0.5651 
2025-08-30 14:05:50.031417: Pseudo dice [np.float32(0.7482)] 
2025-08-30 14:05:50.039488: Epoch time: 27.86 s 
2025-08-30 14:05:50.852819:  
2025-08-30 14:05:50.861343: Epoch 203 
2025-08-30 14:05:50.867260: Current learning rate: 0.00082 
2025-08-30 14:06:18.018090: train_loss -0.4821 
2025-08-30 14:06:18.026066: val_loss -0.5654 
2025-08-30 14:06:18.030144: Pseudo dice [np.float32(0.8116)] 
2025-08-30 14:06:18.036344: Epoch time: 27.17 s 
2025-08-30 14:06:18.692883:  
2025-08-30 14:06:18.701734: Epoch 204 
2025-08-30 14:06:18.705782: Current learning rate: 0.00081 
2025-08-30 14:06:45.982729: train_loss -0.4992 
2025-08-30 14:06:45.982729: val_loss -0.5545 
2025-08-30 14:06:45.992520: Pseudo dice [np.float32(0.7555)] 
2025-08-30 14:06:45.996723: Epoch time: 27.29 s 
2025-08-30 14:06:46.003211: Yayy! New best EMA pseudo Dice: 0.7502999901771545 
2025-08-30 14:06:46.871354:  
2025-08-30 14:06:46.879730: Epoch 205 
2025-08-30 14:06:46.887686: Current learning rate: 0.00081 
2025-08-30 14:07:14.165253: train_loss -0.5549 
2025-08-30 14:07:14.173638: val_loss -0.5535 
2025-08-30 14:07:14.177829: Pseudo dice [np.float32(0.72)] 
2025-08-30 14:07:14.185905: Epoch time: 27.29 s 
2025-08-30 14:07:14.819681:  
2025-08-30 14:07:14.824162: Epoch 206 
2025-08-30 14:07:14.832656: Current learning rate: 0.00081 
2025-08-30 14:07:41.262691: train_loss -0.5582 
2025-08-30 14:07:41.275561: val_loss -0.6214 
2025-08-30 14:07:41.279740: Pseudo dice [np.float32(0.7588)] 
2025-08-30 14:07:41.286992: Epoch time: 26.45 s 
2025-08-30 14:07:41.917931:  
2025-08-30 14:07:41.926298: Epoch 207 
2025-08-30 14:07:41.930408: Current learning rate: 0.00081 
2025-08-30 14:08:08.998674: train_loss -0.5224 
2025-08-30 14:08:09.007393: val_loss -0.4403 
2025-08-30 14:08:09.011557: Pseudo dice [np.float32(0.6743)] 
2025-08-30 14:08:09.018828: Epoch time: 27.08 s 
2025-08-30 14:08:09.770635:  
2025-08-30 14:08:09.779102: Epoch 208 
2025-08-30 14:08:09.783293: Current learning rate: 0.00081 
2025-08-30 14:08:37.727684: train_loss -0.5093 
2025-08-30 14:08:37.740252: val_loss -0.5282 
2025-08-30 14:08:37.744325: Pseudo dice [np.float32(0.7937)] 
2025-08-30 14:08:37.750587: Epoch time: 27.96 s 
2025-08-30 14:08:38.395043:  
2025-08-30 14:08:38.403029: Epoch 209 
2025-08-30 14:08:38.407671: Current learning rate: 0.00081 
2025-08-30 14:09:05.730669: train_loss -0.5233 
2025-08-30 14:09:05.739047: val_loss -0.5326 
2025-08-30 14:09:05.747388: Pseudo dice [np.float32(0.7389)] 
2025-08-30 14:09:05.752262: Epoch time: 27.34 s 
2025-08-30 14:09:06.552247:  
2025-08-30 14:09:06.560304: Epoch 210 
2025-08-30 14:09:06.564738: Current learning rate: 0.00081 
2025-08-30 14:09:33.525033: train_loss -0.5307 
2025-08-30 14:09:33.537191: val_loss -0.61 
2025-08-30 14:09:33.541780: Pseudo dice [np.float32(0.7767)] 
2025-08-30 14:09:33.547832: Epoch time: 26.97 s 
2025-08-30 14:09:34.187799:  
2025-08-30 14:09:34.196510: Epoch 211 
2025-08-30 14:09:34.200649: Current learning rate: 0.00081 
2025-08-30 14:10:01.652676: train_loss -0.5631 
2025-08-30 14:10:01.656850: val_loss -0.5406 
2025-08-30 14:10:01.665547: Pseudo dice [np.float32(0.7293)] 
2025-08-30 14:10:01.671440: Epoch time: 27.46 s 
2025-08-30 14:10:02.316267:  
2025-08-30 14:10:02.324652: Epoch 212 
2025-08-30 14:10:02.328696: Current learning rate: 0.00081 
2025-08-30 14:10:29.264031: train_loss -0.5181 
2025-08-30 14:10:29.272246: val_loss -0.5479 
2025-08-30 14:10:29.280281: Pseudo dice [np.float32(0.7426)] 
2025-08-30 14:10:29.285505: Epoch time: 26.95 s 
2025-08-30 14:10:29.914587:  
2025-08-30 14:10:29.923019: Epoch 213 
2025-08-30 14:10:29.927153: Current learning rate: 0.00081 
2025-08-30 14:10:56.774811: train_loss -0.5313 
2025-08-30 14:10:56.782663: val_loss -0.4881 
2025-08-30 14:10:56.787168: Pseudo dice [np.float32(0.6493)] 
2025-08-30 14:10:56.793333: Epoch time: 26.86 s 
2025-08-30 14:10:57.425378:  
2025-08-30 14:10:57.433312: Epoch 214 
2025-08-30 14:10:57.437918: Current learning rate: 0.00081 
2025-08-30 14:11:25.107145: train_loss -0.5055 
2025-08-30 14:11:25.107145: val_loss -0.4733 
2025-08-30 14:11:25.119338: Pseudo dice [np.float32(0.7217)] 
2025-08-30 14:11:25.125164: Epoch time: 27.69 s 
2025-08-30 14:11:25.765771:  
2025-08-30 14:11:25.774050: Epoch 215 
2025-08-30 14:11:25.782420: Current learning rate: 0.0008 
2025-08-30 14:11:54.992772: train_loss -0.5616 
2025-08-30 14:11:54.999501: val_loss -0.599 
2025-08-30 14:11:55.003662: Pseudo dice [np.float32(0.7856)] 
2025-08-30 14:11:55.011640: Epoch time: 29.23 s 
2025-08-30 14:11:55.791517:  
2025-08-30 14:11:55.800160: Epoch 216 
2025-08-30 14:11:55.804345: Current learning rate: 0.0008 
2025-08-30 14:12:24.237507: train_loss -0.5519 
2025-08-30 14:12:24.245280: val_loss -0.4904 
2025-08-30 14:12:24.249362: Pseudo dice [np.float32(0.6988)] 
2025-08-30 14:12:24.257472: Epoch time: 28.45 s 
2025-08-30 14:12:24.895916:  
2025-08-30 14:12:24.904295: Epoch 217 
2025-08-30 14:12:24.908481: Current learning rate: 0.0008 
2025-08-30 14:12:53.807651: train_loss -0.5085 
2025-08-30 14:12:53.812295: val_loss -0.5545 
2025-08-30 14:12:53.820607: Pseudo dice [np.float32(0.6907)] 
2025-08-30 14:12:53.825873: Epoch time: 28.91 s 
2025-08-30 14:12:54.466654:  
2025-08-30 14:12:54.475338: Epoch 218 
2025-08-30 14:12:54.479170: Current learning rate: 0.0008 
2025-08-30 14:13:23.083047: train_loss -0.5191 
2025-08-30 14:13:23.091057: val_loss -0.5388 
2025-08-30 14:13:23.095665: Pseudo dice [np.float32(0.7726)] 
2025-08-30 14:13:23.101663: Epoch time: 28.62 s 
2025-08-30 14:13:23.742129:  
2025-08-30 14:13:23.750449: Epoch 219 
2025-08-30 14:13:23.754569: Current learning rate: 0.0008 
2025-08-30 14:13:52.203737: train_loss -0.5594 
2025-08-30 14:13:52.212059: val_loss -0.5102 
2025-08-30 14:13:52.216213: Pseudo dice [np.float32(0.6968)] 
2025-08-30 14:13:52.223423: Epoch time: 28.46 s 
2025-08-30 14:13:52.875309:  
2025-08-30 14:13:52.879476: Epoch 220 
2025-08-30 14:13:52.887820: Current learning rate: 0.0008 
2025-08-30 14:14:21.924723: train_loss -0.532 
2025-08-30 14:14:21.933353: val_loss -0.5497 
2025-08-30 14:14:21.942042: Pseudo dice [np.float32(0.7309)] 
2025-08-30 14:14:21.947169: Epoch time: 29.05 s 
2025-08-30 14:14:22.613334:  
2025-08-30 14:14:22.621640: Epoch 221 
2025-08-30 14:14:22.625766: Current learning rate: 0.0008 
2025-08-30 14:14:51.392128: train_loss -0.5323 
2025-08-30 14:14:51.404510: val_loss -0.5267 
2025-08-30 14:14:51.408689: Pseudo dice [np.float32(0.7171)] 
2025-08-30 14:14:51.415855: Epoch time: 28.78 s 
2025-08-30 14:14:52.059237:  
2025-08-30 14:14:52.067283: Epoch 222 
2025-08-30 14:14:52.071427: Current learning rate: 0.0008 
2025-08-30 14:15:20.704332: train_loss -0.5164 
2025-08-30 14:15:20.712812: val_loss -0.5397 
2025-08-30 14:15:20.716962: Pseudo dice [np.float32(0.7744)] 
2025-08-30 14:15:20.724170: Epoch time: 28.65 s 
2025-08-30 14:15:21.517796:  
2025-08-30 14:15:21.526220: Epoch 223 
2025-08-30 14:15:21.530406: Current learning rate: 0.0008 
2025-08-30 14:15:50.109520: train_loss -0.5348 
2025-08-30 14:15:50.109520: val_loss -0.493 
2025-08-30 14:15:50.117260: Pseudo dice [np.float32(0.701)] 
2025-08-30 14:15:50.122927: Epoch time: 28.59 s 
2025-08-30 14:15:50.750758:  
2025-08-30 14:15:50.759122: Epoch 224 
2025-08-30 14:15:50.763272: Current learning rate: 0.0008 
2025-08-30 14:16:20.389103: train_loss -0.5732 
2025-08-30 14:16:20.397411: val_loss -0.5575 
2025-08-30 14:16:20.401592: Pseudo dice [np.float32(0.7513)] 
2025-08-30 14:16:20.407784: Epoch time: 29.64 s 
2025-08-30 14:16:21.043489:  
2025-08-30 14:16:21.047972: Epoch 225 
2025-08-30 14:16:21.056327: Current learning rate: 0.0008 
2025-08-30 14:16:49.084706: train_loss -0.4978 
2025-08-30 14:16:49.096443: val_loss -0.5615 
2025-08-30 14:16:49.101034: Pseudo dice [np.float32(0.8168)] 
2025-08-30 14:16:49.107176: Epoch time: 28.05 s 
2025-08-30 14:16:49.739057:  
2025-08-30 14:16:49.747408: Epoch 226 
2025-08-30 14:16:49.751620: Current learning rate: 0.00079 
2025-08-30 14:17:18.880670: train_loss -0.5293 
2025-08-30 14:17:18.889070: val_loss -0.5369 
2025-08-30 14:17:18.893239: Pseudo dice [np.float32(0.7698)] 
2025-08-30 14:17:18.900440: Epoch time: 29.14 s 
2025-08-30 14:17:19.527084:  
2025-08-30 14:17:19.535135: Epoch 227 
2025-08-30 14:17:19.539614: Current learning rate: 0.00079 
2025-08-30 14:17:48.431024: train_loss -0.5448 
2025-08-30 14:17:48.439261: val_loss -0.4923 
2025-08-30 14:17:48.443394: Pseudo dice [np.float32(0.7041)] 
2025-08-30 14:17:48.450699: Epoch time: 28.9 s 
2025-08-30 14:17:49.085848:  
2025-08-30 14:17:49.093785: Epoch 228 
2025-08-30 14:17:49.098363: Current learning rate: 0.00079 
2025-08-30 14:18:17.822825: train_loss -0.5881 
2025-08-30 14:18:17.831249: val_loss -0.5643 
2025-08-30 14:18:17.835385: Pseudo dice [np.float32(0.7481)] 
2025-08-30 14:18:17.842451: Epoch time: 28.74 s 
2025-08-30 14:18:18.619051:  
2025-08-30 14:18:18.627696: Epoch 229 
2025-08-30 14:18:18.631556: Current learning rate: 0.00079 
2025-08-30 14:18:47.577395: train_loss -0.5522 
2025-08-30 14:18:47.590042: val_loss -0.4155 
2025-08-30 14:18:47.594176: Pseudo dice [np.float32(0.6531)] 
2025-08-30 14:18:47.600306: Epoch time: 28.96 s 
2025-08-30 14:18:48.228101:  
2025-08-30 14:18:48.236543: Epoch 230 
2025-08-30 14:18:48.240652: Current learning rate: 0.00079 
2025-08-30 14:19:17.377616: train_loss -0.4988 
2025-08-30 14:19:17.382186: val_loss -0.5851 
2025-08-30 14:19:17.390482: Pseudo dice [np.float32(0.7622)] 
2025-08-30 14:19:17.395383: Epoch time: 29.15 s 
2025-08-30 14:19:18.020325:  
2025-08-30 14:19:18.028745: Epoch 231 
2025-08-30 14:19:18.032922: Current learning rate: 0.00079 
2025-08-30 14:19:46.302731: train_loss -0.5122 
2025-08-30 14:19:46.311067: val_loss -0.5351 
2025-08-30 14:19:46.319429: Pseudo dice [np.float32(0.7376)] 
2025-08-30 14:19:46.324792: Epoch time: 28.28 s 
2025-08-30 14:19:46.965894:  
2025-08-30 14:19:46.970030: Epoch 232 
2025-08-30 14:19:46.978470: Current learning rate: 0.00079 
2025-08-30 14:20:15.627365: train_loss -0.5573 
2025-08-30 14:20:15.635748: val_loss -0.5356 
2025-08-30 14:20:15.640342: Pseudo dice [np.float32(0.7511)] 
2025-08-30 14:20:15.646539: Epoch time: 28.67 s 
2025-08-30 14:20:16.269727:  
2025-08-30 14:20:16.278025: Epoch 233 
2025-08-30 14:20:16.282238: Current learning rate: 0.00079 
2025-08-30 14:20:45.465817: train_loss -0.5378 
2025-08-30 14:20:45.465817: val_loss -0.5411 
2025-08-30 14:20:45.476544: Pseudo dice [np.float32(0.7236)] 
2025-08-30 14:20:45.482104: Epoch time: 29.2 s 
2025-08-30 14:20:46.120584:  
2025-08-30 14:20:46.129008: Epoch 234 
2025-08-30 14:20:46.133122: Current learning rate: 0.00079 
2025-08-30 14:21:14.369790: train_loss -0.5589 
2025-08-30 14:21:14.378051: val_loss -0.4559 
2025-08-30 14:21:14.386484: Pseudo dice [np.float32(0.6591)] 
2025-08-30 14:21:14.391600: Epoch time: 28.25 s 
2025-08-30 14:21:15.036619:  
2025-08-30 14:21:15.044954: Epoch 235 
2025-08-30 14:21:15.049460: Current learning rate: 0.00079 
2025-08-30 14:21:44.295507: train_loss -0.5611 
2025-08-30 14:21:44.303730: val_loss -0.4904 
2025-08-30 14:21:44.312096: Pseudo dice [np.float32(0.7871)] 
2025-08-30 14:21:44.317848: Epoch time: 29.26 s 
2025-08-30 14:21:45.108641:  
2025-08-30 14:21:45.117067: Epoch 236 
2025-08-30 14:21:45.121251: Current learning rate: 0.00078 
2025-08-30 14:22:14.141780: train_loss -0.525 
2025-08-30 14:22:14.150170: val_loss -0.5169 
2025-08-30 14:22:14.154266: Pseudo dice [np.float32(0.7566)] 
2025-08-30 14:22:14.162225: Epoch time: 29.03 s 
2025-08-30 14:22:14.821564:  
2025-08-30 14:22:14.829565: Epoch 237 
2025-08-30 14:22:14.834039: Current learning rate: 0.00078 
2025-08-30 14:22:43.383441: train_loss -0.5608 
2025-08-30 14:22:43.396037: val_loss -0.5693 
2025-08-30 14:22:43.400184: Pseudo dice [np.float32(0.7568)] 
2025-08-30 14:22:43.406194: Epoch time: 28.56 s 
2025-08-30 14:22:44.029834:  
2025-08-30 14:22:44.034102: Epoch 238 
2025-08-30 14:22:44.042462: Current learning rate: 0.00078 
2025-08-30 14:23:12.562117: train_loss -0.5705 
2025-08-30 14:23:12.570785: val_loss -0.4932 
2025-08-30 14:23:12.574993: Pseudo dice [np.float32(0.6577)] 
2025-08-30 14:23:12.582118: Epoch time: 28.54 s 
2025-08-30 14:23:13.209166:  
2025-08-30 14:23:13.217390: Epoch 239 
2025-08-30 14:23:13.221515: Current learning rate: 0.00078 
2025-08-30 14:23:42.062370: train_loss -0.5373 
2025-08-30 14:23:42.071142: val_loss -0.6162 
2025-08-30 14:23:42.075304: Pseudo dice [np.float32(0.7507)] 
2025-08-30 14:23:42.081499: Epoch time: 28.86 s 
2025-08-30 14:23:42.717577:  
2025-08-30 14:23:42.726086: Epoch 240 
2025-08-30 14:23:42.730175: Current learning rate: 0.00078 
2025-08-30 14:24:11.418642: train_loss -0.5184 
2025-08-30 14:24:11.427041: val_loss -0.6244 
2025-08-30 14:24:11.433159: Pseudo dice [np.float32(0.7935)] 
2025-08-30 14:24:11.438486: Epoch time: 28.71 s 
2025-08-30 14:24:12.134381:  
2025-08-30 14:24:12.142786: Epoch 241 
2025-08-30 14:24:12.146992: Current learning rate: 0.00078 
2025-08-30 14:24:40.692073: train_loss -0.5326 
2025-08-30 14:24:40.704617: val_loss -0.5613 
2025-08-30 14:24:40.708814: Pseudo dice [np.float32(0.757)] 
2025-08-30 14:24:40.715994: Epoch time: 28.56 s 
2025-08-30 14:24:41.355187:  
2025-08-30 14:24:41.363515: Epoch 242 
2025-08-30 14:24:41.367701: Current learning rate: 0.00078 
2025-08-30 14:25:10.559270: train_loss -0.5315 
2025-08-30 14:25:10.559270: val_loss -0.5294 
2025-08-30 14:25:10.568132: Pseudo dice [np.float32(0.6931)] 
2025-08-30 14:25:10.573508: Epoch time: 29.21 s 
2025-08-30 14:25:11.372267:  
2025-08-30 14:25:11.376765: Epoch 243 
2025-08-30 14:25:11.385141: Current learning rate: 0.00078 
2025-08-30 14:25:38.341211: train_loss -0.5395 
2025-08-30 14:25:38.353745: val_loss -0.4948 
2025-08-30 14:25:38.357913: Pseudo dice [np.float32(0.6743)] 
2025-08-30 14:25:38.366116: Epoch time: 26.97 s 
2025-08-30 14:25:38.995642:  
2025-08-30 14:25:39.003986: Epoch 244 
2025-08-30 14:25:39.008500: Current learning rate: 0.00078 
2025-08-30 14:26:05.864868: train_loss -0.5533 
2025-08-30 14:26:05.872880: val_loss -0.5353 
2025-08-30 14:26:05.877015: Pseudo dice [np.float32(0.7531)] 
2025-08-30 14:26:05.883220: Epoch time: 26.87 s 
2025-08-30 14:26:06.514740:  
2025-08-30 14:26:06.523464: Epoch 245 
2025-08-30 14:26:06.531449: Current learning rate: 0.00078 
2025-08-30 14:26:33.658862: train_loss -0.5205 
2025-08-30 14:26:33.671452: val_loss -0.5693 
2025-08-30 14:26:33.675614: Pseudo dice [np.float32(0.7434)] 
2025-08-30 14:26:33.681732: Epoch time: 27.14 s 
2025-08-30 14:26:34.322097:  
2025-08-30 14:26:34.330450: Epoch 246 
2025-08-30 14:26:34.334583: Current learning rate: 0.00078 
2025-08-30 14:27:01.817559: train_loss -0.5403 
2025-08-30 14:27:01.824396: val_loss -0.5777 
2025-08-30 14:27:01.831404: Pseudo dice [np.float32(0.7908)] 
2025-08-30 14:27:01.836645: Epoch time: 27.5 s 
2025-08-30 14:27:02.470882:  
2025-08-30 14:27:02.479337: Epoch 247 
2025-08-30 14:27:02.483516: Current learning rate: 0.00077 
2025-08-30 14:27:29.331180: train_loss -0.5341 
2025-08-30 14:27:29.343513: val_loss -0.5226 
2025-08-30 14:27:29.347687: Pseudo dice [np.float32(0.7312)] 
2025-08-30 14:27:29.354926: Epoch time: 26.86 s 
2025-08-30 14:27:29.990147:  
2025-08-30 14:27:29.998449: Epoch 248 
2025-08-30 14:27:30.002636: Current learning rate: 0.00077 
2025-08-30 14:27:57.826068: train_loss -0.5327 
2025-08-30 14:27:57.834496: val_loss -0.5812 
2025-08-30 14:27:57.838679: Pseudo dice [np.float32(0.8121)] 
2025-08-30 14:27:57.845851: Epoch time: 27.84 s 
2025-08-30 14:27:58.626954:  
2025-08-30 14:27:58.635350: Epoch 249 
2025-08-30 14:27:58.639497: Current learning rate: 0.00077 
2025-08-30 14:28:26.204675: train_loss -0.5253 
2025-08-30 14:28:26.212844: val_loss -0.549 
2025-08-30 14:28:26.220746: Pseudo dice [np.float32(0.7907)] 
2025-08-30 14:28:26.226070: Epoch time: 27.58 s 
2025-08-30 14:28:27.081003:  
2025-08-30 14:28:27.089408: Epoch 250 
2025-08-30 14:28:27.093561: Current learning rate: 0.00077 
2025-08-30 14:28:54.169876: train_loss -0.5405 
2025-08-30 14:28:54.178179: val_loss -0.5441 
2025-08-30 14:28:54.186531: Pseudo dice [np.float32(0.7554)] 
2025-08-30 14:28:54.191908: Epoch time: 27.09 s 
2025-08-30 14:28:54.196843: Yayy! New best EMA pseudo Dice: 0.7505000233650208 
2025-08-30 14:28:55.037409:  
2025-08-30 14:28:55.045744: Epoch 251 
2025-08-30 14:28:55.049896: Current learning rate: 0.00077 
2025-08-30 14:29:22.393842: train_loss -0.5195 
2025-08-30 14:29:22.402153: val_loss -0.5375 
2025-08-30 14:29:22.406330: Pseudo dice [np.float32(0.7576)] 
2025-08-30 14:29:22.413474: Epoch time: 27.36 s 
2025-08-30 14:29:22.419073: Yayy! New best EMA pseudo Dice: 0.7512000203132629 
2025-08-30 14:29:23.344651:  
2025-08-30 14:29:23.353008: Epoch 252 
2025-08-30 14:29:23.361343: Current learning rate: 0.00077 
2025-08-30 14:29:50.959685: train_loss -0.5406 
2025-08-30 14:29:50.963539: val_loss -0.5518 
2025-08-30 14:29:50.968095: Pseudo dice [np.float32(0.7956)] 
2025-08-30 14:29:50.977112: Epoch time: 27.62 s 
2025-08-30 14:29:50.982981: Yayy! New best EMA pseudo Dice: 0.7555999755859375 
2025-08-30 14:29:51.823153:  
2025-08-30 14:29:51.831504: Epoch 253 
2025-08-30 14:29:51.839494: Current learning rate: 0.00077 
2025-08-30 14:30:18.541736: train_loss -0.5399 
2025-08-30 14:30:18.549705: val_loss -0.5835 
2025-08-30 14:30:18.553885: Pseudo dice [np.float32(0.7865)] 
2025-08-30 14:30:18.561141: Epoch time: 26.72 s 
2025-08-30 14:30:18.567620: Yayy! New best EMA pseudo Dice: 0.7587000131607056 
2025-08-30 14:30:19.513157:  
2025-08-30 14:30:19.517331: Epoch 254 
2025-08-30 14:30:19.525356: Current learning rate: 0.00077 
2025-08-30 14:30:46.736206: train_loss -0.5866 
2025-08-30 14:30:46.748772: val_loss -0.5724 
2025-08-30 14:30:46.752939: Pseudo dice [np.float32(0.7685)] 
2025-08-30 14:30:46.759013: Epoch time: 27.23 s 
2025-08-30 14:30:46.761858: Yayy! New best EMA pseudo Dice: 0.7597000002861023 
2025-08-30 14:30:47.691338:  
2025-08-30 14:30:47.699691: Epoch 255 
2025-08-30 14:30:47.703846: Current learning rate: 0.00077 
2025-08-30 14:31:15.481486: train_loss -0.5193 
2025-08-30 14:31:15.489964: val_loss -0.523 
2025-08-30 14:31:15.494133: Pseudo dice [np.float32(0.7604)] 
2025-08-30 14:31:15.501249: Epoch time: 27.79 s 
2025-08-30 14:31:15.506862: Yayy! New best EMA pseudo Dice: 0.7598000168800354 
2025-08-30 14:31:16.357411:  
2025-08-30 14:31:16.365839: Epoch 256 
2025-08-30 14:31:16.369980: Current learning rate: 0.00077 
2025-08-30 14:31:43.292203: train_loss -0.579 
2025-08-30 14:31:43.301020: val_loss -0.5884 
2025-08-30 14:31:43.305167: Pseudo dice [np.float32(0.7839)] 
2025-08-30 14:31:43.313373: Epoch time: 26.93 s 
2025-08-30 14:31:43.319066: Yayy! New best EMA pseudo Dice: 0.7621999979019165 
2025-08-30 14:31:44.151837:  
2025-08-30 14:31:44.160231: Epoch 257 
2025-08-30 14:31:44.164340: Current learning rate: 0.00077 
2025-08-30 14:32:11.366044: train_loss -0.509 
2025-08-30 14:32:11.374736: val_loss -0.5789 
2025-08-30 14:32:11.378572: Pseudo dice [np.float32(0.7255)] 
2025-08-30 14:32:11.386923: Epoch time: 27.21 s 
2025-08-30 14:32:12.029642:  
2025-08-30 14:32:12.038025: Epoch 258 
2025-08-30 14:32:12.042183: Current learning rate: 0.00076 
2025-08-30 14:32:39.561693: train_loss -0.5777 
2025-08-30 14:32:39.573857: val_loss -0.6362 
2025-08-30 14:32:39.579623: Pseudo dice [np.float32(0.7746)] 
2025-08-30 14:32:39.584323: Epoch time: 27.53 s 
2025-08-30 14:32:40.219823:  
2025-08-30 14:32:40.228559: Epoch 259 
2025-08-30 14:32:40.232714: Current learning rate: 0.00076 
2025-08-30 14:33:07.443203: train_loss -0.5444 
2025-08-30 14:33:07.451618: val_loss -0.572 
2025-08-30 14:33:07.455744: Pseudo dice [np.float32(0.763)] 
2025-08-30 14:33:07.463850: Epoch time: 27.22 s 
2025-08-30 14:33:08.102194:  
2025-08-30 14:33:08.110610: Epoch 260 
2025-08-30 14:33:08.118524: Current learning rate: 0.00076 
2025-08-30 14:33:34.724646: train_loss -0.5424 
2025-08-30 14:33:34.737853: val_loss -0.6116 
2025-08-30 14:33:34.741797: Pseudo dice [np.float32(0.7713)] 
2025-08-30 14:33:34.749299: Epoch time: 26.62 s 
2025-08-30 14:33:35.383491:  
2025-08-30 14:33:35.391531: Epoch 261 
2025-08-30 14:33:35.396036: Current learning rate: 0.00076 
2025-08-30 14:34:03.136309: train_loss -0.5764 
2025-08-30 14:34:03.144662: val_loss -0.6011 
2025-08-30 14:34:03.152984: Pseudo dice [np.float32(0.7981)] 
2025-08-30 14:34:03.157866: Epoch time: 27.76 s 
2025-08-30 14:34:03.163522: Yayy! New best EMA pseudo Dice: 0.7652000188827515 
2025-08-30 14:34:04.170241:  
2025-08-30 14:34:04.174387: Epoch 262 
2025-08-30 14:34:04.183064: Current learning rate: 0.00076 
2025-08-30 14:34:31.706300: train_loss -0.5445 
2025-08-30 14:34:31.706300: val_loss -0.5688 
2025-08-30 14:34:31.718535: Pseudo dice [np.float32(0.8002)] 
2025-08-30 14:34:31.723827: Epoch time: 27.54 s 
2025-08-30 14:34:31.730862: Yayy! New best EMA pseudo Dice: 0.7687000036239624 
2025-08-30 14:34:32.569685:  
2025-08-30 14:34:32.578153: Epoch 263 
2025-08-30 14:34:32.586853: Current learning rate: 0.00076 
2025-08-30 14:34:59.834518: train_loss -0.5268 
2025-08-30 14:34:59.842779: val_loss -0.5807 
2025-08-30 14:34:59.851484: Pseudo dice [np.float32(0.7861)] 
2025-08-30 14:34:59.855993: Epoch time: 27.26 s 
2025-08-30 14:34:59.861686: Yayy! New best EMA pseudo Dice: 0.7703999876976013 
2025-08-30 14:35:00.702017:  
2025-08-30 14:35:00.710263: Epoch 264 
2025-08-30 14:35:00.718810: Current learning rate: 0.00076 
2025-08-30 14:35:28.053824: train_loss -0.5792 
2025-08-30 14:35:28.066391: val_loss -0.5445 
2025-08-30 14:35:28.070868: Pseudo dice [np.float32(0.8065)] 
2025-08-30 14:35:28.078041: Epoch time: 27.35 s 
2025-08-30 14:35:28.083532: Yayy! New best EMA pseudo Dice: 0.7739999890327454 
2025-08-30 14:35:29.001071:  
2025-08-30 14:35:29.009521: Epoch 265 
2025-08-30 14:35:29.013480: Current learning rate: 0.00076 
2025-08-30 14:35:56.307375: train_loss -0.5275 
2025-08-30 14:35:56.315392: val_loss -0.6273 
2025-08-30 14:35:56.319991: Pseudo dice [np.float32(0.7879)] 
2025-08-30 14:35:56.326223: Epoch time: 27.31 s 
2025-08-30 14:35:56.332040: Yayy! New best EMA pseudo Dice: 0.7753999829292297 
2025-08-30 14:35:57.191630:  
2025-08-30 14:35:57.200080: Epoch 266 
2025-08-30 14:35:57.208434: Current learning rate: 0.00076 
2025-08-30 14:36:23.789442: train_loss -0.5315 
2025-08-30 14:36:23.797402: val_loss -0.6023 
2025-08-30 14:36:23.805303: Pseudo dice [np.float32(0.7996)] 
2025-08-30 14:36:23.810629: Epoch time: 26.6 s 
2025-08-30 14:36:23.815083: Yayy! New best EMA pseudo Dice: 0.7778000235557556 
2025-08-30 14:36:24.777482:  
2025-08-30 14:36:24.785883: Epoch 267 
2025-08-30 14:36:24.790017: Current learning rate: 0.00076 
2025-08-30 14:36:51.929452: train_loss -0.5263 
2025-08-30 14:36:51.937820: val_loss -0.5642 
2025-08-30 14:36:51.942111: Pseudo dice [np.float32(0.7075)] 
2025-08-30 14:36:51.950162: Epoch time: 27.15 s 
2025-08-30 14:36:52.596811:  
2025-08-30 14:36:52.604870: Epoch 268 
2025-08-30 14:36:52.609469: Current learning rate: 0.00076 
2025-08-30 14:37:20.311941: train_loss -0.5706 
2025-08-30 14:37:20.320401: val_loss -0.6107 
2025-08-30 14:37:20.324637: Pseudo dice [np.float32(0.7546)] 
2025-08-30 14:37:20.332711: Epoch time: 27.72 s 
2025-08-30 14:37:20.983124:  
2025-08-30 14:37:20.991492: Epoch 269 
2025-08-30 14:37:20.995663: Current learning rate: 0.00075 
2025-08-30 14:37:48.206577: train_loss -0.5279 
2025-08-30 14:37:48.219039: val_loss -0.5903 
2025-08-30 14:37:48.223201: Pseudo dice [np.float32(0.8207)] 
2025-08-30 14:37:48.229365: Epoch time: 27.22 s 
2025-08-30 14:37:48.863356:  
2025-08-30 14:37:48.869687: Epoch 270 
2025-08-30 14:37:48.875929: Current learning rate: 0.00075 
2025-08-30 14:38:16.046364: train_loss -0.5681 
2025-08-30 14:38:16.055055: val_loss -0.5469 
2025-08-30 14:38:16.058875: Pseudo dice [np.float32(0.7508)] 
2025-08-30 14:38:16.067237: Epoch time: 27.18 s 
2025-08-30 14:38:16.705658:  
2025-08-30 14:38:16.714179: Epoch 271 
2025-08-30 14:38:16.718322: Current learning rate: 0.00075 
2025-08-30 14:38:43.595040: train_loss -0.555 
2025-08-30 14:38:43.603343: val_loss -0.5203 
2025-08-30 14:38:43.611694: Pseudo dice [np.float32(0.7531)] 
2025-08-30 14:38:43.617947: Epoch time: 26.89 s 
2025-08-30 14:38:44.254041:  
2025-08-30 14:38:44.262482: Epoch 272 
2025-08-30 14:38:44.266597: Current learning rate: 0.00075 
2025-08-30 14:39:11.484952: train_loss -0.5795 
2025-08-30 14:39:11.484952: val_loss -0.5926 
2025-08-30 14:39:11.495969: Pseudo dice [np.float32(0.7605)] 
2025-08-30 14:39:11.501600: Epoch time: 27.23 s 
2025-08-30 14:39:12.136041:  
2025-08-30 14:39:12.144439: Epoch 273 
2025-08-30 14:39:12.152323: Current learning rate: 0.00075 
2025-08-30 14:39:38.582821: train_loss -0.5639 
2025-08-30 14:39:38.591596: val_loss -0.5351 
2025-08-30 14:39:38.595712: Pseudo dice [np.float32(0.7495)] 
2025-08-30 14:39:38.600479: Epoch time: 26.45 s 
2025-08-30 14:39:39.396595:  
2025-08-30 14:39:39.404957: Epoch 274 
2025-08-30 14:39:39.409087: Current learning rate: 0.00075 
2025-08-30 14:40:07.124109: train_loss -0.5687 
2025-08-30 14:40:07.132591: val_loss -0.5184 
2025-08-30 14:40:07.136759: Pseudo dice [np.float32(0.7085)] 
2025-08-30 14:40:07.144793: Epoch time: 27.73 s 
2025-08-30 14:40:07.774432:  
2025-08-30 14:40:07.782799: Epoch 275 
2025-08-30 14:40:07.791435: Current learning rate: 0.00075 
2025-08-30 14:40:35.127009: train_loss -0.579 
2025-08-30 14:40:35.135376: val_loss -0.5698 
2025-08-30 14:40:35.143755: Pseudo dice [np.float32(0.7553)] 
2025-08-30 14:40:35.149052: Epoch time: 27.35 s 
2025-08-30 14:40:35.773664:  
2025-08-30 14:40:35.782011: Epoch 276 
2025-08-30 14:40:35.786173: Current learning rate: 0.00075 
2025-08-30 14:41:03.054545: train_loss -0.5585 
2025-08-30 14:41:03.063262: val_loss -0.5672 
2025-08-30 14:41:03.067408: Pseudo dice [np.float32(0.7948)] 
2025-08-30 14:41:03.073913: Epoch time: 27.28 s 
2025-08-30 14:41:03.701433:  
2025-08-30 14:41:03.709889: Epoch 277 
2025-08-30 14:41:03.713959: Current learning rate: 0.00075 
2025-08-30 14:41:30.894828: train_loss -0.5331 
2025-08-30 14:41:30.903627: val_loss -0.5766 
2025-08-30 14:41:30.907665: Pseudo dice [np.float32(0.7515)] 
2025-08-30 14:41:30.916604: Epoch time: 27.19 s 
2025-08-30 14:41:31.553808:  
2025-08-30 14:41:31.562513: Epoch 278 
2025-08-30 14:41:31.566324: Current learning rate: 0.00075 
2025-08-30 14:41:58.789686: train_loss -0.5796 
2025-08-30 14:41:58.797644: val_loss -0.5626 
2025-08-30 14:41:58.802269: Pseudo dice [np.float32(0.7987)] 
2025-08-30 14:41:58.809408: Epoch time: 27.24 s 
2025-08-30 14:41:59.444137:  
2025-08-30 14:41:59.452762: Epoch 279 
2025-08-30 14:41:59.456910: Current learning rate: 0.00074 
2025-08-30 14:42:28.264916: train_loss -0.5003 
2025-08-30 14:42:28.277338: val_loss -0.5656 
2025-08-30 14:42:28.281563: Pseudo dice [np.float32(0.7355)] 
2025-08-30 14:42:28.289806: Epoch time: 28.82 s 
2025-08-30 14:42:28.927674:  
2025-08-30 14:42:28.932302: Epoch 280 
2025-08-30 14:42:28.940641: Current learning rate: 0.00074 
2025-08-30 14:42:57.585843: train_loss -0.5395 
2025-08-30 14:42:57.594215: val_loss -0.5253 
2025-08-30 14:42:57.598296: Pseudo dice [np.float32(0.7697)] 
2025-08-30 14:42:57.606380: Epoch time: 28.66 s 
2025-08-30 14:42:58.382478:  
2025-08-30 14:42:58.390863: Epoch 281 
2025-08-30 14:42:58.394990: Current learning rate: 0.00074 
2025-08-30 14:43:27.703737: train_loss -0.5457 
2025-08-30 14:43:27.712310: val_loss -0.5636 
2025-08-30 14:43:27.717468: Pseudo dice [np.float32(0.753)] 
2025-08-30 14:43:27.722445: Epoch time: 29.33 s 
2025-08-30 14:43:28.383343:  
2025-08-30 14:43:28.391495: Epoch 282 
2025-08-30 14:43:28.398130: Current learning rate: 0.00074 
2025-08-30 14:43:54.442087: train_loss -0.5463 
2025-08-30 14:43:54.442087: val_loss -0.555 
2025-08-30 14:43:54.453008: Pseudo dice [np.float32(0.73)] 
2025-08-30 14:43:54.458792: Epoch time: 26.06 s 
2025-08-30 14:43:55.083261:  
2025-08-30 14:43:55.090619: Epoch 283 
2025-08-30 14:43:55.096775: Current learning rate: 0.00074 
2025-08-30 14:44:20.468058: train_loss -0.543 
2025-08-30 14:44:20.472589: val_loss -0.5133 
2025-08-30 14:44:20.480899: Pseudo dice [np.float32(0.7325)] 
2025-08-30 14:44:20.485970: Epoch time: 25.39 s 
2025-08-30 14:44:21.106107:  
2025-08-30 14:44:21.115653: Epoch 284 
2025-08-30 14:44:21.121728: Current learning rate: 0.00074 
2025-08-30 14:44:46.014629: train_loss -0.5356 
2025-08-30 14:44:46.022706: val_loss -0.4871 
2025-08-30 14:44:46.031056: Pseudo dice [np.float32(0.6748)] 
2025-08-30 14:44:46.036586: Epoch time: 24.91 s 
2025-08-30 14:44:46.656515:  
2025-08-30 14:44:46.664879: Epoch 285 
2025-08-30 14:44:46.671214: Current learning rate: 0.00074 
2025-08-30 14:45:11.193642: train_loss -0.563 
2025-08-30 14:45:11.201992: val_loss -0.4839 
2025-08-30 14:45:11.206154: Pseudo dice [np.float32(0.7433)] 
2025-08-30 14:45:11.214230: Epoch time: 24.54 s 
2025-08-30 14:45:11.832903:  
2025-08-30 14:45:11.839961: Epoch 286 
2025-08-30 14:45:11.845391: Current learning rate: 0.00074 
2025-08-30 14:45:36.894613: train_loss -0.5821 
2025-08-30 14:45:36.902961: val_loss -0.4972 
2025-08-30 14:45:36.907109: Pseudo dice [np.float32(0.7203)] 
2025-08-30 14:45:36.914853: Epoch time: 25.06 s 
2025-08-30 14:45:37.534482:  
2025-08-30 14:45:37.541808: Epoch 287 
2025-08-30 14:45:37.547030: Current learning rate: 0.00074 
2025-08-30 14:46:03.099941: train_loss -0.5156 
2025-08-30 14:46:03.108274: val_loss -0.5322 
2025-08-30 14:46:03.116613: Pseudo dice [np.float32(0.745)] 
2025-08-30 14:46:03.122393: Epoch time: 25.57 s 
2025-08-30 14:46:03.737595:  
2025-08-30 14:46:03.744956: Epoch 288 
2025-08-30 14:46:03.750107: Current learning rate: 0.00074 
2025-08-30 14:46:28.409971: train_loss -0.5481 
2025-08-30 14:46:28.416831: val_loss -0.5831 
2025-08-30 14:46:28.420715: Pseudo dice [np.float32(0.806)] 
2025-08-30 14:46:28.429770: Epoch time: 24.67 s 
2025-08-30 14:46:29.045082:  
2025-08-30 14:46:29.054599: Epoch 289 
2025-08-30 14:46:29.060874: Current learning rate: 0.00074 
2025-08-30 14:46:54.689572: train_loss -0.5605 
2025-08-30 14:46:54.697263: val_loss -0.5134 
2025-08-30 14:46:54.701409: Pseudo dice [np.float32(0.7862)] 
2025-08-30 14:46:54.709175: Epoch time: 25.65 s 
2025-08-30 14:46:55.341158:  
2025-08-30 14:46:55.351720: Epoch 290 
2025-08-30 14:46:55.356219: Current learning rate: 0.00073 
2025-08-30 14:47:20.668941: train_loss -0.59 
2025-08-30 14:47:20.676933: val_loss -0.622 
2025-08-30 14:47:20.681425: Pseudo dice [np.float32(0.7902)] 
2025-08-30 14:47:20.687342: Epoch time: 25.33 s 
2025-08-30 14:47:21.310691:  
2025-08-30 14:47:21.318162: Epoch 291 
2025-08-30 14:47:21.324494: Current learning rate: 0.00073 
2025-08-30 14:47:46.586401: train_loss -0.5723 
2025-08-30 14:47:46.594759: val_loss -0.4938 
2025-08-30 14:47:46.598946: Pseudo dice [np.float32(0.7222)] 
2025-08-30 14:47:46.605773: Epoch time: 25.28 s 
2025-08-30 14:47:47.235649:  
2025-08-30 14:47:47.245389: Epoch 292 
2025-08-30 14:47:47.252244: Current learning rate: 0.00073 
2025-08-30 14:48:14.093085: train_loss -0.5639 
2025-08-30 14:48:14.101479: val_loss -0.4583 
2025-08-30 14:48:14.105619: Pseudo dice [np.float32(0.744)] 
2025-08-30 14:48:14.111745: Epoch time: 26.86 s 
2025-08-30 14:48:14.792240:  
2025-08-30 14:48:14.798637: Epoch 293 
2025-08-30 14:48:14.804726: Current learning rate: 0.00073 
2025-08-30 14:48:41.257254: train_loss -0.5398 
2025-08-30 14:48:41.257254: val_loss -0.601 
2025-08-30 14:48:41.267230: Pseudo dice [np.float32(0.8047)] 
2025-08-30 14:48:41.273900: Epoch time: 26.47 s 
2025-08-30 14:48:42.108060:  
2025-08-30 14:48:42.116464: Epoch 294 
2025-08-30 14:48:42.121631: Current learning rate: 0.00073 
2025-08-30 14:49:09.072491: train_loss -0.5584 
2025-08-30 14:49:09.080911: val_loss -0.5651 
2025-08-30 14:49:09.085025: Pseudo dice [np.float32(0.758)] 
2025-08-30 14:49:09.091351: Epoch time: 26.97 s 
2025-08-30 14:49:09.791623:  
2025-08-30 14:49:09.799235: Epoch 295 
2025-08-30 14:49:09.802790: Current learning rate: 0.00073 
2025-08-30 14:49:37.154992: train_loss -0.5712 
2025-08-30 14:49:37.163442: val_loss -0.5348 
2025-08-30 14:49:37.171406: Pseudo dice [np.float32(0.7616)] 
2025-08-30 14:49:37.176964: Epoch time: 27.37 s 
2025-08-30 14:49:37.858666:  
2025-08-30 14:49:37.864038: Epoch 296 
2025-08-30 14:49:37.871892: Current learning rate: 0.00073 
2025-08-30 14:50:05.078750: train_loss -0.5403 
2025-08-30 14:50:05.087062: val_loss -0.5779 
2025-08-30 14:50:05.091278: Pseudo dice [np.float32(0.7508)] 
2025-08-30 14:50:05.098277: Epoch time: 27.22 s 
2025-08-30 14:50:05.781059:  
2025-08-30 14:50:05.791933: Epoch 297 
2025-08-30 14:50:05.799002: Current learning rate: 0.00073 
2025-08-30 14:50:32.989512: train_loss -0.5572 
2025-08-30 14:50:32.997872: val_loss -0.4562 
2025-08-30 14:50:33.002037: Pseudo dice [np.float32(0.7796)] 
2025-08-30 14:50:33.009305: Epoch time: 27.21 s 
2025-08-30 14:50:33.682885:  
2025-08-30 14:50:33.690192: Epoch 298 
2025-08-30 14:50:33.696498: Current learning rate: 0.00073 
2025-08-30 14:51:00.763413: train_loss -0.5028 
2025-08-30 14:51:00.771747: val_loss -0.5869 
2025-08-30 14:51:00.779798: Pseudo dice [np.float32(0.7872)] 
2025-08-30 14:51:00.790609: Epoch time: 27.08 s 
2025-08-30 14:51:01.510606:  
2025-08-30 14:51:01.517854: Epoch 299 
2025-08-30 14:51:01.522594: Current learning rate: 0.00073 
2025-08-30 14:51:28.482671: train_loss -0.517 
2025-08-30 14:51:28.490711: val_loss -0.5875 
2025-08-30 14:51:28.495264: Pseudo dice [np.float32(0.7409)] 
2025-08-30 14:51:28.501238: Epoch time: 26.97 s 
2025-08-30 14:51:29.615712:  
2025-08-30 14:51:29.623071: Epoch 300 
2025-08-30 14:51:29.628142: Current learning rate: 0.00073 
2025-08-30 14:51:55.838943: train_loss -0.5896 
2025-08-30 14:51:55.847147: val_loss -0.4772 
2025-08-30 14:51:55.851299: Pseudo dice [np.float32(0.7454)] 
2025-08-30 14:51:55.859644: Epoch time: 26.23 s 
2025-08-30 14:51:56.536423:  
2025-08-30 14:51:56.543564: Epoch 301 
2025-08-30 14:51:56.550935: Current learning rate: 0.00072 
2025-08-30 14:52:23.132955: train_loss -0.5394 
2025-08-30 14:52:23.141024: val_loss -0.5858 
2025-08-30 14:52:23.145183: Pseudo dice [np.float32(0.7855)] 
2025-08-30 14:52:23.152844: Epoch time: 26.6 s 
2025-08-30 14:52:23.838573:  
2025-08-30 14:52:23.847887: Epoch 302 
2025-08-30 14:52:23.854179: Current learning rate: 0.00072 
2025-08-30 14:52:51.161030: train_loss -0.5584 
2025-08-30 14:52:51.169362: val_loss -0.5783 
2025-08-30 14:52:51.177732: Pseudo dice [np.float32(0.7902)] 
2025-08-30 14:52:51.182837: Epoch time: 27.33 s 
2025-08-30 14:52:51.881098:  
2025-08-30 14:52:51.891582: Epoch 303 
2025-08-30 14:52:51.902948: Current learning rate: 0.00072 
2025-08-30 14:53:21.138165: train_loss -0.5731 
2025-08-30 14:53:21.138165: val_loss -0.5675 
2025-08-30 14:53:21.146420: Pseudo dice [np.float32(0.7841)] 
2025-08-30 14:53:21.152999: Epoch time: 29.26 s 
2025-08-30 14:53:21.833940:  
2025-08-30 14:53:21.842343: Epoch 304 
2025-08-30 14:53:21.848516: Current learning rate: 0.00072 
2025-08-30 14:53:49.982169: train_loss -0.5424 
2025-08-30 14:53:49.990474: val_loss -0.6344 
2025-08-30 14:53:49.994702: Pseudo dice [np.float32(0.797)] 
2025-08-30 14:53:50.002522: Epoch time: 28.15 s 
2025-08-30 14:53:50.673035:  
2025-08-30 14:53:50.680394: Epoch 305 
2025-08-30 14:53:50.685596: Current learning rate: 0.00072 
2025-08-30 14:54:19.657577: train_loss -0.5546 
2025-08-30 14:54:19.665542: val_loss -0.5764 
2025-08-30 14:54:19.669750: Pseudo dice [np.float32(0.7859)] 
2025-08-30 14:54:19.676082: Epoch time: 28.99 s 
2025-08-30 14:54:20.366202:  
2025-08-30 14:54:20.373422: Epoch 306 
2025-08-30 14:54:20.378664: Current learning rate: 0.00072 
2025-08-30 14:54:48.933066: train_loss -0.5826 
2025-08-30 14:54:48.940941: val_loss -0.5611 
2025-08-30 14:54:48.945145: Pseudo dice [np.float32(0.7537)] 
2025-08-30 14:54:48.951173: Epoch time: 28.57 s 
2025-08-30 14:54:49.790325:  
2025-08-30 14:54:49.799662: Epoch 307 
2025-08-30 14:54:49.812268: Current learning rate: 0.00072 
2025-08-30 14:55:18.241024: train_loss -0.5143 
2025-08-30 14:55:18.249332: val_loss -0.5771 
2025-08-30 14:55:18.257321: Pseudo dice [np.float32(0.7903)] 
2025-08-30 14:55:18.262320: Epoch time: 28.45 s 
2025-08-30 14:55:18.931897:  
2025-08-30 14:55:18.940233: Epoch 308 
2025-08-30 14:55:18.946558: Current learning rate: 0.00072 
2025-08-30 14:55:46.973883: train_loss -0.5694 
2025-08-30 14:55:46.982156: val_loss -0.534 
2025-08-30 14:55:46.990512: Pseudo dice [np.float32(0.7644)] 
2025-08-30 14:55:46.995643: Epoch time: 28.04 s 
2025-08-30 14:55:47.686458:  
2025-08-30 14:55:47.692864: Epoch 309 
2025-08-30 14:55:47.695855: Current learning rate: 0.00072 
2025-08-30 14:56:16.695093: train_loss -0.5652 
2025-08-30 14:56:16.703482: val_loss -0.5439 
2025-08-30 14:56:16.707570: Pseudo dice [np.float32(0.7078)] 
2025-08-30 14:56:16.715591: Epoch time: 29.01 s 
2025-08-30 14:56:17.390162:  
2025-08-30 14:56:17.397450: Epoch 310 
2025-08-30 14:56:17.404854: Current learning rate: 0.00072 
2025-08-30 14:56:46.265967: train_loss -0.522 
2025-08-30 14:56:46.274247: val_loss -0.4607 
2025-08-30 14:56:46.278405: Pseudo dice [np.float32(0.7306)] 
2025-08-30 14:56:46.284960: Epoch time: 28.88 s 
2025-08-30 14:56:46.967676:  
2025-08-30 14:56:46.976013: Epoch 311 
2025-08-30 14:56:46.981160: Current learning rate: 0.00072 
2025-08-30 14:57:15.295892: train_loss -0.536 
2025-08-30 14:57:15.303558: val_loss -0.572 
2025-08-30 14:57:15.313252: Pseudo dice [np.float32(0.777)] 
2025-08-30 14:57:15.319500: Epoch time: 28.33 s 
2025-08-30 14:57:16.105984:  
2025-08-30 14:57:16.114200: Epoch 312 
2025-08-30 14:57:16.121670: Current learning rate: 0.00071 
2025-08-30 14:57:44.762352: train_loss -0.5656 
2025-08-30 14:57:44.762352: val_loss -0.5865 
2025-08-30 14:57:44.771757: Pseudo dice [np.float32(0.7727)] 
2025-08-30 14:57:44.776400: Epoch time: 28.66 s 
2025-08-30 14:57:45.478015:  
2025-08-30 14:57:45.487110: Epoch 313 
2025-08-30 14:57:45.494497: Current learning rate: 0.00071 
2025-08-30 14:58:14.749949: train_loss -0.5585 
2025-08-30 14:58:14.758297: val_loss -0.5691 
2025-08-30 14:58:14.762459: Pseudo dice [np.float32(0.7781)] 
2025-08-30 14:58:14.770750: Epoch time: 29.27 s 
2025-08-30 14:58:15.595558:  
2025-08-30 14:58:15.602887: Epoch 314 
2025-08-30 14:58:15.608963: Current learning rate: 0.00071 
2025-08-30 14:58:43.979460: train_loss -0.5504 
2025-08-30 14:58:43.987839: val_loss -0.5166 
2025-08-30 14:58:43.996222: Pseudo dice [np.float32(0.6825)] 
2025-08-30 14:58:44.001213: Epoch time: 28.39 s 
2025-08-30 14:58:44.695426:  
2025-08-30 14:58:44.702758: Epoch 315 
2025-08-30 14:58:44.708857: Current learning rate: 0.00071 
2025-08-30 14:59:12.791505: train_loss -0.5442 
2025-08-30 14:59:12.799884: val_loss -0.5106 
2025-08-30 14:59:12.808272: Pseudo dice [np.float32(0.7193)] 
2025-08-30 14:59:12.813797: Epoch time: 28.1 s 
2025-08-30 14:59:13.488723:  
2025-08-30 14:59:13.497099: Epoch 316 
2025-08-30 14:59:13.503294: Current learning rate: 0.00071 
2025-08-30 14:59:42.867423: train_loss -0.5061 
2025-08-30 14:59:42.875713: val_loss -0.5559 
2025-08-30 14:59:42.879798: Pseudo dice [np.float32(0.7626)] 
2025-08-30 14:59:42.888689: Epoch time: 29.38 s 
2025-08-30 14:59:43.583282:  
2025-08-30 14:59:43.593841: Epoch 317 
2025-08-30 14:59:43.603565: Current learning rate: 0.00071 
2025-08-30 15:00:12.638533: train_loss -0.5542 
2025-08-30 15:00:12.646675: val_loss -0.5694 
2025-08-30 15:00:12.650836: Pseudo dice [np.float32(0.8054)] 
2025-08-30 15:00:12.660109: Epoch time: 29.06 s 
2025-08-30 15:00:13.361908:  
2025-08-30 15:00:13.370377: Epoch 318 
2025-08-30 15:00:13.378736: Current learning rate: 0.00071 
2025-08-30 15:00:41.734554: train_loss -0.5454 
2025-08-30 15:00:41.742737: val_loss -0.5609 
2025-08-30 15:00:41.751063: Pseudo dice [np.float32(0.7534)] 
2025-08-30 15:00:41.756230: Epoch time: 28.38 s 
2025-08-30 15:00:42.456599:  
2025-08-30 15:00:42.464333: Epoch 319 
2025-08-30 15:00:42.470138: Current learning rate: 0.00071 
2025-08-30 15:01:10.592323: train_loss -0.5175 
2025-08-30 15:01:10.600661: val_loss -0.6089 
2025-08-30 15:01:10.604816: Pseudo dice [np.float32(0.8068)] 
2025-08-30 15:01:10.612859: Epoch time: 28.14 s 
2025-08-30 15:01:11.458296:  
2025-08-30 15:01:11.465718: Epoch 320 
2025-08-30 15:01:11.470836: Current learning rate: 0.00071 
2025-08-30 15:01:40.179790: train_loss -0.557 
2025-08-30 15:01:40.188145: val_loss -0.5347 
2025-08-30 15:01:40.192284: Pseudo dice [np.float32(0.7921)] 
2025-08-30 15:01:40.201514: Epoch time: 28.72 s 
2025-08-30 15:01:40.863624:  
2025-08-30 15:01:40.871036: Epoch 321 
2025-08-30 15:01:40.876257: Current learning rate: 0.00071 
2025-08-30 15:02:09.413548: train_loss -0.567 
2025-08-30 15:02:09.421855: val_loss -0.5996 
2025-08-30 15:02:09.426004: Pseudo dice [np.float32(0.7635)] 
2025-08-30 15:02:09.433960: Epoch time: 28.55 s 
2025-08-30 15:02:10.129387:  
2025-08-30 15:02:10.137751: Epoch 322 
2025-08-30 15:02:10.145298: Current learning rate: 0.0007 
2025-08-30 15:02:38.258534: train_loss -0.5788 
2025-08-30 15:02:38.258907: val_loss -0.5754 
2025-08-30 15:02:38.267640: Pseudo dice [np.float32(0.7451)] 
2025-08-30 15:02:38.273201: Epoch time: 28.13 s 
2025-08-30 15:02:38.924722:  
2025-08-30 15:02:38.933125: Epoch 323 
2025-08-30 15:02:38.938203: Current learning rate: 0.0007 
2025-08-30 15:03:07.846375: train_loss -0.5806 
2025-08-30 15:03:07.854757: val_loss -0.5253 
2025-08-30 15:03:07.863660: Pseudo dice [np.float32(0.8286)] 
2025-08-30 15:03:07.869396: Epoch time: 28.92 s 
2025-08-30 15:03:08.567844:  
2025-08-30 15:03:08.579353: Epoch 324 
2025-08-30 15:03:08.588983: Current learning rate: 0.0007 
2025-08-30 15:03:37.029969: train_loss -0.5383 
2025-08-30 15:03:37.038368: val_loss -0.6202 
2025-08-30 15:03:37.046342: Pseudo dice [np.float32(0.7974)] 
2025-08-30 15:03:37.052212: Epoch time: 28.46 s 
2025-08-30 15:03:37.759436:  
2025-08-30 15:03:37.770899: Epoch 325 
2025-08-30 15:03:37.778280: Current learning rate: 0.0007 
2025-08-30 15:04:06.333862: train_loss -0.4978 
2025-08-30 15:04:06.342212: val_loss -0.5603 
2025-08-30 15:04:06.350550: Pseudo dice [np.float32(0.7763)] 
2025-08-30 15:04:06.356103: Epoch time: 28.58 s 
2025-08-30 15:04:07.040809:  
2025-08-30 15:04:07.050184: Epoch 326 
2025-08-30 15:04:07.055368: Current learning rate: 0.0007 
2025-08-30 15:04:35.626016: train_loss -0.5665 
2025-08-30 15:04:35.634292: val_loss -0.5323 
2025-08-30 15:04:35.643003: Pseudo dice [np.float32(0.7631)] 
2025-08-30 15:04:35.647807: Epoch time: 28.59 s 
2025-08-30 15:04:36.509695:  
2025-08-30 15:04:36.516978: Epoch 327 
2025-08-30 15:04:36.524316: Current learning rate: 0.0007 
2025-08-30 15:05:06.277371: train_loss -0.5696 
2025-08-30 15:05:06.285663: val_loss -0.5541 
2025-08-30 15:05:06.289872: Pseudo dice [np.float32(0.776)] 
2025-08-30 15:05:06.297770: Epoch time: 29.77 s 
2025-08-30 15:05:07.008888:  
2025-08-30 15:05:07.015932: Epoch 328 
2025-08-30 15:05:07.023413: Current learning rate: 0.0007 
2025-08-30 15:05:35.644101: train_loss -0.553 
2025-08-30 15:05:35.652470: val_loss -0.6178 
2025-08-30 15:05:35.660869: Pseudo dice [np.float32(0.7758)] 
2025-08-30 15:05:35.665935: Epoch time: 28.64 s 
2025-08-30 15:05:36.354776:  
2025-08-30 15:05:36.364187: Epoch 329 
2025-08-30 15:05:36.373584: Current learning rate: 0.0007 
2025-08-30 15:06:04.937411: train_loss -0.55 
2025-08-30 15:06:04.944175: val_loss -0.5517 
2025-08-30 15:06:04.948330: Pseudo dice [np.float32(0.7874)] 
2025-08-30 15:06:04.957216: Epoch time: 28.58 s 
2025-08-30 15:06:05.644351:  
2025-08-30 15:06:05.652658: Epoch 330 
2025-08-30 15:06:05.660088: Current learning rate: 0.0007 
2025-08-30 15:06:34.615713: train_loss -0.5955 
2025-08-30 15:06:34.623787: val_loss -0.5216 
2025-08-30 15:06:34.632158: Pseudo dice [np.float32(0.7494)] 
2025-08-30 15:06:34.637463: Epoch time: 28.97 s 
2025-08-30 15:06:35.327200:  
2025-08-30 15:06:35.334516: Epoch 331 
2025-08-30 15:06:35.340634: Current learning rate: 0.0007 
2025-08-30 15:07:04.261900: train_loss -0.5416 
2025-08-30 15:07:04.261900: val_loss -0.5363 
2025-08-30 15:07:04.270225: Pseudo dice [np.float32(0.7422)] 
2025-08-30 15:07:04.274681: Epoch time: 28.94 s 
2025-08-30 15:07:04.974383:  
2025-08-30 15:07:04.982743: Epoch 332 
2025-08-30 15:07:04.994208: Current learning rate: 0.0007 
2025-08-30 15:07:33.565930: train_loss -0.5987 
2025-08-30 15:07:33.573845: val_loss -0.6142 
2025-08-30 15:07:33.578785: Pseudo dice [np.float32(0.7768)] 
2025-08-30 15:07:33.585384: Epoch time: 28.59 s 
2025-08-30 15:07:34.410136:  
2025-08-30 15:07:34.417379: Epoch 333 
2025-08-30 15:07:34.423549: Current learning rate: 0.00069 
2025-08-30 15:08:03.028292: train_loss -0.5733 
2025-08-30 15:08:03.036595: val_loss -0.4884 
2025-08-30 15:08:03.040712: Pseudo dice [np.float32(0.7464)] 
2025-08-30 15:08:03.049001: Epoch time: 28.62 s 
2025-08-30 15:08:03.719495:  
2025-08-30 15:08:03.726856: Epoch 334 
2025-08-30 15:08:03.731984: Current learning rate: 0.00069 
2025-08-30 15:08:32.832926: train_loss -0.5449 
2025-08-30 15:08:32.841273: val_loss -0.6422 
2025-08-30 15:08:32.849660: Pseudo dice [np.float32(0.824)] 
2025-08-30 15:08:32.855269: Epoch time: 29.12 s 
2025-08-30 15:08:33.553410:  
2025-08-30 15:08:33.563991: Epoch 335 
2025-08-30 15:08:33.572178: Current learning rate: 0.00069 
2025-08-30 15:09:01.953613: train_loss -0.561 
2025-08-30 15:09:01.958195: val_loss -0.5162 
2025-08-30 15:09:01.966572: Pseudo dice [np.float32(0.7696)] 
2025-08-30 15:09:01.971155: Epoch time: 28.4 s 
2025-08-30 15:09:02.679319:  
2025-08-30 15:09:02.686609: Epoch 336 
2025-08-30 15:09:02.692984: Current learning rate: 0.00069 
2025-08-30 15:09:30.991831: train_loss -0.5388 
2025-08-30 15:09:31.006434: val_loss -0.585 
2025-08-30 15:09:31.012791: Pseudo dice [np.float32(0.766)] 
2025-08-30 15:09:31.018977: Epoch time: 28.31 s 
2025-08-30 15:09:31.721815:  
2025-08-30 15:09:31.729528: Epoch 337 
2025-08-30 15:09:31.733957: Current learning rate: 0.00069 
2025-08-30 15:10:00.491207: train_loss -0.5492 
2025-08-30 15:10:00.499519: val_loss -0.5431 
2025-08-30 15:10:00.503695: Pseudo dice [np.float32(0.7028)] 
2025-08-30 15:10:00.512874: Epoch time: 28.77 s 
2025-08-30 15:10:01.184530:  
2025-08-30 15:10:01.191707: Epoch 338 
2025-08-30 15:10:01.198134: Current learning rate: 0.00069 
2025-08-30 15:10:30.217519: train_loss -0.5661 
2025-08-30 15:10:30.225393: val_loss -0.6087 
2025-08-30 15:10:30.233349: Pseudo dice [np.float32(0.796)] 
2025-08-30 15:10:30.238472: Epoch time: 29.04 s 
2025-08-30 15:10:30.925598:  
2025-08-30 15:10:30.932907: Epoch 339 
2025-08-30 15:10:30.940297: Current learning rate: 0.00069 
2025-08-30 15:10:59.387480: train_loss -0.5508 
2025-08-30 15:10:59.395780: val_loss -0.6589 
2025-08-30 15:10:59.404118: Pseudo dice [np.float32(0.8078)] 
2025-08-30 15:10:59.410030: Epoch time: 28.46 s 
2025-08-30 15:11:00.083822:  
2025-08-30 15:11:00.092170: Epoch 340 
2025-08-30 15:11:00.098461: Current learning rate: 0.00069 
2025-08-30 15:11:28.775524: train_loss -0.5675 
2025-08-30 15:11:28.783804: val_loss -0.5443 
2025-08-30 15:11:28.792131: Pseudo dice [np.float32(0.7039)] 
2025-08-30 15:11:28.797113: Epoch time: 28.69 s 
2025-08-30 15:11:29.503853:  
2025-08-30 15:11:29.514307: Epoch 341 
2025-08-30 15:11:29.522133: Current learning rate: 0.00069 
2025-08-30 15:11:58.513906: train_loss -0.5648 
2025-08-30 15:11:58.513906: val_loss -0.6427 
2025-08-30 15:11:58.521799: Pseudo dice [np.float32(0.7806)] 
2025-08-30 15:11:58.526432: Epoch time: 29.01 s 
2025-08-30 15:11:59.232543:  
2025-08-30 15:11:59.241775: Epoch 342 
2025-08-30 15:11:59.251425: Current learning rate: 0.00069 
2025-08-30 15:12:28.146747: train_loss -0.5661 
2025-08-30 15:12:28.155089: val_loss -0.575 
2025-08-30 15:12:28.159258: Pseudo dice [np.float32(0.7501)] 
2025-08-30 15:12:28.168497: Epoch time: 28.92 s 
2025-08-30 15:12:28.864043:  
2025-08-30 15:12:28.871403: Epoch 343 
2025-08-30 15:12:28.879703: Current learning rate: 0.00069 
2025-08-30 15:12:57.338693: train_loss -0.5653 
2025-08-30 15:12:57.347111: val_loss -0.5737 
2025-08-30 15:12:57.351279: Pseudo dice [np.float32(0.7645)] 
2025-08-30 15:12:57.358333: Epoch time: 28.48 s 
2025-08-30 15:12:58.078722:  
2025-08-30 15:12:58.087721: Epoch 344 
2025-08-30 15:12:58.095295: Current learning rate: 0.00068 
2025-08-30 15:13:27.172359: train_loss -0.5836 
2025-08-30 15:13:27.180983: val_loss -0.6057 
2025-08-30 15:13:27.184757: Pseudo dice [np.float32(0.7642)] 
2025-08-30 15:13:27.193119: Epoch time: 29.09 s 
2025-08-30 15:13:27.881212:  
2025-08-30 15:13:27.889503: Epoch 345 
2025-08-30 15:13:27.897961: Current learning rate: 0.00068 
2025-08-30 15:13:56.839399: train_loss -0.5661 
2025-08-30 15:13:56.847718: val_loss -0.6023 
2025-08-30 15:13:56.851896: Pseudo dice [np.float32(0.838)] 
2025-08-30 15:13:56.858279: Epoch time: 28.96 s 
2025-08-30 15:13:57.687050:  
2025-08-30 15:13:57.694873: Epoch 346 
2025-08-30 15:13:57.701346: Current learning rate: 0.00068 
2025-08-30 15:14:26.064717: train_loss -0.5962 
2025-08-30 15:14:26.073080: val_loss -0.5684 
2025-08-30 15:14:26.077158: Pseudo dice [np.float32(0.7846)] 
2025-08-30 15:14:26.086108: Epoch time: 28.38 s 
2025-08-30 15:14:26.782781:  
2025-08-30 15:14:26.792133: Epoch 347 
2025-08-30 15:14:26.802372: Current learning rate: 0.00068 
2025-08-30 15:14:55.723350: train_loss -0.5927 
2025-08-30 15:14:55.731435: val_loss -0.6357 
2025-08-30 15:14:55.735615: Pseudo dice [np.float32(0.7938)] 
2025-08-30 15:14:55.743114: Epoch time: 28.94 s 
2025-08-30 15:14:56.452857:  
2025-08-30 15:14:56.461226: Epoch 348 
2025-08-30 15:14:56.469320: Current learning rate: 0.00068 
2025-08-30 15:15:25.365445: train_loss -0.5481 
2025-08-30 15:15:25.373878: val_loss -0.5768 
2025-08-30 15:15:25.377965: Pseudo dice [np.float32(0.7076)] 
2025-08-30 15:15:25.385915: Epoch time: 28.92 s 
2025-08-30 15:15:26.069920:  
2025-08-30 15:15:26.077290: Epoch 349 
2025-08-30 15:15:26.084085: Current learning rate: 0.00068 
2025-08-30 15:15:54.865749: train_loss -0.5935 
2025-08-30 15:15:54.874132: val_loss -0.5668 
2025-08-30 15:15:54.878262: Pseudo dice [np.float32(0.7543)] 
2025-08-30 15:15:54.887066: Epoch time: 28.8 s 
2025-08-30 15:15:55.761039:  
2025-08-30 15:15:55.769356: Epoch 350 
2025-08-30 15:15:55.775682: Current learning rate: 0.00068 
2025-08-30 15:16:24.494894: train_loss -0.5345 
2025-08-30 15:16:24.494894: val_loss -0.5368 
2025-08-30 15:16:24.505949: Pseudo dice [np.float32(0.7677)] 
2025-08-30 15:16:24.512851: Epoch time: 28.73 s 
2025-08-30 15:16:25.213289:  
2025-08-30 15:16:25.221736: Epoch 351 
2025-08-30 15:16:25.228030: Current learning rate: 0.00068 
2025-08-30 15:16:54.608272: train_loss -0.5854 
2025-08-30 15:16:54.616659: val_loss -0.5885 
2025-08-30 15:16:54.620827: Pseudo dice [np.float32(0.7454)] 
2025-08-30 15:16:54.629190: Epoch time: 29.4 s 
2025-08-30 15:16:55.477877:  
2025-08-30 15:16:55.488248: Epoch 352 
2025-08-30 15:16:55.494590: Current learning rate: 0.00068 
2025-08-30 15:17:24.412989: train_loss -0.5792 
2025-08-30 15:17:24.425551: val_loss -0.6518 
2025-08-30 15:17:24.429718: Pseudo dice [np.float32(0.828)] 
2025-08-30 15:17:24.437058: Epoch time: 28.94 s 
2025-08-30 15:17:25.140867:  
2025-08-30 15:17:25.152087: Epoch 353 
2025-08-30 15:17:25.160276: Current learning rate: 0.00068 
2025-08-30 15:17:53.688703: train_loss -0.6044 
2025-08-30 15:17:53.696756: val_loss -0.5796 
2025-08-30 15:17:53.700959: Pseudo dice [np.float32(0.755)] 
2025-08-30 15:17:53.707052: Epoch time: 28.55 s 
2025-08-30 15:17:54.422084:  
2025-08-30 15:17:54.432340: Epoch 354 
2025-08-30 15:17:54.440356: Current learning rate: 0.00067 
2025-08-30 15:18:23.514007: train_loss -0.6007 
2025-08-30 15:18:23.526131: val_loss -0.55 
2025-08-30 15:18:23.530686: Pseudo dice [np.float32(0.7396)] 
2025-08-30 15:18:23.536695: Epoch time: 29.09 s 
2025-08-30 15:18:24.233045:  
2025-08-30 15:18:24.241433: Epoch 355 
2025-08-30 15:18:24.247537: Current learning rate: 0.00067 
2025-08-30 15:18:53.335065: train_loss -0.5813 
2025-08-30 15:18:53.343377: val_loss -0.5186 
2025-08-30 15:18:53.351718: Pseudo dice [np.float32(0.7367)] 
2025-08-30 15:18:53.357975: Epoch time: 29.1 s 
2025-08-30 15:18:54.064810:  
2025-08-30 15:18:54.076256: Epoch 356 
2025-08-30 15:18:54.083436: Current learning rate: 0.00067 
2025-08-30 15:19:23.331586: train_loss -0.5867 
2025-08-30 15:19:23.344126: val_loss -0.576 
2025-08-30 15:19:23.348294: Pseudo dice [np.float32(0.7452)] 
2025-08-30 15:19:23.356561: Epoch time: 29.27 s 
2025-08-30 15:19:24.048862:  
2025-08-30 15:19:24.057219: Epoch 357 
2025-08-30 15:19:24.065643: Current learning rate: 0.00067 
2025-08-30 15:19:52.586255: train_loss -0.5886 
2025-08-30 15:19:52.594439: val_loss -0.574 
2025-08-30 15:19:52.598673: Pseudo dice [np.float32(0.7728)] 
2025-08-30 15:19:52.605674: Epoch time: 28.54 s 
2025-08-30 15:19:53.298870:  
2025-08-30 15:19:53.306185: Epoch 358 
2025-08-30 15:19:53.311439: Current learning rate: 0.00067 
2025-08-30 15:20:22.265384: train_loss -0.5829 
2025-08-30 15:20:22.273723: val_loss -0.6646 
2025-08-30 15:20:22.282652: Pseudo dice [np.float32(0.787)] 
2025-08-30 15:20:22.288045: Epoch time: 28.97 s 
2025-08-30 15:20:23.123375:  
2025-08-30 15:20:23.131778: Epoch 359 
2025-08-30 15:20:23.138138: Current learning rate: 0.00067 
2025-08-30 15:20:51.895228: train_loss -0.5626 
2025-08-30 15:20:51.907411: val_loss -0.5964 
2025-08-30 15:20:51.911610: Pseudo dice [np.float32(0.7937)] 
2025-08-30 15:20:51.918837: Epoch time: 28.77 s 
2025-08-30 15:20:52.622717:  
2025-08-30 15:20:52.623716: Epoch 360 
2025-08-30 15:20:52.635218: Current learning rate: 0.00067 
2025-08-30 15:21:21.091101: train_loss -0.5848 
2025-08-30 15:21:21.091101: val_loss -0.5723 
2025-08-30 15:21:21.101049: Pseudo dice [np.float32(0.7944)] 
2025-08-30 15:21:21.107341: Epoch time: 28.47 s 
2025-08-30 15:21:21.809109:  
2025-08-30 15:21:21.819942: Epoch 361 
2025-08-30 15:21:21.827079: Current learning rate: 0.00067 
2025-08-30 15:21:50.562047: train_loss -0.5786 
2025-08-30 15:21:50.570459: val_loss -0.5784 
2025-08-30 15:21:50.574677: Pseudo dice [np.float32(0.7698)] 
2025-08-30 15:21:50.582518: Epoch time: 28.75 s 
2025-08-30 15:21:51.269721:  
2025-08-30 15:21:51.276962: Epoch 362 
2025-08-30 15:21:51.283171: Current learning rate: 0.00067 
2025-08-30 15:22:20.425260: train_loss -0.6079 
2025-08-30 15:22:20.433544: val_loss -0.5559 
2025-08-30 15:22:20.437748: Pseudo dice [np.float32(0.748)] 
2025-08-30 15:22:20.444627: Epoch time: 29.16 s 
2025-08-30 15:22:21.139108:  
2025-08-30 15:22:21.148450: Epoch 363 
2025-08-30 15:22:21.156721: Current learning rate: 0.00067 
2025-08-30 15:22:49.683177: train_loss -0.5577 
2025-08-30 15:22:49.691530: val_loss -0.6338 
2025-08-30 15:22:49.695675: Pseudo dice [np.float32(0.7773)] 
2025-08-30 15:22:49.703937: Epoch time: 28.55 s 
2025-08-30 15:22:50.415069:  
2025-08-30 15:22:50.424483: Epoch 364 
2025-08-30 15:22:50.431809: Current learning rate: 0.00067 
2025-08-30 15:23:18.821340: train_loss -0.5641 
2025-08-30 15:23:18.829242: val_loss -0.5767 
2025-08-30 15:23:18.833471: Pseudo dice [np.float32(0.8081)] 
2025-08-30 15:23:18.839443: Epoch time: 28.41 s 
2025-08-30 15:23:19.683863:  
2025-08-30 15:23:19.694564: Epoch 365 
2025-08-30 15:23:19.703362: Current learning rate: 0.00066 
2025-08-30 15:23:48.784217: train_loss -0.5718 
2025-08-30 15:23:48.792515: val_loss -0.6259 
2025-08-30 15:23:48.800491: Pseudo dice [np.float32(0.7972)] 
2025-08-30 15:23:48.806079: Epoch time: 29.1 s 
2025-08-30 15:23:49.485538:  
2025-08-30 15:23:49.493873: Epoch 366 
2025-08-30 15:23:49.501143: Current learning rate: 0.00066 
2025-08-30 15:24:18.313261: train_loss -0.5706 
2025-08-30 15:24:18.321593: val_loss -0.5628 
2025-08-30 15:24:18.325751: Pseudo dice [np.float32(0.802)] 
2025-08-30 15:24:18.333173: Epoch time: 28.83 s 
2025-08-30 15:24:18.338642: Yayy! New best EMA pseudo Dice: 0.7782999873161316 
2025-08-30 15:24:19.244379:  
2025-08-30 15:24:19.254660: Epoch 367 
2025-08-30 15:24:19.264239: Current learning rate: 0.00066 
2025-08-30 15:24:48.064229: train_loss -0.6232 
2025-08-30 15:24:48.076234: val_loss -0.6144 
2025-08-30 15:24:48.080774: Pseudo dice [np.float32(0.8253)] 
2025-08-30 15:24:48.086814: Epoch time: 28.82 s 
2025-08-30 15:24:48.091581: Yayy! New best EMA pseudo Dice: 0.7829999923706055 
2025-08-30 15:24:48.997859:  
2025-08-30 15:24:49.006222: Epoch 368 
2025-08-30 15:24:49.014298: Current learning rate: 0.00066 
2025-08-30 15:25:17.906315: train_loss -0.5834 
2025-08-30 15:25:17.914697: val_loss -0.5166 
2025-08-30 15:25:17.918868: Pseudo dice [np.float32(0.7649)] 
2025-08-30 15:25:17.924863: Epoch time: 28.91 s 
2025-08-30 15:25:18.648381:  
2025-08-30 15:25:18.657721: Epoch 369 
2025-08-30 15:25:18.663908: Current learning rate: 0.00066 
2025-08-30 15:25:48.074555: train_loss -0.5791 
2025-08-30 15:25:48.074555: val_loss -0.5675 
2025-08-30 15:25:48.082336: Pseudo dice [np.float32(0.7438)] 
2025-08-30 15:25:48.088319: Epoch time: 29.43 s 
2025-08-30 15:25:48.806442:  
2025-08-30 15:25:48.814441: Epoch 370 
2025-08-30 15:25:48.822133: Current learning rate: 0.00066 
2025-08-30 15:26:17.381937: train_loss -0.5557 
2025-08-30 15:26:17.390323: val_loss -0.6076 
2025-08-30 15:26:17.398645: Pseudo dice [np.float32(0.7777)] 
2025-08-30 15:26:17.404197: Epoch time: 28.58 s 
2025-08-30 15:26:18.249387:  
2025-08-30 15:26:18.258920: Epoch 371 
2025-08-30 15:26:18.267129: Current learning rate: 0.00066 
2025-08-30 15:26:47.036975: train_loss -0.5779 
2025-08-30 15:26:47.045270: val_loss -0.5923 
2025-08-30 15:26:47.053611: Pseudo dice [np.float32(0.7605)] 
2025-08-30 15:26:47.059553: Epoch time: 28.79 s 
2025-08-30 15:26:47.763250:  
2025-08-30 15:26:47.770490: Epoch 372 
2025-08-30 15:26:47.777848: Current learning rate: 0.00066 
2025-08-30 15:27:16.904268: train_loss -0.5965 
2025-08-30 15:27:16.912512: val_loss -0.5717 
2025-08-30 15:27:16.916704: Pseudo dice [np.float32(0.8003)] 
2025-08-30 15:27:16.923629: Epoch time: 29.14 s 
2025-08-30 15:27:17.622211:  
2025-08-30 15:27:17.631623: Epoch 373 
2025-08-30 15:27:17.640723: Current learning rate: 0.00066 
2025-08-30 15:27:46.575385: train_loss -0.5591 
2025-08-30 15:27:46.583765: val_loss -0.6358 
2025-08-30 15:27:46.587957: Pseudo dice [np.float32(0.7696)] 
2025-08-30 15:27:46.595819: Epoch time: 28.96 s 
2025-08-30 15:27:47.296843:  
2025-08-30 15:27:47.306803: Epoch 374 
2025-08-30 15:27:47.313738: Current learning rate: 0.00066 
2025-08-30 15:28:15.808726: train_loss -0.6178 
2025-08-30 15:28:15.817083: val_loss -0.5699 
2025-08-30 15:28:15.821189: Pseudo dice [np.float32(0.7795)] 
2025-08-30 15:28:15.828063: Epoch time: 28.51 s 
2025-08-30 15:28:16.574701:  
2025-08-30 15:28:16.584721: Epoch 375 
2025-08-30 15:28:16.591424: Current learning rate: 0.00066 
2025-08-30 15:28:45.204679: train_loss -0.5875 
2025-08-30 15:28:45.213067: val_loss -0.5758 
2025-08-30 15:28:45.217160: Pseudo dice [np.float32(0.7806)] 
2025-08-30 15:28:45.225194: Epoch time: 28.63 s 
2025-08-30 15:28:45.932083:  
2025-08-30 15:28:45.941942: Epoch 376 
2025-08-30 15:28:45.950767: Current learning rate: 0.00065 
2025-08-30 15:29:15.084187: train_loss -0.538 
2025-08-30 15:29:15.092904: val_loss -0.6257 
2025-08-30 15:29:15.097103: Pseudo dice [np.float32(0.8108)] 
2025-08-30 15:29:15.105903: Epoch time: 29.16 s 
2025-08-30 15:29:15.817063:  
2025-08-30 15:29:15.826490: Epoch 377 
2025-08-30 15:29:15.835650: Current learning rate: 0.00065 
2025-08-30 15:29:44.180161: train_loss -0.5661 
2025-08-30 15:29:44.192348: val_loss -0.5943 
2025-08-30 15:29:44.197607: Pseudo dice [np.float32(0.7732)] 
2025-08-30 15:29:44.203508: Epoch time: 28.36 s 
2025-08-30 15:29:45.071065:  
2025-08-30 15:29:45.085572: Epoch 378 
2025-08-30 15:29:45.094440: Current learning rate: 0.00065 
2025-08-30 15:30:13.863585: train_loss -0.5468 
2025-08-30 15:30:13.863585: val_loss -0.5465 
2025-08-30 15:30:13.873540: Pseudo dice [np.float32(0.7593)] 
2025-08-30 15:30:13.880231: Epoch time: 28.79 s 
2025-08-30 15:30:14.568308:  
2025-08-30 15:30:14.578132: Epoch 379 
2025-08-30 15:30:14.586124: Current learning rate: 0.00065 
2025-08-30 15:30:43.072236: train_loss -0.595 
2025-08-30 15:30:43.080596: val_loss -0.5579 
2025-08-30 15:30:43.084693: Pseudo dice [np.float32(0.7196)] 
2025-08-30 15:30:43.092751: Epoch time: 28.51 s 
2025-08-30 15:30:43.784903:  
2025-08-30 15:30:43.793347: Epoch 380 
2025-08-30 15:30:43.800033: Current learning rate: 0.00065 
2025-08-30 15:31:12.626346: train_loss -0.6094 
2025-08-30 15:31:12.634726: val_loss -0.6923 
2025-08-30 15:31:12.638849: Pseudo dice [np.float32(0.8179)] 
2025-08-30 15:31:12.647205: Epoch time: 28.84 s 
2025-08-30 15:31:13.329149:  
2025-08-30 15:31:13.337417: Epoch 381 
2025-08-30 15:31:13.345622: Current learning rate: 0.00065 
2025-08-30 15:31:41.735191: train_loss -0.5709 
2025-08-30 15:31:41.743297: val_loss -0.5445 
2025-08-30 15:31:41.751627: Pseudo dice [np.float32(0.7439)] 
2025-08-30 15:31:41.757458: Epoch time: 28.41 s 
2025-08-30 15:31:42.459177:  
2025-08-30 15:31:42.467531: Epoch 382 
2025-08-30 15:31:42.472602: Current learning rate: 0.00065 
2025-08-30 15:32:11.414120: train_loss -0.5807 
2025-08-30 15:32:11.422504: val_loss -0.6505 
2025-08-30 15:32:11.426626: Pseudo dice [np.float32(0.8194)] 
2025-08-30 15:32:11.436085: Epoch time: 28.96 s 
2025-08-30 15:32:12.120098:  
2025-08-30 15:32:12.127173: Epoch 383 
2025-08-30 15:32:12.134128: Current learning rate: 0.00065 
2025-08-30 15:32:40.931620: train_loss -0.6031 
2025-08-30 15:32:40.939790: val_loss -0.5905 
2025-08-30 15:32:40.943935: Pseudo dice [np.float32(0.7698)] 
2025-08-30 15:32:40.952788: Epoch time: 28.81 s 
2025-08-30 15:32:41.802644:  
2025-08-30 15:32:41.812534: Epoch 384 
2025-08-30 15:32:41.819976: Current learning rate: 0.00065 
2025-08-30 15:33:10.018839: train_loss -0.5453 
2025-08-30 15:33:10.026784: val_loss -0.6143 
2025-08-30 15:33:10.030919: Pseudo dice [np.float32(0.7603)] 
2025-08-30 15:33:10.039211: Epoch time: 28.22 s 
2025-08-30 15:33:10.773185:  
2025-08-30 15:33:10.780603: Epoch 385 
2025-08-30 15:33:10.786873: Current learning rate: 0.00065 
2025-08-30 15:33:39.632208: train_loss -0.5454 
2025-08-30 15:33:39.640020: val_loss -0.5599 
2025-08-30 15:33:39.647969: Pseudo dice [np.float32(0.7755)] 
2025-08-30 15:33:39.653472: Epoch time: 28.86 s 
2025-08-30 15:33:40.343365:  
2025-08-30 15:33:40.350636: Epoch 386 
2025-08-30 15:33:40.356905: Current learning rate: 0.00064 
2025-08-30 15:34:08.897997: train_loss -0.5585 
2025-08-30 15:34:08.906325: val_loss -0.5593 
2025-08-30 15:34:08.915204: Pseudo dice [np.float32(0.8071)] 
2025-08-30 15:34:08.920499: Epoch time: 28.56 s 
2025-08-30 15:34:09.615172:  
2025-08-30 15:34:09.624657: Epoch 387 
2025-08-30 15:34:09.633303: Current learning rate: 0.00064 
2025-08-30 15:34:39.117104: train_loss -0.5904 
2025-08-30 15:34:39.124320: val_loss -0.5869 
2025-08-30 15:34:39.128426: Pseudo dice [np.float32(0.7724)] 
2025-08-30 15:34:39.136528: Epoch time: 29.5 s 
2025-08-30 15:34:39.850760:  
2025-08-30 15:34:39.861392: Epoch 388 
2025-08-30 15:34:39.866777: Current learning rate: 0.00064 
2025-08-30 15:35:08.461809: train_loss -0.5582 
2025-08-30 15:35:08.461809: val_loss -0.5915 
2025-08-30 15:35:08.471537: Pseudo dice [np.float32(0.7337)] 
2025-08-30 15:35:08.478167: Epoch time: 28.61 s 
2025-08-30 15:35:09.175732:  
2025-08-30 15:35:09.184103: Epoch 389 
2025-08-30 15:35:09.190329: Current learning rate: 0.00064 
2025-08-30 15:35:38.212359: train_loss -0.5663 
2025-08-30 15:35:38.220793: val_loss -0.5567 
2025-08-30 15:35:38.228736: Pseudo dice [np.float32(0.7856)] 
2025-08-30 15:35:38.234635: Epoch time: 29.04 s 
2025-08-30 15:35:39.100369:  
2025-08-30 15:35:39.107563: Epoch 390 
2025-08-30 15:35:39.115563: Current learning rate: 0.00064 
2025-08-30 15:36:07.908973: train_loss -0.5953 
2025-08-30 15:36:07.917047: val_loss -0.5936 
2025-08-30 15:36:07.921196: Pseudo dice [np.float32(0.7796)] 
2025-08-30 15:36:07.928882: Epoch time: 28.81 s 
2025-08-30 15:36:08.651786:  
2025-08-30 15:36:08.658969: Epoch 391 
2025-08-30 15:36:08.666247: Current learning rate: 0.00064 
2025-08-30 15:36:37.231294: train_loss -0.5884 
2025-08-30 15:36:37.237944: val_loss -0.6198 
2025-08-30 15:36:37.246679: Pseudo dice [np.float32(0.8076)] 
2025-08-30 15:36:37.251532: Epoch time: 28.58 s 
2025-08-30 15:36:37.935067:  
2025-08-30 15:36:37.943490: Epoch 392 
2025-08-30 15:36:37.951762: Current learning rate: 0.00064 
2025-08-30 15:37:06.529227: train_loss -0.5897 
2025-08-30 15:37:06.537578: val_loss -0.5997 
2025-08-30 15:37:06.541762: Pseudo dice [np.float32(0.7728)] 
2025-08-30 15:37:06.548181: Epoch time: 28.6 s 
2025-08-30 15:37:07.258983:  
2025-08-30 15:37:07.269593: Epoch 393 
2025-08-30 15:37:07.281024: Current learning rate: 0.00064 
2025-08-30 15:37:36.296726: train_loss -0.5802 
2025-08-30 15:37:36.304770: val_loss -0.5699 
2025-08-30 15:37:36.308944: Pseudo dice [np.float32(0.7038)] 
2025-08-30 15:37:36.317144: Epoch time: 29.04 s 
2025-08-30 15:37:37.031594:  
2025-08-30 15:37:37.041777: Epoch 394 
2025-08-30 15:37:37.050536: Current learning rate: 0.00064 
2025-08-30 15:38:06.130728: train_loss -0.598 
2025-08-30 15:38:06.139079: val_loss -0.5716 
2025-08-30 15:38:06.147476: Pseudo dice [np.float32(0.7645)] 
2025-08-30 15:38:06.152948: Epoch time: 29.1 s 
2025-08-30 15:38:06.846592:  
2025-08-30 15:38:06.854931: Epoch 395 
2025-08-30 15:38:06.862368: Current learning rate: 0.00064 
2025-08-30 15:38:35.192674: train_loss -0.5576 
2025-08-30 15:38:35.201010: val_loss -0.5873 
2025-08-30 15:38:35.209350: Pseudo dice [np.float32(0.7867)] 
2025-08-30 15:38:35.214306: Epoch time: 28.35 s 
2025-08-30 15:38:36.073810:  
2025-08-30 15:38:36.084140: Epoch 396 
2025-08-30 15:38:36.093534: Current learning rate: 0.00064 
2025-08-30 15:39:05.068670: train_loss -0.5533 
2025-08-30 15:39:05.077024: val_loss -0.5911 
2025-08-30 15:39:05.081199: Pseudo dice [np.float32(0.8068)] 
2025-08-30 15:39:05.088986: Epoch time: 29.0 s 
2025-08-30 15:39:05.790907:  
2025-08-30 15:39:05.802322: Epoch 397 
2025-08-30 15:39:05.809239: Current learning rate: 0.00063 
2025-08-30 15:39:34.618923: train_loss -0.5988 
2025-08-30 15:39:34.618923: val_loss -0.5532 
2025-08-30 15:39:34.629632: Pseudo dice [np.float32(0.7656)] 
2025-08-30 15:39:34.636595: Epoch time: 28.83 s 
2025-08-30 15:39:35.350541:  
2025-08-30 15:39:35.360709: Epoch 398 
2025-08-30 15:39:35.367717: Current learning rate: 0.00063 
2025-08-30 15:40:03.689631: train_loss -0.5914 
2025-08-30 15:40:03.697952: val_loss -0.5991 
2025-08-30 15:40:03.702148: Pseudo dice [np.float32(0.7998)] 
2025-08-30 15:40:03.708065: Epoch time: 28.34 s 
2025-08-30 15:40:04.436945:  
2025-08-30 15:40:04.447002: Epoch 399 
2025-08-30 15:40:04.454209: Current learning rate: 0.00063 
2025-08-30 15:40:32.647877: train_loss -0.5688 
2025-08-30 15:40:32.655953: val_loss -0.5854 
2025-08-30 15:40:32.660099: Pseudo dice [np.float32(0.7886)] 
2025-08-30 15:40:32.666815: Epoch time: 28.21 s 
2025-08-30 15:40:33.524252:  
2025-08-30 15:40:33.531314: Epoch 400 
2025-08-30 15:40:33.536668: Current learning rate: 0.00063 
2025-08-30 15:40:57.526397: train_loss -0.5606 
2025-08-30 15:40:57.526397: val_loss -0.5661 
2025-08-30 15:40:57.536216: Pseudo dice [np.float32(0.7701)] 
2025-08-30 15:40:57.540901: Epoch time: 24.0 s 
2025-08-30 15:40:58.181079:  
2025-08-30 15:40:58.185546: Epoch 401 
2025-08-30 15:40:58.193588: Current learning rate: 0.00063 
2025-08-30 15:41:21.667369: train_loss -0.5719 
2025-08-30 15:41:21.675723: val_loss -0.6228 
2025-08-30 15:41:21.684030: Pseudo dice [np.float32(0.7793)] 
2025-08-30 15:41:21.688665: Epoch time: 23.49 s 
2025-08-30 15:41:22.497327:  
2025-08-30 15:41:22.505670: Epoch 402 
2025-08-30 15:41:22.509849: Current learning rate: 0.00063 
2025-08-30 15:41:45.787186: train_loss -0.5725 
2025-08-30 15:41:45.799373: val_loss -0.5395 
2025-08-30 15:41:45.803932: Pseudo dice [np.float32(0.7943)] 
2025-08-30 15:41:45.810854: Epoch time: 23.29 s 
2025-08-30 15:41:46.437861:  
2025-08-30 15:41:46.446195: Epoch 403 
2025-08-30 15:41:46.450357: Current learning rate: 0.00063 
2025-08-30 15:42:09.602694: train_loss -0.5983 
2025-08-30 15:42:09.610965: val_loss -0.6188 
2025-08-30 15:42:09.619377: Pseudo dice [np.float32(0.7835)] 
2025-08-30 15:42:09.624009: Epoch time: 23.16 s 
2025-08-30 15:42:10.257107:  
2025-08-30 15:42:10.265453: Epoch 404 
2025-08-30 15:42:10.274327: Current learning rate: 0.00063 
2025-08-30 15:42:33.371883: train_loss -0.5661 
2025-08-30 15:42:33.380539: val_loss -0.552 
2025-08-30 15:42:33.384716: Pseudo dice [np.float32(0.8019)] 
2025-08-30 15:42:33.391686: Epoch time: 23.11 s 
2025-08-30 15:42:34.018292:  
2025-08-30 15:42:34.026649: Epoch 405 
2025-08-30 15:42:34.030816: Current learning rate: 0.00063 
2025-08-30 15:42:57.291876: train_loss -0.5855 
2025-08-30 15:42:57.300211: val_loss -0.5672 
2025-08-30 15:42:57.308186: Pseudo dice [np.float32(0.736)] 
2025-08-30 15:42:57.313330: Epoch time: 23.27 s 
2025-08-30 15:42:57.950505:  
2025-08-30 15:42:57.959150: Epoch 406 
2025-08-30 15:42:57.967716: Current learning rate: 0.00063 
2025-08-30 15:43:21.153181: train_loss -0.5601 
2025-08-30 15:43:21.161506: val_loss -0.5616 
2025-08-30 15:43:21.169483: Pseudo dice [np.float32(0.808)] 
2025-08-30 15:43:21.174942: Epoch time: 23.2 s 
2025-08-30 15:43:21.816322:  
2025-08-30 15:43:21.824670: Epoch 407 
2025-08-30 15:43:21.828820: Current learning rate: 0.00062 
2025-08-30 15:43:44.909816: train_loss -0.5752 
2025-08-30 15:43:44.922338: val_loss -0.6324 
2025-08-30 15:43:44.926517: Pseudo dice [np.float32(0.7615)] 
2025-08-30 15:43:44.932026: Epoch time: 23.09 s 
2025-08-30 15:43:45.560812:  
2025-08-30 15:43:45.569200: Epoch 408 
2025-08-30 15:43:45.577513: Current learning rate: 0.00062 
2025-08-30 15:44:11.490506: train_loss -0.5675 
2025-08-30 15:44:11.490506: val_loss -0.6378 
2025-08-30 15:44:11.498833: Pseudo dice [np.float32(0.8068)] 
2025-08-30 15:44:11.504847: Epoch time: 25.93 s 
2025-08-30 15:44:12.141464:  
2025-08-30 15:44:12.149850: Epoch 409 
2025-08-30 15:44:12.154000: Current learning rate: 0.00062 
2025-08-30 15:44:38.184881: train_loss -0.5794 
2025-08-30 15:44:38.192481: val_loss -0.6779 
2025-08-30 15:44:38.196645: Pseudo dice [np.float32(0.8385)] 
2025-08-30 15:44:38.203487: Epoch time: 26.04 s 
2025-08-30 15:44:38.209389: Yayy! New best EMA pseudo Dice: 0.786899983882904 
2025-08-30 15:44:39.042965:  
2025-08-30 15:44:39.047158: Epoch 410 
2025-08-30 15:44:39.055501: Current learning rate: 0.00062 
2025-08-30 15:45:03.913607: train_loss -0.6424 
2025-08-30 15:45:03.921962: val_loss -0.5934 
2025-08-30 15:45:03.926131: Pseudo dice [np.float32(0.8211)] 
2025-08-30 15:45:03.935385: Epoch time: 24.87 s 
2025-08-30 15:45:03.941104: Yayy! New best EMA pseudo Dice: 0.7904000282287598 
2025-08-30 15:45:04.760239:  
2025-08-30 15:45:04.768312: Epoch 411 
2025-08-30 15:45:04.774833: Current learning rate: 0.00062 
2025-08-30 15:45:30.524085: train_loss -0.602 
2025-08-30 15:45:30.532932: val_loss -0.5389 
2025-08-30 15:45:30.537407: Pseudo dice [np.float32(0.7321)] 
2025-08-30 15:45:30.544107: Epoch time: 25.77 s 
2025-08-30 15:45:31.186172:  
2025-08-30 15:45:31.193831: Epoch 412 
2025-08-30 15:45:31.200154: Current learning rate: 0.00062 
2025-08-30 15:45:56.962723: train_loss -0.6056 
2025-08-30 15:45:56.971078: val_loss -0.6007 
2025-08-30 15:45:56.975271: Pseudo dice [np.float32(0.7524)] 
2025-08-30 15:45:56.983127: Epoch time: 25.78 s 
2025-08-30 15:45:57.584240:  
2025-08-30 15:45:57.592615: Epoch 413 
2025-08-30 15:45:57.600972: Current learning rate: 0.00062 
2025-08-30 15:46:23.539254: train_loss -0.5939 
2025-08-30 15:46:23.554375: val_loss -0.6021 
2025-08-30 15:46:23.565907: Pseudo dice [np.float32(0.8093)] 
2025-08-30 15:46:23.574231: Epoch time: 25.96 s 
2025-08-30 15:46:24.227462:  
2025-08-30 15:46:24.235861: Epoch 414 
2025-08-30 15:46:24.243749: Current learning rate: 0.00062 
2025-08-30 15:46:49.857137: train_loss -0.5822 
2025-08-30 15:46:49.865522: val_loss -0.502 
2025-08-30 15:46:49.873940: Pseudo dice [np.float32(0.7293)] 
2025-08-30 15:46:49.879708: Epoch time: 25.63 s 
2025-08-30 15:46:50.499566:  
2025-08-30 15:46:50.507871: Epoch 415 
2025-08-30 15:46:50.512028: Current learning rate: 0.00062 
2025-08-30 15:47:16.228901: train_loss -0.6147 
2025-08-30 15:47:16.233499: val_loss -0.5623 
2025-08-30 15:47:16.241858: Pseudo dice [np.float32(0.8052)] 
2025-08-30 15:47:16.247999: Epoch time: 25.73 s 
2025-08-30 15:47:16.863244:  
2025-08-30 15:47:16.871232: Epoch 416 
2025-08-30 15:47:16.875843: Current learning rate: 0.00062 
2025-08-30 15:47:43.310660: train_loss -0.5828 
2025-08-30 15:47:43.318878: val_loss -0.5377 
2025-08-30 15:47:43.326785: Pseudo dice [np.float32(0.722)] 
2025-08-30 15:47:43.331850: Epoch time: 26.45 s 
2025-08-30 15:47:43.948662:  
2025-08-30 15:47:43.957042: Epoch 417 
2025-08-30 15:47:43.961246: Current learning rate: 0.00062 
2025-08-30 15:48:09.645085: train_loss -0.5856 
2025-08-30 15:48:09.653472: val_loss -0.5551 
2025-08-30 15:48:09.657628: Pseudo dice [np.float32(0.7662)] 
2025-08-30 15:48:09.665434: Epoch time: 25.7 s 
2025-08-30 15:48:10.278625:  
2025-08-30 15:48:10.286975: Epoch 418 
2025-08-30 15:48:10.291560: Current learning rate: 0.00061 
2025-08-30 15:48:35.746391: train_loss -0.5789 
2025-08-30 15:48:35.754507: val_loss -0.5468 
2025-08-30 15:48:35.762409: Pseudo dice [np.float32(0.7465)] 
2025-08-30 15:48:35.767525: Epoch time: 25.47 s 
2025-08-30 15:48:36.384218:  
2025-08-30 15:48:36.392543: Epoch 419 
2025-08-30 15:48:36.396731: Current learning rate: 0.00061 
2025-08-30 15:49:01.771986: train_loss -0.5774 
2025-08-30 15:49:01.771986: val_loss -0.5762 
2025-08-30 15:49:01.782652: Pseudo dice [np.float32(0.7774)] 
2025-08-30 15:49:01.788301: Epoch time: 25.39 s 
2025-08-30 15:49:02.438974:  
2025-08-30 15:49:02.443653: Epoch 420 
2025-08-30 15:49:02.447690: Current learning rate: 0.00061 
2025-08-30 15:49:27.893929: train_loss -0.5951 
2025-08-30 15:49:27.906470: val_loss -0.5732 
2025-08-30 15:49:27.910644: Pseudo dice [np.float32(0.7328)] 
2025-08-30 15:49:27.917534: Epoch time: 25.46 s 
2025-08-30 15:49:28.678065:  
2025-08-30 15:49:28.686465: Epoch 421 
2025-08-30 15:49:28.690632: Current learning rate: 0.00061 
2025-08-30 15:49:57.623756: train_loss -0.562 
2025-08-30 15:49:57.632076: val_loss -0.5749 
2025-08-30 15:49:57.636246: Pseudo dice [np.float32(0.7837)] 
2025-08-30 15:49:57.643276: Epoch time: 28.95 s 
2025-08-30 15:49:58.286388:  
2025-08-30 15:49:58.290955: Epoch 422 
2025-08-30 15:49:58.299466: Current learning rate: 0.00061 
2025-08-30 15:50:26.665241: train_loss -0.5652 
2025-08-30 15:50:26.677685: val_loss -0.6179 
2025-08-30 15:50:26.681914: Pseudo dice [np.float32(0.8346)] 
2025-08-30 15:50:26.688912: Epoch time: 28.38 s 
2025-08-30 15:50:27.336698:  
2025-08-30 15:50:27.344510: Epoch 423 
2025-08-30 15:50:27.349160: Current learning rate: 0.00061 
2025-08-30 15:50:56.348955: train_loss -0.5763 
2025-08-30 15:50:56.357245: val_loss -0.6577 
2025-08-30 15:50:56.361498: Pseudo dice [np.float32(0.801)] 
2025-08-30 15:50:56.369479: Epoch time: 29.02 s 
2025-08-30 15:50:57.007827:  
2025-08-30 15:50:57.016185: Epoch 424 
2025-08-30 15:50:57.024606: Current learning rate: 0.00061 
2025-08-30 15:51:25.628094: train_loss -0.5637 
2025-08-30 15:51:25.640580: val_loss -0.5842 
2025-08-30 15:51:25.644781: Pseudo dice [np.float32(0.7692)] 
2025-08-30 15:51:25.650902: Epoch time: 28.62 s 
2025-08-30 15:51:26.295491:  
2025-08-30 15:51:26.303869: Epoch 425 
2025-08-30 15:51:26.308012: Current learning rate: 0.00061 
2025-08-30 15:51:55.174369: train_loss -0.5408 
2025-08-30 15:51:55.182637: val_loss -0.5993 
2025-08-30 15:51:55.190466: Pseudo dice [np.float32(0.7837)] 
2025-08-30 15:51:55.195699: Epoch time: 28.88 s 
2025-08-30 15:51:55.841491:  
2025-08-30 15:51:55.849876: Epoch 426 
2025-08-30 15:51:55.854036: Current learning rate: 0.00061 
2025-08-30 15:52:25.358562: train_loss -0.5941 
2025-08-30 15:52:25.369491: val_loss -0.589 
2025-08-30 15:52:25.375582: Pseudo dice [np.float32(0.8091)] 
2025-08-30 15:52:25.381252: Epoch time: 29.52 s 
2025-08-30 15:52:26.130200:  
2025-08-30 15:52:26.138001: Epoch 427 
2025-08-30 15:52:26.142799: Current learning rate: 0.00061 
2025-08-30 15:52:54.508950: train_loss -0.6023 
2025-08-30 15:52:54.516690: val_loss -0.5571 
2025-08-30 15:52:54.520824: Pseudo dice [np.float32(0.7733)] 
2025-08-30 15:52:54.527956: Epoch time: 28.38 s 
2025-08-30 15:52:55.325887:  
2025-08-30 15:52:55.333757: Epoch 428 
2025-08-30 15:52:55.338446: Current learning rate: 0.0006 
2025-08-30 15:53:24.751059: train_loss -0.582 
2025-08-30 15:53:24.763563: val_loss -0.5093 
2025-08-30 15:53:24.767788: Pseudo dice [np.float32(0.713)] 
2025-08-30 15:53:24.773820: Epoch time: 29.43 s 
2025-08-30 15:53:25.443443:  
2025-08-30 15:53:25.443443: Epoch 429 
2025-08-30 15:53:25.451728: Current learning rate: 0.0006 
2025-08-30 15:53:53.913561: train_loss -0.5803 
2025-08-30 15:53:53.917141: val_loss -0.6247 
2025-08-30 15:53:53.921873: Pseudo dice [np.float32(0.8538)] 
2025-08-30 15:53:53.930752: Epoch time: 28.47 s 
2025-08-30 15:53:54.584898:  
2025-08-30 15:53:54.593320: Epoch 430 
2025-08-30 15:53:54.597441: Current learning rate: 0.0006 
2025-08-30 15:54:23.485266: train_loss -0.6202 
2025-08-30 15:54:23.492921: val_loss -0.5804 
2025-08-30 15:54:23.500848: Pseudo dice [np.float32(0.7675)] 
2025-08-30 15:54:23.505961: Epoch time: 28.9 s 
2025-08-30 15:54:24.147796:  
2025-08-30 15:54:24.156284: Epoch 431 
2025-08-30 15:54:24.164021: Current learning rate: 0.0006 
2025-08-30 15:54:53.130724: train_loss -0.6107 
2025-08-30 15:54:53.139211: val_loss -0.5545 
2025-08-30 15:54:53.143348: Pseudo dice [np.float32(0.7649)] 
2025-08-30 15:54:53.150359: Epoch time: 28.98 s 
2025-08-30 15:54:53.789851:  
2025-08-30 15:54:53.798271: Epoch 432 
2025-08-30 15:54:53.802415: Current learning rate: 0.0006 
2025-08-30 15:55:21.308873: train_loss -0.5877 
2025-08-30 15:55:21.317367: val_loss -0.5327 
2025-08-30 15:55:21.321436: Pseudo dice [np.float32(0.7525)] 
2025-08-30 15:55:21.330379: Epoch time: 27.52 s 
2025-08-30 15:55:21.980379:  
2025-08-30 15:55:21.988771: Epoch 433 
2025-08-30 15:55:21.992927: Current learning rate: 0.0006 
2025-08-30 15:55:50.392143: train_loss -0.5901 
2025-08-30 15:55:50.404145: val_loss -0.5415 
2025-08-30 15:55:50.408868: Pseudo dice [np.float32(0.7702)] 
2025-08-30 15:55:50.415947: Epoch time: 28.41 s 
2025-08-30 15:55:51.080201:  
2025-08-30 15:55:51.088177: Epoch 434 
2025-08-30 15:55:51.092753: Current learning rate: 0.0006 
2025-08-30 15:56:17.690059: train_loss -0.5865 
2025-08-30 15:56:17.698500: val_loss -0.5756 
2025-08-30 15:56:17.706860: Pseudo dice [np.float32(0.7528)] 
2025-08-30 15:56:17.712670: Epoch time: 26.61 s 
2025-08-30 15:56:18.474161:  
2025-08-30 15:56:18.482493: Epoch 435 
2025-08-30 15:56:18.486657: Current learning rate: 0.0006 
2025-08-30 15:56:43.319800: train_loss -0.581 
2025-08-30 15:56:43.328196: val_loss -0.5417 
2025-08-30 15:56:43.336075: Pseudo dice [np.float32(0.779)] 
2025-08-30 15:56:43.341229: Epoch time: 24.85 s 
2025-08-30 15:56:43.949639:  
2025-08-30 15:56:43.958014: Epoch 436 
2025-08-30 15:56:43.962146: Current learning rate: 0.0006 
2025-08-30 15:57:08.929059: train_loss -0.5674 
2025-08-30 15:57:08.936960: val_loss -0.5276 
2025-08-30 15:57:08.941163: Pseudo dice [np.float32(0.7127)] 
2025-08-30 15:57:08.948151: Epoch time: 24.98 s 
2025-08-30 15:57:09.562680:  
2025-08-30 15:57:09.571027: Epoch 437 
2025-08-30 15:57:09.575197: Current learning rate: 0.0006 
2025-08-30 15:57:34.308172: train_loss -0.5969 
2025-08-30 15:57:34.316556: val_loss -0.6369 
2025-08-30 15:57:34.324422: Pseudo dice [np.float32(0.7459)] 
2025-08-30 15:57:34.329563: Epoch time: 24.75 s 
2025-08-30 15:57:34.950488:  
2025-08-30 15:57:34.958844: Epoch 438 
2025-08-30 15:57:34.963011: Current learning rate: 0.0006 
2025-08-30 15:58:00.288158: train_loss -0.5736 
2025-08-30 15:58:00.296609: val_loss -0.5313 
2025-08-30 15:58:00.304487: Pseudo dice [np.float32(0.7487)] 
2025-08-30 15:58:00.309525: Epoch time: 25.34 s 
2025-08-30 15:58:00.951988:  
2025-08-30 15:58:00.961315: Epoch 439 
2025-08-30 15:58:00.969994: Current learning rate: 0.00059 
2025-08-30 15:58:25.671786: train_loss -0.5871 
2025-08-30 15:58:25.671786: val_loss -0.7028 
2025-08-30 15:58:25.681424: Pseudo dice [np.float32(0.8221)] 
2025-08-30 15:58:25.688115: Epoch time: 24.72 s 
2025-08-30 15:58:26.289189:  
2025-08-30 15:58:26.297525: Epoch 440 
2025-08-30 15:58:26.305967: Current learning rate: 0.00059 
2025-08-30 15:58:51.088801: train_loss -0.609 
2025-08-30 15:58:51.097409: val_loss -0.532 
2025-08-30 15:58:51.105728: Pseudo dice [np.float32(0.7601)] 
2025-08-30 15:58:51.111461: Epoch time: 24.8 s 
2025-08-30 15:58:51.868987:  
2025-08-30 15:58:51.877247: Epoch 441 
2025-08-30 15:58:51.881375: Current learning rate: 0.00059 
2025-08-30 15:59:17.118571: train_loss -0.599 
2025-08-30 15:59:17.123123: val_loss -0.5448 
2025-08-30 15:59:17.131537: Pseudo dice [np.float32(0.8099)] 
2025-08-30 15:59:17.136644: Epoch time: 25.25 s 
2025-08-30 15:59:17.786337:  
2025-08-30 15:59:17.794706: Epoch 442 
2025-08-30 15:59:17.798877: Current learning rate: 0.00059 
2025-08-30 15:59:42.453074: train_loss -0.5743 
2025-08-30 15:59:42.460884: val_loss -0.5681 
2025-08-30 15:59:42.469249: Pseudo dice [np.float32(0.7931)] 
2025-08-30 15:59:42.474739: Epoch time: 24.67 s 
2025-08-30 15:59:43.082429:  
2025-08-30 15:59:43.090783: Epoch 443 
2025-08-30 15:59:43.095055: Current learning rate: 0.00059 
2025-08-30 16:00:07.965526: train_loss -0.5659 
2025-08-30 16:00:07.973915: val_loss -0.5834 
2025-08-30 16:00:07.982317: Pseudo dice [np.float32(0.7896)] 
2025-08-30 16:00:07.988143: Epoch time: 24.88 s 
2025-08-30 16:00:08.582864:  
2025-08-30 16:00:08.591196: Epoch 444 
2025-08-30 16:00:08.599614: Current learning rate: 0.00059 
2025-08-30 16:00:35.872663: train_loss -0.5807 
2025-08-30 16:00:35.885231: val_loss -0.5466 
2025-08-30 16:00:35.889320: Pseudo dice [np.float32(0.75)] 
2025-08-30 16:00:35.896627: Epoch time: 27.29 s 
2025-08-30 16:00:36.539843:  
2025-08-30 16:00:36.548277: Epoch 445 
2025-08-30 16:00:36.552434: Current learning rate: 0.00059 
2025-08-30 16:01:03.988131: train_loss -0.5946 
2025-08-30 16:01:03.996473: val_loss -0.5574 
2025-08-30 16:01:04.004349: Pseudo dice [np.float32(0.8335)] 
2025-08-30 16:01:04.009520: Epoch time: 27.45 s 
2025-08-30 16:01:04.639085:  
2025-08-30 16:01:04.647233: Epoch 446 
2025-08-30 16:01:04.651344: Current learning rate: 0.00059 
2025-08-30 16:01:32.170485: train_loss -0.6287 
2025-08-30 16:01:32.183014: val_loss -0.6025 
2025-08-30 16:01:32.187163: Pseudo dice [np.float32(0.7924)] 
2025-08-30 16:01:32.195116: Epoch time: 27.54 s 
2025-08-30 16:01:32.854369:  
2025-08-30 16:01:32.862721: Epoch 447 
2025-08-30 16:01:32.866916: Current learning rate: 0.00059 
2025-08-30 16:02:02.363110: train_loss -0.6171 
2025-08-30 16:02:02.371408: val_loss -0.6103 
2025-08-30 16:02:02.375589: Pseudo dice [np.float32(0.8081)] 
2025-08-30 16:02:02.383404: Epoch time: 29.51 s 
2025-08-30 16:02:03.188881:  
2025-08-30 16:02:03.197257: Epoch 448 
2025-08-30 16:02:03.201428: Current learning rate: 0.00059 
2025-08-30 16:02:31.926496: train_loss -0.576 
2025-08-30 16:02:31.934233: val_loss -0.5845 
2025-08-30 16:02:31.942614: Pseudo dice [np.float32(0.8143)] 
2025-08-30 16:02:31.947672: Epoch time: 28.74 s 
2025-08-30 16:02:32.580158:  
2025-08-30 16:02:32.584887: Epoch 449 
2025-08-30 16:02:32.593227: Current learning rate: 0.00058 
2025-08-30 16:03:01.580252: train_loss -0.5953 
2025-08-30 16:03:01.580252: val_loss -0.5865 
2025-08-30 16:03:01.588788: Pseudo dice [np.float32(0.7737)] 
2025-08-30 16:03:01.596573: Epoch time: 29.0 s 
2025-08-30 16:03:02.477166:  
2025-08-30 16:03:02.485573: Epoch 450 
2025-08-30 16:03:02.489708: Current learning rate: 0.00058 
2025-08-30 16:03:31.176594: train_loss -0.5506 
2025-08-30 16:03:31.189138: val_loss -0.6003 
2025-08-30 16:03:31.193306: Pseudo dice [np.float32(0.7934)] 
2025-08-30 16:03:31.200578: Epoch time: 28.7 s 
2025-08-30 16:03:31.856576:  
2025-08-30 16:03:31.864880: Epoch 451 
2025-08-30 16:03:31.868932: Current learning rate: 0.00058 
2025-08-30 16:04:00.831255: train_loss -0.5693 
2025-08-30 16:04:00.839553: val_loss -0.5368 
2025-08-30 16:04:00.843745: Pseudo dice [np.float32(0.6922)] 
2025-08-30 16:04:00.853224: Epoch time: 28.98 s 
2025-08-30 16:04:01.485511:  
2025-08-30 16:04:01.490212: Epoch 452 
2025-08-30 16:04:01.498575: Current learning rate: 0.00058 
2025-08-30 16:04:30.610866: train_loss -0.5851 
2025-08-30 16:04:30.623306: val_loss -0.55 
2025-08-30 16:04:30.627460: Pseudo dice [np.float32(0.7666)] 
2025-08-30 16:04:30.635530: Epoch time: 29.13 s 
2025-08-30 16:04:31.269893:  
2025-08-30 16:04:31.278218: Epoch 453 
2025-08-30 16:04:31.283983: Current learning rate: 0.00058 
2025-08-30 16:05:00.036036: train_loss -0.5649 
2025-08-30 16:05:00.044352: val_loss -0.6225 
2025-08-30 16:05:00.052241: Pseudo dice [np.float32(0.7796)] 
2025-08-30 16:05:00.057868: Epoch time: 28.77 s 
2025-08-30 16:05:00.690685:  
2025-08-30 16:05:00.698699: Epoch 454 
2025-08-30 16:05:00.703433: Current learning rate: 0.00058 
2025-08-30 16:05:29.578669: train_loss -0.6053 
2025-08-30 16:05:29.586368: val_loss -0.652 
2025-08-30 16:05:29.594720: Pseudo dice [np.float32(0.8065)] 
2025-08-30 16:05:29.599884: Epoch time: 28.89 s 
2025-08-30 16:05:30.395395:  
2025-08-30 16:05:30.403308: Epoch 455 
2025-08-30 16:05:30.407931: Current learning rate: 0.00058 
2025-08-30 16:05:59.245020: train_loss -0.6006 
2025-08-30 16:05:59.253354: val_loss -0.6301 
2025-08-30 16:05:59.257549: Pseudo dice [np.float32(0.8276)] 
2025-08-30 16:05:59.265522: Epoch time: 28.85 s 
2025-08-30 16:05:59.895788:  
2025-08-30 16:05:59.903577: Epoch 456 
2025-08-30 16:05:59.908272: Current learning rate: 0.00058 
2025-08-30 16:06:28.741334: train_loss -0.63 
2025-08-30 16:06:28.753727: val_loss -0.6225 
2025-08-30 16:06:28.757877: Pseudo dice [np.float32(0.7976)] 
2025-08-30 16:06:28.765175: Epoch time: 28.85 s 
2025-08-30 16:06:29.400042:  
2025-08-30 16:06:29.408435: Epoch 457 
2025-08-30 16:06:29.412600: Current learning rate: 0.00058 
2025-08-30 16:06:58.199706: train_loss -0.5929 
2025-08-30 16:06:58.207995: val_loss -0.6034 
2025-08-30 16:06:58.212184: Pseudo dice [np.float32(0.8142)] 
2025-08-30 16:06:58.219481: Epoch time: 28.8 s 
2025-08-30 16:06:58.854604:  
2025-08-30 16:06:58.862962: Epoch 458 
2025-08-30 16:06:58.867004: Current learning rate: 0.00058 
2025-08-30 16:07:27.462111: train_loss -0.624 
2025-08-30 16:07:27.462111: val_loss -0.5184 
2025-08-30 16:07:27.472912: Pseudo dice [np.float32(0.7693)] 
2025-08-30 16:07:27.478352: Epoch time: 28.61 s 
2025-08-30 16:07:28.112759:  
2025-08-30 16:07:28.121137: Epoch 459 
2025-08-30 16:07:28.125303: Current learning rate: 0.00058 
2025-08-30 16:07:57.392148: train_loss -0.5552 
2025-08-30 16:07:57.400445: val_loss -0.5465 
2025-08-30 16:07:57.404564: Pseudo dice [np.float32(0.7192)] 
2025-08-30 16:07:57.411496: Epoch time: 29.28 s 
2025-08-30 16:07:58.038468:  
2025-08-30 16:07:58.046770: Epoch 460 
2025-08-30 16:07:58.055199: Current learning rate: 0.00057 
2025-08-30 16:08:26.971012: train_loss -0.5958 
2025-08-30 16:08:26.979823: val_loss -0.6457 
2025-08-30 16:08:26.984002: Pseudo dice [np.float32(0.7918)] 
2025-08-30 16:08:26.992245: Epoch time: 28.93 s 
2025-08-30 16:08:27.630562:  
2025-08-30 16:08:27.638381: Epoch 461 
2025-08-30 16:08:27.643391: Current learning rate: 0.00057 
2025-08-30 16:08:56.045835: train_loss -0.5936 
2025-08-30 16:08:56.050545: val_loss -0.5284 
2025-08-30 16:08:56.058917: Pseudo dice [np.float32(0.7606)] 
2025-08-30 16:08:56.065873: Epoch time: 28.42 s 
2025-08-30 16:08:56.847154:  
2025-08-30 16:08:56.857138: Epoch 462 
2025-08-30 16:08:56.860105: Current learning rate: 0.00057 
2025-08-30 16:09:25.680077: train_loss -0.5278 
2025-08-30 16:09:25.692526: val_loss -0.5768 
2025-08-30 16:09:25.696771: Pseudo dice [np.float32(0.754)] 
2025-08-30 16:09:25.703843: Epoch time: 28.83 s 
2025-08-30 16:09:26.334916:  
2025-08-30 16:09:26.343289: Epoch 463 
2025-08-30 16:09:26.347481: Current learning rate: 0.00057 
2025-08-30 16:09:54.584616: train_loss -0.6092 
2025-08-30 16:09:54.592206: val_loss -0.567 
2025-08-30 16:09:54.596318: Pseudo dice [np.float32(0.7704)] 
2025-08-30 16:09:54.603518: Epoch time: 28.25 s 
2025-08-30 16:09:55.259596:  
2025-08-30 16:09:55.267973: Epoch 464 
2025-08-30 16:09:55.272130: Current learning rate: 0.00057 
2025-08-30 16:10:24.384360: train_loss -0.5959 
2025-08-30 16:10:24.396482: val_loss -0.5195 
2025-08-30 16:10:24.401090: Pseudo dice [np.float32(0.7715)] 
2025-08-30 16:10:24.406382: Epoch time: 29.13 s 
2025-08-30 16:10:25.043451:  
2025-08-30 16:10:25.051814: Epoch 465 
2025-08-30 16:10:25.059655: Current learning rate: 0.00057 
2025-08-30 16:10:53.292346: train_loss -0.5567 
2025-08-30 16:10:53.300719: val_loss -0.5783 
2025-08-30 16:10:53.309110: Pseudo dice [np.float32(0.8021)] 
2025-08-30 16:10:53.314358: Epoch time: 28.25 s 
2025-08-30 16:10:53.943156:  
2025-08-30 16:10:53.951460: Epoch 466 
2025-08-30 16:10:53.955613: Current learning rate: 0.00057 
2025-08-30 16:11:23.026301: train_loss -0.5915 
2025-08-30 16:11:23.034612: val_loss -0.5955 
2025-08-30 16:11:23.042961: Pseudo dice [np.float32(0.7792)] 
2025-08-30 16:11:23.048840: Epoch time: 29.08 s 
2025-08-30 16:11:23.676410:  
2025-08-30 16:11:23.685285: Epoch 467 
2025-08-30 16:11:23.689534: Current learning rate: 0.00057 
2025-08-30 16:11:52.426434: train_loss -0.5914 
2025-08-30 16:11:52.434779: val_loss -0.5387 
2025-08-30 16:11:52.442609: Pseudo dice [np.float32(0.7966)] 
2025-08-30 16:11:52.447813: Epoch time: 28.75 s 
2025-08-30 16:11:53.085501:  
2025-08-30 16:11:53.093763: Epoch 468 
2025-08-30 16:11:53.101598: Current learning rate: 0.00057 
2025-08-30 16:12:22.014372: train_loss -0.5748 
2025-08-30 16:12:22.014372: val_loss -0.5867 
2025-08-30 16:12:22.023840: Pseudo dice [np.float32(0.7431)] 
2025-08-30 16:12:22.027966: Epoch time: 28.93 s 
2025-08-30 16:12:22.810902:  
2025-08-30 16:12:22.819255: Epoch 469 
2025-08-30 16:12:22.823463: Current learning rate: 0.00057 
2025-08-30 16:12:51.356005: train_loss -0.5858 
2025-08-30 16:12:51.364382: val_loss -0.6523 
2025-08-30 16:12:51.372732: Pseudo dice [np.float32(0.78)] 
2025-08-30 16:12:51.377847: Epoch time: 28.55 s 
2025-08-30 16:12:52.010768:  
2025-08-30 16:12:52.019122: Epoch 470 
2025-08-30 16:12:52.027498: Current learning rate: 0.00056 
2025-08-30 16:13:20.510025: train_loss -0.6138 
2025-08-30 16:13:20.518454: val_loss -0.4908 
2025-08-30 16:13:20.522629: Pseudo dice [np.float32(0.7007)] 
2025-08-30 16:13:20.529476: Epoch time: 28.5 s 
2025-08-30 16:13:21.164965:  
2025-08-30 16:13:21.173341: Epoch 471 
2025-08-30 16:13:21.177375: Current learning rate: 0.00056 
2025-08-30 16:13:50.399071: train_loss -0.6322 
2025-08-30 16:13:50.406651: val_loss -0.5022 
2025-08-30 16:13:50.410759: Pseudo dice [np.float32(0.7486)] 
2025-08-30 16:13:50.418759: Epoch time: 29.23 s 
2025-08-30 16:13:51.048784:  
2025-08-30 16:13:51.057127: Epoch 472 
2025-08-30 16:13:51.065049: Current learning rate: 0.00056 
2025-08-30 16:14:19.332810: train_loss -0.5781 
2025-08-30 16:14:19.339586: val_loss -0.5947 
2025-08-30 16:14:19.343787: Pseudo dice [np.float32(0.7734)] 
2025-08-30 16:14:19.350862: Epoch time: 28.28 s 
2025-08-30 16:14:19.981904:  
2025-08-30 16:14:19.990275: Epoch 473 
2025-08-30 16:14:19.998080: Current learning rate: 0.00056 
2025-08-30 16:14:48.810667: train_loss -0.5876 
2025-08-30 16:14:48.822631: val_loss -0.5477 
2025-08-30 16:14:48.827334: Pseudo dice [np.float32(0.7512)] 
2025-08-30 16:14:48.833252: Epoch time: 28.83 s 
2025-08-30 16:14:49.465463:  
2025-08-30 16:14:49.473791: Epoch 474 
2025-08-30 16:14:49.482227: Current learning rate: 0.00056 
2025-08-30 16:15:18.073171: train_loss -0.6087 
2025-08-30 16:15:18.081520: val_loss -0.5467 
2025-08-30 16:15:18.089340: Pseudo dice [np.float32(0.7553)] 
2025-08-30 16:15:18.094427: Epoch time: 28.61 s 
2025-08-30 16:15:18.723997:  
2025-08-30 16:15:18.732237: Epoch 475 
2025-08-30 16:15:18.736434: Current learning rate: 0.00056 
2025-08-30 16:15:47.623518: train_loss -0.6017 
2025-08-30 16:15:47.631777: val_loss -0.6113 
2025-08-30 16:15:47.640234: Pseudo dice [np.float32(0.7799)] 
2025-08-30 16:15:47.645223: Epoch time: 28.9 s 
2025-08-30 16:15:48.436775:  
2025-08-30 16:15:48.445041: Epoch 476 
2025-08-30 16:15:48.452984: Current learning rate: 0.00056 
2025-08-30 16:16:17.223695: train_loss -0.6032 
2025-08-30 16:16:17.232077: val_loss -0.5654 
2025-08-30 16:16:17.236316: Pseudo dice [np.float32(0.7638)] 
2025-08-30 16:16:17.244227: Epoch time: 28.79 s 
2025-08-30 16:16:17.882812:  
2025-08-30 16:16:17.891163: Epoch 477 
2025-08-30 16:16:17.895391: Current learning rate: 0.00056 
2025-08-30 16:16:46.360659: train_loss -0.6338 
2025-08-30 16:16:46.361089: val_loss -0.6137 
2025-08-30 16:16:46.369024: Pseudo dice [np.float32(0.7833)] 
2025-08-30 16:16:46.374759: Epoch time: 28.48 s 
2025-08-30 16:16:47.041031:  
2025-08-30 16:16:47.049410: Epoch 478 
2025-08-30 16:16:47.053565: Current learning rate: 0.00056 
2025-08-30 16:17:15.803234: train_loss -0.617 
2025-08-30 16:17:15.811382: val_loss -0.5955 
2025-08-30 16:17:15.820076: Pseudo dice [np.float32(0.7417)] 
2025-08-30 16:17:15.825685: Epoch time: 28.76 s 
2025-08-30 16:17:16.462116:  
2025-08-30 16:17:16.470423: Epoch 479 
2025-08-30 16:17:16.478832: Current learning rate: 0.00056 
2025-08-30 16:17:45.094736: train_loss -0.5768 
2025-08-30 16:17:45.103107: val_loss -0.5426 
2025-08-30 16:17:45.111491: Pseudo dice [np.float32(0.7521)] 
2025-08-30 16:17:45.116910: Epoch time: 28.63 s 
2025-08-30 16:17:45.757830:  
2025-08-30 16:17:45.762136: Epoch 480 
2025-08-30 16:17:45.770536: Current learning rate: 0.00056 
2025-08-30 16:18:14.161275: train_loss -0.5888 
2025-08-30 16:18:14.169610: val_loss -0.6561 
2025-08-30 16:18:14.177975: Pseudo dice [np.float32(0.819)] 
2025-08-30 16:18:14.182537: Epoch time: 28.41 s 
2025-08-30 16:18:14.866020:  
2025-08-30 16:18:14.870230: Epoch 481 
2025-08-30 16:18:14.878642: Current learning rate: 0.00055 
2025-08-30 16:18:43.853410: train_loss -0.6098 
2025-08-30 16:18:43.865817: val_loss -0.5584 
2025-08-30 16:18:43.870003: Pseudo dice [np.float32(0.7963)] 
2025-08-30 16:18:43.876081: Epoch time: 28.99 s 
2025-08-30 16:18:44.662528:  
2025-08-30 16:18:44.670880: Epoch 482 
2025-08-30 16:18:44.675041: Current learning rate: 0.00055 
2025-08-30 16:19:13.550673: train_loss -0.5523 
2025-08-30 16:19:13.557904: val_loss -0.66 
2025-08-30 16:19:13.562063: Pseudo dice [np.float32(0.7833)] 
2025-08-30 16:19:13.570939: Epoch time: 28.89 s 
2025-08-30 16:19:14.212928:  
2025-08-30 16:19:14.221153: Epoch 483 
2025-08-30 16:19:14.225339: Current learning rate: 0.00055 
2025-08-30 16:19:43.012672: train_loss -0.5998 
2025-08-30 16:19:43.024910: val_loss -0.615 
2025-08-30 16:19:43.029060: Pseudo dice [np.float32(0.8264)] 
2025-08-30 16:19:43.036901: Epoch time: 28.8 s 
2025-08-30 16:19:43.671308:  
2025-08-30 16:19:43.679164: Epoch 484 
2025-08-30 16:19:43.683767: Current learning rate: 0.00055 
2025-08-30 16:20:12.258403: train_loss -0.5991 
2025-08-30 16:20:12.266624: val_loss -0.5527 
2025-08-30 16:20:12.274896: Pseudo dice [np.float32(0.7465)] 
2025-08-30 16:20:12.280764: Epoch time: 28.59 s 
2025-08-30 16:20:12.946383:  
2025-08-30 16:20:12.954647: Epoch 485 
2025-08-30 16:20:12.958822: Current learning rate: 0.00055 
2025-08-30 16:20:41.691788: train_loss -0.5798 
2025-08-30 16:20:41.700070: val_loss -0.6237 
2025-08-30 16:20:41.704178: Pseudo dice [np.float32(0.7985)] 
2025-08-30 16:20:41.712144: Epoch time: 28.75 s 
2025-08-30 16:20:42.350595:  
2025-08-30 16:20:42.358950: Epoch 486 
2025-08-30 16:20:42.363136: Current learning rate: 0.00055 
2025-08-30 16:21:11.646606: train_loss -0.5753 
2025-08-30 16:21:11.654935: val_loss -0.6098 
2025-08-30 16:21:11.663345: Pseudo dice [np.float32(0.7986)] 
2025-08-30 16:21:11.668530: Epoch time: 29.3 s 
2025-08-30 16:21:12.305489:  
2025-08-30 16:21:12.313857: Epoch 487 
2025-08-30 16:21:12.318009: Current learning rate: 0.00055 
2025-08-30 16:21:40.913242: train_loss -0.5851 
2025-08-30 16:21:40.913242: val_loss -0.5914 
2025-08-30 16:21:40.925258: Pseudo dice [np.float32(0.7876)] 
2025-08-30 16:21:40.931129: Epoch time: 28.61 s 
2025-08-30 16:21:41.576414:  
2025-08-30 16:21:41.584716: Epoch 488 
2025-08-30 16:21:41.588940: Current learning rate: 0.00055 
2025-08-30 16:22:10.809197: train_loss -0.6101 
2025-08-30 16:22:10.813900: val_loss -0.5964 
2025-08-30 16:22:10.822276: Pseudo dice [np.float32(0.7578)] 
2025-08-30 16:22:10.828219: Epoch time: 29.24 s 
2025-08-30 16:22:11.627233:  
2025-08-30 16:22:11.635573: Epoch 489 
2025-08-30 16:22:11.639757: Current learning rate: 0.00055 
2025-08-30 16:22:40.205646: train_loss -0.6055 
2025-08-30 16:22:40.218161: val_loss -0.6141 
2025-08-30 16:22:40.222326: Pseudo dice [np.float32(0.7672)] 
2025-08-30 16:22:40.230558: Epoch time: 28.58 s 
2025-08-30 16:22:40.877258:  
2025-08-30 16:22:40.885612: Epoch 490 
2025-08-30 16:22:40.889643: Current learning rate: 0.00055 
2025-08-30 16:23:09.981422: train_loss -0.5807 
2025-08-30 16:23:09.989520: val_loss -0.599 
2025-08-30 16:23:09.993649: Pseudo dice [np.float32(0.775)] 
2025-08-30 16:23:09.999729: Epoch time: 29.1 s 
2025-08-30 16:23:10.631921:  
2025-08-30 16:23:10.640265: Epoch 491 
2025-08-30 16:23:10.648083: Current learning rate: 0.00054 
2025-08-30 16:23:39.608265: train_loss -0.5814 
2025-08-30 16:23:39.618620: val_loss -0.5265 
2025-08-30 16:23:39.623348: Pseudo dice [np.float32(0.7427)] 
2025-08-30 16:23:39.629219: Epoch time: 28.98 s 
2025-08-30 16:23:40.269588:  
2025-08-30 16:23:40.273876: Epoch 492 
2025-08-30 16:23:40.282227: Current learning rate: 0.00054 
2025-08-30 16:24:08.760682: train_loss -0.5917 
2025-08-30 16:24:08.768895: val_loss -0.5685 
2025-08-30 16:24:08.776868: Pseudo dice [np.float32(0.7785)] 
2025-08-30 16:24:08.781911: Epoch time: 28.5 s 
2025-08-30 16:24:09.428042:  
2025-08-30 16:24:09.432219: Epoch 493 
2025-08-30 16:24:09.440623: Current learning rate: 0.00054 
2025-08-30 16:24:37.689400: train_loss -0.5959 
2025-08-30 16:24:37.702005: val_loss -0.5847 
2025-08-30 16:24:37.706129: Pseudo dice [np.float32(0.7484)] 
2025-08-30 16:24:37.713123: Epoch time: 28.27 s 
2025-08-30 16:24:38.365216:  
2025-08-30 16:24:38.373084: Epoch 494 
2025-08-30 16:24:38.377802: Current learning rate: 0.00054 
2025-08-30 16:25:05.191846: train_loss -0.5917 
2025-08-30 16:25:05.200258: val_loss -0.5788 
2025-08-30 16:25:05.204360: Pseudo dice [np.float32(0.7689)] 
2025-08-30 16:25:05.211698: Epoch time: 26.83 s 
2025-08-30 16:25:05.846854:  
2025-08-30 16:25:05.855190: Epoch 495 
2025-08-30 16:25:05.859320: Current learning rate: 0.00054 
2025-08-30 16:25:33.683003: train_loss -0.6176 
2025-08-30 16:25:33.694901: val_loss -0.5541 
2025-08-30 16:25:33.699596: Pseudo dice [np.float32(0.7778)] 
2025-08-30 16:25:33.705638: Epoch time: 27.84 s 
2025-08-30 16:25:34.512858:  
2025-08-30 16:25:34.521247: Epoch 496 
2025-08-30 16:25:34.529038: Current learning rate: 0.00054 
2025-08-30 16:26:02.217030: train_loss -0.5967 
2025-08-30 16:26:02.217030: val_loss -0.6661 
2025-08-30 16:26:02.225241: Pseudo dice [np.float32(0.8027)] 
2025-08-30 16:26:02.228519: Epoch time: 27.7 s 
2025-08-30 16:26:02.870230:  
2025-08-30 16:26:02.878554: Epoch 497 
2025-08-30 16:26:02.886918: Current learning rate: 0.00054 
2025-08-30 16:26:30.122360: train_loss -0.6054 
2025-08-30 16:26:30.130824: val_loss -0.5977 
2025-08-30 16:26:30.139228: Pseudo dice [np.float32(0.7363)] 
2025-08-30 16:26:30.144421: Epoch time: 27.25 s 
2025-08-30 16:26:30.785665:  
2025-08-30 16:26:30.796453: Epoch 498 
2025-08-30 16:26:30.802334: Current learning rate: 0.00054 
2025-08-30 16:26:58.726119: train_loss -0.6179 
2025-08-30 16:26:58.734311: val_loss -0.6077 
2025-08-30 16:26:58.738527: Pseudo dice [np.float32(0.8233)] 
2025-08-30 16:26:58.746419: Epoch time: 27.94 s 
2025-08-30 16:26:59.397413:  
2025-08-30 16:26:59.405366: Epoch 499 
2025-08-30 16:26:59.409930: Current learning rate: 0.00054 
2025-08-30 16:27:27.100285: train_loss -0.6151 
2025-08-30 16:27:27.112675: val_loss -0.5569 
2025-08-30 16:27:27.116869: Pseudo dice [np.float32(0.7969)] 
2025-08-30 16:27:27.122951: Epoch time: 27.71 s 
2025-08-30 16:27:27.980042:  
2025-08-30 16:27:27.988428: Epoch 500 
2025-08-30 16:27:27.992603: Current learning rate: 0.00054 
2025-08-30 16:27:55.520570: train_loss -0.5969 
2025-08-30 16:27:55.528405: val_loss -0.5251 
2025-08-30 16:27:55.532617: Pseudo dice [np.float32(0.7196)] 
2025-08-30 16:27:55.538573: Epoch time: 27.54 s 
2025-08-30 16:27:56.183351:  
2025-08-30 16:27:56.191692: Epoch 501 
2025-08-30 16:27:56.195853: Current learning rate: 0.00053 
2025-08-30 16:28:25.600499: train_loss -0.5746 
2025-08-30 16:28:25.608371: val_loss -0.4587 
2025-08-30 16:28:25.612480: Pseudo dice [np.float32(0.6708)] 
2025-08-30 16:28:25.620578: Epoch time: 29.42 s 
2025-08-30 16:28:26.267510:  
2025-08-30 16:28:26.275835: Epoch 502 
2025-08-30 16:28:26.284287: Current learning rate: 0.00053 
2025-08-30 16:28:54.144754: train_loss -0.6234 
2025-08-30 16:28:54.153092: val_loss -0.5543 
2025-08-30 16:28:54.157838: Pseudo dice [np.float32(0.7795)] 
2025-08-30 16:28:54.163854: Epoch time: 27.88 s 
2025-08-30 16:28:54.971095:  
2025-08-30 16:28:54.979444: Epoch 503 
2025-08-30 16:28:54.983611: Current learning rate: 0.00053 
2025-08-30 16:29:24.283709: train_loss -0.5854 
2025-08-30 16:29:24.295646: val_loss -0.5986 
2025-08-30 16:29:24.300337: Pseudo dice [np.float32(0.7932)] 
2025-08-30 16:29:24.305588: Epoch time: 29.32 s 
2025-08-30 16:29:24.950984:  
2025-08-30 16:29:24.959364: Epoch 504 
2025-08-30 16:29:24.963507: Current learning rate: 0.00053 
2025-08-30 16:29:53.247148: train_loss -0.5941 
2025-08-30 16:29:53.254112: val_loss -0.6163 
2025-08-30 16:29:53.258323: Pseudo dice [np.float32(0.8207)] 
2025-08-30 16:29:53.266359: Epoch time: 28.3 s 
2025-08-30 16:29:53.913220:  
2025-08-30 16:29:53.917395: Epoch 505 
2025-08-30 16:29:53.925751: Current learning rate: 0.00053 
2025-08-30 16:30:22.629402: train_loss -0.6159 
2025-08-30 16:30:22.637644: val_loss -0.6112 
2025-08-30 16:30:22.646130: Pseudo dice [np.float32(0.803)] 
2025-08-30 16:30:22.660203: Epoch time: 28.72 s 
2025-08-30 16:30:23.329964:  
2025-08-30 16:30:23.338346: Epoch 506 
2025-08-30 16:30:23.342452: Current learning rate: 0.00053 
2025-08-30 16:30:51.966868: train_loss -0.6211 
2025-08-30 16:30:51.966868: val_loss -0.6179 
2025-08-30 16:30:51.977474: Pseudo dice [np.float32(0.8041)] 
2025-08-30 16:30:51.983028: Epoch time: 28.64 s 
2025-08-30 16:30:52.621743:  
2025-08-30 16:30:52.630083: Epoch 507 
2025-08-30 16:30:52.638459: Current learning rate: 0.00053 
2025-08-30 16:31:21.556240: train_loss -0.5919 
2025-08-30 16:31:21.563142: val_loss -0.6146 
2025-08-30 16:31:21.570946: Pseudo dice [np.float32(0.7885)] 
2025-08-30 16:31:21.575202: Epoch time: 28.93 s 
2025-08-30 16:31:22.217852:  
2025-08-30 16:31:22.226164: Epoch 508 
2025-08-30 16:31:22.230265: Current learning rate: 0.00053 
2025-08-30 16:31:51.517927: train_loss -0.5537 
2025-08-30 16:31:51.526312: val_loss -0.5766 
2025-08-30 16:31:51.534803: Pseudo dice [np.float32(0.772)] 
2025-08-30 16:31:51.539816: Epoch time: 29.3 s 
2025-08-30 16:31:52.193563:  
2025-08-30 16:31:52.201923: Epoch 509 
2025-08-30 16:31:52.206084: Current learning rate: 0.00053 
2025-08-30 16:32:20.400400: train_loss -0.6033 
2025-08-30 16:32:20.408803: val_loss -0.5815 
2025-08-30 16:32:20.413494: Pseudo dice [np.float32(0.7932)] 
2025-08-30 16:32:20.420434: Epoch time: 28.21 s 
2025-08-30 16:32:21.222595:  
2025-08-30 16:32:21.230988: Epoch 510 
2025-08-30 16:32:21.235160: Current learning rate: 0.00053 
2025-08-30 16:32:50.577388: train_loss -0.6045 
2025-08-30 16:32:50.585221: val_loss -0.5343 
2025-08-30 16:32:50.593648: Pseudo dice [np.float32(0.781)] 
2025-08-30 16:32:50.598703: Epoch time: 29.35 s 
2025-08-30 16:32:51.244335:  
2025-08-30 16:32:51.252575: Epoch 511 
2025-08-30 16:32:51.256735: Current learning rate: 0.00053 
2025-08-30 16:33:19.580803: train_loss -0.5994 
2025-08-30 16:33:19.588991: val_loss -0.569 
2025-08-30 16:33:19.597471: Pseudo dice [np.float32(0.802)] 
2025-08-30 16:33:19.602632: Epoch time: 28.34 s 
2025-08-30 16:33:20.248093:  
2025-08-30 16:33:20.255946: Epoch 512 
2025-08-30 16:33:20.260670: Current learning rate: 0.00052 
2025-08-30 16:33:48.760390: train_loss -0.6106 
2025-08-30 16:33:48.768177: val_loss -0.6212 
2025-08-30 16:33:48.772316: Pseudo dice [np.float32(0.8209)] 
2025-08-30 16:33:48.780316: Epoch time: 28.52 s 
2025-08-30 16:33:49.418865:  
2025-08-30 16:33:49.427223: Epoch 513 
2025-08-30 16:33:49.431360: Current learning rate: 0.00052 
2025-08-30 16:34:18.309660: train_loss -0.6228 
2025-08-30 16:34:18.314288: val_loss -0.5753 
2025-08-30 16:34:18.322689: Pseudo dice [np.float32(0.7904)] 
2025-08-30 16:34:18.327279: Epoch time: 28.89 s 
2025-08-30 16:34:19.027071:  
2025-08-30 16:34:19.035391: Epoch 514 
2025-08-30 16:34:19.040094: Current learning rate: 0.00052 
2025-08-30 16:34:47.530948: train_loss -0.6242 
2025-08-30 16:34:47.543504: val_loss -0.5628 
2025-08-30 16:34:47.547735: Pseudo dice [np.float32(0.7305)] 
2025-08-30 16:34:47.555634: Epoch time: 28.51 s 
2025-08-30 16:34:48.202529:  
2025-08-30 16:34:48.210888: Epoch 515 
2025-08-30 16:34:48.215056: Current learning rate: 0.00052 
2025-08-30 16:35:17.268866: train_loss -0.6434 
2025-08-30 16:35:17.272600: val_loss -0.5709 
2025-08-30 16:35:17.280975: Pseudo dice [np.float32(0.7655)] 
2025-08-30 16:35:17.286695: Epoch time: 29.07 s 
2025-08-30 16:35:17.932178:  
2025-08-30 16:35:17.932178: Epoch 516 
2025-08-30 16:35:17.941796: Current learning rate: 0.00052 
2025-08-30 16:35:45.601445: train_loss -0.5983 
2025-08-30 16:35:45.609767: val_loss -0.5438 
2025-08-30 16:35:45.613834: Pseudo dice [np.float32(0.7513)] 
2025-08-30 16:35:45.621945: Epoch time: 27.67 s 
2025-08-30 16:35:46.414724:  
2025-08-30 16:35:46.423021: Epoch 517 
2025-08-30 16:35:46.427202: Current learning rate: 0.00052 
2025-08-30 16:36:13.937907: train_loss -0.6192 
2025-08-30 16:36:13.946343: val_loss -0.5889 
2025-08-30 16:36:13.954717: Pseudo dice [np.float32(0.7552)] 
2025-08-30 16:36:13.959332: Epoch time: 27.52 s 
2025-08-30 16:36:14.634620:  
2025-08-30 16:36:14.642862: Epoch 518 
2025-08-30 16:36:14.650722: Current learning rate: 0.00052 
2025-08-30 16:36:42.403803: train_loss -0.6105 
2025-08-30 16:36:42.412149: val_loss -0.5676 
2025-08-30 16:36:42.416335: Pseudo dice [np.float32(0.7436)] 
2025-08-30 16:36:42.423361: Epoch time: 27.77 s 
2025-08-30 16:36:43.058657:  
2025-08-30 16:36:43.067047: Epoch 519 
2025-08-30 16:36:43.075424: Current learning rate: 0.00052 
2025-08-30 16:37:09.054967: train_loss -0.5918 
2025-08-30 16:37:09.063685: val_loss -0.6255 
2025-08-30 16:37:09.067902: Pseudo dice [np.float32(0.7615)] 
2025-08-30 16:37:09.073981: Epoch time: 26.0 s 
2025-08-30 16:37:09.718615:  
2025-08-30 16:37:09.727010: Epoch 520 
2025-08-30 16:37:09.731149: Current learning rate: 0.00052 
2025-08-30 16:37:35.581914: train_loss -0.585 
2025-08-30 16:37:35.594413: val_loss -0.604 
2025-08-30 16:37:35.598606: Pseudo dice [np.float32(0.7322)] 
2025-08-30 16:37:35.604683: Epoch time: 25.86 s 
2025-08-30 16:37:36.253389:  
2025-08-30 16:37:36.261758: Epoch 521 
2025-08-30 16:37:36.265915: Current learning rate: 0.00052 
2025-08-30 16:38:02.045750: train_loss -0.6057 
2025-08-30 16:38:02.054142: val_loss -0.5745 
2025-08-30 16:38:02.058229: Pseudo dice [np.float32(0.7444)] 
2025-08-30 16:38:02.066279: Epoch time: 25.79 s 
2025-08-30 16:38:02.717199:  
2025-08-30 16:38:02.725588: Epoch 522 
2025-08-30 16:38:02.729706: Current learning rate: 0.00051 
2025-08-30 16:38:28.188496: train_loss -0.5788 
2025-08-30 16:38:28.196784: val_loss -0.5951 
2025-08-30 16:38:28.200970: Pseudo dice [np.float32(0.7803)] 
2025-08-30 16:38:28.209031: Epoch time: 25.47 s 
2025-08-30 16:38:28.851720:  
2025-08-30 16:38:28.860035: Epoch 523 
2025-08-30 16:38:28.864296: Current learning rate: 0.00051 
2025-08-30 16:38:54.644033: train_loss -0.6307 
2025-08-30 16:38:54.651892: val_loss -0.5803 
2025-08-30 16:38:54.656508: Pseudo dice [np.float32(0.7849)] 
2025-08-30 16:38:54.661865: Epoch time: 25.79 s 
2025-08-30 16:38:55.457396:  
2025-08-30 16:38:55.465760: Epoch 524 
2025-08-30 16:38:55.474075: Current learning rate: 0.00051 
2025-08-30 16:39:20.828014: train_loss -0.619 
2025-08-30 16:39:20.836787: val_loss -0.597 
2025-08-30 16:39:20.840967: Pseudo dice [np.float32(0.8215)] 
2025-08-30 16:39:20.847886: Epoch time: 25.37 s 
2025-08-30 16:39:21.495849:  
2025-08-30 16:39:21.504202: Epoch 525 
2025-08-30 16:39:21.508380: Current learning rate: 0.00051 
2025-08-30 16:39:47.380911: train_loss -0.5865 
2025-08-30 16:39:47.388249: val_loss -0.5469 
2025-08-30 16:39:47.396651: Pseudo dice [np.float32(0.7354)] 
2025-08-30 16:39:47.401903: Epoch time: 25.89 s 
2025-08-30 16:39:48.039104:  
2025-08-30 16:39:48.047352: Epoch 526 
2025-08-30 16:39:48.055719: Current learning rate: 0.00051 
2025-08-30 16:40:14.160818: train_loss -0.6083 
2025-08-30 16:40:14.160818: val_loss -0.6289 
2025-08-30 16:40:14.169283: Pseudo dice [np.float32(0.8102)] 
2025-08-30 16:40:14.173807: Epoch time: 26.12 s 
2025-08-30 16:40:14.815579:  
2025-08-30 16:40:14.823526: Epoch 527 
2025-08-30 16:40:14.828096: Current learning rate: 0.00051 
2025-08-30 16:40:42.672561: train_loss -0.6234 
2025-08-30 16:40:42.680914: val_loss -0.5322 
2025-08-30 16:40:42.685025: Pseudo dice [np.float32(0.7621)] 
2025-08-30 16:40:42.694012: Epoch time: 27.86 s 
2025-08-30 16:40:43.356756:  
2025-08-30 16:40:43.364914: Epoch 528 
2025-08-30 16:40:43.372812: Current learning rate: 0.00051 
2025-08-30 16:41:11.326123: train_loss -0.6292 
2025-08-30 16:41:11.334493: val_loss -0.5764 
2025-08-30 16:41:11.338641: Pseudo dice [np.float32(0.7347)] 
2025-08-30 16:41:11.346621: Epoch time: 27.97 s 
2025-08-30 16:41:11.985193:  
2025-08-30 16:41:11.993582: Epoch 529 
2025-08-30 16:41:11.997658: Current learning rate: 0.00051 
2025-08-30 16:41:39.718446: train_loss -0.6172 
2025-08-30 16:41:39.725400: val_loss -0.6179 
2025-08-30 16:41:39.733745: Pseudo dice [np.float32(0.8501)] 
2025-08-30 16:41:39.738830: Epoch time: 27.73 s 
2025-08-30 16:41:40.521975:  
2025-08-30 16:41:40.530395: Epoch 530 
2025-08-30 16:41:40.534520: Current learning rate: 0.00051 
2025-08-30 16:42:08.274648: train_loss -0.6099 
2025-08-30 16:42:08.282992: val_loss -0.6014 
2025-08-30 16:42:08.287148: Pseudo dice [np.float32(0.7777)] 
2025-08-30 16:42:08.295986: Epoch time: 27.75 s 
2025-08-30 16:42:08.933569:  
2025-08-30 16:42:08.941920: Epoch 531 
2025-08-30 16:42:08.946096: Current learning rate: 0.00051 
2025-08-30 16:42:37.061795: train_loss -0.5941 
2025-08-30 16:42:37.070032: val_loss -0.5985 
2025-08-30 16:42:37.078782: Pseudo dice [np.float32(0.7797)] 
2025-08-30 16:42:37.083594: Epoch time: 28.13 s 
2025-08-30 16:42:37.733101:  
2025-08-30 16:42:37.741477: Epoch 532 
2025-08-30 16:42:37.749541: Current learning rate: 0.0005 
2025-08-30 16:43:05.878185: train_loss -0.6169 
2025-08-30 16:43:05.886290: val_loss -0.5795 
2025-08-30 16:43:05.890478: Pseudo dice [np.float32(0.7546)] 
2025-08-30 16:43:05.897355: Epoch time: 28.15 s 
2025-08-30 16:43:06.536813:  
2025-08-30 16:43:06.544741: Epoch 533 
2025-08-30 16:43:06.549351: Current learning rate: 0.0005 
2025-08-30 16:43:34.456430: train_loss -0.6067 
2025-08-30 16:43:34.468923: val_loss -0.6171 
2025-08-30 16:43:34.473209: Pseudo dice [np.float32(0.824)] 
2025-08-30 16:43:34.481157: Epoch time: 27.92 s 
2025-08-30 16:43:35.127869:  
2025-08-30 16:43:35.136228: Epoch 534 
2025-08-30 16:43:35.140354: Current learning rate: 0.0005 
2025-08-30 16:44:03.051088: train_loss -0.589 
2025-08-30 16:44:03.059450: val_loss -0.5945 
2025-08-30 16:44:03.064067: Pseudo dice [np.float32(0.7826)] 
2025-08-30 16:44:03.070277: Epoch time: 27.92 s 
2025-08-30 16:44:03.727328:  
2025-08-30 16:44:03.735718: Epoch 535 
2025-08-30 16:44:03.739792: Current learning rate: 0.0005 
2025-08-30 16:44:31.204678: train_loss -0.6266 
2025-08-30 16:44:31.213070: val_loss -0.5475 
2025-08-30 16:44:31.220850: Pseudo dice [np.float32(0.7649)] 
2025-08-30 16:44:31.226033: Epoch time: 27.48 s 
2025-08-30 16:44:31.884003:  
2025-08-30 16:44:31.888628: Epoch 536 
2025-08-30 16:44:31.897135: Current learning rate: 0.0005 
2025-08-30 16:44:59.653356: train_loss -0.5911 
2025-08-30 16:44:59.653815: val_loss -0.5988 
2025-08-30 16:44:59.661709: Pseudo dice [np.float32(0.7693)] 
2025-08-30 16:44:59.667843: Epoch time: 27.77 s 
2025-08-30 16:45:00.462910:  
2025-08-30 16:45:00.471310: Epoch 537 
2025-08-30 16:45:00.475466: Current learning rate: 0.0005 
2025-08-30 16:45:27.723893: train_loss -0.5761 
2025-08-30 16:45:27.731908: val_loss -0.6194 
2025-08-30 16:45:27.736068: Pseudo dice [np.float32(0.8323)] 
2025-08-30 16:45:27.743963: Epoch time: 27.26 s 
2025-08-30 16:45:28.386715:  
2025-08-30 16:45:28.395334: Epoch 538 
2025-08-30 16:45:28.399233: Current learning rate: 0.0005 
2025-08-30 16:45:54.596732: train_loss -0.6012 
2025-08-30 16:45:54.604426: val_loss -0.5637 
2025-08-30 16:45:54.608658: Pseudo dice [np.float32(0.788)] 
2025-08-30 16:45:54.614908: Epoch time: 26.21 s 
2025-08-30 16:45:55.291023:  
2025-08-30 16:45:55.300356: Epoch 539 
2025-08-30 16:45:55.305805: Current learning rate: 0.0005 
2025-08-30 16:46:21.138846: train_loss -0.6232 
2025-08-30 16:46:21.147125: val_loss -0.6058 
2025-08-30 16:46:21.151906: Pseudo dice [np.float32(0.7611)] 
2025-08-30 16:46:21.157146: Epoch time: 25.85 s 
2025-08-30 16:46:21.773780:  
2025-08-30 16:46:21.782138: Epoch 540 
2025-08-30 16:46:21.787405: Current learning rate: 0.0005 
2025-08-30 16:46:47.523827: train_loss -0.5859 
2025-08-30 16:46:47.532167: val_loss -0.6252 
2025-08-30 16:46:47.540514: Pseudo dice [np.float32(0.8195)] 
2025-08-30 16:46:47.545743: Epoch time: 25.75 s 
2025-08-30 16:46:48.172953:  
2025-08-30 16:46:48.180298: Epoch 541 
2025-08-30 16:46:48.186454: Current learning rate: 0.0005 
2025-08-30 16:47:13.841807: train_loss -0.5895 
2025-08-30 16:47:13.849988: val_loss -0.5795 
2025-08-30 16:47:13.854218: Pseudo dice [np.float32(0.7578)] 
2025-08-30 16:47:13.862519: Epoch time: 25.67 s 
2025-08-30 16:47:14.527675:  
2025-08-30 16:47:14.537009: Epoch 542 
2025-08-30 16:47:14.545717: Current learning rate: 0.0005 
2025-08-30 16:47:39.774292: train_loss -0.5945 
2025-08-30 16:47:39.782717: val_loss -0.669 
2025-08-30 16:47:39.788408: Pseudo dice [np.float32(0.7839)] 
2025-08-30 16:47:39.794258: Epoch time: 25.25 s 
2025-08-30 16:47:40.622544:  
2025-08-30 16:47:40.630914: Epoch 543 
2025-08-30 16:47:40.634701: Current learning rate: 0.00049 
2025-08-30 16:48:05.552421: train_loss -0.5924 
2025-08-30 16:48:05.552421: val_loss -0.626 
2025-08-30 16:48:05.561152: Pseudo dice [np.float32(0.7688)] 
2025-08-30 16:48:05.566538: Epoch time: 24.93 s 
2025-08-30 16:48:06.186311:  
2025-08-30 16:48:06.186311: Epoch 544 
2025-08-30 16:48:06.195997: Current learning rate: 0.00049 
2025-08-30 16:48:30.785047: train_loss -0.5877 
2025-08-30 16:48:30.785047: val_loss -0.5575 
2025-08-30 16:48:30.795775: Pseudo dice [np.float32(0.7976)] 
2025-08-30 16:48:30.801395: Epoch time: 24.6 s 
2025-08-30 16:48:31.419766:  
2025-08-30 16:48:31.419766: Epoch 545 
2025-08-30 16:48:31.429564: Current learning rate: 0.00049 
2025-08-30 16:48:55.964922: train_loss -0.5671 
2025-08-30 16:48:55.964922: val_loss -0.5235 
2025-08-30 16:48:55.972674: Pseudo dice [np.float32(0.8059)] 
2025-08-30 16:48:55.978519: Epoch time: 24.55 s 
2025-08-30 16:48:56.594893:  
2025-08-30 16:48:56.594893: Epoch 546 
2025-08-30 16:48:56.604613: Current learning rate: 0.00049 
2025-08-30 16:49:21.289566: train_loss -0.6253 
2025-08-30 16:49:21.289566: val_loss -0.6073 
2025-08-30 16:49:21.301764: Pseudo dice [np.float32(0.8172)] 
2025-08-30 16:49:21.320561: Epoch time: 24.69 s 
2025-08-30 16:49:21.969096:  
2025-08-30 16:49:21.970142: Epoch 547 
2025-08-30 16:49:21.977465: Current learning rate: 0.00049 
2025-08-30 16:49:46.969327: train_loss -0.6141 
2025-08-30 16:49:46.969327: val_loss -0.5351 
2025-08-30 16:49:46.980972: Pseudo dice [np.float32(0.7364)] 
2025-08-30 16:49:46.987355: Epoch time: 25.0 s 
2025-08-30 16:49:47.616602:  
2025-08-30 16:49:47.616602: Epoch 548 
2025-08-30 16:49:47.624939: Current learning rate: 0.00049 
2025-08-30 16:50:12.331789: train_loss -0.6 
2025-08-30 16:50:12.331789: val_loss -0.541 
2025-08-30 16:50:12.342750: Pseudo dice [np.float32(0.7643)] 
2025-08-30 16:50:12.348433: Epoch time: 24.72 s 
2025-08-30 16:50:12.966876:  
2025-08-30 16:50:12.966876: Epoch 549 
2025-08-30 16:50:12.975549: Current learning rate: 0.00049 
2025-08-30 16:50:38.949989: train_loss -0.6143 
2025-08-30 16:50:38.949989: val_loss -0.5368 
2025-08-30 16:50:38.961945: Pseudo dice [np.float32(0.695)] 
2025-08-30 16:50:38.967541: Epoch time: 25.98 s 
2025-08-30 16:50:39.997989:  
2025-08-30 16:50:39.997989: Epoch 550 
2025-08-30 16:50:40.007576: Current learning rate: 0.00049 
2025-08-30 16:51:05.747891: train_loss -0.6376 
2025-08-30 16:51:05.747891: val_loss -0.5662 
2025-08-30 16:51:05.756322: Pseudo dice [np.float32(0.7846)] 
2025-08-30 16:51:05.762120: Epoch time: 25.75 s 
2025-08-30 16:51:06.411822:  
2025-08-30 16:51:06.411822: Epoch 551 
2025-08-30 16:51:06.420129: Current learning rate: 0.00049 
2025-08-30 16:51:32.140851: train_loss -0.5753 
2025-08-30 16:51:32.140851: val_loss -0.6368 
2025-08-30 16:51:32.153036: Pseudo dice [np.float32(0.818)] 
2025-08-30 16:51:32.159859: Epoch time: 25.73 s 
2025-08-30 16:51:32.788131:  
2025-08-30 16:51:32.791206: Epoch 552 
2025-08-30 16:51:32.799009: Current learning rate: 0.00049 
2025-08-30 16:51:58.413055: train_loss -0.6234 
2025-08-30 16:51:58.413055: val_loss -0.6049 
2025-08-30 16:51:58.423544: Pseudo dice [np.float32(0.8344)] 
2025-08-30 16:51:58.430230: Epoch time: 25.62 s 
2025-08-30 16:51:59.068502:  
2025-08-30 16:51:59.068502: Epoch 553 
2025-08-30 16:51:59.077829: Current learning rate: 0.00048 
2025-08-30 16:52:27.003640: train_loss -0.6092 
2025-08-30 16:52:27.003640: val_loss -0.6335 
2025-08-30 16:52:27.016111: Pseudo dice [np.float32(0.8209)] 
2025-08-30 16:52:27.022069: Epoch time: 27.94 s 
2025-08-30 16:52:27.688738:  
2025-08-30 16:52:27.688738: Epoch 554 
2025-08-30 16:52:27.697078: Current learning rate: 0.00048 
2025-08-30 16:52:57.004325: train_loss -0.6432 
2025-08-30 16:52:57.004325: val_loss -0.6064 
2025-08-30 16:52:57.013362: Pseudo dice [np.float32(0.7809)] 
2025-08-30 16:52:57.019199: Epoch time: 29.32 s 
2025-08-30 16:52:57.710634:  
2025-08-30 16:52:57.713424: Epoch 555 
2025-08-30 16:52:57.720344: Current learning rate: 0.00048 
2025-08-30 16:53:25.262103: train_loss -0.5952 
2025-08-30 16:53:25.262103: val_loss -0.6485 
2025-08-30 16:53:25.273662: Pseudo dice [np.float32(0.8473)] 
2025-08-30 16:53:25.280175: Epoch time: 27.55 s 
2025-08-30 16:53:25.285461: Yayy! New best EMA pseudo Dice: 0.792900025844574 
2025-08-30 16:53:26.372926:  
2025-08-30 16:53:26.372926: Epoch 556 
2025-08-30 16:53:26.383205: Current learning rate: 0.00048 
2025-08-30 16:53:53.761293: train_loss -0.6096 
2025-08-30 16:53:53.765099: val_loss -0.5775 
2025-08-30 16:53:53.769736: Pseudo dice [np.float32(0.7737)] 
2025-08-30 16:53:53.778480: Epoch time: 27.39 s 
2025-08-30 16:53:54.450867:  
2025-08-30 16:53:54.450867: Epoch 557 
2025-08-30 16:53:54.459166: Current learning rate: 0.00048 
2025-08-30 16:54:22.026605: train_loss -0.6207 
2025-08-30 16:54:22.030785: val_loss -0.6173 
2025-08-30 16:54:22.039141: Pseudo dice [np.float32(0.7481)] 
2025-08-30 16:54:22.053064: Epoch time: 27.58 s 
2025-08-30 16:54:22.752336:  
2025-08-30 16:54:22.752336: Epoch 558 
2025-08-30 16:54:22.760689: Current learning rate: 0.00048 
2025-08-30 16:54:50.092565: train_loss -0.6003 
2025-08-30 16:54:50.096279: val_loss -0.5775 
2025-08-30 16:54:50.104671: Pseudo dice [np.float32(0.7868)] 
2025-08-30 16:54:50.110072: Epoch time: 27.34 s 
2025-08-30 16:54:50.777261:  
2025-08-30 16:54:50.777261: Epoch 559 
2025-08-30 16:54:50.784486: Current learning rate: 0.00048 
2025-08-30 16:55:18.374780: train_loss -0.5938 
2025-08-30 16:55:18.374780: val_loss -0.5589 
2025-08-30 16:55:18.382825: Pseudo dice [np.float32(0.7786)] 
2025-08-30 16:55:18.392043: Epoch time: 27.6 s 
2025-08-30 16:55:19.058495:  
2025-08-30 16:55:19.059585: Epoch 560 
2025-08-30 16:55:19.066849: Current learning rate: 0.00048 
2025-08-30 16:55:46.769883: train_loss -0.6228 
2025-08-30 16:55:46.773940: val_loss -0.6062 
2025-08-30 16:55:46.783677: Pseudo dice [np.float32(0.7453)] 
2025-08-30 16:55:46.788335: Epoch time: 27.71 s 
2025-08-30 16:55:47.476096:  
2025-08-30 16:55:47.476096: Epoch 561 
2025-08-30 16:55:47.484219: Current learning rate: 0.00048 
2025-08-30 16:56:15.161082: train_loss -0.6621 
2025-08-30 16:56:15.161082: val_loss -0.6465 
2025-08-30 16:56:15.169006: Pseudo dice [np.float32(0.8735)] 
2025-08-30 16:56:15.177889: Epoch time: 27.69 s 
2025-08-30 16:56:15.837061:  
2025-08-30 16:56:15.837061: Epoch 562 
2025-08-30 16:56:15.845810: Current learning rate: 0.00048 
2025-08-30 16:56:43.055139: train_loss -0.6363 
2025-08-30 16:56:43.055139: val_loss -0.5126 
2025-08-30 16:56:43.068632: Pseudo dice [np.float32(0.7083)] 
2025-08-30 16:56:43.072356: Epoch time: 27.22 s 
2025-08-30 16:56:43.742934:  
2025-08-30 16:56:43.742934: Epoch 563 
2025-08-30 16:56:43.748248: Current learning rate: 0.00047 
2025-08-30 16:57:10.949705: train_loss -0.6184 
2025-08-30 16:57:10.949705: val_loss -0.5095 
2025-08-30 16:57:10.959282: Pseudo dice [np.float32(0.6939)] 
2025-08-30 16:57:10.962668: Epoch time: 27.21 s 
2025-08-30 16:57:11.626171:  
2025-08-30 16:57:11.629115: Epoch 564 
2025-08-30 16:57:11.635942: Current learning rate: 0.00047 
2025-08-30 16:57:39.103203: train_loss -0.6161 
2025-08-30 16:57:39.103203: val_loss -0.661 
2025-08-30 16:57:39.112299: Pseudo dice [np.float32(0.8046)] 
2025-08-30 16:57:39.116207: Epoch time: 27.48 s 
2025-08-30 16:57:39.779075:  
2025-08-30 16:57:39.779075: Epoch 565 
2025-08-30 16:57:39.788133: Current learning rate: 0.00047 
2025-08-30 16:58:07.218619: train_loss -0.6338 
2025-08-30 16:58:07.218619: val_loss -0.5675 
2025-08-30 16:58:07.227871: Pseudo dice [np.float32(0.7634)] 
2025-08-30 16:58:07.232541: Epoch time: 27.44 s 
2025-08-30 16:58:07.907129:  
2025-08-30 16:58:07.907129: Epoch 566 
2025-08-30 16:58:07.915505: Current learning rate: 0.00047 
2025-08-30 16:58:35.989030: train_loss -0.6339 
2025-08-30 16:58:35.989030: val_loss -0.5728 
2025-08-30 16:58:35.997011: Pseudo dice [np.float32(0.7794)] 
2025-08-30 16:58:36.002141: Epoch time: 28.09 s 
2025-08-30 16:58:36.669164:  
2025-08-30 16:58:36.669164: Epoch 567 
2025-08-30 16:58:36.678195: Current learning rate: 0.00047 
2025-08-30 16:59:03.875720: train_loss -0.5877 
2025-08-30 16:59:03.875720: val_loss -0.5542 
2025-08-30 16:59:03.884378: Pseudo dice [np.float32(0.7518)] 
2025-08-30 16:59:03.889076: Epoch time: 27.21 s 
2025-08-30 16:59:04.558364:  
2025-08-30 16:59:04.559463: Epoch 568 
2025-08-30 16:59:04.565624: Current learning rate: 0.00047 
2025-08-30 16:59:32.136163: train_loss -0.632 
2025-08-30 16:59:32.136163: val_loss -0.5503 
2025-08-30 16:59:32.146867: Pseudo dice [np.float32(0.7502)] 
2025-08-30 16:59:32.150631: Epoch time: 27.58 s 
2025-08-30 16:59:32.958621:  
2025-08-30 16:59:32.958621: Epoch 569 
2025-08-30 16:59:32.968634: Current learning rate: 0.00047 
2025-08-30 17:00:00.641925: train_loss -0.5774 
2025-08-30 17:00:00.641925: val_loss -0.5558 
2025-08-30 17:00:00.647619: Pseudo dice [np.float32(0.7146)] 
2025-08-30 17:00:00.655989: Epoch time: 27.68 s 
2025-08-30 17:00:01.316035:  
2025-08-30 17:00:01.319099: Epoch 570 
2025-08-30 17:00:01.326082: Current learning rate: 0.00047 
2025-08-30 17:00:28.947097: train_loss -0.6082 
2025-08-30 17:00:28.950814: val_loss -0.5477 
2025-08-30 17:00:28.960888: Pseudo dice [np.float32(0.8026)] 
2025-08-30 17:00:28.967464: Epoch time: 27.63 s 
2025-08-30 17:00:29.623823:  
2025-08-30 17:00:29.623823: Epoch 571 
2025-08-30 17:00:29.633207: Current learning rate: 0.00047 
2025-08-30 17:00:57.216926: train_loss -0.6283 
2025-08-30 17:00:57.220704: val_loss -0.6544 
2025-08-30 17:00:57.229084: Pseudo dice [np.float32(0.7971)] 
2025-08-30 17:00:57.235065: Epoch time: 27.59 s 
2025-08-30 17:00:57.889475:  
2025-08-30 17:00:57.892223: Epoch 572 
2025-08-30 17:00:57.900600: Current learning rate: 0.00047 
2025-08-30 17:01:25.749132: train_loss -0.5969 
2025-08-30 17:01:25.749132: val_loss -0.6026 
2025-08-30 17:01:25.761972: Pseudo dice [np.float32(0.7921)] 
2025-08-30 17:01:25.767277: Epoch time: 27.86 s 
2025-08-30 17:01:26.446797:  
2025-08-30 17:01:26.446797: Epoch 573 
2025-08-30 17:01:26.458141: Current learning rate: 0.00046 
2025-08-30 17:01:53.631471: train_loss -0.597 
2025-08-30 17:01:53.631471: val_loss -0.5493 
2025-08-30 17:01:53.642173: Pseudo dice [np.float32(0.8029)] 
2025-08-30 17:01:53.649170: Epoch time: 27.18 s 
2025-08-30 17:01:54.333545:  
2025-08-30 17:01:54.333545: Epoch 574 
2025-08-30 17:01:54.342666: Current learning rate: 0.00046 
2025-08-30 17:02:21.868114: train_loss -0.6168 
2025-08-30 17:02:21.868114: val_loss -0.6149 
2025-08-30 17:02:21.876393: Pseudo dice [np.float32(0.8173)] 
2025-08-30 17:02:21.885071: Epoch time: 27.53 s 
2025-08-30 17:02:22.561033:  
2025-08-30 17:02:22.561033: Epoch 575 
2025-08-30 17:02:22.571584: Current learning rate: 0.00046 
2025-08-30 17:02:50.246995: train_loss -0.6086 
2025-08-30 17:02:50.246995: val_loss -0.6741 
2025-08-30 17:02:50.258514: Pseudo dice [np.float32(0.8229)] 
2025-08-30 17:02:50.263690: Epoch time: 27.69 s 
2025-08-30 17:02:51.093790:  
2025-08-30 17:02:51.093790: Epoch 576 
2025-08-30 17:02:51.102370: Current learning rate: 0.00046 
2025-08-30 17:03:18.521798: train_loss -0.6058 
2025-08-30 17:03:18.521798: val_loss -0.5741 
2025-08-30 17:03:18.529974: Pseudo dice [np.float32(0.7358)] 
2025-08-30 17:03:18.536556: Epoch time: 27.43 s 
2025-08-30 17:03:19.208151:  
2025-08-30 17:03:19.208151: Epoch 577 
2025-08-30 17:03:19.216465: Current learning rate: 0.00046 
2025-08-30 17:03:46.548539: train_loss -0.6436 
2025-08-30 17:03:46.548539: val_loss -0.6274 
2025-08-30 17:03:46.556677: Pseudo dice [np.float32(0.8022)] 
2025-08-30 17:03:46.562574: Epoch time: 27.34 s 
2025-08-30 17:03:47.241345:  
2025-08-30 17:03:47.244449: Epoch 578 
2025-08-30 17:03:47.251254: Current learning rate: 0.00046 
2025-08-30 17:04:14.926189: train_loss -0.6205 
2025-08-30 17:04:14.926189: val_loss -0.6407 
2025-08-30 17:04:14.937151: Pseudo dice [np.float32(0.8227)] 
2025-08-30 17:04:14.944086: Epoch time: 27.68 s 
2025-08-30 17:04:15.618559:  
2025-08-30 17:04:15.619651: Epoch 579 
2025-08-30 17:04:15.626862: Current learning rate: 0.00046 
2025-08-30 17:04:43.042073: train_loss -0.5817 
2025-08-30 17:04:43.042073: val_loss -0.6156 
2025-08-30 17:04:43.052760: Pseudo dice [np.float32(0.745)] 
2025-08-30 17:04:43.058332: Epoch time: 27.43 s 
2025-08-30 17:04:43.744067:  
2025-08-30 17:04:43.744067: Epoch 580 
2025-08-30 17:04:43.752426: Current learning rate: 0.00046 
2025-08-30 17:05:11.628951: train_loss -0.6485 
2025-08-30 17:05:11.628951: val_loss -0.6187 
2025-08-30 17:05:11.637367: Pseudo dice [np.float32(0.8041)] 
2025-08-30 17:05:11.643257: Epoch time: 27.88 s 
2025-08-30 17:05:12.314251:  
2025-08-30 17:05:12.314251: Epoch 581 
2025-08-30 17:05:12.323530: Current learning rate: 0.00046 
2025-08-30 17:05:39.965164: train_loss -0.6256 
2025-08-30 17:05:39.965164: val_loss -0.6553 
2025-08-30 17:05:39.978316: Pseudo dice [np.float32(0.8398)] 
2025-08-30 17:05:39.983328: Epoch time: 27.65 s 
2025-08-30 17:05:40.817913:  
2025-08-30 17:05:40.817913: Epoch 582 
2025-08-30 17:05:40.826880: Current learning rate: 0.00046 
2025-08-30 17:06:08.218819: train_loss -0.6166 
2025-08-30 17:06:08.218819: val_loss -0.5711 
2025-08-30 17:06:08.227490: Pseudo dice [np.float32(0.7648)] 
2025-08-30 17:06:08.233148: Epoch time: 27.4 s 
2025-08-30 17:06:08.903419:  
2025-08-30 17:06:08.903419: Epoch 583 
2025-08-30 17:06:08.912132: Current learning rate: 0.00046 
2025-08-30 17:06:36.605303: train_loss -0.629 
2025-08-30 17:06:36.605303: val_loss -0.6373 
2025-08-30 17:06:36.615913: Pseudo dice [np.float32(0.7978)] 
2025-08-30 17:06:36.621590: Epoch time: 27.7 s 
2025-08-30 17:06:37.360225:  
2025-08-30 17:06:37.360225: Epoch 584 
2025-08-30 17:06:37.368262: Current learning rate: 0.00045 
2025-08-30 17:07:04.641575: train_loss -0.625 
2025-08-30 17:07:04.641575: val_loss -0.6227 
2025-08-30 17:07:04.650364: Pseudo dice [np.float32(0.7954)] 
2025-08-30 17:07:04.655618: Epoch time: 27.29 s 
2025-08-30 17:07:05.330505:  
2025-08-30 17:07:05.330505: Epoch 585 
2025-08-30 17:07:05.339192: Current learning rate: 0.00045 
2025-08-30 17:07:32.899043: train_loss -0.6104 
2025-08-30 17:07:32.899043: val_loss -0.6352 
2025-08-30 17:07:32.911054: Pseudo dice [np.float32(0.7904)] 
2025-08-30 17:07:32.917051: Epoch time: 27.57 s 
2025-08-30 17:07:33.584416:  
2025-08-30 17:07:33.584416: Epoch 586 
2025-08-30 17:07:33.593443: Current learning rate: 0.00045 
2025-08-30 17:08:01.206381: train_loss -0.5699 
2025-08-30 17:08:01.206381: val_loss -0.6368 
2025-08-30 17:08:01.216064: Pseudo dice [np.float32(0.7815)] 
2025-08-30 17:08:01.222604: Epoch time: 27.62 s 
2025-08-30 17:08:01.912734:  
2025-08-30 17:08:01.912734: Epoch 587 
2025-08-30 17:08:01.922140: Current learning rate: 0.00045 
2025-08-30 17:08:29.659328: train_loss -0.5821 
2025-08-30 17:08:29.659659: val_loss -0.563 
2025-08-30 17:08:29.669404: Pseudo dice [np.float32(0.7593)] 
2025-08-30 17:08:29.673966: Epoch time: 27.75 s 
2025-08-30 17:08:30.340285:  
2025-08-30 17:08:30.340285: Epoch 588 
2025-08-30 17:08:30.351170: Current learning rate: 0.00045 
2025-08-30 17:08:57.779023: train_loss -0.6081 
2025-08-30 17:08:57.779373: val_loss -0.5745 
2025-08-30 17:08:57.787863: Pseudo dice [np.float32(0.7223)] 
2025-08-30 17:08:57.792930: Epoch time: 27.44 s 
2025-08-30 17:08:58.610967:  
2025-08-30 17:08:58.610967: Epoch 589 
2025-08-30 17:08:58.618959: Current learning rate: 0.00045 
2025-08-30 17:09:26.233037: train_loss -0.6257 
2025-08-30 17:09:26.233037: val_loss -0.6431 
2025-08-30 17:09:26.243885: Pseudo dice [np.float32(0.8078)] 
2025-08-30 17:09:26.249168: Epoch time: 27.63 s 
2025-08-30 17:09:26.926241:  
2025-08-30 17:09:26.926241: Epoch 590 
2025-08-30 17:09:26.935574: Current learning rate: 0.00045 
2025-08-30 17:09:54.589905: train_loss -0.6489 
2025-08-30 17:09:54.589905: val_loss -0.6101 
2025-08-30 17:09:54.601859: Pseudo dice [np.float32(0.8252)] 
2025-08-30 17:09:54.607493: Epoch time: 27.67 s 
2025-08-30 17:09:55.291650:  
2025-08-30 17:09:55.294736: Epoch 591 
2025-08-30 17:09:55.301786: Current learning rate: 0.00045 
2025-08-30 17:10:22.596939: train_loss -0.607 
2025-08-30 17:10:22.597313: val_loss -0.6131 
2025-08-30 17:10:22.605685: Pseudo dice [np.float32(0.7722)] 
2025-08-30 17:10:22.611622: Epoch time: 27.31 s 
2025-08-30 17:10:23.273725:  
2025-08-30 17:10:23.273725: Epoch 592 
2025-08-30 17:10:23.283454: Current learning rate: 0.00045 
2025-08-30 17:10:50.975289: train_loss -0.6099 
2025-08-30 17:10:50.975289: val_loss -0.6261 
2025-08-30 17:10:50.987853: Pseudo dice [np.float32(0.8214)] 
2025-08-30 17:10:50.992751: Epoch time: 27.7 s 
2025-08-30 17:10:51.682079:  
2025-08-30 17:10:51.682079: Epoch 593 
2025-08-30 17:10:51.689950: Current learning rate: 0.00045 
2025-08-30 17:11:19.212133: train_loss -0.5954 
2025-08-30 17:11:19.212133: val_loss -0.6304 
2025-08-30 17:11:19.222811: Pseudo dice [np.float32(0.7953)] 
2025-08-30 17:11:19.228394: Epoch time: 27.53 s 
2025-08-30 17:11:19.909364:  
2025-08-30 17:11:19.909364: Epoch 594 
2025-08-30 17:11:19.919231: Current learning rate: 0.00044 
2025-08-30 17:11:46.903018: train_loss -0.6206 
2025-08-30 17:11:46.903018: val_loss -0.5689 
2025-08-30 17:11:46.913929: Pseudo dice [np.float32(0.7941)] 
2025-08-30 17:11:46.920502: Epoch time: 26.99 s 
2025-08-30 17:11:47.752679:  
2025-08-30 17:11:47.752679: Epoch 595 
2025-08-30 17:11:47.760657: Current learning rate: 0.00044 
2025-08-30 17:12:15.185014: train_loss -0.6528 
2025-08-30 17:12:15.185014: val_loss -0.5794 
2025-08-30 17:12:15.195299: Pseudo dice [np.float32(0.7476)] 
2025-08-30 17:12:15.202326: Epoch time: 27.43 s 
2025-08-30 17:12:15.869377:  
2025-08-30 17:12:15.869377: Epoch 596 
2025-08-30 17:12:15.878029: Current learning rate: 0.00044 
2025-08-30 17:12:43.520848: train_loss -0.6133 
2025-08-30 17:12:43.520848: val_loss -0.6015 
2025-08-30 17:12:43.531310: Pseudo dice [np.float32(0.8313)] 
2025-08-30 17:12:43.537433: Epoch time: 27.65 s 
2025-08-30 17:12:44.219167:  
2025-08-30 17:12:44.219167: Epoch 597 
2025-08-30 17:12:44.228475: Current learning rate: 0.00044 
2025-08-30 17:13:11.579410: train_loss -0.6351 
2025-08-30 17:13:11.579410: val_loss -0.6469 
2025-08-30 17:13:11.587972: Pseudo dice [np.float32(0.7932)] 
2025-08-30 17:13:11.591925: Epoch time: 27.36 s 
2025-08-30 17:13:12.278677:  
2025-08-30 17:13:12.279759: Epoch 598 
2025-08-30 17:13:12.283939: Current learning rate: 0.00044 
2025-08-30 17:13:39.702164: train_loss -0.6144 
2025-08-30 17:13:39.702164: val_loss -0.634 
2025-08-30 17:13:39.715261: Pseudo dice [np.float32(0.7946)] 
2025-08-30 17:13:39.719368: Epoch time: 27.43 s 
2025-08-30 17:13:40.394162:  
2025-08-30 17:13:40.394162: Epoch 599 
2025-08-30 17:13:40.401190: Current learning rate: 0.00044 
2025-08-30 17:14:07.863237: train_loss -0.6317 
2025-08-30 17:14:07.863237: val_loss -0.6306 
2025-08-30 17:14:07.873262: Pseudo dice [np.float32(0.7645)] 
2025-08-30 17:14:07.879517: Epoch time: 27.47 s 
2025-08-30 17:14:08.840642:  
2025-08-30 17:14:08.840642: Epoch 600 
2025-08-30 17:14:08.850036: Current learning rate: 0.00044 
2025-08-30 17:14:36.233554: train_loss -0.5975 
2025-08-30 17:14:36.233554: val_loss -0.6013 
2025-08-30 17:14:36.246578: Pseudo dice [np.float32(0.7634)] 
2025-08-30 17:14:36.253088: Epoch time: 27.39 s 
2025-08-30 17:14:36.918613:  
2025-08-30 17:14:36.918613: Epoch 601 
2025-08-30 17:14:36.929805: Current learning rate: 0.00044 
2025-08-30 17:15:04.645264: train_loss -0.616 
2025-08-30 17:15:04.645264: val_loss -0.5836 
2025-08-30 17:15:04.654906: Pseudo dice [np.float32(0.773)] 
2025-08-30 17:15:04.659612: Epoch time: 27.73 s 
2025-08-30 17:15:05.496804:  
2025-08-30 17:15:05.496804: Epoch 602 
2025-08-30 17:15:05.505528: Current learning rate: 0.00044 
2025-08-30 17:15:32.752050: train_loss -0.6461 
2025-08-30 17:15:32.752050: val_loss -0.5698 
2025-08-30 17:15:32.766212: Pseudo dice [np.float32(0.7736)] 
2025-08-30 17:15:32.770873: Epoch time: 27.26 s 
2025-08-30 17:15:33.441311:  
2025-08-30 17:15:33.441311: Epoch 603 
2025-08-30 17:15:33.450484: Current learning rate: 0.00044 
2025-08-30 17:16:01.239223: train_loss -0.5941 
2025-08-30 17:16:01.239223: val_loss -0.5938 
2025-08-30 17:16:01.249856: Pseudo dice [np.float32(0.8052)] 
2025-08-30 17:16:01.255437: Epoch time: 27.8 s 
2025-08-30 17:16:01.961787:  
2025-08-30 17:16:01.961787: Epoch 604 
2025-08-30 17:16:01.970240: Current learning rate: 0.00043 
2025-08-30 17:16:29.350927: train_loss -0.6008 
2025-08-30 17:16:29.350927: val_loss -0.5379 
2025-08-30 17:16:29.362105: Pseudo dice [np.float32(0.8069)] 
2025-08-30 17:16:29.367663: Epoch time: 27.39 s 
2025-08-30 17:16:30.035275:  
2025-08-30 17:16:30.038358: Epoch 605 
2025-08-30 17:16:30.046263: Current learning rate: 0.00043 
2025-08-30 17:16:57.474413: train_loss -0.623 
2025-08-30 17:16:57.474413: val_loss -0.6775 
2025-08-30 17:16:57.485169: Pseudo dice [np.float32(0.8106)] 
2025-08-30 17:16:57.491637: Epoch time: 27.44 s 
2025-08-30 17:16:58.167489:  
2025-08-30 17:16:58.167489: Epoch 606 
2025-08-30 17:16:58.175860: Current learning rate: 0.00043 
2025-08-30 17:17:25.585898: train_loss -0.6201 
2025-08-30 17:17:25.585898: val_loss -0.6799 
2025-08-30 17:17:25.597417: Pseudo dice [np.float32(0.8445)] 
2025-08-30 17:17:25.603434: Epoch time: 27.42 s 
2025-08-30 17:17:25.608083: Yayy! New best EMA pseudo Dice: 0.7954000234603882 
2025-08-30 17:17:26.513149:  
2025-08-30 17:17:26.515488: Epoch 607 
2025-08-30 17:17:26.523516: Current learning rate: 0.00043 
2025-08-30 17:17:54.685230: train_loss -0.6516 
2025-08-30 17:17:54.685230: val_loss -0.5664 
2025-08-30 17:17:54.693919: Pseudo dice [np.float32(0.8328)] 
2025-08-30 17:17:54.699228: Epoch time: 28.17 s 
2025-08-30 17:17:54.707021: Yayy! New best EMA pseudo Dice: 0.7991999983787537 
2025-08-30 17:17:55.823920:  
2025-08-30 17:17:55.823920: Epoch 608 
2025-08-30 17:17:55.832252: Current learning rate: 0.00043 
2025-08-30 17:18:23.390565: train_loss -0.6301 
2025-08-30 17:18:23.390565: val_loss -0.575 
2025-08-30 17:18:23.398877: Pseudo dice [np.float32(0.7885)] 
2025-08-30 17:18:23.405486: Epoch time: 27.57 s 
2025-08-30 17:18:24.097924:  
2025-08-30 17:18:24.099015: Epoch 609 
2025-08-30 17:18:24.108758: Current learning rate: 0.00043 
2025-08-30 17:18:51.863514: train_loss -0.6606 
2025-08-30 17:18:51.863514: val_loss -0.5711 
2025-08-30 17:18:51.874130: Pseudo dice [np.float32(0.8179)] 
2025-08-30 17:18:51.879717: Epoch time: 27.77 s 
2025-08-30 17:18:51.885630: Yayy! New best EMA pseudo Dice: 0.8001000285148621 
2025-08-30 17:18:52.769299:  
2025-08-30 17:18:52.769299: Epoch 610 
2025-08-30 17:18:52.777948: Current learning rate: 0.00043 
2025-08-30 17:19:20.713034: train_loss -0.6013 
2025-08-30 17:19:20.716835: val_loss -0.5712 
2025-08-30 17:19:20.721356: Pseudo dice [np.float32(0.7488)] 
2025-08-30 17:19:20.730210: Epoch time: 27.95 s 
2025-08-30 17:19:21.406171:  
2025-08-30 17:19:21.406171: Epoch 611 
2025-08-30 17:19:21.416097: Current learning rate: 0.00043 
2025-08-30 17:19:48.958482: train_loss -0.6181 
2025-08-30 17:19:48.958482: val_loss -0.6388 
2025-08-30 17:19:48.969558: Pseudo dice [np.float32(0.7805)] 
2025-08-30 17:19:48.976024: Epoch time: 27.55 s 
2025-08-30 17:19:49.655199:  
2025-08-30 17:19:49.655199: Epoch 612 
2025-08-30 17:19:49.664218: Current learning rate: 0.00043 
2025-08-30 17:20:17.310785: train_loss -0.618 
2025-08-30 17:20:17.310785: val_loss -0.6313 
2025-08-30 17:20:17.320769: Pseudo dice [np.float32(0.8245)] 
2025-08-30 17:20:17.327423: Epoch time: 27.66 s 
2025-08-30 17:20:18.017115:  
2025-08-30 17:20:18.017115: Epoch 613 
2025-08-30 17:20:18.026525: Current learning rate: 0.00043 
2025-08-30 17:20:45.760377: train_loss -0.6344 
2025-08-30 17:20:45.760377: val_loss -0.6632 
2025-08-30 17:20:45.774231: Pseudo dice [np.float32(0.8559)] 
2025-08-30 17:20:45.778141: Epoch time: 27.74 s 
2025-08-30 17:20:45.786493: Yayy! New best EMA pseudo Dice: 0.8025000095367432 
2025-08-30 17:20:46.670355:  
2025-08-30 17:20:46.670355: Epoch 614 
2025-08-30 17:20:46.680355: Current learning rate: 0.00042 
2025-08-30 17:21:14.225864: train_loss -0.6297 
2025-08-30 17:21:14.226193: val_loss -0.5836 
2025-08-30 17:21:14.234691: Pseudo dice [np.float32(0.7587)] 
2025-08-30 17:21:14.239315: Epoch time: 27.56 s 
2025-08-30 17:21:14.906865:  
2025-08-30 17:21:14.906865: Epoch 615 
2025-08-30 17:21:14.914071: Current learning rate: 0.00042 
2025-08-30 17:21:42.429016: train_loss -0.5986 
2025-08-30 17:21:42.429016: val_loss -0.602 
2025-08-30 17:21:42.439931: Pseudo dice [np.float32(0.7767)] 
2025-08-30 17:21:42.445625: Epoch time: 27.53 s 
2025-08-30 17:21:43.109978:  
2025-08-30 17:21:43.109978: Epoch 616 
2025-08-30 17:21:43.118283: Current learning rate: 0.00042 
2025-08-30 17:22:11.458490: train_loss -0.6034 
2025-08-30 17:22:11.458490: val_loss -0.6726 
2025-08-30 17:22:11.466954: Pseudo dice [np.float32(0.81)] 
2025-08-30 17:22:11.473047: Epoch time: 28.35 s 
2025-08-30 17:22:12.151418:  
2025-08-30 17:22:12.151418: Epoch 617 
2025-08-30 17:22:12.160191: Current learning rate: 0.00042 
2025-08-30 17:22:39.703515: train_loss -0.6435 
2025-08-30 17:22:39.703515: val_loss -0.628 
2025-08-30 17:22:39.719434: Pseudo dice [np.float32(0.7684)] 
2025-08-30 17:22:39.729498: Epoch time: 27.55 s 
2025-08-30 17:22:40.429584:  
2025-08-30 17:22:40.429584: Epoch 618 
2025-08-30 17:22:40.439329: Current learning rate: 0.00042 
2025-08-30 17:23:08.298406: train_loss -0.6101 
2025-08-30 17:23:08.298406: val_loss -0.6277 
2025-08-30 17:23:08.308980: Pseudo dice [np.float32(0.8241)] 
2025-08-30 17:23:08.315512: Epoch time: 27.87 s 
2025-08-30 17:23:09.027843:  
2025-08-30 17:23:09.027843: Epoch 619 
2025-08-30 17:23:09.036196: Current learning rate: 0.00042 
2025-08-30 17:23:36.438821: train_loss -0.6262 
2025-08-30 17:23:36.442731: val_loss -0.662 
2025-08-30 17:23:36.452664: Pseudo dice [np.float32(0.8193)] 
2025-08-30 17:23:36.456606: Epoch time: 27.41 s 
2025-08-30 17:23:37.145175:  
2025-08-30 17:23:37.145175: Epoch 620 
2025-08-30 17:23:37.154272: Current learning rate: 0.00042 
2025-08-30 17:24:04.892221: train_loss -0.6211 
2025-08-30 17:24:04.892221: val_loss -0.5634 
2025-08-30 17:24:04.900689: Pseudo dice [np.float32(0.805)] 
2025-08-30 17:24:04.905313: Epoch time: 27.75 s 
2025-08-30 17:24:05.759428:  
2025-08-30 17:24:05.760527: Epoch 621 
2025-08-30 17:24:05.768843: Current learning rate: 0.00042 
2025-08-30 17:24:33.345592: train_loss -0.5944 
2025-08-30 17:24:33.345592: val_loss -0.555 
2025-08-30 17:24:33.357824: Pseudo dice [np.float32(0.7796)] 
2025-08-30 17:24:33.362793: Epoch time: 27.59 s 
2025-08-30 17:24:34.068440:  
2025-08-30 17:24:34.068440: Epoch 622 
2025-08-30 17:24:34.076665: Current learning rate: 0.00042 
2025-08-30 17:25:01.769866: train_loss -0.6509 
2025-08-30 17:25:01.769866: val_loss -0.632 
2025-08-30 17:25:01.778080: Pseudo dice [np.float32(0.8036)] 
2025-08-30 17:25:01.786066: Epoch time: 27.7 s 
2025-08-30 17:25:02.459413:  
2025-08-30 17:25:02.459413: Epoch 623 
2025-08-30 17:25:02.467536: Current learning rate: 0.00042 
2025-08-30 17:25:29.797724: train_loss -0.6167 
2025-08-30 17:25:29.797724: val_loss -0.556 
2025-08-30 17:25:29.808521: Pseudo dice [np.float32(0.7677)] 
2025-08-30 17:25:29.815028: Epoch time: 27.34 s 
2025-08-30 17:25:30.499195:  
2025-08-30 17:25:30.499195: Epoch 624 
2025-08-30 17:25:30.507530: Current learning rate: 0.00041 
2025-08-30 17:25:58.234524: train_loss -0.6092 
2025-08-30 17:25:58.234524: val_loss -0.6 
2025-08-30 17:25:58.244019: Pseudo dice [np.float32(0.8115)] 
2025-08-30 17:25:58.248013: Epoch time: 27.74 s 
2025-08-30 17:25:58.972331:  
2025-08-30 17:25:58.972331: Epoch 625 
2025-08-30 17:25:58.980666: Current learning rate: 0.00041 
2025-08-30 17:26:26.737834: train_loss -0.6248 
2025-08-30 17:26:26.737834: val_loss -0.4897 
2025-08-30 17:26:26.748423: Pseudo dice [np.float32(0.7925)] 
2025-08-30 17:26:26.754128: Epoch time: 27.77 s 
2025-08-30 17:26:27.443441:  
2025-08-30 17:26:27.443441: Epoch 626 
2025-08-30 17:26:27.452306: Current learning rate: 0.00041 
2025-08-30 17:26:54.682014: train_loss -0.6257 
2025-08-30 17:26:54.682014: val_loss -0.6243 
2025-08-30 17:26:54.692022: Pseudo dice [np.float32(0.8233)] 
2025-08-30 17:26:54.695966: Epoch time: 27.24 s 
2025-08-30 17:26:55.370188:  
2025-08-30 17:26:55.370188: Epoch 627 
2025-08-30 17:26:55.378595: Current learning rate: 0.00041 
2025-08-30 17:27:23.165112: train_loss -0.6361 
2025-08-30 17:27:23.165112: val_loss -0.6357 
2025-08-30 17:27:23.174538: Pseudo dice [np.float32(0.8197)] 
2025-08-30 17:27:23.179632: Epoch time: 27.8 s 
2025-08-30 17:27:23.873656:  
2025-08-30 17:27:23.873656: Epoch 628 
2025-08-30 17:27:23.884292: Current learning rate: 0.00041 
2025-08-30 17:27:51.484972: train_loss -0.6191 
2025-08-30 17:27:51.484972: val_loss -0.6293 
2025-08-30 17:27:51.495538: Pseudo dice [np.float32(0.769)] 
2025-08-30 17:27:51.501115: Epoch time: 27.61 s 
2025-08-30 17:27:52.169600:  
2025-08-30 17:27:52.169600: Epoch 629 
2025-08-30 17:27:52.180449: Current learning rate: 0.00041 
2025-08-30 17:28:19.783933: train_loss -0.6033 
2025-08-30 17:28:19.783933: val_loss -0.6142 
2025-08-30 17:28:19.794494: Pseudo dice [np.float32(0.8236)] 
2025-08-30 17:28:19.800156: Epoch time: 27.61 s 
2025-08-30 17:28:20.476980:  
2025-08-30 17:28:20.477788: Epoch 630 
2025-08-30 17:28:20.486140: Current learning rate: 0.00041 
2025-08-30 17:28:48.095519: train_loss -0.5943 
2025-08-30 17:28:48.095519: val_loss -0.5643 
2025-08-30 17:28:48.108476: Pseudo dice [np.float32(0.8285)] 
2025-08-30 17:28:48.112758: Epoch time: 27.62 s 
2025-08-30 17:28:48.120884: Yayy! New best EMA pseudo Dice: 0.8034999966621399 
2025-08-30 17:28:49.014667:  
2025-08-30 17:28:49.014667: Epoch 631 
2025-08-30 17:28:49.022530: Current learning rate: 0.00041 
2025-08-30 17:29:16.611402: train_loss -0.5938 
2025-08-30 17:29:16.611402: val_loss -0.618 
2025-08-30 17:29:16.621156: Pseudo dice [np.float32(0.7689)] 
2025-08-30 17:29:16.627675: Epoch time: 27.6 s 
2025-08-30 17:29:17.299233:  
2025-08-30 17:29:17.299233: Epoch 632 
2025-08-30 17:29:17.307594: Current learning rate: 0.00041 
2025-08-30 17:29:44.476740: train_loss -0.601 
2025-08-30 17:29:44.476740: val_loss -0.6966 
2025-08-30 17:29:44.489285: Pseudo dice [np.float32(0.8166)] 
2025-08-30 17:29:44.495303: Epoch time: 27.18 s 
2025-08-30 17:29:45.181200:  
2025-08-30 17:29:45.181200: Epoch 633 
2025-08-30 17:29:45.189557: Current learning rate: 0.00041 
2025-08-30 17:30:12.767394: train_loss -0.6262 
2025-08-30 17:30:12.771543: val_loss -0.6416 
2025-08-30 17:30:12.779557: Pseudo dice [np.float32(0.7713)] 
2025-08-30 17:30:12.785486: Epoch time: 27.59 s 
2025-08-30 17:30:13.610659:  
2025-08-30 17:30:13.610659: Epoch 634 
2025-08-30 17:30:13.617921: Current learning rate: 0.0004 
2025-08-30 17:30:41.074792: train_loss -0.603 
2025-08-30 17:30:41.074792: val_loss -0.5828 
2025-08-30 17:30:41.088598: Pseudo dice [np.float32(0.7969)] 
2025-08-30 17:30:41.092073: Epoch time: 27.47 s 
2025-08-30 17:30:41.793688:  
2025-08-30 17:30:41.794554: Epoch 635 
2025-08-30 17:30:41.805338: Current learning rate: 0.0004 
2025-08-30 17:31:09.064827: train_loss -0.6421 
2025-08-30 17:31:09.064827: val_loss -0.6698 
2025-08-30 17:31:09.075749: Pseudo dice [np.float32(0.8229)] 
2025-08-30 17:31:09.081458: Epoch time: 27.27 s 
2025-08-30 17:31:09.799474:  
2025-08-30 17:31:09.799474: Epoch 636 
2025-08-30 17:31:09.808359: Current learning rate: 0.0004 
2025-08-30 17:31:37.289250: train_loss -0.6276 
2025-08-30 17:31:37.289250: val_loss -0.64 
2025-08-30 17:31:37.301407: Pseudo dice [np.float32(0.8053)] 
2025-08-30 17:31:37.306457: Epoch time: 27.49 s 
2025-08-30 17:31:37.979179:  
2025-08-30 17:31:37.979179: Epoch 637 
2025-08-30 17:31:37.986890: Current learning rate: 0.0004 
2025-08-30 17:32:05.384265: train_loss -0.6414 
2025-08-30 17:32:05.384265: val_loss -0.6184 
2025-08-30 17:32:05.393500: Pseudo dice [np.float32(0.81)] 
2025-08-30 17:32:05.398599: Epoch time: 27.41 s 
2025-08-30 17:32:06.072444:  
2025-08-30 17:32:06.073589: Epoch 638 
2025-08-30 17:32:06.081602: Current learning rate: 0.0004 
2025-08-30 17:32:33.545509: train_loss -0.6252 
2025-08-30 17:32:33.549472: val_loss -0.6635 
2025-08-30 17:32:33.559176: Pseudo dice [np.float32(0.8359)] 
2025-08-30 17:32:33.565696: Epoch time: 27.47 s 
2025-08-30 17:32:33.571487: Yayy! New best EMA pseudo Dice: 0.8055999875068665 
2025-08-30 17:32:34.455244:  
2025-08-30 17:32:34.455244: Epoch 639 
2025-08-30 17:32:34.466170: Current learning rate: 0.0004 
2025-08-30 17:33:02.211444: train_loss -0.628 
2025-08-30 17:33:02.215159: val_loss -0.6059 
2025-08-30 17:33:02.223519: Pseudo dice [np.float32(0.7854)] 
2025-08-30 17:33:02.229536: Epoch time: 27.76 s 
2025-08-30 17:33:03.049305:  
2025-08-30 17:33:03.049305: Epoch 640 
2025-08-30 17:33:03.054596: Current learning rate: 0.0004 
2025-08-30 17:33:30.794009: train_loss -0.6298 
2025-08-30 17:33:30.794009: val_loss -0.6723 
2025-08-30 17:33:30.804749: Pseudo dice [np.float32(0.8098)] 
2025-08-30 17:33:30.811302: Epoch time: 27.75 s 
2025-08-30 17:33:31.478804:  
2025-08-30 17:33:31.478804: Epoch 641 
2025-08-30 17:33:31.487565: Current learning rate: 0.0004 
2025-08-30 17:33:59.205320: train_loss -0.6552 
2025-08-30 17:33:59.205320: val_loss -0.685 
2025-08-30 17:33:59.215273: Pseudo dice [np.float32(0.8071)] 
2025-08-30 17:33:59.221952: Epoch time: 27.73 s 
2025-08-30 17:33:59.902933:  
2025-08-30 17:33:59.902933: Epoch 642 
2025-08-30 17:33:59.910200: Current learning rate: 0.0004 
2025-08-30 17:34:27.467226: train_loss -0.6747 
2025-08-30 17:34:27.467226: val_loss -0.5516 
2025-08-30 17:34:27.480251: Pseudo dice [np.float32(0.7969)] 
2025-08-30 17:34:27.484473: Epoch time: 27.57 s 
2025-08-30 17:34:28.168639:  
2025-08-30 17:34:28.171737: Epoch 643 
2025-08-30 17:34:28.179539: Current learning rate: 0.0004 
2025-08-30 17:34:55.269899: train_loss -0.6168 
2025-08-30 17:34:55.269899: val_loss -0.6119 
2025-08-30 17:34:55.279607: Pseudo dice [np.float32(0.8008)] 
2025-08-30 17:34:55.284265: Epoch time: 27.1 s 
2025-08-30 17:34:55.966073:  
2025-08-30 17:34:55.966073: Epoch 644 
2025-08-30 17:34:55.974465: Current learning rate: 0.00039 
2025-08-30 17:35:23.285449: train_loss -0.6258 
2025-08-30 17:35:23.285449: val_loss -0.6408 
2025-08-30 17:35:23.294967: Pseudo dice [np.float32(0.8396)] 
2025-08-30 17:35:23.298975: Epoch time: 27.32 s 
2025-08-30 17:35:23.306635: Yayy! New best EMA pseudo Dice: 0.8070999979972839 
2025-08-30 17:35:24.216912:  
2025-08-30 17:35:24.216912: Epoch 645 
2025-08-30 17:35:24.228693: Current learning rate: 0.00039 
2025-08-30 17:35:52.113727: train_loss -0.6201 
2025-08-30 17:35:52.113727: val_loss -0.5218 
2025-08-30 17:35:52.123714: Pseudo dice [np.float32(0.8015)] 
2025-08-30 17:35:52.130358: Epoch time: 27.9 s 
2025-08-30 17:35:52.974729:  
2025-08-30 17:35:52.974729: Epoch 646 
2025-08-30 17:35:52.983295: Current learning rate: 0.00039 
2025-08-30 17:36:20.313017: train_loss -0.6189 
2025-08-30 17:36:20.313017: val_loss -0.6192 
2025-08-30 17:36:20.321499: Pseudo dice [np.float32(0.8029)] 
2025-08-30 17:36:20.326640: Epoch time: 27.34 s 
2025-08-30 17:36:21.001955:  
2025-08-30 17:36:21.001955: Epoch 647 
2025-08-30 17:36:21.010726: Current learning rate: 0.00039 
2025-08-30 17:36:48.741391: train_loss -0.62 
2025-08-30 17:36:48.741391: val_loss -0.6378 
2025-08-30 17:36:48.753595: Pseudo dice [np.float32(0.7297)] 
2025-08-30 17:36:48.758622: Epoch time: 27.74 s 
2025-08-30 17:36:49.442841:  
2025-08-30 17:36:49.442841: Epoch 648 
2025-08-30 17:36:49.451206: Current learning rate: 0.00039 
2025-08-30 17:37:16.998762: train_loss -0.6418 
2025-08-30 17:37:17.002554: val_loss -0.6093 
2025-08-30 17:37:17.007150: Pseudo dice [np.float32(0.8284)] 
2025-08-30 17:37:17.016571: Epoch time: 27.56 s 
2025-08-30 17:37:17.704372:  
2025-08-30 17:37:17.704372: Epoch 649 
2025-08-30 17:37:17.714339: Current learning rate: 0.00039 
2025-08-30 17:37:45.222744: train_loss -0.6023 
2025-08-30 17:37:45.226862: val_loss -0.5553 
2025-08-30 17:37:45.236669: Pseudo dice [np.float32(0.7857)] 
2025-08-30 17:37:45.241296: Epoch time: 27.52 s 
2025-08-30 17:37:46.120220:  
2025-08-30 17:37:46.120220: Epoch 650 
2025-08-30 17:37:46.131089: Current learning rate: 0.00039 
2025-08-30 17:38:13.346599: train_loss -0.6369 
2025-08-30 17:38:13.346599: val_loss -0.5893 
2025-08-30 17:38:13.354984: Pseudo dice [np.float32(0.7996)] 
2025-08-30 17:38:13.376412: Epoch time: 27.23 s 
2025-08-30 17:38:14.076159:  
2025-08-30 17:38:14.077240: Epoch 651 
2025-08-30 17:38:14.085582: Current learning rate: 0.00039 
2025-08-30 17:38:41.933413: train_loss -0.6274 
2025-08-30 17:38:41.933413: val_loss -0.5768 
2025-08-30 17:38:41.946451: Pseudo dice [np.float32(0.7873)] 
2025-08-30 17:38:41.950714: Epoch time: 27.86 s 
2025-08-30 17:38:42.793752:  
2025-08-30 17:38:42.793752: Epoch 652 
2025-08-30 17:38:42.802109: Current learning rate: 0.00039 
2025-08-30 17:39:10.366521: train_loss -0.6359 
2025-08-30 17:39:10.366521: val_loss -0.6251 
2025-08-30 17:39:10.374388: Pseudo dice [np.float32(0.8408)] 
2025-08-30 17:39:10.380336: Epoch time: 27.57 s 
2025-08-30 17:39:11.063250:  
2025-08-30 17:39:11.063250: Epoch 653 
2025-08-30 17:39:11.071955: Current learning rate: 0.00039 
2025-08-30 17:39:38.581657: train_loss -0.6314 
2025-08-30 17:39:38.585721: val_loss -0.6609 
2025-08-30 17:39:38.595447: Pseudo dice [np.float32(0.8075)] 
2025-08-30 17:39:38.600142: Epoch time: 27.52 s 
2025-08-30 17:39:39.281919:  
2025-08-30 17:39:39.283306: Epoch 654 
2025-08-30 17:39:39.290263: Current learning rate: 0.00038 
2025-08-30 17:40:07.189355: train_loss -0.6184 
2025-08-30 17:40:07.189355: val_loss -0.5134 
2025-08-30 17:40:07.200972: Pseudo dice [np.float32(0.7108)] 
2025-08-30 17:40:07.206984: Epoch time: 27.91 s 
2025-08-30 17:40:07.890722:  
2025-08-30 17:40:07.890722: Epoch 655 
2025-08-30 17:40:07.900587: Current learning rate: 0.00038 
2025-08-30 17:40:35.054194: train_loss -0.6149 
2025-08-30 17:40:35.054569: val_loss -0.5787 
2025-08-30 17:40:35.065218: Pseudo dice [np.float32(0.798)] 
2025-08-30 17:40:35.070823: Epoch time: 27.16 s 
2025-08-30 17:40:35.750723:  
2025-08-30 17:40:35.750723: Epoch 656 
2025-08-30 17:40:35.758647: Current learning rate: 0.00038 
2025-08-30 17:41:03.466239: train_loss -0.6322 
2025-08-30 17:41:03.470012: val_loss -0.5374 
2025-08-30 17:41:03.478398: Pseudo dice [np.float32(0.8196)] 
2025-08-30 17:41:03.484393: Epoch time: 27.72 s 
2025-08-30 17:41:04.163479:  
2025-08-30 17:41:04.163479: Epoch 657 
2025-08-30 17:41:04.174423: Current learning rate: 0.00038 
2025-08-30 17:41:32.007232: train_loss -0.6129 
2025-08-30 17:41:32.007232: val_loss -0.7135 
2025-08-30 17:41:32.017803: Pseudo dice [np.float32(0.8288)] 
2025-08-30 17:41:32.024838: Epoch time: 27.84 s 
2025-08-30 17:41:32.700285:  
2025-08-30 17:41:32.700285: Epoch 658 
2025-08-30 17:41:32.710074: Current learning rate: 0.00038 
2025-08-30 17:42:00.468567: train_loss -0.6453 
2025-08-30 17:42:00.468567: val_loss -0.6495 
2025-08-30 17:42:00.478511: Pseudo dice [np.float32(0.7637)] 
2025-08-30 17:42:00.485161: Epoch time: 27.77 s 
2025-08-30 17:42:01.169232:  
2025-08-30 17:42:01.170349: Epoch 659 
2025-08-30 17:42:01.177605: Current learning rate: 0.00038 
2025-08-30 17:42:29.018198: train_loss -0.6449 
2025-08-30 17:42:29.018198: val_loss -0.613 
2025-08-30 17:42:29.031296: Pseudo dice [np.float32(0.7848)] 
2025-08-30 17:42:29.035427: Epoch time: 27.85 s 
2025-08-30 17:42:29.707105:  
2025-08-30 17:42:29.707105: Epoch 660 
2025-08-30 17:42:29.716959: Current learning rate: 0.00038 
2025-08-30 17:42:57.793511: train_loss -0.6413 
2025-08-30 17:42:57.793511: val_loss -0.5519 
2025-08-30 17:42:57.801146: Pseudo dice [np.float32(0.7998)] 
2025-08-30 17:42:57.806216: Epoch time: 28.09 s 
2025-08-30 17:42:58.485862:  
2025-08-30 17:42:58.485862: Epoch 661 
2025-08-30 17:42:58.494545: Current learning rate: 0.00038 
2025-08-30 17:43:25.812562: train_loss -0.5991 
2025-08-30 17:43:25.812562: val_loss -0.6057 
2025-08-30 17:43:25.825352: Pseudo dice [np.float32(0.7323)] 
2025-08-30 17:43:25.829528: Epoch time: 27.33 s 
2025-08-30 17:43:26.509573:  
2025-08-30 17:43:26.509573: Epoch 662 
2025-08-30 17:43:26.519889: Current learning rate: 0.00038 
2025-08-30 17:43:54.269927: train_loss -0.6037 
2025-08-30 17:43:54.269927: val_loss -0.5686 
2025-08-30 17:43:54.279556: Pseudo dice [np.float32(0.7794)] 
2025-08-30 17:43:54.286139: Epoch time: 27.76 s 
2025-08-30 17:43:54.972022:  
2025-08-30 17:43:54.974378: Epoch 663 
2025-08-30 17:43:54.981276: Current learning rate: 0.00038 
2025-08-30 17:44:22.548058: train_loss -0.6272 
2025-08-30 17:44:22.548058: val_loss -0.6271 
2025-08-30 17:44:22.558728: Pseudo dice [np.float32(0.7815)] 
2025-08-30 17:44:22.565310: Epoch time: 27.58 s 
2025-08-30 17:44:23.241158:  
2025-08-30 17:44:23.244236: Epoch 664 
2025-08-30 17:44:23.252055: Current learning rate: 0.00037 
2025-08-30 17:44:50.926344: train_loss -0.6278 
2025-08-30 17:44:50.926344: val_loss -0.6949 
2025-08-30 17:44:50.939911: Pseudo dice [np.float32(0.8251)] 
2025-08-30 17:44:50.943538: Epoch time: 27.69 s 
2025-08-30 17:44:51.773795:  
2025-08-30 17:44:51.773795: Epoch 665 
2025-08-30 17:44:51.782114: Current learning rate: 0.00037 
2025-08-30 17:45:19.546196: train_loss -0.6143 
2025-08-30 17:45:19.546196: val_loss -0.6198 
2025-08-30 17:45:19.557194: Pseudo dice [np.float32(0.8063)] 
2025-08-30 17:45:19.562845: Epoch time: 27.78 s 
2025-08-30 17:45:20.247998:  
2025-08-30 17:45:20.247998: Epoch 666 
2025-08-30 17:45:20.256340: Current learning rate: 0.00037 
2025-08-30 17:45:48.363519: train_loss -0.6121 
2025-08-30 17:45:48.364518: val_loss -0.6391 
2025-08-30 17:45:48.373472: Pseudo dice [np.float32(0.7877)] 
2025-08-30 17:45:48.379069: Epoch time: 28.12 s 
2025-08-30 17:45:49.065053:  
2025-08-30 17:45:49.065053: Epoch 667 
2025-08-30 17:45:49.072989: Current learning rate: 0.00037 
2025-08-30 17:46:16.273906: train_loss -0.636 
2025-08-30 17:46:16.273906: val_loss -0.5893 
2025-08-30 17:46:16.284583: Pseudo dice [np.float32(0.7909)] 
2025-08-30 17:46:16.291252: Epoch time: 27.21 s 
2025-08-30 17:46:16.988711:  
2025-08-30 17:46:16.988711: Epoch 668 
2025-08-30 17:46:16.997722: Current learning rate: 0.00037 
2025-08-30 17:46:44.560742: train_loss -0.6513 
2025-08-30 17:46:44.560742: val_loss -0.6239 
2025-08-30 17:46:44.568898: Pseudo dice [np.float32(0.7656)] 
2025-08-30 17:46:44.574130: Epoch time: 27.57 s 
2025-08-30 17:46:45.266844:  
2025-08-30 17:46:45.269180: Epoch 669 
2025-08-30 17:46:45.277084: Current learning rate: 0.00037 
2025-08-30 17:47:12.876185: train_loss -0.6122 
2025-08-30 17:47:12.876185: val_loss -0.6905 
2025-08-30 17:47:12.886966: Pseudo dice [np.float32(0.8461)] 
2025-08-30 17:47:12.892495: Epoch time: 27.61 s 
2025-08-30 17:47:13.578021:  
2025-08-30 17:47:13.578021: Epoch 670 
2025-08-30 17:47:13.587410: Current learning rate: 0.00037 
2025-08-30 17:47:40.979879: train_loss -0.6345 
2025-08-30 17:47:40.979879: val_loss -0.6649 
2025-08-30 17:47:40.990957: Pseudo dice [np.float32(0.8284)] 
2025-08-30 17:47:40.996444: Epoch time: 27.4 s 
2025-08-30 17:47:41.702265:  
2025-08-30 17:47:41.702265: Epoch 671 
2025-08-30 17:47:41.711586: Current learning rate: 0.00037 
2025-08-30 17:48:09.574457: train_loss -0.6415 
2025-08-30 17:48:09.574457: val_loss -0.657 
2025-08-30 17:48:09.584150: Pseudo dice [np.float32(0.7902)] 
2025-08-30 17:48:09.588098: Epoch time: 27.87 s 
2025-08-30 17:48:10.433256:  
2025-08-30 17:48:10.433256: Epoch 672 
2025-08-30 17:48:10.441637: Current learning rate: 0.00037 
2025-08-30 17:48:38.024358: train_loss -0.6025 
2025-08-30 17:48:38.024358: val_loss -0.6304 
2025-08-30 17:48:38.034351: Pseudo dice [np.float32(0.8019)] 
2025-08-30 17:48:38.041323: Epoch time: 27.59 s 
2025-08-30 17:48:38.729294:  
2025-08-30 17:48:38.729294: Epoch 673 
2025-08-30 17:48:38.738978: Current learning rate: 0.00037 
2025-08-30 17:49:06.060447: train_loss -0.6136 
2025-08-30 17:49:06.060447: val_loss -0.6078 
2025-08-30 17:49:06.068370: Pseudo dice [np.float32(0.7762)] 
2025-08-30 17:49:06.074868: Epoch time: 27.33 s 
2025-08-30 17:49:06.756089:  
2025-08-30 17:49:06.756089: Epoch 674 
2025-08-30 17:49:06.764533: Current learning rate: 0.00036 
2025-08-30 17:49:34.596693: train_loss -0.6453 
2025-08-30 17:49:34.596693: val_loss -0.5855 
2025-08-30 17:49:34.607466: Pseudo dice [np.float32(0.7938)] 
2025-08-30 17:49:34.612985: Epoch time: 27.84 s 
2025-08-30 17:49:35.297054:  
2025-08-30 17:49:35.298145: Epoch 675 
2025-08-30 17:49:35.305391: Current learning rate: 0.00036 
2025-08-30 17:50:02.920406: train_loss -0.6346 
2025-08-30 17:50:02.920406: val_loss -0.6411 
2025-08-30 17:50:02.924958: Pseudo dice [np.float32(0.8023)] 
2025-08-30 17:50:02.932989: Epoch time: 27.63 s 
2025-08-30 17:50:03.616964:  
2025-08-30 17:50:03.618049: Epoch 676 
2025-08-30 17:50:03.626385: Current learning rate: 0.00036 
2025-08-30 17:50:30.981757: train_loss -0.6091 
2025-08-30 17:50:30.982138: val_loss -0.5193 
2025-08-30 17:50:30.991862: Pseudo dice [np.float32(0.7621)] 
2025-08-30 17:50:30.998374: Epoch time: 27.37 s 
2025-08-30 17:50:31.679379:  
2025-08-30 17:50:31.679379: Epoch 677 
2025-08-30 17:50:31.686650: Current learning rate: 0.00036 
2025-08-30 17:50:59.330824: train_loss -0.6218 
2025-08-30 17:50:59.330824: val_loss -0.599 
2025-08-30 17:50:59.340808: Pseudo dice [np.float32(0.75)] 
2025-08-30 17:50:59.344752: Epoch time: 27.66 s 
2025-08-30 17:51:00.181765:  
2025-08-30 17:51:00.181765: Epoch 678 
2025-08-30 17:51:00.189527: Current learning rate: 0.00036 
2025-08-30 17:51:27.604877: train_loss -0.6113 
2025-08-30 17:51:27.605250: val_loss -0.6087 
2025-08-30 17:51:27.615972: Pseudo dice [np.float32(0.8086)] 
2025-08-30 17:51:27.621495: Epoch time: 27.43 s 
2025-08-30 17:51:28.306710:  
2025-08-30 17:51:28.306710: Epoch 679 
2025-08-30 17:51:28.315343: Current learning rate: 0.00036 
2025-08-30 17:51:55.620352: train_loss -0.6634 
2025-08-30 17:51:55.620352: val_loss -0.6555 
2025-08-30 17:51:55.630284: Pseudo dice [np.float32(0.8103)] 
2025-08-30 17:51:55.636938: Epoch time: 27.31 s 
2025-08-30 17:51:56.322130:  
2025-08-30 17:51:56.322130: Epoch 680 
2025-08-30 17:51:56.329391: Current learning rate: 0.00036 
2025-08-30 17:52:24.007298: train_loss -0.6544 
2025-08-30 17:52:24.007298: val_loss -0.6597 
2025-08-30 17:52:24.020421: Pseudo dice [np.float32(0.7852)] 
2025-08-30 17:52:24.027772: Epoch time: 27.69 s 
2025-08-30 17:52:24.708722:  
2025-08-30 17:52:24.708722: Epoch 681 
2025-08-30 17:52:24.718606: Current learning rate: 0.00036 
2025-08-30 17:52:52.443947: train_loss -0.6055 
2025-08-30 17:52:52.443947: val_loss -0.6226 
2025-08-30 17:52:52.452540: Pseudo dice [np.float32(0.7539)] 
2025-08-30 17:52:52.458218: Epoch time: 27.74 s 
2025-08-30 17:52:53.149599:  
2025-08-30 17:52:53.149599: Epoch 682 
2025-08-30 17:52:53.159407: Current learning rate: 0.00036 
2025-08-30 17:53:20.818219: train_loss -0.605 
2025-08-30 17:53:20.818219: val_loss -0.6257 
2025-08-30 17:53:20.827746: Pseudo dice [np.float32(0.7922)] 
2025-08-30 17:53:20.831668: Epoch time: 27.67 s 
2025-08-30 17:53:21.507363:  
2025-08-30 17:53:21.507363: Epoch 683 
2025-08-30 17:53:21.517362: Current learning rate: 0.00036 
2025-08-30 17:53:49.208963: train_loss -0.6203 
2025-08-30 17:53:49.208963: val_loss -0.6277 
2025-08-30 17:53:49.221533: Pseudo dice [np.float32(0.8108)] 
2025-08-30 17:53:49.227559: Epoch time: 27.7 s 
2025-08-30 17:53:50.068865:  
2025-08-30 17:53:50.068865: Epoch 684 
2025-08-30 17:53:50.077228: Current learning rate: 0.00035 
2025-08-30 17:54:17.524987: train_loss -0.6327 
2025-08-30 17:54:17.524987: val_loss -0.6722 
2025-08-30 17:54:17.534409: Pseudo dice [np.float32(0.8025)] 
2025-08-30 17:54:17.540923: Epoch time: 27.46 s 
2025-08-30 17:54:18.217752:  
2025-08-30 17:54:18.220817: Epoch 685 
2025-08-30 17:54:18.227762: Current learning rate: 0.00035 
2025-08-30 17:54:45.644433: train_loss -0.6496 
2025-08-30 17:54:45.644433: val_loss -0.6135 
2025-08-30 17:54:45.656029: Pseudo dice [np.float32(0.8025)] 
2025-08-30 17:54:45.662378: Epoch time: 27.43 s 
2025-08-30 17:54:46.350728:  
2025-08-30 17:54:46.350728: Epoch 686 
2025-08-30 17:54:46.358893: Current learning rate: 0.00035 
2025-08-30 17:55:14.172767: train_loss -0.6247 
2025-08-30 17:55:14.172767: val_loss -0.5292 
2025-08-30 17:55:14.181269: Pseudo dice [np.float32(0.8086)] 
2025-08-30 17:55:14.187404: Epoch time: 27.82 s 
2025-08-30 17:55:14.882582:  
2025-08-30 17:55:14.883195: Epoch 687 
2025-08-30 17:55:14.890961: Current learning rate: 0.00035 
2025-08-30 17:55:42.455160: train_loss -0.6023 
2025-08-30 17:55:42.455160: val_loss -0.5942 
2025-08-30 17:55:42.465817: Pseudo dice [np.float32(0.8117)] 
2025-08-30 17:55:42.472655: Epoch time: 27.58 s 
2025-08-30 17:55:43.173299:  
2025-08-30 17:55:43.173299: Epoch 688 
2025-08-30 17:55:43.182174: Current learning rate: 0.00035 
2025-08-30 17:56:10.679125: train_loss -0.6467 
2025-08-30 17:56:10.679125: val_loss -0.6311 
2025-08-30 17:56:10.687562: Pseudo dice [np.float32(0.8112)] 
2025-08-30 17:56:10.692791: Epoch time: 27.51 s 
2025-08-30 17:56:11.379495:  
2025-08-30 17:56:11.379495: Epoch 689 
2025-08-30 17:56:11.387933: Current learning rate: 0.00035 
2025-08-30 17:56:39.049062: train_loss -0.6432 
2025-08-30 17:56:39.049062: val_loss -0.6511 
2025-08-30 17:56:39.060709: Pseudo dice [np.float32(0.8314)] 
2025-08-30 17:56:39.066400: Epoch time: 27.67 s 
2025-08-30 17:56:39.904899:  
2025-08-30 17:56:39.904899: Epoch 690 
2025-08-30 17:56:39.914484: Current learning rate: 0.00035 
2025-08-30 17:57:07.001945: train_loss -0.6113 
2025-08-30 17:57:07.001945: val_loss -0.6184 
2025-08-30 17:57:07.009987: Pseudo dice [np.float32(0.7633)] 
2025-08-30 17:57:07.014979: Epoch time: 27.1 s 
2025-08-30 17:57:07.690923:  
2025-08-30 17:57:07.690923: Epoch 691 
2025-08-30 17:57:07.699972: Current learning rate: 0.00035 
2025-08-30 17:57:35.405257: train_loss -0.6104 
2025-08-30 17:57:35.405257: val_loss -0.6728 
2025-08-30 17:57:35.418945: Pseudo dice [np.float32(0.8315)] 
2025-08-30 17:57:35.425771: Epoch time: 27.72 s 
2025-08-30 17:57:36.115097:  
2025-08-30 17:57:36.115097: Epoch 692 
2025-08-30 17:57:36.124207: Current learning rate: 0.00035 
2025-08-30 17:58:04.012974: train_loss -0.6244 
2025-08-30 17:58:04.012974: val_loss -0.6027 
2025-08-30 17:58:04.022597: Pseudo dice [np.float32(0.7877)] 
2025-08-30 17:58:04.027427: Epoch time: 27.9 s 
2025-08-30 17:58:04.718933:  
2025-08-30 17:58:04.718933: Epoch 693 
2025-08-30 17:58:04.727311: Current learning rate: 0.00035 
2025-08-30 17:58:32.328720: train_loss -0.6257 
2025-08-30 17:58:32.328720: val_loss -0.693 
2025-08-30 17:58:32.340950: Pseudo dice [np.float32(0.8412)] 
2025-08-30 17:58:32.345921: Epoch time: 27.61 s 
2025-08-30 17:58:33.030740:  
2025-08-30 17:58:33.030740: Epoch 694 
2025-08-30 17:58:33.041031: Current learning rate: 0.00034 
2025-08-30 17:59:00.635776: train_loss -0.6232 
2025-08-30 17:59:00.635776: val_loss -0.6217 
2025-08-30 17:59:00.646718: Pseudo dice [np.float32(0.8063)] 
2025-08-30 17:59:00.653666: Epoch time: 27.61 s 
2025-08-30 17:59:01.342472:  
2025-08-30 17:59:01.342472: Epoch 695 
2025-08-30 17:59:01.352171: Current learning rate: 0.00034 
2025-08-30 17:59:29.197578: train_loss -0.6403 
2025-08-30 17:59:29.201725: val_loss -0.7076 
2025-08-30 17:59:29.211679: Pseudo dice [np.float32(0.8011)] 
2025-08-30 17:59:29.215688: Epoch time: 27.86 s 
2025-08-30 17:59:29.902450:  
2025-08-30 17:59:29.903541: Epoch 696 
2025-08-30 17:59:29.910799: Current learning rate: 0.00034 
2025-08-30 17:59:57.271892: train_loss -0.6195 
2025-08-30 17:59:57.271892: val_loss -0.5823 
2025-08-30 17:59:57.280184: Pseudo dice [np.float32(0.7727)] 
2025-08-30 17:59:57.288083: Epoch time: 27.37 s 
2025-08-30 17:59:58.138940:  
2025-08-30 17:59:58.138940: Epoch 697 
2025-08-30 17:59:58.147377: Current learning rate: 0.00034 
2025-08-30 18:00:25.783475: train_loss -0.6531 
2025-08-30 18:00:25.783475: val_loss -0.5755 
2025-08-30 18:00:25.795730: Pseudo dice [np.float32(0.7377)] 
2025-08-30 18:00:25.800802: Epoch time: 27.65 s 
2025-08-30 18:00:26.505838:  
2025-08-30 18:00:26.506634: Epoch 698 
2025-08-30 18:00:26.514191: Current learning rate: 0.00034 
2025-08-30 18:00:54.224370: train_loss -0.6277 
2025-08-30 18:00:54.224370: val_loss -0.5499 
2025-08-30 18:00:54.234055: Pseudo dice [np.float32(0.7652)] 
2025-08-30 18:00:54.238734: Epoch time: 27.72 s 
2025-08-30 18:00:54.938328:  
2025-08-30 18:00:54.938328: Epoch 699 
2025-08-30 18:00:54.947965: Current learning rate: 0.00034 
2025-08-30 18:01:22.268718: train_loss -0.6054 
2025-08-30 18:01:22.268718: val_loss -0.6637 
2025-08-30 18:01:22.278635: Pseudo dice [np.float32(0.797)] 
2025-08-30 18:01:22.283323: Epoch time: 27.33 s 
2025-08-30 18:01:23.190451:  
2025-08-30 18:01:23.190451: Epoch 700 
2025-08-30 18:01:23.198751: Current learning rate: 0.00034 
2025-08-30 18:01:51.030648: train_loss -0.6216 
2025-08-30 18:01:51.030648: val_loss -0.5955 
2025-08-30 18:01:51.041658: Pseudo dice [np.float32(0.7828)] 
2025-08-30 18:01:51.048217: Epoch time: 27.84 s 
2025-08-30 18:01:51.745851:  
2025-08-30 18:01:51.745851: Epoch 701 
2025-08-30 18:01:51.754715: Current learning rate: 0.00034 
2025-08-30 18:02:19.280113: train_loss -0.643 
2025-08-30 18:02:19.284175: val_loss -0.6232 
2025-08-30 18:02:19.292202: Pseudo dice [np.float32(0.8063)] 
2025-08-30 18:02:19.297228: Epoch time: 27.54 s 
2025-08-30 18:02:19.974006:  
2025-08-30 18:02:19.974006: Epoch 702 
2025-08-30 18:02:19.981819: Current learning rate: 0.00034 
2025-08-30 18:02:47.408181: train_loss -0.6186 
2025-08-30 18:02:47.408181: val_loss -0.6133 
2025-08-30 18:02:47.418731: Pseudo dice [np.float32(0.8049)] 
2025-08-30 18:02:47.424352: Epoch time: 27.44 s 
2025-08-30 18:02:48.276349:  
2025-08-30 18:02:48.276349: Epoch 703 
2025-08-30 18:02:48.285210: Current learning rate: 0.00034 
2025-08-30 18:03:15.766241: train_loss -0.6402 
2025-08-30 18:03:15.767238: val_loss -0.6828 
2025-08-30 18:03:15.775240: Pseudo dice [np.float32(0.8512)] 
2025-08-30 18:03:15.779902: Epoch time: 27.49 s 
2025-08-30 18:03:16.459041:  
2025-08-30 18:03:16.459041: Epoch 704 
2025-08-30 18:03:16.466969: Current learning rate: 0.00033 
2025-08-30 18:03:44.286109: train_loss -0.6433 
2025-08-30 18:03:44.286109: val_loss -0.5956 
2025-08-30 18:03:44.296333: Pseudo dice [np.float32(0.8034)] 
2025-08-30 18:03:44.301893: Epoch time: 27.83 s 
2025-08-30 18:03:44.991227:  
2025-08-30 18:03:44.991227: Epoch 705 
2025-08-30 18:03:45.001600: Current learning rate: 0.00033 
2025-08-30 18:04:12.346882: train_loss -0.6241 
2025-08-30 18:04:12.346882: val_loss -0.6012 
2025-08-30 18:04:12.356538: Pseudo dice [np.float32(0.7905)] 
2025-08-30 18:04:12.361179: Epoch time: 27.36 s 
2025-08-30 18:04:13.048737:  
2025-08-30 18:04:13.048737: Epoch 706 
2025-08-30 18:04:13.057191: Current learning rate: 0.00033 
2025-08-30 18:04:41.021297: train_loss -0.6451 
2025-08-30 18:04:41.021297: val_loss -0.6754 
2025-08-30 18:04:41.032088: Pseudo dice [np.float32(0.8185)] 
2025-08-30 18:04:41.037653: Epoch time: 27.97 s 
2025-08-30 18:04:41.736231:  
2025-08-30 18:04:41.736231: Epoch 707 
2025-08-30 18:04:41.744131: Current learning rate: 0.00033 
2025-08-30 18:05:08.752822: train_loss -0.5999 
2025-08-30 18:05:08.752822: val_loss -0.645 
2025-08-30 18:05:08.762849: Pseudo dice [np.float32(0.8306)] 
2025-08-30 18:05:08.767286: Epoch time: 27.02 s 
2025-08-30 18:05:09.417078:  
2025-08-30 18:05:09.420137: Epoch 708 
2025-08-30 18:05:09.428496: Current learning rate: 0.00033 
2025-08-30 18:05:35.546587: train_loss -0.6836 
2025-08-30 18:05:35.546587: val_loss -0.6362 
2025-08-30 18:05:35.567026: Pseudo dice [np.float32(0.7971)] 
2025-08-30 18:05:35.571605: Epoch time: 26.13 s 
2025-08-30 18:05:36.430748:  
2025-08-30 18:05:36.430748: Epoch 709 
2025-08-30 18:05:36.442711: Current learning rate: 0.00033 
2025-08-30 18:06:02.686087: train_loss -0.62 
2025-08-30 18:06:02.686087: val_loss -0.6603 
2025-08-30 18:06:02.696703: Pseudo dice [np.float32(0.8115)] 
2025-08-30 18:06:02.702395: Epoch time: 26.26 s 
2025-08-30 18:06:03.391729:  
2025-08-30 18:06:03.394797: Epoch 710 
2025-08-30 18:06:03.401809: Current learning rate: 0.00033 
2025-08-30 18:06:29.366770: train_loss -0.6531 
2025-08-30 18:06:29.366770: val_loss -0.5888 
2025-08-30 18:06:29.378081: Pseudo dice [np.float32(0.821)] 
2025-08-30 18:06:29.384176: Epoch time: 25.98 s 
2025-08-30 18:06:30.018268:  
2025-08-30 18:06:30.021358: Epoch 711 
2025-08-30 18:06:30.028297: Current learning rate: 0.00033 
2025-08-30 18:06:55.455332: train_loss -0.6109 
2025-08-30 18:06:55.455332: val_loss -0.6099 
2025-08-30 18:06:55.463781: Pseudo dice [np.float32(0.7759)] 
2025-08-30 18:06:55.473095: Epoch time: 25.44 s 
2025-08-30 18:06:56.118195:  
2025-08-30 18:06:56.118195: Epoch 712 
2025-08-30 18:06:56.126556: Current learning rate: 0.00033 
2025-08-30 18:07:21.477127: train_loss -0.636 
2025-08-30 18:07:21.477127: val_loss -0.6683 
2025-08-30 18:07:21.486742: Pseudo dice [np.float32(0.8399)] 
2025-08-30 18:07:21.493457: Epoch time: 25.36 s 
2025-08-30 18:07:22.178615:  
2025-08-30 18:07:22.178615: Epoch 713 
2025-08-30 18:07:22.186929: Current learning rate: 0.00033 
2025-08-30 18:07:46.856930: train_loss -0.6217 
2025-08-30 18:07:46.856930: val_loss -0.6505 
2025-08-30 18:07:46.867213: Pseudo dice [np.float32(0.8286)] 
2025-08-30 18:07:46.872955: Epoch time: 24.68 s 
2025-08-30 18:07:46.879149: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2025-08-30 18:07:47.733250:  
2025-08-30 18:07:47.733250: Epoch 714 
2025-08-30 18:07:47.741599: Current learning rate: 0.00032 
2025-08-30 18:08:13.366033: train_loss -0.6153 
2025-08-30 18:08:13.366033: val_loss -0.6964 
2025-08-30 18:08:13.375976: Pseudo dice [np.float32(0.8356)] 
2025-08-30 18:08:13.380703: Epoch time: 25.64 s 
2025-08-30 18:08:13.387758: Yayy! New best EMA pseudo Dice: 0.8113999962806702 
2025-08-30 18:08:14.437947:  
2025-08-30 18:08:14.437947: Epoch 715 
2025-08-30 18:08:14.445946: Current learning rate: 0.00032 
2025-08-30 18:08:40.810497: train_loss -0.6132 
2025-08-30 18:08:40.814251: val_loss -0.649 
2025-08-30 18:08:40.818811: Pseudo dice [np.float32(0.8129)] 
2025-08-30 18:08:40.824912: Epoch time: 26.38 s 
2025-08-30 18:08:40.830831: Yayy! New best EMA pseudo Dice: 0.8115000128746033 
2025-08-30 18:08:41.713798:  
2025-08-30 18:08:41.715211: Epoch 716 
2025-08-30 18:08:41.725707: Current learning rate: 0.00032 
2025-08-30 18:09:08.163461: train_loss -0.6274 
2025-08-30 18:09:08.163461: val_loss -0.6888 
2025-08-30 18:09:08.166962: Pseudo dice [np.float32(0.8291)] 
2025-08-30 18:09:08.176026: Epoch time: 26.45 s 
2025-08-30 18:09:08.183918: Yayy! New best EMA pseudo Dice: 0.8133000135421753 
2025-08-30 18:09:09.131108:  
2025-08-30 18:09:09.131108: Epoch 717 
2025-08-30 18:09:09.135703: Current learning rate: 0.00032 
2025-08-30 18:09:35.414506: train_loss -0.6485 
2025-08-30 18:09:35.418691: val_loss -0.6301 
2025-08-30 18:09:35.422882: Pseudo dice [np.float32(0.7951)] 
2025-08-30 18:09:35.432491: Epoch time: 26.29 s 
2025-08-30 18:09:36.078817:  
2025-08-30 18:09:36.078817: Epoch 718 
2025-08-30 18:09:36.087454: Current learning rate: 0.00032 
2025-08-30 18:10:01.273937: train_loss -0.6163 
2025-08-30 18:10:01.273937: val_loss -0.6459 
2025-08-30 18:10:01.284579: Pseudo dice [np.float32(0.8146)] 
2025-08-30 18:10:01.290306: Epoch time: 25.2 s 
2025-08-30 18:10:01.937883:  
2025-08-30 18:10:01.937883: Epoch 719 
2025-08-30 18:10:01.947627: Current learning rate: 0.00032 
2025-08-30 18:10:27.070523: train_loss -0.6289 
2025-08-30 18:10:27.074353: val_loss -0.5339 
2025-08-30 18:10:27.084295: Pseudo dice [np.float32(0.7068)] 
2025-08-30 18:10:27.088941: Epoch time: 25.13 s 
2025-08-30 18:10:27.737517:  
2025-08-30 18:10:27.737517: Epoch 720 
2025-08-30 18:10:27.745871: Current learning rate: 0.00032 
2025-08-30 18:10:53.022136: train_loss -0.6135 
2025-08-30 18:10:53.022136: val_loss -0.5663 
2025-08-30 18:10:53.030971: Pseudo dice [np.float32(0.7887)] 
2025-08-30 18:10:53.037699: Epoch time: 25.29 s 
2025-08-30 18:10:53.834739:  
2025-08-30 18:10:53.843153: Epoch 721 
2025-08-30 18:10:53.847263: Current learning rate: 0.00032 
2025-08-30 18:11:19.056316: train_loss -0.6632 
2025-08-30 18:11:19.064061: val_loss -0.5108 
2025-08-30 18:11:19.068186: Pseudo dice [np.float32(0.7283)] 
2025-08-30 18:11:19.075063: Epoch time: 25.22 s 
2025-08-30 18:11:19.710166:  
2025-08-30 18:11:19.714350: Epoch 722 
2025-08-30 18:11:19.722685: Current learning rate: 0.00032 
2025-08-30 18:11:45.590997: train_loss -0.6164 
2025-08-30 18:11:45.590997: val_loss -0.6309 
2025-08-30 18:11:45.590997: Pseudo dice [np.float32(0.7662)] 
2025-08-30 18:11:45.609339: Epoch time: 25.89 s 
2025-08-30 18:11:46.252434:  
2025-08-30 18:11:46.268083: Epoch 723 
2025-08-30 18:11:46.268083: Current learning rate: 0.00031 
2025-08-30 18:12:12.491969: train_loss -0.6187 
2025-08-30 18:12:12.491969: val_loss -0.6126 
2025-08-30 18:12:12.502913: Pseudo dice [np.float32(0.7795)] 
2025-08-30 18:12:12.508616: Epoch time: 26.24 s 
2025-08-30 18:12:13.138808:  
2025-08-30 18:12:13.147135: Epoch 724 
2025-08-30 18:12:13.151282: Current learning rate: 0.00031 
2025-08-30 18:12:38.026127: train_loss -0.6412 
2025-08-30 18:12:38.034457: val_loss -0.6251 
2025-08-30 18:12:38.042449: Pseudo dice [np.float32(0.8184)] 
2025-08-30 18:12:38.047813: Epoch time: 24.89 s 
2025-08-30 18:12:38.685092:  
2025-08-30 18:12:38.693429: Epoch 725 
2025-08-30 18:12:38.701434: Current learning rate: 0.00031 
2025-08-30 18:13:03.968657: train_loss -0.6372 
2025-08-30 18:13:03.968657: val_loss -0.6174 
2025-08-30 18:13:03.976947: Pseudo dice [np.float32(0.8163)] 
2025-08-30 18:13:03.985691: Epoch time: 25.28 s 
2025-08-30 18:13:04.619287:  
2025-08-30 18:13:04.627642: Epoch 726 
2025-08-30 18:13:04.631819: Current learning rate: 0.00031 
2025-08-30 18:13:29.439513: train_loss -0.6357 
2025-08-30 18:13:29.452354: val_loss -0.5943 
2025-08-30 18:13:29.456198: Pseudo dice [np.float32(0.7683)] 
2025-08-30 18:13:29.462343: Epoch time: 24.82 s 
2025-08-30 18:13:30.094668:  
2025-08-30 18:13:30.103101: Epoch 727 
2025-08-30 18:13:30.111379: Current learning rate: 0.00031 
2025-08-30 18:13:55.198902: train_loss -0.638 
2025-08-30 18:13:55.207247: val_loss -0.6418 
2025-08-30 18:13:55.211419: Pseudo dice [np.float32(0.8121)] 
2025-08-30 18:13:55.220091: Epoch time: 25.1 s 
2025-08-30 18:13:56.008008:  
2025-08-30 18:13:56.018557: Epoch 728 
2025-08-30 18:13:56.024280: Current learning rate: 0.00031 
2025-08-30 18:14:20.598838: train_loss -0.624 
2025-08-30 18:14:20.603399: val_loss -0.5661 
2025-08-30 18:14:20.611780: Pseudo dice [np.float32(0.7333)] 
2025-08-30 18:14:20.616716: Epoch time: 24.59 s 
2025-08-30 18:14:21.249489:  
2025-08-30 18:14:21.254104: Epoch 729 
2025-08-30 18:14:21.262398: Current learning rate: 0.00031 
2025-08-30 18:14:46.425014: train_loss -0.6684 
2025-08-30 18:14:46.437116: val_loss -0.5978 
2025-08-30 18:14:46.441696: Pseudo dice [np.float32(0.7852)] 
2025-08-30 18:14:46.447248: Epoch time: 25.18 s 
2025-08-30 18:14:47.075593:  
2025-08-30 18:14:47.083956: Epoch 730 
2025-08-30 18:14:47.091936: Current learning rate: 0.00031 
2025-08-30 18:15:12.546482: train_loss -0.6459 
2025-08-30 18:15:12.554838: val_loss -0.6396 
2025-08-30 18:15:12.563799: Pseudo dice [np.float32(0.8087)] 
2025-08-30 18:15:12.569230: Epoch time: 25.47 s 
2025-08-30 18:15:13.205808:  
2025-08-30 18:15:13.214187: Epoch 731 
2025-08-30 18:15:13.218318: Current learning rate: 0.00031 
2025-08-30 18:15:38.130612: train_loss -0.6411 
2025-08-30 18:15:38.139010: val_loss -0.6043 
2025-08-30 18:15:38.143251: Pseudo dice [np.float32(0.8236)] 
2025-08-30 18:15:38.150957: Epoch time: 24.93 s 
2025-08-30 18:15:38.789294:  
2025-08-30 18:15:38.797687: Epoch 732 
2025-08-30 18:15:38.801864: Current learning rate: 0.00031 
2025-08-30 18:16:07.042948: train_loss -0.6159 
2025-08-30 18:16:07.051306: val_loss -0.6097 
2025-08-30 18:16:07.055410: Pseudo dice [np.float32(0.8266)] 
2025-08-30 18:16:07.061276: Epoch time: 28.25 s 
2025-08-30 18:16:07.734870:  
2025-08-30 18:16:07.743547: Epoch 733 
2025-08-30 18:16:07.747366: Current learning rate: 0.0003 
2025-08-30 18:16:35.458345: train_loss -0.6577 
2025-08-30 18:16:35.466984: val_loss -0.6318 
2025-08-30 18:16:35.475375: Pseudo dice [np.float32(0.781)] 
2025-08-30 18:16:35.480795: Epoch time: 27.72 s 
2025-08-30 18:16:36.330018:  
2025-08-30 18:16:36.338399: Epoch 734 
2025-08-30 18:16:36.342563: Current learning rate: 0.0003 
2025-08-30 18:17:03.407459: train_loss -0.6437 
2025-08-30 18:17:03.415817: val_loss -0.6392 
2025-08-30 18:17:03.419961: Pseudo dice [np.float32(0.814)] 
2025-08-30 18:17:03.428795: Epoch time: 27.08 s 
2025-08-30 18:17:04.095209:  
2025-08-30 18:17:04.103884: Epoch 735 
2025-08-30 18:17:04.108056: Current learning rate: 0.0003 
2025-08-30 18:17:30.822239: train_loss -0.6454 
2025-08-30 18:17:30.830625: val_loss -0.6178 
2025-08-30 18:17:30.838546: Pseudo dice [np.float32(0.8359)] 
2025-08-30 18:17:30.844034: Epoch time: 26.73 s 
2025-08-30 18:17:31.514215:  
2025-08-30 18:17:31.522874: Epoch 736 
2025-08-30 18:17:31.527078: Current learning rate: 0.0003 
2025-08-30 18:17:58.970744: train_loss -0.6448 
2025-08-30 18:17:58.971110: val_loss -0.6398 
2025-08-30 18:17:58.979552: Pseudo dice [np.float32(0.8199)] 
2025-08-30 18:17:58.984240: Epoch time: 27.46 s 
2025-08-30 18:17:59.659386:  
2025-08-30 18:17:59.667707: Epoch 737 
2025-08-30 18:17:59.671910: Current learning rate: 0.0003 
2025-08-30 18:18:26.798483: train_loss -0.637 
2025-08-30 18:18:26.807249: val_loss -0.6738 
2025-08-30 18:18:26.815534: Pseudo dice [np.float32(0.8282)] 
2025-08-30 18:18:26.821179: Epoch time: 27.14 s 
2025-08-30 18:18:27.491157:  
2025-08-30 18:18:27.499621: Epoch 738 
2025-08-30 18:18:27.503808: Current learning rate: 0.0003 
2025-08-30 18:18:54.639050: train_loss -0.6483 
2025-08-30 18:18:54.647127: val_loss -0.6289 
2025-08-30 18:18:54.655769: Pseudo dice [np.float32(0.8019)] 
2025-08-30 18:18:54.662738: Epoch time: 27.15 s 
2025-08-30 18:18:55.339789:  
2025-08-30 18:18:55.348339: Epoch 739 
2025-08-30 18:18:55.352389: Current learning rate: 0.0003 
2025-08-30 18:19:23.238213: train_loss -0.6192 
2025-08-30 18:19:23.250612: val_loss -0.5729 
2025-08-30 18:19:23.255138: Pseudo dice [np.float32(0.7697)] 
2025-08-30 18:19:23.263023: Epoch time: 27.9 s 
2025-08-30 18:19:23.931652:  
2025-08-30 18:19:23.939234: Epoch 740 
2025-08-30 18:19:23.947594: Current learning rate: 0.0003 
2025-08-30 18:19:52.313750: train_loss -0.6425 
2025-08-30 18:19:52.321708: val_loss -0.6083 
2025-08-30 18:19:52.325912: Pseudo dice [np.float32(0.7949)] 
2025-08-30 18:19:52.334670: Epoch time: 28.39 s 
2025-08-30 18:19:53.026554:  
2025-08-30 18:19:53.034928: Epoch 741 
2025-08-30 18:19:53.043288: Current learning rate: 0.0003 
2025-08-30 18:20:21.596689: train_loss -0.6262 
2025-08-30 18:20:21.605062: val_loss -0.6303 
2025-08-30 18:20:21.609142: Pseudo dice [np.float32(0.8285)] 
2025-08-30 18:20:21.618163: Epoch time: 28.57 s 
2025-08-30 18:20:22.284783:  
2025-08-30 18:20:22.293123: Epoch 742 
2025-08-30 18:20:22.297501: Current learning rate: 0.0003 
2025-08-30 18:20:50.896676: train_loss -0.6369 
2025-08-30 18:20:50.909188: val_loss -0.6337 
2025-08-30 18:20:50.913321: Pseudo dice [np.float32(0.7937)] 
2025-08-30 18:20:50.921258: Epoch time: 28.62 s 
2025-08-30 18:20:51.580762:  
2025-08-30 18:20:51.589135: Epoch 743 
2025-08-30 18:20:51.593252: Current learning rate: 0.00029 
2025-08-30 18:21:20.084198: train_loss -0.6349 
2025-08-30 18:21:20.092560: val_loss -0.6638 
2025-08-30 18:21:20.096721: Pseudo dice [np.float32(0.831)] 
2025-08-30 18:21:20.104659: Epoch time: 28.5 s 
2025-08-30 18:21:20.776142:  
2025-08-30 18:21:20.784795: Epoch 744 
2025-08-30 18:21:20.789008: Current learning rate: 0.00029 
2025-08-30 18:21:49.188208: train_loss -0.6578 
2025-08-30 18:21:49.200713: val_loss -0.6105 
2025-08-30 18:21:49.209135: Pseudo dice [np.float32(0.7382)] 
2025-08-30 18:21:49.213770: Epoch time: 28.41 s 
2025-08-30 18:21:49.884642:  
2025-08-30 18:21:49.892962: Epoch 745 
2025-08-30 18:21:49.897331: Current learning rate: 0.00029 
2025-08-30 18:22:19.543397: train_loss -0.6283 
2025-08-30 18:22:19.547214: val_loss -0.6193 
2025-08-30 18:22:19.556320: Pseudo dice [np.float32(0.7889)] 
2025-08-30 18:22:19.560635: Epoch time: 29.66 s 
2025-08-30 18:22:20.219229:  
2025-08-30 18:22:20.227553: Epoch 746 
2025-08-30 18:22:20.236005: Current learning rate: 0.00029 
2025-08-30 18:22:48.818523: train_loss -0.6153 
2025-08-30 18:22:48.826842: val_loss -0.63 
2025-08-30 18:22:48.835237: Pseudo dice [np.float32(0.7925)] 
2025-08-30 18:22:48.841106: Epoch time: 28.6 s 
2025-08-30 18:22:49.518784:  
2025-08-30 18:22:49.527455: Epoch 747 
2025-08-30 18:22:49.531286: Current learning rate: 0.00029 
2025-08-30 18:23:18.123552: train_loss -0.6356 
2025-08-30 18:23:18.131068: val_loss -0.5868 
2025-08-30 18:23:18.135242: Pseudo dice [np.float32(0.7904)] 
2025-08-30 18:23:18.143035: Epoch time: 28.6 s 
2025-08-30 18:23:18.810882:  
2025-08-30 18:23:18.819245: Epoch 748 
2025-08-30 18:23:18.823428: Current learning rate: 0.00029 
2025-08-30 18:23:47.564137: train_loss -0.6739 
2025-08-30 18:23:47.572900: val_loss -0.6238 
2025-08-30 18:23:47.577062: Pseudo dice [np.float32(0.7893)] 
2025-08-30 18:23:47.585899: Epoch time: 28.75 s 
2025-08-30 18:23:48.261050:  
2025-08-30 18:23:48.269494: Epoch 749 
2025-08-30 18:23:48.273620: Current learning rate: 0.00029 
2025-08-30 18:24:16.434966: train_loss -0.6548 
2025-08-30 18:24:16.443384: val_loss -0.6075 
2025-08-30 18:24:16.447577: Pseudo dice [np.float32(0.7567)] 
2025-08-30 18:24:16.455317: Epoch time: 28.17 s 
2025-08-30 18:24:17.343852:  
2025-08-30 18:24:17.352494: Epoch 750 
2025-08-30 18:24:17.356709: Current learning rate: 0.00029 
2025-08-30 18:24:46.218806: train_loss -0.6423 
2025-08-30 18:24:46.227143: val_loss -0.6198 
2025-08-30 18:24:46.235923: Pseudo dice [np.float32(0.8278)] 
2025-08-30 18:24:46.241561: Epoch time: 28.88 s 
2025-08-30 18:24:46.907080:  
2025-08-30 18:24:46.915407: Epoch 751 
2025-08-30 18:24:46.923754: Current learning rate: 0.00029 
2025-08-30 18:25:16.294296: train_loss -0.6421 
2025-08-30 18:25:16.303116: val_loss -0.6961 
2025-08-30 18:25:16.307286: Pseudo dice [np.float32(0.8212)] 
2025-08-30 18:25:16.316113: Epoch time: 29.39 s 
2025-08-30 18:25:17.124318:  
2025-08-30 18:25:17.132954: Epoch 752 
2025-08-30 18:25:17.137122: Current learning rate: 0.00029 
2025-08-30 18:25:45.612250: train_loss -0.6697 
2025-08-30 18:25:45.619791: val_loss -0.6573 
2025-08-30 18:25:45.628066: Pseudo dice [np.float32(0.7479)] 
2025-08-30 18:25:45.634108: Epoch time: 28.49 s 
2025-08-30 18:25:46.312141:  
2025-08-30 18:25:46.320495: Epoch 753 
2025-08-30 18:25:46.324678: Current learning rate: 0.00028 
2025-08-30 18:26:14.094035: train_loss -0.6404 
2025-08-30 18:26:14.102356: val_loss -0.6637 
2025-08-30 18:26:14.106533: Pseudo dice [np.float32(0.8066)] 
2025-08-30 18:26:14.114502: Epoch time: 27.78 s 
2025-08-30 18:26:14.782088:  
2025-08-30 18:26:14.790427: Epoch 754 
2025-08-30 18:26:14.794296: Current learning rate: 0.00028 
2025-08-30 18:26:43.781526: train_loss -0.6496 
2025-08-30 18:26:43.794408: val_loss -0.6225 
2025-08-30 18:26:43.802733: Pseudo dice [np.float32(0.7819)] 
2025-08-30 18:26:43.807797: Epoch time: 29.0 s 
2025-08-30 18:26:44.478470:  
2025-08-30 18:26:44.486834: Epoch 755 
2025-08-30 18:26:44.491010: Current learning rate: 0.00028 
2025-08-30 18:27:13.102821: train_loss -0.6367 
2025-08-30 18:27:13.102821: val_loss -0.6563 
2025-08-30 18:27:13.112492: Pseudo dice [np.float32(0.8007)] 
2025-08-30 18:27:13.119087: Epoch time: 28.63 s 
2025-08-30 18:27:13.790601:  
2025-08-30 18:27:13.799264: Epoch 756 
2025-08-30 18:27:13.803418: Current learning rate: 0.00028 
2025-08-30 18:27:42.466415: train_loss -0.6288 
2025-08-30 18:27:42.477876: val_loss -0.6249 
2025-08-30 18:27:42.482079: Pseudo dice [np.float32(0.8069)] 
2025-08-30 18:27:42.489097: Epoch time: 28.68 s 
2025-08-30 18:27:43.157776:  
2025-08-30 18:27:43.170342: Epoch 757 
2025-08-30 18:27:43.174491: Current learning rate: 0.00028 
2025-08-30 18:28:12.257607: train_loss -0.6396 
2025-08-30 18:28:12.266050: val_loss -0.6169 
2025-08-30 18:28:12.270220: Pseudo dice [np.float32(0.8187)] 
2025-08-30 18:28:12.277997: Epoch time: 29.1 s 
2025-08-30 18:28:12.945452:  
2025-08-30 18:28:12.954231: Epoch 758 
2025-08-30 18:28:12.958378: Current learning rate: 0.00028 
2025-08-30 18:28:41.595222: train_loss -0.6422 
2025-08-30 18:28:41.607800: val_loss -0.6367 
2025-08-30 18:28:41.616454: Pseudo dice [np.float32(0.8155)] 
2025-08-30 18:28:41.620666: Epoch time: 28.65 s 
2025-08-30 18:28:42.458661:  
2025-08-30 18:28:42.466861: Epoch 759 
2025-08-30 18:28:42.470734: Current learning rate: 0.00028 
2025-08-30 18:29:11.062106: train_loss -0.6501 
2025-08-30 18:29:11.070497: val_loss -0.5882 
2025-08-30 18:29:11.078840: Pseudo dice [np.float32(0.7905)] 
2025-08-30 18:29:11.085737: Epoch time: 28.61 s 
2025-08-30 18:29:11.754524:  
2025-08-30 18:29:11.762865: Epoch 760 
2025-08-30 18:29:11.767023: Current learning rate: 0.00028 
2025-08-30 18:29:40.829275: train_loss -0.6205 
2025-08-30 18:29:40.841812: val_loss -0.6454 
2025-08-30 18:29:40.845949: Pseudo dice [np.float32(0.7941)] 
2025-08-30 18:29:40.854880: Epoch time: 29.07 s 
2025-08-30 18:29:41.525815:  
2025-08-30 18:29:41.537884: Epoch 761 
2025-08-30 18:29:41.543729: Current learning rate: 0.00028 
2025-08-30 18:30:10.109861: train_loss -0.646 
2025-08-30 18:30:10.116759: val_loss -0.6496 
2025-08-30 18:30:10.120894: Pseudo dice [np.float32(0.789)] 
2025-08-30 18:30:10.128836: Epoch time: 28.58 s 
2025-08-30 18:30:10.796709:  
2025-08-30 18:30:10.805036: Epoch 762 
2025-08-30 18:30:10.813420: Current learning rate: 0.00027 
2025-08-30 18:30:39.078608: train_loss -0.6396 
2025-08-30 18:30:39.087327: val_loss -0.5949 
2025-08-30 18:30:39.095675: Pseudo dice [np.float32(0.8093)] 
2025-08-30 18:30:39.100966: Epoch time: 28.28 s 
2025-08-30 18:30:39.783922:  
2025-08-30 18:30:39.792298: Epoch 763 
2025-08-30 18:30:39.800595: Current learning rate: 0.00027 
2025-08-30 18:31:09.083553: train_loss -0.6248 
2025-08-30 18:31:09.092227: val_loss -0.6357 
2025-08-30 18:31:09.096506: Pseudo dice [np.float32(0.8271)] 
2025-08-30 18:31:09.104400: Epoch time: 29.3 s 
2025-08-30 18:31:09.780507:  
2025-08-30 18:31:09.788912: Epoch 764 
2025-08-30 18:31:09.793030: Current learning rate: 0.00027 
2025-08-30 18:31:38.354414: train_loss -0.6388 
2025-08-30 18:31:38.354821: val_loss -0.59 
2025-08-30 18:31:38.363258: Pseudo dice [np.float32(0.8276)] 
2025-08-30 18:31:38.367771: Epoch time: 28.57 s 
2025-08-30 18:31:39.184798:  
2025-08-30 18:31:39.193213: Epoch 765 
2025-08-30 18:31:39.199448: Current learning rate: 0.00027 
2025-08-30 18:32:07.980383: train_loss -0.6696 
2025-08-30 18:32:07.988542: val_loss -0.6607 
2025-08-30 18:32:07.997007: Pseudo dice [np.float32(0.7911)] 
2025-08-30 18:32:08.002771: Epoch time: 28.8 s 
2025-08-30 18:32:08.672612:  
2025-08-30 18:32:08.680897: Epoch 766 
2025-08-30 18:32:08.689277: Current learning rate: 0.00027 
2025-08-30 18:32:37.609620: train_loss -0.643 
2025-08-30 18:32:37.622194: val_loss -0.5604 
2025-08-30 18:32:37.626359: Pseudo dice [np.float32(0.8065)] 
2025-08-30 18:32:37.633465: Epoch time: 28.94 s 
2025-08-30 18:32:38.314615:  
2025-08-30 18:32:38.322979: Epoch 767 
2025-08-30 18:32:38.327124: Current learning rate: 0.00027 
2025-08-30 18:33:07.301862: train_loss -0.6302 
2025-08-30 18:33:07.313956: val_loss -0.6133 
2025-08-30 18:33:07.320243: Pseudo dice [np.float32(0.8142)] 
2025-08-30 18:33:07.325341: Epoch time: 28.99 s 
2025-08-30 18:33:07.994213:  
2025-08-30 18:33:08.002538: Epoch 768 
2025-08-30 18:33:08.010502: Current learning rate: 0.00027 
2025-08-30 18:33:35.866051: train_loss -0.6347 
2025-08-30 18:33:35.876220: val_loss -0.6615 
2025-08-30 18:33:35.880291: Pseudo dice [np.float32(0.8159)] 
2025-08-30 18:33:35.889205: Epoch time: 27.87 s 
2025-08-30 18:33:36.576428:  
2025-08-30 18:33:36.584807: Epoch 769 
2025-08-30 18:33:36.589309: Current learning rate: 0.00027 
2025-08-30 18:34:05.547407: train_loss -0.6482 
2025-08-30 18:34:05.555780: val_loss -0.6398 
2025-08-30 18:34:05.559896: Pseudo dice [np.float32(0.8487)] 
2025-08-30 18:34:05.567862: Epoch time: 28.97 s 
2025-08-30 18:34:06.243942:  
2025-08-30 18:34:06.252326: Epoch 770 
2025-08-30 18:34:06.256502: Current learning rate: 0.00027 
2025-08-30 18:34:34.901248: train_loss -0.6327 
2025-08-30 18:34:34.910048: val_loss -0.5879 
2025-08-30 18:34:34.918430: Pseudo dice [np.float32(0.7712)] 
2025-08-30 18:34:34.924043: Epoch time: 28.65 s 
2025-08-30 18:34:35.606576:  
2025-08-30 18:34:35.614912: Epoch 771 
2025-08-30 18:34:35.619093: Current learning rate: 0.00027 
2025-08-30 18:35:04.072060: train_loss -0.6212 
2025-08-30 18:35:04.084569: val_loss -0.5851 
2025-08-30 18:35:04.089050: Pseudo dice [np.float32(0.8067)] 
2025-08-30 18:35:04.095055: Epoch time: 28.47 s 
2025-08-30 18:35:04.773098:  
2025-08-30 18:35:04.777318: Epoch 772 
2025-08-30 18:35:04.785720: Current learning rate: 0.00026 
2025-08-30 18:35:33.956337: train_loss -0.6529 
2025-08-30 18:35:33.964656: val_loss -0.6708 
2025-08-30 18:35:33.972995: Pseudo dice [np.float32(0.783)] 
2025-08-30 18:35:33.979138: Epoch time: 29.19 s 
2025-08-30 18:35:34.652954:  
2025-08-30 18:35:34.661289: Epoch 773 
2025-08-30 18:35:34.665486: Current learning rate: 0.00026 
2025-08-30 18:36:03.456881: train_loss -0.6268 
2025-08-30 18:36:03.465028: val_loss -0.6356 
2025-08-30 18:36:03.469180: Pseudo dice [np.float32(0.8035)] 
2025-08-30 18:36:03.476931: Epoch time: 28.8 s 
2025-08-30 18:36:04.161139:  
2025-08-30 18:36:04.169795: Epoch 774 
2025-08-30 18:36:04.177826: Current learning rate: 0.00026 
2025-08-30 18:36:32.564884: train_loss -0.6434 
2025-08-30 18:36:32.564884: val_loss -0.6381 
2025-08-30 18:36:32.578637: Pseudo dice [np.float32(0.7939)] 
2025-08-30 18:36:32.583180: Epoch time: 28.4 s 
2025-08-30 18:36:33.273921:  
2025-08-30 18:36:33.282247: Epoch 775 
2025-08-30 18:36:33.286455: Current learning rate: 0.00026 
2025-08-30 18:37:02.210993: train_loss -0.6451 
2025-08-30 18:37:02.219398: val_loss -0.6138 
2025-08-30 18:37:02.223596: Pseudo dice [np.float32(0.8155)] 
2025-08-30 18:37:02.231697: Epoch time: 28.94 s 
2025-08-30 18:37:02.903046:  
2025-08-30 18:37:02.911675: Epoch 776 
2025-08-30 18:37:02.920004: Current learning rate: 0.00026 
2025-08-30 18:37:31.590032: train_loss -0.6595 
2025-08-30 18:37:31.598636: val_loss -0.5458 
2025-08-30 18:37:31.606993: Pseudo dice [np.float32(0.7627)] 
2025-08-30 18:37:31.611691: Epoch time: 28.69 s 
2025-08-30 18:37:32.432892:  
2025-08-30 18:37:32.441210: Epoch 777 
2025-08-30 18:37:32.445408: Current learning rate: 0.00026 
2025-08-30 18:38:00.656436: train_loss -0.6535 
2025-08-30 18:38:00.665106: val_loss -0.622 
2025-08-30 18:38:00.669308: Pseudo dice [np.float32(0.8156)] 
2025-08-30 18:38:00.677148: Epoch time: 28.22 s 
2025-08-30 18:38:01.361674:  
2025-08-30 18:38:01.370088: Epoch 778 
2025-08-30 18:38:01.374262: Current learning rate: 0.00026 
2025-08-30 18:38:30.394413: train_loss -0.6555 
2025-08-30 18:38:30.403092: val_loss -0.5629 
2025-08-30 18:38:30.411126: Pseudo dice [np.float32(0.8153)] 
2025-08-30 18:38:30.416185: Epoch time: 29.03 s 
2025-08-30 18:38:31.087163:  
2025-08-30 18:38:31.095142: Epoch 779 
2025-08-30 18:38:31.100075: Current learning rate: 0.00026 
2025-08-30 18:39:00.028150: train_loss -0.6618 
2025-08-30 18:39:00.036964: val_loss -0.5906 
2025-08-30 18:39:00.041062: Pseudo dice [np.float32(0.8057)] 
2025-08-30 18:39:00.049006: Epoch time: 28.95 s 
2025-08-30 18:39:00.733376:  
2025-08-30 18:39:00.745547: Epoch 780 
2025-08-30 18:39:00.750136: Current learning rate: 0.00026 
2025-08-30 18:39:29.241204: train_loss -0.6618 
2025-08-30 18:39:29.253163: val_loss -0.6026 
2025-08-30 18:39:29.257606: Pseudo dice [np.float32(0.7582)] 
2025-08-30 18:39:29.264586: Epoch time: 28.51 s 
2025-08-30 18:39:29.945885:  
2025-08-30 18:39:29.954235: Epoch 781 
2025-08-30 18:39:29.958328: Current learning rate: 0.00025 
2025-08-30 18:39:58.870516: train_loss -0.625 
2025-08-30 18:39:58.878912: val_loss -0.6683 
2025-08-30 18:39:58.887295: Pseudo dice [np.float32(0.8157)] 
2025-08-30 18:39:58.891903: Epoch time: 28.92 s 
2025-08-30 18:39:59.571220:  
2025-08-30 18:39:59.575481: Epoch 782 
2025-08-30 18:39:59.583807: Current learning rate: 0.00025 
2025-08-30 18:40:28.270299: train_loss -0.6639 
2025-08-30 18:40:28.283113: val_loss -0.6227 
2025-08-30 18:40:28.287277: Pseudo dice [np.float32(0.8085)] 
2025-08-30 18:40:28.294369: Epoch time: 28.7 s 
2025-08-30 18:40:28.975571:  
2025-08-30 18:40:28.983903: Epoch 783 
2025-08-30 18:40:28.991853: Current learning rate: 0.00025 
2025-08-30 18:40:57.420653: train_loss -0.6319 
2025-08-30 18:40:57.420653: val_loss -0.5986 
2025-08-30 18:40:57.431302: Pseudo dice [np.float32(0.7605)] 
2025-08-30 18:40:57.438182: Epoch time: 28.45 s 
2025-08-30 18:40:58.267180:  
2025-08-30 18:40:58.275544: Epoch 784 
2025-08-30 18:40:58.279725: Current learning rate: 0.00025 
2025-08-30 18:41:26.995515: train_loss -0.6617 
2025-08-30 18:41:27.004172: val_loss -0.6915 
2025-08-30 18:41:27.008322: Pseudo dice [np.float32(0.8054)] 
2025-08-30 18:41:27.016376: Epoch time: 28.73 s 
2025-08-30 18:41:27.692469:  
2025-08-30 18:41:27.700834: Epoch 785 
2025-08-30 18:41:27.704957: Current learning rate: 0.00025 
2025-08-30 18:41:56.975394: train_loss -0.6219 
2025-08-30 18:41:56.984097: val_loss -0.6848 
2025-08-30 18:41:56.988233: Pseudo dice [np.float32(0.8159)] 
2025-08-30 18:41:56.996102: Epoch time: 29.29 s 
2025-08-30 18:41:57.680685:  
2025-08-30 18:41:57.689070: Epoch 786 
2025-08-30 18:41:57.693212: Current learning rate: 0.00025 
2025-08-30 18:42:25.889443: train_loss -0.6236 
2025-08-30 18:42:25.900584: val_loss -0.6453 
2025-08-30 18:42:25.904733: Pseudo dice [np.float32(0.838)] 
2025-08-30 18:42:25.912609: Epoch time: 28.21 s 
2025-08-30 18:42:26.584541:  
2025-08-30 18:42:26.592876: Epoch 787 
2025-08-30 18:42:26.597061: Current learning rate: 0.00025 
2025-08-30 18:42:55.838575: train_loss -0.62 
2025-08-30 18:42:55.846959: val_loss -0.5974 
2025-08-30 18:42:55.855275: Pseudo dice [np.float32(0.785)] 
2025-08-30 18:42:55.861208: Epoch time: 29.26 s 
2025-08-30 18:42:56.539774:  
2025-08-30 18:42:56.547784: Epoch 788 
2025-08-30 18:42:56.551887: Current learning rate: 0.00025 
2025-08-30 18:43:25.017748: train_loss -0.6257 
2025-08-30 18:43:25.030305: val_loss -0.5999 
2025-08-30 18:43:25.034484: Pseudo dice [np.float32(0.8343)] 
2025-08-30 18:43:25.042212: Epoch time: 28.48 s 
2025-08-30 18:43:25.730911:  
2025-08-30 18:43:25.739235: Epoch 789 
2025-08-30 18:43:25.743420: Current learning rate: 0.00025 
2025-08-30 18:43:54.185291: train_loss -0.6814 
2025-08-30 18:43:54.192720: val_loss -0.5702 
2025-08-30 18:43:54.201507: Pseudo dice [np.float32(0.7497)] 
2025-08-30 18:43:54.206258: Epoch time: 28.46 s 
2025-08-30 18:43:55.059815:  
2025-08-30 18:43:55.068585: Epoch 790 
2025-08-30 18:43:55.072767: Current learning rate: 0.00025 
2025-08-30 18:44:23.689360: train_loss -0.6595 
2025-08-30 18:44:23.701294: val_loss -0.5765 
2025-08-30 18:44:23.705470: Pseudo dice [np.float32(0.8043)] 
2025-08-30 18:44:23.714298: Epoch time: 28.63 s 
2025-08-30 18:44:24.397742:  
2025-08-30 18:44:24.406118: Epoch 791 
2025-08-30 18:44:24.410253: Current learning rate: 0.00024 
2025-08-30 18:44:53.372125: train_loss -0.6169 
2025-08-30 18:44:53.380479: val_loss -0.709 
2025-08-30 18:44:53.384997: Pseudo dice [np.float32(0.8107)] 
2025-08-30 18:44:53.390925: Epoch time: 28.97 s 
2025-08-30 18:44:54.064869:  
2025-08-30 18:44:54.073270: Epoch 792 
2025-08-30 18:44:54.077354: Current learning rate: 0.00024 
2025-08-30 18:45:22.693493: train_loss -0.6317 
2025-08-30 18:45:22.701807: val_loss -0.6894 
2025-08-30 18:45:22.710508: Pseudo dice [np.float32(0.8381)] 
2025-08-30 18:45:22.716063: Epoch time: 28.63 s 
2025-08-30 18:45:23.397890:  
2025-08-30 18:45:23.406569: Epoch 793 
2025-08-30 18:45:23.414933: Current learning rate: 0.00024 
2025-08-30 18:45:52.239136: train_loss -0.6448 
2025-08-30 18:45:52.239136: val_loss -0.7182 
2025-08-30 18:45:52.247951: Pseudo dice [np.float32(0.8151)] 
2025-08-30 18:45:52.253841: Epoch time: 28.84 s 
2025-08-30 18:45:53.030002:  
2025-08-30 18:45:53.036353: Epoch 794 
2025-08-30 18:45:53.044569: Current learning rate: 0.00024 
2025-08-30 18:46:22.160644: train_loss -0.6468 
2025-08-30 18:46:22.169334: val_loss -0.626 
2025-08-30 18:46:22.173499: Pseudo dice [np.float32(0.8125)] 
2025-08-30 18:46:22.181153: Epoch time: 29.13 s 
2025-08-30 18:46:22.861782:  
2025-08-30 18:46:22.870147: Epoch 795 
2025-08-30 18:46:22.878470: Current learning rate: 0.00024 
2025-08-30 18:46:51.227557: train_loss -0.6471 
2025-08-30 18:46:51.235895: val_loss -0.6812 
2025-08-30 18:46:51.240094: Pseudo dice [np.float32(0.8359)] 
2025-08-30 18:46:51.248906: Epoch time: 28.37 s 
2025-08-30 18:46:52.074169:  
2025-08-30 18:46:52.082484: Epoch 796 
2025-08-30 18:46:52.086316: Current learning rate: 0.00024 
2025-08-30 18:47:21.111513: train_loss -0.6627 
2025-08-30 18:47:21.119888: val_loss -0.6296 
2025-08-30 18:47:21.128284: Pseudo dice [np.float32(0.8351)] 
2025-08-30 18:47:21.132828: Epoch time: 29.04 s 
2025-08-30 18:47:21.804617:  
2025-08-30 18:47:21.812210: Epoch 797 
2025-08-30 18:47:21.816451: Current learning rate: 0.00024 
2025-08-30 18:47:50.903630: train_loss -0.6378 
2025-08-30 18:47:50.916142: val_loss -0.6123 
2025-08-30 18:47:50.920338: Pseudo dice [np.float32(0.8275)] 
2025-08-30 18:47:50.926284: Epoch time: 29.1 s 
2025-08-30 18:47:50.932979: Yayy! New best EMA pseudo Dice: 0.8134999871253967 
2025-08-30 18:47:51.825494:  
2025-08-30 18:47:51.835510: Epoch 798 
2025-08-30 18:47:51.838553: Current learning rate: 0.00024 
2025-08-30 18:48:20.328918: train_loss -0.6485 
2025-08-30 18:48:20.337249: val_loss -0.6051 
2025-08-30 18:48:20.345986: Pseudo dice [np.float32(0.7924)] 
2025-08-30 18:48:20.350791: Epoch time: 28.5 s 
2025-08-30 18:48:21.016676:  
2025-08-30 18:48:21.025329: Epoch 799 
2025-08-30 18:48:21.029541: Current learning rate: 0.00024 
2025-08-30 18:48:49.758156: train_loss -0.6293 
2025-08-30 18:48:49.770676: val_loss -0.6255 
2025-08-30 18:48:49.774499: Pseudo dice [np.float32(0.8108)] 
2025-08-30 18:48:49.783729: Epoch time: 28.74 s 
2025-08-30 18:48:50.688357:  
2025-08-30 18:48:50.696689: Epoch 800 
2025-08-30 18:48:50.700535: Current learning rate: 0.00023 
2025-08-30 18:49:19.754774: train_loss -0.638 
2025-08-30 18:49:19.762748: val_loss -0.6697 
2025-08-30 18:49:19.772748: Pseudo dice [np.float32(0.8352)] 
2025-08-30 18:49:19.777376: Epoch time: 29.07 s 
2025-08-30 18:49:19.784296: Yayy! New best EMA pseudo Dice: 0.8137000203132629 
2025-08-30 18:49:20.684931:  
2025-08-30 18:49:20.693248: Epoch 801 
2025-08-30 18:49:20.697430: Current learning rate: 0.00023 
2025-08-30 18:49:48.554280: train_loss -0.6157 
2025-08-30 18:49:48.566802: val_loss -0.6225 
2025-08-30 18:49:48.575501: Pseudo dice [np.float32(0.8039)] 
2025-08-30 18:49:48.581316: Epoch time: 27.87 s 
2025-08-30 18:49:49.413568:  
2025-08-30 18:49:49.421903: Epoch 802 
2025-08-30 18:49:49.430279: Current learning rate: 0.00023 
2025-08-30 18:50:18.225194: train_loss -0.6344 
2025-08-30 18:50:18.225194: val_loss -0.6079 
2025-08-30 18:50:18.234009: Pseudo dice [np.float32(0.8305)] 
2025-08-30 18:50:18.238561: Epoch time: 28.81 s 
2025-08-30 18:50:18.247002: Yayy! New best EMA pseudo Dice: 0.8144999742507935 
2025-08-30 18:50:19.139236:  
2025-08-30 18:50:19.147392: Epoch 803 
2025-08-30 18:50:19.151608: Current learning rate: 0.00023 
2025-08-30 18:50:48.063663: train_loss -0.646 
2025-08-30 18:50:48.072069: val_loss -0.5948 
2025-08-30 18:50:48.080438: Pseudo dice [np.float32(0.8291)] 
2025-08-30 18:50:48.085484: Epoch time: 28.93 s 
2025-08-30 18:50:48.091678: Yayy! New best EMA pseudo Dice: 0.8159999847412109 
2025-08-30 18:50:48.993838:  
2025-08-30 18:50:49.002130: Epoch 804 
2025-08-30 18:50:49.006302: Current learning rate: 0.00023 
2025-08-30 18:51:17.100607: train_loss -0.6212 
2025-08-30 18:51:17.108932: val_loss -0.6123 
2025-08-30 18:51:17.113410: Pseudo dice [np.float32(0.7335)] 
2025-08-30 18:51:17.120212: Epoch time: 28.11 s 
2025-08-30 18:51:17.785031:  
2025-08-30 18:51:17.793375: Epoch 805 
2025-08-30 18:51:17.801731: Current learning rate: 0.00023 
2025-08-30 18:51:46.235787: train_loss -0.621 
2025-08-30 18:51:46.242465: val_loss -0.5905 
2025-08-30 18:51:46.251135: Pseudo dice [np.float32(0.7765)] 
2025-08-30 18:51:46.256739: Epoch time: 28.45 s 
2025-08-30 18:51:46.926538:  
2025-08-30 18:51:46.934936: Epoch 806 
2025-08-30 18:51:46.939131: Current learning rate: 0.00023 
2025-08-30 18:52:15.534268: train_loss -0.6473 
2025-08-30 18:52:15.542660: val_loss -0.5355 
2025-08-30 18:52:15.546786: Pseudo dice [np.float32(0.7338)] 
2025-08-30 18:52:15.554613: Epoch time: 28.61 s 
2025-08-30 18:52:16.222425:  
2025-08-30 18:52:16.230727: Epoch 807 
2025-08-30 18:52:16.234552: Current learning rate: 0.00023 
2025-08-30 18:52:44.517008: train_loss -0.6058 
2025-08-30 18:52:44.525721: val_loss -0.5893 
2025-08-30 18:52:44.534120: Pseudo dice [np.float32(0.7882)] 
2025-08-30 18:52:44.541911: Epoch time: 28.3 s 
2025-08-30 18:52:45.355665:  
2025-08-30 18:52:45.364131: Epoch 808 
2025-08-30 18:52:45.371892: Current learning rate: 0.00023 
2025-08-30 18:53:13.374846: train_loss -0.6531 
2025-08-30 18:53:13.383614: val_loss -0.6644 
2025-08-30 18:53:13.387827: Pseudo dice [np.float32(0.8468)] 
2025-08-30 18:53:13.394762: Epoch time: 28.02 s 
2025-08-30 18:53:14.063482:  
2025-08-30 18:53:14.071868: Epoch 809 
2025-08-30 18:53:14.080197: Current learning rate: 0.00023 
2025-08-30 18:53:43.163306: train_loss -0.6518 
2025-08-30 18:53:43.175925: val_loss -0.6157 
2025-08-30 18:53:43.180038: Pseudo dice [np.float32(0.8151)] 
2025-08-30 18:53:43.188766: Epoch time: 29.1 s 
2025-08-30 18:53:43.851389:  
2025-08-30 18:53:43.859729: Epoch 810 
2025-08-30 18:53:43.863943: Current learning rate: 0.00022 
2025-08-30 18:54:12.417048: train_loss -0.65 
2025-08-30 18:54:12.425766: val_loss -0.6306 
2025-08-30 18:54:12.434638: Pseudo dice [np.float32(0.8101)] 
2025-08-30 18:54:12.439234: Epoch time: 28.57 s 
2025-08-30 18:54:13.109822:  
2025-08-30 18:54:13.118203: Epoch 811 
2025-08-30 18:54:13.126537: Current learning rate: 0.00022 
2025-08-30 18:54:41.905156: train_loss -0.6493 
2025-08-30 18:54:41.917732: val_loss -0.6302 
2025-08-30 18:54:41.921917: Pseudo dice [np.float32(0.8095)] 
2025-08-30 18:54:41.928700: Epoch time: 28.8 s 
2025-08-30 18:54:42.589168:  
2025-08-30 18:54:42.597183: Epoch 812 
2025-08-30 18:54:42.605839: Current learning rate: 0.00022 
2025-08-30 18:55:11.892013: train_loss -0.651 
2025-08-30 18:55:11.892013: val_loss -0.6566 
2025-08-30 18:55:11.901396: Pseudo dice [np.float32(0.8063)] 
2025-08-30 18:55:11.907285: Epoch time: 29.3 s 
2025-08-30 18:55:12.577041:  
2025-08-30 18:55:12.585749: Epoch 813 
2025-08-30 18:55:12.589910: Current learning rate: 0.00022 
2025-08-30 18:55:40.817704: train_loss -0.6349 
2025-08-30 18:55:40.826484: val_loss -0.6255 
2025-08-30 18:55:40.830666: Pseudo dice [np.float32(0.7943)] 
2025-08-30 18:55:40.838511: Epoch time: 28.24 s 
2025-08-30 18:55:41.506307:  
2025-08-30 18:55:41.514723: Epoch 814 
2025-08-30 18:55:41.523079: Current learning rate: 0.00022 
2025-08-30 18:56:10.426761: train_loss -0.6566 
2025-08-30 18:56:10.435166: val_loss -0.6265 
2025-08-30 18:56:10.439394: Pseudo dice [np.float32(0.7942)] 
2025-08-30 18:56:10.448136: Epoch time: 28.92 s 
2025-08-30 18:56:11.118752:  
2025-08-30 18:56:11.127083: Epoch 815 
2025-08-30 18:56:11.131626: Current learning rate: 0.00022 
2025-08-30 18:56:40.060407: train_loss -0.6591 
2025-08-30 18:56:40.072648: val_loss -0.5971 
2025-08-30 18:56:40.077129: Pseudo dice [np.float32(0.7861)] 
2025-08-30 18:56:40.085179: Epoch time: 28.95 s 
2025-08-30 18:56:40.752514:  
2025-08-30 18:56:40.760827: Epoch 816 
2025-08-30 18:56:40.765404: Current learning rate: 0.00022 
2025-08-30 18:57:09.627510: train_loss -0.6471 
2025-08-30 18:57:09.635867: val_loss -0.655 
2025-08-30 18:57:09.640086: Pseudo dice [np.float32(0.8128)] 
2025-08-30 18:57:09.647964: Epoch time: 28.88 s 
2025-08-30 18:57:10.336525:  
2025-08-30 18:57:10.344933: Epoch 817 
2025-08-30 18:57:10.353312: Current learning rate: 0.00022 
2025-08-30 18:57:38.539721: train_loss -0.6407 
2025-08-30 18:57:38.548000: val_loss -0.6588 
2025-08-30 18:57:38.556447: Pseudo dice [np.float32(0.7971)] 
2025-08-30 18:57:38.562283: Epoch time: 28.2 s 
2025-08-30 18:57:39.227870:  
2025-08-30 18:57:39.236252: Epoch 818 
2025-08-30 18:57:39.240415: Current learning rate: 0.00022 
2025-08-30 18:58:08.469554: train_loss -0.6592 
2025-08-30 18:58:08.477901: val_loss -0.6424 
2025-08-30 18:58:08.486275: Pseudo dice [np.float32(0.8106)] 
2025-08-30 18:58:08.492199: Epoch time: 29.25 s 
2025-08-30 18:58:09.157724:  
2025-08-30 18:58:09.166085: Epoch 819 
2025-08-30 18:58:09.174020: Current learning rate: 0.00021 
2025-08-30 18:58:36.947912: train_loss -0.6492 
2025-08-30 18:58:36.960468: val_loss -0.5889 
2025-08-30 18:58:36.964623: Pseudo dice [np.float32(0.8432)] 
2025-08-30 18:58:36.972356: Epoch time: 27.79 s 
2025-08-30 18:58:37.627333:  
2025-08-30 18:58:37.636042: Epoch 820 
2025-08-30 18:58:37.639894: Current learning rate: 0.00021 
2025-08-30 18:59:06.339340: train_loss -0.6583 
2025-08-30 18:59:06.347974: val_loss -0.6318 
2025-08-30 18:59:06.352243: Pseudo dice [np.float32(0.8377)] 
2025-08-30 18:59:06.360024: Epoch time: 28.71 s 
2025-08-30 18:59:07.148848:  
2025-08-30 18:59:07.157249: Epoch 821 
2025-08-30 18:59:07.161421: Current learning rate: 0.00021 
2025-08-30 18:59:35.973346: train_loss -0.6349 
2025-08-30 18:59:35.973346: val_loss -0.6243 
2025-08-30 18:59:35.981805: Pseudo dice [np.float32(0.8014)] 
2025-08-30 18:59:35.991189: Epoch time: 28.83 s 
2025-08-30 18:59:36.636181:  
2025-08-30 18:59:36.646946: Epoch 822 
2025-08-30 18:59:36.652334: Current learning rate: 0.00021 
2025-08-30 19:00:05.048244: train_loss -0.6485 
2025-08-30 19:00:05.056628: val_loss -0.6397 
2025-08-30 19:00:05.060733: Pseudo dice [np.float32(0.8162)] 
2025-08-30 19:00:05.068552: Epoch time: 28.41 s 
2025-08-30 19:00:05.707142:  
2025-08-30 19:00:05.711433: Epoch 823 
2025-08-30 19:00:05.719753: Current learning rate: 0.00021 
2025-08-30 19:00:34.227245: train_loss -0.646 
2025-08-30 19:00:34.239826: val_loss -0.5838 
2025-08-30 19:00:34.248182: Pseudo dice [np.float32(0.7534)] 
2025-08-30 19:00:34.253849: Epoch time: 28.52 s 
2025-08-30 19:00:34.902945:  
2025-08-30 19:00:34.910969: Epoch 824 
2025-08-30 19:00:34.915603: Current learning rate: 0.00021 
2025-08-30 19:01:03.744249: train_loss -0.6588 
2025-08-30 19:01:03.752845: val_loss -0.613 
2025-08-30 19:01:03.761699: Pseudo dice [np.float32(0.8248)] 
2025-08-30 19:01:03.767723: Epoch time: 28.85 s 
2025-08-30 19:01:04.407478:  
2025-08-30 19:01:04.415788: Epoch 825 
2025-08-30 19:01:04.424204: Current learning rate: 0.00021 
2025-08-30 19:01:32.922941: train_loss -0.6449 
2025-08-30 19:01:32.931635: val_loss -0.6014 
2025-08-30 19:01:32.935820: Pseudo dice [np.float32(0.8405)] 
2025-08-30 19:01:32.943682: Epoch time: 28.52 s 
2025-08-30 19:01:33.590732:  
2025-08-30 19:01:33.599101: Epoch 826 
2025-08-30 19:01:33.606981: Current learning rate: 0.00021 
2025-08-30 19:02:02.044678: train_loss -0.6596 
2025-08-30 19:02:02.052471: val_loss -0.558 
2025-08-30 19:02:02.056670: Pseudo dice [np.float32(0.7627)] 
2025-08-30 19:02:02.063561: Epoch time: 28.45 s 
2025-08-30 19:02:02.702664:  
2025-08-30 19:02:02.711314: Epoch 827 
2025-08-30 19:02:02.719712: Current learning rate: 0.00021 
2025-08-30 19:02:31.844516: train_loss -0.6722 
2025-08-30 19:02:31.857062: val_loss -0.6527 
2025-08-30 19:02:31.861261: Pseudo dice [np.float32(0.8396)] 
2025-08-30 19:02:31.870142: Epoch time: 29.14 s 
2025-08-30 19:02:32.674646:  
2025-08-30 19:02:32.683023: Epoch 828 
2025-08-30 19:02:32.690904: Current learning rate: 0.00021 
2025-08-30 19:03:01.032325: train_loss -0.6209 
2025-08-30 19:03:01.044938: val_loss -0.6158 
2025-08-30 19:03:01.053213: Pseudo dice [np.float32(0.7968)] 
2025-08-30 19:03:01.065040: Epoch time: 28.36 s 
2025-08-30 19:03:01.732349:  
2025-08-30 19:03:01.741082: Epoch 829 
2025-08-30 19:03:01.745183: Current learning rate: 0.0002 
2025-08-30 19:03:30.720054: train_loss -0.6235 
2025-08-30 19:03:30.732515: val_loss -0.6423 
2025-08-30 19:03:30.740456: Pseudo dice [np.float32(0.7886)] 
2025-08-30 19:03:30.745931: Epoch time: 28.99 s 
2025-08-30 19:03:31.395736:  
2025-08-30 19:03:31.404026: Epoch 830 
2025-08-30 19:03:31.408215: Current learning rate: 0.0002 
2025-08-30 19:04:00.490955: train_loss -0.6695 
2025-08-30 19:04:00.499604: val_loss -0.6276 
2025-08-30 19:04:00.503839: Pseudo dice [np.float32(0.8369)] 
2025-08-30 19:04:00.511737: Epoch time: 29.1 s 
2025-08-30 19:04:01.158697:  
2025-08-30 19:04:01.167021: Epoch 831 
2025-08-30 19:04:01.171235: Current learning rate: 0.0002 
2025-08-30 19:04:29.883346: train_loss -0.6382 
2025-08-30 19:04:29.883346: val_loss -0.6961 
2025-08-30 19:04:29.896208: Pseudo dice [np.float32(0.8602)] 
2025-08-30 19:04:29.900419: Epoch time: 28.73 s 
2025-08-30 19:04:30.545956:  
2025-08-30 19:04:30.554302: Epoch 832 
2025-08-30 19:04:30.558432: Current learning rate: 0.0002 
2025-08-30 19:04:58.962659: train_loss -0.6332 
2025-08-30 19:04:58.970543: val_loss -0.6133 
2025-08-30 19:04:58.974720: Pseudo dice [np.float32(0.761)] 
2025-08-30 19:04:58.983499: Epoch time: 28.42 s 
2025-08-30 19:04:59.625349:  
2025-08-30 19:04:59.633687: Epoch 833 
2025-08-30 19:04:59.637780: Current learning rate: 0.0002 
2025-08-30 19:05:29.154794: train_loss -0.6224 
2025-08-30 19:05:29.167191: val_loss -0.593 
2025-08-30 19:05:29.171364: Pseudo dice [np.float32(0.8052)] 
2025-08-30 19:05:29.179235: Epoch time: 29.53 s 
2025-08-30 19:05:29.817952:  
2025-08-30 19:05:29.826283: Epoch 834 
2025-08-30 19:05:29.830489: Current learning rate: 0.0002 
2025-08-30 19:05:58.617447: train_loss -0.6407 
2025-08-30 19:05:58.625857: val_loss -0.6759 
2025-08-30 19:05:58.630020: Pseudo dice [np.float32(0.8368)] 
2025-08-30 19:05:58.636898: Epoch time: 28.8 s 
2025-08-30 19:05:59.288595:  
2025-08-30 19:05:59.297256: Epoch 835 
2025-08-30 19:05:59.301443: Current learning rate: 0.0002 
2025-08-30 19:06:27.946704: train_loss -0.649 
2025-08-30 19:06:27.954971: val_loss -0.6195 
2025-08-30 19:06:27.963664: Pseudo dice [np.float32(0.8157)] 
2025-08-30 19:06:27.969264: Epoch time: 28.66 s 
2025-08-30 19:06:28.614095:  
2025-08-30 19:06:28.622426: Epoch 836 
2025-08-30 19:06:28.626607: Current learning rate: 0.0002 
2025-08-30 19:06:57.588790: train_loss -0.6773 
2025-08-30 19:06:57.597141: val_loss -0.668 
2025-08-30 19:06:57.601319: Pseudo dice [np.float32(0.7916)] 
2025-08-30 19:06:57.610646: Epoch time: 28.98 s 
2025-08-30 19:06:58.251542:  
2025-08-30 19:06:58.260197: Epoch 837 
2025-08-30 19:06:58.264367: Current learning rate: 0.0002 
2025-08-30 19:07:27.034406: train_loss -0.6369 
2025-08-30 19:07:27.042758: val_loss -0.6074 
2025-08-30 19:07:27.051710: Pseudo dice [np.float32(0.7993)] 
2025-08-30 19:07:27.056634: Epoch time: 28.78 s 
2025-08-30 19:07:27.722973:  
2025-08-30 19:07:27.731422: Epoch 838 
2025-08-30 19:07:27.739662: Current learning rate: 0.00019 
2025-08-30 19:07:56.447546: train_loss -0.6561 
2025-08-30 19:07:56.455882: val_loss -0.6618 
2025-08-30 19:07:56.464202: Pseudo dice [np.float32(0.7959)] 
2025-08-30 19:07:56.470252: Epoch time: 28.72 s 
2025-08-30 19:07:57.110657:  
2025-08-30 19:07:57.119057: Epoch 839 
2025-08-30 19:07:57.123179: Current learning rate: 0.00019 
2025-08-30 19:08:26.131348: train_loss -0.6289 
2025-08-30 19:08:26.143802: val_loss -0.6632 
2025-08-30 19:08:26.151713: Pseudo dice [np.float32(0.7908)] 
2025-08-30 19:08:26.157155: Epoch time: 29.02 s 
2025-08-30 19:08:26.790193:  
2025-08-30 19:08:26.798196: Epoch 840 
2025-08-30 19:08:26.806549: Current learning rate: 0.00019 
2025-08-30 19:08:55.831967: train_loss -0.6556 
2025-08-30 19:08:55.832972: val_loss -0.6414 
2025-08-30 19:08:55.841649: Pseudo dice [np.float32(0.8189)] 
2025-08-30 19:08:55.847767: Epoch time: 29.04 s 
2025-08-30 19:08:56.536520:  
2025-08-30 19:08:56.544915: Epoch 841 
2025-08-30 19:08:56.549083: Current learning rate: 0.00019 
2025-08-30 19:09:24.618301: train_loss -0.6487 
2025-08-30 19:09:24.631197: val_loss -0.6181 
2025-08-30 19:09:24.639645: Pseudo dice [np.float32(0.7873)] 
2025-08-30 19:09:24.645541: Epoch time: 28.08 s 
2025-08-30 19:09:25.432031:  
2025-08-30 19:09:25.440388: Epoch 842 
2025-08-30 19:09:25.444526: Current learning rate: 0.00019 
2025-08-30 19:09:54.811322: train_loss -0.6582 
2025-08-30 19:09:54.819629: val_loss -0.6282 
2025-08-30 19:09:54.828092: Pseudo dice [np.float32(0.8228)] 
2025-08-30 19:09:54.833238: Epoch time: 29.38 s 
2025-08-30 19:09:55.478261:  
2025-08-30 19:09:55.482833: Epoch 843 
2025-08-30 19:09:55.491241: Current learning rate: 0.00019 
2025-08-30 19:10:23.752654: train_loss -0.6648 
2025-08-30 19:10:23.765221: val_loss -0.619 
2025-08-30 19:10:23.769387: Pseudo dice [np.float32(0.7538)] 
2025-08-30 19:10:23.777952: Epoch time: 28.28 s 
2025-08-30 19:10:24.423775:  
2025-08-30 19:10:24.432128: Epoch 844 
2025-08-30 19:10:24.436621: Current learning rate: 0.00019 
2025-08-30 19:10:52.489599: train_loss -0.6229 
2025-08-30 19:10:52.498037: val_loss -0.6845 
2025-08-30 19:10:52.502248: Pseudo dice [np.float32(0.8463)] 
2025-08-30 19:10:52.510089: Epoch time: 28.07 s 
2025-08-30 19:10:53.148279:  
2025-08-30 19:10:53.157012: Epoch 845 
2025-08-30 19:10:53.165297: Current learning rate: 0.00019 
2025-08-30 19:11:22.168844: train_loss -0.6246 
2025-08-30 19:11:22.177558: val_loss -0.6777 
2025-08-30 19:11:22.185867: Pseudo dice [np.float32(0.8275)] 
2025-08-30 19:11:22.191797: Epoch time: 29.02 s 
2025-08-30 19:11:22.840749:  
2025-08-30 19:11:22.849125: Epoch 846 
2025-08-30 19:11:22.853343: Current learning rate: 0.00019 
2025-08-30 19:11:50.288916: train_loss -0.6192 
2025-08-30 19:11:50.301497: val_loss -0.6138 
2025-08-30 19:11:50.305637: Pseudo dice [np.float32(0.8147)] 
2025-08-30 19:11:50.314456: Epoch time: 27.45 s 
2025-08-30 19:11:50.968429:  
2025-08-30 19:11:50.977065: Epoch 847 
2025-08-30 19:11:50.981301: Current learning rate: 0.00018 
2025-08-30 19:12:18.362859: train_loss -0.6243 
2025-08-30 19:12:18.371039: val_loss -0.6061 
2025-08-30 19:12:18.379386: Pseudo dice [np.float32(0.7906)] 
2025-08-30 19:12:18.384104: Epoch time: 27.4 s 
2025-08-30 19:12:19.021793:  
2025-08-30 19:12:19.030130: Epoch 848 
2025-08-30 19:12:19.034310: Current learning rate: 0.00018 
2025-08-30 19:12:46.294719: train_loss -0.6581 
2025-08-30 19:12:46.307373: val_loss -0.6593 
2025-08-30 19:12:46.315256: Pseudo dice [np.float32(0.8405)] 
2025-08-30 19:12:46.320846: Epoch time: 27.27 s 
2025-08-30 19:12:47.128583:  
2025-08-30 19:12:47.137242: Epoch 849 
2025-08-30 19:12:47.141395: Current learning rate: 0.00018 
2025-08-30 19:13:14.076689: train_loss -0.6477 
2025-08-30 19:13:14.085077: val_loss -0.5777 
2025-08-30 19:13:14.093418: Pseudo dice [np.float32(0.8295)] 
2025-08-30 19:13:14.099188: Epoch time: 26.95 s 
2025-08-30 19:13:14.971270:  
2025-08-30 19:13:14.977529: Epoch 850 
2025-08-30 19:13:14.985876: Current learning rate: 0.00018 
2025-08-30 19:13:41.378498: train_loss -0.6571 
2025-08-30 19:13:41.378498: val_loss -0.6413 
2025-08-30 19:13:41.393255: Pseudo dice [np.float32(0.7837)] 
2025-08-30 19:13:41.396093: Epoch time: 26.41 s 
2025-08-30 19:13:42.062867:  
2025-08-30 19:13:42.070869: Epoch 851 
2025-08-30 19:13:42.075516: Current learning rate: 0.00018 
2025-08-30 19:14:09.173277: train_loss -0.6792 
2025-08-30 19:14:09.181550: val_loss -0.5868 
2025-08-30 19:14:09.189569: Pseudo dice [np.float32(0.7599)] 
2025-08-30 19:14:09.194927: Epoch time: 27.11 s 
2025-08-30 19:14:09.836349:  
2025-08-30 19:14:09.844393: Epoch 852 
2025-08-30 19:14:09.848967: Current learning rate: 0.00018 
2025-08-30 19:14:37.647593: train_loss -0.6412 
2025-08-30 19:14:37.655776: val_loss -0.6595 
2025-08-30 19:14:37.664188: Pseudo dice [np.float32(0.806)] 
2025-08-30 19:14:37.668788: Epoch time: 27.82 s 
2025-08-30 19:14:38.302454:  
2025-08-30 19:14:38.310685: Epoch 853 
2025-08-30 19:14:38.315006: Current learning rate: 0.00018 
2025-08-30 19:15:05.704240: train_loss -0.6568 
2025-08-30 19:15:05.712592: val_loss -0.6624 
2025-08-30 19:15:05.717193: Pseudo dice [np.float32(0.8207)] 
2025-08-30 19:15:05.723031: Epoch time: 27.41 s 
2025-08-30 19:15:06.359072:  
2025-08-30 19:15:06.367399: Epoch 854 
2025-08-30 19:15:06.371892: Current learning rate: 0.00018 
2025-08-30 19:15:33.494900: train_loss -0.6439 
2025-08-30 19:15:33.503248: val_loss -0.6026 
2025-08-30 19:15:33.511600: Pseudo dice [np.float32(0.8074)] 
2025-08-30 19:15:33.517449: Epoch time: 27.14 s 
2025-08-30 19:15:34.157612:  
2025-08-30 19:15:34.165954: Epoch 855 
2025-08-30 19:15:34.170110: Current learning rate: 0.00018 
2025-08-30 19:16:01.739647: train_loss -0.6309 
2025-08-30 19:16:01.747936: val_loss -0.6221 
2025-08-30 19:16:01.756665: Pseudo dice [np.float32(0.8056)] 
2025-08-30 19:16:01.762299: Epoch time: 27.58 s 
2025-08-30 19:16:02.402926:  
2025-08-30 19:16:02.411185: Epoch 856 
2025-08-30 19:16:02.419503: Current learning rate: 0.00017 
2025-08-30 19:16:29.254284: train_loss -0.6694 
2025-08-30 19:16:29.262570: val_loss -0.6284 
2025-08-30 19:16:29.271283: Pseudo dice [np.float32(0.8009)] 
2025-08-30 19:16:29.277305: Epoch time: 26.85 s 
2025-08-30 19:16:29.905295:  
2025-08-30 19:16:29.913672: Epoch 857 
2025-08-30 19:16:29.921998: Current learning rate: 0.00017 
2025-08-30 19:16:56.935972: train_loss -0.6302 
2025-08-30 19:16:56.944360: val_loss -0.6586 
2025-08-30 19:16:56.948866: Pseudo dice [np.float32(0.7449)] 
2025-08-30 19:16:56.955674: Epoch time: 27.03 s 
2025-08-30 19:16:57.632918:  
2025-08-30 19:16:57.641360: Epoch 858 
2025-08-30 19:16:57.645503: Current learning rate: 0.00017 
2025-08-30 19:17:24.881044: train_loss -0.6496 
2025-08-30 19:17:24.893429: val_loss -0.648 
2025-08-30 19:17:24.897707: Pseudo dice [np.float32(0.8342)] 
2025-08-30 19:17:24.905343: Epoch time: 27.25 s 
2025-08-30 19:17:25.552023:  
2025-08-30 19:17:25.560686: Epoch 859 
2025-08-30 19:17:25.564543: Current learning rate: 0.00017 
2025-08-30 19:17:52.787832: train_loss -0.6513 
2025-08-30 19:17:52.796328: val_loss -0.6846 
2025-08-30 19:17:52.804224: Pseudo dice [np.float32(0.7965)] 
2025-08-30 19:17:52.809705: Epoch time: 27.24 s 
2025-08-30 19:17:53.438487:  
2025-08-30 19:17:53.446871: Epoch 860 
2025-08-30 19:17:53.450679: Current learning rate: 0.00017 
2025-08-30 19:18:19.981669: train_loss -0.652 
2025-08-30 19:18:19.981669: val_loss -0.6337 
2025-08-30 19:18:19.991347: Pseudo dice [np.float32(0.7753)] 
2025-08-30 19:18:19.997958: Epoch time: 26.54 s 
2025-08-30 19:18:20.636718:  
2025-08-30 19:18:20.644874: Epoch 861 
2025-08-30 19:18:20.649069: Current learning rate: 0.00017 
2025-08-30 19:18:48.047162: train_loss -0.658 
2025-08-30 19:18:48.059760: val_loss -0.593 
2025-08-30 19:18:48.063900: Pseudo dice [np.float32(0.7712)] 
2025-08-30 19:18:48.071608: Epoch time: 27.41 s 
2025-08-30 19:18:48.706269:  
2025-08-30 19:18:48.714593: Epoch 862 
2025-08-30 19:18:48.722965: Current learning rate: 0.00017 
2025-08-30 19:19:15.695173: train_loss -0.6534 
2025-08-30 19:19:15.703957: val_loss -0.6311 
2025-08-30 19:19:15.708153: Pseudo dice [np.float32(0.8012)] 
2025-08-30 19:19:15.715061: Epoch time: 26.99 s 
2025-08-30 19:19:16.392136:  
2025-08-30 19:19:16.400494: Epoch 863 
2025-08-30 19:19:16.404675: Current learning rate: 0.00017 
2025-08-30 19:19:43.123119: train_loss -0.6563 
2025-08-30 19:19:43.135474: val_loss -0.609 
2025-08-30 19:19:43.139647: Pseudo dice [np.float32(0.8091)] 
2025-08-30 19:19:43.147317: Epoch time: 26.74 s 
2025-08-30 19:19:43.773467:  
2025-08-30 19:19:43.781561: Epoch 864 
2025-08-30 19:19:43.785689: Current learning rate: 0.00017 
2025-08-30 19:20:10.829767: train_loss -0.6357 
2025-08-30 19:20:10.838084: val_loss -0.6137 
2025-08-30 19:20:10.846467: Pseudo dice [np.float32(0.7923)] 
2025-08-30 19:20:10.851674: Epoch time: 27.06 s 
2025-08-30 19:20:11.488311:  
2025-08-30 19:20:11.497212: Epoch 865 
2025-08-30 19:20:11.502969: Current learning rate: 0.00016 
2025-08-30 19:20:39.007716: train_loss -0.6585 
2025-08-30 19:20:39.020280: val_loss -0.6559 
2025-08-30 19:20:39.024415: Pseudo dice [np.float32(0.8109)] 
2025-08-30 19:20:39.032370: Epoch time: 27.52 s 
2025-08-30 19:20:39.666726:  
2025-08-30 19:20:39.675223: Epoch 866 
2025-08-30 19:20:39.683134: Current learning rate: 0.00016 
2025-08-30 19:21:06.386541: train_loss -0.6428 
2025-08-30 19:21:06.393415: val_loss -0.6528 
2025-08-30 19:21:06.397213: Pseudo dice [np.float32(0.8464)] 
2025-08-30 19:21:06.406663: Epoch time: 26.72 s 
2025-08-30 19:21:07.035754:  
2025-08-30 19:21:07.044184: Epoch 867 
2025-08-30 19:21:07.048335: Current learning rate: 0.00016 
2025-08-30 19:21:34.000055: train_loss -0.6442 
2025-08-30 19:21:34.012607: val_loss -0.6235 
2025-08-30 19:21:34.020961: Pseudo dice [np.float32(0.7678)] 
2025-08-30 19:21:34.027959: Epoch time: 26.97 s 
2025-08-30 19:21:34.663342:  
2025-08-30 19:21:34.673410: Epoch 868 
2025-08-30 19:21:34.679609: Current learning rate: 0.00016 
2025-08-30 19:22:01.965596: train_loss -0.6905 
2025-08-30 19:22:01.973933: val_loss -0.5897 
2025-08-30 19:22:01.982311: Pseudo dice [np.float32(0.7605)] 
2025-08-30 19:22:01.987530: Epoch time: 27.3 s 
2025-08-30 19:22:02.620382:  
2025-08-30 19:22:02.628713: Epoch 869 
2025-08-30 19:22:02.637100: Current learning rate: 0.00016 
2025-08-30 19:22:29.721960: train_loss -0.6542 
2025-08-30 19:22:29.730784: val_loss -0.6834 
2025-08-30 19:22:29.739199: Pseudo dice [np.float32(0.8599)] 
2025-08-30 19:22:29.744133: Epoch time: 27.1 s 
2025-08-30 19:22:30.531124:  
2025-08-30 19:22:30.539509: Epoch 870 
2025-08-30 19:22:30.543634: Current learning rate: 0.00016 
2025-08-30 19:22:57.425313: train_loss -0.7051 
2025-08-30 19:22:57.425313: val_loss -0.5681 
2025-08-30 19:22:57.434985: Pseudo dice [np.float32(0.75)] 
2025-08-30 19:22:57.442243: Epoch time: 26.9 s 
2025-08-30 19:22:58.133934:  
2025-08-30 19:22:58.142338: Epoch 871 
2025-08-30 19:22:58.146472: Current learning rate: 0.00016 
2025-08-30 19:23:26.053839: train_loss -0.6916 
2025-08-30 19:23:26.065145: val_loss -0.5946 
2025-08-30 19:23:26.070296: Pseudo dice [np.float32(0.7827)] 
2025-08-30 19:23:26.075973: Epoch time: 27.92 s 
2025-08-30 19:23:26.716304:  
2025-08-30 19:23:26.720882: Epoch 872 
2025-08-30 19:23:26.729191: Current learning rate: 0.00016 
2025-08-30 19:23:53.601430: train_loss -0.6888 
2025-08-30 19:23:53.609792: val_loss -0.6405 
2025-08-30 19:23:53.615496: Pseudo dice [np.float32(0.8258)] 
2025-08-30 19:23:53.622272: Epoch time: 26.89 s 
2025-08-30 19:23:54.296346:  
2025-08-30 19:23:54.302495: Epoch 873 
2025-08-30 19:23:54.310533: Current learning rate: 0.00016 
2025-08-30 19:24:21.443819: train_loss -0.6469 
2025-08-30 19:24:21.450514: val_loss -0.6466 
2025-08-30 19:24:21.459202: Pseudo dice [np.float32(0.8203)] 
2025-08-30 19:24:21.464681: Epoch time: 27.15 s 
2025-08-30 19:24:22.092344:  
2025-08-30 19:24:22.100700: Epoch 874 
2025-08-30 19:24:22.104878: Current learning rate: 0.00016 
2025-08-30 19:24:49.520018: train_loss -0.6665 
2025-08-30 19:24:49.532639: val_loss -0.6064 
2025-08-30 19:24:49.536706: Pseudo dice [np.float32(0.7921)] 
2025-08-30 19:24:49.544611: Epoch time: 27.43 s 
2025-08-30 19:24:50.187445:  
2025-08-30 19:24:50.195914: Epoch 875 
2025-08-30 19:24:50.199953: Current learning rate: 0.00015 
2025-08-30 19:25:17.910872: train_loss -0.6176 
2025-08-30 19:25:17.919328: val_loss -0.5982 
2025-08-30 19:25:17.927728: Pseudo dice [np.float32(0.8256)] 
2025-08-30 19:25:17.933607: Epoch time: 27.72 s 
2025-08-30 19:25:18.565318:  
2025-08-30 19:25:18.573688: Epoch 876 
2025-08-30 19:25:18.577878: Current learning rate: 0.00015 
2025-08-30 19:25:46.969190: train_loss -0.6422 
2025-08-30 19:25:46.981624: val_loss -0.5864 
2025-08-30 19:25:46.985766: Pseudo dice [np.float32(0.804)] 
2025-08-30 19:25:46.993576: Epoch time: 28.41 s 
2025-08-30 19:25:47.636419:  
2025-08-30 19:25:47.644762: Epoch 877 
2025-08-30 19:25:47.648847: Current learning rate: 0.00015 
2025-08-30 19:26:16.932284: train_loss -0.6383 
2025-08-30 19:26:16.940635: val_loss -0.5473 
2025-08-30 19:26:16.948995: Pseudo dice [np.float32(0.7567)] 
2025-08-30 19:26:16.953807: Epoch time: 29.3 s 
2025-08-30 19:26:17.758153:  
2025-08-30 19:26:17.766506: Epoch 878 
2025-08-30 19:26:17.772431: Current learning rate: 0.00015 
2025-08-30 19:26:46.261445: train_loss -0.651 
2025-08-30 19:26:46.273947: val_loss -0.6381 
2025-08-30 19:26:46.282316: Pseudo dice [np.float32(0.7967)] 
2025-08-30 19:26:46.287842: Epoch time: 28.51 s 
2025-08-30 19:26:46.933048:  
2025-08-30 19:26:46.941407: Epoch 879 
2025-08-30 19:26:46.945590: Current learning rate: 0.00015 
2025-08-30 19:27:15.585126: train_loss -0.6828 
2025-08-30 19:27:15.594965: val_loss -0.6154 
2025-08-30 19:27:15.599165: Pseudo dice [np.float32(0.8175)] 
2025-08-30 19:27:15.606057: Epoch time: 28.65 s 
2025-08-30 19:27:16.236843:  
2025-08-30 19:27:16.245544: Epoch 880 
2025-08-30 19:27:16.249683: Current learning rate: 0.00015 
2025-08-30 19:27:44.974176: train_loss -0.6398 
2025-08-30 19:27:44.974176: val_loss -0.636 
2025-08-30 19:27:44.987133: Pseudo dice [np.float32(0.8368)] 
2025-08-30 19:27:44.991463: Epoch time: 28.74 s 
2025-08-30 19:27:45.624855:  
2025-08-30 19:27:45.632830: Epoch 881 
2025-08-30 19:27:45.637440: Current learning rate: 0.00015 
2025-08-30 19:28:14.516313: train_loss -0.6589 
2025-08-30 19:28:14.524551: val_loss -0.6143 
2025-08-30 19:28:14.528729: Pseudo dice [np.float32(0.7758)] 
2025-08-30 19:28:14.536528: Epoch time: 28.9 s 
2025-08-30 19:28:15.170994:  
2025-08-30 19:28:15.179378: Epoch 882 
2025-08-30 19:28:15.183542: Current learning rate: 0.00015 
2025-08-30 19:28:43.891484: train_loss -0.631 
2025-08-30 19:28:43.899747: val_loss -0.5775 
2025-08-30 19:28:43.908046: Pseudo dice [np.float32(0.783)] 
2025-08-30 19:28:43.913878: Epoch time: 28.72 s 
2025-08-30 19:28:44.554445:  
2025-08-30 19:28:44.562827: Epoch 883 
2025-08-30 19:28:44.566997: Current learning rate: 0.00014 
2025-08-30 19:29:13.308088: train_loss -0.6412 
2025-08-30 19:29:13.316481: val_loss -0.5766 
2025-08-30 19:29:13.320632: Pseudo dice [np.float32(0.7511)] 
2025-08-30 19:29:13.328533: Epoch time: 28.75 s 
2025-08-30 19:29:13.950507:  
2025-08-30 19:29:13.958867: Epoch 884 
2025-08-30 19:29:13.967237: Current learning rate: 0.00014 
2025-08-30 19:29:42.954313: train_loss -0.6722 
2025-08-30 19:29:42.966937: val_loss -0.6961 
2025-08-30 19:29:42.971092: Pseudo dice [np.float32(0.8327)] 
2025-08-30 19:29:42.979876: Epoch time: 29.0 s 
2025-08-30 19:29:43.767269:  
2025-08-30 19:29:43.775975: Epoch 885 
2025-08-30 19:29:43.780134: Current learning rate: 0.00014 
2025-08-30 19:30:12.050115: train_loss -0.6339 
2025-08-30 19:30:12.058434: val_loss -0.6319 
2025-08-30 19:30:12.066328: Pseudo dice [np.float32(0.8068)] 
2025-08-30 19:30:12.071255: Epoch time: 28.28 s 
2025-08-30 19:30:12.700690:  
2025-08-30 19:30:12.709071: Epoch 886 
2025-08-30 19:30:12.717464: Current learning rate: 0.00014 
2025-08-30 19:30:41.349723: train_loss -0.6433 
2025-08-30 19:30:41.358084: val_loss -0.6564 
2025-08-30 19:30:41.367013: Pseudo dice [np.float32(0.8251)] 
2025-08-30 19:30:41.372802: Epoch time: 28.65 s 
2025-08-30 19:30:42.005001:  
2025-08-30 19:30:42.013294: Epoch 887 
2025-08-30 19:30:42.022884: Current learning rate: 0.00014 
2025-08-30 19:31:10.687747: train_loss -0.6552 
2025-08-30 19:31:10.696085: val_loss -0.6397 
2025-08-30 19:31:10.704398: Pseudo dice [np.float32(0.8441)] 
2025-08-30 19:31:10.710304: Epoch time: 28.68 s 
2025-08-30 19:31:11.346276:  
2025-08-30 19:31:11.354939: Epoch 888 
2025-08-30 19:31:11.359103: Current learning rate: 0.00014 
2025-08-30 19:31:39.687506: train_loss -0.681 
2025-08-30 19:31:39.699991: val_loss -0.6737 
2025-08-30 19:31:39.707891: Pseudo dice [np.float32(0.8333)] 
2025-08-30 19:31:39.713893: Epoch time: 28.34 s 
2025-08-30 19:31:40.350535:  
2025-08-30 19:31:40.354801: Epoch 889 
2025-08-30 19:31:40.363183: Current learning rate: 0.00014 
2025-08-30 19:32:09.054170: train_loss -0.6623 
2025-08-30 19:32:09.054170: val_loss -0.5514 
2025-08-30 19:32:09.062822: Pseudo dice [np.float32(0.7966)] 
2025-08-30 19:32:09.068409: Epoch time: 28.71 s 
2025-08-30 19:32:09.709036:  
2025-08-30 19:32:09.717399: Epoch 890 
2025-08-30 19:32:09.721646: Current learning rate: 0.00014 
2025-08-30 19:32:39.155159: train_loss -0.65 
2025-08-30 19:32:39.167628: val_loss -0.6005 
2025-08-30 19:32:39.176023: Pseudo dice [np.float32(0.784)] 
2025-08-30 19:32:39.181026: Epoch time: 29.45 s 
2025-08-30 19:32:39.826585:  
2025-08-30 19:32:39.834915: Epoch 891 
2025-08-30 19:32:39.843345: Current learning rate: 0.00014 
2025-08-30 19:33:08.351213: train_loss -0.6535 
2025-08-30 19:33:08.359213: val_loss -0.6296 
2025-08-30 19:33:08.363391: Pseudo dice [np.float32(0.8159)] 
2025-08-30 19:33:08.371146: Epoch time: 28.52 s 
2025-08-30 19:33:09.009427:  
2025-08-30 19:33:09.018110: Epoch 892 
2025-08-30 19:33:09.022283: Current learning rate: 0.00013 
2025-08-30 19:33:37.767244: train_loss -0.6787 
2025-08-30 19:33:37.775964: val_loss -0.6275 
2025-08-30 19:33:37.784643: Pseudo dice [np.float32(0.7837)] 
2025-08-30 19:33:37.789822: Epoch time: 28.76 s 
2025-08-30 19:33:38.581020:  
2025-08-30 19:33:38.589348: Epoch 893 
2025-08-30 19:33:38.593563: Current learning rate: 0.00013 
2025-08-30 19:34:07.276306: train_loss -0.6551 
2025-08-30 19:34:07.284656: val_loss -0.6739 
2025-08-30 19:34:07.288847: Pseudo dice [np.float32(0.8258)] 
2025-08-30 19:34:07.296692: Epoch time: 28.7 s 
2025-08-30 19:34:07.931083:  
2025-08-30 19:34:07.939454: Epoch 894 
2025-08-30 19:34:07.943663: Current learning rate: 0.00013 
2025-08-30 19:34:36.271893: train_loss -0.6194 
2025-08-30 19:34:36.284395: val_loss -0.605 
2025-08-30 19:34:36.288550: Pseudo dice [np.float32(0.7759)] 
2025-08-30 19:34:36.296561: Epoch time: 28.34 s 
2025-08-30 19:34:36.934939:  
2025-08-30 19:34:36.942962: Epoch 895 
2025-08-30 19:34:36.947587: Current learning rate: 0.00013 
2025-08-30 19:35:05.993082: train_loss -0.6803 
2025-08-30 19:35:06.001556: val_loss -0.6437 
2025-08-30 19:35:06.009470: Pseudo dice [np.float32(0.8471)] 
2025-08-30 19:35:06.014979: Epoch time: 29.06 s 
2025-08-30 19:35:06.647942:  
2025-08-30 19:35:06.656217: Epoch 896 
2025-08-30 19:35:06.660435: Current learning rate: 0.00013 
2025-08-30 19:35:35.743692: train_loss -0.6523 
2025-08-30 19:35:35.752034: val_loss -0.6628 
2025-08-30 19:35:35.760385: Pseudo dice [np.float32(0.8072)] 
2025-08-30 19:35:35.766237: Epoch time: 29.1 s 
2025-08-30 19:35:36.403845:  
2025-08-30 19:35:36.410615: Epoch 897 
2025-08-30 19:35:36.419252: Current learning rate: 0.00013 
2025-08-30 19:36:04.776334: train_loss -0.6281 
2025-08-30 19:36:04.780952: val_loss -0.6685 
2025-08-30 19:36:04.789289: Pseudo dice [np.float32(0.8362)] 
2025-08-30 19:36:04.794347: Epoch time: 28.37 s 
2025-08-30 19:36:05.435386:  
2025-08-30 19:36:05.444018: Epoch 898 
2025-08-30 19:36:05.448182: Current learning rate: 0.00013 
2025-08-30 19:36:33.901225: train_loss -0.6408 
2025-08-30 19:36:33.914103: val_loss -0.6246 
2025-08-30 19:36:33.918242: Pseudo dice [np.float32(0.7917)] 
2025-08-30 19:36:33.924140: Epoch time: 28.47 s 
2025-08-30 19:36:34.564820:  
2025-08-30 19:36:34.573213: Epoch 899 
2025-08-30 19:36:34.577353: Current learning rate: 0.00013 
2025-08-30 19:37:01.816556: train_loss -0.6506 
2025-08-30 19:37:01.816556: val_loss -0.6683 
2025-08-30 19:37:01.825247: Pseudo dice [np.float32(0.8233)] 
2025-08-30 19:37:01.831025: Epoch time: 27.25 s 
2025-08-30 19:37:02.667786:  
2025-08-30 19:37:02.676093: Epoch 900 
2025-08-30 19:37:02.684488: Current learning rate: 0.00013 
2025-08-30 19:37:27.955173: train_loss -0.6777 
2025-08-30 19:37:27.967649: val_loss -0.621 
2025-08-30 19:37:27.971815: Pseudo dice [np.float32(0.8188)] 
2025-08-30 19:37:27.979854: Epoch time: 25.29 s 
2025-08-30 19:37:28.589468:  
2025-08-30 19:37:28.597793: Epoch 901 
2025-08-30 19:37:28.602005: Current learning rate: 0.00012 
2025-08-30 19:37:55.278552: train_loss -0.6476 
2025-08-30 19:37:55.278552: val_loss -0.648 
2025-08-30 19:37:55.289247: Pseudo dice [np.float32(0.8145)] 
2025-08-30 19:37:55.296181: Epoch time: 26.69 s 
2025-08-30 19:37:55.915182:  
2025-08-30 19:37:55.923559: Epoch 902 
2025-08-30 19:37:55.929877: Current learning rate: 0.00012 
2025-08-30 19:38:21.946462: train_loss -0.6537 
2025-08-30 19:38:21.955129: val_loss -0.616 
2025-08-30 19:38:21.963760: Pseudo dice [np.float32(0.7719)] 
2025-08-30 19:38:21.969289: Epoch time: 26.03 s 
2025-08-30 19:38:22.587666:  
2025-08-30 19:38:22.595962: Epoch 903 
2025-08-30 19:38:22.602348: Current learning rate: 0.00012 
2025-08-30 19:38:48.131290: train_loss -0.6841 
2025-08-30 19:38:48.139607: val_loss -0.6322 
2025-08-30 19:38:48.147986: Pseudo dice [np.float32(0.7607)] 
2025-08-30 19:38:48.153707: Epoch time: 25.54 s 
2025-08-30 19:38:48.775303:  
2025-08-30 19:38:48.785597: Epoch 904 
2025-08-30 19:38:48.792915: Current learning rate: 0.00012 
2025-08-30 19:39:14.962254: train_loss -0.634 
2025-08-30 19:39:14.970463: val_loss -0.5308 
2025-08-30 19:39:14.974338: Pseudo dice [np.float32(0.7916)] 
2025-08-30 19:39:14.983450: Epoch time: 26.19 s 
2025-08-30 19:39:15.623832:  
2025-08-30 19:39:15.633196: Epoch 905 
2025-08-30 19:39:15.640388: Current learning rate: 0.00012 
2025-08-30 19:39:41.680478: train_loss -0.6635 
2025-08-30 19:39:41.688838: val_loss -0.6287 
2025-08-30 19:39:41.692954: Pseudo dice [np.float32(0.8314)] 
2025-08-30 19:39:41.701847: Epoch time: 26.06 s 
2025-08-30 19:39:42.458913:  
2025-08-30 19:39:42.468340: Epoch 906 
2025-08-30 19:39:42.477799: Current learning rate: 0.00012 
2025-08-30 19:40:08.315007: train_loss -0.6529 
2025-08-30 19:40:08.323358: val_loss -0.6104 
2025-08-30 19:40:08.327938: Pseudo dice [np.float32(0.7937)] 
2025-08-30 19:40:08.333876: Epoch time: 25.86 s 
2025-08-30 19:40:08.957267:  
2025-08-30 19:40:08.965580: Epoch 907 
2025-08-30 19:40:08.971870: Current learning rate: 0.00012 
2025-08-30 19:40:34.466691: train_loss -0.6678 
2025-08-30 19:40:34.474820: val_loss -0.6537 
2025-08-30 19:40:34.478928: Pseudo dice [np.float32(0.7945)] 
2025-08-30 19:40:34.486705: Epoch time: 25.51 s 
2025-08-30 19:40:35.117757:  
2025-08-30 19:40:35.126208: Epoch 908 
2025-08-30 19:40:35.132265: Current learning rate: 0.00012 
2025-08-30 19:41:01.297808: train_loss -0.684 
2025-08-30 19:41:01.305762: val_loss -0.6667 
2025-08-30 19:41:01.309910: Pseudo dice [np.float32(0.8066)] 
2025-08-30 19:41:01.316827: Epoch time: 26.18 s 
2025-08-30 19:41:01.945503:  
2025-08-30 19:41:01.954844: Epoch 909 
2025-08-30 19:41:01.961185: Current learning rate: 0.00012 
2025-08-30 19:41:28.127936: train_loss -0.674 
2025-08-30 19:41:28.127936: val_loss -0.6959 
2025-08-30 19:41:28.139868: Pseudo dice [np.float32(0.856)] 
2025-08-30 19:41:28.146000: Epoch time: 26.18 s 
2025-08-30 19:41:28.788967:  
2025-08-30 19:41:28.798315: Epoch 910 
2025-08-30 19:41:28.807665: Current learning rate: 0.00011 
2025-08-30 19:41:54.700764: train_loss -0.6407 
2025-08-30 19:41:54.709044: val_loss -0.6157 
2025-08-30 19:41:54.713157: Pseudo dice [np.float32(0.7942)] 
2025-08-30 19:41:54.720822: Epoch time: 25.91 s 
2025-08-30 19:41:55.353943:  
2025-08-30 19:41:55.361272: Epoch 911 
2025-08-30 19:41:55.367435: Current learning rate: 0.00011 
2025-08-30 19:42:21.460632: train_loss -0.6732 
2025-08-30 19:42:21.468999: val_loss -0.6233 
2025-08-30 19:42:21.476971: Pseudo dice [np.float32(0.7839)] 
2025-08-30 19:42:21.481967: Epoch time: 26.11 s 
2025-08-30 19:42:22.101441:  
2025-08-30 19:42:22.111958: Epoch 912 
2025-08-30 19:42:22.118116: Current learning rate: 0.00011 
2025-08-30 19:42:48.245653: train_loss -0.6403 
2025-08-30 19:42:48.254021: val_loss -0.6151 
2025-08-30 19:42:48.258202: Pseudo dice [np.float32(0.8118)] 
2025-08-30 19:42:48.265876: Epoch time: 26.15 s 
2025-08-30 19:42:48.893812:  
2025-08-30 19:42:48.904153: Epoch 913 
2025-08-30 19:42:48.910497: Current learning rate: 0.00011 
2025-08-30 19:43:14.865442: train_loss -0.6683 
2025-08-30 19:43:14.871883: val_loss -0.6691 
2025-08-30 19:43:14.876058: Pseudo dice [np.float32(0.8402)] 
2025-08-30 19:43:14.884159: Epoch time: 25.97 s 
2025-08-30 19:43:15.667343:  
2025-08-30 19:43:15.676689: Epoch 914 
2025-08-30 19:43:15.683097: Current learning rate: 0.00011 
2025-08-30 19:43:41.185598: train_loss -0.6561 
2025-08-30 19:43:41.193962: val_loss -0.7183 
2025-08-30 19:43:41.202626: Pseudo dice [np.float32(0.8321)] 
2025-08-30 19:43:41.209608: Epoch time: 25.52 s 
2025-08-30 19:43:41.845615:  
2025-08-30 19:43:41.855501: Epoch 915 
2025-08-30 19:43:41.862331: Current learning rate: 0.00011 
2025-08-30 19:44:08.042007: train_loss -0.6344 
2025-08-30 19:44:08.050292: val_loss -0.6619 
2025-08-30 19:44:08.058706: Pseudo dice [np.float32(0.7893)] 
2025-08-30 19:44:08.064421: Epoch time: 26.2 s 
2025-08-30 19:44:08.686887:  
2025-08-30 19:44:08.696304: Epoch 916 
2025-08-30 19:44:08.702555: Current learning rate: 0.00011 
2025-08-30 19:44:34.631167: train_loss -0.6396 
2025-08-30 19:44:34.643449: val_loss -0.6159 
2025-08-30 19:44:34.647636: Pseudo dice [np.float32(0.8485)] 
2025-08-30 19:44:34.655463: Epoch time: 25.95 s 
2025-08-30 19:44:35.278062:  
2025-08-30 19:44:35.285247: Epoch 917 
2025-08-30 19:44:35.291580: Current learning rate: 0.00011 
2025-08-30 19:45:01.240800: train_loss -0.659 
2025-08-30 19:45:01.249141: val_loss -0.6061 
2025-08-30 19:45:01.257514: Pseudo dice [np.float32(0.8249)] 
2025-08-30 19:45:01.263344: Epoch time: 25.96 s 
2025-08-30 19:45:01.887903:  
2025-08-30 19:45:01.896325: Epoch 918 
2025-08-30 19:45:01.901424: Current learning rate: 0.00011 
2025-08-30 19:45:30.361457: train_loss -0.6607 
2025-08-30 19:45:30.369796: val_loss -0.6444 
2025-08-30 19:45:30.373664: Pseudo dice [np.float32(0.8501)] 
2025-08-30 19:45:30.382949: Epoch time: 28.47 s 
2025-08-30 19:45:30.388867: Yayy! New best EMA pseudo Dice: 0.8177000284194946 
2025-08-30 19:45:31.286992:  
2025-08-30 19:45:31.295264: Epoch 919 
2025-08-30 19:45:31.302585: Current learning rate: 0.0001 
2025-08-30 19:46:00.562400: train_loss -0.6864 
2025-08-30 19:46:00.562400: val_loss -0.6263 
2025-08-30 19:46:00.574626: Pseudo dice [np.float32(0.8123)] 
2025-08-30 19:46:00.579597: Epoch time: 29.28 s 
2025-08-30 19:46:01.466098:  
2025-08-30 19:46:01.477642: Epoch 920 
2025-08-30 19:46:01.491581: Current learning rate: 0.0001 
2025-08-30 19:46:29.716558: train_loss -0.6636 
2025-08-30 19:46:29.724927: val_loss -0.5607 
2025-08-30 19:46:29.733341: Pseudo dice [np.float32(0.8128)] 
2025-08-30 19:46:29.739206: Epoch time: 28.25 s 
2025-08-30 19:46:30.430409:  
2025-08-30 19:46:30.441758: Epoch 921 
2025-08-30 19:46:30.452168: Current learning rate: 0.0001 
2025-08-30 19:46:59.100065: train_loss -0.6609 
2025-08-30 19:46:59.112504: val_loss -0.6198 
2025-08-30 19:46:59.116676: Pseudo dice [np.float32(0.8032)] 
2025-08-30 19:46:59.123576: Epoch time: 28.67 s 
2025-08-30 19:46:59.800239:  
2025-08-30 19:46:59.810689: Epoch 922 
2025-08-30 19:46:59.817694: Current learning rate: 0.0001 
2025-08-30 19:47:28.775440: train_loss -0.6422 
2025-08-30 19:47:28.783823: val_loss -0.6497 
2025-08-30 19:47:28.792181: Pseudo dice [np.float32(0.7871)] 
2025-08-30 19:47:28.799147: Epoch time: 28.98 s 
2025-08-30 19:47:29.514791:  
2025-08-30 19:47:29.525781: Epoch 923 
2025-08-30 19:47:29.534328: Current learning rate: 0.0001 
2025-08-30 19:47:58.083671: train_loss -0.648 
2025-08-30 19:47:58.092109: val_loss -0.6963 
2025-08-30 19:47:58.096297: Pseudo dice [np.float32(0.817)] 
2025-08-30 19:47:58.103411: Epoch time: 28.57 s 
2025-08-30 19:47:58.777935:  
2025-08-30 19:47:58.786259: Epoch 924 
2025-08-30 19:47:58.791323: Current learning rate: 0.0001 
2025-08-30 19:48:27.513194: train_loss -0.684 
2025-08-30 19:48:27.525736: val_loss -0.6618 
2025-08-30 19:48:27.529895: Pseudo dice [np.float32(0.7822)] 
2025-08-30 19:48:27.536805: Epoch time: 28.74 s 
2025-08-30 19:48:28.223832:  
2025-08-30 19:48:28.232191: Epoch 925 
2025-08-30 19:48:28.239191: Current learning rate: 0.0001 
2025-08-30 19:48:57.334655: train_loss -0.6738 
2025-08-30 19:48:57.342965: val_loss -0.6256 
2025-08-30 19:48:57.347175: Pseudo dice [np.float32(0.8236)] 
2025-08-30 19:48:57.356066: Epoch time: 29.11 s 
2025-08-30 19:48:58.055657:  
2025-08-30 19:48:58.065186: Epoch 926 
2025-08-30 19:48:58.070265: Current learning rate: 0.0001 
2025-08-30 19:49:26.396878: train_loss -0.6683 
2025-08-30 19:49:26.409414: val_loss -0.6541 
2025-08-30 19:49:26.417356: Pseudo dice [np.float32(0.8164)] 
2025-08-30 19:49:26.423399: Epoch time: 28.34 s 
2025-08-30 19:49:27.139911:  
2025-08-30 19:49:27.147130: Epoch 927 
2025-08-30 19:49:27.155625: Current learning rate: 9e-05 
2025-08-30 19:49:55.488398: train_loss -0.6344 
2025-08-30 19:49:55.496772: val_loss -0.5788 
2025-08-30 19:49:55.500874: Pseudo dice [np.float32(0.7916)] 
2025-08-30 19:49:55.508805: Epoch time: 28.35 s 
2025-08-30 19:49:56.340929:  
2025-08-30 19:49:56.348929: Epoch 928 
2025-08-30 19:49:56.354392: Current learning rate: 9e-05 
2025-08-30 19:50:25.680619: train_loss -0.6746 
2025-08-30 19:50:25.693442: val_loss -0.6422 
2025-08-30 19:50:25.697634: Pseudo dice [np.float32(0.819)] 
2025-08-30 19:50:25.705614: Epoch time: 29.34 s 
2025-08-30 19:50:26.409407:  
2025-08-30 19:50:26.418842: Epoch 929 
2025-08-30 19:50:26.427501: Current learning rate: 9e-05 
2025-08-30 19:50:54.885734: train_loss -0.7036 
2025-08-30 19:50:54.885734: val_loss -0.6668 
2025-08-30 19:50:54.894756: Pseudo dice [np.float32(0.8014)] 
2025-08-30 19:50:54.898771: Epoch time: 28.48 s 
2025-08-30 19:50:55.572781:  
2025-08-30 19:50:55.581219: Epoch 930 
2025-08-30 19:50:55.587472: Current learning rate: 9e-05 
2025-08-30 19:51:24.326588: train_loss -0.6899 
2025-08-30 19:51:24.335282: val_loss -0.5834 
2025-08-30 19:51:24.344035: Pseudo dice [np.float32(0.8174)] 
2025-08-30 19:51:24.349722: Epoch time: 28.75 s 
2025-08-30 19:51:25.025147:  
2025-08-30 19:51:25.034516: Epoch 931 
2025-08-30 19:51:25.040676: Current learning rate: 9e-05 
2025-08-30 19:51:53.801795: train_loss -0.6639 
2025-08-30 19:51:53.810634: val_loss -0.6136 
2025-08-30 19:51:53.814752: Pseudo dice [np.float32(0.7855)] 
2025-08-30 19:51:53.821719: Epoch time: 28.78 s 
2025-08-30 19:51:54.528232:  
2025-08-30 19:51:54.537872: Epoch 932 
2025-08-30 19:51:54.547626: Current learning rate: 9e-05 
2025-08-30 19:52:23.186694: train_loss -0.6496 
2025-08-30 19:52:23.193968: val_loss -0.6225 
2025-08-30 19:52:23.198102: Pseudo dice [np.float32(0.7569)] 
2025-08-30 19:52:23.207499: Epoch time: 28.66 s 
2025-08-30 19:52:23.893898:  
2025-08-30 19:52:23.907545: Epoch 933 
2025-08-30 19:52:23.917009: Current learning rate: 9e-05 
2025-08-30 19:52:52.373069: train_loss -0.6546 
2025-08-30 19:52:52.381573: val_loss -0.6282 
2025-08-30 19:52:52.385678: Pseudo dice [np.float32(0.7835)] 
2025-08-30 19:52:52.393578: Epoch time: 28.48 s 
2025-08-30 19:52:53.088550:  
2025-08-30 19:52:53.098307: Epoch 934 
2025-08-30 19:52:53.104306: Current learning rate: 9e-05 
2025-08-30 19:53:22.686688: train_loss -0.6631 
2025-08-30 19:53:22.695043: val_loss -0.6465 
2025-08-30 19:53:22.699137: Pseudo dice [np.float32(0.8266)] 
2025-08-30 19:53:22.707685: Epoch time: 29.6 s 
2025-08-30 19:53:23.525700:  
2025-08-30 19:53:23.534594: Epoch 935 
2025-08-30 19:53:23.542402: Current learning rate: 9e-05 
2025-08-30 19:53:51.998819: train_loss -0.665 
2025-08-30 19:53:52.007523: val_loss -0.6545 
2025-08-30 19:53:52.011652: Pseudo dice [np.float32(0.8054)] 
2025-08-30 19:53:52.017550: Epoch time: 28.47 s 
2025-08-30 19:53:52.720234:  
2025-08-30 19:53:52.728574: Epoch 936 
2025-08-30 19:53:52.735743: Current learning rate: 8e-05 
2025-08-30 19:54:21.399394: train_loss -0.6626 
2025-08-30 19:54:21.407750: val_loss -0.586 
2025-08-30 19:54:21.416118: Pseudo dice [np.float32(0.8159)] 
2025-08-30 19:54:21.421585: Epoch time: 28.68 s 
2025-08-30 19:54:22.097526:  
2025-08-30 19:54:22.107525: Epoch 937 
2025-08-30 19:54:22.114212: Current learning rate: 8e-05 
2025-08-30 19:54:50.790782: train_loss -0.6647 
2025-08-30 19:54:50.799453: val_loss -0.6772 
2025-08-30 19:54:50.803278: Pseudo dice [np.float32(0.7834)] 
2025-08-30 19:54:50.812475: Epoch time: 28.7 s 
2025-08-30 19:54:51.487174:  
2025-08-30 19:54:51.496339: Epoch 938 
2025-08-30 19:54:51.502883: Current learning rate: 8e-05 
2025-08-30 19:55:20.116254: train_loss -0.6665 
2025-08-30 19:55:20.119304: val_loss -0.6721 
2025-08-30 19:55:20.124656: Pseudo dice [np.float32(0.8506)] 
2025-08-30 19:55:20.133425: Epoch time: 28.63 s 
2025-08-30 19:55:20.830090:  
2025-08-30 19:55:20.838533: Epoch 939 
2025-08-30 19:55:20.844531: Current learning rate: 8e-05 
2025-08-30 19:55:49.220211: train_loss -0.6703 
2025-08-30 19:55:49.228660: val_loss -0.62 
2025-08-30 19:55:49.232829: Pseudo dice [np.float32(0.7855)] 
2025-08-30 19:55:49.241637: Epoch time: 28.39 s 
2025-08-30 19:55:49.955982:  
2025-08-30 19:55:49.965326: Epoch 940 
2025-08-30 19:55:49.974827: Current learning rate: 8e-05 
2025-08-30 19:56:18.920339: train_loss -0.6701 
2025-08-30 19:56:18.929167: val_loss -0.7016 
2025-08-30 19:56:18.933259: Pseudo dice [np.float32(0.8089)] 
2025-08-30 19:56:18.941070: Epoch time: 28.97 s 
2025-08-30 19:56:19.624083:  
2025-08-30 19:56:19.633080: Epoch 941 
2025-08-30 19:56:19.639765: Current learning rate: 8e-05 
2025-08-30 19:56:48.671138: train_loss -0.6635 
2025-08-30 19:56:48.679491: val_loss -0.6153 
2025-08-30 19:56:48.683303: Pseudo dice [np.float32(0.803)] 
2025-08-30 19:56:48.693054: Epoch time: 29.05 s 
2025-08-30 19:56:49.523689:  
2025-08-30 19:56:49.531689: Epoch 942 
2025-08-30 19:56:49.537240: Current learning rate: 8e-05 
2025-08-30 19:57:17.913000: train_loss -0.6669 
2025-08-30 19:57:17.925018: val_loss -0.606 
2025-08-30 19:57:17.929591: Pseudo dice [np.float32(0.8428)] 
2025-08-30 19:57:17.935593: Epoch time: 28.39 s 
2025-08-30 19:57:18.635033:  
2025-08-30 19:57:18.645393: Epoch 943 
2025-08-30 19:57:18.653898: Current learning rate: 8e-05 
2025-08-30 19:57:47.721365: train_loss -0.6755 
2025-08-30 19:57:47.730150: val_loss -0.5817 
2025-08-30 19:57:47.734354: Pseudo dice [np.float32(0.7667)] 
2025-08-30 19:57:47.740147: Epoch time: 29.09 s 
2025-08-30 19:57:48.415751:  
2025-08-30 19:57:48.423771: Epoch 944 
2025-08-30 19:57:48.430255: Current learning rate: 7e-05 
2025-08-30 19:58:16.663101: train_loss -0.6813 
2025-08-30 19:58:16.671455: val_loss -0.6008 
2025-08-30 19:58:16.679457: Pseudo dice [np.float32(0.8259)] 
2025-08-30 19:58:16.684884: Epoch time: 28.25 s 
2025-08-30 19:58:17.395777:  
2025-08-30 19:58:17.403979: Epoch 945 
2025-08-30 19:58:17.409207: Current learning rate: 7e-05 
2025-08-30 19:58:46.000654: train_loss -0.6619 
2025-08-30 19:58:46.009034: val_loss -0.7255 
2025-08-30 19:58:46.017326: Pseudo dice [np.float32(0.85)] 
2025-08-30 19:58:46.022612: Epoch time: 28.61 s 
2025-08-30 19:58:46.698855:  
2025-08-30 19:58:46.706856: Epoch 946 
2025-08-30 19:58:46.714706: Current learning rate: 7e-05 
2025-08-30 19:59:16.043140: train_loss -0.6745 
2025-08-30 19:59:16.051522: val_loss -0.6748 
2025-08-30 19:59:16.055667: Pseudo dice [np.float32(0.8135)] 
2025-08-30 19:59:16.065291: Epoch time: 29.35 s 
2025-08-30 19:59:16.776677:  
2025-08-30 19:59:16.787182: Epoch 947 
2025-08-30 19:59:16.795241: Current learning rate: 7e-05 
2025-08-30 19:59:45.814648: train_loss -0.6736 
2025-08-30 19:59:45.822892: val_loss -0.6301 
2025-08-30 19:59:45.826985: Pseudo dice [np.float32(0.8467)] 
2025-08-30 19:59:45.834982: Epoch time: 29.04 s 
2025-08-30 19:59:46.514672:  
2025-08-30 19:59:46.523145: Epoch 948 
2025-08-30 19:59:46.531373: Current learning rate: 7e-05 
2025-08-30 20:00:15.156355: train_loss -0.6665 
2025-08-30 20:00:15.160065: val_loss -0.674 
2025-08-30 20:00:15.168864: Pseudo dice [np.float32(0.8135)] 
2025-08-30 20:00:15.174686: Epoch time: 28.64 s 
2025-08-30 20:00:15.854009:  
2025-08-30 20:00:15.863786: Epoch 949 
2025-08-30 20:00:15.870785: Current learning rate: 7e-05 
2025-08-30 20:00:44.793763: train_loss -0.6529 
2025-08-30 20:00:44.802440: val_loss -0.7003 
2025-08-30 20:00:44.806648: Pseudo dice [np.float32(0.8261)] 
2025-08-30 20:00:44.813580: Epoch time: 28.94 s 
2025-08-30 20:00:45.732514:  
2025-08-30 20:00:45.742589: Epoch 950 
2025-08-30 20:00:45.750591: Current learning rate: 7e-05 
2025-08-30 20:01:14.836202: train_loss -0.6587 
2025-08-30 20:01:14.844909: val_loss -0.6058 
2025-08-30 20:01:14.849060: Pseudo dice [np.float32(0.8219)] 
2025-08-30 20:01:14.856197: Epoch time: 29.11 s 
2025-08-30 20:01:15.576219:  
2025-08-30 20:01:15.587337: Epoch 951 
2025-08-30 20:01:15.593550: Current learning rate: 7e-05 
2025-08-30 20:01:44.045327: train_loss -0.65 
2025-08-30 20:01:44.053281: val_loss -0.6429 
2025-08-30 20:01:44.061208: Pseudo dice [np.float32(0.7486)] 
2025-08-30 20:01:44.067141: Epoch time: 28.47 s 
2025-08-30 20:01:44.748892:  
2025-08-30 20:01:44.757660: Epoch 952 
2025-08-30 20:01:44.765907: Current learning rate: 7e-05 
2025-08-30 20:02:13.853778: train_loss -0.6771 
2025-08-30 20:02:13.862111: val_loss -0.6344 
2025-08-30 20:02:13.870387: Pseudo dice [np.float32(0.8292)] 
2025-08-30 20:02:13.876482: Epoch time: 29.11 s 
2025-08-30 20:02:14.563437:  
2025-08-30 20:02:14.572857: Epoch 953 
2025-08-30 20:02:14.582211: Current learning rate: 6e-05 
2025-08-30 20:02:44.018747: train_loss -0.6824 
2025-08-30 20:02:44.025595: val_loss -0.6764 
2025-08-30 20:02:44.029651: Pseudo dice [np.float32(0.8233)] 
2025-08-30 20:02:44.038603: Epoch time: 29.46 s 
2025-08-30 20:02:44.753926:  
2025-08-30 20:02:44.761926: Epoch 954 
2025-08-30 20:02:44.769707: Current learning rate: 6e-05 
2025-08-30 20:03:13.329844: train_loss -0.6606 
2025-08-30 20:03:13.338188: val_loss -0.6653 
2025-08-30 20:03:13.346510: Pseudo dice [np.float32(0.8492)] 
2025-08-30 20:03:13.352812: Epoch time: 28.58 s 
2025-08-30 20:03:14.047624:  
2025-08-30 20:03:14.055096: Epoch 955 
2025-08-30 20:03:14.062384: Current learning rate: 6e-05 
2025-08-30 20:03:42.880102: train_loss -0.6518 
2025-08-30 20:03:42.892616: val_loss -0.6123 
2025-08-30 20:03:42.896746: Pseudo dice [np.float32(0.8131)] 
2025-08-30 20:03:42.904545: Epoch time: 28.84 s 
2025-08-30 20:03:43.749225:  
2025-08-30 20:03:43.757480: Epoch 956 
2025-08-30 20:03:43.762843: Current learning rate: 6e-05 
2025-08-30 20:04:12.809490: train_loss -0.6403 
2025-08-30 20:04:12.817862: val_loss -0.6271 
2025-08-30 20:04:12.822498: Pseudo dice [np.float32(0.7808)] 
2025-08-30 20:04:12.828331: Epoch time: 29.06 s 
2025-08-30 20:04:13.510146:  
2025-08-30 20:04:13.519598: Epoch 957 
2025-08-30 20:04:13.525600: Current learning rate: 6e-05 
2025-08-30 20:04:41.705455: train_loss -0.6372 
2025-08-30 20:04:41.705455: val_loss -0.5787 
2025-08-30 20:04:41.716074: Pseudo dice [np.float32(0.7945)] 
2025-08-30 20:04:41.722563: Epoch time: 28.2 s 
2025-08-30 20:04:42.428399:  
2025-08-30 20:04:42.436921: Epoch 958 
2025-08-30 20:04:42.443143: Current learning rate: 6e-05 
2025-08-30 20:05:11.146823: train_loss -0.6814 
2025-08-30 20:05:11.151349: val_loss -0.6622 
2025-08-30 20:05:11.159673: Pseudo dice [np.float32(0.84)] 
2025-08-30 20:05:11.164845: Epoch time: 28.72 s 
2025-08-30 20:05:11.845387:  
2025-08-30 20:05:11.854722: Epoch 959 
2025-08-30 20:05:11.861914: Current learning rate: 6e-05 
2025-08-30 20:05:40.893581: train_loss -0.6188 
2025-08-30 20:05:40.901930: val_loss -0.5964 
2025-08-30 20:05:40.910298: Pseudo dice [np.float32(0.8028)] 
2025-08-30 20:05:40.915129: Epoch time: 29.05 s 
2025-08-30 20:05:41.619518:  
2025-08-30 20:05:41.628348: Epoch 960 
2025-08-30 20:05:41.634430: Current learning rate: 6e-05 
2025-08-30 20:06:10.252837: train_loss -0.6566 
2025-08-30 20:06:10.260255: val_loss -0.6539 
2025-08-30 20:06:10.264105: Pseudo dice [np.float32(0.797)] 
2025-08-30 20:06:10.273388: Epoch time: 28.64 s 
2025-08-30 20:06:10.980366:  
2025-08-30 20:06:10.988780: Epoch 961 
2025-08-30 20:06:10.997105: Current learning rate: 5e-05 
2025-08-30 20:06:39.793942: train_loss -0.6334 
2025-08-30 20:06:39.802311: val_loss -0.647 
2025-08-30 20:06:39.806565: Pseudo dice [np.float32(0.8282)] 
2025-08-30 20:06:39.814335: Epoch time: 28.81 s 
2025-08-30 20:06:40.534852:  
2025-08-30 20:06:40.543051: Epoch 962 
2025-08-30 20:06:40.549540: Current learning rate: 5e-05 
2025-08-30 20:07:09.548724: train_loss -0.6522 
2025-08-30 20:07:09.557018: val_loss -0.6805 
2025-08-30 20:07:09.561198: Pseudo dice [np.float32(0.8421)] 
2025-08-30 20:07:09.568110: Epoch time: 29.02 s 
2025-08-30 20:07:10.403082:  
2025-08-30 20:07:10.411433: Epoch 963 
2025-08-30 20:07:10.418798: Current learning rate: 5e-05 
2025-08-30 20:07:39.274066: train_loss -0.6683 
2025-08-30 20:07:39.282508: val_loss -0.631 
2025-08-30 20:07:39.286711: Pseudo dice [np.float32(0.7906)] 
2025-08-30 20:07:39.295534: Epoch time: 28.87 s 
2025-08-30 20:07:39.985747:  
2025-08-30 20:07:39.995195: Epoch 964 
2025-08-30 20:07:40.005779: Current learning rate: 5e-05 
2025-08-30 20:08:08.419824: train_loss -0.649 
2025-08-30 20:08:08.428180: val_loss -0.5844 
2025-08-30 20:08:08.436286: Pseudo dice [np.float32(0.8024)] 
2025-08-30 20:08:08.442492: Epoch time: 28.44 s 
2025-08-30 20:08:09.167708:  
2025-08-30 20:08:09.177438: Epoch 965 
2025-08-30 20:08:09.185021: Current learning rate: 5e-05 
2025-08-30 20:08:38.533188: train_loss -0.644 
2025-08-30 20:08:38.541580: val_loss -0.6582 
2025-08-30 20:08:38.545770: Pseudo dice [np.float32(0.788)] 
2025-08-30 20:08:38.552803: Epoch time: 29.37 s 
2025-08-30 20:08:39.234615:  
2025-08-30 20:08:39.242947: Epoch 966 
2025-08-30 20:08:39.249021: Current learning rate: 5e-05 
2025-08-30 20:09:07.549224: train_loss -0.6664 
2025-08-30 20:09:07.557865: val_loss -0.5782 
2025-08-30 20:09:07.566244: Pseudo dice [np.float32(0.7442)] 
2025-08-30 20:09:07.571847: Epoch time: 28.32 s 
2025-08-30 20:09:08.278954:  
2025-08-30 20:09:08.287357: Epoch 967 
2025-08-30 20:09:08.295749: Current learning rate: 5e-05 
2025-08-30 20:09:37.020782: train_loss -0.6549 
2025-08-30 20:09:37.020782: val_loss -0.7134 
2025-08-30 20:09:37.033273: Pseudo dice [np.float32(0.8633)] 
2025-08-30 20:09:37.039285: Epoch time: 28.74 s 
2025-08-30 20:09:37.751193:  
2025-08-30 20:09:37.759537: Epoch 968 
2025-08-30 20:09:37.764803: Current learning rate: 5e-05 
2025-08-30 20:10:06.821455: train_loss -0.6669 
2025-08-30 20:10:06.829640: val_loss -0.6586 
2025-08-30 20:10:06.837493: Pseudo dice [np.float32(0.8126)] 
2025-08-30 20:10:06.843462: Epoch time: 29.07 s 
2025-08-30 20:10:07.550547:  
2025-08-30 20:10:07.559009: Epoch 969 
2025-08-30 20:10:07.564269: Current learning rate: 4e-05 
2025-08-30 20:10:36.416966: train_loss -0.6767 
2025-08-30 20:10:36.425648: val_loss -0.6228 
2025-08-30 20:10:36.429513: Pseudo dice [np.float32(0.8096)] 
2025-08-30 20:10:36.439237: Epoch time: 28.87 s 
2025-08-30 20:10:37.155073:  
2025-08-30 20:10:37.163496: Epoch 970 
2025-08-30 20:10:37.170766: Current learning rate: 4e-05 
2025-08-30 20:11:05.963578: train_loss -0.6658 
2025-08-30 20:11:05.971947: val_loss -0.6711 
2025-08-30 20:11:05.980209: Pseudo dice [np.float32(0.8093)] 
2025-08-30 20:11:05.986059: Epoch time: 28.81 s 
2025-08-30 20:11:06.676308:  
2025-08-30 20:11:06.684614: Epoch 971 
2025-08-30 20:11:06.690697: Current learning rate: 4e-05 
2025-08-30 20:11:35.117176: train_loss -0.683 
2025-08-30 20:11:35.125865: val_loss -0.5971 
2025-08-30 20:11:35.134256: Pseudo dice [np.float32(0.7884)] 
2025-08-30 20:11:35.139901: Epoch time: 28.44 s 
2025-08-30 20:11:35.831308:  
2025-08-30 20:11:35.839769: Epoch 972 
2025-08-30 20:11:35.846022: Current learning rate: 4e-05 
2025-08-30 20:12:04.626351: train_loss -0.6489 
2025-08-30 20:12:04.634567: val_loss -0.6935 
2025-08-30 20:12:04.638794: Pseudo dice [np.float32(0.8271)] 
2025-08-30 20:12:04.647633: Epoch time: 28.8 s 
2025-08-30 20:12:05.412006:  
2025-08-30 20:12:05.421328: Epoch 973 
2025-08-30 20:12:05.427583: Current learning rate: 4e-05 
2025-08-30 20:12:33.710010: train_loss -0.6788 
2025-08-30 20:12:33.717699: val_loss -0.6671 
2025-08-30 20:12:33.726128: Pseudo dice [np.float32(0.8119)] 
2025-08-30 20:12:33.731634: Epoch time: 28.3 s 
2025-08-30 20:12:34.416533:  
2025-08-30 20:12:34.426203: Epoch 974 
2025-08-30 20:12:34.431504: Current learning rate: 4e-05 
2025-08-30 20:13:03.509841: train_loss -0.6712 
2025-08-30 20:13:03.518256: val_loss -0.6005 
2025-08-30 20:13:03.522416: Pseudo dice [np.float32(0.775)] 
2025-08-30 20:13:03.531303: Epoch time: 29.1 s 
2025-08-30 20:13:04.216406:  
2025-08-30 20:13:04.225407: Epoch 975 
2025-08-30 20:13:04.232188: Current learning rate: 4e-05 
2025-08-30 20:13:32.459661: train_loss -0.6591 
2025-08-30 20:13:32.467955: val_loss -0.6266 
2025-08-30 20:13:32.472203: Pseudo dice [np.float32(0.771)] 
2025-08-30 20:13:32.481004: Epoch time: 28.25 s 
2025-08-30 20:13:33.175419:  
2025-08-30 20:13:33.183418: Epoch 976 
2025-08-30 20:13:33.192141: Current learning rate: 3e-05 
2025-08-30 20:14:02.135017: train_loss -0.6586 
2025-08-30 20:14:02.135017: val_loss -0.6328 
2025-08-30 20:14:02.145791: Pseudo dice [np.float32(0.7939)] 
2025-08-30 20:14:02.152686: Epoch time: 28.96 s 
2025-08-30 20:14:02.992340:  
2025-08-30 20:14:03.000071: Epoch 977 
2025-08-30 20:14:03.007436: Current learning rate: 3e-05 
2025-08-30 20:14:31.772871: train_loss -0.6453 
2025-08-30 20:14:31.785330: val_loss -0.5999 
2025-08-30 20:14:31.789521: Pseudo dice [np.float32(0.787)] 
2025-08-30 20:14:31.796554: Epoch time: 28.78 s 
2025-08-30 20:14:32.501245:  
2025-08-30 20:14:32.509564: Epoch 978 
2025-08-30 20:14:32.517946: Current learning rate: 3e-05 
2025-08-30 20:15:01.323296: train_loss -0.6797 
2025-08-30 20:15:01.331580: val_loss -0.6212 
2025-08-30 20:15:01.335781: Pseudo dice [np.float32(0.8254)] 
2025-08-30 20:15:01.341717: Epoch time: 28.82 s 
2025-08-30 20:15:02.022405:  
2025-08-30 20:15:02.031712: Epoch 979 
2025-08-30 20:15:02.038714: Current learning rate: 3e-05 
2025-08-30 20:15:30.531064: train_loss -0.6589 
2025-08-30 20:15:30.539760: val_loss -0.6462 
2025-08-30 20:15:30.548151: Pseudo dice [np.float32(0.8105)] 
2025-08-30 20:15:30.553386: Epoch time: 28.51 s 
2025-08-30 20:15:31.254677:  
2025-08-30 20:15:31.264031: Epoch 980 
2025-08-30 20:15:31.273008: Current learning rate: 3e-05 
2025-08-30 20:16:00.256926: train_loss -0.682 
2025-08-30 20:16:00.265325: val_loss -0.6368 
2025-08-30 20:16:00.269483: Pseudo dice [np.float32(0.8189)] 
2025-08-30 20:16:00.278325: Epoch time: 29.0 s 
2025-08-30 20:16:00.971694:  
2025-08-30 20:16:00.980188: Epoch 981 
2025-08-30 20:16:00.986413: Current learning rate: 3e-05 
2025-08-30 20:16:30.224330: train_loss -0.6654 
2025-08-30 20:16:30.236863: val_loss -0.6495 
2025-08-30 20:16:30.241063: Pseudo dice [np.float32(0.8436)] 
2025-08-30 20:16:30.248944: Epoch time: 29.25 s 
2025-08-30 20:16:30.959125:  
2025-08-30 20:16:30.968465: Epoch 982 
2025-08-30 20:16:30.974541: Current learning rate: 3e-05 
2025-08-30 20:16:59.737146: train_loss -0.6882 
2025-08-30 20:16:59.745470: val_loss -0.6601 
2025-08-30 20:16:59.749672: Pseudo dice [np.float32(0.7941)] 
2025-08-30 20:16:59.757639: Epoch time: 28.78 s 
2025-08-30 20:17:00.451947:  
2025-08-30 20:17:00.461096: Epoch 983 
2025-08-30 20:17:00.468671: Current learning rate: 3e-05 
2025-08-30 20:17:29.725266: train_loss -0.6454 
2025-08-30 20:17:29.733765: val_loss -0.6136 
2025-08-30 20:17:29.742126: Pseudo dice [np.float32(0.7817)] 
2025-08-30 20:17:29.747953: Epoch time: 29.28 s 
2025-08-30 20:17:30.616396:  
2025-08-30 20:17:30.626927: Epoch 984 
2025-08-30 20:17:30.636512: Current learning rate: 2e-05 
2025-08-30 20:17:59.100062: train_loss -0.6453 
2025-08-30 20:17:59.108745: val_loss -0.6538 
2025-08-30 20:17:59.112937: Pseudo dice [np.float32(0.8071)] 
2025-08-30 20:17:59.120873: Epoch time: 28.49 s 
2025-08-30 20:17:59.819520:  
2025-08-30 20:17:59.827809: Epoch 985 
2025-08-30 20:17:59.835154: Current learning rate: 2e-05 
2025-08-30 20:18:28.392809: train_loss -0.6825 
2025-08-30 20:18:28.404699: val_loss -0.6119 
2025-08-30 20:18:28.408931: Pseudo dice [np.float32(0.8123)] 
2025-08-30 20:18:28.416764: Epoch time: 28.58 s 
2025-08-30 20:18:29.109060:  
2025-08-30 20:18:29.109060: Epoch 986 
2025-08-30 20:18:29.118524: Current learning rate: 2e-05 
2025-08-30 20:18:57.792336: train_loss -0.6711 
2025-08-30 20:18:57.792336: val_loss -0.6468 
2025-08-30 20:18:57.802948: Pseudo dice [np.float32(0.7944)] 
2025-08-30 20:18:57.810228: Epoch time: 28.69 s 
2025-08-30 20:18:58.525835:  
2025-08-30 20:18:58.536368: Epoch 987 
2025-08-30 20:18:58.545785: Current learning rate: 2e-05 
2025-08-30 20:19:27.526239: train_loss -0.6697 
2025-08-30 20:19:27.534499: val_loss -0.6395 
2025-08-30 20:19:27.542932: Pseudo dice [np.float32(0.8463)] 
2025-08-30 20:19:27.548074: Epoch time: 29.0 s 
2025-08-30 20:19:28.234660:  
2025-08-30 20:19:28.241957: Epoch 988 
2025-08-30 20:19:28.248309: Current learning rate: 2e-05 
2025-08-30 20:19:56.767751: train_loss -0.6661 
2025-08-30 20:19:56.776044: val_loss -0.6904 
2025-08-30 20:19:56.780245: Pseudo dice [np.float32(0.8632)] 
2025-08-30 20:19:56.789164: Epoch time: 28.54 s 
2025-08-30 20:19:57.485653:  
2025-08-30 20:19:57.494734: Epoch 989 
2025-08-30 20:19:57.501363: Current learning rate: 2e-05 
2025-08-30 20:20:26.734750: train_loss -0.6744 
2025-08-30 20:20:26.747603: val_loss -0.617 
2025-08-30 20:20:26.751813: Pseudo dice [np.float32(0.7623)] 
2025-08-30 20:20:26.757869: Epoch time: 29.25 s 
2025-08-30 20:20:27.447826:  
2025-08-30 20:20:27.456192: Epoch 990 
2025-08-30 20:20:27.462542: Current learning rate: 2e-05 
2025-08-30 20:20:56.414877: train_loss -0.6854 
2025-08-30 20:20:56.427289: val_loss -0.6438 
2025-08-30 20:20:56.431489: Pseudo dice [np.float32(0.8397)] 
2025-08-30 20:20:56.440369: Epoch time: 28.97 s 
2025-08-30 20:20:57.130597:  
2025-08-30 20:20:57.139962: Epoch 991 
2025-08-30 20:20:57.147145: Current learning rate: 1e-05 
2025-08-30 20:21:25.740544: train_loss -0.6552 
2025-08-30 20:21:25.752266: val_loss -0.6683 
2025-08-30 20:21:25.756481: Pseudo dice [np.float32(0.8148)] 
2025-08-30 20:21:25.765339: Epoch time: 28.61 s 
2025-08-30 20:21:26.462694:  
2025-08-30 20:21:26.471415: Epoch 992 
2025-08-30 20:21:26.479731: Current learning rate: 1e-05 
2025-08-30 20:21:55.390274: train_loss -0.6649 
2025-08-30 20:21:55.398653: val_loss -0.7044 
2025-08-30 20:21:55.406532: Pseudo dice [np.float32(0.8366)] 
2025-08-30 20:21:55.411562: Epoch time: 28.93 s 
2025-08-30 20:21:56.112402:  
2025-08-30 20:21:56.119574: Epoch 993 
2025-08-30 20:21:56.126915: Current learning rate: 1e-05 
2025-08-30 20:22:24.656589: train_loss -0.6467 
2025-08-30 20:22:24.669359: val_loss -0.6186 
2025-08-30 20:22:24.673539: Pseudo dice [np.float32(0.8024)] 
2025-08-30 20:22:24.681677: Epoch time: 28.55 s 
2025-08-30 20:22:25.398638:  
2025-08-30 20:22:25.409353: Epoch 994 
2025-08-30 20:22:25.419026: Current learning rate: 1e-05 
2025-08-30 20:22:53.827729: train_loss -0.6885 
2025-08-30 20:22:53.836018: val_loss -0.648 
2025-08-30 20:22:53.844398: Pseudo dice [np.float32(0.7945)] 
2025-08-30 20:22:53.849629: Epoch time: 28.43 s 
2025-08-30 20:22:54.580681:  
2025-08-30 20:22:54.589482: Epoch 995 
2025-08-30 20:22:54.597058: Current learning rate: 1e-05 
2025-08-30 20:23:23.181511: train_loss -0.661 
2025-08-30 20:23:23.181511: val_loss -0.5678 
2025-08-30 20:23:23.190562: Pseudo dice [np.float32(0.8006)] 
2025-08-30 20:23:23.196347: Epoch time: 28.6 s 
2025-08-30 20:23:23.897769:  
2025-08-30 20:23:23.909322: Epoch 996 
2025-08-30 20:23:23.916322: Current learning rate: 1e-05 
2025-08-30 20:23:53.311602: train_loss -0.6691 
2025-08-30 20:23:53.320223: val_loss -0.6551 
2025-08-30 20:23:53.324445: Pseudo dice [np.float32(0.8271)] 
2025-08-30 20:23:53.333336: Epoch time: 29.42 s 
2025-08-30 20:23:54.044523:  
2025-08-30 20:23:54.052912: Epoch 997 
2025-08-30 20:23:54.059186: Current learning rate: 1e-05 
2025-08-30 20:24:22.095435: train_loss -0.6892 
2025-08-30 20:24:22.103144: val_loss -0.6653 
2025-08-30 20:24:22.111152: Pseudo dice [np.float32(0.8097)] 
2025-08-30 20:24:22.116652: Epoch time: 28.05 s 
2025-08-30 20:24:22.970215:  
2025-08-30 20:24:22.980674: Epoch 998 
2025-08-30 20:24:22.992721: Current learning rate: 0.0 
2025-08-30 20:24:51.916538: train_loss -0.6682 
2025-08-30 20:24:51.924201: val_loss -0.6414 
2025-08-30 20:24:51.928694: Pseudo dice [np.float32(0.8167)] 
2025-08-30 20:24:51.937616: Epoch time: 28.95 s 
2025-08-30 20:24:52.638446:  
2025-08-30 20:24:52.646445: Epoch 999 
2025-08-30 20:24:52.652445: Current learning rate: 0.0 
2025-08-30 20:25:21.533410: train_loss -0.671 
2025-08-30 20:25:21.541644: val_loss -0.6442 
2025-08-30 20:25:21.545748: Pseudo dice [np.float32(0.8313)] 
2025-08-30 20:25:21.554636: Epoch time: 28.9 s 
2025-08-30 20:25:22.551519: Training done. 
2025-08-30 20:25:22.710128: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-30 20:25:22.722670: The split file contains 5 splits. 
2025-08-30 20:25:22.735039: Desired fold for training: 0 
2025-08-30 20:25:22.748682: This split has 524 training and 131 validation cases. 
2025-08-30 20:25:22.762299: predicting sub-r001s001 
2025-08-30 20:25:23.009723: sub-r001s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:25:42.087120: predicting sub-r001s005 
2025-08-30 20:25:42.270556: sub-r001s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:26:03.470933: predicting sub-r001s007 
2025-08-30 20:26:03.650314: sub-r001s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:26:24.796265: predicting sub-r001s011 
2025-08-30 20:26:25.013244: sub-r001s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:26:48.235956: predicting sub-r001s023 
2025-08-30 20:26:48.427816: sub-r001s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:27:09.223880: predicting sub-r001s026 
2025-08-30 20:27:09.428326: sub-r001s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:27:30.294990: predicting sub-r002s009 
2025-08-30 20:27:30.503126: sub-r002s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:27:53.063115: predicting sub-r002s011 
2025-08-30 20:27:53.234100: sub-r002s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:28:12.649344: predicting sub-r003s005 
2025-08-30 20:28:12.829014: sub-r003s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:28:32.752703: predicting sub-r003s006 
2025-08-30 20:28:32.973759: sub-r003s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:28:50.870779: predicting sub-r003s007 
2025-08-30 20:28:51.054277: sub-r003s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:29:08.296449: predicting sub-r003s008 
2025-08-30 20:29:08.476170: sub-r003s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:29:26.231350: predicting sub-r004s003 
2025-08-30 20:29:26.410662: sub-r004s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:29:44.645725: predicting sub-r004s023 
2025-08-30 20:29:44.824557: sub-r004s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:30:05.140624: predicting sub-r004s026 
2025-08-30 20:30:05.315824: sub-r004s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:30:24.247534: predicting sub-r005s068 
2025-08-30 20:30:24.464090: sub-r005s068, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:30:43.307093: predicting sub-r005s074 
2025-08-30 20:30:43.537307: sub-r005s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:31:04.078571: predicting sub-r005s081 
2025-08-30 20:31:04.266279: sub-r005s081, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:31:24.123980: predicting sub-r009s004 
2025-08-30 20:31:24.327957: sub-r009s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:31:44.677811: predicting sub-r009s011 
2025-08-30 20:31:44.865133: sub-r009s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:32:05.740510: predicting sub-r009s014 
2025-08-30 20:32:05.920005: sub-r009s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:32:23.975334: predicting sub-r009s015 
2025-08-30 20:32:24.192193: sub-r009s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:32:42.047498: predicting sub-r009s016 
2025-08-30 20:32:42.218493: sub-r009s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:33:00.866235: predicting sub-r009s017 
2025-08-30 20:33:01.041422: sub-r009s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:33:21.153146: predicting sub-r009s020 
2025-08-30 20:33:21.340897: sub-r009s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:33:43.166829: predicting sub-r009s038 
2025-08-30 20:33:43.404560: sub-r009s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:34:02.490210: predicting sub-r009s043 
2025-08-30 20:34:02.682120: sub-r009s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:34:23.198000: predicting sub-r009s049 
2025-08-30 20:34:23.381531: sub-r009s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:34:43.710153: predicting sub-r009s050 
2025-08-30 20:34:43.936027: sub-r009s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:35:03.025252: predicting sub-r009s054 
2025-08-30 20:35:03.213353: sub-r009s054, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:35:21.994151: predicting sub-r009s064 
2025-08-30 20:35:22.173506: sub-r009s064, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:35:41.655762: predicting sub-r009s067 
2025-08-30 20:35:41.843540: sub-r009s067, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:36:03.219021: predicting sub-r009s074 
2025-08-30 20:36:03.435889: sub-r009s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:36:25.195021: predicting sub-r009s078 
2025-08-30 20:36:25.395244: sub-r009s078, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:36:45.899027: predicting sub-r009s082 
2025-08-30 20:36:46.082194: sub-r009s082, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:37:05.914864: predicting sub-r009s083 
2025-08-30 20:37:06.085885: sub-r009s083, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:37:25.321320: predicting sub-r009s085 
2025-08-30 20:37:25.492750: sub-r009s085, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:37:46.396867: predicting sub-r009s087 
2025-08-30 20:37:46.584197: sub-r009s087, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:38:11.250459: predicting sub-r009s088 
2025-08-30 20:38:11.425680: sub-r009s088, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:38:34.269571: predicting sub-r009s089 
2025-08-30 20:38:34.465283: sub-r009s089, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:38:55.569666: predicting sub-r009s090 
2025-08-30 20:38:55.749034: sub-r009s090, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:39:16.495030: predicting sub-r009s091 
2025-08-30 20:39:16.690747: sub-r009s091, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:39:39.576444: predicting sub-r009s095 
2025-08-30 20:39:39.801644: sub-r009s095, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:39:56.697774: predicting sub-r009s098 
2025-08-30 20:39:56.876645: sub-r009s098, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:40:15.633193: predicting sub-r009s107 
2025-08-30 20:40:15.812598: sub-r009s107, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:40:34.698080: predicting sub-r009s115 
2025-08-30 20:40:34.898290: sub-r009s115, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:40:54.146661: predicting sub-r009s117 
2025-08-30 20:40:54.325623: sub-r009s117, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:41:15.843261: predicting sub-r010s008 
2025-08-30 20:41:16.026435: sub-r010s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:41:35.587960: predicting sub-r010s009 
2025-08-30 20:41:35.804843: sub-r010s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:41:55.332705: predicting sub-r010s010 
2025-08-30 20:41:55.503630: sub-r010s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:42:15.844826: predicting sub-r010s011 
2025-08-30 20:42:16.032154: sub-r010s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:42:37.132676: predicting sub-r010s027 
2025-08-30 20:42:37.337073: sub-r010s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:42:59.834507: predicting sub-r010s028 
2025-08-30 20:43:00.013849: sub-r010s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:43:21.439390: predicting sub-r011s001 
2025-08-30 20:43:21.618741: sub-r011s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:43:39.936642: predicting sub-r011s002 
2025-08-30 20:43:40.124319: sub-r011s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:43:57.032868: predicting sub-r011s024 
2025-08-30 20:43:57.216769: sub-r011s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:44:15.551667: predicting sub-r011s029 
2025-08-30 20:44:15.735252: sub-r011s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:44:35.567139: predicting sub-r011s032 
2025-08-30 20:44:35.780214: sub-r011s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:44:55.462341: predicting sub-r011s033 
2025-08-30 20:44:55.641340: sub-r011s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:45:13.046541: predicting sub-r014s002 
2025-08-30 20:45:13.242618: sub-r014s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:45:32.090566: predicting sub-r015s001 
2025-08-30 20:45:32.303317: sub-r015s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:45:52.802884: predicting sub-r015s025 
2025-08-30 20:45:52.986432: sub-r015s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:46:12.902089: predicting sub-r017s104 
2025-08-30 20:46:13.081447: sub-r017s104, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:46:35.198943: predicting sub-r017s105 
2025-08-30 20:46:35.369958: sub-r017s105, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:46:55.631816: predicting sub-r017s119 
2025-08-30 20:46:55.811175: sub-r017s119, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:47:15.931221: predicting sub-r018s010 
2025-08-30 20:47:16.118966: sub-r018s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:47:38.575018: predicting sub-r023s009 
2025-08-30 20:47:38.762340: sub-r023s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:48:02.636487: predicting sub-r023s014 
2025-08-30 20:48:02.823847: sub-r023s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:48:25.559043: predicting sub-r024s005 
2025-08-30 20:48:25.759218: sub-r024s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:48:45.491811: predicting sub-r024s019 
2025-08-30 20:48:45.683647: sub-r024s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:49:07.155023: predicting sub-r027s031 
2025-08-30 20:49:07.367806: sub-r027s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:49:24.130296: predicting sub-r027s032 
2025-08-30 20:49:24.346843: sub-r027s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:49:41.831289: predicting sub-r027s048 
2025-08-30 20:49:42.010703: sub-r027s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:50:03.022933: predicting sub-r028s002 
2025-08-30 20:50:03.219288: sub-r028s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:50:20.252609: predicting sub-r028s013 
2025-08-30 20:50:20.428206: sub-r028s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:50:36.852895: predicting sub-r029s009 
2025-08-30 20:50:37.057261: sub-r029s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:50:53.623684: predicting sub-r031s004 
2025-08-30 20:50:53.819848: sub-r031s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:51:11.846092: predicting sub-r031s005 
2025-08-30 20:51:12.012948: sub-r031s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:51:34.293129: predicting sub-r031s010 
2025-08-30 20:51:34.510351: sub-r031s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:51:53.241497: predicting sub-r031s012 
2025-08-30 20:51:53.416392: sub-r031s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:52:12.202197: predicting sub-r031s015 
2025-08-30 20:52:12.385307: sub-r031s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:52:29.619492: predicting sub-r031s019 
2025-08-30 20:52:29.828009: sub-r031s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:52:49.393356: predicting sub-r031s027 
2025-08-30 20:52:49.576569: sub-r031s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:53:11.185581: predicting sub-r031s035 
2025-08-30 20:53:11.364928: sub-r031s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:53:30.905635: predicting sub-r031s037 
2025-08-30 20:53:31.118417: sub-r031s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:53:51.029466: predicting sub-r034s007 
2025-08-30 20:53:51.213398: sub-r034s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:54:12.655221: predicting sub-r034s008 
2025-08-30 20:54:12.839156: sub-r034s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:54:35.061239: predicting sub-r034s015 
2025-08-30 20:54:35.252789: sub-r034s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:54:57.220944: predicting sub-r034s025 
2025-08-30 20:54:57.404383: sub-r034s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:55:15.706004: predicting sub-r034s048 
2025-08-30 20:55:15.901659: sub-r034s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:55:34.933529: predicting sub-r035s003 
2025-08-30 20:55:35.137508: sub-r035s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:55:55.099432: predicting sub-r038s024 
2025-08-30 20:55:55.274617: sub-r038s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:56:18.626775: predicting sub-r038s026 
2025-08-30 20:56:18.814855: sub-r038s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:56:38.555318: predicting sub-r038s032 
2025-08-30 20:56:38.771810: sub-r038s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:56:58.007673: predicting sub-r038s036 
2025-08-30 20:56:58.182846: sub-r038s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:57:17.143406: predicting sub-r038s049 
2025-08-30 20:57:17.314466: sub-r038s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:57:40.049590: predicting sub-r038s057 
2025-08-30 20:57:40.270653: sub-r038s057, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:58:03.998480: predicting sub-r038s071 
2025-08-30 20:58:04.173658: sub-r038s071, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:58:23.806034: predicting sub-r038s081 
2025-08-30 20:58:23.981354: sub-r038s081, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:58:43.413147: predicting sub-r038s097 
2025-08-30 20:58:43.600521: sub-r038s097, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:59:04.425767: predicting sub-r040s008 
2025-08-30 20:59:04.609328: sub-r040s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:59:26.677131: predicting sub-r040s017 
2025-08-30 20:59:26.898154: sub-r040s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 20:59:48.895134: predicting sub-r040s020 
2025-08-30 20:59:49.074503: sub-r040s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:00:10.165985: predicting sub-r040s042 
2025-08-30 21:00:10.349922: sub-r040s042, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:00:29.886099: predicting sub-r040s043 
2025-08-30 21:00:30.069523: sub-r040s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:00:49.692908: predicting sub-r040s045 
2025-08-30 21:00:49.868119: sub-r040s045, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:01:09.725785: predicting sub-r040s047 
2025-08-30 21:01:09.946450: sub-r040s047, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:01:29.115566: predicting sub-r040s064 
2025-08-30 21:01:29.324138: sub-r040s064, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:01:46.116186: predicting sub-r040s072 
2025-08-30 21:01:46.291378: sub-r040s072, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:02:04.154988: predicting sub-r042s003 
2025-08-30 21:02:04.346897: sub-r042s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:02:22.548044: predicting sub-r042s004 
2025-08-30 21:02:22.731954: sub-r042s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:02:42.305253: predicting sub-r042s025 
2025-08-30 21:02:42.505440: sub-r042s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:03:03.347431: predicting sub-r046s006 
2025-08-30 21:03:03.535150: sub-r046s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:03:22.249228: predicting sub-r046s012 
2025-08-30 21:03:22.429022: sub-r046s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:03:42.123591: predicting sub-r047s018 
2025-08-30 21:03:42.310926: sub-r047s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:04:03.444878: predicting sub-r047s050 
2025-08-30 21:04:03.628444: sub-r047s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:04:23.665032: predicting sub-r048s006 
2025-08-30 21:04:23.848542: sub-r048s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:04:46.879888: predicting sub-r048s015 
2025-08-30 21:04:47.075575: sub-r048s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:05:03.730076: predicting sub-r048s032 
2025-08-30 21:05:03.900957: sub-r048s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:05:20.221416: predicting sub-r048s037 
2025-08-30 21:05:20.396661: sub-r048s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:05:39.290498: predicting sub-r049s005 
2025-08-30 21:05:39.494821: sub-r049s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:06:01.595686: predicting sub-r049s024 
2025-08-30 21:06:01.791754: sub-r049s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:06:23.551262: predicting sub-r049s026 
2025-08-30 21:06:23.730687: sub-r049s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:06:44.568127: predicting sub-r050s002 
2025-08-30 21:06:44.788776: sub-r050s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:07:05.968642: predicting sub-r050s008 
2025-08-30 21:07:06.156369: sub-r050s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:07:24.691076: predicting sub-r050s015 
2025-08-30 21:07:24.904166: sub-r050s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:07:43.591197: predicting sub-r052s001 
2025-08-30 21:07:43.780984: sub-r052s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:08:02.087078: predicting sub-r052s014 
2025-08-30 21:08:02.274757: sub-r052s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:08:24.809370: predicting sub-r052s016 
2025-08-30 21:08:24.997401: sub-r052s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:08:48.439124: predicting sub-r052s019 
2025-08-30 21:08:48.616464: sub-r052s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:09:11.660597: predicting sub-r052s023 
2025-08-30 21:09:11.852480: sub-r052s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 21:09:41.452501: Validation complete 
2025-08-30 21:09:41.452501: Mean Validation Dice:  0.5484688198323737 
