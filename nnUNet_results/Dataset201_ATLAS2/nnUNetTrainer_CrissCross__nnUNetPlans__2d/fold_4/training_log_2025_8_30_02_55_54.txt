
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-30 02:55:55.196327: do_dummy_2d_data_aug: False 
2025-08-30 02:55:55.208734: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-30 02:55:55.216240: The split file contains 5 splits. 
2025-08-30 02:55:55.221332: Desired fold for training: 4 
2025-08-30 02:55:55.225819: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-30 02:56:01.835111: Unable to plot network architecture: 
2025-08-30 02:56:01.842244: No module named 'hiddenlayer' 
2025-08-30 02:56:01.890441:  
2025-08-30 02:56:01.895001: Epoch 0 
2025-08-30 02:56:01.899142: Current learning rate: 0.001 
2025-08-30 02:56:30.156553: train_loss 0.0981 
2025-08-30 02:56:30.164584: val_loss 0.0218 
2025-08-30 02:56:30.169025: Pseudo dice [np.float32(0.0)] 
2025-08-30 02:56:30.177152: Epoch time: 28.27 s 
2025-08-30 02:56:30.183043: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-30 02:56:30.977971:  
2025-08-30 02:56:30.986345: Epoch 1 
2025-08-30 02:56:30.990456: Current learning rate: 0.001 
2025-08-30 02:56:57.684121: train_loss 0.0055 
2025-08-30 02:56:57.692099: val_loss -0.0111 
2025-08-30 02:56:57.700474: Pseudo dice [np.float32(0.0)] 
2025-08-30 02:56:57.705455: Epoch time: 26.71 s 
2025-08-30 02:56:58.380254:  
2025-08-30 02:56:58.388978: Epoch 2 
2025-08-30 02:56:58.392785: Current learning rate: 0.001 
2025-08-30 02:57:25.081971: train_loss -0.0392 
2025-08-30 02:57:25.094476: val_loss -0.0547 
2025-08-30 02:57:25.098637: Pseudo dice [np.float32(0.0)] 
2025-08-30 02:57:25.104831: Epoch time: 26.7 s 
2025-08-30 02:57:25.757956:  
2025-08-30 02:57:25.767016: Epoch 3 
2025-08-30 02:57:25.773167: Current learning rate: 0.001 
2025-08-30 02:57:53.051549: train_loss -0.0829 
2025-08-30 02:57:53.059942: val_loss -0.1151 
2025-08-30 02:57:53.064067: Pseudo dice [np.float32(0.0)] 
2025-08-30 02:57:53.068235: Epoch time: 27.3 s 
2025-08-30 02:57:53.673007:  
2025-08-30 02:57:53.681345: Epoch 4 
2025-08-30 02:57:53.685983: Current learning rate: 0.001 
2025-08-30 02:58:20.971101: train_loss -0.0914 
2025-08-30 02:58:20.979490: val_loss -0.1993 
2025-08-30 02:58:20.983636: Pseudo dice [np.float32(0.4092)] 
2025-08-30 02:58:20.989317: Epoch time: 27.3 s 
2025-08-30 02:58:20.992932: Yayy! New best EMA pseudo Dice: 0.04089999943971634 
2025-08-30 02:58:21.844890:  
2025-08-30 02:58:21.853942: Epoch 5 
2025-08-30 02:58:21.859850: Current learning rate: 0.001 
2025-08-30 02:58:49.162306: train_loss -0.141 
2025-08-30 02:58:49.170136: val_loss -0.2039 
2025-08-30 02:58:49.179075: Pseudo dice [np.float32(0.3654)] 
2025-08-30 02:58:49.183943: Epoch time: 27.32 s 
2025-08-30 02:58:49.189631: Yayy! New best EMA pseudo Dice: 0.07339999824762344 
2025-08-30 02:58:49.967211:  
2025-08-30 02:58:49.975117: Epoch 6 
2025-08-30 02:58:49.979745: Current learning rate: 0.00099 
2025-08-30 02:59:17.257074: train_loss -0.1677 
2025-08-30 02:59:17.264896: val_loss -0.2328 
2025-08-30 02:59:17.269330: Pseudo dice [np.float32(0.4979)] 
2025-08-30 02:59:17.274289: Epoch time: 27.29 s 
2025-08-30 02:59:17.278345: Yayy! New best EMA pseudo Dice: 0.11580000072717667 
2025-08-30 02:59:18.086526:  
2025-08-30 02:59:18.094851: Epoch 7 
2025-08-30 02:59:18.103186: Current learning rate: 0.00099 
2025-08-30 02:59:45.818358: train_loss -0.1726 
2025-08-30 02:59:45.826700: val_loss -0.1959 
2025-08-30 02:59:45.830856: Pseudo dice [np.float32(0.4753)] 
2025-08-30 02:59:45.838166: Epoch time: 27.73 s 
2025-08-30 02:59:45.843794: Yayy! New best EMA pseudo Dice: 0.1518000066280365 
2025-08-30 02:59:46.827880:  
2025-08-30 02:59:46.836055: Epoch 8 
2025-08-30 02:59:46.838965: Current learning rate: 0.00099 
2025-08-30 03:00:14.126099: train_loss -0.2039 
2025-08-30 03:00:14.134487: val_loss -0.2573 
2025-08-30 03:00:14.138314: Pseudo dice [np.float32(0.4857)] 
2025-08-30 03:00:14.145955: Epoch time: 27.3 s 
2025-08-30 03:00:14.152432: Yayy! New best EMA pseudo Dice: 0.18520000576972961 
2025-08-30 03:00:14.972583:  
2025-08-30 03:00:14.980830: Epoch 9 
2025-08-30 03:00:14.984993: Current learning rate: 0.00099 
2025-08-30 03:00:42.224688: train_loss -0.1856 
2025-08-30 03:00:42.233051: val_loss -0.1964 
2025-08-30 03:00:42.237207: Pseudo dice [np.float32(0.4031)] 
2025-08-30 03:00:42.242808: Epoch time: 27.25 s 
2025-08-30 03:00:42.246408: Yayy! New best EMA pseudo Dice: 0.2070000022649765 
2025-08-30 03:00:43.046442:  
2025-08-30 03:00:43.054918: Epoch 10 
2025-08-30 03:00:43.058942: Current learning rate: 0.00099 
2025-08-30 03:01:09.869216: train_loss -0.1878 
2025-08-30 03:01:09.873458: val_loss -0.2572 
2025-08-30 03:01:09.881736: Pseudo dice [np.float32(0.5066)] 
2025-08-30 03:01:09.886959: Epoch time: 26.82 s 
2025-08-30 03:01:09.890862: Yayy! New best EMA pseudo Dice: 0.23690000176429749 
2025-08-30 03:01:10.687232:  
2025-08-30 03:01:10.695428: Epoch 11 
2025-08-30 03:01:10.703130: Current learning rate: 0.00099 
2025-08-30 03:01:38.548272: train_loss -0.2294 
2025-08-30 03:01:38.555957: val_loss -0.3072 
2025-08-30 03:01:38.560111: Pseudo dice [np.float32(0.5347)] 
2025-08-30 03:01:38.567332: Epoch time: 27.86 s 
2025-08-30 03:01:38.573019: Yayy! New best EMA pseudo Dice: 0.26669999957084656 
2025-08-30 03:01:39.390185:  
2025-08-30 03:01:39.398496: Epoch 12 
2025-08-30 03:01:39.402731: Current learning rate: 0.00099 
2025-08-30 03:02:06.392530: train_loss -0.2781 
2025-08-30 03:02:06.400421: val_loss -0.3218 
2025-08-30 03:02:06.404587: Pseudo dice [np.float32(0.5007)] 
2025-08-30 03:02:06.413011: Epoch time: 27.0 s 
2025-08-30 03:02:06.417091: Yayy! New best EMA pseudo Dice: 0.29010000824928284 
2025-08-30 03:02:07.218149:  
2025-08-30 03:02:07.226298: Epoch 13 
2025-08-30 03:02:07.230432: Current learning rate: 0.00099 
2025-08-30 03:02:34.328659: train_loss -0.255 
2025-08-30 03:02:34.339588: val_loss -0.3336 
2025-08-30 03:02:34.347497: Pseudo dice [np.float32(0.6293)] 
2025-08-30 03:02:34.353040: Epoch time: 27.11 s 
2025-08-30 03:02:34.358073: Yayy! New best EMA pseudo Dice: 0.3240000009536743 
2025-08-30 03:02:35.421459:  
2025-08-30 03:02:35.429442: Epoch 14 
2025-08-30 03:02:35.437768: Current learning rate: 0.00099 
2025-08-30 03:03:02.698646: train_loss -0.2684 
2025-08-30 03:03:02.706933: val_loss -0.376 
2025-08-30 03:03:02.711168: Pseudo dice [np.float32(0.5783)] 
2025-08-30 03:03:02.716525: Epoch time: 27.28 s 
2025-08-30 03:03:02.720169: Yayy! New best EMA pseudo Dice: 0.34950000047683716 
2025-08-30 03:03:03.528346:  
2025-08-30 03:03:03.536659: Epoch 15 
2025-08-30 03:03:03.544863: Current learning rate: 0.00099 
2025-08-30 03:03:31.039450: train_loss -0.2544 
2025-08-30 03:03:31.051965: val_loss -0.3354 
2025-08-30 03:03:31.055801: Pseudo dice [np.float32(0.5689)] 
2025-08-30 03:03:31.062134: Epoch time: 27.51 s 
2025-08-30 03:03:31.068287: Yayy! New best EMA pseudo Dice: 0.37139999866485596 
2025-08-30 03:03:31.885887:  
2025-08-30 03:03:31.894530: Epoch 16 
2025-08-30 03:03:31.901861: Current learning rate: 0.00099 
2025-08-30 03:03:57.421548: train_loss -0.3084 
2025-08-30 03:03:57.427980: val_loss -0.2692 
2025-08-30 03:03:57.432177: Pseudo dice [np.float32(0.5198)] 
2025-08-30 03:03:57.438524: Epoch time: 25.54 s 
2025-08-30 03:03:57.444627: Yayy! New best EMA pseudo Dice: 0.3862000107765198 
2025-08-30 03:03:58.278829:  
2025-08-30 03:03:58.287211: Epoch 17 
2025-08-30 03:03:58.291800: Current learning rate: 0.00098 
2025-08-30 03:04:24.759899: train_loss -0.2486 
2025-08-30 03:04:24.763656: val_loss -0.3892 
2025-08-30 03:04:24.771950: Pseudo dice [np.float32(0.603)] 
2025-08-30 03:04:24.777318: Epoch time: 26.48 s 
2025-08-30 03:04:24.781270: Yayy! New best EMA pseudo Dice: 0.40790000557899475 
2025-08-30 03:04:25.589573:  
2025-08-30 03:04:25.598582: Epoch 18 
2025-08-30 03:04:25.610811: Current learning rate: 0.00098 
2025-08-30 03:04:52.295209: train_loss -0.285 
2025-08-30 03:04:52.299476: val_loss -0.3696 
2025-08-30 03:04:52.308154: Pseudo dice [np.float32(0.5875)] 
2025-08-30 03:04:52.312955: Epoch time: 26.71 s 
2025-08-30 03:04:52.317765: Yayy! New best EMA pseudo Dice: 0.42590001225471497 
2025-08-30 03:04:53.296576:  
2025-08-30 03:04:53.304971: Epoch 19 
2025-08-30 03:04:53.309130: Current learning rate: 0.00098 
2025-08-30 03:05:19.927603: train_loss -0.3231 
2025-08-30 03:05:19.935805: val_loss -0.3209 
2025-08-30 03:05:19.939608: Pseudo dice [np.float32(0.6322)] 
2025-08-30 03:05:19.946724: Epoch time: 26.64 s 
2025-08-30 03:05:19.952065: Yayy! New best EMA pseudo Dice: 0.4465000033378601 
2025-08-30 03:05:20.765691:  
2025-08-30 03:05:20.769558: Epoch 20 
2025-08-30 03:05:20.777900: Current learning rate: 0.00098 
2025-08-30 03:05:47.546461: train_loss -0.3071 
2025-08-30 03:05:47.555111: val_loss -0.3803 
2025-08-30 03:05:47.559227: Pseudo dice [np.float32(0.6833)] 
2025-08-30 03:05:47.566969: Epoch time: 26.79 s 
2025-08-30 03:05:47.571895: Yayy! New best EMA pseudo Dice: 0.4702000021934509 
2025-08-30 03:05:48.418301:  
2025-08-30 03:05:48.426681: Epoch 21 
2025-08-30 03:05:48.430525: Current learning rate: 0.00098 
2025-08-30 03:06:14.694200: train_loss -0.2844 
2025-08-30 03:06:14.698757: val_loss -0.3555 
2025-08-30 03:06:14.706764: Pseudo dice [np.float32(0.6389)] 
2025-08-30 03:06:14.710941: Epoch time: 26.28 s 
2025-08-30 03:06:14.716140: Yayy! New best EMA pseudo Dice: 0.4869999885559082 
2025-08-30 03:06:15.516196:  
2025-08-30 03:06:15.524255: Epoch 22 
2025-08-30 03:06:15.528629: Current learning rate: 0.00098 
2025-08-30 03:06:43.105914: train_loss -0.348 
2025-08-30 03:06:43.118478: val_loss -0.4483 
2025-08-30 03:06:43.122608: Pseudo dice [np.float32(0.6449)] 
2025-08-30 03:06:43.128816: Epoch time: 27.59 s 
2025-08-30 03:06:43.131914: Yayy! New best EMA pseudo Dice: 0.5027999877929688 
2025-08-30 03:06:43.948934:  
2025-08-30 03:06:43.956821: Epoch 23 
2025-08-30 03:06:43.961287: Current learning rate: 0.00098 
2025-08-30 03:07:11.631118: train_loss -0.3627 
2025-08-30 03:07:11.638921: val_loss -0.3259 
2025-08-30 03:07:11.643106: Pseudo dice [np.float32(0.5334)] 
2025-08-30 03:07:11.651055: Epoch time: 27.69 s 
2025-08-30 03:07:11.657999: Yayy! New best EMA pseudo Dice: 0.5059000253677368 
2025-08-30 03:07:12.456112:  
2025-08-30 03:07:12.464483: Epoch 24 
2025-08-30 03:07:12.468959: Current learning rate: 0.00098 
2025-08-30 03:07:39.891326: train_loss -0.3146 
2025-08-30 03:07:39.900442: val_loss -0.4088 
2025-08-30 03:07:39.904314: Pseudo dice [np.float32(0.6684)] 
2025-08-30 03:07:39.912509: Epoch time: 27.44 s 
2025-08-30 03:07:39.917346: Yayy! New best EMA pseudo Dice: 0.5220999717712402 
2025-08-30 03:07:40.738484:  
2025-08-30 03:07:40.742660: Epoch 25 
2025-08-30 03:07:40.751628: Current learning rate: 0.00098 
2025-08-30 03:08:07.110669: train_loss -0.2713 
2025-08-30 03:08:07.118990: val_loss -0.373 
2025-08-30 03:08:07.123428: Pseudo dice [np.float32(0.6642)] 
2025-08-30 03:08:07.129381: Epoch time: 26.38 s 
2025-08-30 03:08:07.132474: Yayy! New best EMA pseudo Dice: 0.536300003528595 
2025-08-30 03:08:08.091115:  
2025-08-30 03:08:08.099179: Epoch 26 
2025-08-30 03:08:08.103640: Current learning rate: 0.00098 
2025-08-30 03:08:34.600921: train_loss -0.334 
2025-08-30 03:08:34.613468: val_loss -0.4577 
2025-08-30 03:08:34.617301: Pseudo dice [np.float32(0.6479)] 
2025-08-30 03:08:34.623590: Epoch time: 26.51 s 
2025-08-30 03:08:34.631514: Yayy! New best EMA pseudo Dice: 0.5475000143051147 
2025-08-30 03:08:35.430659:  
2025-08-30 03:08:35.439014: Epoch 27 
2025-08-30 03:08:35.443435: Current learning rate: 0.00098 
2025-08-30 03:09:01.907376: train_loss -0.3564 
2025-08-30 03:09:01.915731: val_loss -0.45 
2025-08-30 03:09:01.919786: Pseudo dice [np.float32(0.6512)] 
2025-08-30 03:09:01.927823: Epoch time: 26.48 s 
2025-08-30 03:09:01.932534: Yayy! New best EMA pseudo Dice: 0.5579000115394592 
2025-08-30 03:09:02.741191:  
2025-08-30 03:09:02.745409: Epoch 28 
2025-08-30 03:09:02.754098: Current learning rate: 0.00097 
2025-08-30 03:09:30.206131: train_loss -0.3176 
2025-08-30 03:09:30.210548: val_loss -0.4141 
2025-08-30 03:09:30.218665: Pseudo dice [np.float32(0.5876)] 
2025-08-30 03:09:30.223912: Epoch time: 27.47 s 
2025-08-30 03:09:30.228874: Yayy! New best EMA pseudo Dice: 0.5608000159263611 
2025-08-30 03:09:31.032220:  
2025-08-30 03:09:31.040581: Epoch 29 
2025-08-30 03:09:31.044707: Current learning rate: 0.00097 
2025-08-30 03:09:57.975879: train_loss -0.3472 
2025-08-30 03:09:57.984202: val_loss -0.4196 
2025-08-30 03:09:57.988292: Pseudo dice [np.float32(0.6433)] 
2025-08-30 03:09:57.996140: Epoch time: 26.94 s 
2025-08-30 03:09:58.001058: Yayy! New best EMA pseudo Dice: 0.569100022315979 
2025-08-30 03:09:58.822189:  
2025-08-30 03:09:58.826420: Epoch 30 
2025-08-30 03:09:58.834737: Current learning rate: 0.00097 
2025-08-30 03:10:25.407078: train_loss -0.3662 
2025-08-30 03:10:25.419623: val_loss -0.4806 
2025-08-30 03:10:25.423763: Pseudo dice [np.float32(0.7387)] 
2025-08-30 03:10:25.430253: Epoch time: 26.59 s 
2025-08-30 03:10:25.436244: Yayy! New best EMA pseudo Dice: 0.5860999822616577 
2025-08-30 03:10:26.257936:  
2025-08-30 03:10:26.266304: Epoch 31 
2025-08-30 03:10:26.270442: Current learning rate: 0.00097 
2025-08-30 03:10:53.131195: train_loss -0.3262 
2025-08-30 03:10:53.138938: val_loss -0.4931 
2025-08-30 03:10:53.143461: Pseudo dice [np.float32(0.7293)] 
2025-08-30 03:10:53.149362: Epoch time: 26.87 s 
2025-08-30 03:10:53.152450: Yayy! New best EMA pseudo Dice: 0.6003999710083008 
2025-08-30 03:10:54.110737:  
2025-08-30 03:10:54.119133: Epoch 32 
2025-08-30 03:10:54.123551: Current learning rate: 0.00097 
2025-08-30 03:11:21.321935: train_loss -0.381 
2025-08-30 03:11:21.329639: val_loss -0.4312 
2025-08-30 03:11:21.334115: Pseudo dice [np.float32(0.6871)] 
2025-08-30 03:11:21.339203: Epoch time: 27.21 s 
2025-08-30 03:11:21.341202: Yayy! New best EMA pseudo Dice: 0.6090999841690063 
2025-08-30 03:11:22.159634:  
2025-08-30 03:11:22.168218: Epoch 33 
2025-08-30 03:11:22.172209: Current learning rate: 0.00097 
2025-08-30 03:11:49.095076: train_loss -0.4111 
2025-08-30 03:11:49.107368: val_loss -0.4412 
2025-08-30 03:11:49.111536: Pseudo dice [np.float32(0.6868)] 
2025-08-30 03:11:49.117091: Epoch time: 26.94 s 
2025-08-30 03:11:49.120838: Yayy! New best EMA pseudo Dice: 0.6168000102043152 
2025-08-30 03:11:49.945682:  
2025-08-30 03:11:49.954319: Epoch 34 
2025-08-30 03:11:49.958568: Current learning rate: 0.00097 
2025-08-30 03:12:16.343347: train_loss -0.3519 
2025-08-30 03:12:16.351542: val_loss -0.3792 
2025-08-30 03:12:16.355394: Pseudo dice [np.float32(0.712)] 
2025-08-30 03:12:16.361675: Epoch time: 26.4 s 
2025-08-30 03:12:16.364729: Yayy! New best EMA pseudo Dice: 0.6262999773025513 
2025-08-30 03:12:17.218826:  
2025-08-30 03:12:17.227128: Epoch 35 
2025-08-30 03:12:17.231670: Current learning rate: 0.00097 
2025-08-30 03:12:44.483492: train_loss -0.3583 
2025-08-30 03:12:44.495979: val_loss -0.3483 
2025-08-30 03:12:44.500160: Pseudo dice [np.float32(0.6632)] 
2025-08-30 03:12:44.506205: Epoch time: 27.26 s 
2025-08-30 03:12:44.509368: Yayy! New best EMA pseudo Dice: 0.6299999952316284 
2025-08-30 03:12:45.326037:  
2025-08-30 03:12:45.334646: Epoch 36 
2025-08-30 03:12:45.341708: Current learning rate: 0.00097 
2025-08-30 03:13:11.956702: train_loss -0.3705 
2025-08-30 03:13:11.965092: val_loss -0.3797 
2025-08-30 03:13:11.973485: Pseudo dice [np.float32(0.6116)] 
2025-08-30 03:13:11.977622: Epoch time: 26.63 s 
2025-08-30 03:13:12.624427:  
2025-08-30 03:13:12.632513: Epoch 37 
2025-08-30 03:13:12.636818: Current learning rate: 0.00097 
2025-08-30 03:13:39.822056: train_loss -0.3481 
2025-08-30 03:13:39.834569: val_loss -0.3791 
2025-08-30 03:13:39.839992: Pseudo dice [np.float32(0.6479)] 
2025-08-30 03:13:39.844663: Epoch time: 27.2 s 
2025-08-30 03:13:39.847478: Yayy! New best EMA pseudo Dice: 0.6302000284194946 
2025-08-30 03:13:40.814749:  
2025-08-30 03:13:40.823093: Epoch 38 
2025-08-30 03:13:40.827229: Current learning rate: 0.00097 
2025-08-30 03:14:07.257787: train_loss -0.3145 
2025-08-30 03:14:07.261984: val_loss -0.4061 
2025-08-30 03:14:07.270295: Pseudo dice [np.float32(0.6143)] 
2025-08-30 03:14:07.275913: Epoch time: 26.44 s 
2025-08-30 03:14:07.904327:  
2025-08-30 03:14:07.912678: Epoch 39 
2025-08-30 03:14:07.916857: Current learning rate: 0.00096 
2025-08-30 03:14:34.897962: train_loss -0.4064 
2025-08-30 03:14:34.906269: val_loss -0.3962 
2025-08-30 03:14:34.910429: Pseudo dice [np.float32(0.6037)] 
2025-08-30 03:14:34.918540: Epoch time: 26.99 s 
2025-08-30 03:14:35.548878:  
2025-08-30 03:14:35.552714: Epoch 40 
2025-08-30 03:14:35.561090: Current learning rate: 0.00096 
2025-08-30 03:15:02.462966: train_loss -0.3889 
2025-08-30 03:15:02.471257: val_loss -0.4641 
2025-08-30 03:15:02.475465: Pseudo dice [np.float32(0.6998)] 
2025-08-30 03:15:02.483362: Epoch time: 26.92 s 
2025-08-30 03:15:02.493449: Yayy! New best EMA pseudo Dice: 0.6334999799728394 
2025-08-30 03:15:03.359672:  
2025-08-30 03:15:03.368305: Epoch 41 
2025-08-30 03:15:03.373257: Current learning rate: 0.00096 
2025-08-30 03:15:30.173911: train_loss -0.3797 
2025-08-30 03:15:30.182272: val_loss -0.3859 
2025-08-30 03:15:30.186464: Pseudo dice [np.float32(0.5163)] 
2025-08-30 03:15:30.193080: Epoch time: 26.82 s 
2025-08-30 03:15:30.866302:  
2025-08-30 03:15:30.875325: Epoch 42 
2025-08-30 03:15:30.878821: Current learning rate: 0.00096 
2025-08-30 03:15:57.272148: train_loss -0.3718 
2025-08-30 03:15:57.280246: val_loss -0.4111 
2025-08-30 03:15:57.284631: Pseudo dice [np.float32(0.6384)] 
2025-08-30 03:15:57.292461: Epoch time: 26.41 s 
2025-08-30 03:15:57.906131:  
2025-08-30 03:15:57.914618: Epoch 43 
2025-08-30 03:15:57.918613: Current learning rate: 0.00096 
2025-08-30 03:16:25.287670: train_loss -0.3775 
2025-08-30 03:16:25.299885: val_loss -0.3925 
2025-08-30 03:16:25.304182: Pseudo dice [np.float32(0.657)] 
2025-08-30 03:16:25.310354: Epoch time: 27.38 s 
2025-08-30 03:16:26.071384:  
2025-08-30 03:16:26.075858: Epoch 44 
2025-08-30 03:16:26.083977: Current learning rate: 0.00096 
2025-08-30 03:16:53.152932: train_loss -0.3615 
2025-08-30 03:16:53.161331: val_loss -0.4239 
2025-08-30 03:16:53.169309: Pseudo dice [np.float32(0.6966)] 
2025-08-30 03:16:53.175880: Epoch time: 27.09 s 
2025-08-30 03:16:53.178613: Yayy! New best EMA pseudo Dice: 0.6338000297546387 
2025-08-30 03:16:53.982583:  
2025-08-30 03:16:53.990965: Epoch 45 
2025-08-30 03:16:53.995358: Current learning rate: 0.00096 
2025-08-30 03:17:21.443650: train_loss -0.364 
2025-08-30 03:17:21.452054: val_loss -0.4384 
2025-08-30 03:17:21.455827: Pseudo dice [np.float32(0.6919)] 
2025-08-30 03:17:21.464319: Epoch time: 27.47 s 
2025-08-30 03:17:21.469297: Yayy! New best EMA pseudo Dice: 0.6395999789237976 
2025-08-30 03:17:22.277808:  
2025-08-30 03:17:22.286251: Epoch 46 
2025-08-30 03:17:22.293934: Current learning rate: 0.00096 
2025-08-30 03:17:49.500851: train_loss -0.425 
2025-08-30 03:17:49.512847: val_loss -0.4702 
2025-08-30 03:17:49.517542: Pseudo dice [np.float32(0.7153)] 
2025-08-30 03:17:49.522263: Epoch time: 27.22 s 
2025-08-30 03:17:49.526488: Yayy! New best EMA pseudo Dice: 0.6470999717712402 
2025-08-30 03:17:50.334704:  
2025-08-30 03:17:50.345306: Epoch 47 
2025-08-30 03:17:50.352964: Current learning rate: 0.00096 
2025-08-30 03:18:17.858293: train_loss -0.3706 
2025-08-30 03:18:17.866386: val_loss -0.5104 
2025-08-30 03:18:17.870578: Pseudo dice [np.float32(0.7173)] 
2025-08-30 03:18:17.876199: Epoch time: 27.52 s 
2025-08-30 03:18:17.883020: Yayy! New best EMA pseudo Dice: 0.65420001745224 
2025-08-30 03:18:18.679657:  
2025-08-30 03:18:18.688385: Epoch 48 
2025-08-30 03:18:18.692181: Current learning rate: 0.00096 
2025-08-30 03:18:45.899399: train_loss -0.3759 
2025-08-30 03:18:45.907212: val_loss -0.465 
2025-08-30 03:18:45.911077: Pseudo dice [np.float32(0.6402)] 
2025-08-30 03:18:45.919435: Epoch time: 27.22 s 
2025-08-30 03:18:46.553427:  
2025-08-30 03:18:46.562162: Epoch 49 
2025-08-30 03:18:46.566392: Current learning rate: 0.00096 
2025-08-30 03:19:13.776682: train_loss -0.3772 
2025-08-30 03:19:13.784710: val_loss -0.4758 
2025-08-30 03:19:13.789250: Pseudo dice [np.float32(0.6647)] 
2025-08-30 03:19:13.796155: Epoch time: 27.22 s 
2025-08-30 03:19:14.606360:  
2025-08-30 03:19:14.614774: Epoch 50 
2025-08-30 03:19:14.618905: Current learning rate: 0.00095 
2025-08-30 03:19:41.759070: train_loss -0.3988 
2025-08-30 03:19:41.771028: val_loss -0.4873 
2025-08-30 03:19:41.775473: Pseudo dice [np.float32(0.6604)] 
2025-08-30 03:19:41.782415: Epoch time: 27.16 s 
2025-08-30 03:19:41.788166: Yayy! New best EMA pseudo Dice: 0.6546000242233276 
2025-08-30 03:19:42.743186:  
2025-08-30 03:19:42.751442: Epoch 51 
2025-08-30 03:19:42.759807: Current learning rate: 0.00095 
2025-08-30 03:20:09.327969: train_loss -0.4084 
2025-08-30 03:20:09.338233: val_loss -0.4926 
2025-08-30 03:20:09.344323: Pseudo dice [np.float32(0.6995)] 
2025-08-30 03:20:09.348995: Epoch time: 26.58 s 
2025-08-30 03:20:09.353602: Yayy! New best EMA pseudo Dice: 0.6590999960899353 
2025-08-30 03:20:10.158001:  
2025-08-30 03:20:10.166300: Epoch 52 
2025-08-30 03:20:10.170177: Current learning rate: 0.00095 
2025-08-30 03:20:36.822008: train_loss -0.4576 
2025-08-30 03:20:36.830446: val_loss -0.4855 
2025-08-30 03:20:36.834301: Pseudo dice [np.float32(0.7512)] 
2025-08-30 03:20:36.841786: Epoch time: 26.66 s 
2025-08-30 03:20:36.846806: Yayy! New best EMA pseudo Dice: 0.6682999730110168 
2025-08-30 03:20:37.668482:  
2025-08-30 03:20:37.677166: Epoch 53 
2025-08-30 03:20:37.681227: Current learning rate: 0.00095 
2025-08-30 03:21:04.649931: train_loss -0.4363 
2025-08-30 03:21:04.658233: val_loss -0.458 
2025-08-30 03:21:04.666270: Pseudo dice [np.float32(0.7264)] 
2025-08-30 03:21:04.672733: Epoch time: 26.98 s 
2025-08-30 03:21:04.679646: Yayy! New best EMA pseudo Dice: 0.6740999817848206 
2025-08-30 03:21:05.502710:  
2025-08-30 03:21:05.508861: Epoch 54 
2025-08-30 03:21:05.516966: Current learning rate: 0.00095 
2025-08-30 03:21:31.868269: train_loss -0.3913 
2025-08-30 03:21:31.877011: val_loss -0.5445 
2025-08-30 03:21:31.880948: Pseudo dice [np.float32(0.761)] 
2025-08-30 03:21:31.889270: Epoch time: 26.37 s 
2025-08-30 03:21:31.895018: Yayy! New best EMA pseudo Dice: 0.6827999949455261 
2025-08-30 03:21:32.740180:  
2025-08-30 03:21:32.744298: Epoch 55 
2025-08-30 03:21:32.753062: Current learning rate: 0.00095 
2025-08-30 03:21:58.028293: train_loss -0.4222 
2025-08-30 03:21:58.036527: val_loss -0.4657 
2025-08-30 03:21:58.040648: Pseudo dice [np.float32(0.6713)] 
2025-08-30 03:21:58.050012: Epoch time: 25.29 s 
2025-08-30 03:21:58.674453:  
2025-08-30 03:21:58.682729: Epoch 56 
2025-08-30 03:21:58.686892: Current learning rate: 0.00095 
2025-08-30 03:22:24.187340: train_loss -0.4346 
2025-08-30 03:22:24.191501: val_loss -0.4024 
2025-08-30 03:22:24.199850: Pseudo dice [np.float32(0.6483)] 
2025-08-30 03:22:24.204737: Epoch time: 25.51 s 
2025-08-30 03:22:24.958935:  
2025-08-30 03:22:24.967621: Epoch 57 
2025-08-30 03:22:24.971451: Current learning rate: 0.00095 
2025-08-30 03:22:50.551370: train_loss -0.4093 
2025-08-30 03:22:50.563678: val_loss -0.4192 
2025-08-30 03:22:50.568075: Pseudo dice [np.float32(0.657)] 
2025-08-30 03:22:50.574312: Epoch time: 25.59 s 
2025-08-30 03:22:51.180981:  
2025-08-30 03:22:51.189703: Epoch 58 
2025-08-30 03:22:51.193722: Current learning rate: 0.00095 
2025-08-30 03:23:16.898326: train_loss -0.4499 
2025-08-30 03:23:16.906663: val_loss -0.4812 
2025-08-30 03:23:16.910802: Pseudo dice [np.float32(0.7403)] 
2025-08-30 03:23:16.917169: Epoch time: 25.72 s 
2025-08-30 03:23:17.528471:  
2025-08-30 03:23:17.536505: Epoch 59 
2025-08-30 03:23:17.540672: Current learning rate: 0.00095 
2025-08-30 03:23:43.003590: train_loss -0.4364 
2025-08-30 03:23:43.016142: val_loss -0.436 
2025-08-30 03:23:43.020514: Pseudo dice [np.float32(0.6831)] 
2025-08-30 03:23:43.025678: Epoch time: 25.48 s 
2025-08-30 03:23:43.633455:  
2025-08-30 03:23:43.642018: Epoch 60 
2025-08-30 03:23:43.650067: Current learning rate: 0.00095 
2025-08-30 03:24:09.154813: train_loss -0.3885 
2025-08-30 03:24:09.163396: val_loss -0.4376 
2025-08-30 03:24:09.167510: Pseudo dice [np.float32(0.6911)] 
2025-08-30 03:24:09.172594: Epoch time: 25.52 s 
2025-08-30 03:24:09.176517: Yayy! New best EMA pseudo Dice: 0.6834999918937683 
2025-08-30 03:24:09.985037:  
2025-08-30 03:24:09.993587: Epoch 61 
2025-08-30 03:24:10.001255: Current learning rate: 0.00094 
2025-08-30 03:24:37.161776: train_loss -0.4407 
2025-08-30 03:24:37.170161: val_loss -0.4643 
2025-08-30 03:24:37.174305: Pseudo dice [np.float32(0.6762)] 
2025-08-30 03:24:37.179778: Epoch time: 27.18 s 
2025-08-30 03:24:37.791963:  
2025-08-30 03:24:37.800033: Epoch 62 
2025-08-30 03:24:37.804418: Current learning rate: 0.00094 
2025-08-30 03:25:05.056731: train_loss -0.4279 
2025-08-30 03:25:05.060816: val_loss -0.4265 
2025-08-30 03:25:05.068877: Pseudo dice [np.float32(0.7261)] 
2025-08-30 03:25:05.074322: Epoch time: 27.26 s 
2025-08-30 03:25:05.078211: Yayy! New best EMA pseudo Dice: 0.6870999932289124 
2025-08-30 03:25:05.890481:  
2025-08-30 03:25:05.898845: Epoch 63 
2025-08-30 03:25:05.903170: Current learning rate: 0.00094 
2025-08-30 03:25:32.508720: train_loss -0.4176 
2025-08-30 03:25:32.517048: val_loss -0.3894 
2025-08-30 03:25:32.521204: Pseudo dice [np.float32(0.6346)] 
2025-08-30 03:25:32.529638: Epoch time: 26.62 s 
2025-08-30 03:25:33.314038:  
2025-08-30 03:25:33.322096: Epoch 64 
2025-08-30 03:25:33.326488: Current learning rate: 0.00094 
2025-08-30 03:25:59.815305: train_loss -0.4293 
2025-08-30 03:25:59.819352: val_loss -0.4395 
2025-08-30 03:25:59.827993: Pseudo dice [np.float32(0.7506)] 
2025-08-30 03:25:59.833184: Epoch time: 26.51 s 
2025-08-30 03:25:59.838194: Yayy! New best EMA pseudo Dice: 0.6887000203132629 
2025-08-30 03:26:00.657984:  
2025-08-30 03:26:00.666315: Epoch 65 
2025-08-30 03:26:00.670492: Current learning rate: 0.00094 
2025-08-30 03:26:27.422624: train_loss -0.4249 
2025-08-30 03:26:27.430261: val_loss -0.5342 
2025-08-30 03:26:27.434379: Pseudo dice [np.float32(0.7258)] 
2025-08-30 03:26:27.442796: Epoch time: 26.77 s 
2025-08-30 03:26:27.447860: Yayy! New best EMA pseudo Dice: 0.6923999786376953 
2025-08-30 03:26:28.260589:  
2025-08-30 03:26:28.270206: Epoch 66 
2025-08-30 03:26:28.273083: Current learning rate: 0.00094 
2025-08-30 03:26:55.529523: train_loss -0.4229 
2025-08-30 03:26:55.537569: val_loss -0.4646 
2025-08-30 03:26:55.541872: Pseudo dice [np.float32(0.7319)] 
2025-08-30 03:26:55.548764: Epoch time: 27.27 s 
2025-08-30 03:26:55.554619: Yayy! New best EMA pseudo Dice: 0.696399986743927 
2025-08-30 03:26:56.359279:  
2025-08-30 03:26:56.367448: Epoch 67 
2025-08-30 03:26:56.375788: Current learning rate: 0.00094 
2025-08-30 03:27:23.632270: train_loss -0.3996 
2025-08-30 03:27:23.640609: val_loss -0.4923 
2025-08-30 03:27:23.645011: Pseudo dice [np.float32(0.6901)] 
2025-08-30 03:27:23.651875: Epoch time: 27.27 s 
2025-08-30 03:27:24.270386:  
2025-08-30 03:27:24.278672: Epoch 68 
2025-08-30 03:27:24.283119: Current learning rate: 0.00094 
2025-08-30 03:27:51.374677: train_loss -0.411 
2025-08-30 03:27:51.385241: val_loss -0.4473 
2025-08-30 03:27:51.389429: Pseudo dice [np.float32(0.7503)] 
2025-08-30 03:27:51.396802: Epoch time: 27.11 s 
2025-08-30 03:27:51.402055: Yayy! New best EMA pseudo Dice: 0.701200008392334 
2025-08-30 03:27:52.210705:  
2025-08-30 03:27:52.218895: Epoch 69 
2025-08-30 03:27:52.223513: Current learning rate: 0.00094 
2025-08-30 03:28:19.081224: train_loss -0.3947 
2025-08-30 03:28:19.087605: val_loss -0.4172 
2025-08-30 03:28:19.091717: Pseudo dice [np.float32(0.7075)] 
2025-08-30 03:28:19.099890: Epoch time: 26.87 s 
2025-08-30 03:28:19.104577: Yayy! New best EMA pseudo Dice: 0.7017999887466431 
2025-08-30 03:28:20.118073:  
2025-08-30 03:28:20.126083: Epoch 70 
2025-08-30 03:28:20.130638: Current learning rate: 0.00094 
2025-08-30 03:28:47.028084: train_loss -0.4442 
2025-08-30 03:28:47.040260: val_loss -0.4962 
2025-08-30 03:28:47.044650: Pseudo dice [np.float32(0.7027)] 
2025-08-30 03:28:47.050196: Epoch time: 26.91 s 
2025-08-30 03:28:47.053964: Yayy! New best EMA pseudo Dice: 0.7019000053405762 
2025-08-30 03:28:47.878824:  
2025-08-30 03:28:47.883007: Epoch 71 
2025-08-30 03:28:47.887128: Current learning rate: 0.00094 
2025-08-30 03:29:14.840483: train_loss -0.4212 
2025-08-30 03:29:14.848892: val_loss -0.4986 
2025-08-30 03:29:14.854069: Pseudo dice [np.float32(0.6727)] 
2025-08-30 03:29:14.858999: Epoch time: 26.97 s 
2025-08-30 03:29:15.485539:  
2025-08-30 03:29:15.493887: Epoch 72 
2025-08-30 03:29:15.498082: Current learning rate: 0.00093 
2025-08-30 03:29:42.696266: train_loss -0.4303 
2025-08-30 03:29:42.704612: val_loss -0.4693 
2025-08-30 03:29:42.708590: Pseudo dice [np.float32(0.7068)] 
2025-08-30 03:29:42.715836: Epoch time: 27.21 s 
2025-08-30 03:29:43.330006:  
2025-08-30 03:29:43.334180: Epoch 73 
2025-08-30 03:29:43.341383: Current learning rate: 0.00093 
2025-08-30 03:30:10.599153: train_loss -0.4255 
2025-08-30 03:30:10.607639: val_loss -0.4872 
2025-08-30 03:30:10.611796: Pseudo dice [np.float32(0.7032)] 
2025-08-30 03:30:10.619194: Epoch time: 27.27 s 
2025-08-30 03:30:11.241288:  
2025-08-30 03:30:11.245714: Epoch 74 
2025-08-30 03:30:11.253491: Current learning rate: 0.00093 
2025-08-30 03:30:38.084987: train_loss -0.4252 
2025-08-30 03:30:38.093111: val_loss -0.5068 
2025-08-30 03:30:38.101385: Pseudo dice [np.float32(0.6948)] 
2025-08-30 03:30:38.106419: Epoch time: 26.85 s 
2025-08-30 03:30:38.739578:  
2025-08-30 03:30:38.747892: Epoch 75 
2025-08-30 03:30:38.752257: Current learning rate: 0.00093 
2025-08-30 03:31:05.757921: train_loss -0.4672 
2025-08-30 03:31:05.762424: val_loss -0.4768 
2025-08-30 03:31:05.770762: Pseudo dice [np.float32(0.6319)] 
2025-08-30 03:31:05.776525: Epoch time: 27.02 s 
2025-08-30 03:31:06.546703:  
2025-08-30 03:31:06.550642: Epoch 76 
2025-08-30 03:31:06.558982: Current learning rate: 0.00093 
2025-08-30 03:31:32.963281: train_loss -0.4537 
2025-08-30 03:31:32.975788: val_loss -0.4516 
2025-08-30 03:31:32.981737: Pseudo dice [np.float32(0.7115)] 
2025-08-30 03:31:32.987899: Epoch time: 26.42 s 
2025-08-30 03:31:33.611001:  
2025-08-30 03:31:33.619310: Epoch 77 
2025-08-30 03:31:33.623493: Current learning rate: 0.00093 
2025-08-30 03:32:00.483618: train_loss -0.4303 
2025-08-30 03:32:00.487812: val_loss -0.4631 
2025-08-30 03:32:00.496542: Pseudo dice [np.float32(0.6942)] 
2025-08-30 03:32:00.502328: Epoch time: 26.87 s 
2025-08-30 03:32:01.138453:  
2025-08-30 03:32:01.142616: Epoch 78 
2025-08-30 03:32:01.150974: Current learning rate: 0.00093 
2025-08-30 03:32:27.961797: train_loss -0.4251 
2025-08-30 03:32:27.969417: val_loss -0.447 
2025-08-30 03:32:27.973913: Pseudo dice [np.float32(0.7097)] 
2025-08-30 03:32:27.981637: Epoch time: 26.83 s 
2025-08-30 03:32:28.615889:  
2025-08-30 03:32:28.624118: Epoch 79 
2025-08-30 03:32:28.628515: Current learning rate: 0.00093 
2025-08-30 03:32:55.960191: train_loss -0.4544 
2025-08-30 03:32:55.968524: val_loss -0.4943 
2025-08-30 03:32:55.972468: Pseudo dice [np.float32(0.714)] 
2025-08-30 03:32:55.980542: Epoch time: 27.35 s 
2025-08-30 03:32:56.635533:  
2025-08-30 03:32:56.643911: Epoch 80 
2025-08-30 03:32:56.648063: Current learning rate: 0.00093 
2025-08-30 03:33:23.012268: train_loss -0.4406 
2025-08-30 03:33:23.020223: val_loss -0.5135 
2025-08-30 03:33:23.024407: Pseudo dice [np.float32(0.6903)] 
2025-08-30 03:33:23.030360: Epoch time: 26.38 s 
2025-08-30 03:33:23.658442:  
2025-08-30 03:33:23.667459: Epoch 81 
2025-08-30 03:33:23.671418: Current learning rate: 0.00093 
2025-08-30 03:33:50.962441: train_loss -0.4683 
2025-08-30 03:33:50.969307: val_loss -0.5367 
2025-08-30 03:33:50.977312: Pseudo dice [np.float32(0.7383)] 
2025-08-30 03:33:50.982852: Epoch time: 27.3 s 
2025-08-30 03:33:51.607091:  
2025-08-30 03:33:51.611269: Epoch 82 
2025-08-30 03:33:51.617496: Current learning rate: 0.00093 
2025-08-30 03:34:18.497085: train_loss -0.4507 
2025-08-30 03:34:18.504806: val_loss -0.5099 
2025-08-30 03:34:18.509433: Pseudo dice [np.float32(0.6943)] 
2025-08-30 03:34:18.515191: Epoch time: 26.89 s 
2025-08-30 03:34:19.130885:  
2025-08-30 03:34:19.138761: Epoch 83 
2025-08-30 03:34:19.142944: Current learning rate: 0.00092 
2025-08-30 03:34:45.969783: train_loss -0.4468 
2025-08-30 03:34:45.978348: val_loss -0.5194 
2025-08-30 03:34:45.982447: Pseudo dice [np.float32(0.7628)] 
2025-08-30 03:34:45.989660: Epoch time: 26.84 s 
2025-08-30 03:34:45.995314: Yayy! New best EMA pseudo Dice: 0.7067999839782715 
2025-08-30 03:34:46.820560:  
2025-08-30 03:34:46.829318: Epoch 84 
2025-08-30 03:34:46.833065: Current learning rate: 0.00092 
2025-08-30 03:35:12.768824: train_loss -0.4577 
2025-08-30 03:35:12.775682: val_loss -0.5247 
2025-08-30 03:35:12.780144: Pseudo dice [np.float32(0.7773)] 
2025-08-30 03:35:12.787366: Epoch time: 25.95 s 
2025-08-30 03:35:12.792907: Yayy! New best EMA pseudo Dice: 0.7139000296592712 
2025-08-30 03:35:13.605974:  
2025-08-30 03:35:13.613984: Epoch 85 
2025-08-30 03:35:13.618486: Current learning rate: 0.00092 
2025-08-30 03:35:40.507928: train_loss -0.4724 
2025-08-30 03:35:40.516208: val_loss -0.5744 
2025-08-30 03:35:40.520021: Pseudo dice [np.float32(0.7584)] 
2025-08-30 03:35:40.526155: Epoch time: 26.91 s 
2025-08-30 03:35:40.529354: Yayy! New best EMA pseudo Dice: 0.7182999849319458 
2025-08-30 03:35:41.357626:  
2025-08-30 03:35:41.362574: Epoch 86 
2025-08-30 03:35:41.366708: Current learning rate: 0.00092 
2025-08-30 03:36:08.072838: train_loss -0.4701 
2025-08-30 03:36:08.076703: val_loss -0.437 
2025-08-30 03:36:08.085402: Pseudo dice [np.float32(0.5396)] 
2025-08-30 03:36:08.090020: Epoch time: 26.72 s 
2025-08-30 03:36:08.735754:  
2025-08-30 03:36:08.740233: Epoch 87 
2025-08-30 03:36:08.748338: Current learning rate: 0.00092 
2025-08-30 03:36:34.332483: train_loss -0.4442 
2025-08-30 03:36:34.344572: val_loss -0.5096 
2025-08-30 03:36:34.350322: Pseudo dice [np.float32(0.7125)] 
2025-08-30 03:36:34.355979: Epoch time: 25.6 s 
2025-08-30 03:36:34.970497:  
2025-08-30 03:36:34.978582: Epoch 88 
2025-08-30 03:36:34.982770: Current learning rate: 0.00092 
2025-08-30 03:37:00.274747: train_loss -0.4345 
2025-08-30 03:37:00.283329: val_loss -0.4663 
2025-08-30 03:37:00.287538: Pseudo dice [np.float32(0.6926)] 
2025-08-30 03:37:00.296374: Epoch time: 25.31 s 
2025-08-30 03:37:01.054617:  
2025-08-30 03:37:01.063159: Epoch 89 
2025-08-30 03:37:01.067335: Current learning rate: 0.00092 
2025-08-30 03:37:26.513508: train_loss -0.4514 
2025-08-30 03:37:26.521721: val_loss -0.4765 
2025-08-30 03:37:26.525846: Pseudo dice [np.float32(0.7416)] 
2025-08-30 03:37:26.533068: Epoch time: 25.46 s 
2025-08-30 03:37:27.147314:  
2025-08-30 03:37:27.155731: Epoch 90 
2025-08-30 03:37:27.164352: Current learning rate: 0.00092 
2025-08-30 03:37:52.576954: train_loss -0.4445 
2025-08-30 03:37:52.585313: val_loss -0.5305 
2025-08-30 03:37:52.593930: Pseudo dice [np.float32(0.714)] 
2025-08-30 03:37:52.598913: Epoch time: 25.43 s 
2025-08-30 03:37:53.202496:  
2025-08-30 03:37:53.206681: Epoch 91 
2025-08-30 03:37:53.215345: Current learning rate: 0.00092 
2025-08-30 03:38:18.657735: train_loss -0.4525 
2025-08-30 03:38:18.665458: val_loss -0.4155 
2025-08-30 03:38:18.674156: Pseudo dice [np.float32(0.6245)] 
2025-08-30 03:38:18.679381: Epoch time: 25.46 s 
2025-08-30 03:38:19.295241:  
2025-08-30 03:38:19.303679: Epoch 92 
2025-08-30 03:38:19.307760: Current learning rate: 0.00092 
2025-08-30 03:38:44.797216: train_loss -0.4592 
2025-08-30 03:38:44.804375: val_loss -0.5135 
2025-08-30 03:38:44.808458: Pseudo dice [np.float32(0.7217)] 
2025-08-30 03:38:44.817321: Epoch time: 25.51 s 
2025-08-30 03:38:45.425750:  
2025-08-30 03:38:45.429693: Epoch 93 
2025-08-30 03:38:45.438030: Current learning rate: 0.00092 
2025-08-30 03:39:11.251912: train_loss -0.4663 
2025-08-30 03:39:11.259602: val_loss -0.5069 
2025-08-30 03:39:11.264102: Pseudo dice [np.float32(0.7315)] 
2025-08-30 03:39:11.270913: Epoch time: 25.83 s 
2025-08-30 03:39:11.876921:  
2025-08-30 03:39:11.884878: Epoch 94 
2025-08-30 03:39:11.889455: Current learning rate: 0.00091 
2025-08-30 03:39:38.974930: train_loss -0.4678 
2025-08-30 03:39:38.983171: val_loss -0.4965 
2025-08-30 03:39:38.987684: Pseudo dice [np.float32(0.7291)] 
2025-08-30 03:39:38.993488: Epoch time: 27.1 s 
2025-08-30 03:39:39.604627:  
2025-08-30 03:39:39.608785: Epoch 95 
2025-08-30 03:39:39.612941: Current learning rate: 0.00091 
2025-08-30 03:40:06.452633: train_loss -0.46 
2025-08-30 03:40:06.460642: val_loss -0.5222 
2025-08-30 03:40:06.464804: Pseudo dice [np.float32(0.7548)] 
2025-08-30 03:40:06.473152: Epoch time: 26.85 s 
2025-08-30 03:40:07.278082:  
2025-08-30 03:40:07.286436: Epoch 96 
2025-08-30 03:40:07.290567: Current learning rate: 0.00091 
2025-08-30 03:40:34.138270: train_loss -0.4728 
2025-08-30 03:40:34.146899: val_loss -0.5389 
2025-08-30 03:40:34.151050: Pseudo dice [np.float32(0.7166)] 
2025-08-30 03:40:34.157409: Epoch time: 26.86 s 
2025-08-30 03:40:34.847563:  
2025-08-30 03:40:34.855628: Epoch 97 
2025-08-30 03:40:34.859796: Current learning rate: 0.00091 
2025-08-30 03:41:01.933030: train_loss -0.4379 
2025-08-30 03:41:01.941477: val_loss -0.4807 
2025-08-30 03:41:01.945640: Pseudo dice [np.float32(0.6766)] 
2025-08-30 03:41:01.955117: Epoch time: 27.09 s 
2025-08-30 03:41:02.599973:  
2025-08-30 03:41:02.604134: Epoch 98 
2025-08-30 03:41:02.612509: Current learning rate: 0.00091 
2025-08-30 03:41:29.940219: train_loss -0.4774 
2025-08-30 03:41:29.948153: val_loss -0.5716 
2025-08-30 03:41:29.952307: Pseudo dice [np.float32(0.7182)] 
2025-08-30 03:41:29.960562: Epoch time: 27.34 s 
2025-08-30 03:41:30.569574:  
2025-08-30 03:41:30.578268: Epoch 99 
2025-08-30 03:41:30.582449: Current learning rate: 0.00091 
2025-08-30 03:41:57.196821: train_loss -0.4493 
2025-08-30 03:41:57.204862: val_loss -0.5115 
2025-08-30 03:41:57.208972: Pseudo dice [np.float32(0.7178)] 
2025-08-30 03:41:57.214883: Epoch time: 26.63 s 
2025-08-30 03:41:58.030325:  
2025-08-30 03:41:58.039059: Epoch 100 
2025-08-30 03:41:58.047456: Current learning rate: 0.00091 
2025-08-30 03:42:24.523764: train_loss -0.4706 
2025-08-30 03:42:24.531711: val_loss -0.4879 
2025-08-30 03:42:24.536379: Pseudo dice [np.float32(0.6821)] 
2025-08-30 03:42:24.541543: Epoch time: 26.49 s 
2025-08-30 03:42:25.161570:  
2025-08-30 03:42:25.170147: Epoch 101 
2025-08-30 03:42:25.174748: Current learning rate: 0.00091 
2025-08-30 03:42:51.857665: train_loss -0.4888 
2025-08-30 03:42:51.863597: val_loss -0.5374 
2025-08-30 03:42:51.867725: Pseudo dice [np.float32(0.7398)] 
2025-08-30 03:42:51.874982: Epoch time: 26.7 s 
2025-08-30 03:42:52.639349:  
2025-08-30 03:42:52.647656: Epoch 102 
2025-08-30 03:42:52.656130: Current learning rate: 0.00091 
2025-08-30 03:43:19.903755: train_loss -0.4436 
2025-08-30 03:43:19.912095: val_loss -0.4486 
2025-08-30 03:43:19.916291: Pseudo dice [np.float32(0.7228)] 
2025-08-30 03:43:19.923478: Epoch time: 27.26 s 
2025-08-30 03:43:20.537702:  
2025-08-30 03:43:20.541904: Epoch 103 
2025-08-30 03:43:20.550264: Current learning rate: 0.00091 
2025-08-30 03:43:47.453972: train_loss -0.4527 
2025-08-30 03:43:47.464937: val_loss -0.5155 
2025-08-30 03:43:47.468775: Pseudo dice [np.float32(0.7744)] 
2025-08-30 03:43:47.474977: Epoch time: 26.92 s 
2025-08-30 03:43:48.102772:  
2025-08-30 03:43:48.111100: Epoch 104 
2025-08-30 03:43:48.115256: Current learning rate: 0.00091 
2025-08-30 03:44:14.981860: train_loss -0.466 
2025-08-30 03:44:14.988012: val_loss -0.511 
2025-08-30 03:44:14.992180: Pseudo dice [np.float32(0.7614)] 
2025-08-30 03:44:14.999229: Epoch time: 26.88 s 
2025-08-30 03:44:15.005248: Yayy! New best EMA pseudo Dice: 0.7221999764442444 
2025-08-30 03:44:15.817893:  
2025-08-30 03:44:15.822116: Epoch 105 
2025-08-30 03:44:15.830407: Current learning rate: 0.0009 
2025-08-30 03:44:42.653059: train_loss -0.457 
2025-08-30 03:44:42.665606: val_loss -0.5183 
2025-08-30 03:44:42.669715: Pseudo dice [np.float32(0.6894)] 
2025-08-30 03:44:42.675290: Epoch time: 26.84 s 
2025-08-30 03:44:43.295357:  
2025-08-30 03:44:43.299670: Epoch 106 
2025-08-30 03:44:43.307886: Current learning rate: 0.0009 
2025-08-30 03:45:10.372808: train_loss -0.4479 
2025-08-30 03:45:10.381070: val_loss -0.5561 
2025-08-30 03:45:10.384897: Pseudo dice [np.float32(0.7158)] 
2025-08-30 03:45:10.393249: Epoch time: 27.08 s 
2025-08-30 03:45:11.010547:  
2025-08-30 03:45:11.018874: Epoch 107 
2025-08-30 03:45:11.023075: Current learning rate: 0.0009 
2025-08-30 03:45:37.899973: train_loss -0.4693 
2025-08-30 03:45:37.908297: val_loss -0.596 
2025-08-30 03:45:37.912461: Pseudo dice [np.float32(0.7527)] 
2025-08-30 03:45:37.920855: Epoch time: 26.89 s 
2025-08-30 03:45:38.538046:  
2025-08-30 03:45:38.546399: Epoch 108 
2025-08-30 03:45:38.550567: Current learning rate: 0.0009 
2025-08-30 03:46:05.135792: train_loss -0.4704 
2025-08-30 03:46:05.143815: val_loss -0.4808 
2025-08-30 03:46:05.148010: Pseudo dice [np.float32(0.7314)] 
2025-08-30 03:46:05.155989: Epoch time: 26.6 s 
2025-08-30 03:46:05.160994: Yayy! New best EMA pseudo Dice: 0.7228999733924866 
2025-08-30 03:46:06.219823:  
2025-08-30 03:46:06.223969: Epoch 109 
2025-08-30 03:46:06.232854: Current learning rate: 0.0009 
2025-08-30 03:46:32.875634: train_loss -0.4623 
2025-08-30 03:46:32.883986: val_loss -0.369 
2025-08-30 03:46:32.888134: Pseudo dice [np.float32(0.6571)] 
2025-08-30 03:46:32.895320: Epoch time: 26.66 s 
2025-08-30 03:46:33.505386:  
2025-08-30 03:46:33.513789: Epoch 110 
2025-08-30 03:46:33.517954: Current learning rate: 0.0009 
2025-08-30 03:47:00.741135: train_loss -0.4637 
2025-08-30 03:47:00.749375: val_loss -0.5498 
2025-08-30 03:47:00.753540: Pseudo dice [np.float32(0.7537)] 
2025-08-30 03:47:00.760876: Epoch time: 27.24 s 
2025-08-30 03:47:01.374891:  
2025-08-30 03:47:01.383241: Epoch 111 
2025-08-30 03:47:01.391658: Current learning rate: 0.0009 
2025-08-30 03:47:28.577085: train_loss -0.4836 
2025-08-30 03:47:28.585723: val_loss -0.5074 
2025-08-30 03:47:28.589605: Pseudo dice [np.float32(0.72)] 
2025-08-30 03:47:28.597724: Epoch time: 27.2 s 
2025-08-30 03:47:29.219556:  
2025-08-30 03:47:29.227725: Epoch 112 
2025-08-30 03:47:29.232256: Current learning rate: 0.0009 
2025-08-30 03:47:56.355094: train_loss -0.5115 
2025-08-30 03:47:56.363244: val_loss -0.5461 
2025-08-30 03:47:56.367321: Pseudo dice [np.float32(0.7827)] 
2025-08-30 03:47:56.375137: Epoch time: 27.14 s 
2025-08-30 03:47:56.381261: Yayy! New best EMA pseudo Dice: 0.7263000011444092 
2025-08-30 03:47:57.210117:  
2025-08-30 03:47:57.218205: Epoch 113 
2025-08-30 03:47:57.222684: Current learning rate: 0.0009 
2025-08-30 03:48:23.423498: train_loss -0.4401 
2025-08-30 03:48:23.432180: val_loss -0.55 
2025-08-30 03:48:23.437773: Pseudo dice [np.float32(0.7418)] 
2025-08-30 03:48:23.444208: Epoch time: 26.21 s 
2025-08-30 03:48:23.450155: Yayy! New best EMA pseudo Dice: 0.7279000282287598 
2025-08-30 03:48:24.278544:  
2025-08-30 03:48:24.286751: Epoch 114 
2025-08-30 03:48:24.291440: Current learning rate: 0.0009 
2025-08-30 03:48:50.317271: train_loss -0.4776 
2025-08-30 03:48:50.325385: val_loss -0.4682 
2025-08-30 03:48:50.333729: Pseudo dice [np.float32(0.6659)] 
2025-08-30 03:48:50.337881: Epoch time: 26.04 s 
2025-08-30 03:48:51.101162:  
2025-08-30 03:48:51.109514: Epoch 115 
2025-08-30 03:48:51.113650: Current learning rate: 0.0009 
2025-08-30 03:49:16.576898: train_loss -0.4743 
2025-08-30 03:49:16.584947: val_loss -0.4859 
2025-08-30 03:49:16.589087: Pseudo dice [np.float32(0.6998)] 
2025-08-30 03:49:16.596221: Epoch time: 25.48 s 
2025-08-30 03:49:17.223404:  
2025-08-30 03:49:17.227222: Epoch 116 
2025-08-30 03:49:17.236347: Current learning rate: 0.00089 
2025-08-30 03:49:42.582108: train_loss -0.4963 
2025-08-30 03:49:42.590315: val_loss -0.4336 
2025-08-30 03:49:42.598401: Pseudo dice [np.float32(0.6809)] 
2025-08-30 03:49:42.603929: Epoch time: 25.36 s 
2025-08-30 03:49:43.232389:  
2025-08-30 03:49:43.240719: Epoch 117 
2025-08-30 03:49:43.244881: Current learning rate: 0.00089 
2025-08-30 03:50:08.599611: train_loss -0.4194 
2025-08-30 03:50:08.607697: val_loss -0.5142 
2025-08-30 03:50:08.616223: Pseudo dice [np.float32(0.6948)] 
2025-08-30 03:50:08.623751: Epoch time: 25.37 s 
2025-08-30 03:50:09.270875:  
2025-08-30 03:50:09.279557: Epoch 118 
2025-08-30 03:50:09.283387: Current learning rate: 0.00089 
2025-08-30 03:50:34.925635: train_loss -0.4871 
2025-08-30 03:50:34.929825: val_loss -0.5183 
2025-08-30 03:50:34.938172: Pseudo dice [np.float32(0.7769)] 
2025-08-30 03:50:34.944728: Epoch time: 25.65 s 
2025-08-30 03:50:35.564056:  
2025-08-30 03:50:35.572198: Epoch 119 
2025-08-30 03:50:35.576895: Current learning rate: 0.00089 
2025-08-30 03:51:02.857919: train_loss -0.4895 
2025-08-30 03:51:02.865809: val_loss -0.56 
2025-08-30 03:51:02.870486: Pseudo dice [np.float32(0.7551)] 
2025-08-30 03:51:02.875723: Epoch time: 27.3 s 
2025-08-30 03:51:03.499996:  
2025-08-30 03:51:03.508355: Epoch 120 
2025-08-30 03:51:03.512523: Current learning rate: 0.00089 
2025-08-30 03:51:30.435088: train_loss -0.5026 
2025-08-30 03:51:30.443910: val_loss -0.5804 
2025-08-30 03:51:30.447853: Pseudo dice [np.float32(0.7561)] 
2025-08-30 03:51:30.454975: Epoch time: 26.94 s 
2025-08-30 03:51:31.081701:  
2025-08-30 03:51:31.090093: Epoch 121 
2025-08-30 03:51:31.094230: Current learning rate: 0.00089 
2025-08-30 03:51:58.042377: train_loss -0.4663 
2025-08-30 03:51:58.050640: val_loss -0.4325 
2025-08-30 03:51:58.054476: Pseudo dice [np.float32(0.7082)] 
2025-08-30 03:51:58.060567: Epoch time: 26.96 s 
2025-08-30 03:51:58.850281:  
2025-08-30 03:51:58.855540: Epoch 122 
2025-08-30 03:51:58.859459: Current learning rate: 0.00089 
2025-08-30 03:52:25.782635: train_loss -0.5204 
2025-08-30 03:52:25.790518: val_loss -0.5809 
2025-08-30 03:52:25.794688: Pseudo dice [np.float32(0.7408)] 
2025-08-30 03:52:25.802951: Epoch time: 26.93 s 
2025-08-30 03:52:26.441156:  
2025-08-30 03:52:26.449513: Epoch 123 
2025-08-30 03:52:26.453712: Current learning rate: 0.00089 
2025-08-30 03:52:54.131487: train_loss -0.5129 
2025-08-30 03:52:54.139657: val_loss -0.4266 
2025-08-30 03:52:54.143817: Pseudo dice [np.float32(0.658)] 
2025-08-30 03:52:54.151023: Epoch time: 27.69 s 
2025-08-30 03:52:54.782273:  
2025-08-30 03:52:54.790303: Epoch 124 
2025-08-30 03:52:54.794512: Current learning rate: 0.00089 
2025-08-30 03:53:22.144301: train_loss -0.453 
2025-08-30 03:53:22.150949: val_loss -0.4783 
2025-08-30 03:53:22.155421: Pseudo dice [np.float32(0.6743)] 
2025-08-30 03:53:22.163548: Epoch time: 27.37 s 
2025-08-30 03:53:22.789078:  
2025-08-30 03:53:22.797416: Epoch 125 
2025-08-30 03:53:22.805814: Current learning rate: 0.00089 
2025-08-30 03:53:49.895315: train_loss -0.4884 
2025-08-30 03:53:49.903971: val_loss -0.5031 
2025-08-30 03:53:49.908078: Pseudo dice [np.float32(0.7229)] 
2025-08-30 03:53:49.916014: Epoch time: 27.11 s 
2025-08-30 03:53:50.550143:  
2025-08-30 03:53:50.554354: Epoch 126 
2025-08-30 03:53:50.562706: Current learning rate: 0.00089 
2025-08-30 03:54:17.343529: train_loss -0.4678 
2025-08-30 03:54:17.352237: val_loss -0.4811 
2025-08-30 03:54:17.356481: Pseudo dice [np.float32(0.6873)] 
2025-08-30 03:54:17.362260: Epoch time: 26.8 s 
2025-08-30 03:54:17.990046:  
2025-08-30 03:54:17.994215: Epoch 127 
2025-08-30 03:54:18.002571: Current learning rate: 0.00088 
2025-08-30 03:54:45.509223: train_loss -0.526 
2025-08-30 03:54:45.517527: val_loss -0.4967 
2025-08-30 03:54:45.521719: Pseudo dice [np.float32(0.7166)] 
2025-08-30 03:54:45.528789: Epoch time: 27.52 s 
2025-08-30 03:54:46.318484:  
2025-08-30 03:54:46.326981: Epoch 128 
2025-08-30 03:54:46.331111: Current learning rate: 0.00088 
2025-08-30 03:55:13.462802: train_loss -0.5148 
2025-08-30 03:55:13.470757: val_loss -0.5415 
2025-08-30 03:55:13.474930: Pseudo dice [np.float32(0.7594)] 
2025-08-30 03:55:13.480862: Epoch time: 27.14 s 
2025-08-30 03:55:14.104807:  
2025-08-30 03:55:14.112805: Epoch 129 
2025-08-30 03:55:14.117350: Current learning rate: 0.00088 
2025-08-30 03:55:40.773076: train_loss -0.5029 
2025-08-30 03:55:40.781058: val_loss -0.5145 
2025-08-30 03:55:40.785234: Pseudo dice [np.float32(0.7233)] 
2025-08-30 03:55:40.794409: Epoch time: 26.67 s 
2025-08-30 03:55:41.427596:  
2025-08-30 03:55:41.435954: Epoch 130 
2025-08-30 03:55:41.440122: Current learning rate: 0.00088 
2025-08-30 03:56:08.087569: train_loss -0.4794 
2025-08-30 03:56:08.096118: val_loss -0.568 
2025-08-30 03:56:08.104214: Pseudo dice [np.float32(0.7628)] 
2025-08-30 03:56:08.108452: Epoch time: 26.66 s 
2025-08-30 03:56:08.742368:  
2025-08-30 03:56:08.746833: Epoch 131 
2025-08-30 03:56:08.750668: Current learning rate: 0.00088 
2025-08-30 03:56:35.707078: train_loss -0.5056 
2025-08-30 03:56:35.719285: val_loss -0.5414 
2025-08-30 03:56:35.723456: Pseudo dice [np.float32(0.7523)] 
2025-08-30 03:56:35.731558: Epoch time: 26.97 s 
2025-08-30 03:56:36.361633:  
2025-08-30 03:56:36.366055: Epoch 132 
2025-08-30 03:56:36.374105: Current learning rate: 0.00088 
2025-08-30 03:57:03.263804: train_loss -0.5068 
2025-08-30 03:57:03.272125: val_loss -0.5827 
2025-08-30 03:57:03.275935: Pseudo dice [np.float32(0.7422)] 
2025-08-30 03:57:03.281988: Epoch time: 26.91 s 
2025-08-30 03:57:03.922444:  
2025-08-30 03:57:03.931092: Epoch 133 
2025-08-30 03:57:03.939092: Current learning rate: 0.00088 
2025-08-30 03:57:30.766192: train_loss -0.4909 
2025-08-30 03:57:30.778486: val_loss -0.5671 
2025-08-30 03:57:30.782859: Pseudo dice [np.float32(0.7561)] 
2025-08-30 03:57:30.787981: Epoch time: 26.84 s 
2025-08-30 03:57:30.791867: Yayy! New best EMA pseudo Dice: 0.730400025844574 
2025-08-30 03:57:31.838994:  
2025-08-30 03:57:31.848699: Epoch 134 
2025-08-30 03:57:31.854434: Current learning rate: 0.00088 
2025-08-30 03:57:57.859585: train_loss -0.5151 
2025-08-30 03:57:57.868021: val_loss -0.5074 
2025-08-30 03:57:57.872457: Pseudo dice [np.float32(0.6929)] 
2025-08-30 03:57:57.877909: Epoch time: 26.02 s 
2025-08-30 03:57:58.514813:  
2025-08-30 03:57:58.523044: Epoch 135 
2025-08-30 03:57:58.527071: Current learning rate: 0.00088 
2025-08-30 03:58:25.704195: train_loss -0.5027 
2025-08-30 03:58:25.712705: val_loss -0.5259 
2025-08-30 03:58:25.720433: Pseudo dice [np.float32(0.7654)] 
2025-08-30 03:58:25.726434: Epoch time: 27.19 s 
2025-08-30 03:58:25.730072: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2025-08-30 03:58:26.684309:  
2025-08-30 03:58:26.692869: Epoch 136 
2025-08-30 03:58:26.696991: Current learning rate: 0.00088 
2025-08-30 03:58:53.432610: train_loss -0.4875 
2025-08-30 03:58:53.440097: val_loss -0.5446 
2025-08-30 03:58:53.444583: Pseudo dice [np.float32(0.7603)] 
2025-08-30 03:58:53.452402: Epoch time: 26.75 s 
2025-08-30 03:58:53.457253: Yayy! New best EMA pseudo Dice: 0.7335000038146973 
2025-08-30 03:58:54.286623:  
2025-08-30 03:58:54.291293: Epoch 137 
2025-08-30 03:58:54.299735: Current learning rate: 0.00088 
2025-08-30 03:59:20.960011: train_loss -0.5106 
2025-08-30 03:59:20.967938: val_loss -0.6074 
2025-08-30 03:59:20.971753: Pseudo dice [np.float32(0.7673)] 
2025-08-30 03:59:20.978836: Epoch time: 26.68 s 
2025-08-30 03:59:20.984868: Yayy! New best EMA pseudo Dice: 0.7368999719619751 
2025-08-30 03:59:21.822947:  
2025-08-30 03:59:21.831004: Epoch 138 
2025-08-30 03:59:21.840525: Current learning rate: 0.00087 
2025-08-30 03:59:48.662201: train_loss -0.49 
2025-08-30 03:59:48.674779: val_loss -0.5187 
2025-08-30 03:59:48.678962: Pseudo dice [np.float32(0.7296)] 
2025-08-30 03:59:48.685788: Epoch time: 26.84 s 
2025-08-30 03:59:49.312580:  
2025-08-30 03:59:49.321068: Epoch 139 
2025-08-30 03:59:49.325112: Current learning rate: 0.00087 
2025-08-30 04:00:16.153048: train_loss -0.4865 
2025-08-30 04:00:16.160217: val_loss -0.5674 
2025-08-30 04:00:16.164684: Pseudo dice [np.float32(0.7432)] 
2025-08-30 04:00:16.171235: Epoch time: 26.84 s 
2025-08-30 04:00:16.960998:  
2025-08-30 04:00:16.969349: Epoch 140 
2025-08-30 04:00:16.973499: Current learning rate: 0.00087 
2025-08-30 04:00:43.583699: train_loss -0.5207 
2025-08-30 04:00:43.591847: val_loss -0.4795 
2025-08-30 04:00:43.596000: Pseudo dice [np.float32(0.6817)] 
2025-08-30 04:00:43.602141: Epoch time: 26.62 s 
2025-08-30 04:00:44.238286:  
2025-08-30 04:00:44.246365: Epoch 141 
2025-08-30 04:00:44.250824: Current learning rate: 0.00087 
2025-08-30 04:01:11.390658: train_loss -0.507 
2025-08-30 04:01:11.394566: val_loss -0.5294 
2025-08-30 04:01:11.403968: Pseudo dice [np.float32(0.705)] 
2025-08-30 04:01:11.408752: Epoch time: 27.16 s 
2025-08-30 04:01:12.036860:  
2025-08-30 04:01:12.045183: Epoch 142 
2025-08-30 04:01:12.049332: Current learning rate: 0.00087 
2025-08-30 04:01:39.239379: train_loss -0.5194 
2025-08-30 04:01:39.251515: val_loss -0.4748 
2025-08-30 04:01:39.255725: Pseudo dice [np.float32(0.6536)] 
2025-08-30 04:01:39.261824: Epoch time: 27.2 s 
2025-08-30 04:01:39.898248:  
2025-08-30 04:01:39.906441: Epoch 143 
2025-08-30 04:01:39.914503: Current learning rate: 0.00087 
2025-08-30 04:02:06.728755: train_loss -0.4937 
2025-08-30 04:02:06.733203: val_loss -0.5288 
2025-08-30 04:02:06.741548: Pseudo dice [np.float32(0.7584)] 
2025-08-30 04:02:06.746842: Epoch time: 26.83 s 
2025-08-30 04:02:07.388257:  
2025-08-30 04:02:07.396291: Epoch 144 
2025-08-30 04:02:07.400477: Current learning rate: 0.00087 
2025-08-30 04:02:34.377692: train_loss -0.5038 
2025-08-30 04:02:34.385893: val_loss -0.5156 
2025-08-30 04:02:34.393937: Pseudo dice [np.float32(0.7441)] 
2025-08-30 04:02:34.399058: Epoch time: 26.99 s 
2025-08-30 04:02:35.032209:  
2025-08-30 04:02:35.040574: Epoch 145 
2025-08-30 04:02:35.044744: Current learning rate: 0.00087 
2025-08-30 04:03:02.105098: train_loss -0.5055 
2025-08-30 04:03:02.113456: val_loss -0.5317 
2025-08-30 04:03:02.117630: Pseudo dice [np.float32(0.7657)] 
2025-08-30 04:03:02.123806: Epoch time: 27.07 s 
2025-08-30 04:03:02.910138:  
2025-08-30 04:03:02.918154: Epoch 146 
2025-08-30 04:03:02.921945: Current learning rate: 0.00087 
2025-08-30 04:03:29.774696: train_loss -0.533 
2025-08-30 04:03:29.782753: val_loss -0.492 
2025-08-30 04:03:29.791091: Pseudo dice [np.float32(0.7044)] 
2025-08-30 04:03:29.796074: Epoch time: 26.86 s 
2025-08-30 04:03:30.429210:  
2025-08-30 04:03:30.437579: Epoch 147 
2025-08-30 04:03:30.441966: Current learning rate: 0.00087 
2025-08-30 04:03:57.581315: train_loss -0.5147 
2025-08-30 04:03:57.589650: val_loss -0.5005 
2025-08-30 04:03:57.593811: Pseudo dice [np.float32(0.6853)] 
2025-08-30 04:03:57.601071: Epoch time: 27.15 s 
2025-08-30 04:03:58.240339:  
2025-08-30 04:03:58.248883: Epoch 148 
2025-08-30 04:03:58.252829: Current learning rate: 0.00087 
2025-08-30 04:04:25.013530: train_loss -0.498 
2025-08-30 04:04:25.021215: val_loss -0.4914 
2025-08-30 04:04:25.025731: Pseudo dice [np.float32(0.6984)] 
2025-08-30 04:04:25.031641: Epoch time: 26.77 s 
2025-08-30 04:04:25.663815:  
2025-08-30 04:04:25.672218: Epoch 149 
2025-08-30 04:04:25.676383: Current learning rate: 0.00086 
2025-08-30 04:04:52.528360: train_loss -0.5068 
2025-08-30 04:04:52.536504: val_loss -0.4374 
2025-08-30 04:04:52.540364: Pseudo dice [np.float32(0.6957)] 
2025-08-30 04:04:52.546556: Epoch time: 26.87 s 
2025-08-30 04:04:53.382939:  
2025-08-30 04:04:53.387312: Epoch 150 
2025-08-30 04:04:53.395465: Current learning rate: 0.00086 
2025-08-30 04:05:20.326431: train_loss -0.4853 
2025-08-30 04:05:20.334822: val_loss -0.5299 
2025-08-30 04:05:20.341218: Pseudo dice [np.float32(0.7679)] 
2025-08-30 04:05:20.345864: Epoch time: 26.95 s 
2025-08-30 04:05:20.981674:  
2025-08-30 04:05:20.989608: Epoch 151 
2025-08-30 04:05:20.997787: Current learning rate: 0.00086 
2025-08-30 04:05:47.653726: train_loss -0.5097 
2025-08-30 04:05:47.662086: val_loss -0.5324 
2025-08-30 04:05:47.670418: Pseudo dice [np.float32(0.7487)] 
2025-08-30 04:05:47.676658: Epoch time: 26.67 s 
2025-08-30 04:05:48.316891:  
2025-08-30 04:05:48.325247: Epoch 152 
2025-08-30 04:05:48.333878: Current learning rate: 0.00086 
2025-08-30 04:06:15.581662: train_loss -0.5119 
2025-08-30 04:06:15.589979: val_loss -0.5457 
2025-08-30 04:06:15.598310: Pseudo dice [np.float32(0.7097)] 
2025-08-30 04:06:15.603387: Epoch time: 27.26 s 
2025-08-30 04:06:16.232393:  
2025-08-30 04:06:16.240721: Epoch 153 
2025-08-30 04:06:16.245059: Current learning rate: 0.00086 
2025-08-30 04:06:43.205072: train_loss -0.5227 
2025-08-30 04:06:43.213868: val_loss -0.5443 
2025-08-30 04:06:43.221756: Pseudo dice [np.float32(0.7919)] 
2025-08-30 04:06:43.226590: Epoch time: 26.98 s 
2025-08-30 04:06:43.868481:  
2025-08-30 04:06:43.876891: Epoch 154 
2025-08-30 04:06:43.880734: Current learning rate: 0.00086 
2025-08-30 04:07:10.899806: train_loss -0.5149 
2025-08-30 04:07:10.908112: val_loss -0.5786 
2025-08-30 04:07:10.916446: Pseudo dice [np.float32(0.7634)] 
2025-08-30 04:07:10.924268: Epoch time: 27.04 s 
2025-08-30 04:07:11.595915:  
2025-08-30 04:07:11.600451: Epoch 155 
2025-08-30 04:07:11.608430: Current learning rate: 0.00086 
2025-08-30 04:07:38.443516: train_loss -0.4893 
2025-08-30 04:07:38.453858: val_loss -0.52 
2025-08-30 04:07:38.459021: Pseudo dice [np.float32(0.7034)] 
2025-08-30 04:07:38.464218: Epoch time: 26.85 s 
2025-08-30 04:07:39.169247:  
2025-08-30 04:07:39.177606: Epoch 156 
2025-08-30 04:07:39.182071: Current learning rate: 0.00086 
2025-08-30 04:08:05.958552: train_loss -0.4811 
2025-08-30 04:08:05.966852: val_loss -0.5411 
2025-08-30 04:08:05.971021: Pseudo dice [np.float32(0.7488)] 
2025-08-30 04:08:05.978195: Epoch time: 26.79 s 
2025-08-30 04:08:06.613375:  
2025-08-30 04:08:06.621724: Epoch 157 
2025-08-30 04:08:06.626216: Current learning rate: 0.00086 
2025-08-30 04:08:33.573650: train_loss -0.4736 
2025-08-30 04:08:33.581947: val_loss -0.4826 
2025-08-30 04:08:33.586072: Pseudo dice [np.float32(0.7239)] 
2025-08-30 04:08:33.594421: Epoch time: 26.96 s 
2025-08-30 04:08:34.378610:  
2025-08-30 04:08:34.383002: Epoch 158 
2025-08-30 04:08:34.391075: Current learning rate: 0.00086 
2025-08-30 04:09:01.485075: train_loss -0.5175 
2025-08-30 04:09:01.493197: val_loss -0.6036 
2025-08-30 04:09:01.497360: Pseudo dice [np.float32(0.7805)] 
2025-08-30 04:09:01.503531: Epoch time: 27.11 s 
2025-08-30 04:09:01.506631: Yayy! New best EMA pseudo Dice: 0.7369999885559082 
2025-08-30 04:09:02.360517:  
2025-08-30 04:09:02.364860: Epoch 159 
2025-08-30 04:09:02.373558: Current learning rate: 0.00086 
2025-08-30 04:09:29.175020: train_loss -0.4859 
2025-08-30 04:09:29.187492: val_loss -0.4478 
2025-08-30 04:09:29.191942: Pseudo dice [np.float32(0.7146)] 
2025-08-30 04:09:29.198804: Epoch time: 26.82 s 
2025-08-30 04:09:29.841332:  
2025-08-30 04:09:29.850535: Epoch 160 
2025-08-30 04:09:29.855080: Current learning rate: 0.00085 
2025-08-30 04:09:56.702910: train_loss -0.4872 
2025-08-30 04:09:56.711037: val_loss -0.6008 
2025-08-30 04:09:56.715029: Pseudo dice [np.float32(0.7988)] 
2025-08-30 04:09:56.721136: Epoch time: 26.86 s 
2025-08-30 04:09:56.724324: Yayy! New best EMA pseudo Dice: 0.7411999702453613 
2025-08-30 04:09:57.569963:  
2025-08-30 04:09:57.578311: Epoch 161 
2025-08-30 04:09:57.582482: Current learning rate: 0.00085 
2025-08-30 04:10:24.893493: train_loss -0.5531 
2025-08-30 04:10:24.901515: val_loss -0.5582 
2025-08-30 04:10:24.909464: Pseudo dice [np.float32(0.7834)] 
2025-08-30 04:10:24.913971: Epoch time: 27.33 s 
2025-08-30 04:10:24.919458: Yayy! New best EMA pseudo Dice: 0.7454000115394592 
2025-08-30 04:10:25.769014:  
2025-08-30 04:10:25.777602: Epoch 162 
2025-08-30 04:10:25.781770: Current learning rate: 0.00085 
2025-08-30 04:10:53.142235: train_loss -0.5311 
2025-08-30 04:10:53.150535: val_loss -0.5219 
2025-08-30 04:10:53.154729: Pseudo dice [np.float32(0.7137)] 
2025-08-30 04:10:53.162799: Epoch time: 27.38 s 
2025-08-30 04:10:53.812192:  
2025-08-30 04:10:53.818161: Epoch 163 
2025-08-30 04:10:53.826563: Current learning rate: 0.00085 
2025-08-30 04:11:21.291366: train_loss -0.516 
2025-08-30 04:11:21.299427: val_loss -0.5171 
2025-08-30 04:11:21.307781: Pseudo dice [np.float32(0.7641)] 
2025-08-30 04:11:21.312699: Epoch time: 27.48 s 
2025-08-30 04:11:22.113048:  
2025-08-30 04:11:22.121389: Epoch 164 
2025-08-30 04:11:22.125199: Current learning rate: 0.00085 
2025-08-30 04:11:49.369088: train_loss -0.5318 
2025-08-30 04:11:49.377435: val_loss -0.5732 
2025-08-30 04:11:49.381840: Pseudo dice [np.float32(0.7834)] 
2025-08-30 04:11:49.387831: Epoch time: 27.26 s 
2025-08-30 04:11:49.394122: Yayy! New best EMA pseudo Dice: 0.7483000159263611 
2025-08-30 04:11:50.232804:  
2025-08-30 04:11:50.241205: Epoch 165 
2025-08-30 04:11:50.245317: Current learning rate: 0.00085 
2025-08-30 04:12:17.276143: train_loss -0.5062 
2025-08-30 04:12:17.284855: val_loss -0.5402 
2025-08-30 04:12:17.288620: Pseudo dice [np.float32(0.6865)] 
2025-08-30 04:12:17.297076: Epoch time: 27.05 s 
2025-08-30 04:12:17.922643:  
2025-08-30 04:12:17.930957: Epoch 166 
2025-08-30 04:12:17.935107: Current learning rate: 0.00085 
2025-08-30 04:12:44.851731: train_loss -0.5128 
2025-08-30 04:12:44.862299: val_loss -0.4657 
2025-08-30 04:12:44.866526: Pseudo dice [np.float32(0.6897)] 
2025-08-30 04:12:44.873106: Epoch time: 26.93 s 
2025-08-30 04:12:45.512665:  
2025-08-30 04:12:45.520985: Epoch 167 
2025-08-30 04:12:45.525168: Current learning rate: 0.00085 
2025-08-30 04:13:12.453135: train_loss -0.4574 
2025-08-30 04:13:12.460401: val_loss -0.5386 
2025-08-30 04:13:12.464870: Pseudo dice [np.float32(0.7268)] 
2025-08-30 04:13:12.473693: Epoch time: 26.94 s 
2025-08-30 04:13:13.140233:  
2025-08-30 04:13:13.144452: Epoch 168 
2025-08-30 04:13:13.152800: Current learning rate: 0.00085 
2025-08-30 04:13:39.992336: train_loss -0.503 
2025-08-30 04:13:40.000485: val_loss -0.4665 
2025-08-30 04:13:40.009154: Pseudo dice [np.float32(0.7286)] 
2025-08-30 04:13:40.014285: Epoch time: 26.86 s 
2025-08-30 04:13:40.655329:  
2025-08-30 04:13:40.664119: Epoch 169 
2025-08-30 04:13:40.672493: Current learning rate: 0.00085 
2025-08-30 04:14:07.866206: train_loss -0.5207 
2025-08-30 04:14:07.874371: val_loss -0.6013 
2025-08-30 04:14:07.878584: Pseudo dice [np.float32(0.7561)] 
2025-08-30 04:14:07.886271: Epoch time: 27.21 s 
2025-08-30 04:14:08.675208:  
2025-08-30 04:14:08.683204: Epoch 170 
2025-08-30 04:14:08.687860: Current learning rate: 0.00085 
2025-08-30 04:14:35.785901: train_loss -0.4956 
2025-08-30 04:14:35.794020: val_loss -0.4694 
2025-08-30 04:14:35.798038: Pseudo dice [np.float32(0.6887)] 
2025-08-30 04:14:35.806234: Epoch time: 27.11 s 
2025-08-30 04:14:36.444311:  
2025-08-30 04:14:36.452647: Epoch 171 
2025-08-30 04:14:36.457132: Current learning rate: 0.00084 
2025-08-30 04:15:03.830063: train_loss -0.531 
2025-08-30 04:15:03.840492: val_loss -0.4629 
2025-08-30 04:15:03.847674: Pseudo dice [np.float32(0.6958)] 
2025-08-30 04:15:03.853901: Epoch time: 27.39 s 
2025-08-30 04:15:04.493458:  
2025-08-30 04:15:04.501535: Epoch 172 
2025-08-30 04:15:04.505648: Current learning rate: 0.00084 
2025-08-30 04:15:31.320423: train_loss -0.5153 
2025-08-30 04:15:31.328210: val_loss -0.6001 
2025-08-30 04:15:31.335191: Pseudo dice [np.float32(0.7895)] 
2025-08-30 04:15:31.341058: Epoch time: 26.83 s 
2025-08-30 04:15:31.979216:  
2025-08-30 04:15:31.987265: Epoch 173 
2025-08-30 04:15:31.991765: Current learning rate: 0.00084 
2025-08-30 04:15:58.926615: train_loss -0.495 
2025-08-30 04:15:58.935019: val_loss -0.5617 
2025-08-30 04:15:58.939123: Pseudo dice [np.float32(0.7927)] 
2025-08-30 04:15:58.946232: Epoch time: 26.95 s 
2025-08-30 04:15:59.585687:  
2025-08-30 04:15:59.590089: Epoch 174 
2025-08-30 04:15:59.598454: Current learning rate: 0.00084 
2025-08-30 04:16:26.779436: train_loss -0.5372 
2025-08-30 04:16:26.788171: val_loss -0.5168 
2025-08-30 04:16:26.791992: Pseudo dice [np.float32(0.7245)] 
2025-08-30 04:16:26.799172: Epoch time: 27.2 s 
2025-08-30 04:16:27.438921:  
2025-08-30 04:16:27.446876: Epoch 175 
2025-08-30 04:16:27.450982: Current learning rate: 0.00084 
2025-08-30 04:16:54.953821: train_loss -0.5027 
2025-08-30 04:16:54.962087: val_loss -0.5757 
2025-08-30 04:16:54.965933: Pseudo dice [np.float32(0.7533)] 
2025-08-30 04:16:54.974084: Epoch time: 27.52 s 
2025-08-30 04:16:55.616959:  
2025-08-30 04:16:55.621154: Epoch 176 
2025-08-30 04:16:55.629420: Current learning rate: 0.00084 
2025-08-30 04:17:22.848207: train_loss -0.5316 
2025-08-30 04:17:22.856268: val_loss -0.6324 
2025-08-30 04:17:22.860487: Pseudo dice [np.float32(0.7466)] 
2025-08-30 04:17:22.867921: Epoch time: 27.24 s 
2025-08-30 04:17:23.665626:  
2025-08-30 04:17:23.673743: Epoch 177 
2025-08-30 04:17:23.677902: Current learning rate: 0.00084 
2025-08-30 04:17:51.034836: train_loss -0.5038 
2025-08-30 04:17:51.047228: val_loss -0.5522 
2025-08-30 04:17:51.051407: Pseudo dice [np.float32(0.7312)] 
2025-08-30 04:17:51.057467: Epoch time: 27.37 s 
2025-08-30 04:17:51.751786:  
2025-08-30 04:17:51.760117: Epoch 178 
2025-08-30 04:17:51.764559: Current learning rate: 0.00084 
2025-08-30 04:18:18.620634: train_loss -0.4923 
2025-08-30 04:18:18.628707: val_loss -0.6002 
2025-08-30 04:18:18.633011: Pseudo dice [np.float32(0.7428)] 
2025-08-30 04:18:18.639973: Epoch time: 26.87 s 
2025-08-30 04:18:19.287608:  
2025-08-30 04:18:19.296004: Epoch 179 
2025-08-30 04:18:19.300360: Current learning rate: 0.00084 
2025-08-30 04:18:46.969458: train_loss -0.4919 
2025-08-30 04:18:46.981930: val_loss -0.5755 
2025-08-30 04:18:46.986103: Pseudo dice [np.float32(0.7348)] 
2025-08-30 04:18:46.993214: Epoch time: 27.68 s 
2025-08-30 04:18:47.624541:  
2025-08-30 04:18:47.633136: Epoch 180 
2025-08-30 04:18:47.641270: Current learning rate: 0.00084 
2025-08-30 04:19:14.471925: train_loss -0.5271 
2025-08-30 04:19:14.480237: val_loss -0.5058 
2025-08-30 04:19:14.489209: Pseudo dice [np.float32(0.7383)] 
2025-08-30 04:19:14.493971: Epoch time: 26.85 s 
2025-08-30 04:19:15.135363:  
2025-08-30 04:19:15.143407: Epoch 181 
2025-08-30 04:19:15.147961: Current learning rate: 0.00084 
2025-08-30 04:19:42.470975: train_loss -0.5011 
2025-08-30 04:19:42.482945: val_loss -0.4734 
2025-08-30 04:19:42.487689: Pseudo dice [np.float32(0.6499)] 
2025-08-30 04:19:42.493293: Epoch time: 27.34 s 
2025-08-30 04:19:43.125503:  
2025-08-30 04:19:43.133854: Epoch 182 
2025-08-30 04:19:43.142207: Current learning rate: 0.00083 
2025-08-30 04:20:10.790658: train_loss -0.5212 
2025-08-30 04:20:10.794833: val_loss -0.5529 
2025-08-30 04:20:10.803144: Pseudo dice [np.float32(0.7627)] 
2025-08-30 04:20:10.808762: Epoch time: 27.67 s 
2025-08-30 04:20:11.445741:  
2025-08-30 04:20:11.453833: Epoch 183 
2025-08-30 04:20:11.457996: Current learning rate: 0.00083 
2025-08-30 04:20:38.455781: train_loss -0.4923 
2025-08-30 04:20:38.465506: val_loss -0.5202 
2025-08-30 04:20:38.472539: Pseudo dice [np.float32(0.7427)] 
2025-08-30 04:20:38.477813: Epoch time: 27.01 s 
2025-08-30 04:20:39.106692:  
2025-08-30 04:20:39.114775: Epoch 184 
2025-08-30 04:20:39.118957: Current learning rate: 0.00083 
2025-08-30 04:21:06.646906: train_loss -0.5271 
2025-08-30 04:21:06.654759: val_loss -0.5383 
2025-08-30 04:21:06.663434: Pseudo dice [np.float32(0.7553)] 
2025-08-30 04:21:06.668571: Epoch time: 27.54 s 
2025-08-30 04:21:07.301225:  
2025-08-30 04:21:07.309610: Epoch 185 
2025-08-30 04:21:07.313729: Current learning rate: 0.00083 
2025-08-30 04:21:33.965349: train_loss -0.4945 
2025-08-30 04:21:33.974011: val_loss -0.5476 
2025-08-30 04:21:33.978199: Pseudo dice [np.float32(0.775)] 
2025-08-30 04:21:33.985049: Epoch time: 26.67 s 
2025-08-30 04:21:34.625092:  
2025-08-30 04:21:34.632720: Epoch 186 
2025-08-30 04:21:34.638271: Current learning rate: 0.00083 
2025-08-30 04:22:01.809832: train_loss -0.5351 
2025-08-30 04:22:01.818556: val_loss -0.5684 
2025-08-30 04:22:01.822304: Pseudo dice [np.float32(0.7841)] 
2025-08-30 04:22:01.830736: Epoch time: 27.19 s 
2025-08-30 04:22:02.460469:  
2025-08-30 04:22:02.468818: Epoch 187 
2025-08-30 04:22:02.472965: Current learning rate: 0.00083 
2025-08-30 04:22:29.929683: train_loss -0.5029 
2025-08-30 04:22:29.942111: val_loss -0.5864 
2025-08-30 04:22:29.946278: Pseudo dice [np.float32(0.7717)] 
2025-08-30 04:22:29.952391: Epoch time: 27.47 s 
2025-08-30 04:22:30.588565:  
2025-08-30 04:22:30.597239: Epoch 188 
2025-08-30 04:22:30.601409: Current learning rate: 0.00083 
2025-08-30 04:22:58.000301: train_loss -0.5229 
2025-08-30 04:22:58.007617: val_loss -0.5259 
2025-08-30 04:22:58.012239: Pseudo dice [np.float32(0.7399)] 
2025-08-30 04:22:58.021304: Epoch time: 27.41 s 
2025-08-30 04:22:58.654182:  
2025-08-30 04:22:58.662428: Epoch 189 
2025-08-30 04:22:58.670768: Current learning rate: 0.00083 
2025-08-30 04:23:25.748041: train_loss -0.5243 
2025-08-30 04:23:25.756432: val_loss -0.5922 
2025-08-30 04:23:25.764558: Pseudo dice [np.float32(0.7678)] 
2025-08-30 04:23:25.770037: Epoch time: 27.09 s 
2025-08-30 04:23:25.773740: Yayy! New best EMA pseudo Dice: 0.7490000128746033 
2025-08-30 04:23:26.611154:  
2025-08-30 04:23:26.623712: Epoch 190 
2025-08-30 04:23:26.627841: Current learning rate: 0.00083 
2025-08-30 04:23:54.251771: train_loss -0.5324 
2025-08-30 04:23:54.259923: val_loss -0.5278 
2025-08-30 04:23:54.264124: Pseudo dice [np.float32(0.7565)] 
2025-08-30 04:23:54.270257: Epoch time: 27.64 s 
2025-08-30 04:23:54.273126: Yayy! New best EMA pseudo Dice: 0.7497000098228455 
2025-08-30 04:23:55.122992:  
2025-08-30 04:23:55.131338: Epoch 191 
2025-08-30 04:23:55.135512: Current learning rate: 0.00083 
2025-08-30 04:24:22.121222: train_loss -0.5246 
2025-08-30 04:24:22.129122: val_loss -0.5443 
2025-08-30 04:24:22.137759: Pseudo dice [np.float32(0.7007)] 
2025-08-30 04:24:22.142924: Epoch time: 27.0 s 
2025-08-30 04:24:22.788409:  
2025-08-30 04:24:22.792296: Epoch 192 
2025-08-30 04:24:22.800857: Current learning rate: 0.00083 
2025-08-30 04:24:50.094699: train_loss -0.5255 
2025-08-30 04:24:50.103178: val_loss -0.6045 
2025-08-30 04:24:50.107118: Pseudo dice [np.float32(0.746)] 
2025-08-30 04:24:50.115190: Epoch time: 27.31 s 
2025-08-30 04:24:50.753257:  
2025-08-30 04:24:50.757770: Epoch 193 
2025-08-30 04:24:50.766318: Current learning rate: 0.00082 
2025-08-30 04:25:17.676527: train_loss -0.5087 
2025-08-30 04:25:17.684958: val_loss -0.5112 
2025-08-30 04:25:17.689076: Pseudo dice [np.float32(0.659)] 
2025-08-30 04:25:17.695191: Epoch time: 26.93 s 
2025-08-30 04:25:18.481726:  
2025-08-30 04:25:18.489593: Epoch 194 
2025-08-30 04:25:18.493731: Current learning rate: 0.00082 
2025-08-30 04:25:45.441561: train_loss -0.4954 
2025-08-30 04:25:45.449886: val_loss -0.593 
2025-08-30 04:25:45.458244: Pseudo dice [np.float32(0.7533)] 
2025-08-30 04:25:45.463579: Epoch time: 26.96 s 
2025-08-30 04:25:46.109000:  
2025-08-30 04:25:46.117170: Epoch 195 
2025-08-30 04:25:46.121612: Current learning rate: 0.00082 
2025-08-30 04:26:13.085740: train_loss -0.5026 
2025-08-30 04:26:13.094087: val_loss -0.5528 
2025-08-30 04:26:13.098278: Pseudo dice [np.float32(0.7338)] 
2025-08-30 04:26:13.105497: Epoch time: 26.98 s 
2025-08-30 04:26:13.740555:  
2025-08-30 04:26:13.748930: Epoch 196 
2025-08-30 04:26:13.753433: Current learning rate: 0.00082 
2025-08-30 04:26:40.588038: train_loss -0.5281 
2025-08-30 04:26:40.596852: val_loss -0.5422 
2025-08-30 04:26:40.601047: Pseudo dice [np.float32(0.7409)] 
2025-08-30 04:26:40.608853: Epoch time: 26.85 s 
2025-08-30 04:26:41.247174:  
2025-08-30 04:26:41.255921: Epoch 197 
2025-08-30 04:26:41.259995: Current learning rate: 0.00082 
2025-08-30 04:27:08.545280: train_loss -0.5327 
2025-08-30 04:27:08.553640: val_loss -0.5599 
2025-08-30 04:27:08.557781: Pseudo dice [np.float32(0.8082)] 
2025-08-30 04:27:08.565002: Epoch time: 27.3 s 
2025-08-30 04:27:09.204259:  
2025-08-30 04:27:09.213005: Epoch 198 
2025-08-30 04:27:09.217061: Current learning rate: 0.00082 
2025-08-30 04:27:36.060233: train_loss -0.5377 
2025-08-30 04:27:36.068578: val_loss -0.5712 
2025-08-30 04:27:36.076935: Pseudo dice [np.float32(0.7843)] 
2025-08-30 04:27:36.083152: Epoch time: 26.86 s 
2025-08-30 04:27:36.727575:  
2025-08-30 04:27:36.736253: Epoch 199 
2025-08-30 04:27:36.740078: Current learning rate: 0.00082 
2025-08-30 04:28:04.033859: train_loss -0.5464 
2025-08-30 04:28:04.042156: val_loss -0.5594 
2025-08-30 04:28:04.046842: Pseudo dice [np.float32(0.7305)] 
2025-08-30 04:28:04.052043: Epoch time: 27.31 s 
2025-08-30 04:28:04.959949:  
2025-08-30 04:28:04.968284: Epoch 200 
2025-08-30 04:28:04.976648: Current learning rate: 0.00082 
2025-08-30 04:28:32.395692: train_loss -0.5228 
2025-08-30 04:28:32.408187: val_loss -0.5399 
2025-08-30 04:28:32.412392: Pseudo dice [np.float32(0.7458)] 
2025-08-30 04:28:32.418622: Epoch time: 27.44 s 
2025-08-30 04:28:33.058863:  
2025-08-30 04:28:33.067480: Epoch 201 
2025-08-30 04:28:33.071604: Current learning rate: 0.00082 
2025-08-30 04:29:00.165516: train_loss -0.5319 
2025-08-30 04:29:00.173400: val_loss -0.5246 
2025-08-30 04:29:00.177620: Pseudo dice [np.float32(0.7297)] 
2025-08-30 04:29:00.183088: Epoch time: 27.11 s 
2025-08-30 04:29:00.832500:  
2025-08-30 04:29:00.839269: Epoch 202 
2025-08-30 04:29:00.846387: Current learning rate: 0.00082 
2025-08-30 04:29:27.771784: train_loss -0.5399 
2025-08-30 04:29:27.780148: val_loss -0.5563 
2025-08-30 04:29:27.784289: Pseudo dice [np.float32(0.7706)] 
2025-08-30 04:29:27.793516: Epoch time: 26.94 s 
2025-08-30 04:29:28.464180:  
2025-08-30 04:29:28.468638: Epoch 203 
2025-08-30 04:29:28.476670: Current learning rate: 0.00082 
2025-08-30 04:29:55.966886: train_loss -0.5014 
2025-08-30 04:29:55.975361: val_loss -0.5819 
2025-08-30 04:29:55.979120: Pseudo dice [np.float32(0.7544)] 
2025-08-30 04:29:55.985371: Epoch time: 27.51 s 
2025-08-30 04:29:56.629774:  
2025-08-30 04:29:56.638117: Epoch 204 
2025-08-30 04:29:56.646979: Current learning rate: 0.00081 
2025-08-30 04:30:23.411013: train_loss -0.5137 
2025-08-30 04:30:23.419344: val_loss -0.4631 
2025-08-30 04:30:23.427380: Pseudo dice [np.float32(0.6604)] 
2025-08-30 04:30:23.432673: Epoch time: 26.78 s 
2025-08-30 04:30:24.073878:  
2025-08-30 04:30:24.082201: Epoch 205 
2025-08-30 04:30:24.087486: Current learning rate: 0.00081 
2025-08-30 04:30:51.353864: train_loss -0.5186 
2025-08-30 04:30:51.359740: val_loss -0.5283 
2025-08-30 04:30:51.363927: Pseudo dice [np.float32(0.7937)] 
2025-08-30 04:30:51.371919: Epoch time: 27.28 s 
2025-08-30 04:30:52.131069:  
2025-08-30 04:30:52.139671: Epoch 206 
2025-08-30 04:30:52.143650: Current learning rate: 0.00081 
2025-08-30 04:31:19.370974: train_loss -0.5026 
2025-08-30 04:31:19.379101: val_loss -0.5361 
2025-08-30 04:31:19.383266: Pseudo dice [np.float32(0.7312)] 
2025-08-30 04:31:19.390608: Epoch time: 27.24 s 
2025-08-30 04:31:20.025611:  
2025-08-30 04:31:20.029797: Epoch 207 
2025-08-30 04:31:20.033957: Current learning rate: 0.00081 
2025-08-30 04:31:47.507564: train_loss -0.5092 
2025-08-30 04:31:47.519753: val_loss -0.4882 
2025-08-30 04:31:47.524183: Pseudo dice [np.float32(0.7033)] 
2025-08-30 04:31:47.531009: Epoch time: 27.49 s 
2025-08-30 04:31:48.157848:  
2025-08-30 04:31:48.162038: Epoch 208 
2025-08-30 04:31:48.166181: Current learning rate: 0.00081 
2025-08-30 04:32:15.080331: train_loss -0.551 
2025-08-30 04:32:15.084796: val_loss -0.583 
2025-08-30 04:32:15.093343: Pseudo dice [np.float32(0.7608)] 
2025-08-30 04:32:15.099449: Epoch time: 26.93 s 
2025-08-30 04:32:15.731475:  
2025-08-30 04:32:15.735402: Epoch 209 
2025-08-30 04:32:15.743405: Current learning rate: 0.00081 
2025-08-30 04:32:42.854060: train_loss -0.502 
2025-08-30 04:32:42.862211: val_loss -0.5118 
2025-08-30 04:32:42.867141: Pseudo dice [np.float32(0.7492)] 
2025-08-30 04:32:42.873901: Epoch time: 27.13 s 
2025-08-30 04:32:43.488066:  
2025-08-30 04:32:43.496797: Epoch 210 
2025-08-30 04:32:43.500932: Current learning rate: 0.00081 
2025-08-30 04:33:10.644408: train_loss -0.5225 
2025-08-30 04:33:10.652478: val_loss -0.5786 
2025-08-30 04:33:10.657249: Pseudo dice [np.float32(0.7651)] 
2025-08-30 04:33:10.663192: Epoch time: 27.16 s 
2025-08-30 04:33:11.286731:  
2025-08-30 04:33:11.295094: Epoch 211 
2025-08-30 04:33:11.299556: Current learning rate: 0.00081 
2025-08-30 04:33:38.614601: train_loss -0.5412 
2025-08-30 04:33:38.622588: val_loss -0.5751 
2025-08-30 04:33:38.630632: Pseudo dice [np.float32(0.7614)] 
2025-08-30 04:33:38.636179: Epoch time: 27.33 s 
2025-08-30 04:33:39.256046:  
2025-08-30 04:33:39.260753: Epoch 212 
2025-08-30 04:33:39.268904: Current learning rate: 0.00081 
2025-08-30 04:34:06.672230: train_loss -0.5619 
2025-08-30 04:34:06.679884: val_loss -0.5118 
2025-08-30 04:34:06.683730: Pseudo dice [np.float32(0.7385)] 
2025-08-30 04:34:06.690802: Epoch time: 27.42 s 
2025-08-30 04:34:07.459756:  
2025-08-30 04:34:07.468069: Epoch 213 
2025-08-30 04:34:07.472304: Current learning rate: 0.00081 
2025-08-30 04:34:34.123863: train_loss -0.5601 
2025-08-30 04:34:34.136393: val_loss -0.553 
2025-08-30 04:34:34.140521: Pseudo dice [np.float32(0.7557)] 
2025-08-30 04:34:34.148386: Epoch time: 26.66 s 
2025-08-30 04:34:34.770045:  
2025-08-30 04:34:34.778365: Epoch 214 
2025-08-30 04:34:34.782537: Current learning rate: 0.00081 
2025-08-30 04:35:01.793227: train_loss -0.5332 
2025-08-30 04:35:01.801529: val_loss -0.5606 
2025-08-30 04:35:01.805369: Pseudo dice [np.float32(0.7464)] 
2025-08-30 04:35:01.813530: Epoch time: 27.02 s 
2025-08-30 04:35:02.439361:  
2025-08-30 04:35:02.443541: Epoch 215 
2025-08-30 04:35:02.447680: Current learning rate: 0.0008 
2025-08-30 04:35:29.420428: train_loss -0.524 
2025-08-30 04:35:29.424594: val_loss -0.5009 
2025-08-30 04:35:29.433320: Pseudo dice [np.float32(0.6711)] 
2025-08-30 04:35:29.438394: Epoch time: 26.99 s 
2025-08-30 04:35:30.063087:  
2025-08-30 04:35:30.071080: Epoch 216 
2025-08-30 04:35:30.075292: Current learning rate: 0.0008 
2025-08-30 04:35:57.027460: train_loss -0.5209 
2025-08-30 04:35:57.035500: val_loss -0.5642 
2025-08-30 04:35:57.039996: Pseudo dice [np.float32(0.7212)] 
2025-08-30 04:35:57.045851: Epoch time: 26.96 s 
2025-08-30 04:35:57.661125:  
2025-08-30 04:35:57.669475: Epoch 217 
2025-08-30 04:35:57.677719: Current learning rate: 0.0008 
2025-08-30 04:36:24.237667: train_loss -0.5399 
2025-08-30 04:36:24.246024: val_loss -0.5452 
2025-08-30 04:36:24.250478: Pseudo dice [np.float32(0.7624)] 
2025-08-30 04:36:24.258289: Epoch time: 26.58 s 
2025-08-30 04:36:24.871700:  
2025-08-30 04:36:24.880040: Epoch 218 
2025-08-30 04:36:24.884230: Current learning rate: 0.0008 
2025-08-30 04:36:51.957685: train_loss -0.5553 
2025-08-30 04:36:51.965340: val_loss -0.4741 
2025-08-30 04:36:51.974040: Pseudo dice [np.float32(0.7305)] 
2025-08-30 04:36:51.978656: Epoch time: 27.09 s 
2025-08-30 04:36:52.603987:  
2025-08-30 04:36:52.612358: Epoch 219 
2025-08-30 04:36:52.624862: Current learning rate: 0.0008 
2025-08-30 04:37:19.730558: train_loss -0.5453 
2025-08-30 04:37:19.738927: val_loss -0.5933 
2025-08-30 04:37:19.747539: Pseudo dice [np.float32(0.7853)] 
2025-08-30 04:37:19.753508: Epoch time: 27.13 s 
2025-08-30 04:37:20.527204:  
2025-08-30 04:37:20.535584: Epoch 220 
2025-08-30 04:37:20.539728: Current learning rate: 0.0008 
2025-08-30 04:37:47.492151: train_loss -0.529 
2025-08-30 04:37:47.500059: val_loss -0.5374 
2025-08-30 04:37:47.504155: Pseudo dice [np.float32(0.7808)] 
2025-08-30 04:37:47.512316: Epoch time: 26.96 s 
2025-08-30 04:37:48.133934:  
2025-08-30 04:37:48.138330: Epoch 221 
2025-08-30 04:37:48.142304: Current learning rate: 0.0008 
2025-08-30 04:38:14.944145: train_loss -0.5449 
2025-08-30 04:38:14.952741: val_loss -0.5874 
2025-08-30 04:38:14.956860: Pseudo dice [np.float32(0.7616)] 
2025-08-30 04:38:14.963743: Epoch time: 26.81 s 
2025-08-30 04:38:15.582181:  
2025-08-30 04:38:15.590566: Epoch 222 
2025-08-30 04:38:15.594700: Current learning rate: 0.0008 
2025-08-30 04:38:42.271630: train_loss -0.5418 
2025-08-30 04:38:42.279689: val_loss -0.5328 
2025-08-30 04:38:42.283835: Pseudo dice [np.float32(0.7004)] 
2025-08-30 04:38:42.292494: Epoch time: 26.69 s 
2025-08-30 04:38:42.921981:  
2025-08-30 04:38:42.930708: Epoch 223 
2025-08-30 04:38:42.934509: Current learning rate: 0.0008 
2025-08-30 04:39:10.136985: train_loss -0.5282 
2025-08-30 04:39:10.145342: val_loss -0.5881 
2025-08-30 04:39:10.153701: Pseudo dice [np.float32(0.771)] 
2025-08-30 04:39:10.158769: Epoch time: 27.22 s 
2025-08-30 04:39:10.791477:  
2025-08-30 04:39:10.799869: Epoch 224 
2025-08-30 04:39:10.804001: Current learning rate: 0.0008 
2025-08-30 04:39:38.139945: train_loss -0.5484 
2025-08-30 04:39:38.148248: val_loss -0.5155 
2025-08-30 04:39:38.152422: Pseudo dice [np.float32(0.8055)] 
2025-08-30 04:39:38.158401: Epoch time: 27.35 s 
2025-08-30 04:39:38.165135: Yayy! New best EMA pseudo Dice: 0.7524999976158142 
2025-08-30 04:39:38.974118:  
2025-08-30 04:39:38.982518: Epoch 225 
2025-08-30 04:39:38.986660: Current learning rate: 0.0008 
2025-08-30 04:40:06.413945: train_loss -0.5315 
2025-08-30 04:40:06.422058: val_loss -0.6193 
2025-08-30 04:40:06.426216: Pseudo dice [np.float32(0.7763)] 
2025-08-30 04:40:06.431714: Epoch time: 27.44 s 
2025-08-30 04:40:06.435473: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2025-08-30 04:40:07.435546:  
2025-08-30 04:40:07.443889: Epoch 226 
2025-08-30 04:40:07.448092: Current learning rate: 0.00079 
2025-08-30 04:40:34.737890: train_loss -0.5535 
2025-08-30 04:40:34.746155: val_loss -0.6006 
2025-08-30 04:40:34.750563: Pseudo dice [np.float32(0.7573)] 
2025-08-30 04:40:34.755749: Epoch time: 27.31 s 
2025-08-30 04:40:34.759632: Yayy! New best EMA pseudo Dice: 0.7551000118255615 
2025-08-30 04:40:35.601464:  
2025-08-30 04:40:35.609925: Epoch 227 
2025-08-30 04:40:35.613990: Current learning rate: 0.00079 
2025-08-30 04:41:02.715503: train_loss -0.5523 
2025-08-30 04:41:02.719990: val_loss -0.6488 
2025-08-30 04:41:02.728339: Pseudo dice [np.float32(0.7635)] 
2025-08-30 04:41:02.733680: Epoch time: 27.12 s 
2025-08-30 04:41:02.737533: Yayy! New best EMA pseudo Dice: 0.7559000253677368 
2025-08-30 04:41:03.558243:  
2025-08-30 04:41:03.562638: Epoch 228 
2025-08-30 04:41:03.571208: Current learning rate: 0.00079 
2025-08-30 04:41:30.690260: train_loss -0.5094 
2025-08-30 04:41:30.697846: val_loss -0.5058 
2025-08-30 04:41:30.706203: Pseudo dice [np.float32(0.7593)] 
2025-08-30 04:41:30.710471: Epoch time: 27.14 s 
2025-08-30 04:41:30.715515: Yayy! New best EMA pseudo Dice: 0.7562999725341797 
2025-08-30 04:41:31.532036:  
2025-08-30 04:41:31.540748: Epoch 229 
2025-08-30 04:41:31.544532: Current learning rate: 0.00079 
2025-08-30 04:41:58.867630: train_loss -0.556 
2025-08-30 04:41:58.872027: val_loss -0.5965 
2025-08-30 04:41:58.880165: Pseudo dice [np.float32(0.7614)] 
2025-08-30 04:41:58.885595: Epoch time: 27.34 s 
2025-08-30 04:41:58.889362: Yayy! New best EMA pseudo Dice: 0.7567999958992004 
2025-08-30 04:41:59.706221:  
2025-08-30 04:41:59.714337: Epoch 230 
2025-08-30 04:41:59.718852: Current learning rate: 0.00079 
2025-08-30 04:42:26.829562: train_loss -0.5396 
2025-08-30 04:42:26.839495: val_loss -0.5463 
2025-08-30 04:42:26.845556: Pseudo dice [np.float32(0.7619)] 
2025-08-30 04:42:26.851296: Epoch time: 27.13 s 
2025-08-30 04:42:26.854884: Yayy! New best EMA pseudo Dice: 0.7573000192642212 
2025-08-30 04:42:27.667287:  
2025-08-30 04:42:27.675621: Epoch 231 
2025-08-30 04:42:27.683944: Current learning rate: 0.00079 
2025-08-30 04:42:55.211494: train_loss -0.5559 
2025-08-30 04:42:55.219764: val_loss -0.5594 
2025-08-30 04:42:55.228096: Pseudo dice [np.float32(0.8064)] 
2025-08-30 04:42:55.233602: Epoch time: 27.54 s 
2025-08-30 04:42:55.239285: Yayy! New best EMA pseudo Dice: 0.7621999979019165 
2025-08-30 04:42:56.312511:  
2025-08-30 04:42:56.320879: Epoch 232 
2025-08-30 04:42:56.325395: Current learning rate: 0.00079 
2025-08-30 04:43:22.755618: train_loss -0.5384 
2025-08-30 04:43:22.759728: val_loss -0.4839 
2025-08-30 04:43:22.768128: Pseudo dice [np.float32(0.7674)] 
2025-08-30 04:43:22.773095: Epoch time: 26.44 s 
2025-08-30 04:43:22.780457: Yayy! New best EMA pseudo Dice: 0.7627000212669373 
2025-08-30 04:43:23.594272:  
2025-08-30 04:43:23.602267: Epoch 233 
2025-08-30 04:43:23.606807: Current learning rate: 0.00079 
2025-08-30 04:43:50.133340: train_loss -0.53 
2025-08-30 04:43:50.145498: val_loss -0.5795 
2025-08-30 04:43:50.149894: Pseudo dice [np.float32(0.7549)] 
2025-08-30 04:43:50.155922: Epoch time: 26.54 s 
2025-08-30 04:43:50.762794:  
2025-08-30 04:43:50.771189: Epoch 234 
2025-08-30 04:43:50.775611: Current learning rate: 0.00079 
2025-08-30 04:44:17.055747: train_loss -0.5377 
2025-08-30 04:44:17.064368: val_loss -0.6559 
2025-08-30 04:44:17.068481: Pseudo dice [np.float32(0.8025)] 
2025-08-30 04:44:17.075452: Epoch time: 26.29 s 
2025-08-30 04:44:17.081227: Yayy! New best EMA pseudo Dice: 0.765999972820282 
2025-08-30 04:44:17.919019:  
2025-08-30 04:44:17.927346: Epoch 235 
2025-08-30 04:44:17.931523: Current learning rate: 0.00079 
2025-08-30 04:44:44.170517: train_loss -0.5368 
2025-08-30 04:44:44.182539: val_loss -0.5752 
2025-08-30 04:44:44.187337: Pseudo dice [np.float32(0.7456)] 
2025-08-30 04:44:44.193882: Epoch time: 26.26 s 
2025-08-30 04:44:44.879250:  
2025-08-30 04:44:44.887598: Epoch 236 
2025-08-30 04:44:44.892167: Current learning rate: 0.00078 
2025-08-30 04:45:10.984526: train_loss -0.5142 
2025-08-30 04:45:10.992872: val_loss -0.4956 
2025-08-30 04:45:10.997235: Pseudo dice [np.float32(0.7379)] 
2025-08-30 04:45:11.004117: Epoch time: 26.11 s 
2025-08-30 04:45:11.618606:  
2025-08-30 04:45:11.627218: Epoch 237 
2025-08-30 04:45:11.631034: Current learning rate: 0.00078 
2025-08-30 04:45:37.244382: train_loss -0.55 
2025-08-30 04:45:37.252476: val_loss -0.6339 
2025-08-30 04:45:37.256642: Pseudo dice [np.float32(0.8177)] 
2025-08-30 04:45:37.262833: Epoch time: 25.63 s 
2025-08-30 04:45:37.265855: Yayy! New best EMA pseudo Dice: 0.7670000195503235 
2025-08-30 04:45:38.078239:  
2025-08-30 04:45:38.090645: Epoch 238 
2025-08-30 04:45:38.095387: Current learning rate: 0.00078 
2025-08-30 04:46:05.326637: train_loss -0.5245 
2025-08-30 04:46:05.334635: val_loss -0.5458 
2025-08-30 04:46:05.340000: Pseudo dice [np.float32(0.769)] 
2025-08-30 04:46:05.344873: Epoch time: 27.25 s 
2025-08-30 04:46:05.351277: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-08-30 04:46:06.361044:  
2025-08-30 04:46:06.369329: Epoch 239 
2025-08-30 04:46:06.373106: Current learning rate: 0.00078 
2025-08-30 04:46:33.475743: train_loss -0.5479 
2025-08-30 04:46:33.487700: val_loss -0.6182 
2025-08-30 04:46:33.491863: Pseudo dice [np.float32(0.7758)] 
2025-08-30 04:46:33.498083: Epoch time: 27.11 s 
2025-08-30 04:46:33.504373: Yayy! New best EMA pseudo Dice: 0.7680000066757202 
2025-08-30 04:46:34.346161:  
2025-08-30 04:46:34.354641: Epoch 240 
2025-08-30 04:46:34.359495: Current learning rate: 0.00078 
2025-08-30 04:47:01.671044: train_loss -0.5278 
2025-08-30 04:47:01.678557: val_loss -0.5493 
2025-08-30 04:47:01.682927: Pseudo dice [np.float32(0.7793)] 
2025-08-30 04:47:01.691788: Epoch time: 27.33 s 
2025-08-30 04:47:01.698590: Yayy! New best EMA pseudo Dice: 0.7692000269889832 
2025-08-30 04:47:02.525082:  
2025-08-30 04:47:02.533405: Epoch 241 
2025-08-30 04:47:02.537528: Current learning rate: 0.00078 
2025-08-30 04:47:29.502490: train_loss -0.5433 
2025-08-30 04:47:29.510827: val_loss -0.5715 
2025-08-30 04:47:29.518655: Pseudo dice [np.float32(0.7358)] 
2025-08-30 04:47:29.524713: Epoch time: 26.98 s 
2025-08-30 04:47:30.177868:  
2025-08-30 04:47:30.186030: Epoch 242 
2025-08-30 04:47:30.190099: Current learning rate: 0.00078 
2025-08-30 04:47:57.438539: train_loss -0.5803 
2025-08-30 04:47:57.446881: val_loss -0.5574 
2025-08-30 04:47:57.454895: Pseudo dice [np.float32(0.7374)] 
2025-08-30 04:47:57.460344: Epoch time: 27.26 s 
2025-08-30 04:47:58.072193:  
2025-08-30 04:47:58.080550: Epoch 243 
2025-08-30 04:47:58.084957: Current learning rate: 0.00078 
2025-08-30 04:48:25.220678: train_loss -0.5174 
2025-08-30 04:48:25.228446: val_loss -0.5491 
2025-08-30 04:48:25.232839: Pseudo dice [np.float32(0.7973)] 
2025-08-30 04:48:25.240852: Epoch time: 27.15 s 
2025-08-30 04:48:25.879444:  
2025-08-30 04:48:25.887757: Epoch 244 
2025-08-30 04:48:25.896180: Current learning rate: 0.00078 
2025-08-30 04:48:52.964726: train_loss -0.5433 
2025-08-30 04:48:52.972808: val_loss -0.5511 
2025-08-30 04:48:52.977023: Pseudo dice [np.float32(0.8034)] 
2025-08-30 04:48:52.984120: Epoch time: 27.09 s 
2025-08-30 04:48:52.989876: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2025-08-30 04:48:53.969684:  
2025-08-30 04:48:53.977986: Epoch 245 
2025-08-30 04:48:53.986376: Current learning rate: 0.00078 
2025-08-30 04:49:21.138434: train_loss -0.5177 
2025-08-30 04:49:21.147119: val_loss -0.5442 
2025-08-30 04:49:21.155120: Pseudo dice [np.float32(0.6657)] 
2025-08-30 04:49:21.161288: Epoch time: 27.17 s 
2025-08-30 04:49:21.797700:  
2025-08-30 04:49:21.805761: Epoch 246 
2025-08-30 04:49:21.814151: Current learning rate: 0.00078 
2025-08-30 04:49:48.866564: train_loss -0.5006 
2025-08-30 04:49:48.874474: val_loss -0.5249 
2025-08-30 04:49:48.882859: Pseudo dice [np.float32(0.7534)] 
2025-08-30 04:49:48.887667: Epoch time: 27.07 s 
2025-08-30 04:49:49.500380:  
2025-08-30 04:49:49.508512: Epoch 247 
2025-08-30 04:49:49.512928: Current learning rate: 0.00077 
2025-08-30 04:50:16.985926: train_loss -0.5462 
2025-08-30 04:50:16.994257: val_loss -0.5624 
2025-08-30 04:50:16.998425: Pseudo dice [np.float32(0.7947)] 
2025-08-30 04:50:17.003810: Epoch time: 27.49 s 
2025-08-30 04:50:17.624338:  
2025-08-30 04:50:17.632191: Epoch 248 
2025-08-30 04:50:17.636623: Current learning rate: 0.00077 
2025-08-30 04:50:44.340361: train_loss -0.5123 
2025-08-30 04:50:44.347844: val_loss -0.5998 
2025-08-30 04:50:44.353131: Pseudo dice [np.float32(0.7958)] 
2025-08-30 04:50:44.358867: Epoch time: 26.72 s 
2025-08-30 04:50:44.989222:  
2025-08-30 04:50:44.997268: Epoch 249 
2025-08-30 04:50:45.001431: Current learning rate: 0.00077 
2025-08-30 04:51:12.145101: train_loss -0.5398 
2025-08-30 04:51:12.153471: val_loss -0.6144 
2025-08-30 04:51:12.157857: Pseudo dice [np.float32(0.7941)] 
2025-08-30 04:51:12.163919: Epoch time: 27.16 s 
2025-08-30 04:51:12.996043:  
2025-08-30 04:51:13.004613: Epoch 250 
2025-08-30 04:51:13.008585: Current learning rate: 0.00077 
2025-08-30 04:51:40.081341: train_loss -0.541 
2025-08-30 04:51:40.090005: val_loss -0.5947 
2025-08-30 04:51:40.098050: Pseudo dice [np.float32(0.7878)] 
2025-08-30 04:51:40.102306: Epoch time: 27.09 s 
2025-08-30 04:51:40.107303: Yayy! New best EMA pseudo Dice: 0.7706999778747559 
2025-08-30 04:51:40.986431:  
2025-08-30 04:51:40.994802: Epoch 251 
2025-08-30 04:51:40.999136: Current learning rate: 0.00077 
2025-08-30 04:52:08.021819: train_loss -0.5382 
2025-08-30 04:52:08.034042: val_loss -0.5631 
2025-08-30 04:52:08.038500: Pseudo dice [np.float32(0.8083)] 
2025-08-30 04:52:08.044048: Epoch time: 27.04 s 
2025-08-30 04:52:08.047709: Yayy! New best EMA pseudo Dice: 0.774399995803833 
2025-08-30 04:52:09.035219:  
2025-08-30 04:52:09.043604: Epoch 252 
2025-08-30 04:52:09.048154: Current learning rate: 0.00077 
2025-08-30 04:52:35.653493: train_loss -0.5199 
2025-08-30 04:52:35.666374: val_loss -0.5468 
2025-08-30 04:52:35.674474: Pseudo dice [np.float32(0.7995)] 
2025-08-30 04:52:35.679892: Epoch time: 26.62 s 
2025-08-30 04:52:35.683853: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-08-30 04:52:36.512821:  
2025-08-30 04:52:36.521408: Epoch 253 
2025-08-30 04:52:36.525812: Current learning rate: 0.00077 
2025-08-30 04:53:02.793949: train_loss -0.5212 
2025-08-30 04:53:02.801791: val_loss -0.5193 
2025-08-30 04:53:02.805604: Pseudo dice [np.float32(0.7586)] 
2025-08-30 04:53:02.811807: Epoch time: 26.29 s 
2025-08-30 04:53:03.439973:  
2025-08-30 04:53:03.448280: Epoch 254 
2025-08-30 04:53:03.452336: Current learning rate: 0.00077 
2025-08-30 04:53:30.375118: train_loss -0.5196 
2025-08-30 04:53:30.383252: val_loss -0.6176 
2025-08-30 04:53:30.387411: Pseudo dice [np.float32(0.837)] 
2025-08-30 04:53:30.396534: Epoch time: 26.94 s 
2025-08-30 04:53:30.402409: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-08-30 04:53:31.213151:  
2025-08-30 04:53:31.221542: Epoch 255 
2025-08-30 04:53:31.225667: Current learning rate: 0.00077 
2025-08-30 04:53:58.381998: train_loss -0.5507 
2025-08-30 04:53:58.390658: val_loss -0.5603 
2025-08-30 04:53:58.394438: Pseudo dice [np.float32(0.7703)] 
2025-08-30 04:53:58.402528: Epoch time: 27.17 s 
2025-08-30 04:53:59.011780:  
2025-08-30 04:53:59.015949: Epoch 256 
2025-08-30 04:53:59.024288: Current learning rate: 0.00077 
2025-08-30 04:54:25.826395: train_loss -0.567 
2025-08-30 04:54:25.834360: val_loss -0.5449 
2025-08-30 04:54:25.842741: Pseudo dice [np.float32(0.739)] 
2025-08-30 04:54:25.848852: Epoch time: 26.82 s 
2025-08-30 04:54:26.468321:  
2025-08-30 04:54:26.476722: Epoch 257 
2025-08-30 04:54:26.480835: Current learning rate: 0.00077 
2025-08-30 04:54:53.508125: train_loss -0.545 
2025-08-30 04:54:53.516205: val_loss -0.5692 
2025-08-30 04:54:53.520641: Pseudo dice [np.float32(0.7041)] 
2025-08-30 04:54:53.528394: Epoch time: 27.04 s 
2025-08-30 04:54:54.296527:  
2025-08-30 04:54:54.304409: Epoch 258 
2025-08-30 04:54:54.308630: Current learning rate: 0.00076 
2025-08-30 04:55:21.136451: train_loss -0.5697 
2025-08-30 04:55:21.144101: val_loss -0.5511 
2025-08-30 04:55:21.148256: Pseudo dice [np.float32(0.7044)] 
2025-08-30 04:55:21.156279: Epoch time: 26.84 s 
2025-08-30 04:55:21.761047:  
2025-08-30 04:55:21.765211: Epoch 259 
2025-08-30 04:55:21.773590: Current learning rate: 0.00076 
2025-08-30 04:55:48.546305: train_loss -0.5755 
2025-08-30 04:55:48.554569: val_loss -0.603 
2025-08-30 04:55:48.562916: Pseudo dice [np.float32(0.7881)] 
2025-08-30 04:55:48.567074: Epoch time: 26.79 s 
2025-08-30 04:55:49.172818:  
2025-08-30 04:55:49.180097: Epoch 260 
2025-08-30 04:55:49.184262: Current learning rate: 0.00076 
2025-08-30 04:56:15.986125: train_loss -0.5818 
2025-08-30 04:56:15.994213: val_loss -0.5717 
2025-08-30 04:56:15.998636: Pseudo dice [np.float32(0.7871)] 
2025-08-30 04:56:16.003482: Epoch time: 26.81 s 
2025-08-30 04:56:16.632868:  
2025-08-30 04:56:16.641182: Epoch 261 
2025-08-30 04:56:16.645344: Current learning rate: 0.00076 
2025-08-30 04:56:43.309157: train_loss -0.5158 
2025-08-30 04:56:43.317479: val_loss -0.6228 
2025-08-30 04:56:43.321652: Pseudo dice [np.float32(0.7568)] 
2025-08-30 04:56:43.328804: Epoch time: 26.68 s 
2025-08-30 04:56:43.934754:  
2025-08-30 04:56:43.943115: Epoch 262 
2025-08-30 04:56:43.947288: Current learning rate: 0.00076 
2025-08-30 04:57:11.020601: train_loss -0.5603 
2025-08-30 04:57:11.028509: val_loss -0.5845 
2025-08-30 04:57:11.032660: Pseudo dice [np.float32(0.7706)] 
2025-08-30 04:57:11.038168: Epoch time: 27.09 s 
2025-08-30 04:57:11.649933:  
2025-08-30 04:57:11.654288: Epoch 263 
2025-08-30 04:57:11.662718: Current learning rate: 0.00076 
2025-08-30 04:57:38.865252: train_loss -0.5994 
2025-08-30 04:57:38.873252: val_loss -0.5353 
2025-08-30 04:57:38.877398: Pseudo dice [np.float32(0.758)] 
2025-08-30 04:57:38.884306: Epoch time: 27.22 s 
2025-08-30 04:57:39.652897:  
2025-08-30 04:57:39.657107: Epoch 264 
2025-08-30 04:57:39.665458: Current learning rate: 0.00076 
2025-08-30 04:58:06.767830: train_loss -0.5272 
2025-08-30 04:58:06.775878: val_loss -0.5886 
2025-08-30 04:58:06.779999: Pseudo dice [np.float32(0.7759)] 
2025-08-30 04:58:06.785501: Epoch time: 27.12 s 
2025-08-30 04:58:07.405603:  
2025-08-30 04:58:07.413949: Epoch 265 
2025-08-30 04:58:07.418160: Current learning rate: 0.00076 
2025-08-30 04:58:34.591440: train_loss -0.5278 
2025-08-30 04:58:34.603621: val_loss -0.6185 
2025-08-30 04:58:34.608143: Pseudo dice [np.float32(0.7478)] 
2025-08-30 04:58:34.614992: Epoch time: 27.19 s 
2025-08-30 04:58:35.217029:  
2025-08-30 04:58:35.225057: Epoch 266 
2025-08-30 04:58:35.229234: Current learning rate: 0.00076 
2025-08-30 04:59:02.260812: train_loss -0.5256 
2025-08-30 04:59:02.268770: val_loss -0.6299 
2025-08-30 04:59:02.272929: Pseudo dice [np.float32(0.7789)] 
2025-08-30 04:59:02.279225: Epoch time: 27.04 s 
2025-08-30 04:59:02.890182:  
2025-08-30 04:59:02.898880: Epoch 267 
2025-08-30 04:59:02.902994: Current learning rate: 0.00076 
2025-08-30 04:59:29.575636: train_loss -0.5149 
2025-08-30 04:59:29.583782: val_loss -0.5826 
2025-08-30 04:59:29.587738: Pseudo dice [np.float32(0.7418)] 
2025-08-30 04:59:29.594792: Epoch time: 26.69 s 
2025-08-30 04:59:30.200779:  
2025-08-30 04:59:30.209985: Epoch 268 
2025-08-30 04:59:30.217582: Current learning rate: 0.00076 
2025-08-30 04:59:56.940000: train_loss -0.5462 
2025-08-30 04:59:56.944161: val_loss -0.5878 
2025-08-30 04:59:56.952845: Pseudo dice [np.float32(0.7732)] 
2025-08-30 04:59:56.958666: Epoch time: 26.74 s 
2025-08-30 04:59:57.578113:  
2025-08-30 04:59:57.586517: Epoch 269 
2025-08-30 04:59:57.590668: Current learning rate: 0.00075 
2025-08-30 05:00:24.596790: train_loss -0.5626 
2025-08-30 05:00:24.605114: val_loss -0.5486 
2025-08-30 05:00:24.613816: Pseudo dice [np.float32(0.7552)] 
2025-08-30 05:00:24.621751: Epoch time: 27.02 s 
2025-08-30 05:00:25.239107:  
2025-08-30 05:00:25.247452: Epoch 270 
2025-08-30 05:00:25.251606: Current learning rate: 0.00075 
2025-08-30 05:00:52.328722: train_loss -0.5617 
2025-08-30 05:00:52.339849: val_loss -0.593 
2025-08-30 05:00:52.345796: Pseudo dice [np.float32(0.7801)] 
2025-08-30 05:00:52.350820: Epoch time: 27.09 s 
2025-08-30 05:00:53.150575:  
2025-08-30 05:00:53.154495: Epoch 271 
2025-08-30 05:00:53.162803: Current learning rate: 0.00075 
2025-08-30 05:01:20.152616: train_loss -0.5576 
2025-08-30 05:01:20.156421: val_loss -0.5388 
2025-08-30 05:01:20.165249: Pseudo dice [np.float32(0.7658)] 
2025-08-30 05:01:20.170659: Epoch time: 27.01 s 
2025-08-30 05:01:20.798746:  
2025-08-30 05:01:20.807056: Epoch 272 
2025-08-30 05:01:20.815784: Current learning rate: 0.00075 
2025-08-30 05:01:47.776669: train_loss -0.5654 
2025-08-30 05:01:47.784009: val_loss -0.5657 
2025-08-30 05:01:47.788171: Pseudo dice [np.float32(0.8003)] 
2025-08-30 05:01:47.794409: Epoch time: 26.98 s 
2025-08-30 05:01:48.414126:  
2025-08-30 05:01:48.422460: Epoch 273 
2025-08-30 05:01:48.426610: Current learning rate: 0.00075 
2025-08-30 05:02:15.315759: train_loss -0.5382 
2025-08-30 05:02:15.324078: val_loss -0.5446 
2025-08-30 05:02:15.332163: Pseudo dice [np.float32(0.7614)] 
2025-08-30 05:02:15.336748: Epoch time: 26.9 s 
2025-08-30 05:02:15.949687:  
2025-08-30 05:02:15.958049: Epoch 274 
2025-08-30 05:02:15.962221: Current learning rate: 0.00075 
2025-08-30 05:02:42.515209: train_loss -0.5286 
2025-08-30 05:02:42.526527: val_loss -0.5751 
2025-08-30 05:02:42.530337: Pseudo dice [np.float32(0.7435)] 
2025-08-30 05:02:42.537550: Epoch time: 26.57 s 
2025-08-30 05:02:43.168548:  
2025-08-30 05:02:43.172641: Epoch 275 
2025-08-30 05:02:43.181002: Current learning rate: 0.00075 
2025-08-30 05:03:10.462604: train_loss -0.5243 
2025-08-30 05:03:10.470806: val_loss -0.5963 
2025-08-30 05:03:10.474974: Pseudo dice [np.float32(0.8067)] 
2025-08-30 05:03:10.483093: Epoch time: 27.3 s 
2025-08-30 05:03:11.100533:  
2025-08-30 05:03:11.109265: Epoch 276 
2025-08-30 05:03:11.113045: Current learning rate: 0.00075 
2025-08-30 05:03:38.302682: train_loss -0.5676 
2025-08-30 05:03:38.311086: val_loss -0.5767 
2025-08-30 05:03:38.315224: Pseudo dice [np.float32(0.7396)] 
2025-08-30 05:03:38.322583: Epoch time: 27.2 s 
2025-08-30 05:03:38.936671:  
2025-08-30 05:03:38.945397: Epoch 277 
2025-08-30 05:03:38.949485: Current learning rate: 0.00075 
2025-08-30 05:04:05.948046: train_loss -0.5544 
2025-08-30 05:04:05.955317: val_loss -0.5514 
2025-08-30 05:04:05.959511: Pseudo dice [np.float32(0.7665)] 
2025-08-30 05:04:05.966575: Epoch time: 27.02 s 
2025-08-30 05:04:06.735601:  
2025-08-30 05:04:06.743909: Epoch 278 
2025-08-30 05:04:06.748064: Current learning rate: 0.00075 
2025-08-30 05:04:33.416780: train_loss -0.5562 
2025-08-30 05:04:33.424745: val_loss -0.499 
2025-08-30 05:04:33.433181: Pseudo dice [np.float32(0.6874)] 
2025-08-30 05:04:33.439080: Epoch time: 26.69 s 
2025-08-30 05:04:34.050334:  
2025-08-30 05:04:34.058374: Epoch 279 
2025-08-30 05:04:34.062885: Current learning rate: 0.00074 
2025-08-30 05:05:00.739171: train_loss -0.537 
2025-08-30 05:05:00.747885: val_loss -0.5935 
2025-08-30 05:05:00.755971: Pseudo dice [np.float32(0.7686)] 
2025-08-30 05:05:00.762124: Epoch time: 26.69 s 
2025-08-30 05:05:01.373152:  
2025-08-30 05:05:01.377327: Epoch 280 
2025-08-30 05:05:01.386011: Current learning rate: 0.00074 
2025-08-30 05:05:27.967263: train_loss -0.574 
2025-08-30 05:05:27.975119: val_loss -0.5118 
2025-08-30 05:05:27.978867: Pseudo dice [np.float32(0.7156)] 
2025-08-30 05:05:27.987295: Epoch time: 26.6 s 
2025-08-30 05:05:28.600410:  
2025-08-30 05:05:28.608675: Epoch 281 
2025-08-30 05:05:28.613285: Current learning rate: 0.00074 
2025-08-30 05:05:55.377004: train_loss -0.5352 
2025-08-30 05:05:55.385753: val_loss -0.5953 
2025-08-30 05:05:55.393767: Pseudo dice [np.float32(0.7783)] 
2025-08-30 05:05:55.399130: Epoch time: 26.78 s 
2025-08-30 05:05:56.011049:  
2025-08-30 05:05:56.019401: Epoch 282 
2025-08-30 05:05:56.023960: Current learning rate: 0.00074 
2025-08-30 05:06:22.550292: train_loss -0.5596 
2025-08-30 05:06:22.558456: val_loss -0.6432 
2025-08-30 05:06:22.562624: Pseudo dice [np.float32(0.8139)] 
2025-08-30 05:06:22.571710: Epoch time: 26.54 s 
2025-08-30 05:06:23.175379:  
2025-08-30 05:06:23.179904: Epoch 283 
2025-08-30 05:06:23.188530: Current learning rate: 0.00074 
2025-08-30 05:06:50.153329: train_loss -0.5599 
2025-08-30 05:06:50.160936: val_loss -0.5817 
2025-08-30 05:06:50.165117: Pseudo dice [np.float32(0.8157)] 
2025-08-30 05:06:50.173220: Epoch time: 26.98 s 
2025-08-30 05:06:50.794924:  
2025-08-30 05:06:50.799467: Epoch 284 
2025-08-30 05:06:50.807454: Current learning rate: 0.00074 
2025-08-30 05:07:17.723197: train_loss -0.5551 
2025-08-30 05:07:17.730146: val_loss -0.4941 
2025-08-30 05:07:17.734607: Pseudo dice [np.float32(0.7439)] 
2025-08-30 05:07:17.741524: Epoch time: 26.93 s 
2025-08-30 05:07:18.510194:  
2025-08-30 05:07:18.518482: Epoch 285 
2025-08-30 05:07:18.522677: Current learning rate: 0.00074 
2025-08-30 05:07:45.353504: train_loss -0.5257 
2025-08-30 05:07:45.361991: val_loss -0.6196 
2025-08-30 05:07:45.366068: Pseudo dice [np.float32(0.8069)] 
2025-08-30 05:07:45.374146: Epoch time: 26.84 s 
2025-08-30 05:07:46.000369:  
2025-08-30 05:07:46.008435: Epoch 286 
2025-08-30 05:07:46.012575: Current learning rate: 0.00074 
2025-08-30 05:08:12.868657: train_loss -0.5622 
2025-08-30 05:08:12.877134: val_loss -0.4881 
2025-08-30 05:08:12.885859: Pseudo dice [np.float32(0.7728)] 
2025-08-30 05:08:12.891397: Epoch time: 26.87 s 
2025-08-30 05:08:13.506716:  
2025-08-30 05:08:13.510850: Epoch 287 
2025-08-30 05:08:13.519500: Current learning rate: 0.00074 
2025-08-30 05:08:40.441905: train_loss -0.5446 
2025-08-30 05:08:40.450255: val_loss -0.6404 
2025-08-30 05:08:40.458905: Pseudo dice [np.float32(0.8379)] 
2025-08-30 05:08:40.463982: Epoch time: 26.94 s 
2025-08-30 05:08:41.092536:  
2025-08-30 05:08:41.097054: Epoch 288 
2025-08-30 05:08:41.105077: Current learning rate: 0.00074 
2025-08-30 05:09:07.719219: train_loss -0.5656 
2025-08-30 05:09:07.727906: val_loss -0.6411 
2025-08-30 05:09:07.731985: Pseudo dice [np.float32(0.7936)] 
2025-08-30 05:09:07.737136: Epoch time: 26.63 s 
2025-08-30 05:09:08.353101:  
2025-08-30 05:09:08.361452: Epoch 289 
2025-08-30 05:09:08.365601: Current learning rate: 0.00074 
2025-08-30 05:09:35.496949: train_loss -0.5773 
2025-08-30 05:09:35.505933: val_loss -0.58 
2025-08-30 05:09:35.509406: Pseudo dice [np.float32(0.7614)] 
2025-08-30 05:09:35.517746: Epoch time: 27.14 s 
2025-08-30 05:09:36.151731:  
2025-08-30 05:09:36.161471: Epoch 290 
2025-08-30 05:09:36.164247: Current learning rate: 0.00073 
2025-08-30 05:10:03.045266: train_loss -0.5266 
2025-08-30 05:10:03.053895: val_loss -0.5904 
2025-08-30 05:10:03.057723: Pseudo dice [np.float32(0.778)] 
2025-08-30 05:10:03.066217: Epoch time: 26.89 s 
2025-08-30 05:10:03.691702:  
2025-08-30 05:10:03.700050: Epoch 291 
2025-08-30 05:10:03.704156: Current learning rate: 0.00073 
2025-08-30 05:10:31.019278: train_loss -0.5391 
2025-08-30 05:10:31.027643: val_loss -0.5342 
2025-08-30 05:10:31.035386: Pseudo dice [np.float32(0.6825)] 
2025-08-30 05:10:31.039915: Epoch time: 27.33 s 
2025-08-30 05:10:31.828460:  
2025-08-30 05:10:31.839613: Epoch 292 
2025-08-30 05:10:31.845297: Current learning rate: 0.00073 
2025-08-30 05:10:59.030304: train_loss -0.5552 
2025-08-30 05:10:59.038634: val_loss -0.539 
2025-08-30 05:10:59.047028: Pseudo dice [np.float32(0.7726)] 
2025-08-30 05:10:59.051186: Epoch time: 27.2 s 
2025-08-30 05:10:59.680743:  
2025-08-30 05:10:59.689658: Epoch 293 
2025-08-30 05:10:59.697776: Current learning rate: 0.00073 
2025-08-30 05:11:26.612483: train_loss -0.5627 
2025-08-30 05:11:26.620349: val_loss -0.5322 
2025-08-30 05:11:26.624718: Pseudo dice [np.float32(0.7309)] 
2025-08-30 05:11:26.633680: Epoch time: 26.93 s 
2025-08-30 05:11:27.279365:  
2025-08-30 05:11:27.287713: Epoch 294 
2025-08-30 05:11:27.291852: Current learning rate: 0.00073 
2025-08-30 05:11:54.223494: train_loss -0.5082 
2025-08-30 05:11:54.231247: val_loss -0.5211 
2025-08-30 05:11:54.235413: Pseudo dice [np.float32(0.7774)] 
2025-08-30 05:11:54.243620: Epoch time: 26.94 s 
2025-08-30 05:11:54.865272:  
2025-08-30 05:11:54.873656: Epoch 295 
2025-08-30 05:11:54.878016: Current learning rate: 0.00073 
2025-08-30 05:12:22.318036: train_loss -0.5647 
2025-08-30 05:12:22.322172: val_loss -0.5716 
2025-08-30 05:12:22.330441: Pseudo dice [np.float32(0.7954)] 
2025-08-30 05:12:22.335523: Epoch time: 27.46 s 
2025-08-30 05:12:22.964101:  
2025-08-30 05:12:22.972455: Epoch 296 
2025-08-30 05:12:22.976599: Current learning rate: 0.00073 
2025-08-30 05:12:49.976269: train_loss -0.5391 
2025-08-30 05:12:49.983058: val_loss -0.5797 
2025-08-30 05:12:49.991110: Pseudo dice [np.float32(0.7382)] 
2025-08-30 05:12:49.996608: Epoch time: 27.01 s 
2025-08-30 05:12:50.616721:  
2025-08-30 05:12:50.625186: Epoch 297 
2025-08-30 05:12:50.629394: Current learning rate: 0.00073 
2025-08-30 05:13:17.862071: train_loss -0.5382 
2025-08-30 05:13:17.869182: val_loss -0.6228 
2025-08-30 05:13:17.873140: Pseudo dice [np.float32(0.7957)] 
2025-08-30 05:13:17.881243: Epoch time: 27.25 s 
2025-08-30 05:13:18.532155:  
2025-08-30 05:13:18.540543: Epoch 298 
2025-08-30 05:13:18.544706: Current learning rate: 0.00073 
2025-08-30 05:13:45.446819: train_loss -0.5434 
2025-08-30 05:13:45.455156: val_loss -0.5962 
2025-08-30 05:13:45.458976: Pseudo dice [np.float32(0.7657)] 
2025-08-30 05:13:45.468090: Epoch time: 26.91 s 
2025-08-30 05:13:46.247280:  
2025-08-30 05:13:46.255662: Epoch 299 
2025-08-30 05:13:46.259789: Current learning rate: 0.00073 
2025-08-30 05:14:13.520599: train_loss -0.5359 
2025-08-30 05:14:13.528417: val_loss -0.5775 
2025-08-30 05:14:13.532928: Pseudo dice [np.float32(0.7741)] 
2025-08-30 05:14:13.537854: Epoch time: 27.28 s 
2025-08-30 05:14:14.371191:  
2025-08-30 05:14:14.379530: Epoch 300 
2025-08-30 05:14:14.383678: Current learning rate: 0.00073 
2025-08-30 05:14:41.594508: train_loss -0.5896 
2025-08-30 05:14:41.602547: val_loss -0.6498 
2025-08-30 05:14:41.606703: Pseudo dice [np.float32(0.8056)] 
2025-08-30 05:14:41.616196: Epoch time: 27.22 s 
2025-08-30 05:14:42.236506:  
2025-08-30 05:14:42.244862: Epoch 301 
2025-08-30 05:14:42.249012: Current learning rate: 0.00072 
2025-08-30 05:15:09.117516: train_loss -0.5892 
2025-08-30 05:15:09.125964: val_loss -0.5948 
2025-08-30 05:15:09.130371: Pseudo dice [np.float32(0.8057)] 
2025-08-30 05:15:09.135657: Epoch time: 26.88 s 
2025-08-30 05:15:09.797411:  
2025-08-30 05:15:09.805754: Epoch 302 
2025-08-30 05:15:09.809893: Current learning rate: 0.00072 
2025-08-30 05:15:37.304047: train_loss -0.5858 
2025-08-30 05:15:37.312354: val_loss -0.5692 
2025-08-30 05:15:37.316507: Pseudo dice [np.float32(0.7617)] 
2025-08-30 05:15:37.324925: Epoch time: 27.51 s 
2025-08-30 05:15:37.942544:  
2025-08-30 05:15:37.950781: Epoch 303 
2025-08-30 05:15:37.954643: Current learning rate: 0.00072 
2025-08-30 05:16:04.846415: train_loss -0.5522 
2025-08-30 05:16:04.852624: val_loss -0.5464 
2025-08-30 05:16:04.861334: Pseudo dice [np.float32(0.7372)] 
2025-08-30 05:16:04.866577: Epoch time: 26.9 s 
2025-08-30 05:16:05.477970:  
2025-08-30 05:16:05.486317: Epoch 304 
2025-08-30 05:16:05.490473: Current learning rate: 0.00072 
2025-08-30 05:16:32.717671: train_loss -0.5722 
2025-08-30 05:16:32.726368: val_loss -0.5814 
2025-08-30 05:16:32.730189: Pseudo dice [np.float32(0.7243)] 
2025-08-30 05:16:32.738614: Epoch time: 27.24 s 
2025-08-30 05:16:33.518451:  
2025-08-30 05:16:33.526856: Epoch 305 
2025-08-30 05:16:33.530985: Current learning rate: 0.00072 
2025-08-30 05:17:00.466310: train_loss -0.5672 
2025-08-30 05:17:00.474330: val_loss -0.5706 
2025-08-30 05:17:00.478806: Pseudo dice [np.float32(0.7923)] 
2025-08-30 05:17:00.483689: Epoch time: 26.95 s 
2025-08-30 05:17:01.125245:  
2025-08-30 05:17:01.133544: Epoch 306 
2025-08-30 05:17:01.138193: Current learning rate: 0.00072 
2025-08-30 05:17:27.897856: train_loss -0.5702 
2025-08-30 05:17:27.910380: val_loss -0.5215 
2025-08-30 05:17:27.914457: Pseudo dice [np.float32(0.7042)] 
2025-08-30 05:17:27.920055: Epoch time: 26.77 s 
2025-08-30 05:17:28.540143:  
2025-08-30 05:17:28.548486: Epoch 307 
2025-08-30 05:17:28.557225: Current learning rate: 0.00072 
2025-08-30 05:17:55.329891: train_loss -0.549 
2025-08-30 05:17:55.337692: val_loss -0.493 
2025-08-30 05:17:55.340639: Pseudo dice [np.float32(0.7224)] 
2025-08-30 05:17:55.347897: Epoch time: 26.79 s 
2025-08-30 05:17:55.967780:  
2025-08-30 05:17:55.976176: Epoch 308 
2025-08-30 05:17:55.980262: Current learning rate: 0.00072 
2025-08-30 05:18:23.036190: train_loss -0.5723 
2025-08-30 05:18:23.044516: val_loss -0.5578 
2025-08-30 05:18:23.048663: Pseudo dice [np.float32(0.7149)] 
2025-08-30 05:18:23.057061: Epoch time: 27.07 s 
2025-08-30 05:18:23.674347:  
2025-08-30 05:18:23.683019: Epoch 309 
2025-08-30 05:18:23.686821: Current learning rate: 0.00072 
2025-08-30 05:18:50.584476: train_loss -0.5685 
2025-08-30 05:18:50.592889: val_loss -0.6174 
2025-08-30 05:18:50.597023: Pseudo dice [np.float32(0.8174)] 
2025-08-30 05:18:50.604146: Epoch time: 26.91 s 
2025-08-30 05:18:51.222687:  
2025-08-30 05:18:51.231036: Epoch 310 
2025-08-30 05:18:51.235170: Current learning rate: 0.00072 
2025-08-30 05:19:18.228788: train_loss -0.5544 
2025-08-30 05:19:18.237124: val_loss -0.556 
2025-08-30 05:19:18.241211: Pseudo dice [np.float32(0.7275)] 
2025-08-30 05:19:18.247427: Epoch time: 27.01 s 
2025-08-30 05:19:18.871148:  
2025-08-30 05:19:18.879803: Epoch 311 
2025-08-30 05:19:18.883761: Current learning rate: 0.00072 
2025-08-30 05:19:45.969712: train_loss -0.5496 
2025-08-30 05:19:45.977310: val_loss -0.5372 
2025-08-30 05:19:45.981861: Pseudo dice [np.float32(0.803)] 
2025-08-30 05:19:45.987719: Epoch time: 27.1 s 
2025-08-30 05:19:46.769801:  
2025-08-30 05:19:46.778497: Epoch 312 
2025-08-30 05:19:46.782277: Current learning rate: 0.00071 
2025-08-30 05:20:13.588217: train_loss -0.5415 
2025-08-30 05:20:13.596961: val_loss -0.625 
2025-08-30 05:20:13.600761: Pseudo dice [np.float32(0.7807)] 
2025-08-30 05:20:13.608903: Epoch time: 26.82 s 
2025-08-30 05:20:14.239206:  
2025-08-30 05:20:14.247251: Epoch 313 
2025-08-30 05:20:14.251766: Current learning rate: 0.00071 
2025-08-30 05:20:41.483200: train_loss -0.5784 
2025-08-30 05:20:41.491393: val_loss -0.5375 
2025-08-30 05:20:41.501177: Pseudo dice [np.float32(0.7697)] 
2025-08-30 05:20:41.505754: Epoch time: 27.24 s 
2025-08-30 05:20:42.133784:  
2025-08-30 05:20:42.141732: Epoch 314 
2025-08-30 05:20:42.145917: Current learning rate: 0.00071 
2025-08-30 05:21:08.872658: train_loss -0.5458 
2025-08-30 05:21:08.877101: val_loss -0.6435 
2025-08-30 05:21:08.885110: Pseudo dice [np.float32(0.76)] 
2025-08-30 05:21:08.890429: Epoch time: 26.74 s 
2025-08-30 05:21:09.510774:  
2025-08-30 05:21:09.519081: Epoch 315 
2025-08-30 05:21:09.523278: Current learning rate: 0.00071 
2025-08-30 05:21:36.158181: train_loss -0.5605 
2025-08-30 05:21:36.167029: val_loss -0.5845 
2025-08-30 05:21:36.170949: Pseudo dice [np.float32(0.7612)] 
2025-08-30 05:21:36.180133: Epoch time: 26.65 s 
2025-08-30 05:21:36.813313:  
2025-08-30 05:21:36.821338: Epoch 316 
2025-08-30 05:21:36.825828: Current learning rate: 0.00071 
2025-08-30 05:22:03.815391: train_loss -0.5475 
2025-08-30 05:22:03.823344: val_loss -0.5639 
2025-08-30 05:22:03.831640: Pseudo dice [np.float32(0.7011)] 
2025-08-30 05:22:03.839241: Epoch time: 27.0 s 
2025-08-30 05:22:04.461433:  
2025-08-30 05:22:04.470149: Epoch 317 
2025-08-30 05:22:04.478278: Current learning rate: 0.00071 
2025-08-30 05:22:31.434192: train_loss -0.5425 
2025-08-30 05:22:31.446745: val_loss -0.5016 
2025-08-30 05:22:31.451287: Pseudo dice [np.float32(0.7122)] 
2025-08-30 05:22:31.456351: Epoch time: 26.97 s 
2025-08-30 05:22:32.243340:  
2025-08-30 05:22:32.247833: Epoch 318 
2025-08-30 05:22:32.255547: Current learning rate: 0.00071 
2025-08-30 05:22:59.036750: train_loss -0.5417 
2025-08-30 05:22:59.045099: val_loss -0.5552 
2025-08-30 05:22:59.053813: Pseudo dice [np.float32(0.7588)] 
2025-08-30 05:22:59.058996: Epoch time: 26.8 s 
2025-08-30 05:22:59.679331:  
2025-08-30 05:22:59.687784: Epoch 319 
2025-08-30 05:22:59.695480: Current learning rate: 0.00071 
2025-08-30 05:23:26.505874: train_loss -0.5555 
2025-08-30 05:23:26.514205: val_loss -0.5725 
2025-08-30 05:23:26.522596: Pseudo dice [np.float32(0.7536)] 
2025-08-30 05:23:26.526822: Epoch time: 26.83 s 
2025-08-30 05:23:27.148245:  
2025-08-30 05:23:27.156594: Epoch 320 
2025-08-30 05:23:27.160764: Current learning rate: 0.00071 
2025-08-30 05:23:54.676023: train_loss -0.5508 
2025-08-30 05:23:54.684343: val_loss -0.601 
2025-08-30 05:23:54.688435: Pseudo dice [np.float32(0.7981)] 
2025-08-30 05:23:54.696572: Epoch time: 27.53 s 
2025-08-30 05:23:55.317971:  
2025-08-30 05:23:55.322143: Epoch 321 
2025-08-30 05:23:55.330488: Current learning rate: 0.00071 
2025-08-30 05:24:22.057806: train_loss -0.529 
2025-08-30 05:24:22.065902: val_loss -0.5233 
2025-08-30 05:24:22.069940: Pseudo dice [np.float32(0.7626)] 
2025-08-30 05:24:22.078123: Epoch time: 26.74 s 
2025-08-30 05:24:22.703599:  
2025-08-30 05:24:22.708065: Epoch 322 
2025-08-30 05:24:22.716176: Current learning rate: 0.0007 
2025-08-30 05:24:49.739313: train_loss -0.5792 
2025-08-30 05:24:49.747650: val_loss -0.5612 
2025-08-30 05:24:49.756602: Pseudo dice [np.float32(0.7622)] 
2025-08-30 05:24:49.761118: Epoch time: 27.04 s 
2025-08-30 05:24:50.389438:  
2025-08-30 05:24:50.396788: Epoch 323 
2025-08-30 05:24:50.403141: Current learning rate: 0.0007 
2025-08-30 05:25:17.224738: train_loss -0.5496 
2025-08-30 05:25:17.233445: val_loss -0.6281 
2025-08-30 05:25:17.237619: Pseudo dice [np.float32(0.8376)] 
2025-08-30 05:25:17.242836: Epoch time: 26.84 s 
2025-08-30 05:25:17.883727:  
2025-08-30 05:25:17.888175: Epoch 324 
2025-08-30 05:25:17.892094: Current learning rate: 0.0007 
2025-08-30 05:25:44.431096: train_loss -0.5384 
2025-08-30 05:25:44.443609: val_loss -0.5269 
2025-08-30 05:25:44.447798: Pseudo dice [np.float32(0.7544)] 
2025-08-30 05:25:44.457302: Epoch time: 26.55 s 
2025-08-30 05:25:45.244397:  
2025-08-30 05:25:45.253079: Epoch 325 
2025-08-30 05:25:45.261199: Current learning rate: 0.0007 
2025-08-30 05:26:12.130074: train_loss -0.5282 
2025-08-30 05:26:12.137938: val_loss -0.6145 
2025-08-30 05:26:12.142115: Pseudo dice [np.float32(0.771)] 
2025-08-30 05:26:12.148260: Epoch time: 26.89 s 
2025-08-30 05:26:12.772195:  
2025-08-30 05:26:12.780240: Epoch 326 
2025-08-30 05:26:12.784439: Current learning rate: 0.0007 
2025-08-30 05:26:39.987124: train_loss -0.5536 
2025-08-30 05:26:39.995287: val_loss -0.5816 
2025-08-30 05:26:39.999114: Pseudo dice [np.float32(0.7583)] 
2025-08-30 05:26:40.004562: Epoch time: 27.22 s 
2025-08-30 05:26:40.633315:  
2025-08-30 05:26:40.641365: Epoch 327 
2025-08-30 05:26:40.645833: Current learning rate: 0.0007 
2025-08-30 05:27:07.802186: train_loss -0.6044 
2025-08-30 05:27:07.810175: val_loss -0.5822 
2025-08-30 05:27:07.814688: Pseudo dice [np.float32(0.7237)] 
2025-08-30 05:27:07.820623: Epoch time: 27.17 s 
2025-08-30 05:27:08.477512:  
2025-08-30 05:27:08.481715: Epoch 328 
2025-08-30 05:27:08.490060: Current learning rate: 0.0007 
2025-08-30 05:27:35.491983: train_loss -0.59 
2025-08-30 05:27:35.500373: val_loss -0.594 
2025-08-30 05:27:35.508665: Pseudo dice [np.float32(0.7802)] 
2025-08-30 05:27:35.514035: Epoch time: 27.02 s 
2025-08-30 05:27:36.134272:  
2025-08-30 05:27:36.142681: Epoch 329 
2025-08-30 05:27:36.146804: Current learning rate: 0.0007 
2025-08-30 05:28:02.961368: train_loss -0.5533 
2025-08-30 05:28:02.969727: val_loss -0.603 
2025-08-30 05:28:02.973663: Pseudo dice [np.float32(0.7762)] 
2025-08-30 05:28:02.980732: Epoch time: 26.83 s 
2025-08-30 05:28:03.599215:  
2025-08-30 05:28:03.607601: Epoch 330 
2025-08-30 05:28:03.611667: Current learning rate: 0.0007 
2025-08-30 05:28:30.584505: train_loss -0.5541 
2025-08-30 05:28:30.597295: val_loss -0.533 
2025-08-30 05:28:30.601461: Pseudo dice [np.float32(0.7842)] 
2025-08-30 05:28:30.608961: Epoch time: 26.99 s 
2025-08-30 05:28:31.230965:  
2025-08-30 05:28:31.239360: Epoch 331 
2025-08-30 05:28:31.243525: Current learning rate: 0.0007 
2025-08-30 05:28:58.399896: train_loss -0.5316 
2025-08-30 05:28:58.408181: val_loss -0.5761 
2025-08-30 05:28:58.412356: Pseudo dice [np.float32(0.79)] 
2025-08-30 05:28:58.420389: Epoch time: 27.17 s 
2025-08-30 05:28:59.042081:  
2025-08-30 05:28:59.050417: Epoch 332 
2025-08-30 05:28:59.054932: Current learning rate: 0.0007 
2025-08-30 05:29:26.015211: train_loss -0.5516 
2025-08-30 05:29:26.023194: val_loss -0.6625 
2025-08-30 05:29:26.031542: Pseudo dice [np.float32(0.7971)] 
2025-08-30 05:29:26.036909: Epoch time: 26.98 s 
2025-08-30 05:29:26.665537:  
2025-08-30 05:29:26.670085: Epoch 333 
2025-08-30 05:29:26.678339: Current learning rate: 0.00069 
2025-08-30 05:29:53.855156: train_loss -0.5531 
2025-08-30 05:29:53.863489: val_loss -0.661 
2025-08-30 05:29:53.867736: Pseudo dice [np.float32(0.8173)] 
2025-08-30 05:29:53.873109: Epoch time: 27.19 s 
2025-08-30 05:29:54.497800:  
2025-08-30 05:29:54.505869: Epoch 334 
2025-08-30 05:29:54.514499: Current learning rate: 0.00069 
2025-08-30 05:30:21.516148: train_loss -0.5796 
2025-08-30 05:30:21.524487: val_loss -0.5369 
2025-08-30 05:30:21.528617: Pseudo dice [np.float32(0.7952)] 
2025-08-30 05:30:21.536717: Epoch time: 27.02 s 
2025-08-30 05:30:22.170960:  
2025-08-30 05:30:22.179317: Epoch 335 
2025-08-30 05:30:22.184349: Current learning rate: 0.00069 
2025-08-30 05:30:48.939324: train_loss -0.5605 
2025-08-30 05:30:48.948181: val_loss -0.525 
2025-08-30 05:30:48.952121: Pseudo dice [np.float32(0.704)] 
2025-08-30 05:30:48.961258: Epoch time: 26.77 s 
2025-08-30 05:30:49.594185:  
2025-08-30 05:30:49.602558: Epoch 336 
2025-08-30 05:30:49.606967: Current learning rate: 0.00069 
2025-08-30 05:31:16.712899: train_loss -0.5744 
2025-08-30 05:31:16.721489: val_loss -0.6179 
2025-08-30 05:31:16.725430: Pseudo dice [np.float32(0.7424)] 
2025-08-30 05:31:16.732759: Epoch time: 27.12 s 
2025-08-30 05:31:17.371959:  
2025-08-30 05:31:17.381311: Epoch 337 
2025-08-30 05:31:17.385425: Current learning rate: 0.00069 
2025-08-30 05:31:44.232117: train_loss -0.5852 
2025-08-30 05:31:44.244573: val_loss -0.6428 
2025-08-30 05:31:44.249006: Pseudo dice [np.float32(0.779)] 
2025-08-30 05:31:44.254722: Epoch time: 26.86 s 
2025-08-30 05:31:45.032912:  
2025-08-30 05:31:45.041274: Epoch 338 
2025-08-30 05:31:45.045626: Current learning rate: 0.00069 
2025-08-30 05:32:11.938983: train_loss -0.5668 
2025-08-30 05:32:11.947489: val_loss -0.6476 
2025-08-30 05:32:11.955734: Pseudo dice [np.float32(0.7712)] 
2025-08-30 05:32:11.961401: Epoch time: 26.91 s 
2025-08-30 05:32:12.606213:  
2025-08-30 05:32:12.614919: Epoch 339 
2025-08-30 05:32:12.623196: Current learning rate: 0.00069 
2025-08-30 05:32:39.637369: train_loss -0.5574 
2025-08-30 05:32:39.645701: val_loss -0.5058 
2025-08-30 05:32:39.654045: Pseudo dice [np.float32(0.8009)] 
2025-08-30 05:32:39.659431: Epoch time: 27.03 s 
2025-08-30 05:32:40.292201:  
2025-08-30 05:32:40.300560: Epoch 340 
2025-08-30 05:32:40.304702: Current learning rate: 0.00069 
2025-08-30 05:33:07.544467: train_loss -0.5705 
2025-08-30 05:33:07.552807: val_loss -0.5691 
2025-08-30 05:33:07.561122: Pseudo dice [np.float32(0.7313)] 
2025-08-30 05:33:07.565283: Epoch time: 27.25 s 
2025-08-30 05:33:08.203391:  
2025-08-30 05:33:08.207848: Epoch 341 
2025-08-30 05:33:08.215582: Current learning rate: 0.00069 
2025-08-30 05:33:35.071682: train_loss -0.5757 
2025-08-30 05:33:35.080307: val_loss -0.5507 
2025-08-30 05:33:35.084493: Pseudo dice [np.float32(0.7128)] 
2025-08-30 05:33:35.091774: Epoch time: 26.87 s 
2025-08-30 05:33:35.726700:  
2025-08-30 05:33:35.731173: Epoch 342 
2025-08-30 05:33:35.739317: Current learning rate: 0.00069 
2025-08-30 05:34:02.854257: train_loss -0.5721 
2025-08-30 05:34:02.862135: val_loss -0.5742 
2025-08-30 05:34:02.866655: Pseudo dice [np.float32(0.7769)] 
2025-08-30 05:34:02.872454: Epoch time: 27.13 s 
2025-08-30 05:34:03.516932:  
2025-08-30 05:34:03.521122: Epoch 343 
2025-08-30 05:34:03.529452: Current learning rate: 0.00069 
2025-08-30 05:34:30.290345: train_loss -0.5493 
2025-08-30 05:34:30.298146: val_loss -0.5944 
2025-08-30 05:34:30.306537: Pseudo dice [np.float32(0.7373)] 
2025-08-30 05:34:30.311804: Epoch time: 26.78 s 
2025-08-30 05:34:31.098647:  
2025-08-30 05:34:31.107000: Epoch 344 
2025-08-30 05:34:31.111173: Current learning rate: 0.00068 
2025-08-30 05:34:58.029598: train_loss -0.5566 
2025-08-30 05:34:58.038685: val_loss -0.6092 
2025-08-30 05:34:58.046720: Pseudo dice [np.float32(0.7597)] 
2025-08-30 05:34:58.053516: Epoch time: 26.93 s 
2025-08-30 05:34:58.688713:  
2025-08-30 05:34:58.697052: Epoch 345 
2025-08-30 05:34:58.701203: Current learning rate: 0.00068 
2025-08-30 05:35:25.933487: train_loss -0.5548 
2025-08-30 05:35:25.945084: val_loss -0.5824 
2025-08-30 05:35:25.949271: Pseudo dice [np.float32(0.7717)] 
2025-08-30 05:35:25.955622: Epoch time: 27.24 s 
2025-08-30 05:35:26.583290:  
2025-08-30 05:35:26.591599: Epoch 346 
2025-08-30 05:35:26.595745: Current learning rate: 0.00068 
2025-08-30 05:35:53.568514: train_loss -0.5399 
2025-08-30 05:35:53.577185: val_loss -0.6246 
2025-08-30 05:35:53.585234: Pseudo dice [np.float32(0.7972)] 
2025-08-30 05:35:53.590674: Epoch time: 26.99 s 
2025-08-30 05:35:54.219162:  
2025-08-30 05:35:54.223358: Epoch 347 
2025-08-30 05:35:54.231781: Current learning rate: 0.00068 
2025-08-30 05:36:20.925149: train_loss -0.5603 
2025-08-30 05:36:20.933638: val_loss -0.6272 
2025-08-30 05:36:20.941676: Pseudo dice [np.float32(0.7978)] 
2025-08-30 05:36:20.947058: Epoch time: 26.71 s 
2025-08-30 05:36:21.579836:  
2025-08-30 05:36:21.588187: Epoch 348 
2025-08-30 05:36:21.592322: Current learning rate: 0.00068 
2025-08-30 05:36:48.281719: train_loss -0.55 
2025-08-30 05:36:48.289608: val_loss -0.6547 
2025-08-30 05:36:48.294313: Pseudo dice [np.float32(0.8028)] 
2025-08-30 05:36:48.299454: Epoch time: 26.71 s 
2025-08-30 05:36:48.940472:  
2025-08-30 05:36:48.949158: Epoch 349 
2025-08-30 05:36:48.956988: Current learning rate: 0.00068 
2025-08-30 05:37:15.892450: train_loss -0.559 
2025-08-30 05:37:15.901030: val_loss -0.5216 
2025-08-30 05:37:15.904989: Pseudo dice [np.float32(0.7214)] 
2025-08-30 05:37:15.912172: Epoch time: 26.95 s 
2025-08-30 05:37:16.960097:  
2025-08-30 05:37:16.968465: Epoch 350 
2025-08-30 05:37:16.972621: Current learning rate: 0.00068 
2025-08-30 05:37:43.603983: train_loss -0.5833 
2025-08-30 05:37:43.611744: val_loss -0.5844 
2025-08-30 05:37:43.615880: Pseudo dice [np.float32(0.7793)] 
2025-08-30 05:37:43.625481: Epoch time: 26.64 s 
2025-08-30 05:37:44.258351:  
2025-08-30 05:37:44.266553: Epoch 351 
2025-08-30 05:37:44.274903: Current learning rate: 0.00068 
2025-08-30 05:38:11.260234: train_loss -0.5771 
2025-08-30 05:38:11.268578: val_loss -0.5507 
2025-08-30 05:38:11.272782: Pseudo dice [np.float32(0.6811)] 
2025-08-30 05:38:11.281816: Epoch time: 27.0 s 
2025-08-30 05:38:11.923349:  
2025-08-30 05:38:11.931736: Epoch 352 
2025-08-30 05:38:11.935856: Current learning rate: 0.00068 
2025-08-30 05:38:38.862806: train_loss -0.5563 
2025-08-30 05:38:38.871144: val_loss -0.5729 
2025-08-30 05:38:38.875318: Pseudo dice [np.float32(0.7724)] 
2025-08-30 05:38:38.882523: Epoch time: 26.94 s 
2025-08-30 05:38:39.517540:  
2025-08-30 05:38:39.525874: Epoch 353 
2025-08-30 05:38:39.530048: Current learning rate: 0.00068 
2025-08-30 05:39:06.461557: train_loss -0.5447 
2025-08-30 05:39:06.469532: val_loss -0.5813 
2025-08-30 05:39:06.473722: Pseudo dice [np.float32(0.778)] 
2025-08-30 05:39:06.479650: Epoch time: 26.94 s 
2025-08-30 05:39:07.140996:  
2025-08-30 05:39:07.149350: Epoch 354 
2025-08-30 05:39:07.153492: Current learning rate: 0.00067 
2025-08-30 05:39:34.059521: train_loss -0.5812 
2025-08-30 05:39:34.068175: val_loss -0.5981 
2025-08-30 05:39:34.072027: Pseudo dice [np.float32(0.7797)] 
2025-08-30 05:39:34.079510: Epoch time: 26.92 s 
2025-08-30 05:39:34.726833:  
2025-08-30 05:39:34.731062: Epoch 355 
2025-08-30 05:39:34.735206: Current learning rate: 0.00067 
2025-08-30 05:40:01.533101: train_loss -0.5534 
2025-08-30 05:40:01.541220: val_loss -0.5801 
2025-08-30 05:40:01.549536: Pseudo dice [np.float32(0.832)] 
2025-08-30 05:40:01.554438: Epoch time: 26.81 s 
2025-08-30 05:40:02.195990:  
2025-08-30 05:40:02.204150: Epoch 356 
2025-08-30 05:40:02.208752: Current learning rate: 0.00067 
2025-08-30 05:40:29.077302: train_loss -0.5837 
2025-08-30 05:40:29.085563: val_loss -0.6118 
2025-08-30 05:40:29.089536: Pseudo dice [np.float32(0.7932)] 
2025-08-30 05:40:29.097558: Epoch time: 26.89 s 
2025-08-30 05:40:29.735984:  
2025-08-30 05:40:29.741590: Epoch 357 
2025-08-30 05:40:29.745339: Current learning rate: 0.00067 
2025-08-30 05:40:57.042851: train_loss -0.5596 
2025-08-30 05:40:57.051039: val_loss -0.5685 
2025-08-30 05:40:57.059206: Pseudo dice [np.float32(0.7685)] 
2025-08-30 05:40:57.064054: Epoch time: 27.31 s 
2025-08-30 05:40:57.701366:  
2025-08-30 05:40:57.709711: Epoch 358 
2025-08-30 05:40:57.713884: Current learning rate: 0.00067 
2025-08-30 05:41:25.024488: train_loss -0.5942 
2025-08-30 05:41:25.033173: val_loss -0.5222 
2025-08-30 05:41:25.041184: Pseudo dice [np.float32(0.6879)] 
2025-08-30 05:41:25.046796: Epoch time: 27.32 s 
2025-08-30 05:41:25.708832:  
2025-08-30 05:41:25.717141: Epoch 359 
2025-08-30 05:41:25.721081: Current learning rate: 0.00067 
2025-08-30 05:41:52.547832: train_loss -0.6082 
2025-08-30 05:41:52.556467: val_loss -0.5524 
2025-08-30 05:41:52.564506: Pseudo dice [np.float32(0.7507)] 
2025-08-30 05:41:52.569460: Epoch time: 26.84 s 
2025-08-30 05:41:53.252676:  
2025-08-30 05:41:53.261052: Epoch 360 
2025-08-30 05:41:53.265214: Current learning rate: 0.00067 
2025-08-30 05:42:20.446962: train_loss -0.5593 
2025-08-30 05:42:20.454871: val_loss -0.6056 
2025-08-30 05:42:20.459039: Pseudo dice [np.float32(0.7891)] 
2025-08-30 05:42:20.463218: Epoch time: 27.2 s 
2025-08-30 05:42:21.101347:  
2025-08-30 05:42:21.105949: Epoch 361 
2025-08-30 05:42:21.113832: Current learning rate: 0.00067 
2025-08-30 05:42:48.053672: train_loss -0.576 
2025-08-30 05:42:48.061605: val_loss -0.5864 
2025-08-30 05:42:48.065768: Pseudo dice [np.float32(0.8199)] 
2025-08-30 05:42:48.074161: Epoch time: 26.96 s 
2025-08-30 05:42:48.720798:  
2025-08-30 05:42:48.724771: Epoch 362 
2025-08-30 05:42:48.728918: Current learning rate: 0.00067 
2025-08-30 05:43:15.243586: train_loss -0.5719 
2025-08-30 05:43:15.251565: val_loss -0.6406 
2025-08-30 05:43:15.255403: Pseudo dice [np.float32(0.7649)] 
2025-08-30 05:43:15.261447: Epoch time: 26.53 s 
2025-08-30 05:43:16.072883:  
2025-08-30 05:43:16.081385: Epoch 363 
2025-08-30 05:43:16.085768: Current learning rate: 0.00067 
2025-08-30 05:43:42.620544: train_loss -0.6023 
2025-08-30 05:43:42.633106: val_loss -0.5364 
2025-08-30 05:43:42.639281: Pseudo dice [np.float32(0.7578)] 
2025-08-30 05:43:42.644198: Epoch time: 26.55 s 
2025-08-30 05:43:43.279524:  
2025-08-30 05:43:43.287547: Epoch 364 
2025-08-30 05:43:43.295897: Current learning rate: 0.00067 
2025-08-30 05:44:09.993738: train_loss -0.5754 
2025-08-30 05:44:10.001723: val_loss -0.6007 
2025-08-30 05:44:10.005888: Pseudo dice [np.float32(0.7859)] 
2025-08-30 05:44:10.015298: Epoch time: 26.71 s 
2025-08-30 05:44:10.677403:  
2025-08-30 05:44:10.685758: Epoch 365 
2025-08-30 05:44:10.689957: Current learning rate: 0.00066 
2025-08-30 05:44:37.512520: train_loss -0.5859 
2025-08-30 05:44:37.525399: val_loss -0.602 
2025-08-30 05:44:37.529637: Pseudo dice [np.float32(0.7922)] 
2025-08-30 05:44:37.535449: Epoch time: 26.84 s 
2025-08-30 05:44:38.175979:  
2025-08-30 05:44:38.184125: Epoch 366 
2025-08-30 05:44:38.188492: Current learning rate: 0.00066 
2025-08-30 05:45:04.998307: train_loss -0.5528 
2025-08-30 05:45:05.006723: val_loss -0.5145 
2025-08-30 05:45:05.010814: Pseudo dice [np.float32(0.7594)] 
2025-08-30 05:45:05.017036: Epoch time: 26.83 s 
2025-08-30 05:45:05.649018:  
2025-08-30 05:45:05.657399: Epoch 367 
2025-08-30 05:45:05.661753: Current learning rate: 0.00066 
2025-08-30 05:45:32.738583: train_loss -0.5573 
2025-08-30 05:45:32.747113: val_loss -0.5533 
2025-08-30 05:45:32.751019: Pseudo dice [np.float32(0.7513)] 
2025-08-30 05:45:32.758423: Epoch time: 27.09 s 
2025-08-30 05:45:33.401729:  
2025-08-30 05:45:33.410050: Epoch 368 
2025-08-30 05:45:33.414629: Current learning rate: 0.00066 
2025-08-30 05:45:59.907725: train_loss -0.5481 
2025-08-30 05:45:59.915636: val_loss -0.5121 
2025-08-30 05:45:59.919743: Pseudo dice [np.float32(0.6834)] 
2025-08-30 05:45:59.925312: Epoch time: 26.51 s 
2025-08-30 05:46:00.562127:  
2025-08-30 05:46:00.570747: Epoch 369 
2025-08-30 05:46:00.574712: Current learning rate: 0.00066 
2025-08-30 05:46:27.448896: train_loss -0.5442 
2025-08-30 05:46:27.455901: val_loss -0.588 
2025-08-30 05:46:27.459982: Pseudo dice [np.float32(0.8258)] 
2025-08-30 05:46:27.464000: Epoch time: 26.89 s 
2025-08-30 05:46:28.093815:  
2025-08-30 05:46:28.102483: Epoch 370 
2025-08-30 05:46:28.110473: Current learning rate: 0.00066 
2025-08-30 05:46:54.733211: train_loss -0.5775 
2025-08-30 05:46:54.741493: val_loss -0.6069 
2025-08-30 05:46:54.745463: Pseudo dice [np.float32(0.8019)] 
2025-08-30 05:46:54.753633: Epoch time: 26.64 s 
2025-08-30 05:46:55.387719:  
2025-08-30 05:46:55.396069: Epoch 371 
2025-08-30 05:46:55.400487: Current learning rate: 0.00066 
2025-08-30 05:47:22.114668: train_loss -0.5779 
2025-08-30 05:47:22.123037: val_loss -0.5543 
2025-08-30 05:47:22.126984: Pseudo dice [np.float32(0.7193)] 
2025-08-30 05:47:22.135014: Epoch time: 26.73 s 
2025-08-30 05:47:22.790080:  
2025-08-30 05:47:22.798756: Epoch 372 
2025-08-30 05:47:22.806728: Current learning rate: 0.00066 
2025-08-30 05:47:49.625573: train_loss -0.5799 
2025-08-30 05:47:49.633616: val_loss -0.6576 
2025-08-30 05:47:49.637961: Pseudo dice [np.float32(0.7816)] 
2025-08-30 05:47:49.646818: Epoch time: 26.84 s 
2025-08-30 05:47:50.288342:  
2025-08-30 05:47:50.296744: Epoch 373 
2025-08-30 05:47:50.300880: Current learning rate: 0.00066 
2025-08-30 05:48:17.453352: train_loss -0.5967 
2025-08-30 05:48:17.461687: val_loss -0.5905 
2025-08-30 05:48:17.465518: Pseudo dice [np.float32(0.766)] 
2025-08-30 05:48:17.470832: Epoch time: 27.17 s 
2025-08-30 05:48:18.116601:  
2025-08-30 05:48:18.124543: Epoch 374 
2025-08-30 05:48:18.128681: Current learning rate: 0.00066 
2025-08-30 05:48:44.793436: train_loss -0.5776 
2025-08-30 05:48:44.805692: val_loss -0.5689 
2025-08-30 05:48:44.809825: Pseudo dice [np.float32(0.7869)] 
2025-08-30 05:48:44.815542: Epoch time: 26.68 s 
2025-08-30 05:48:45.455960:  
2025-08-30 05:48:45.464457: Epoch 375 
2025-08-30 05:48:45.468475: Current learning rate: 0.00066 
2025-08-30 05:49:12.429259: train_loss -0.5762 
2025-08-30 05:49:12.437092: val_loss -0.6508 
2025-08-30 05:49:12.441573: Pseudo dice [np.float32(0.8105)] 
2025-08-30 05:49:12.449465: Epoch time: 26.98 s 
2025-08-30 05:49:13.237854:  
2025-08-30 05:49:13.246236: Epoch 376 
2025-08-30 05:49:13.250376: Current learning rate: 0.00065 
2025-08-30 05:49:39.985801: train_loss -0.5638 
2025-08-30 05:49:39.993755: val_loss -0.5925 
2025-08-30 05:49:39.997895: Pseudo dice [np.float32(0.7855)] 
2025-08-30 05:49:40.007408: Epoch time: 26.75 s 
2025-08-30 05:49:40.648552:  
2025-08-30 05:49:40.656956: Epoch 377 
2025-08-30 05:49:40.665269: Current learning rate: 0.00065 
2025-08-30 05:50:06.870944: train_loss -0.5805 
2025-08-30 05:50:06.878922: val_loss -0.6167 
2025-08-30 05:50:06.883426: Pseudo dice [np.float32(0.7664)] 
2025-08-30 05:50:06.891165: Epoch time: 26.22 s 
2025-08-30 05:50:07.529593:  
2025-08-30 05:50:07.537954: Epoch 378 
2025-08-30 05:50:07.542093: Current learning rate: 0.00065 
2025-08-30 05:50:34.189041: train_loss -0.5619 
2025-08-30 05:50:34.193741: val_loss -0.5542 
2025-08-30 05:50:34.202048: Pseudo dice [np.float32(0.7943)] 
2025-08-30 05:50:34.206253: Epoch time: 26.66 s 
2025-08-30 05:50:34.849850:  
2025-08-30 05:50:34.856863: Epoch 379 
2025-08-30 05:50:34.861020: Current learning rate: 0.00065 
2025-08-30 05:51:01.984385: train_loss -0.5845 
2025-08-30 05:51:01.992674: val_loss -0.6471 
2025-08-30 05:51:02.000698: Pseudo dice [np.float32(0.8061)] 
2025-08-30 05:51:02.006315: Epoch time: 27.14 s 
2025-08-30 05:51:02.642693:  
2025-08-30 05:51:02.649106: Epoch 380 
2025-08-30 05:51:02.655744: Current learning rate: 0.00065 
2025-08-30 05:51:29.716227: train_loss -0.563 
2025-08-30 05:51:29.724147: val_loss -0.63 
2025-08-30 05:51:29.732790: Pseudo dice [np.float32(0.807)] 
2025-08-30 05:51:29.737504: Epoch time: 27.08 s 
2025-08-30 05:51:29.741802: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2025-08-30 05:51:30.579464:  
2025-08-30 05:51:30.587506: Epoch 381 
2025-08-30 05:51:30.591984: Current learning rate: 0.00065 
2025-08-30 05:51:57.097670: train_loss -0.5926 
2025-08-30 05:51:57.105690: val_loss -0.5159 
2025-08-30 05:51:57.113841: Pseudo dice [np.float32(0.6569)] 
2025-08-30 05:51:57.118235: Epoch time: 26.52 s 
2025-08-30 05:51:57.919026:  
2025-08-30 05:51:57.927607: Epoch 382 
2025-08-30 05:51:57.931491: Current learning rate: 0.00065 
2025-08-30 05:52:23.461185: train_loss -0.5805 
2025-08-30 05:52:23.469516: val_loss -0.62 
2025-08-30 05:52:23.473910: Pseudo dice [np.float32(0.7784)] 
2025-08-30 05:52:23.481649: Epoch time: 25.54 s 
2025-08-30 05:52:24.124311:  
2025-08-30 05:52:24.132651: Epoch 383 
2025-08-30 05:52:24.136835: Current learning rate: 0.00065 
2025-08-30 05:52:49.458341: train_loss -0.5928 
2025-08-30 05:52:49.466568: val_loss -0.6126 
2025-08-30 05:52:49.474621: Pseudo dice [np.float32(0.7766)] 
2025-08-30 05:52:49.479667: Epoch time: 25.33 s 
2025-08-30 05:52:50.229893:  
2025-08-30 05:52:50.238306: Epoch 384 
2025-08-30 05:52:50.242498: Current learning rate: 0.00065 
2025-08-30 05:53:15.905143: train_loss -0.5706 
2025-08-30 05:53:15.913524: val_loss -0.5447 
2025-08-30 05:53:15.918102: Pseudo dice [np.float32(0.7542)] 
2025-08-30 05:53:15.924184: Epoch time: 25.68 s 
2025-08-30 05:53:16.576749:  
2025-08-30 05:53:16.585106: Epoch 385 
2025-08-30 05:53:16.589225: Current learning rate: 0.00065 
2025-08-30 05:53:42.102168: train_loss -0.5566 
2025-08-30 05:53:42.114693: val_loss -0.6072 
2025-08-30 05:53:42.118880: Pseudo dice [np.float32(0.7881)] 
2025-08-30 05:53:42.124425: Epoch time: 25.53 s 
2025-08-30 05:53:42.773767:  
2025-08-30 05:53:42.782096: Epoch 386 
2025-08-30 05:53:42.786543: Current learning rate: 0.00064 
2025-08-30 05:54:08.182801: train_loss -0.558 
2025-08-30 05:54:08.191084: val_loss -0.5691 
2025-08-30 05:54:08.199136: Pseudo dice [np.float32(0.7569)] 
2025-08-30 05:54:08.204780: Epoch time: 25.41 s 
2025-08-30 05:54:08.850018:  
2025-08-30 05:54:08.858265: Epoch 387 
2025-08-30 05:54:08.862563: Current learning rate: 0.00064 
2025-08-30 05:54:34.372110: train_loss -0.5479 
2025-08-30 05:54:34.379409: val_loss -0.5899 
2025-08-30 05:54:34.388111: Pseudo dice [np.float32(0.7707)] 
2025-08-30 05:54:34.392662: Epoch time: 25.52 s 
2025-08-30 05:54:35.209701:  
2025-08-30 05:54:35.218043: Epoch 388 
2025-08-30 05:54:35.226047: Current learning rate: 0.00064 
2025-08-30 05:55:00.789627: train_loss -0.5165 
2025-08-30 05:55:00.797745: val_loss -0.6542 
2025-08-30 05:55:00.801585: Pseudo dice [np.float32(0.8238)] 
2025-08-30 05:55:00.808749: Epoch time: 25.58 s 
2025-08-30 05:55:01.448177:  
2025-08-30 05:55:01.456965: Epoch 389 
2025-08-30 05:55:01.460916: Current learning rate: 0.00064 
2025-08-30 05:55:26.997530: train_loss -0.5921 
2025-08-30 05:55:27.006934: val_loss -0.6061 
2025-08-30 05:55:27.011078: Pseudo dice [np.float32(0.7838)] 
2025-08-30 05:55:27.018104: Epoch time: 25.55 s 
2025-08-30 05:55:27.690916:  
2025-08-30 05:55:27.699306: Epoch 390 
2025-08-30 05:55:27.703439: Current learning rate: 0.00064 
2025-08-30 05:55:53.274958: train_loss -0.5454 
2025-08-30 05:55:53.283190: val_loss -0.5575 
2025-08-30 05:55:53.287569: Pseudo dice [np.float32(0.7854)] 
2025-08-30 05:55:53.295760: Epoch time: 25.58 s 
2025-08-30 05:55:53.937960:  
2025-08-30 05:55:53.946337: Epoch 391 
2025-08-30 05:55:53.950476: Current learning rate: 0.00064 
2025-08-30 05:56:19.318508: train_loss -0.5999 
2025-08-30 05:56:19.325855: val_loss -0.5559 
2025-08-30 05:56:19.334179: Pseudo dice [np.float32(0.7869)] 
2025-08-30 05:56:19.340672: Epoch time: 25.38 s 
2025-08-30 05:56:19.988991:  
2025-08-30 05:56:19.997357: Epoch 392 
2025-08-30 05:56:20.001813: Current learning rate: 0.00064 
2025-08-30 05:56:45.447753: train_loss -0.5714 
2025-08-30 05:56:45.456115: val_loss -0.5873 
2025-08-30 05:56:45.460260: Pseudo dice [np.float32(0.788)] 
2025-08-30 05:56:45.468385: Epoch time: 25.46 s 
2025-08-30 05:56:46.115189:  
2025-08-30 05:56:46.119672: Epoch 393 
2025-08-30 05:56:46.127633: Current learning rate: 0.00064 
2025-08-30 05:57:11.744843: train_loss -0.622 
2025-08-30 05:57:11.753523: val_loss -0.6302 
2025-08-30 05:57:11.761615: Pseudo dice [np.float32(0.801)] 
2025-08-30 05:57:11.766560: Epoch time: 25.63 s 
2025-08-30 05:57:12.408308:  
2025-08-30 05:57:12.416340: Epoch 394 
2025-08-30 05:57:12.421223: Current learning rate: 0.00064 
2025-08-30 05:57:38.021119: train_loss -0.566 
2025-08-30 05:57:38.029707: val_loss -0.5522 
2025-08-30 05:57:38.033670: Pseudo dice [np.float32(0.7805)] 
2025-08-30 05:57:38.041776: Epoch time: 25.61 s 
2025-08-30 05:57:38.848383:  
2025-08-30 05:57:38.855554: Epoch 395 
2025-08-30 05:57:38.859407: Current learning rate: 0.00064 
2025-08-30 05:58:04.334957: train_loss -0.5884 
2025-08-30 05:58:04.341707: val_loss -0.5953 
2025-08-30 05:58:04.349864: Pseudo dice [np.float32(0.7973)] 
2025-08-30 05:58:04.354416: Epoch time: 25.49 s 
2025-08-30 05:58:04.359888: Yayy! New best EMA pseudo Dice: 0.7827000021934509 
2025-08-30 05:58:05.202684:  
2025-08-30 05:58:05.211013: Epoch 396 
2025-08-30 05:58:05.215266: Current learning rate: 0.00064 
2025-08-30 05:58:32.437883: train_loss -0.5661 
2025-08-30 05:58:32.446277: val_loss -0.5564 
2025-08-30 05:58:32.450419: Pseudo dice [np.float32(0.7981)] 
2025-08-30 05:58:32.458796: Epoch time: 27.24 s 
2025-08-30 05:58:32.463834: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2025-08-30 05:58:33.322128:  
2025-08-30 05:58:33.330784: Epoch 397 
2025-08-30 05:58:33.335003: Current learning rate: 0.00063 
2025-08-30 05:59:01.187609: train_loss -0.5851 
2025-08-30 05:59:01.195779: val_loss -0.5649 
2025-08-30 05:59:01.199953: Pseudo dice [np.float32(0.765)] 
2025-08-30 05:59:01.206164: Epoch time: 27.87 s 
2025-08-30 05:59:01.875691:  
2025-08-30 05:59:01.879875: Epoch 398 
2025-08-30 05:59:01.888231: Current learning rate: 0.00063 
2025-08-30 05:59:28.823421: train_loss -0.6058 
2025-08-30 05:59:28.835928: val_loss -0.5802 
2025-08-30 05:59:28.842145: Pseudo dice [np.float32(0.7429)] 
2025-08-30 05:59:28.846982: Epoch time: 26.95 s 
2025-08-30 05:59:29.524073:  
2025-08-30 05:59:29.532806: Epoch 399 
2025-08-30 05:59:29.536895: Current learning rate: 0.00063 
2025-08-30 05:59:57.239996: train_loss -0.6091 
2025-08-30 05:59:57.247993: val_loss -0.5669 
2025-08-30 05:59:57.251785: Pseudo dice [np.float32(0.8157)] 
2025-08-30 05:59:57.257288: Epoch time: 27.72 s 
2025-08-30 05:59:58.244438:  
2025-08-30 05:59:58.252559: Epoch 400 
2025-08-30 05:59:58.257262: Current learning rate: 0.00063 
2025-08-30 06:00:25.288152: train_loss -0.5665 
2025-08-30 06:00:25.296396: val_loss -0.6003 
2025-08-30 06:00:25.300594: Pseudo dice [np.float32(0.7936)] 
2025-08-30 06:00:25.308755: Epoch time: 27.05 s 
2025-08-30 06:00:25.955715:  
2025-08-30 06:00:25.959929: Epoch 401 
2025-08-30 06:00:25.967905: Current learning rate: 0.00063 
2025-08-30 06:00:53.516351: train_loss -0.5646 
2025-08-30 06:00:53.524925: val_loss -0.5589 
2025-08-30 06:00:53.529117: Pseudo dice [np.float32(0.8095)] 
2025-08-30 06:00:53.533904: Epoch time: 27.56 s 
2025-08-30 06:00:53.542791: Yayy! New best EMA pseudo Dice: 0.7858999967575073 
2025-08-30 06:00:54.384262:  
2025-08-30 06:00:54.392565: Epoch 402 
2025-08-30 06:00:54.396348: Current learning rate: 0.00063 
2025-08-30 06:01:21.652714: train_loss -0.6139 
2025-08-30 06:01:21.661071: val_loss -0.5764 
2025-08-30 06:01:21.665513: Pseudo dice [np.float32(0.7926)] 
2025-08-30 06:01:21.672822: Epoch time: 27.27 s 
2025-08-30 06:01:21.679340: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2025-08-30 06:01:22.550115:  
2025-08-30 06:01:22.559158: Epoch 403 
2025-08-30 06:01:22.566577: Current learning rate: 0.00063 
2025-08-30 06:01:49.146898: train_loss -0.5804 
2025-08-30 06:01:49.155154: val_loss -0.5937 
2025-08-30 06:01:49.159334: Pseudo dice [np.float32(0.7438)] 
2025-08-30 06:01:49.167107: Epoch time: 26.6 s 
2025-08-30 06:01:49.814192:  
2025-08-30 06:01:49.822876: Epoch 404 
2025-08-30 06:01:49.830578: Current learning rate: 0.00063 
2025-08-30 06:02:16.157509: train_loss -0.5545 
2025-08-30 06:02:16.165465: val_loss -0.5951 
2025-08-30 06:02:16.169927: Pseudo dice [np.float32(0.7375)] 
2025-08-30 06:02:16.176864: Epoch time: 26.34 s 
2025-08-30 06:02:16.832824:  
2025-08-30 06:02:16.841521: Epoch 405 
2025-08-30 06:02:16.846782: Current learning rate: 0.00063 
2025-08-30 06:02:43.054862: train_loss -0.5609 
2025-08-30 06:02:43.067366: val_loss -0.5383 
2025-08-30 06:02:43.071536: Pseudo dice [np.float32(0.7941)] 
2025-08-30 06:02:43.076948: Epoch time: 26.22 s 
2025-08-30 06:02:43.885041:  
2025-08-30 06:02:43.893239: Epoch 406 
2025-08-30 06:02:43.897694: Current learning rate: 0.00063 
2025-08-30 06:03:09.939728: train_loss -0.6058 
2025-08-30 06:03:09.948738: val_loss -0.5953 
2025-08-30 06:03:09.952810: Pseudo dice [np.float32(0.7924)] 
2025-08-30 06:03:09.958923: Epoch time: 26.06 s 
2025-08-30 06:03:10.711608:  
2025-08-30 06:03:10.719953: Epoch 407 
2025-08-30 06:03:10.724389: Current learning rate: 0.00062 
2025-08-30 06:03:37.167198: train_loss -0.5714 
2025-08-30 06:03:37.179281: val_loss -0.56 
2025-08-30 06:03:37.183890: Pseudo dice [np.float32(0.7669)] 
2025-08-30 06:03:37.188917: Epoch time: 26.46 s 
2025-08-30 06:03:37.843030:  
2025-08-30 06:03:37.851625: Epoch 408 
2025-08-30 06:03:37.855636: Current learning rate: 0.00062 
2025-08-30 06:04:04.415624: train_loss -0.6144 
2025-08-30 06:04:04.423411: val_loss -0.5339 
2025-08-30 06:04:04.428107: Pseudo dice [np.float32(0.7903)] 
2025-08-30 06:04:04.433304: Epoch time: 26.57 s 
2025-08-30 06:04:05.099578:  
2025-08-30 06:04:05.107663: Epoch 409 
2025-08-30 06:04:05.111870: Current learning rate: 0.00062 
2025-08-30 06:04:31.805154: train_loss -0.5981 
2025-08-30 06:04:31.813778: val_loss -0.5592 
2025-08-30 06:04:31.822111: Pseudo dice [np.float32(0.7711)] 
2025-08-30 06:04:31.826814: Epoch time: 26.71 s 
2025-08-30 06:04:32.468239:  
2025-08-30 06:04:32.476621: Epoch 410 
2025-08-30 06:04:32.484959: Current learning rate: 0.00062 
2025-08-30 06:04:59.395343: train_loss -0.5545 
2025-08-30 06:04:59.403785: val_loss -0.6232 
2025-08-30 06:04:59.407959: Pseudo dice [np.float32(0.8038)] 
2025-08-30 06:04:59.416806: Epoch time: 26.93 s 
2025-08-30 06:05:00.037431:  
2025-08-30 06:05:00.045820: Epoch 411 
2025-08-30 06:05:00.049984: Current learning rate: 0.00062 
2025-08-30 06:05:26.906884: train_loss -0.5669 
2025-08-30 06:05:26.914286: val_loss -0.5606 
2025-08-30 06:05:26.924548: Pseudo dice [np.float32(0.7728)] 
2025-08-30 06:05:26.931975: Epoch time: 26.87 s 
2025-08-30 06:05:27.560756:  
2025-08-30 06:05:27.569112: Epoch 412 
2025-08-30 06:05:27.574794: Current learning rate: 0.00062 
2025-08-30 06:05:54.187411: train_loss -0.5769 
2025-08-30 06:05:54.195683: val_loss -0.6133 
2025-08-30 06:05:54.199847: Pseudo dice [np.float32(0.7916)] 
2025-08-30 06:05:54.205618: Epoch time: 26.63 s 
2025-08-30 06:05:54.991109:  
2025-08-30 06:05:55.000646: Epoch 413 
2025-08-30 06:05:55.005160: Current learning rate: 0.00062 
2025-08-30 06:06:21.752483: train_loss -0.6024 
2025-08-30 06:06:21.760746: val_loss -0.6147 
2025-08-30 06:06:21.764884: Pseudo dice [np.float32(0.7504)] 
2025-08-30 06:06:21.770421: Epoch time: 26.76 s 
2025-08-30 06:06:22.394673:  
2025-08-30 06:06:22.403033: Epoch 414 
2025-08-30 06:06:22.407561: Current learning rate: 0.00062 
2025-08-30 06:06:49.284104: train_loss -0.6186 
2025-08-30 06:06:49.292380: val_loss -0.5765 
2025-08-30 06:06:49.296571: Pseudo dice [np.float32(0.7837)] 
2025-08-30 06:06:49.302859: Epoch time: 26.89 s 
2025-08-30 06:06:49.926313:  
2025-08-30 06:06:49.930500: Epoch 415 
2025-08-30 06:06:49.934679: Current learning rate: 0.00062 
2025-08-30 06:07:16.903372: train_loss -0.6016 
2025-08-30 06:07:16.911608: val_loss -0.636 
2025-08-30 06:07:16.916216: Pseudo dice [np.float32(0.7383)] 
2025-08-30 06:07:16.923191: Epoch time: 26.98 s 
2025-08-30 06:07:17.566793:  
2025-08-30 06:07:17.574850: Epoch 416 
2025-08-30 06:07:17.579013: Current learning rate: 0.00062 
2025-08-30 06:07:44.497514: train_loss -0.5705 
2025-08-30 06:07:44.505833: val_loss -0.6055 
2025-08-30 06:07:44.510046: Pseudo dice [np.float32(0.8029)] 
2025-08-30 06:07:44.518231: Epoch time: 26.93 s 
2025-08-30 06:07:45.143968:  
2025-08-30 06:07:45.152074: Epoch 417 
2025-08-30 06:07:45.156574: Current learning rate: 0.00062 
2025-08-30 06:08:12.125120: train_loss -0.589 
2025-08-30 06:08:12.133936: val_loss -0.5775 
2025-08-30 06:08:12.137591: Pseudo dice [np.float32(0.7702)] 
2025-08-30 06:08:12.146396: Epoch time: 26.98 s 
2025-08-30 06:08:12.767467:  
2025-08-30 06:08:12.776010: Epoch 418 
2025-08-30 06:08:12.779997: Current learning rate: 0.00061 
2025-08-30 06:08:39.540438: train_loss -0.5788 
2025-08-30 06:08:39.548825: val_loss -0.5449 
2025-08-30 06:08:39.556676: Pseudo dice [np.float32(0.7861)] 
2025-08-30 06:08:39.561618: Epoch time: 26.77 s 
2025-08-30 06:08:40.338793:  
2025-08-30 06:08:40.346455: Epoch 419 
2025-08-30 06:08:40.351728: Current learning rate: 0.00061 
2025-08-30 06:09:07.652163: train_loss -0.5598 
2025-08-30 06:09:07.659702: val_loss -0.6585 
2025-08-30 06:09:07.664178: Pseudo dice [np.float32(0.785)] 
2025-08-30 06:09:07.673183: Epoch time: 27.32 s 
2025-08-30 06:09:08.297830:  
2025-08-30 06:09:08.306184: Epoch 420 
2025-08-30 06:09:08.310376: Current learning rate: 0.00061 
2025-08-30 06:09:35.433327: train_loss -0.5674 
2025-08-30 06:09:35.441694: val_loss -0.5905 
2025-08-30 06:09:35.445845: Pseudo dice [np.float32(0.7478)] 
2025-08-30 06:09:35.452888: Epoch time: 27.14 s 
2025-08-30 06:09:36.096415:  
2025-08-30 06:09:36.104770: Epoch 421 
2025-08-30 06:09:36.108947: Current learning rate: 0.00061 
2025-08-30 06:10:02.785982: train_loss -0.5678 
2025-08-30 06:10:02.793927: val_loss -0.5141 
2025-08-30 06:10:02.798434: Pseudo dice [np.float32(0.7738)] 
2025-08-30 06:10:02.806244: Epoch time: 26.69 s 
2025-08-30 06:10:03.432045:  
2025-08-30 06:10:03.440457: Epoch 422 
2025-08-30 06:10:03.444580: Current learning rate: 0.00061 
2025-08-30 06:10:30.513469: train_loss -0.5913 
2025-08-30 06:10:30.521646: val_loss -0.5575 
2025-08-30 06:10:30.526138: Pseudo dice [np.float32(0.7826)] 
2025-08-30 06:10:30.531991: Epoch time: 27.09 s 
2025-08-30 06:10:31.151402:  
2025-08-30 06:10:31.155586: Epoch 423 
2025-08-30 06:10:31.163973: Current learning rate: 0.00061 
2025-08-30 06:10:57.690425: train_loss -0.585 
2025-08-30 06:10:57.698761: val_loss -0.6037 
2025-08-30 06:10:57.702930: Pseudo dice [np.float32(0.7871)] 
2025-08-30 06:10:57.708443: Epoch time: 26.54 s 
2025-08-30 06:10:58.332703:  
2025-08-30 06:10:58.343366: Epoch 424 
2025-08-30 06:10:58.349930: Current learning rate: 0.00061 
2025-08-30 06:11:25.422357: train_loss -0.5972 
2025-08-30 06:11:25.430652: val_loss -0.5035 
2025-08-30 06:11:25.434788: Pseudo dice [np.float32(0.726)] 
2025-08-30 06:11:25.442166: Epoch time: 27.09 s 
2025-08-30 06:11:26.081322:  
2025-08-30 06:11:26.089615: Epoch 425 
2025-08-30 06:11:26.093776: Current learning rate: 0.00061 
2025-08-30 06:11:52.916371: train_loss -0.5563 
2025-08-30 06:11:52.924721: val_loss -0.5579 
2025-08-30 06:11:52.928910: Pseudo dice [np.float32(0.7541)] 
2025-08-30 06:11:52.937353: Epoch time: 26.84 s 
2025-08-30 06:11:53.738081:  
2025-08-30 06:11:53.746460: Epoch 426 
2025-08-30 06:11:53.750625: Current learning rate: 0.00061 
2025-08-30 06:12:20.531460: train_loss -0.5653 
2025-08-30 06:12:20.539801: val_loss -0.6525 
2025-08-30 06:12:20.543982: Pseudo dice [np.float32(0.8188)] 
2025-08-30 06:12:20.553045: Epoch time: 26.79 s 
2025-08-30 06:12:21.198774:  
2025-08-30 06:12:21.207149: Epoch 427 
2025-08-30 06:12:21.211289: Current learning rate: 0.00061 
2025-08-30 06:12:47.700352: train_loss -0.5775 
2025-08-30 06:12:47.712826: val_loss -0.6017 
2025-08-30 06:12:47.717296: Pseudo dice [np.float32(0.8084)] 
2025-08-30 06:12:47.724200: Epoch time: 26.5 s 
2025-08-30 06:12:48.342748:  
2025-08-30 06:12:48.354449: Epoch 428 
2025-08-30 06:12:48.359343: Current learning rate: 0.0006 
2025-08-30 06:13:15.261460: train_loss -0.5817 
2025-08-30 06:13:15.269787: val_loss -0.5761 
2025-08-30 06:13:15.277803: Pseudo dice [np.float32(0.7754)] 
2025-08-30 06:13:15.282823: Epoch time: 26.92 s 
2025-08-30 06:13:15.920444:  
2025-08-30 06:13:15.928735: Epoch 429 
2025-08-30 06:13:15.932725: Current learning rate: 0.0006 
2025-08-30 06:13:42.375706: train_loss -0.6065 
2025-08-30 06:13:42.384449: val_loss -0.6045 
2025-08-30 06:13:42.388480: Pseudo dice [np.float32(0.7665)] 
2025-08-30 06:13:42.396293: Epoch time: 26.46 s 
2025-08-30 06:13:43.013804:  
2025-08-30 06:13:43.022489: Epoch 430 
2025-08-30 06:13:43.026370: Current learning rate: 0.0006 
2025-08-30 06:14:09.702981: train_loss -0.5857 
2025-08-30 06:14:09.711328: val_loss -0.6062 
2025-08-30 06:14:09.719690: Pseudo dice [np.float32(0.7873)] 
2025-08-30 06:14:09.724643: Epoch time: 26.69 s 
2025-08-30 06:14:10.352049:  
2025-08-30 06:14:10.357877: Epoch 431 
2025-08-30 06:14:10.366229: Current learning rate: 0.0006 
2025-08-30 06:14:37.305845: train_loss -0.6018 
2025-08-30 06:14:37.313883: val_loss -0.6146 
2025-08-30 06:14:37.322221: Pseudo dice [np.float32(0.8229)] 
2025-08-30 06:14:37.327204: Epoch time: 26.96 s 
2025-08-30 06:14:37.958101:  
2025-08-30 06:14:37.965614: Epoch 432 
2025-08-30 06:14:37.968701: Current learning rate: 0.0006 
2025-08-30 06:15:04.912252: train_loss -0.6052 
2025-08-30 06:15:04.920625: val_loss -0.5938 
2025-08-30 06:15:04.928960: Pseudo dice [np.float32(0.8281)] 
2025-08-30 06:15:04.934505: Epoch time: 26.96 s 
2025-08-30 06:15:04.939579: Yayy! New best EMA pseudo Dice: 0.7871000170707703 
2025-08-30 06:15:06.005020:  
2025-08-30 06:15:06.013285: Epoch 433 
2025-08-30 06:15:06.017547: Current learning rate: 0.0006 
2025-08-30 06:15:32.911198: train_loss -0.5659 
2025-08-30 06:15:32.919733: val_loss -0.6156 
2025-08-30 06:15:32.923640: Pseudo dice [np.float32(0.7971)] 
2025-08-30 06:15:32.930840: Epoch time: 26.91 s 
2025-08-30 06:15:32.936565: Yayy! New best EMA pseudo Dice: 0.788100004196167 
2025-08-30 06:15:33.786967:  
2025-08-30 06:15:33.795709: Epoch 434 
2025-08-30 06:15:33.801330: Current learning rate: 0.0006 
2025-08-30 06:16:00.392999: train_loss -0.6303 
2025-08-30 06:16:00.401330: val_loss -0.5824 
2025-08-30 06:16:00.409258: Pseudo dice [np.float32(0.8042)] 
2025-08-30 06:16:00.414341: Epoch time: 26.61 s 
2025-08-30 06:16:00.418761: Yayy! New best EMA pseudo Dice: 0.7896999716758728 
2025-08-30 06:16:01.264367:  
2025-08-30 06:16:01.272719: Epoch 435 
2025-08-30 06:16:01.276920: Current learning rate: 0.0006 
2025-08-30 06:16:27.532864: train_loss -0.5541 
2025-08-30 06:16:27.540655: val_loss -0.5445 
2025-08-30 06:16:27.544786: Pseudo dice [np.float32(0.7545)] 
2025-08-30 06:16:27.550948: Epoch time: 26.27 s 
2025-08-30 06:16:28.178729:  
2025-08-30 06:16:28.186879: Epoch 436 
2025-08-30 06:16:28.191358: Current learning rate: 0.0006 
2025-08-30 06:16:55.119239: train_loss -0.6038 
2025-08-30 06:16:55.126478: val_loss -0.6898 
2025-08-30 06:16:55.134837: Pseudo dice [np.float32(0.8256)] 
2025-08-30 06:16:55.140293: Epoch time: 26.94 s 
2025-08-30 06:16:55.144079: Yayy! New best EMA pseudo Dice: 0.7900999784469604 
2025-08-30 06:16:55.969015:  
2025-08-30 06:16:55.977618: Epoch 437 
2025-08-30 06:16:55.985787: Current learning rate: 0.0006 
2025-08-30 06:17:23.129735: train_loss -0.6088 
2025-08-30 06:17:23.138107: val_loss -0.6297 
2025-08-30 06:17:23.142371: Pseudo dice [np.float32(0.7908)] 
2025-08-30 06:17:23.149501: Epoch time: 27.16 s 
2025-08-30 06:17:23.155033: Yayy! New best EMA pseudo Dice: 0.7901999950408936 
2025-08-30 06:17:23.984466:  
2025-08-30 06:17:23.992858: Epoch 438 
2025-08-30 06:17:24.001148: Current learning rate: 0.0006 
2025-08-30 06:17:50.928560: train_loss -0.6293 
2025-08-30 06:17:50.940889: val_loss -0.6106 
2025-08-30 06:17:50.944737: Pseudo dice [np.float32(0.7401)] 
2025-08-30 06:17:50.950923: Epoch time: 26.94 s 
2025-08-30 06:17:51.724669:  
2025-08-30 06:17:51.733020: Epoch 439 
2025-08-30 06:17:51.737196: Current learning rate: 0.00059 
2025-08-30 06:18:18.898462: train_loss -0.5672 
2025-08-30 06:18:18.905970: val_loss -0.5943 
2025-08-30 06:18:18.910133: Pseudo dice [np.float32(0.818)] 
2025-08-30 06:18:18.917600: Epoch time: 27.17 s 
2025-08-30 06:18:19.539739:  
2025-08-30 06:18:19.548309: Epoch 440 
2025-08-30 06:18:19.553041: Current learning rate: 0.00059 
2025-08-30 06:18:47.000697: train_loss -0.6085 
2025-08-30 06:18:47.013250: val_loss -0.5814 
2025-08-30 06:18:47.017375: Pseudo dice [np.float32(0.8272)] 
2025-08-30 06:18:47.023520: Epoch time: 27.46 s 
2025-08-30 06:18:47.029758: Yayy! New best EMA pseudo Dice: 0.7922999858856201 
2025-08-30 06:18:47.864056:  
2025-08-30 06:18:47.872433: Epoch 441 
2025-08-30 06:18:47.876607: Current learning rate: 0.00059 
2025-08-30 06:19:15.374864: train_loss -0.6001 
2025-08-30 06:19:15.383548: val_loss -0.5947 
2025-08-30 06:19:15.387728: Pseudo dice [np.float32(0.769)] 
2025-08-30 06:19:15.394675: Epoch time: 27.51 s 
2025-08-30 06:19:16.042521:  
2025-08-30 06:19:16.050854: Epoch 442 
2025-08-30 06:19:16.054828: Current learning rate: 0.00059 
2025-08-30 06:19:43.069191: train_loss -0.5851 
2025-08-30 06:19:43.077461: val_loss -0.6039 
2025-08-30 06:19:43.085876: Pseudo dice [np.float32(0.7289)] 
2025-08-30 06:19:43.090769: Epoch time: 27.03 s 
2025-08-30 06:19:43.707353:  
2025-08-30 06:19:43.715987: Epoch 443 
2025-08-30 06:19:43.720162: Current learning rate: 0.00059 
2025-08-30 06:20:10.601138: train_loss -0.5952 
2025-08-30 06:20:10.609181: val_loss -0.5736 
2025-08-30 06:20:10.613675: Pseudo dice [np.float32(0.7994)] 
2025-08-30 06:20:10.623004: Epoch time: 26.89 s 
2025-08-30 06:20:11.238969:  
2025-08-30 06:20:11.247331: Epoch 444 
2025-08-30 06:20:11.251532: Current learning rate: 0.00059 
2025-08-30 06:20:38.274528: train_loss -0.6221 
2025-08-30 06:20:38.282696: val_loss -0.6276 
2025-08-30 06:20:38.286814: Pseudo dice [np.float32(0.8205)] 
2025-08-30 06:20:38.293943: Epoch time: 27.04 s 
2025-08-30 06:20:38.899919:  
2025-08-30 06:20:38.908271: Epoch 445 
2025-08-30 06:20:38.912780: Current learning rate: 0.00059 
2025-08-30 06:21:06.097941: train_loss -0.5863 
2025-08-30 06:21:06.102055: val_loss -0.4211 
2025-08-30 06:21:06.111081: Pseudo dice [np.float32(0.643)] 
2025-08-30 06:21:06.115458: Epoch time: 27.2 s 
2025-08-30 06:21:06.894625:  
2025-08-30 06:21:06.902977: Epoch 446 
2025-08-30 06:21:06.907317: Current learning rate: 0.00059 
2025-08-30 06:21:33.505551: train_loss -0.5717 
2025-08-30 06:21:33.512809: val_loss -0.5729 
2025-08-30 06:21:33.521155: Pseudo dice [np.float32(0.7503)] 
2025-08-30 06:21:33.527901: Epoch time: 26.61 s 
2025-08-30 06:21:34.155211:  
2025-08-30 06:21:34.163814: Epoch 447 
2025-08-30 06:21:34.172025: Current learning rate: 0.00059 
2025-08-30 06:21:59.715145: train_loss -0.5684 
2025-08-30 06:21:59.722673: val_loss -0.5752 
2025-08-30 06:21:59.726818: Pseudo dice [np.float32(0.8031)] 
2025-08-30 06:21:59.734821: Epoch time: 25.56 s 
2025-08-30 06:22:00.346273:  
2025-08-30 06:22:00.352132: Epoch 448 
2025-08-30 06:22:00.360178: Current learning rate: 0.00059 
2025-08-30 06:22:25.498163: train_loss -0.6114 
2025-08-30 06:22:25.506706: val_loss -0.6039 
2025-08-30 06:22:25.514710: Pseudo dice [np.float32(0.7946)] 
2025-08-30 06:22:25.520287: Epoch time: 25.15 s 
2025-08-30 06:22:26.136179:  
2025-08-30 06:22:26.144615: Epoch 449 
2025-08-30 06:22:26.148763: Current learning rate: 0.00058 
2025-08-30 06:22:51.479373: train_loss -0.591 
2025-08-30 06:22:51.490664: val_loss -0.5731 
2025-08-30 06:22:51.494842: Pseudo dice [np.float32(0.7791)] 
2025-08-30 06:22:51.501346: Epoch time: 25.34 s 
2025-08-30 06:22:52.312394:  
2025-08-30 06:22:52.320655: Epoch 450 
2025-08-30 06:22:52.325043: Current learning rate: 0.00058 
2025-08-30 06:23:19.009814: train_loss -0.5549 
2025-08-30 06:23:19.018159: val_loss -0.629 
2025-08-30 06:23:19.022315: Pseudo dice [np.float32(0.8102)] 
2025-08-30 06:23:19.031377: Epoch time: 26.7 s 
2025-08-30 06:23:19.639888:  
2025-08-30 06:23:19.648348: Epoch 451 
2025-08-30 06:23:19.652415: Current learning rate: 0.00058 
2025-08-30 06:23:46.408336: train_loss -0.5605 
2025-08-30 06:23:46.416691: val_loss -0.5415 
2025-08-30 06:23:46.424689: Pseudo dice [np.float32(0.8346)] 
2025-08-30 06:23:46.430158: Epoch time: 26.77 s 
2025-08-30 06:23:47.041953:  
2025-08-30 06:23:47.050696: Epoch 452 
2025-08-30 06:23:47.058724: Current learning rate: 0.00058 
2025-08-30 06:24:13.610154: train_loss -0.5926 
2025-08-30 06:24:13.618867: val_loss -0.5691 
2025-08-30 06:24:13.623178: Pseudo dice [np.float32(0.7828)] 
2025-08-30 06:24:13.630933: Epoch time: 26.57 s 
2025-08-30 06:24:14.406805:  
2025-08-30 06:24:14.415234: Epoch 453 
2025-08-30 06:24:14.419396: Current learning rate: 0.00058 
2025-08-30 06:24:41.171811: train_loss -0.5989 
2025-08-30 06:24:41.179371: val_loss -0.572 
2025-08-30 06:24:41.183867: Pseudo dice [np.float32(0.7631)] 
2025-08-30 06:24:41.190899: Epoch time: 26.77 s 
2025-08-30 06:24:41.809209:  
2025-08-30 06:24:41.817245: Epoch 454 
2025-08-30 06:24:41.821769: Current learning rate: 0.00058 
2025-08-30 06:25:08.460819: train_loss -0.6144 
2025-08-30 06:25:08.469112: val_loss -0.5943 
2025-08-30 06:25:08.473316: Pseudo dice [np.float32(0.8069)] 
2025-08-30 06:25:08.479487: Epoch time: 26.66 s 
2025-08-30 06:25:09.082218:  
2025-08-30 06:25:09.090580: Epoch 455 
2025-08-30 06:25:09.094717: Current learning rate: 0.00058 
2025-08-30 06:25:35.855134: train_loss -0.5676 
2025-08-30 06:25:35.863142: val_loss -0.5786 
2025-08-30 06:25:35.871042: Pseudo dice [np.float32(0.778)] 
2025-08-30 06:25:35.876321: Epoch time: 26.77 s 
2025-08-30 06:25:36.484953:  
2025-08-30 06:25:36.493515: Epoch 456 
2025-08-30 06:25:36.497100: Current learning rate: 0.00058 
2025-08-30 06:26:03.077803: train_loss -0.6095 
2025-08-30 06:26:03.086187: val_loss -0.644 
2025-08-30 06:26:03.090616: Pseudo dice [np.float32(0.7806)] 
2025-08-30 06:26:03.098484: Epoch time: 26.59 s 
2025-08-30 06:26:03.707591:  
2025-08-30 06:26:03.711804: Epoch 457 
2025-08-30 06:26:03.715950: Current learning rate: 0.00058 
2025-08-30 06:26:30.455150: train_loss -0.5904 
2025-08-30 06:26:30.463494: val_loss -0.545 
2025-08-30 06:26:30.471839: Pseudo dice [np.float32(0.7497)] 
2025-08-30 06:26:30.477929: Epoch time: 26.75 s 
2025-08-30 06:26:31.089097:  
2025-08-30 06:26:31.097564: Epoch 458 
2025-08-30 06:26:31.101614: Current learning rate: 0.00058 
2025-08-30 06:26:57.540521: train_loss -0.5711 
2025-08-30 06:26:57.548876: val_loss -0.6247 
2025-08-30 06:26:57.553019: Pseudo dice [np.float32(0.7938)] 
2025-08-30 06:26:57.561456: Epoch time: 26.45 s 
2025-08-30 06:26:58.324662:  
2025-08-30 06:26:58.333327: Epoch 459 
2025-08-30 06:26:58.339394: Current learning rate: 0.00058 
2025-08-30 06:27:25.097228: train_loss -0.5901 
2025-08-30 06:27:25.105561: val_loss -0.6244 
2025-08-30 06:27:25.114544: Pseudo dice [np.float32(0.7973)] 
2025-08-30 06:27:25.119343: Epoch time: 26.77 s 
2025-08-30 06:27:25.727092:  
2025-08-30 06:27:25.735688: Epoch 460 
2025-08-30 06:27:25.739818: Current learning rate: 0.00057 
2025-08-30 06:27:52.357655: train_loss -0.5907 
2025-08-30 06:27:52.366125: val_loss -0.5473 
2025-08-30 06:27:52.370657: Pseudo dice [np.float32(0.7606)] 
2025-08-30 06:27:52.377316: Epoch time: 26.63 s 
2025-08-30 06:27:52.995901:  
2025-08-30 06:27:53.004277: Epoch 461 
2025-08-30 06:27:53.008425: Current learning rate: 0.00057 
2025-08-30 06:28:19.622924: train_loss -0.607 
2025-08-30 06:28:19.631105: val_loss -0.5701 
2025-08-30 06:28:19.639217: Pseudo dice [np.float32(0.7059)] 
2025-08-30 06:28:19.644620: Epoch time: 26.63 s 
2025-08-30 06:28:20.260620:  
2025-08-30 06:28:20.264801: Epoch 462 
2025-08-30 06:28:20.273174: Current learning rate: 0.00057 
2025-08-30 06:28:47.279038: train_loss -0.5771 
2025-08-30 06:28:47.287688: val_loss -0.5809 
2025-08-30 06:28:47.291883: Pseudo dice [np.float32(0.7741)] 
2025-08-30 06:28:47.300089: Epoch time: 27.02 s 
2025-08-30 06:28:47.909089:  
2025-08-30 06:28:47.917414: Epoch 463 
2025-08-30 06:28:47.921613: Current learning rate: 0.00057 
2025-08-30 06:29:14.732266: train_loss -0.5766 
2025-08-30 06:29:14.740075: val_loss -0.6069 
2025-08-30 06:29:14.744208: Pseudo dice [np.float32(0.7536)] 
2025-08-30 06:29:14.752678: Epoch time: 26.82 s 
2025-08-30 06:29:15.378222:  
2025-08-30 06:29:15.386811: Epoch 464 
2025-08-30 06:29:15.390752: Current learning rate: 0.00057 
2025-08-30 06:29:42.054831: train_loss -0.5645 
2025-08-30 06:29:42.067309: val_loss -0.5638 
2025-08-30 06:29:42.071722: Pseudo dice [np.float32(0.768)] 
2025-08-30 06:29:42.078727: Epoch time: 26.68 s 
2025-08-30 06:29:42.701597:  
2025-08-30 06:29:42.709662: Epoch 465 
2025-08-30 06:29:42.714150: Current learning rate: 0.00057 
2025-08-30 06:30:09.457254: train_loss -0.5957 
2025-08-30 06:30:09.465910: val_loss -0.6298 
2025-08-30 06:30:09.473852: Pseudo dice [np.float32(0.7788)] 
2025-08-30 06:30:09.479340: Epoch time: 26.76 s 
2025-08-30 06:30:10.270536:  
2025-08-30 06:30:10.278579: Epoch 466 
2025-08-30 06:30:10.283312: Current learning rate: 0.00057 
2025-08-30 06:30:37.372534: train_loss -0.5781 
2025-08-30 06:30:37.380892: val_loss -0.6431 
2025-08-30 06:30:37.385607: Pseudo dice [np.float32(0.8149)] 
2025-08-30 06:30:37.394123: Epoch time: 27.11 s 
2025-08-30 06:30:38.002423:  
2025-08-30 06:30:38.010746: Epoch 467 
2025-08-30 06:30:38.015252: Current learning rate: 0.00057 
2025-08-30 06:31:04.879171: train_loss -0.5892 
2025-08-30 06:31:04.887539: val_loss -0.571 
2025-08-30 06:31:04.895862: Pseudo dice [np.float32(0.7402)] 
2025-08-30 06:31:04.901596: Epoch time: 26.88 s 
2025-08-30 06:31:05.551041:  
2025-08-30 06:31:05.559386: Epoch 468 
2025-08-30 06:31:05.567470: Current learning rate: 0.00057 
2025-08-30 06:31:32.682292: train_loss -0.6201 
2025-08-30 06:31:32.690291: val_loss -0.5576 
2025-08-30 06:31:32.698671: Pseudo dice [np.float32(0.7815)] 
2025-08-30 06:31:32.703581: Epoch time: 27.13 s 
2025-08-30 06:31:33.357947:  
2025-08-30 06:31:33.365987: Epoch 469 
2025-08-30 06:31:33.370466: Current learning rate: 0.00057 
2025-08-30 06:32:00.484996: train_loss -0.6052 
2025-08-30 06:32:00.493110: val_loss -0.5931 
2025-08-30 06:32:00.497767: Pseudo dice [np.float32(0.7863)] 
2025-08-30 06:32:00.506748: Epoch time: 27.13 s 
2025-08-30 06:32:01.198264:  
2025-08-30 06:32:01.206301: Epoch 470 
2025-08-30 06:32:01.210436: Current learning rate: 0.00056 
2025-08-30 06:32:28.008391: train_loss -0.5972 
2025-08-30 06:32:28.016719: val_loss -0.6004 
2025-08-30 06:32:28.025037: Pseudo dice [np.float32(0.7526)] 
2025-08-30 06:32:28.029728: Epoch time: 26.81 s 
2025-08-30 06:32:28.637864:  
2025-08-30 06:32:28.646605: Epoch 471 
2025-08-30 06:32:28.654495: Current learning rate: 0.00056 
2025-08-30 06:32:55.944260: train_loss -0.5674 
2025-08-30 06:32:55.952847: val_loss -0.6131 
2025-08-30 06:32:55.956862: Pseudo dice [np.float32(0.7928)] 
2025-08-30 06:32:55.964913: Epoch time: 27.31 s 
2025-08-30 06:32:56.574038:  
2025-08-30 06:32:56.578158: Epoch 472 
2025-08-30 06:32:56.586576: Current learning rate: 0.00056 
2025-08-30 06:33:24.009860: train_loss -0.586 
2025-08-30 06:33:24.018465: val_loss -0.6571 
2025-08-30 06:33:24.022563: Pseudo dice [np.float32(0.8412)] 
2025-08-30 06:33:24.030734: Epoch time: 27.44 s 
2025-08-30 06:33:24.647906:  
2025-08-30 06:33:24.652101: Epoch 473 
2025-08-30 06:33:24.660436: Current learning rate: 0.00056 
2025-08-30 06:33:51.412210: train_loss -0.5745 
2025-08-30 06:33:51.420532: val_loss -0.6288 
2025-08-30 06:33:51.428905: Pseudo dice [np.float32(0.774)] 
2025-08-30 06:33:51.433820: Epoch time: 26.77 s 
2025-08-30 06:33:52.042011:  
2025-08-30 06:33:52.050273: Epoch 474 
2025-08-30 06:33:52.054521: Current learning rate: 0.00056 
2025-08-30 06:34:19.411541: train_loss -0.5581 
2025-08-30 06:34:19.419266: val_loss -0.6117 
2025-08-30 06:34:19.423443: Pseudo dice [np.float32(0.7713)] 
2025-08-30 06:34:19.429826: Epoch time: 27.37 s 
2025-08-30 06:34:20.040777:  
2025-08-30 06:34:20.049464: Epoch 475 
2025-08-30 06:34:20.053287: Current learning rate: 0.00056 
2025-08-30 06:34:47.222419: train_loss -0.6132 
2025-08-30 06:34:47.230699: val_loss -0.5753 
2025-08-30 06:34:47.238769: Pseudo dice [np.float32(0.7545)] 
2025-08-30 06:34:47.244981: Epoch time: 27.18 s 
2025-08-30 06:34:47.864322:  
2025-08-30 06:34:47.868521: Epoch 476 
2025-08-30 06:34:47.872681: Current learning rate: 0.00056 
2025-08-30 06:35:15.287888: train_loss -0.5969 
2025-08-30 06:35:15.296251: val_loss -0.5443 
2025-08-30 06:35:15.300119: Pseudo dice [np.float32(0.7926)] 
2025-08-30 06:35:15.307358: Epoch time: 27.43 s 
2025-08-30 06:35:16.005004:  
2025-08-30 06:35:16.013388: Epoch 477 
2025-08-30 06:35:16.017741: Current learning rate: 0.00056 
2025-08-30 06:35:42.806713: train_loss -0.5927 
2025-08-30 06:35:42.815049: val_loss -0.5959 
2025-08-30 06:35:42.819577: Pseudo dice [np.float32(0.8243)] 
2025-08-30 06:35:42.825409: Epoch time: 26.8 s 
2025-08-30 06:35:43.440708:  
2025-08-30 06:35:43.449024: Epoch 478 
2025-08-30 06:35:43.453588: Current learning rate: 0.00056 
2025-08-30 06:36:10.830522: train_loss -0.57 
2025-08-30 06:36:10.842084: val_loss -0.5936 
2025-08-30 06:36:10.848575: Pseudo dice [np.float32(0.8193)] 
2025-08-30 06:36:10.854451: Epoch time: 27.39 s 
2025-08-30 06:36:11.473450:  
2025-08-30 06:36:11.481177: Epoch 479 
2025-08-30 06:36:11.485697: Current learning rate: 0.00056 
2025-08-30 06:36:38.333000: train_loss -0.607 
2025-08-30 06:36:38.344714: val_loss -0.6199 
2025-08-30 06:36:38.351103: Pseudo dice [np.float32(0.8099)] 
2025-08-30 06:36:38.357098: Epoch time: 26.86 s 
2025-08-30 06:36:39.150489:  
2025-08-30 06:36:39.158851: Epoch 480 
2025-08-30 06:36:39.163083: Current learning rate: 0.00056 
2025-08-30 06:37:05.673432: train_loss -0.6343 
2025-08-30 06:37:05.681135: val_loss -0.5557 
2025-08-30 06:37:05.685298: Pseudo dice [np.float32(0.7574)] 
2025-08-30 06:37:05.692735: Epoch time: 26.52 s 
2025-08-30 06:37:06.315423:  
2025-08-30 06:37:06.319256: Epoch 481 
2025-08-30 06:37:06.327612: Current learning rate: 0.00055 
2025-08-30 06:37:32.984028: train_loss -0.5912 
2025-08-30 06:37:32.991723: val_loss -0.6298 
2025-08-30 06:37:32.995915: Pseudo dice [np.float32(0.7841)] 
2025-08-30 06:37:33.004093: Epoch time: 26.67 s 
2025-08-30 06:37:33.659080:  
2025-08-30 06:37:33.667419: Epoch 482 
2025-08-30 06:37:33.675782: Current learning rate: 0.00055 
2025-08-30 06:38:00.773992: train_loss -0.5901 
2025-08-30 06:38:00.782342: val_loss -0.6321 
2025-08-30 06:38:00.791016: Pseudo dice [np.float32(0.7641)] 
2025-08-30 06:38:00.796690: Epoch time: 27.12 s 
2025-08-30 06:38:01.411810:  
2025-08-30 06:38:01.420160: Epoch 483 
2025-08-30 06:38:01.428472: Current learning rate: 0.00055 
2025-08-30 06:38:28.301179: train_loss -0.6026 
2025-08-30 06:38:28.313643: val_loss -0.5572 
2025-08-30 06:38:28.318117: Pseudo dice [np.float32(0.7306)] 
2025-08-30 06:38:28.324320: Epoch time: 26.89 s 
2025-08-30 06:38:28.951990:  
2025-08-30 06:38:28.955996: Epoch 484 
2025-08-30 06:38:28.964346: Current learning rate: 0.00055 
2025-08-30 06:38:55.609375: train_loss -0.6043 
2025-08-30 06:38:55.615946: val_loss -0.6038 
2025-08-30 06:38:55.620504: Pseudo dice [np.float32(0.7631)] 
2025-08-30 06:38:55.629598: Epoch time: 26.66 s 
2025-08-30 06:38:56.249835:  
2025-08-30 06:38:56.254074: Epoch 485 
2025-08-30 06:38:56.258220: Current learning rate: 0.00055 
2025-08-30 06:39:23.076639: train_loss -0.607 
2025-08-30 06:39:23.085381: val_loss -0.6043 
2025-08-30 06:39:23.089486: Pseudo dice [np.float32(0.8018)] 
2025-08-30 06:39:23.097239: Epoch time: 26.83 s 
2025-08-30 06:39:23.727393:  
2025-08-30 06:39:23.735956: Epoch 486 
2025-08-30 06:39:23.739905: Current learning rate: 0.00055 
2025-08-30 06:39:51.059153: train_loss -0.5819 
2025-08-30 06:39:51.067093: val_loss -0.5383 
2025-08-30 06:39:51.075841: Pseudo dice [np.float32(0.7439)] 
2025-08-30 06:39:51.080436: Epoch time: 27.33 s 
2025-08-30 06:39:51.868248:  
2025-08-30 06:39:51.876546: Epoch 487 
2025-08-30 06:39:51.880457: Current learning rate: 0.00055 
2025-08-30 06:40:18.674157: train_loss -0.5793 
2025-08-30 06:40:18.682580: val_loss -0.5961 
2025-08-30 06:40:18.686754: Pseudo dice [np.float32(0.7878)] 
2025-08-30 06:40:18.692672: Epoch time: 26.81 s 
2025-08-30 06:40:19.316194:  
2025-08-30 06:40:19.324529: Epoch 488 
2025-08-30 06:40:19.328672: Current learning rate: 0.00055 
2025-08-30 06:40:46.093243: train_loss -0.588 
2025-08-30 06:40:46.101571: val_loss -0.5393 
2025-08-30 06:40:46.105519: Pseudo dice [np.float32(0.8009)] 
2025-08-30 06:40:46.111597: Epoch time: 26.78 s 
2025-08-30 06:40:46.743539:  
2025-08-30 06:40:46.747740: Epoch 489 
2025-08-30 06:40:46.756086: Current learning rate: 0.00055 
2025-08-30 06:41:13.637036: train_loss -0.5754 
2025-08-30 06:41:13.645729: val_loss -0.6305 
2025-08-30 06:41:13.649874: Pseudo dice [np.float32(0.8117)] 
2025-08-30 06:41:13.655825: Epoch time: 26.9 s 
2025-08-30 06:41:14.279359:  
2025-08-30 06:41:14.287751: Epoch 490 
2025-08-30 06:41:14.291885: Current learning rate: 0.00055 
2025-08-30 06:41:41.456251: train_loss -0.6021 
2025-08-30 06:41:41.464587: val_loss -0.6208 
2025-08-30 06:41:41.469317: Pseudo dice [np.float32(0.7925)] 
2025-08-30 06:41:41.474553: Epoch time: 27.18 s 
2025-08-30 06:41:42.127644:  
2025-08-30 06:41:42.132194: Epoch 491 
2025-08-30 06:41:42.140538: Current learning rate: 0.00054 
2025-08-30 06:42:09.117455: train_loss -0.6164 
2025-08-30 06:42:09.125601: val_loss -0.588 
2025-08-30 06:42:09.130053: Pseudo dice [np.float32(0.8152)] 
2025-08-30 06:42:09.135516: Epoch time: 26.99 s 
2025-08-30 06:42:09.818151:  
2025-08-30 06:42:09.826550: Epoch 492 
2025-08-30 06:42:09.830709: Current learning rate: 0.00054 
2025-08-30 06:42:36.912225: train_loss -0.6223 
2025-08-30 06:42:36.920235: val_loss -0.6048 
2025-08-30 06:42:36.928901: Pseudo dice [np.float32(0.7597)] 
2025-08-30 06:42:36.934629: Epoch time: 27.09 s 
2025-08-30 06:42:37.554407:  
2025-08-30 06:42:37.558444: Epoch 493 
2025-08-30 06:42:37.566739: Current learning rate: 0.00054 
2025-08-30 06:43:04.435467: train_loss -0.6038 
2025-08-30 06:43:04.443576: val_loss -0.5779 
2025-08-30 06:43:04.451585: Pseudo dice [np.float32(0.7488)] 
2025-08-30 06:43:04.456068: Epoch time: 26.89 s 
2025-08-30 06:43:05.240268:  
2025-08-30 06:43:05.251146: Epoch 494 
2025-08-30 06:43:05.252848: Current learning rate: 0.00054 
2025-08-30 06:43:31.913109: train_loss -0.5777 
2025-08-30 06:43:31.921321: val_loss -0.5969 
2025-08-30 06:43:31.929401: Pseudo dice [np.float32(0.797)] 
2025-08-30 06:43:31.934210: Epoch time: 26.67 s 
2025-08-30 06:43:32.546607:  
2025-08-30 06:43:32.550774: Epoch 495 
2025-08-30 06:43:32.559145: Current learning rate: 0.00054 
2025-08-30 06:43:58.801976: train_loss -0.611 
2025-08-30 06:43:58.810348: val_loss -0.5377 
2025-08-30 06:43:58.814756: Pseudo dice [np.float32(0.78)] 
2025-08-30 06:43:58.823708: Epoch time: 26.26 s 
2025-08-30 06:43:59.448767:  
2025-08-30 06:43:59.457150: Epoch 496 
2025-08-30 06:43:59.465163: Current learning rate: 0.00054 
2025-08-30 06:44:24.974818: train_loss -0.5798 
2025-08-30 06:44:24.982682: val_loss -0.5518 
2025-08-30 06:44:24.986803: Pseudo dice [np.float32(0.763)] 
2025-08-30 06:44:24.993799: Epoch time: 25.53 s 
2025-08-30 06:44:25.620401:  
2025-08-30 06:44:25.624942: Epoch 497 
2025-08-30 06:44:25.632992: Current learning rate: 0.00054 
2025-08-30 06:44:50.924962: train_loss -0.5989 
2025-08-30 06:44:50.937384: val_loss -0.6469 
2025-08-30 06:44:50.941900: Pseudo dice [np.float32(0.7724)] 
2025-08-30 06:44:50.947805: Epoch time: 25.31 s 
2025-08-30 06:44:51.571334:  
2025-08-30 06:44:51.580060: Epoch 498 
2025-08-30 06:44:51.583842: Current learning rate: 0.00054 
2025-08-30 06:45:16.988731: train_loss -0.6224 
2025-08-30 06:45:16.996739: val_loss -0.6263 
2025-08-30 06:45:17.000908: Pseudo dice [np.float32(0.7275)] 
2025-08-30 06:45:17.007233: Epoch time: 25.42 s 
2025-08-30 06:45:17.631009:  
2025-08-30 06:45:17.639401: Epoch 499 
2025-08-30 06:45:17.643198: Current learning rate: 0.00054 
2025-08-30 06:45:42.955922: train_loss -0.6089 
2025-08-30 06:45:42.960449: val_loss -0.6372 
2025-08-30 06:45:42.968842: Pseudo dice [np.float32(0.825)] 
2025-08-30 06:45:42.973532: Epoch time: 25.32 s 
2025-08-30 06:45:43.781893:  
2025-08-30 06:45:43.790175: Epoch 500 
2025-08-30 06:45:43.794639: Current learning rate: 0.00054 
2025-08-30 06:46:11.353591: train_loss -0.5997 
2025-08-30 06:46:11.359651: val_loss -0.5811 
2025-08-30 06:46:11.363594: Pseudo dice [np.float32(0.7997)] 
2025-08-30 06:46:11.371608: Epoch time: 27.57 s 
2025-08-30 06:46:12.155978:  
2025-08-30 06:46:12.164557: Epoch 501 
2025-08-30 06:46:12.168771: Current learning rate: 0.00053 
2025-08-30 06:46:38.967085: train_loss -0.5779 
2025-08-30 06:46:38.974737: val_loss -0.6152 
2025-08-30 06:46:38.978905: Pseudo dice [np.float32(0.7726)] 
2025-08-30 06:46:38.986645: Epoch time: 26.81 s 
2025-08-30 06:46:39.612547:  
2025-08-30 06:46:39.620945: Epoch 502 
2025-08-30 06:46:39.625372: Current learning rate: 0.00053 
2025-08-30 06:47:06.675247: train_loss -0.5946 
2025-08-30 06:47:06.681256: val_loss -0.5797 
2025-08-30 06:47:06.689941: Pseudo dice [np.float32(0.7485)] 
2025-08-30 06:47:06.695093: Epoch time: 27.06 s 
2025-08-30 06:47:07.319402:  
2025-08-30 06:47:07.327746: Epoch 503 
2025-08-30 06:47:07.332131: Current learning rate: 0.00053 
2025-08-30 06:47:34.705071: train_loss -0.5908 
2025-08-30 06:47:34.713409: val_loss -0.6238 
2025-08-30 06:47:34.717530: Pseudo dice [np.float32(0.8223)] 
2025-08-30 06:47:34.725909: Epoch time: 27.39 s 
2025-08-30 06:47:35.353047:  
2025-08-30 06:47:35.360207: Epoch 504 
2025-08-30 06:47:35.364168: Current learning rate: 0.00053 
2025-08-30 06:48:02.128306: train_loss -0.5922 
2025-08-30 06:48:02.136647: val_loss -0.5521 
2025-08-30 06:48:02.142360: Pseudo dice [np.float32(0.7863)] 
2025-08-30 06:48:02.149998: Epoch time: 26.78 s 
2025-08-30 06:48:02.778951:  
2025-08-30 06:48:02.787654: Epoch 505 
2025-08-30 06:48:02.795331: Current learning rate: 0.00053 
2025-08-30 06:48:30.168768: train_loss -0.6007 
2025-08-30 06:48:30.177130: val_loss -0.6672 
2025-08-30 06:48:30.185489: Pseudo dice [np.float32(0.8251)] 
2025-08-30 06:48:30.190402: Epoch time: 27.39 s 
2025-08-30 06:48:30.815310:  
2025-08-30 06:48:30.819778: Epoch 506 
2025-08-30 06:48:30.827901: Current learning rate: 0.00053 
2025-08-30 06:48:57.968293: train_loss -0.6206 
2025-08-30 06:48:57.976099: val_loss -0.6785 
2025-08-30 06:48:57.980212: Pseudo dice [np.float32(0.8197)] 
2025-08-30 06:48:57.986184: Epoch time: 27.16 s 
2025-08-30 06:48:58.672241:  
2025-08-30 06:48:58.680607: Epoch 507 
2025-08-30 06:48:58.685018: Current learning rate: 0.00053 
2025-08-30 06:49:25.707795: train_loss -0.5894 
2025-08-30 06:49:25.716035: val_loss -0.6088 
2025-08-30 06:49:25.720207: Pseudo dice [np.float32(0.7698)] 
2025-08-30 06:49:25.726204: Epoch time: 27.04 s 
2025-08-30 06:49:26.495862:  
2025-08-30 06:49:26.504214: Epoch 508 
2025-08-30 06:49:26.508368: Current learning rate: 0.00053 
2025-08-30 06:49:53.264540: train_loss -0.6289 
2025-08-30 06:49:53.272905: val_loss -0.6578 
2025-08-30 06:49:53.276845: Pseudo dice [np.float32(0.7861)] 
2025-08-30 06:49:53.283032: Epoch time: 26.77 s 
2025-08-30 06:49:53.902412:  
2025-08-30 06:49:53.910756: Epoch 509 
2025-08-30 06:49:53.914930: Current learning rate: 0.00053 
2025-08-30 06:50:20.959049: train_loss -0.6077 
2025-08-30 06:50:20.967144: val_loss -0.5533 
2025-08-30 06:50:20.971091: Pseudo dice [np.float32(0.7126)] 
2025-08-30 06:50:20.977203: Epoch time: 27.06 s 
2025-08-30 06:50:21.597080:  
2025-08-30 06:50:21.605113: Epoch 510 
2025-08-30 06:50:21.609512: Current learning rate: 0.00053 
2025-08-30 06:50:48.223337: train_loss -0.6083 
2025-08-30 06:50:48.231946: val_loss -0.5013 
2025-08-30 06:50:48.240107: Pseudo dice [np.float32(0.7789)] 
2025-08-30 06:50:48.245736: Epoch time: 26.63 s 
2025-08-30 06:50:48.903243:  
2025-08-30 06:50:48.911575: Epoch 511 
2025-08-30 06:50:48.915996: Current learning rate: 0.00053 
2025-08-30 06:51:15.813358: train_loss -0.5945 
2025-08-30 06:51:15.821738: val_loss -0.6529 
2025-08-30 06:51:15.825870: Pseudo dice [np.float32(0.8009)] 
2025-08-30 06:51:15.832274: Epoch time: 26.91 s 
2025-08-30 06:51:16.459882:  
2025-08-30 06:51:16.468175: Epoch 512 
2025-08-30 06:51:16.472384: Current learning rate: 0.00052 
2025-08-30 06:51:43.274094: train_loss -0.5982 
2025-08-30 06:51:43.282914: val_loss -0.646 
2025-08-30 06:51:43.286785: Pseudo dice [np.float32(0.792)] 
2025-08-30 06:51:43.294946: Epoch time: 26.81 s 
2025-08-30 06:51:43.916424:  
2025-08-30 06:51:43.925131: Epoch 513 
2025-08-30 06:51:43.928948: Current learning rate: 0.00052 
2025-08-30 06:52:10.543059: train_loss -0.5667 
2025-08-30 06:52:10.551141: val_loss -0.6251 
2025-08-30 06:52:10.555899: Pseudo dice [np.float32(0.8098)] 
2025-08-30 06:52:10.561093: Epoch time: 26.63 s 
2025-08-30 06:52:11.338225:  
2025-08-30 06:52:11.346291: Epoch 514 
2025-08-30 06:52:11.351469: Current learning rate: 0.00052 
2025-08-30 06:52:38.158938: train_loss -0.5988 
2025-08-30 06:52:38.166433: val_loss -0.6756 
2025-08-30 06:52:38.170894: Pseudo dice [np.float32(0.8207)] 
2025-08-30 06:52:38.179440: Epoch time: 26.82 s 
2025-08-30 06:52:38.796333:  
2025-08-30 06:52:38.804679: Epoch 515 
2025-08-30 06:52:38.809034: Current learning rate: 0.00052 
2025-08-30 06:53:06.216006: train_loss -0.6008 
2025-08-30 06:53:06.223643: val_loss -0.6019 
2025-08-30 06:53:06.227814: Pseudo dice [np.float32(0.7557)] 
2025-08-30 06:53:06.235803: Epoch time: 27.42 s 
2025-08-30 06:53:06.907955:  
2025-08-30 06:53:06.916411: Epoch 516 
2025-08-30 06:53:06.920512: Current learning rate: 0.00052 
2025-08-30 06:53:34.076440: train_loss -0.5877 
2025-08-30 06:53:34.089270: val_loss -0.6 
2025-08-30 06:53:34.093435: Pseudo dice [np.float32(0.7862)] 
2025-08-30 06:53:34.100434: Epoch time: 27.17 s 
2025-08-30 06:53:34.722906:  
2025-08-30 06:53:34.731299: Epoch 517 
2025-08-30 06:53:34.735458: Current learning rate: 0.00052 
2025-08-30 06:54:02.041930: train_loss -0.6012 
2025-08-30 06:54:02.050509: val_loss -0.6802 
2025-08-30 06:54:02.054784: Pseudo dice [np.float32(0.8293)] 
2025-08-30 06:54:02.063487: Epoch time: 27.32 s 
2025-08-30 06:54:02.700845:  
2025-08-30 06:54:02.705025: Epoch 518 
2025-08-30 06:54:02.714105: Current learning rate: 0.00052 
2025-08-30 06:54:29.565676: train_loss -0.6439 
2025-08-30 06:54:29.573848: val_loss -0.6304 
2025-08-30 06:54:29.582232: Pseudo dice [np.float32(0.7999)] 
2025-08-30 06:54:29.586865: Epoch time: 26.87 s 
2025-08-30 06:54:30.215475:  
2025-08-30 06:54:30.223533: Epoch 519 
2025-08-30 06:54:30.228362: Current learning rate: 0.00052 
2025-08-30 06:54:57.522267: train_loss -0.6158 
2025-08-30 06:54:57.530609: val_loss -0.5106 
2025-08-30 06:54:57.534809: Pseudo dice [np.float32(0.7694)] 
2025-08-30 06:54:57.542101: Epoch time: 27.31 s 
2025-08-30 06:54:58.168889:  
2025-08-30 06:54:58.177131: Epoch 520 
2025-08-30 06:54:58.181251: Current learning rate: 0.00052 
2025-08-30 06:55:25.352362: train_loss -0.5891 
2025-08-30 06:55:25.358419: val_loss -0.5587 
2025-08-30 06:55:25.362563: Pseudo dice [np.float32(0.791)] 
2025-08-30 06:55:25.369702: Epoch time: 27.18 s 
2025-08-30 06:55:26.159187:  
2025-08-30 06:55:26.167568: Epoch 521 
2025-08-30 06:55:26.172044: Current learning rate: 0.00052 
2025-08-30 06:55:53.299465: train_loss -0.5985 
2025-08-30 06:55:53.307133: val_loss -0.5855 
2025-08-30 06:55:53.311595: Pseudo dice [np.float32(0.7703)] 
2025-08-30 06:55:53.319599: Epoch time: 27.14 s 
2025-08-30 06:55:53.945275:  
2025-08-30 06:55:53.953650: Epoch 522 
2025-08-30 06:55:53.957775: Current learning rate: 0.00051 
2025-08-30 06:56:21.072433: train_loss -0.6002 
2025-08-30 06:56:21.080772: val_loss -0.654 
2025-08-30 06:56:21.085182: Pseudo dice [np.float32(0.8309)] 
2025-08-30 06:56:21.091220: Epoch time: 27.13 s 
2025-08-30 06:56:21.714662:  
2025-08-30 06:56:21.723010: Epoch 523 
2025-08-30 06:56:21.727210: Current learning rate: 0.00051 
2025-08-30 06:56:48.729500: train_loss -0.6119 
2025-08-30 06:56:48.737581: val_loss -0.657 
2025-08-30 06:56:48.745915: Pseudo dice [np.float32(0.8228)] 
2025-08-30 06:56:48.750870: Epoch time: 27.02 s 
2025-08-30 06:56:48.755989: Yayy! New best EMA pseudo Dice: 0.7947999835014343 
2025-08-30 06:56:49.596724:  
2025-08-30 06:56:49.605074: Epoch 524 
2025-08-30 06:56:49.609500: Current learning rate: 0.00051 
2025-08-30 06:57:16.532171: train_loss -0.5755 
2025-08-30 06:57:16.540530: val_loss -0.5539 
2025-08-30 06:57:16.544757: Pseudo dice [np.float32(0.7544)] 
2025-08-30 06:57:16.553811: Epoch time: 26.94 s 
2025-08-30 06:57:17.178481:  
2025-08-30 06:57:17.188006: Epoch 525 
2025-08-30 06:57:17.195122: Current learning rate: 0.00051 
2025-08-30 06:57:43.921850: train_loss -0.6031 
2025-08-30 06:57:43.930191: val_loss -0.6303 
2025-08-30 06:57:43.938160: Pseudo dice [np.float32(0.777)] 
2025-08-30 06:57:43.942623: Epoch time: 26.74 s 
2025-08-30 06:57:44.564054:  
2025-08-30 06:57:44.568269: Epoch 526 
2025-08-30 06:57:44.576615: Current learning rate: 0.00051 
2025-08-30 06:58:11.862217: train_loss -0.6343 
2025-08-30 06:58:11.870498: val_loss -0.5657 
2025-08-30 06:58:11.874885: Pseudo dice [np.float32(0.7936)] 
2025-08-30 06:58:11.882016: Epoch time: 27.3 s 
2025-08-30 06:58:12.500340:  
2025-08-30 06:58:12.508678: Epoch 527 
2025-08-30 06:58:12.513164: Current learning rate: 0.00051 
2025-08-30 06:58:39.673282: train_loss -0.6415 
2025-08-30 06:58:39.685812: val_loss -0.6411 
2025-08-30 06:58:39.689935: Pseudo dice [np.float32(0.7914)] 
2025-08-30 06:58:39.697311: Epoch time: 27.17 s 
2025-08-30 06:58:40.490797:  
2025-08-30 06:58:40.499174: Epoch 528 
2025-08-30 06:58:40.507441: Current learning rate: 0.00051 
2025-08-30 06:59:07.693183: train_loss -0.5755 
2025-08-30 06:59:07.701250: val_loss -0.622 
2025-08-30 06:59:07.705712: Pseudo dice [np.float32(0.81)] 
2025-08-30 06:59:07.712590: Epoch time: 27.2 s 
2025-08-30 06:59:08.335201:  
2025-08-30 06:59:08.346560: Epoch 529 
2025-08-30 06:59:08.352252: Current learning rate: 0.00051 
2025-08-30 06:59:35.312494: train_loss -0.6267 
2025-08-30 06:59:35.320561: val_loss -0.6297 
2025-08-30 06:59:35.324922: Pseudo dice [np.float32(0.8031)] 
2025-08-30 06:59:35.333098: Epoch time: 26.98 s 
2025-08-30 06:59:35.975348:  
2025-08-30 06:59:35.979515: Epoch 530 
2025-08-30 06:59:35.987823: Current learning rate: 0.00051 
2025-08-30 07:00:02.497616: train_loss -0.6418 
2025-08-30 07:00:02.505970: val_loss -0.644 
2025-08-30 07:00:02.510141: Pseudo dice [np.float32(0.7911)] 
2025-08-30 07:00:02.518313: Epoch time: 26.53 s 
2025-08-30 07:00:03.148270:  
2025-08-30 07:00:03.156634: Epoch 531 
2025-08-30 07:00:03.161867: Current learning rate: 0.00051 
2025-08-30 07:00:30.033871: train_loss -0.6048 
2025-08-30 07:00:30.041847: val_loss -0.638 
2025-08-30 07:00:30.045999: Pseudo dice [np.float32(0.8086)] 
2025-08-30 07:00:30.053199: Epoch time: 26.89 s 
2025-08-30 07:00:30.742542:  
2025-08-30 07:00:30.746716: Epoch 532 
2025-08-30 07:00:30.755039: Current learning rate: 0.0005 
2025-08-30 07:00:57.690256: train_loss -0.5852 
2025-08-30 07:00:57.694419: val_loss -0.6203 
2025-08-30 07:00:57.702773: Pseudo dice [np.float32(0.8166)] 
2025-08-30 07:00:57.710079: Epoch time: 26.95 s 
2025-08-30 07:00:57.715627: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2025-08-30 07:00:58.549681:  
2025-08-30 07:00:58.558073: Epoch 533 
2025-08-30 07:00:58.562305: Current learning rate: 0.0005 
2025-08-30 07:01:25.597599: train_loss -0.6156 
2025-08-30 07:01:25.605939: val_loss -0.6174 
2025-08-30 07:01:25.613966: Pseudo dice [np.float32(0.7805)] 
2025-08-30 07:01:25.621374: Epoch time: 27.05 s 
2025-08-30 07:01:26.256289:  
2025-08-30 07:01:26.264979: Epoch 534 
2025-08-30 07:01:26.273056: Current learning rate: 0.0005 
2025-08-30 07:01:53.329112: train_loss -0.5732 
2025-08-30 07:01:53.338725: val_loss -0.5761 
2025-08-30 07:01:53.344027: Pseudo dice [np.float32(0.7751)] 
2025-08-30 07:01:53.349663: Epoch time: 27.07 s 
2025-08-30 07:01:54.129966:  
2025-08-30 07:01:54.138317: Epoch 535 
2025-08-30 07:01:54.142489: Current learning rate: 0.0005 
2025-08-30 07:02:21.065219: train_loss -0.6103 
2025-08-30 07:02:21.073841: val_loss -0.6437 
2025-08-30 07:02:21.081877: Pseudo dice [np.float32(0.814)] 
2025-08-30 07:02:21.086840: Epoch time: 26.94 s 
2025-08-30 07:02:21.707474:  
2025-08-30 07:02:21.715867: Epoch 536 
2025-08-30 07:02:21.720029: Current learning rate: 0.0005 
2025-08-30 07:02:48.793162: train_loss -0.5806 
2025-08-30 07:02:48.805368: val_loss -0.6186 
2025-08-30 07:02:48.809776: Pseudo dice [np.float32(0.8017)] 
2025-08-30 07:02:48.815815: Epoch time: 27.09 s 
2025-08-30 07:02:49.430998:  
2025-08-30 07:02:49.439345: Epoch 537 
2025-08-30 07:02:49.443512: Current learning rate: 0.0005 
2025-08-30 07:03:16.225981: train_loss -0.6371 
2025-08-30 07:03:16.232754: val_loss -0.6041 
2025-08-30 07:03:16.236916: Pseudo dice [np.float32(0.8143)] 
2025-08-30 07:03:16.245239: Epoch time: 26.79 s 
2025-08-30 07:03:16.251037: Yayy! New best EMA pseudo Dice: 0.7976999878883362 
2025-08-30 07:03:17.096177:  
2025-08-30 07:03:17.100694: Epoch 538 
2025-08-30 07:03:17.108737: Current learning rate: 0.0005 
2025-08-30 07:03:43.993844: train_loss -0.6481 
2025-08-30 07:03:44.002142: val_loss -0.6642 
2025-08-30 07:03:44.006664: Pseudo dice [np.float32(0.8113)] 
2025-08-30 07:03:44.014769: Epoch time: 26.9 s 
2025-08-30 07:03:44.020314: Yayy! New best EMA pseudo Dice: 0.7990000247955322 
2025-08-30 07:03:44.848757:  
2025-08-30 07:03:44.857934: Epoch 539 
2025-08-30 07:03:44.861796: Current learning rate: 0.0005 
2025-08-30 07:04:11.450400: train_loss -0.5946 
2025-08-30 07:04:11.458776: val_loss -0.623 
2025-08-30 07:04:11.462943: Pseudo dice [np.float32(0.7859)] 
2025-08-30 07:04:11.472393: Epoch time: 26.6 s 
2025-08-30 07:04:12.101043:  
2025-08-30 07:04:12.105221: Epoch 540 
2025-08-30 07:04:12.113592: Current learning rate: 0.0005 
2025-08-30 07:04:39.653576: train_loss -0.6131 
2025-08-30 07:04:39.661911: val_loss -0.6539 
2025-08-30 07:04:39.670236: Pseudo dice [np.float32(0.8331)] 
2025-08-30 07:04:39.676566: Epoch time: 27.56 s 
2025-08-30 07:04:39.683738: Yayy! New best EMA pseudo Dice: 0.8011999726295471 
2025-08-30 07:04:40.717144:  
2025-08-30 07:04:40.725497: Epoch 541 
2025-08-30 07:04:40.729612: Current learning rate: 0.0005 
2025-08-30 07:05:07.656564: train_loss -0.6033 
2025-08-30 07:05:07.664844: val_loss -0.6002 
2025-08-30 07:05:07.669338: Pseudo dice [np.float32(0.7797)] 
2025-08-30 07:05:07.678277: Epoch time: 26.94 s 
2025-08-30 07:05:08.307452:  
2025-08-30 07:05:08.315542: Epoch 542 
2025-08-30 07:05:08.319670: Current learning rate: 0.0005 
2025-08-30 07:05:35.292963: train_loss -0.5721 
2025-08-30 07:05:35.300815: val_loss -0.5738 
2025-08-30 07:05:35.304976: Pseudo dice [np.float32(0.7567)] 
2025-08-30 07:05:35.313355: Epoch time: 26.99 s 
2025-08-30 07:05:35.943078:  
2025-08-30 07:05:35.947191: Epoch 543 
2025-08-30 07:05:35.955654: Current learning rate: 0.00049 
2025-08-30 07:06:02.741045: train_loss -0.6114 
2025-08-30 07:06:02.749363: val_loss -0.5558 
2025-08-30 07:06:02.753206: Pseudo dice [np.float32(0.8019)] 
2025-08-30 07:06:02.761647: Epoch time: 26.8 s 
2025-08-30 07:06:03.379181:  
2025-08-30 07:06:03.387201: Epoch 544 
2025-08-30 07:06:03.391351: Current learning rate: 0.00049 
2025-08-30 07:06:30.649820: train_loss -0.6072 
2025-08-30 07:06:30.656404: val_loss -0.5885 
2025-08-30 07:06:30.665231: Pseudo dice [np.float32(0.821)] 
2025-08-30 07:06:30.670125: Epoch time: 27.27 s 
2025-08-30 07:06:31.298413:  
2025-08-30 07:06:31.302593: Epoch 545 
2025-08-30 07:06:31.311019: Current learning rate: 0.00049 
2025-08-30 07:06:58.892588: train_loss -0.6315 
2025-08-30 07:06:58.900981: val_loss -0.6707 
2025-08-30 07:06:58.905020: Pseudo dice [np.float32(0.7952)] 
2025-08-30 07:06:58.913235: Epoch time: 27.6 s 
2025-08-30 07:06:59.534744:  
2025-08-30 07:06:59.539163: Epoch 546 
2025-08-30 07:06:59.547422: Current learning rate: 0.00049 
2025-08-30 07:07:26.595460: train_loss -0.5822 
2025-08-30 07:07:26.607774: val_loss -0.6527 
2025-08-30 07:07:26.616150: Pseudo dice [np.float32(0.8312)] 
2025-08-30 07:07:26.622351: Epoch time: 27.06 s 
2025-08-30 07:07:27.404771:  
2025-08-30 07:07:27.412769: Epoch 547 
2025-08-30 07:07:27.416928: Current learning rate: 0.00049 
2025-08-30 07:07:54.607061: train_loss -0.5732 
2025-08-30 07:07:54.615430: val_loss -0.6102 
2025-08-30 07:07:54.623592: Pseudo dice [np.float32(0.8087)] 
2025-08-30 07:07:54.628342: Epoch time: 27.2 s 
2025-08-30 07:07:54.632504: Yayy! New best EMA pseudo Dice: 0.8019000291824341 
2025-08-30 07:07:55.482442:  
2025-08-30 07:07:55.490798: Epoch 548 
2025-08-30 07:07:55.495338: Current learning rate: 0.00049 
2025-08-30 07:08:21.675817: train_loss -0.6242 
2025-08-30 07:08:21.683610: val_loss -0.6544 
2025-08-30 07:08:21.688063: Pseudo dice [np.float32(0.7727)] 
2025-08-30 07:08:21.696986: Epoch time: 26.19 s 
2025-08-30 07:08:22.325972:  
2025-08-30 07:08:22.334526: Epoch 549 
2025-08-30 07:08:22.341224: Current learning rate: 0.00049 
2025-08-30 07:08:48.969517: train_loss -0.5708 
2025-08-30 07:08:48.977612: val_loss -0.5585 
2025-08-30 07:08:48.982080: Pseudo dice [np.float32(0.7925)] 
2025-08-30 07:08:48.987847: Epoch time: 26.64 s 
2025-08-30 07:08:49.824548:  
2025-08-30 07:08:49.832932: Epoch 550 
2025-08-30 07:08:49.839913: Current learning rate: 0.00049 
2025-08-30 07:09:17.583078: train_loss -0.5821 
2025-08-30 07:09:17.589785: val_loss -0.5397 
2025-08-30 07:09:17.597574: Pseudo dice [np.float32(0.7904)] 
2025-08-30 07:09:17.602715: Epoch time: 27.76 s 
2025-08-30 07:09:18.231722:  
2025-08-30 07:09:18.240114: Epoch 551 
2025-08-30 07:09:18.244255: Current learning rate: 0.00049 
2025-08-30 07:09:45.622530: train_loss -0.6027 
2025-08-30 07:09:45.629941: val_loss -0.6046 
2025-08-30 07:09:45.634096: Pseudo dice [np.float32(0.8015)] 
2025-08-30 07:09:45.643251: Epoch time: 27.39 s 
2025-08-30 07:09:46.276703:  
2025-08-30 07:09:46.285238: Epoch 552 
2025-08-30 07:09:46.289579: Current learning rate: 0.00049 
2025-08-30 07:10:12.990651: train_loss -0.6236 
2025-08-30 07:10:12.998959: val_loss -0.6074 
2025-08-30 07:10:13.003399: Pseudo dice [np.float32(0.8149)] 
2025-08-30 07:10:13.011502: Epoch time: 26.71 s 
2025-08-30 07:10:13.649681:  
2025-08-30 07:10:13.658299: Epoch 553 
2025-08-30 07:10:13.662396: Current learning rate: 0.00048 
2025-08-30 07:10:41.356682: train_loss -0.6391 
2025-08-30 07:10:41.364755: val_loss -0.5649 
2025-08-30 07:10:41.368930: Pseudo dice [np.float32(0.8335)] 
2025-08-30 07:10:41.377383: Epoch time: 27.71 s 
2025-08-30 07:10:41.382387: Yayy! New best EMA pseudo Dice: 0.8029999732971191 
2025-08-30 07:10:42.407229:  
2025-08-30 07:10:42.411926: Epoch 554 
2025-08-30 07:10:42.419997: Current learning rate: 0.00048 
2025-08-30 07:11:09.426324: train_loss -0.6455 
2025-08-30 07:11:09.434481: val_loss -0.6208 
2025-08-30 07:11:09.438939: Pseudo dice [np.float32(0.7754)] 
2025-08-30 07:11:09.444860: Epoch time: 27.02 s 
2025-08-30 07:11:10.064311:  
2025-08-30 07:11:10.068517: Epoch 555 
2025-08-30 07:11:10.076557: Current learning rate: 0.00048 
2025-08-30 07:11:37.400091: train_loss -0.62 
2025-08-30 07:11:37.408208: val_loss -0.6912 
2025-08-30 07:11:37.412569: Pseudo dice [np.float32(0.8262)] 
2025-08-30 07:11:37.420478: Epoch time: 27.34 s 
2025-08-30 07:11:38.042199:  
2025-08-30 07:11:38.050872: Epoch 556 
2025-08-30 07:11:38.054990: Current learning rate: 0.00048 
2025-08-30 07:12:05.298988: train_loss -0.6249 
2025-08-30 07:12:05.307223: val_loss -0.5478 
2025-08-30 07:12:05.311445: Pseudo dice [np.float32(0.7858)] 
2025-08-30 07:12:05.319231: Epoch time: 27.26 s 
2025-08-30 07:12:05.945037:  
2025-08-30 07:12:05.950320: Epoch 557 
2025-08-30 07:12:05.957611: Current learning rate: 0.00048 
2025-08-30 07:12:33.631006: train_loss -0.6018 
2025-08-30 07:12:33.643542: val_loss -0.568 
2025-08-30 07:12:33.647687: Pseudo dice [np.float32(0.7584)] 
2025-08-30 07:12:33.655161: Epoch time: 27.69 s 
2025-08-30 07:12:34.286232:  
2025-08-30 07:12:34.294742: Epoch 558 
2025-08-30 07:12:34.302945: Current learning rate: 0.00048 
2025-08-30 07:13:01.183787: train_loss -0.642 
2025-08-30 07:13:01.191849: val_loss -0.6332 
2025-08-30 07:13:01.196366: Pseudo dice [np.float32(0.8037)] 
2025-08-30 07:13:01.203579: Epoch time: 26.9 s 
2025-08-30 07:13:01.846653:  
2025-08-30 07:13:01.854965: Epoch 559 
2025-08-30 07:13:01.859524: Current learning rate: 0.00048 
2025-08-30 07:13:29.624952: train_loss -0.5994 
2025-08-30 07:13:29.637306: val_loss -0.5843 
2025-08-30 07:13:29.641423: Pseudo dice [np.float32(0.7893)] 
2025-08-30 07:13:29.647392: Epoch time: 27.78 s 
2025-08-30 07:13:30.421320:  
2025-08-30 07:13:30.429395: Epoch 560 
2025-08-30 07:13:30.438210: Current learning rate: 0.00048 
2025-08-30 07:13:57.773620: train_loss -0.6033 
2025-08-30 07:13:57.781711: val_loss -0.5396 
2025-08-30 07:13:57.790096: Pseudo dice [np.float32(0.7592)] 
2025-08-30 07:13:57.795445: Epoch time: 27.35 s 
2025-08-30 07:13:58.424048:  
2025-08-30 07:13:58.432456: Epoch 561 
2025-08-30 07:13:58.436879: Current learning rate: 0.00048 
2025-08-30 07:14:25.905735: train_loss -0.6054 
2025-08-30 07:14:25.913968: val_loss -0.5955 
2025-08-30 07:14:25.922835: Pseudo dice [np.float32(0.7881)] 
2025-08-30 07:14:25.927611: Epoch time: 27.48 s 
2025-08-30 07:14:26.543766:  
2025-08-30 07:14:26.552157: Epoch 562 
2025-08-30 07:14:26.556313: Current learning rate: 0.00048 
2025-08-30 07:14:53.533680: train_loss -0.626 
2025-08-30 07:14:53.545831: val_loss -0.6601 
2025-08-30 07:14:53.549926: Pseudo dice [np.float32(0.8015)] 
2025-08-30 07:14:53.557040: Epoch time: 26.99 s 
2025-08-30 07:14:54.179881:  
2025-08-30 07:14:54.188082: Epoch 563 
2025-08-30 07:14:54.192438: Current learning rate: 0.00047 
2025-08-30 07:15:21.294364: train_loss -0.6145 
2025-08-30 07:15:21.302674: val_loss -0.6259 
2025-08-30 07:15:21.306868: Pseudo dice [np.float32(0.8332)] 
2025-08-30 07:15:21.313988: Epoch time: 27.11 s 
2025-08-30 07:15:21.961582:  
2025-08-30 07:15:21.973904: Epoch 564 
2025-08-30 07:15:21.978789: Current learning rate: 0.00047 
2025-08-30 07:15:49.443213: train_loss -0.5846 
2025-08-30 07:15:49.451985: val_loss -0.6417 
2025-08-30 07:15:49.456854: Pseudo dice [np.float32(0.7782)] 
2025-08-30 07:15:49.464165: Epoch time: 27.48 s 
2025-08-30 07:15:50.094202:  
2025-08-30 07:15:50.102549: Epoch 565 
2025-08-30 07:15:50.110241: Current learning rate: 0.00047 
2025-08-30 07:16:17.943063: train_loss -0.6231 
2025-08-30 07:16:17.950842: val_loss -0.595 
2025-08-30 07:16:17.955030: Pseudo dice [np.float32(0.8071)] 
2025-08-30 07:16:17.962219: Epoch time: 27.85 s 
2025-08-30 07:16:18.600697:  
2025-08-30 07:16:18.607208: Epoch 566 
2025-08-30 07:16:18.611840: Current learning rate: 0.00047 
2025-08-30 07:16:46.208230: train_loss -0.594 
2025-08-30 07:16:46.220747: val_loss -0.6123 
2025-08-30 07:16:46.224908: Pseudo dice [np.float32(0.8035)] 
2025-08-30 07:16:46.232457: Epoch time: 27.61 s 
2025-08-30 07:16:47.025703:  
2025-08-30 07:16:47.029918: Epoch 567 
2025-08-30 07:16:47.038209: Current learning rate: 0.00047 
2025-08-30 07:17:14.528258: train_loss -0.5822 
2025-08-30 07:17:14.536508: val_loss -0.6238 
2025-08-30 07:17:14.544868: Pseudo dice [np.float32(0.7758)] 
2025-08-30 07:17:14.553112: Epoch time: 27.51 s 
2025-08-30 07:17:15.183084:  
2025-08-30 07:17:15.191640: Epoch 568 
2025-08-30 07:17:15.195801: Current learning rate: 0.00047 
2025-08-30 07:17:42.673309: train_loss -0.6207 
2025-08-30 07:17:42.681605: val_loss -0.6181 
2025-08-30 07:17:42.689667: Pseudo dice [np.float32(0.8142)] 
2025-08-30 07:17:42.695790: Epoch time: 27.49 s 
2025-08-30 07:17:43.311083:  
2025-08-30 07:17:43.319430: Epoch 569 
2025-08-30 07:17:43.327808: Current learning rate: 0.00047 
2025-08-30 07:18:10.463521: train_loss -0.6034 
2025-08-30 07:18:10.471416: val_loss -0.6662 
2025-08-30 07:18:10.476035: Pseudo dice [np.float32(0.8136)] 
2025-08-30 07:18:10.481815: Epoch time: 27.15 s 
2025-08-30 07:18:11.115932:  
2025-08-30 07:18:11.122249: Epoch 570 
2025-08-30 07:18:11.130530: Current learning rate: 0.00047 
2025-08-30 07:18:38.796261: train_loss -0.6122 
2025-08-30 07:18:38.804110: val_loss -0.6279 
2025-08-30 07:18:38.812737: Pseudo dice [np.float32(0.803)] 
2025-08-30 07:18:38.817293: Epoch time: 27.68 s 
2025-08-30 07:18:39.434036:  
2025-08-30 07:18:39.442131: Epoch 571 
2025-08-30 07:18:39.446306: Current learning rate: 0.00047 
2025-08-30 07:19:06.653026: train_loss -0.5953 
2025-08-30 07:19:06.661228: val_loss -0.6055 
2025-08-30 07:19:06.665215: Pseudo dice [np.float32(0.7716)] 
2025-08-30 07:19:06.673264: Epoch time: 27.22 s 
2025-08-30 07:19:07.294940:  
2025-08-30 07:19:07.303280: Epoch 572 
2025-08-30 07:19:07.307450: Current learning rate: 0.00047 
2025-08-30 07:19:34.897480: train_loss -0.6177 
2025-08-30 07:19:34.910044: val_loss -0.6213 
2025-08-30 07:19:34.914190: Pseudo dice [np.float32(0.7795)] 
2025-08-30 07:19:34.920249: Epoch time: 27.6 s 
2025-08-30 07:19:35.552631:  
2025-08-30 07:19:35.560690: Epoch 573 
2025-08-30 07:19:35.564859: Current learning rate: 0.00046 
2025-08-30 07:20:01.803587: train_loss -0.5865 
2025-08-30 07:20:01.812128: val_loss -0.578 
2025-08-30 07:20:01.816103: Pseudo dice [np.float32(0.7481)] 
2025-08-30 07:20:01.825306: Epoch time: 26.25 s 
2025-08-30 07:20:02.619291:  
2025-08-30 07:20:02.625213: Epoch 574 
2025-08-30 07:20:02.629375: Current learning rate: 0.00046 
2025-08-30 07:20:28.688735: train_loss -0.5776 
2025-08-30 07:20:28.699862: val_loss -0.6291 
2025-08-30 07:20:28.705416: Pseudo dice [np.float32(0.8069)] 
2025-08-30 07:20:28.711202: Epoch time: 26.07 s 
2025-08-30 07:20:29.335186:  
2025-08-30 07:20:29.347209: Epoch 575 
2025-08-30 07:20:29.352240: Current learning rate: 0.00046 
2025-08-30 07:20:55.603537: train_loss -0.615 
2025-08-30 07:20:55.615614: val_loss -0.5686 
2025-08-30 07:20:55.620165: Pseudo dice [np.float32(0.8043)] 
2025-08-30 07:20:55.629066: Epoch time: 26.27 s 
2025-08-30 07:20:56.286725:  
2025-08-30 07:20:56.291280: Epoch 576 
2025-08-30 07:20:56.295455: Current learning rate: 0.00046 
2025-08-30 07:21:22.880320: train_loss -0.6476 
2025-08-30 07:21:22.888690: val_loss -0.63 
2025-08-30 07:21:22.893098: Pseudo dice [np.float32(0.804)] 
2025-08-30 07:21:22.898303: Epoch time: 26.6 s 
2025-08-30 07:21:23.530972:  
2025-08-30 07:21:23.539852: Epoch 577 
2025-08-30 07:21:23.543779: Current learning rate: 0.00046 
2025-08-30 07:21:49.548626: train_loss -0.6193 
2025-08-30 07:21:49.557035: val_loss -0.5928 
2025-08-30 07:21:49.561208: Pseudo dice [np.float32(0.7949)] 
2025-08-30 07:21:49.569265: Epoch time: 26.02 s 
2025-08-30 07:21:50.199559:  
2025-08-30 07:21:50.203740: Epoch 578 
2025-08-30 07:21:50.212192: Current learning rate: 0.00046 
2025-08-30 07:22:16.408752: train_loss -0.6317 
2025-08-30 07:22:16.417126: val_loss -0.5878 
2025-08-30 07:22:16.421597: Pseudo dice [np.float32(0.7823)] 
2025-08-30 07:22:16.429528: Epoch time: 26.21 s 
2025-08-30 07:22:17.059495:  
2025-08-30 07:22:17.067904: Epoch 579 
2025-08-30 07:22:17.072250: Current learning rate: 0.00046 
2025-08-30 07:22:43.419074: train_loss -0.6197 
2025-08-30 07:22:43.431638: val_loss -0.545 
2025-08-30 07:22:43.435760: Pseudo dice [np.float32(0.7521)] 
2025-08-30 07:22:43.442084: Epoch time: 26.36 s 
2025-08-30 07:22:44.228228:  
2025-08-30 07:22:44.236929: Epoch 580 
2025-08-30 07:22:44.241492: Current learning rate: 0.00046 
2025-08-30 07:23:10.981310: train_loss -0.6011 
2025-08-30 07:23:10.988287: val_loss -0.5774 
2025-08-30 07:23:10.992428: Pseudo dice [np.float32(0.7897)] 
2025-08-30 07:23:11.001883: Epoch time: 26.75 s 
2025-08-30 07:23:11.626785:  
2025-08-30 07:23:11.634830: Epoch 581 
2025-08-30 07:23:11.643465: Current learning rate: 0.00046 
2025-08-30 07:23:38.549135: train_loss -0.5887 
2025-08-30 07:23:38.561671: val_loss -0.6533 
2025-08-30 07:23:38.569890: Pseudo dice [np.float32(0.8204)] 
2025-08-30 07:23:38.576325: Epoch time: 26.92 s 
2025-08-30 07:23:39.204333:  
2025-08-30 07:23:39.212650: Epoch 582 
2025-08-30 07:23:39.216464: Current learning rate: 0.00046 
2025-08-30 07:24:06.344257: train_loss -0.6135 
2025-08-30 07:24:06.351891: val_loss -0.6644 
2025-08-30 07:24:06.356379: Pseudo dice [np.float32(0.7919)] 
2025-08-30 07:24:06.365109: Epoch time: 27.14 s 
2025-08-30 07:24:06.994226:  
2025-08-30 07:24:07.002580: Epoch 583 
2025-08-30 07:24:07.007157: Current learning rate: 0.00046 
2025-08-30 07:24:34.271668: train_loss -0.6213 
2025-08-30 07:24:34.284108: val_loss -0.5499 
2025-08-30 07:24:34.288470: Pseudo dice [np.float32(0.804)] 
2025-08-30 07:24:34.293627: Epoch time: 27.28 s 
2025-08-30 07:24:34.926273:  
2025-08-30 07:24:34.934641: Epoch 584 
2025-08-30 07:24:34.938740: Current learning rate: 0.00045 
2025-08-30 07:25:00.456206: train_loss -0.6376 
2025-08-30 07:25:00.464609: val_loss -0.7083 
2025-08-30 07:25:00.468411: Pseudo dice [np.float32(0.8482)] 
2025-08-30 07:25:00.475745: Epoch time: 25.53 s 
2025-08-30 07:25:01.111053:  
2025-08-30 07:25:01.119123: Epoch 585 
2025-08-30 07:25:01.123261: Current learning rate: 0.00045 
2025-08-30 07:25:26.621140: train_loss -0.6117 
2025-08-30 07:25:26.627927: val_loss -0.564 
2025-08-30 07:25:26.636879: Pseudo dice [np.float32(0.782)] 
2025-08-30 07:25:26.641837: Epoch time: 25.51 s 
2025-08-30 07:25:27.282752:  
2025-08-30 07:25:27.291051: Epoch 586 
2025-08-30 07:25:27.299408: Current learning rate: 0.00045 
2025-08-30 07:25:53.064144: train_loss -0.5691 
2025-08-30 07:25:53.071777: val_loss -0.562 
2025-08-30 07:25:53.079357: Pseudo dice [np.float32(0.843)] 
2025-08-30 07:25:53.084348: Epoch time: 25.79 s 
2025-08-30 07:25:53.884284:  
2025-08-30 07:25:53.892628: Epoch 587 
2025-08-30 07:25:53.897104: Current learning rate: 0.00045 
2025-08-30 07:26:19.447325: train_loss -0.6067 
2025-08-30 07:26:19.455484: val_loss -0.5958 
2025-08-30 07:26:19.460163: Pseudo dice [np.float32(0.8046)] 
2025-08-30 07:26:19.465998: Epoch time: 25.57 s 
2025-08-30 07:26:20.093759:  
2025-08-30 07:26:20.097976: Epoch 588 
2025-08-30 07:26:20.106297: Current learning rate: 0.00045 
2025-08-30 07:26:45.465734: train_loss -0.6027 
2025-08-30 07:26:45.474029: val_loss -0.6079 
2025-08-30 07:26:45.481850: Pseudo dice [np.float32(0.8072)] 
2025-08-30 07:26:45.488191: Epoch time: 25.38 s 
2025-08-30 07:26:46.115659:  
2025-08-30 07:26:46.124001: Epoch 589 
2025-08-30 07:26:46.132568: Current learning rate: 0.00045 
2025-08-30 07:27:11.549409: train_loss -0.5721 
2025-08-30 07:27:11.557658: val_loss -0.6281 
2025-08-30 07:27:11.561807: Pseudo dice [np.float32(0.8163)] 
2025-08-30 07:27:11.570251: Epoch time: 25.43 s 
2025-08-30 07:27:11.575330: Yayy! New best EMA pseudo Dice: 0.8039000034332275 
2025-08-30 07:27:12.429708:  
2025-08-30 07:27:12.438080: Epoch 590 
2025-08-30 07:27:12.446121: Current learning rate: 0.00045 
2025-08-30 07:27:38.842282: train_loss -0.5985 
2025-08-30 07:27:38.853184: val_loss -0.5287 
2025-08-30 07:27:38.859266: Pseudo dice [np.float32(0.7696)] 
2025-08-30 07:27:38.864716: Epoch time: 26.41 s 
2025-08-30 07:27:39.485556:  
2025-08-30 07:27:39.493896: Epoch 591 
2025-08-30 07:27:39.500150: Current learning rate: 0.00045 
2025-08-30 07:28:05.286714: train_loss -0.6135 
2025-08-30 07:28:05.294655: val_loss -0.6305 
2025-08-30 07:28:05.299240: Pseudo dice [np.float32(0.8266)] 
2025-08-30 07:28:05.307083: Epoch time: 25.8 s 
2025-08-30 07:28:05.961972:  
2025-08-30 07:28:05.970363: Epoch 592 
2025-08-30 07:28:05.974733: Current learning rate: 0.00045 
2025-08-30 07:28:32.872540: train_loss -0.605 
2025-08-30 07:28:32.884836: val_loss -0.6126 
2025-08-30 07:28:32.889187: Pseudo dice [np.float32(0.8051)] 
2025-08-30 07:28:32.896111: Epoch time: 26.91 s 
2025-08-30 07:28:33.677821:  
2025-08-30 07:28:33.685541: Epoch 593 
2025-08-30 07:28:33.689636: Current learning rate: 0.00045 
2025-08-30 07:28:59.857717: train_loss -0.6283 
2025-08-30 07:28:59.865807: val_loss -0.6856 
2025-08-30 07:28:59.869899: Pseudo dice [np.float32(0.8398)] 
2025-08-30 07:28:59.878084: Epoch time: 26.18 s 
2025-08-30 07:28:59.882832: Yayy! New best EMA pseudo Dice: 0.8069000244140625 
2025-08-30 07:29:00.745898:  
2025-08-30 07:29:00.754431: Epoch 594 
2025-08-30 07:29:00.758698: Current learning rate: 0.00044 
2025-08-30 07:29:27.385042: train_loss -0.6413 
2025-08-30 07:29:27.393401: val_loss -0.5854 
2025-08-30 07:29:27.401628: Pseudo dice [np.float32(0.8013)] 
2025-08-30 07:29:27.407041: Epoch time: 26.64 s 
2025-08-30 07:29:28.035879:  
2025-08-30 07:29:28.044156: Epoch 595 
2025-08-30 07:29:28.048153: Current learning rate: 0.00044 
2025-08-30 07:29:54.311908: train_loss -0.5995 
2025-08-30 07:29:54.320280: val_loss -0.6297 
2025-08-30 07:29:54.328588: Pseudo dice [np.float32(0.8167)] 
2025-08-30 07:29:54.334228: Epoch time: 26.28 s 
2025-08-30 07:29:54.339828: Yayy! New best EMA pseudo Dice: 0.8073999881744385 
2025-08-30 07:29:55.187748:  
2025-08-30 07:29:55.196065: Epoch 596 
2025-08-30 07:29:55.200225: Current learning rate: 0.00044 
2025-08-30 07:30:22.189714: train_loss -0.5868 
2025-08-30 07:30:22.198253: val_loss -0.6223 
2025-08-30 07:30:22.202525: Pseudo dice [np.float32(0.8183)] 
2025-08-30 07:30:22.209661: Epoch time: 27.0 s 
2025-08-30 07:30:22.216320: Yayy! New best EMA pseudo Dice: 0.8084999918937683 
2025-08-30 07:30:23.065845:  
2025-08-30 07:30:23.073986: Epoch 597 
2025-08-30 07:30:23.078394: Current learning rate: 0.00044 
2025-08-30 07:30:49.030850: train_loss -0.6256 
2025-08-30 07:30:49.037693: val_loss -0.5798 
2025-08-30 07:30:49.041499: Pseudo dice [np.float32(0.8216)] 
2025-08-30 07:30:49.049818: Epoch time: 25.97 s 
2025-08-30 07:30:49.054927: Yayy! New best EMA pseudo Dice: 0.8098000288009644 
2025-08-30 07:30:49.913198:  
2025-08-30 07:30:49.921543: Epoch 598 
2025-08-30 07:30:49.926064: Current learning rate: 0.00044 
2025-08-30 07:31:16.464691: train_loss -0.603 
2025-08-30 07:31:16.473347: val_loss -0.5905 
2025-08-30 07:31:16.477537: Pseudo dice [np.float32(0.7526)] 
2025-08-30 07:31:16.484360: Epoch time: 26.55 s 
2025-08-30 07:31:17.273891:  
2025-08-30 07:31:17.282221: Epoch 599 
2025-08-30 07:31:17.290650: Current learning rate: 0.00044 
2025-08-30 07:31:43.775746: train_loss -0.6174 
2025-08-30 07:31:43.784000: val_loss -0.6602 
2025-08-30 07:31:43.787821: Pseudo dice [np.float32(0.8122)] 
2025-08-30 07:31:43.796047: Epoch time: 26.5 s 
2025-08-30 07:31:44.642830:  
2025-08-30 07:31:44.651561: Epoch 600 
2025-08-30 07:31:44.659871: Current learning rate: 0.00044 
2025-08-30 07:32:11.031932: train_loss -0.6068 
2025-08-30 07:32:11.040049: val_loss -0.6319 
2025-08-30 07:32:11.044200: Pseudo dice [np.float32(0.8171)] 
2025-08-30 07:32:11.051329: Epoch time: 26.39 s 
2025-08-30 07:32:11.686498:  
2025-08-30 07:32:11.694926: Epoch 601 
2025-08-30 07:32:11.699324: Current learning rate: 0.00044 
2025-08-30 07:32:37.737590: train_loss -0.6252 
2025-08-30 07:32:37.750273: val_loss -0.6385 
2025-08-30 07:32:37.754575: Pseudo dice [np.float32(0.7818)] 
2025-08-30 07:32:37.762358: Epoch time: 26.06 s 
2025-08-30 07:32:38.396515:  
2025-08-30 07:32:38.404901: Epoch 602 
2025-08-30 07:32:38.409045: Current learning rate: 0.00044 
2025-08-30 07:33:04.314385: train_loss -0.6034 
2025-08-30 07:33:04.322426: val_loss -0.7183 
2025-08-30 07:33:04.330755: Pseudo dice [np.float32(0.8434)] 
2025-08-30 07:33:04.337141: Epoch time: 25.92 s 
2025-08-30 07:33:04.964707:  
2025-08-30 07:33:04.973059: Epoch 603 
2025-08-30 07:33:04.977261: Current learning rate: 0.00044 
2025-08-30 07:33:31.182494: train_loss -0.6246 
2025-08-30 07:33:31.195114: val_loss -0.6137 
2025-08-30 07:33:31.199471: Pseudo dice [np.float32(0.7896)] 
2025-08-30 07:33:31.206527: Epoch time: 26.22 s 
2025-08-30 07:33:31.838599:  
2025-08-30 07:33:31.846215: Epoch 604 
2025-08-30 07:33:31.851496: Current learning rate: 0.00043 
2025-08-30 07:33:58.297666: train_loss -0.6336 
2025-08-30 07:33:58.305813: val_loss -0.6309 
2025-08-30 07:33:58.314198: Pseudo dice [np.float32(0.8238)] 
2025-08-30 07:33:58.319330: Epoch time: 26.46 s 
2025-08-30 07:33:59.114858:  
2025-08-30 07:33:59.118836: Epoch 605 
2025-08-30 07:33:59.127021: Current learning rate: 0.00043 
2025-08-30 07:34:25.245546: train_loss -0.6216 
2025-08-30 07:34:25.253501: val_loss -0.5609 
2025-08-30 07:34:25.257428: Pseudo dice [np.float32(0.8192)] 
2025-08-30 07:34:25.263812: Epoch time: 26.14 s 
2025-08-30 07:34:25.903996:  
2025-08-30 07:34:25.912627: Epoch 606 
2025-08-30 07:34:25.916416: Current learning rate: 0.00043 
2025-08-30 07:34:52.606357: train_loss -0.6392 
2025-08-30 07:34:52.613908: val_loss -0.6146 
2025-08-30 07:34:52.618056: Pseudo dice [np.float32(0.7884)] 
2025-08-30 07:34:52.627452: Epoch time: 26.7 s 
2025-08-30 07:34:53.264868:  
2025-08-30 07:34:53.272879: Epoch 607 
2025-08-30 07:34:53.277025: Current learning rate: 0.00043 
2025-08-30 07:35:20.371218: train_loss -0.6212 
2025-08-30 07:35:20.379093: val_loss -0.6474 
2025-08-30 07:35:20.383492: Pseudo dice [np.float32(0.8031)] 
2025-08-30 07:35:20.392544: Epoch time: 27.11 s 
2025-08-30 07:35:21.025978:  
2025-08-30 07:35:21.034342: Epoch 608 
2025-08-30 07:35:21.038614: Current learning rate: 0.00043 
2025-08-30 07:35:48.478253: train_loss -0.5956 
2025-08-30 07:35:48.486417: val_loss -0.5879 
2025-08-30 07:35:48.490839: Pseudo dice [np.float32(0.7916)] 
2025-08-30 07:35:48.496000: Epoch time: 27.45 s 
2025-08-30 07:35:49.128671:  
2025-08-30 07:35:49.137649: Epoch 609 
2025-08-30 07:35:49.141187: Current learning rate: 0.00043 
2025-08-30 07:36:16.314807: train_loss -0.5871 
2025-08-30 07:36:16.322767: val_loss -0.55 
2025-08-30 07:36:16.326962: Pseudo dice [np.float32(0.769)] 
2025-08-30 07:36:16.332930: Epoch time: 27.19 s 
2025-08-30 07:36:16.964936:  
2025-08-30 07:36:16.968976: Epoch 610 
2025-08-30 07:36:16.977294: Current learning rate: 0.00043 
2025-08-30 07:36:44.112735: train_loss -0.6083 
2025-08-30 07:36:44.121383: val_loss -0.5297 
2025-08-30 07:36:44.129135: Pseudo dice [np.float32(0.7852)] 
2025-08-30 07:36:44.133666: Epoch time: 27.15 s 
2025-08-30 07:36:44.771809:  
2025-08-30 07:36:44.780080: Epoch 611 
2025-08-30 07:36:44.788477: Current learning rate: 0.00043 
2025-08-30 07:37:11.928383: train_loss -0.5878 
2025-08-30 07:37:11.936309: val_loss -0.578 
2025-08-30 07:37:11.940722: Pseudo dice [np.float32(0.7612)] 
2025-08-30 07:37:11.948635: Epoch time: 27.16 s 
2025-08-30 07:37:12.745461:  
2025-08-30 07:37:12.753849: Epoch 612 
2025-08-30 07:37:12.758357: Current learning rate: 0.00043 
2025-08-30 07:37:39.856193: train_loss -0.6014 
2025-08-30 07:37:39.868692: val_loss -0.6579 
2025-08-30 07:37:39.873275: Pseudo dice [np.float32(0.8245)] 
2025-08-30 07:37:39.881712: Epoch time: 27.11 s 
2025-08-30 07:37:40.514888:  
2025-08-30 07:37:40.523510: Epoch 613 
2025-08-30 07:37:40.527490: Current learning rate: 0.00043 
2025-08-30 07:38:07.754992: train_loss -0.6347 
2025-08-30 07:38:07.762911: val_loss -0.5984 
2025-08-30 07:38:07.767130: Pseudo dice [np.float32(0.821)] 
2025-08-30 07:38:07.774755: Epoch time: 27.24 s 
2025-08-30 07:38:08.409423:  
2025-08-30 07:38:08.413606: Epoch 614 
2025-08-30 07:38:08.421936: Current learning rate: 0.00042 
2025-08-30 07:38:35.695272: train_loss -0.6404 
2025-08-30 07:38:35.708284: val_loss -0.6288 
2025-08-30 07:38:35.711966: Pseudo dice [np.float32(0.7912)] 
2025-08-30 07:38:35.721378: Epoch time: 27.29 s 
2025-08-30 07:38:36.358455:  
2025-08-30 07:38:36.366507: Epoch 615 
2025-08-30 07:38:36.370838: Current learning rate: 0.00042 
2025-08-30 07:39:03.356901: train_loss -0.6026 
2025-08-30 07:39:03.364861: val_loss -0.5834 
2025-08-30 07:39:03.368783: Pseudo dice [np.float32(0.7784)] 
2025-08-30 07:39:03.376881: Epoch time: 27.0 s 
2025-08-30 07:39:04.031597:  
2025-08-30 07:39:04.039938: Epoch 616 
2025-08-30 07:39:04.048290: Current learning rate: 0.00042 
2025-08-30 07:39:30.958779: train_loss -0.6386 
2025-08-30 07:39:30.971283: val_loss -0.6202 
2025-08-30 07:39:30.975574: Pseudo dice [np.float32(0.8209)] 
2025-08-30 07:39:30.983444: Epoch time: 26.93 s 
2025-08-30 07:39:31.609159:  
2025-08-30 07:39:31.617512: Epoch 617 
2025-08-30 07:39:31.626271: Current learning rate: 0.00042 
2025-08-30 07:39:58.686166: train_loss -0.5939 
2025-08-30 07:39:58.694523: val_loss -0.6282 
2025-08-30 07:39:58.698955: Pseudo dice [np.float32(0.8146)] 
2025-08-30 07:39:58.704788: Epoch time: 27.08 s 
2025-08-30 07:39:59.353824:  
2025-08-30 07:39:59.361953: Epoch 618 
2025-08-30 07:39:59.366311: Current learning rate: 0.00042 
2025-08-30 07:40:26.276214: train_loss -0.6179 
2025-08-30 07:40:26.284620: val_loss -0.6108 
2025-08-30 07:40:26.293708: Pseudo dice [np.float32(0.8211)] 
2025-08-30 07:40:26.299092: Epoch time: 26.92 s 
2025-08-30 07:40:27.089840:  
2025-08-30 07:40:27.098171: Epoch 619 
2025-08-30 07:40:27.106244: Current learning rate: 0.00042 
2025-08-30 07:40:54.237474: train_loss -0.6143 
2025-08-30 07:40:54.245862: val_loss -0.6128 
2025-08-30 07:40:54.254844: Pseudo dice [np.float32(0.8)] 
2025-08-30 07:40:54.259501: Epoch time: 27.15 s 
2025-08-30 07:40:54.892342:  
2025-08-30 07:40:54.900734: Epoch 620 
2025-08-30 07:40:54.904838: Current learning rate: 0.00042 
2025-08-30 07:41:21.869738: train_loss -0.646 
2025-08-30 07:41:21.877618: val_loss -0.6387 
2025-08-30 07:41:21.882124: Pseudo dice [np.float32(0.8003)] 
2025-08-30 07:41:21.889798: Epoch time: 26.98 s 
2025-08-30 07:41:22.519887:  
2025-08-30 07:41:22.528234: Epoch 621 
2025-08-30 07:41:22.536946: Current learning rate: 0.00042 
2025-08-30 07:41:49.497192: train_loss -0.6134 
2025-08-30 07:41:49.505207: val_loss -0.6127 
2025-08-30 07:41:49.513973: Pseudo dice [np.float32(0.733)] 
2025-08-30 07:41:49.518498: Epoch time: 26.98 s 
2025-08-30 07:41:50.156194:  
2025-08-30 07:41:50.164232: Epoch 622 
2025-08-30 07:41:50.172585: Current learning rate: 0.00042 
2025-08-30 07:42:17.208229: train_loss -0.6435 
2025-08-30 07:42:17.216202: val_loss -0.6352 
2025-08-30 07:42:17.220568: Pseudo dice [np.float32(0.8029)] 
2025-08-30 07:42:17.228513: Epoch time: 27.05 s 
2025-08-30 07:42:17.858472:  
2025-08-30 07:42:17.866831: Epoch 623 
2025-08-30 07:42:17.870994: Current learning rate: 0.00042 
2025-08-30 07:42:44.781953: train_loss -0.6026 
2025-08-30 07:42:44.789567: val_loss -0.5743 
2025-08-30 07:42:44.794065: Pseudo dice [np.float32(0.7896)] 
2025-08-30 07:42:44.802154: Epoch time: 26.92 s 
2025-08-30 07:42:45.436031:  
2025-08-30 07:42:45.444432: Epoch 624 
2025-08-30 07:42:45.452805: Current learning rate: 0.00041 
2025-08-30 07:43:12.166864: train_loss -0.6169 
2025-08-30 07:43:12.179798: val_loss -0.6045 
2025-08-30 07:43:12.183834: Pseudo dice [np.float32(0.8087)] 
2025-08-30 07:43:12.193130: Epoch time: 26.73 s 
2025-08-30 07:43:12.972231:  
2025-08-30 07:43:12.980197: Epoch 625 
2025-08-30 07:43:12.984380: Current learning rate: 0.00041 
2025-08-30 07:43:39.936570: train_loss -0.5976 
2025-08-30 07:43:39.948784: val_loss -0.685 
2025-08-30 07:43:39.953255: Pseudo dice [np.float32(0.8449)] 
2025-08-30 07:43:39.960070: Epoch time: 26.96 s 
2025-08-30 07:43:40.603664:  
2025-08-30 07:43:40.612010: Epoch 626 
2025-08-30 07:43:40.620741: Current learning rate: 0.00041 
2025-08-30 07:44:07.756058: train_loss -0.6205 
2025-08-30 07:44:07.764392: val_loss -0.5417 
2025-08-30 07:44:07.768250: Pseudo dice [np.float32(0.7753)] 
2025-08-30 07:44:07.774639: Epoch time: 27.15 s 
2025-08-30 07:44:08.410521:  
2025-08-30 07:44:08.418883: Epoch 627 
2025-08-30 07:44:08.423223: Current learning rate: 0.00041 
2025-08-30 07:44:35.379622: train_loss -0.6002 
2025-08-30 07:44:35.391993: val_loss -0.6379 
2025-08-30 07:44:35.396169: Pseudo dice [np.float32(0.8049)] 
2025-08-30 07:44:35.402119: Epoch time: 26.97 s 
2025-08-30 07:44:36.033936:  
2025-08-30 07:44:36.038153: Epoch 628 
2025-08-30 07:44:36.047072: Current learning rate: 0.00041 
2025-08-30 07:45:02.856875: train_loss -0.6385 
2025-08-30 07:45:02.864997: val_loss -0.5801 
2025-08-30 07:45:02.869172: Pseudo dice [np.float32(0.7965)] 
2025-08-30 07:45:02.876269: Epoch time: 26.83 s 
2025-08-30 07:45:03.511365:  
2025-08-30 07:45:03.519734: Epoch 629 
2025-08-30 07:45:03.523904: Current learning rate: 0.00041 
2025-08-30 07:45:30.221480: train_loss -0.6457 
2025-08-30 07:45:30.229756: val_loss -0.6508 
2025-08-30 07:45:30.238091: Pseudo dice [np.float32(0.8282)] 
2025-08-30 07:45:30.243038: Epoch time: 26.71 s 
2025-08-30 07:45:30.876234:  
2025-08-30 07:45:30.884554: Epoch 630 
2025-08-30 07:45:30.889123: Current learning rate: 0.00041 
2025-08-30 07:45:57.586441: train_loss -0.6133 
2025-08-30 07:45:57.594569: val_loss -0.6043 
2025-08-30 07:45:57.598760: Pseudo dice [np.float32(0.8323)] 
2025-08-30 07:45:57.604350: Epoch time: 26.71 s 
2025-08-30 07:45:58.241095:  
2025-08-30 07:45:58.249450: Epoch 631 
2025-08-30 07:45:58.257763: Current learning rate: 0.00041 
2025-08-30 07:46:25.313899: train_loss -0.6478 
2025-08-30 07:46:25.322248: val_loss -0.6353 
2025-08-30 07:46:25.330602: Pseudo dice [np.float32(0.7959)] 
2025-08-30 07:46:25.336369: Epoch time: 27.07 s 
2025-08-30 07:46:26.114757:  
2025-08-30 07:46:26.123056: Epoch 632 
2025-08-30 07:46:26.131419: Current learning rate: 0.00041 
2025-08-30 07:46:53.141909: train_loss -0.6266 
2025-08-30 07:46:53.150135: val_loss -0.5979 
2025-08-30 07:46:53.154508: Pseudo dice [np.float32(0.8017)] 
2025-08-30 07:46:53.160613: Epoch time: 27.03 s 
2025-08-30 07:46:53.800694:  
2025-08-30 07:46:53.809333: Epoch 633 
2025-08-30 07:46:53.813505: Current learning rate: 0.00041 
2025-08-30 07:47:20.615267: train_loss -0.6263 
2025-08-30 07:47:20.623300: val_loss -0.6371 
2025-08-30 07:47:20.627563: Pseudo dice [np.float32(0.8149)] 
2025-08-30 07:47:20.634719: Epoch time: 26.82 s 
2025-08-30 07:47:21.269775:  
2025-08-30 07:47:21.278132: Epoch 634 
2025-08-30 07:47:21.282564: Current learning rate: 0.0004 
2025-08-30 07:47:48.217561: train_loss -0.6463 
2025-08-30 07:47:48.230589: val_loss -0.6827 
2025-08-30 07:47:48.234200: Pseudo dice [np.float32(0.8365)] 
2025-08-30 07:47:48.242936: Epoch time: 26.95 s 
2025-08-30 07:47:48.880707:  
2025-08-30 07:47:48.889066: Epoch 635 
2025-08-30 07:47:48.893193: Current learning rate: 0.0004 
2025-08-30 07:48:14.477255: train_loss -0.628 
2025-08-30 07:48:14.485443: val_loss -0.5619 
2025-08-30 07:48:14.489615: Pseudo dice [np.float32(0.7119)] 
2025-08-30 07:48:14.495769: Epoch time: 25.6 s 
2025-08-30 07:48:15.136051:  
2025-08-30 07:48:15.144442: Epoch 636 
2025-08-30 07:48:15.152848: Current learning rate: 0.0004 
2025-08-30 07:48:41.026173: train_loss -0.5979 
2025-08-30 07:48:41.037284: val_loss -0.6067 
2025-08-30 07:48:41.041587: Pseudo dice [np.float32(0.7759)] 
2025-08-30 07:48:41.049570: Epoch time: 25.89 s 
2025-08-30 07:48:41.692123:  
2025-08-30 07:48:41.700458: Epoch 637 
2025-08-30 07:48:41.704709: Current learning rate: 0.0004 
2025-08-30 07:49:07.544315: train_loss -0.6242 
2025-08-30 07:49:07.551241: val_loss -0.6228 
2025-08-30 07:49:07.559118: Pseudo dice [np.float32(0.8034)] 
2025-08-30 07:49:07.564258: Epoch time: 25.85 s 
2025-08-30 07:49:08.356143:  
2025-08-30 07:49:08.364175: Epoch 638 
2025-08-30 07:49:08.368549: Current learning rate: 0.0004 
2025-08-30 07:49:33.918907: train_loss -0.6563 
2025-08-30 07:49:33.927237: val_loss -0.6107 
2025-08-30 07:49:33.936044: Pseudo dice [np.float32(0.7477)] 
2025-08-30 07:49:33.941868: Epoch time: 25.56 s 
2025-08-30 07:49:34.573852:  
2025-08-30 07:49:34.582163: Epoch 639 
2025-08-30 07:49:34.586289: Current learning rate: 0.0004 
2025-08-30 07:50:00.120439: train_loss -0.6258 
2025-08-30 07:50:00.128427: val_loss -0.6263 
2025-08-30 07:50:00.132868: Pseudo dice [np.float32(0.7845)] 
2025-08-30 07:50:00.139733: Epoch time: 25.55 s 
2025-08-30 07:50:00.774979:  
2025-08-30 07:50:00.783557: Epoch 640 
2025-08-30 07:50:00.791670: Current learning rate: 0.0004 
2025-08-30 07:50:26.395840: train_loss -0.6181 
2025-08-30 07:50:26.400487: val_loss -0.6405 
2025-08-30 07:50:26.408839: Pseudo dice [np.float32(0.8315)] 
2025-08-30 07:50:26.413907: Epoch time: 25.62 s 
2025-08-30 07:50:27.046985:  
2025-08-30 07:50:27.055332: Epoch 641 
2025-08-30 07:50:27.059877: Current learning rate: 0.0004 
2025-08-30 07:50:52.527253: train_loss -0.6219 
2025-08-30 07:50:52.535216: val_loss -0.6302 
2025-08-30 07:50:52.539368: Pseudo dice [np.float32(0.8157)] 
2025-08-30 07:50:52.548243: Epoch time: 25.48 s 
2025-08-30 07:50:53.189503:  
2025-08-30 07:50:53.194001: Epoch 642 
2025-08-30 07:50:53.198326: Current learning rate: 0.0004 
2025-08-30 07:51:18.569597: train_loss -0.6101 
2025-08-30 07:51:18.577593: val_loss -0.6355 
2025-08-30 07:51:18.586321: Pseudo dice [np.float32(0.8021)] 
2025-08-30 07:51:18.591447: Epoch time: 25.38 s 
2025-08-30 07:51:19.228248:  
2025-08-30 07:51:19.232386: Epoch 643 
2025-08-30 07:51:19.240764: Current learning rate: 0.0004 
2025-08-30 07:51:44.708220: train_loss -0.6227 
2025-08-30 07:51:44.720161: val_loss -0.6645 
2025-08-30 07:51:44.724610: Pseudo dice [np.float32(0.823)] 
2025-08-30 07:51:44.730098: Epoch time: 25.48 s 
2025-08-30 07:51:45.397074:  
2025-08-30 07:51:45.405152: Epoch 644 
2025-08-30 07:51:45.408889: Current learning rate: 0.00039 
2025-08-30 07:52:10.913123: train_loss -0.6339 
2025-08-30 07:52:10.921517: val_loss -0.6195 
2025-08-30 07:52:10.925611: Pseudo dice [np.float32(0.8255)] 
2025-08-30 07:52:10.931898: Epoch time: 25.52 s 
2025-08-30 07:52:11.730939:  
2025-08-30 07:52:11.739312: Epoch 645 
2025-08-30 07:52:11.743479: Current learning rate: 0.00039 
2025-08-30 07:52:37.206578: train_loss -0.6323 
2025-08-30 07:52:37.214456: val_loss -0.6877 
2025-08-30 07:52:37.218611: Pseudo dice [np.float32(0.8187)] 
2025-08-30 07:52:37.226959: Epoch time: 25.48 s 
2025-08-30 07:52:37.860945:  
2025-08-30 07:52:37.869283: Epoch 646 
2025-08-30 07:52:37.873402: Current learning rate: 0.00039 
2025-08-30 07:53:03.375140: train_loss -0.6465 
2025-08-30 07:53:03.382234: val_loss -0.586 
2025-08-30 07:53:03.386704: Pseudo dice [np.float32(0.7587)] 
2025-08-30 07:53:03.393524: Epoch time: 25.51 s 
2025-08-30 07:53:04.029059:  
2025-08-30 07:53:04.037054: Epoch 647 
2025-08-30 07:53:04.041231: Current learning rate: 0.00039 
2025-08-30 07:53:30.050085: train_loss -0.6386 
2025-08-30 07:53:30.058875: val_loss -0.6618 
2025-08-30 07:53:30.063238: Pseudo dice [np.float32(0.7909)] 
2025-08-30 07:53:30.070156: Epoch time: 26.02 s 
2025-08-30 07:53:30.692846:  
2025-08-30 07:53:30.701204: Epoch 648 
2025-08-30 07:53:30.709863: Current learning rate: 0.00039 
2025-08-30 07:53:56.090001: train_loss -0.6341 
2025-08-30 07:53:56.097678: val_loss -0.5484 
2025-08-30 07:53:56.101614: Pseudo dice [np.float32(0.7832)] 
2025-08-30 07:53:56.109588: Epoch time: 25.4 s 
2025-08-30 07:53:56.739944:  
2025-08-30 07:53:56.748043: Epoch 649 
2025-08-30 07:53:56.752279: Current learning rate: 0.00039 
2025-08-30 07:54:22.148512: train_loss -0.6259 
2025-08-30 07:54:22.156699: val_loss -0.6288 
2025-08-30 07:54:22.160898: Pseudo dice [np.float32(0.7766)] 
2025-08-30 07:54:22.170346: Epoch time: 25.41 s 
2025-08-30 07:54:23.070112:  
2025-08-30 07:54:23.078479: Epoch 650 
2025-08-30 07:54:23.082854: Current learning rate: 0.00039 
2025-08-30 07:54:48.967057: train_loss -0.6435 
2025-08-30 07:54:48.975167: val_loss -0.5882 
2025-08-30 07:54:48.979735: Pseudo dice [np.float32(0.753)] 
2025-08-30 07:54:48.985534: Epoch time: 25.9 s 
2025-08-30 07:54:49.763510:  
2025-08-30 07:54:49.767982: Epoch 651 
2025-08-30 07:54:49.776250: Current learning rate: 0.00039 
2025-08-30 07:55:15.147462: train_loss -0.623 
2025-08-30 07:55:15.155817: val_loss -0.6043 
2025-08-30 07:55:15.159889: Pseudo dice [np.float32(0.7928)] 
2025-08-30 07:55:15.168059: Epoch time: 25.39 s 
2025-08-30 07:55:15.802016:  
2025-08-30 07:55:15.810907: Epoch 652 
2025-08-30 07:55:15.819026: Current learning rate: 0.00039 
2025-08-30 07:55:41.244139: train_loss -0.6379 
2025-08-30 07:55:41.252476: val_loss -0.6034 
2025-08-30 07:55:41.256607: Pseudo dice [np.float32(0.8153)] 
2025-08-30 07:55:41.263712: Epoch time: 25.44 s 
2025-08-30 07:55:41.903039:  
2025-08-30 07:55:41.911361: Epoch 653 
2025-08-30 07:55:41.915526: Current learning rate: 0.00039 
2025-08-30 07:56:07.340372: train_loss -0.6098 
2025-08-30 07:56:07.349215: val_loss -0.602 
2025-08-30 07:56:07.353768: Pseudo dice [np.float32(0.821)] 
2025-08-30 07:56:07.359462: Epoch time: 25.44 s 
2025-08-30 07:56:07.995734:  
2025-08-30 07:56:08.004396: Epoch 654 
2025-08-30 07:56:08.012780: Current learning rate: 0.00038 
2025-08-30 07:56:33.698913: train_loss -0.6412 
2025-08-30 07:56:33.704954: val_loss -0.5664 
2025-08-30 07:56:33.713334: Pseudo dice [np.float32(0.8187)] 
2025-08-30 07:56:33.721405: Epoch time: 25.7 s 
2025-08-30 07:56:34.363802:  
2025-08-30 07:56:34.372072: Epoch 655 
2025-08-30 07:56:34.376337: Current learning rate: 0.00038 
2025-08-30 07:56:59.760412: train_loss -0.6138 
2025-08-30 07:56:59.768652: val_loss -0.6385 
2025-08-30 07:56:59.772742: Pseudo dice [np.float32(0.8322)] 
2025-08-30 07:56:59.778777: Epoch time: 25.4 s 
2025-08-30 07:57:00.415009:  
2025-08-30 07:57:00.423605: Epoch 656 
2025-08-30 07:57:00.427238: Current learning rate: 0.00038 
2025-08-30 07:57:25.916657: train_loss -0.6182 
2025-08-30 07:57:25.923850: val_loss -0.6708 
2025-08-30 07:57:25.928005: Pseudo dice [np.float32(0.8081)] 
2025-08-30 07:57:25.935996: Epoch time: 25.5 s 
2025-08-30 07:57:26.720471:  
2025-08-30 07:57:26.728553: Epoch 657 
2025-08-30 07:57:26.733021: Current learning rate: 0.00038 
2025-08-30 07:57:51.891438: train_loss -0.6196 
2025-08-30 07:57:51.899565: val_loss -0.6518 
2025-08-30 07:57:51.903696: Pseudo dice [np.float32(0.8116)] 
2025-08-30 07:57:51.911803: Epoch time: 25.17 s 
2025-08-30 07:57:52.545972:  
2025-08-30 07:57:52.554345: Epoch 658 
2025-08-30 07:57:52.558743: Current learning rate: 0.00038 
2025-08-30 07:58:18.001627: train_loss -0.6581 
2025-08-30 07:58:18.008910: val_loss -0.639 
2025-08-30 07:58:18.013071: Pseudo dice [np.float32(0.8057)] 
2025-08-30 07:58:18.022318: Epoch time: 25.46 s 
2025-08-30 07:58:18.697417:  
2025-08-30 07:58:18.705539: Epoch 659 
2025-08-30 07:58:18.713808: Current learning rate: 0.00038 
2025-08-30 07:58:44.219101: train_loss -0.625 
2025-08-30 07:58:44.226736: val_loss -0.5791 
2025-08-30 07:58:44.235115: Pseudo dice [np.float32(0.7871)] 
2025-08-30 07:58:44.240587: Epoch time: 25.52 s 
2025-08-30 07:58:44.869048:  
2025-08-30 07:58:44.877398: Epoch 660 
2025-08-30 07:58:44.881939: Current learning rate: 0.00038 
2025-08-30 07:59:10.446090: train_loss -0.628 
2025-08-30 07:59:10.453235: val_loss -0.6117 
2025-08-30 07:59:10.457224: Pseudo dice [np.float32(0.804)] 
2025-08-30 07:59:10.465178: Epoch time: 25.58 s 
2025-08-30 07:59:11.103926:  
2025-08-30 07:59:11.112032: Epoch 661 
2025-08-30 07:59:11.116186: Current learning rate: 0.00038 
2025-08-30 07:59:36.333721: train_loss -0.6195 
2025-08-30 07:59:36.345868: val_loss -0.552 
2025-08-30 07:59:36.353731: Pseudo dice [np.float32(0.7928)] 
2025-08-30 07:59:36.360342: Epoch time: 25.23 s 
2025-08-30 07:59:36.996127:  
2025-08-30 07:59:37.004480: Epoch 662 
2025-08-30 07:59:37.008910: Current learning rate: 0.00038 
2025-08-30 08:00:02.337205: train_loss -0.6314 
2025-08-30 08:00:02.346804: val_loss -0.618 
2025-08-30 08:00:02.350864: Pseudo dice [np.float32(0.8157)] 
2025-08-30 08:00:02.357914: Epoch time: 25.35 s 
2025-08-30 08:00:02.992871:  
2025-08-30 08:00:03.001329: Epoch 663 
2025-08-30 08:00:03.009490: Current learning rate: 0.00038 
2025-08-30 08:00:28.510032: train_loss -0.659 
2025-08-30 08:00:28.522610: val_loss -0.5775 
2025-08-30 08:00:28.526724: Pseudo dice [np.float32(0.7921)] 
2025-08-30 08:00:28.535282: Epoch time: 25.52 s 
2025-08-30 08:00:29.338715:  
2025-08-30 08:00:29.347670: Epoch 664 
2025-08-30 08:00:29.352921: Current learning rate: 0.00037 
2025-08-30 08:00:54.853529: train_loss -0.6171 
2025-08-30 08:00:54.861359: val_loss -0.6486 
2025-08-30 08:00:54.869723: Pseudo dice [np.float32(0.8385)] 
2025-08-30 08:00:54.875826: Epoch time: 25.52 s 
2025-08-30 08:00:55.507820:  
2025-08-30 08:00:55.517272: Epoch 665 
2025-08-30 08:00:55.520341: Current learning rate: 0.00037 
2025-08-30 08:01:21.233516: train_loss -0.6263 
2025-08-30 08:01:21.242196: val_loss -0.6405 
2025-08-30 08:01:21.246323: Pseudo dice [np.float32(0.7757)] 
2025-08-30 08:01:21.253147: Epoch time: 25.73 s 
2025-08-30 08:01:21.884162:  
2025-08-30 08:01:21.888345: Epoch 666 
2025-08-30 08:01:21.892514: Current learning rate: 0.00037 
2025-08-30 08:01:47.462909: train_loss -0.6388 
2025-08-30 08:01:47.468920: val_loss -0.6456 
2025-08-30 08:01:47.476688: Pseudo dice [np.float32(0.8404)] 
2025-08-30 08:01:47.481866: Epoch time: 25.58 s 
2025-08-30 08:01:48.114512:  
2025-08-30 08:01:48.122874: Epoch 667 
2025-08-30 08:01:48.131216: Current learning rate: 0.00037 
2025-08-30 08:02:13.583124: train_loss -0.6072 
2025-08-30 08:02:13.590285: val_loss -0.626 
2025-08-30 08:02:13.594138: Pseudo dice [np.float32(0.8402)] 
2025-08-30 08:02:13.601317: Epoch time: 25.47 s 
2025-08-30 08:02:14.248958:  
2025-08-30 08:02:14.257295: Epoch 668 
2025-08-30 08:02:14.265625: Current learning rate: 0.00037 
2025-08-30 08:02:39.565916: train_loss -0.6232 
2025-08-30 08:02:39.578428: val_loss -0.5971 
2025-08-30 08:02:39.582590: Pseudo dice [np.float32(0.7911)] 
2025-08-30 08:02:39.590790: Epoch time: 25.32 s 
2025-08-30 08:02:40.229131:  
2025-08-30 08:02:40.237476: Epoch 669 
2025-08-30 08:02:40.245527: Current learning rate: 0.00037 
2025-08-30 08:03:05.717443: train_loss -0.6048 
2025-08-30 08:03:05.725394: val_loss -0.5827 
2025-08-30 08:03:05.729852: Pseudo dice [np.float32(0.7634)] 
2025-08-30 08:03:05.735701: Epoch time: 25.49 s 
2025-08-30 08:03:06.384344:  
2025-08-30 08:03:06.396860: Epoch 670 
2025-08-30 08:03:06.401313: Current learning rate: 0.00037 
2025-08-30 08:03:32.101574: train_loss -0.5911 
2025-08-30 08:03:32.110506: val_loss -0.5498 
2025-08-30 08:03:32.120326: Pseudo dice [np.float32(0.7374)] 
2025-08-30 08:03:32.124300: Epoch time: 25.71 s 
2025-08-30 08:03:32.819351:  
2025-08-30 08:03:32.827776: Epoch 671 
2025-08-30 08:03:32.831594: Current learning rate: 0.00037 
2025-08-30 08:03:58.223720: train_loss -0.6499 
2025-08-30 08:03:58.232011: val_loss -0.614 
2025-08-30 08:03:58.240372: Pseudo dice [np.float32(0.8152)] 
2025-08-30 08:03:58.245300: Epoch time: 25.41 s 
2025-08-30 08:03:58.899320:  
2025-08-30 08:03:58.903468: Epoch 672 
2025-08-30 08:03:58.911812: Current learning rate: 0.00037 
2025-08-30 08:04:24.404244: train_loss -0.6269 
2025-08-30 08:04:24.412558: val_loss -0.5885 
2025-08-30 08:04:24.420678: Pseudo dice [np.float32(0.8147)] 
2025-08-30 08:04:24.425477: Epoch time: 25.51 s 
2025-08-30 08:04:25.067070:  
2025-08-30 08:04:25.071277: Epoch 673 
2025-08-30 08:04:25.079595: Current learning rate: 0.00037 
2025-08-30 08:04:50.647934: train_loss -0.6663 
2025-08-30 08:04:50.659239: val_loss -0.6842 
2025-08-30 08:04:50.663808: Pseudo dice [np.float32(0.8168)] 
2025-08-30 08:04:50.671284: Epoch time: 25.59 s 
2025-08-30 08:04:51.314470:  
2025-08-30 08:04:51.322464: Epoch 674 
2025-08-30 08:04:51.326630: Current learning rate: 0.00036 
2025-08-30 08:05:16.982689: train_loss -0.6128 
2025-08-30 08:05:16.989796: val_loss -0.6269 
2025-08-30 08:05:16.993894: Pseudo dice [np.float32(0.8046)] 
2025-08-30 08:05:17.000160: Epoch time: 25.67 s 
2025-08-30 08:05:17.640798:  
2025-08-30 08:05:17.649030: Epoch 675 
2025-08-30 08:05:17.653218: Current learning rate: 0.00036 
2025-08-30 08:05:43.224281: train_loss -0.619 
2025-08-30 08:05:43.232658: val_loss -0.6315 
2025-08-30 08:05:43.236801: Pseudo dice [np.float32(0.8263)] 
2025-08-30 08:05:43.243978: Epoch time: 25.58 s 
2025-08-30 08:05:43.892004:  
2025-08-30 08:05:43.900348: Epoch 676 
2025-08-30 08:05:43.904525: Current learning rate: 0.00036 
2025-08-30 08:06:09.379906: train_loss -0.6289 
2025-08-30 08:06:09.388218: val_loss -0.6673 
2025-08-30 08:06:09.396610: Pseudo dice [np.float32(0.8147)] 
2025-08-30 08:06:09.401287: Epoch time: 25.49 s 
2025-08-30 08:06:10.188786:  
2025-08-30 08:06:10.193186: Epoch 677 
2025-08-30 08:06:10.201236: Current learning rate: 0.00036 
2025-08-30 08:06:35.685465: train_loss -0.6255 
2025-08-30 08:06:35.697574: val_loss -0.6911 
2025-08-30 08:06:35.701775: Pseudo dice [np.float32(0.8118)] 
2025-08-30 08:06:35.707891: Epoch time: 25.5 s 
2025-08-30 08:06:36.356810:  
2025-08-30 08:06:36.365264: Epoch 678 
2025-08-30 08:06:36.369015: Current learning rate: 0.00036 
2025-08-30 08:07:01.703317: train_loss -0.6203 
2025-08-30 08:07:01.711325: val_loss -0.6347 
2025-08-30 08:07:01.715168: Pseudo dice [np.float32(0.8199)] 
2025-08-30 08:07:01.722321: Epoch time: 25.35 s 
2025-08-30 08:07:02.366834:  
2025-08-30 08:07:02.374148: Epoch 679 
2025-08-30 08:07:02.378353: Current learning rate: 0.00036 
2025-08-30 08:07:27.967606: train_loss -0.6459 
2025-08-30 08:07:27.974724: val_loss -0.6065 
2025-08-30 08:07:27.983393: Pseudo dice [np.float32(0.7432)] 
2025-08-30 08:07:27.988083: Epoch time: 25.6 s 
2025-08-30 08:07:28.634004:  
2025-08-30 08:07:28.642429: Epoch 680 
2025-08-30 08:07:28.646247: Current learning rate: 0.00036 
2025-08-30 08:07:54.329583: train_loss -0.6302 
2025-08-30 08:07:54.338346: val_loss -0.6545 
2025-08-30 08:07:54.341323: Pseudo dice [np.float32(0.8223)] 
2025-08-30 08:07:54.349813: Epoch time: 25.7 s 
2025-08-30 08:07:54.993488:  
2025-08-30 08:07:55.001536: Epoch 681 
2025-08-30 08:07:55.006515: Current learning rate: 0.00036 
2025-08-30 08:08:20.660930: train_loss -0.6556 
2025-08-30 08:08:20.669322: val_loss -0.6437 
2025-08-30 08:08:20.673508: Pseudo dice [np.float32(0.7988)] 
2025-08-30 08:08:20.681413: Epoch time: 25.67 s 
2025-08-30 08:08:21.324174:  
2025-08-30 08:08:21.332255: Epoch 682 
2025-08-30 08:08:21.337652: Current learning rate: 0.00036 
2025-08-30 08:08:46.765967: train_loss -0.6101 
2025-08-30 08:08:46.778448: val_loss -0.6635 
2025-08-30 08:08:46.782614: Pseudo dice [np.float32(0.8105)] 
2025-08-30 08:08:46.789817: Epoch time: 25.45 s 
2025-08-30 08:08:47.433282:  
2025-08-30 08:08:47.441878: Epoch 683 
2025-08-30 08:08:47.446021: Current learning rate: 0.00036 
2025-08-30 08:09:12.993897: train_loss -0.6381 
2025-08-30 08:09:13.000452: val_loss -0.5777 
2025-08-30 08:09:13.004814: Pseudo dice [np.float32(0.8057)] 
2025-08-30 08:09:13.012721: Epoch time: 25.56 s 
2025-08-30 08:09:13.655365:  
2025-08-30 08:09:13.663962: Epoch 684 
2025-08-30 08:09:13.668178: Current learning rate: 0.00035 
2025-08-30 08:09:39.389271: train_loss -0.6139 
2025-08-30 08:09:39.397983: val_loss -0.551 
2025-08-30 08:09:39.401829: Pseudo dice [np.float32(0.7942)] 
2025-08-30 08:09:39.408023: Epoch time: 25.74 s 
2025-08-30 08:09:40.069129:  
2025-08-30 08:09:40.081640: Epoch 685 
2025-08-30 08:09:40.086059: Current learning rate: 0.00035 
2025-08-30 08:10:05.670016: train_loss -0.6275 
2025-08-30 08:10:05.678379: val_loss -0.6026 
2025-08-30 08:10:05.686728: Pseudo dice [np.float32(0.8158)] 
2025-08-30 08:10:05.693770: Epoch time: 25.6 s 
2025-08-30 08:10:06.333195:  
2025-08-30 08:10:06.339837: Epoch 686 
2025-08-30 08:10:06.348843: Current learning rate: 0.00035 
2025-08-30 08:10:31.959299: train_loss -0.6493 
2025-08-30 08:10:31.967119: val_loss -0.5829 
2025-08-30 08:10:31.970948: Pseudo dice [np.float32(0.8213)] 
2025-08-30 08:10:31.980113: Epoch time: 25.63 s 
2025-08-30 08:10:32.646621:  
2025-08-30 08:10:32.655280: Epoch 687 
2025-08-30 08:10:32.659513: Current learning rate: 0.00035 
2025-08-30 08:10:58.176663: train_loss -0.6327 
2025-08-30 08:10:58.184949: val_loss -0.5745 
2025-08-30 08:10:58.193367: Pseudo dice [np.float32(0.7805)] 
2025-08-30 08:10:58.198236: Epoch time: 25.53 s 
2025-08-30 08:10:58.845783:  
2025-08-30 08:10:58.853409: Epoch 688 
2025-08-30 08:10:58.856378: Current learning rate: 0.00035 
2025-08-30 08:11:24.452864: train_loss -0.6189 
2025-08-30 08:11:24.456717: val_loss -0.6206 
2025-08-30 08:11:24.465339: Pseudo dice [np.float32(0.7996)] 
2025-08-30 08:11:24.471260: Epoch time: 25.61 s 
2025-08-30 08:11:25.119850:  
2025-08-30 08:11:25.128200: Epoch 689 
2025-08-30 08:11:25.132398: Current learning rate: 0.00035 
2025-08-30 08:11:50.486930: train_loss -0.6222 
2025-08-30 08:11:50.499386: val_loss -0.6857 
2025-08-30 08:11:50.503548: Pseudo dice [np.float32(0.8103)] 
2025-08-30 08:11:50.510759: Epoch time: 25.37 s 
2025-08-30 08:11:51.321457:  
2025-08-30 08:11:51.329359: Epoch 690 
2025-08-30 08:11:51.337716: Current learning rate: 0.00035 
2025-08-30 08:12:16.821467: train_loss -0.6284 
2025-08-30 08:12:16.825896: val_loss -0.6063 
2025-08-30 08:12:16.834021: Pseudo dice [np.float32(0.8275)] 
2025-08-30 08:12:16.839344: Epoch time: 25.5 s 
2025-08-30 08:12:17.484934:  
2025-08-30 08:12:17.493288: Epoch 691 
2025-08-30 08:12:17.497509: Current learning rate: 0.00035 
2025-08-30 08:12:42.977083: train_loss -0.623 
2025-08-30 08:12:42.989592: val_loss -0.6812 
2025-08-30 08:12:42.997350: Pseudo dice [np.float32(0.8209)] 
2025-08-30 08:12:43.002629: Epoch time: 25.5 s 
2025-08-30 08:12:43.636184:  
2025-08-30 08:12:43.644444: Epoch 692 
2025-08-30 08:12:43.652820: Current learning rate: 0.00035 
2025-08-30 08:13:09.154114: train_loss -0.618 
2025-08-30 08:13:09.161580: val_loss -0.5806 
2025-08-30 08:13:09.165413: Pseudo dice [np.float32(0.7904)] 
2025-08-30 08:13:09.173803: Epoch time: 25.52 s 
2025-08-30 08:13:09.828669:  
2025-08-30 08:13:09.838129: Epoch 693 
2025-08-30 08:13:09.844608: Current learning rate: 0.00035 
2025-08-30 08:13:35.337360: train_loss -0.6392 
2025-08-30 08:13:35.348187: val_loss -0.6688 
2025-08-30 08:13:35.354454: Pseudo dice [np.float32(0.8169)] 
2025-08-30 08:13:35.361544: Epoch time: 25.51 s 
2025-08-30 08:13:36.013076:  
2025-08-30 08:13:36.021439: Epoch 694 
2025-08-30 08:13:36.025601: Current learning rate: 0.00034 
2025-08-30 08:14:01.576479: train_loss -0.6433 
2025-08-30 08:14:01.584468: val_loss -0.5722 
2025-08-30 08:14:01.588636: Pseudo dice [np.float32(0.7962)] 
2025-08-30 08:14:01.597829: Epoch time: 25.57 s 
2025-08-30 08:14:02.239244:  
2025-08-30 08:14:02.251376: Epoch 695 
2025-08-30 08:14:02.255928: Current learning rate: 0.00034 
2025-08-30 08:14:27.961189: train_loss -0.6233 
2025-08-30 08:14:27.969124: val_loss -0.6663 
2025-08-30 08:14:27.973595: Pseudo dice [np.float32(0.8286)] 
2025-08-30 08:14:27.981635: Epoch time: 25.72 s 
2025-08-30 08:14:28.628091:  
2025-08-30 08:14:28.636471: Epoch 696 
2025-08-30 08:14:28.640609: Current learning rate: 0.00034 
2025-08-30 08:14:54.207767: train_loss -0.6307 
2025-08-30 08:14:54.216154: val_loss -0.5585 
2025-08-30 08:14:54.224507: Pseudo dice [np.float32(0.7449)] 
2025-08-30 08:14:54.230140: Epoch time: 25.58 s 
2025-08-30 08:14:54.887662:  
2025-08-30 08:14:54.896022: Epoch 697 
2025-08-30 08:14:54.900528: Current learning rate: 0.00034 
2025-08-30 08:15:20.246664: train_loss -0.6351 
2025-08-30 08:15:20.254657: val_loss -0.6836 
2025-08-30 08:15:20.258853: Pseudo dice [np.float32(0.8286)] 
2025-08-30 08:15:20.264300: Epoch time: 25.36 s 
2025-08-30 08:15:20.909756:  
2025-08-30 08:15:20.917843: Epoch 698 
2025-08-30 08:15:20.922426: Current learning rate: 0.00034 
2025-08-30 08:15:46.384966: train_loss -0.6219 
2025-08-30 08:15:46.393351: val_loss -0.6978 
2025-08-30 08:15:46.401657: Pseudo dice [np.float32(0.8475)] 
2025-08-30 08:15:46.407908: Epoch time: 25.48 s 
2025-08-30 08:15:47.052251:  
2025-08-30 08:15:47.056797: Epoch 699 
2025-08-30 08:15:47.065112: Current learning rate: 0.00034 
2025-08-30 08:16:12.774116: train_loss -0.6199 
2025-08-30 08:16:12.782574: val_loss -0.664 
2025-08-30 08:16:12.790866: Pseudo dice [np.float32(0.8264)] 
2025-08-30 08:16:12.798162: Epoch time: 25.73 s 
2025-08-30 08:16:13.024400: Yayy! New best EMA pseudo Dice: 0.8105999827384949 
2025-08-30 08:16:13.891575:  
2025-08-30 08:16:13.899907: Epoch 700 
2025-08-30 08:16:13.904111: Current learning rate: 0.00034 
2025-08-30 08:16:41.001963: train_loss -0.6377 
2025-08-30 08:16:41.014122: val_loss -0.6263 
2025-08-30 08:16:41.018696: Pseudo dice [np.float32(0.8166)] 
2025-08-30 08:16:41.025950: Epoch time: 27.11 s 
2025-08-30 08:16:41.031512: Yayy! New best EMA pseudo Dice: 0.8112000226974487 
2025-08-30 08:16:41.881982:  
2025-08-30 08:16:41.886165: Epoch 701 
2025-08-30 08:16:41.894552: Current learning rate: 0.00034 
2025-08-30 08:17:09.455561: train_loss -0.6401 
2025-08-30 08:17:09.463739: val_loss -0.5919 
2025-08-30 08:17:09.467903: Pseudo dice [np.float32(0.8112)] 
2025-08-30 08:17:09.476165: Epoch time: 27.58 s 
2025-08-30 08:17:09.481786: Yayy! New best EMA pseudo Dice: 0.8112000226974487 
2025-08-30 08:17:10.535628:  
2025-08-30 08:17:10.543976: Epoch 702 
2025-08-30 08:17:10.548153: Current learning rate: 0.00034 
2025-08-30 08:17:37.611674: train_loss -0.6078 
2025-08-30 08:17:37.621386: val_loss -0.6521 
2025-08-30 08:17:37.629693: Pseudo dice [np.float32(0.8367)] 
2025-08-30 08:17:37.635786: Epoch time: 27.08 s 
2025-08-30 08:17:37.641730: Yayy! New best EMA pseudo Dice: 0.8137000203132629 
2025-08-30 08:17:38.505623:  
2025-08-30 08:17:38.514632: Epoch 703 
2025-08-30 08:17:38.521905: Current learning rate: 0.00034 
2025-08-30 08:18:05.928416: train_loss -0.6458 
2025-08-30 08:18:05.936799: val_loss -0.6325 
2025-08-30 08:18:05.940944: Pseudo dice [np.float32(0.8419)] 
2025-08-30 08:18:05.949305: Epoch time: 27.42 s 
2025-08-30 08:18:05.954411: Yayy! New best EMA pseudo Dice: 0.8165000081062317 
2025-08-30 08:18:06.800164:  
2025-08-30 08:18:06.808537: Epoch 704 
2025-08-30 08:18:06.812684: Current learning rate: 0.00033 
2025-08-30 08:18:34.031465: train_loss -0.6373 
2025-08-30 08:18:34.040184: val_loss -0.6347 
2025-08-30 08:18:34.044237: Pseudo dice [np.float32(0.8474)] 
2025-08-30 08:18:34.052423: Epoch time: 27.23 s 
2025-08-30 08:18:34.061306: Yayy! New best EMA pseudo Dice: 0.819599986076355 
2025-08-30 08:18:35.103454:  
2025-08-30 08:18:35.111814: Epoch 705 
2025-08-30 08:18:35.120369: Current learning rate: 0.00033 
2025-08-30 08:19:01.859704: train_loss -0.6259 
2025-08-30 08:19:01.868059: val_loss -0.6055 
2025-08-30 08:19:01.876028: Pseudo dice [np.float32(0.8141)] 
2025-08-30 08:19:01.882868: Epoch time: 26.76 s 
2025-08-30 08:19:02.534925:  
2025-08-30 08:19:02.543304: Epoch 706 
2025-08-30 08:19:02.547439: Current learning rate: 0.00033 
2025-08-30 08:19:29.478194: train_loss -0.6598 
2025-08-30 08:19:29.487130: val_loss -0.636 
2025-08-30 08:19:29.491076: Pseudo dice [np.float32(0.8088)] 
2025-08-30 08:19:29.500180: Epoch time: 26.94 s 
2025-08-30 08:19:30.145875:  
2025-08-30 08:19:30.155303: Epoch 707 
2025-08-30 08:19:30.158395: Current learning rate: 0.00033 
2025-08-30 08:19:56.776977: train_loss -0.6436 
2025-08-30 08:19:56.784942: val_loss -0.6626 
2025-08-30 08:19:56.789403: Pseudo dice [np.float32(0.8123)] 
2025-08-30 08:19:56.795429: Epoch time: 26.63 s 
2025-08-30 08:19:57.577023:  
2025-08-30 08:19:57.585414: Epoch 708 
2025-08-30 08:19:57.589944: Current learning rate: 0.00033 
2025-08-30 08:20:24.362506: train_loss -0.6214 
2025-08-30 08:20:24.370839: val_loss -0.6681 
2025-08-30 08:20:24.375005: Pseudo dice [np.float32(0.8267)] 
2025-08-30 08:20:24.382312: Epoch time: 26.79 s 
2025-08-30 08:20:25.042380:  
2025-08-30 08:20:25.051051: Epoch 709 
2025-08-30 08:20:25.059027: Current learning rate: 0.00033 
2025-08-30 08:20:51.856988: train_loss -0.6446 
2025-08-30 08:20:51.865026: val_loss -0.6223 
2025-08-30 08:20:51.873697: Pseudo dice [np.float32(0.756)] 
2025-08-30 08:20:51.878813: Epoch time: 26.81 s 
2025-08-30 08:20:52.519751:  
2025-08-30 08:20:52.528508: Epoch 710 
2025-08-30 08:20:52.536447: Current learning rate: 0.00033 
2025-08-30 08:21:19.751241: train_loss -0.6062 
2025-08-30 08:21:19.759548: val_loss -0.6269 
2025-08-30 08:21:19.763738: Pseudo dice [np.float32(0.8155)] 
2025-08-30 08:21:19.769854: Epoch time: 27.23 s 
2025-08-30 08:21:20.414272:  
2025-08-30 08:21:20.422648: Epoch 711 
2025-08-30 08:21:20.426832: Current learning rate: 0.00033 
2025-08-30 08:21:47.370742: train_loss -0.5633 
2025-08-30 08:21:47.382928: val_loss -0.6001 
2025-08-30 08:21:47.387317: Pseudo dice [np.float32(0.7695)] 
2025-08-30 08:21:47.393359: Epoch time: 26.96 s 
2025-08-30 08:21:48.037688:  
2025-08-30 08:21:48.046061: Epoch 712 
2025-08-30 08:21:48.050254: Current learning rate: 0.00033 
2025-08-30 08:22:15.069161: train_loss -0.646 
2025-08-30 08:22:15.077601: val_loss -0.5984 
2025-08-30 08:22:15.081740: Pseudo dice [np.float32(0.7969)] 
2025-08-30 08:22:15.087617: Epoch time: 27.04 s 
2025-08-30 08:22:15.732028:  
2025-08-30 08:22:15.740388: Epoch 713 
2025-08-30 08:22:15.744577: Current learning rate: 0.00033 
2025-08-30 08:22:42.705288: train_loss -0.6532 
2025-08-30 08:22:42.717354: val_loss -0.6661 
2025-08-30 08:22:42.721764: Pseudo dice [np.float32(0.813)] 
2025-08-30 08:22:42.728911: Epoch time: 26.98 s 
2025-08-30 08:22:43.526838:  
2025-08-30 08:22:43.534830: Epoch 714 
2025-08-30 08:22:43.538992: Current learning rate: 0.00032 
2025-08-30 08:23:09.829467: train_loss -0.6345 
2025-08-30 08:23:09.838286: val_loss -0.6671 
2025-08-30 08:23:09.844359: Pseudo dice [np.float32(0.8119)] 
2025-08-30 08:23:09.849756: Epoch time: 26.3 s 
2025-08-30 08:23:10.490927:  
2025-08-30 08:23:10.495397: Epoch 715 
2025-08-30 08:23:10.503464: Current learning rate: 0.00032 
2025-08-30 08:23:37.326578: train_loss -0.6301 
2025-08-30 08:23:37.340791: val_loss -0.5946 
2025-08-30 08:23:37.348320: Pseudo dice [np.float32(0.8198)] 
2025-08-30 08:23:37.353082: Epoch time: 26.84 s 
2025-08-30 08:23:38.010183:  
2025-08-30 08:23:38.014226: Epoch 716 
2025-08-30 08:23:38.022549: Current learning rate: 0.00032 
2025-08-30 08:24:05.128889: train_loss -0.612 
2025-08-30 08:24:05.136726: val_loss -0.6404 
2025-08-30 08:24:05.141016: Pseudo dice [np.float32(0.8324)] 
2025-08-30 08:24:05.147640: Epoch time: 27.12 s 
2025-08-30 08:24:05.796093:  
2025-08-30 08:24:05.804475: Epoch 717 
2025-08-30 08:24:05.808648: Current learning rate: 0.00032 
2025-08-30 08:24:32.873218: train_loss -0.6382 
2025-08-30 08:24:32.885973: val_loss -0.6423 
2025-08-30 08:24:32.890156: Pseudo dice [np.float32(0.7998)] 
2025-08-30 08:24:32.898070: Epoch time: 27.08 s 
2025-08-30 08:24:33.548822:  
2025-08-30 08:24:33.557191: Epoch 718 
2025-08-30 08:24:33.561360: Current learning rate: 0.00032 
2025-08-30 08:25:00.471598: train_loss -0.6427 
2025-08-30 08:25:00.479905: val_loss -0.6726 
2025-08-30 08:25:00.487960: Pseudo dice [np.float32(0.8109)] 
2025-08-30 08:25:00.493902: Epoch time: 26.92 s 
2025-08-30 08:25:01.143028:  
2025-08-30 08:25:01.151410: Epoch 719 
2025-08-30 08:25:01.155585: Current learning rate: 0.00032 
2025-08-30 08:25:28.207928: train_loss -0.6175 
2025-08-30 08:25:28.220438: val_loss -0.5637 
2025-08-30 08:25:28.224548: Pseudo dice [np.float32(0.7892)] 
2025-08-30 08:25:28.231474: Epoch time: 27.06 s 
2025-08-30 08:25:28.908262:  
2025-08-30 08:25:28.916611: Epoch 720 
2025-08-30 08:25:28.920778: Current learning rate: 0.00032 
2025-08-30 08:25:55.843460: train_loss -0.6382 
2025-08-30 08:25:55.851694: val_loss -0.615 
2025-08-30 08:25:55.856344: Pseudo dice [np.float32(0.8426)] 
2025-08-30 08:25:55.861588: Epoch time: 26.94 s 
2025-08-30 08:25:56.678083:  
2025-08-30 08:25:56.686100: Epoch 721 
2025-08-30 08:25:56.690194: Current learning rate: 0.00032 
2025-08-30 08:26:23.629903: train_loss -0.6067 
2025-08-30 08:26:23.638364: val_loss -0.5769 
2025-08-30 08:26:23.642450: Pseudo dice [np.float32(0.7303)] 
2025-08-30 08:26:23.651396: Epoch time: 26.96 s 
2025-08-30 08:26:24.297034:  
2025-08-30 08:26:24.305629: Epoch 722 
2025-08-30 08:26:24.313590: Current learning rate: 0.00032 
2025-08-30 08:26:51.169912: train_loss -0.6583 
2025-08-30 08:26:51.182397: val_loss -0.6513 
2025-08-30 08:26:51.186536: Pseudo dice [np.float32(0.8043)] 
2025-08-30 08:26:51.195374: Epoch time: 26.87 s 
2025-08-30 08:26:51.916541:  
2025-08-30 08:26:51.926317: Epoch 723 
2025-08-30 08:26:51.928699: Current learning rate: 0.00031 
2025-08-30 08:27:18.313360: train_loss -0.6359 
2025-08-30 08:27:18.321682: val_loss -0.636 
2025-08-30 08:27:18.327866: Pseudo dice [np.float32(0.8037)] 
2025-08-30 08:27:18.333069: Epoch time: 26.4 s 
2025-08-30 08:27:19.039377:  
2025-08-30 08:27:19.047800: Epoch 724 
2025-08-30 08:27:19.051921: Current learning rate: 0.00031 
2025-08-30 08:27:46.078607: train_loss -0.6336 
2025-08-30 08:27:46.091465: val_loss -0.6468 
2025-08-30 08:27:46.095245: Pseudo dice [np.float32(0.8006)] 
2025-08-30 08:27:46.102494: Epoch time: 27.04 s 
2025-08-30 08:27:46.754287:  
2025-08-30 08:27:46.762637: Epoch 725 
2025-08-30 08:27:46.766784: Current learning rate: 0.00031 
2025-08-30 08:28:13.539323: train_loss -0.6514 
2025-08-30 08:28:13.547999: val_loss -0.638 
2025-08-30 08:28:13.556340: Pseudo dice [np.float32(0.8033)] 
2025-08-30 08:28:13.561492: Epoch time: 26.79 s 
2025-08-30 08:28:14.210832:  
2025-08-30 08:28:14.215005: Epoch 726 
2025-08-30 08:28:14.223360: Current learning rate: 0.00031 
2025-08-30 08:28:41.138362: train_loss -0.6406 
2025-08-30 08:28:41.146464: val_loss -0.6276 
2025-08-30 08:28:41.154461: Pseudo dice [np.float32(0.8234)] 
2025-08-30 08:28:41.158707: Epoch time: 26.93 s 
2025-08-30 08:28:41.951063:  
2025-08-30 08:28:41.955233: Epoch 727 
2025-08-30 08:28:41.963550: Current learning rate: 0.00031 
2025-08-30 08:29:08.790484: train_loss -0.6345 
2025-08-30 08:29:08.798684: val_loss -0.6865 
2025-08-30 08:29:08.807020: Pseudo dice [np.float32(0.8432)] 
2025-08-30 08:29:08.812031: Epoch time: 26.84 s 
2025-08-30 08:29:09.457776:  
2025-08-30 08:29:09.466031: Epoch 728 
2025-08-30 08:29:09.470217: Current learning rate: 0.00031 
2025-08-30 08:29:36.227660: train_loss -0.6382 
2025-08-30 08:29:36.238663: val_loss -0.6322 
2025-08-30 08:29:36.242757: Pseudo dice [np.float32(0.7993)] 
2025-08-30 08:29:36.249947: Epoch time: 26.77 s 
2025-08-30 08:29:36.893456:  
2025-08-30 08:29:36.902026: Epoch 729 
2025-08-30 08:29:36.905979: Current learning rate: 0.00031 
2025-08-30 08:30:03.541878: train_loss -0.6167 
2025-08-30 08:30:03.549164: val_loss -0.5765 
2025-08-30 08:30:03.557531: Pseudo dice [np.float32(0.8496)] 
2025-08-30 08:30:03.562438: Epoch time: 26.65 s 
2025-08-30 08:30:04.208455:  
2025-08-30 08:30:04.216848: Epoch 730 
2025-08-30 08:30:04.221249: Current learning rate: 0.00031 
2025-08-30 08:30:31.147593: train_loss -0.6004 
2025-08-30 08:30:31.155902: val_loss -0.6261 
2025-08-30 08:30:31.160058: Pseudo dice [np.float32(0.8221)] 
2025-08-30 08:30:31.165009: Epoch time: 26.94 s 
2025-08-30 08:30:31.815133:  
2025-08-30 08:30:31.823639: Epoch 731 
2025-08-30 08:30:31.827446: Current learning rate: 0.00031 
2025-08-30 08:30:58.675065: train_loss -0.6238 
2025-08-30 08:30:58.683391: val_loss -0.6224 
2025-08-30 08:30:58.687554: Pseudo dice [np.float32(0.7581)] 
2025-08-30 08:30:58.696737: Epoch time: 26.86 s 
2025-08-30 08:30:59.352722:  
2025-08-30 08:30:59.359372: Epoch 732 
2025-08-30 08:30:59.363551: Current learning rate: 0.00031 
2025-08-30 08:31:26.428162: train_loss -0.6168 
2025-08-30 08:31:26.436098: val_loss -0.6359 
2025-08-30 08:31:26.440306: Pseudo dice [np.float32(0.8256)] 
2025-08-30 08:31:26.448519: Epoch time: 27.08 s 
2025-08-30 08:31:27.253349:  
2025-08-30 08:31:27.262002: Epoch 733 
2025-08-30 08:31:27.270046: Current learning rate: 0.0003 
2025-08-30 08:31:53.976739: train_loss -0.6129 
2025-08-30 08:31:53.984445: val_loss -0.616 
2025-08-30 08:31:53.988623: Pseudo dice [np.float32(0.8028)] 
2025-08-30 08:31:53.997739: Epoch time: 26.73 s 
2025-08-30 08:31:54.643505:  
2025-08-30 08:31:54.651837: Epoch 734 
2025-08-30 08:31:54.656306: Current learning rate: 0.0003 
2025-08-30 08:32:21.324333: train_loss -0.6316 
2025-08-30 08:32:21.332785: val_loss -0.5968 
2025-08-30 08:32:21.335798: Pseudo dice [np.float32(0.8373)] 
2025-08-30 08:32:21.345777: Epoch time: 26.69 s 
2025-08-30 08:32:21.983344:  
2025-08-30 08:32:21.991676: Epoch 735 
2025-08-30 08:32:21.995859: Current learning rate: 0.0003 
2025-08-30 08:32:48.868969: train_loss -0.6231 
2025-08-30 08:32:48.876794: val_loss -0.6352 
2025-08-30 08:32:48.880921: Pseudo dice [np.float32(0.7886)] 
2025-08-30 08:32:48.889291: Epoch time: 26.89 s 
2025-08-30 08:32:49.535855:  
2025-08-30 08:32:49.544117: Epoch 736 
2025-08-30 08:32:49.552585: Current learning rate: 0.0003 
2025-08-30 08:33:16.425531: train_loss -0.6301 
2025-08-30 08:33:16.433489: val_loss -0.6396 
2025-08-30 08:33:16.437658: Pseudo dice [np.float32(0.8261)] 
2025-08-30 08:33:16.444912: Epoch time: 26.89 s 
2025-08-30 08:33:17.092439:  
2025-08-30 08:33:17.101054: Epoch 737 
2025-08-30 08:33:17.109249: Current learning rate: 0.0003 
2025-08-30 08:33:44.371865: train_loss -0.6376 
2025-08-30 08:33:44.382233: val_loss -0.5471 
2025-08-30 08:33:44.386375: Pseudo dice [np.float32(0.7844)] 
2025-08-30 08:33:44.392550: Epoch time: 27.28 s 
2025-08-30 08:33:45.069019:  
2025-08-30 08:33:45.074664: Epoch 738 
2025-08-30 08:33:45.078816: Current learning rate: 0.0003 
2025-08-30 08:34:11.913838: train_loss -0.6064 
2025-08-30 08:34:11.922195: val_loss -0.6217 
2025-08-30 08:34:11.930557: Pseudo dice [np.float32(0.8537)] 
2025-08-30 08:34:11.935890: Epoch time: 26.85 s 
2025-08-30 08:34:12.581183:  
2025-08-30 08:34:12.589528: Epoch 739 
2025-08-30 08:34:12.597870: Current learning rate: 0.0003 
2025-08-30 08:34:39.608204: train_loss -0.6648 
2025-08-30 08:34:39.616551: val_loss -0.6993 
2025-08-30 08:34:39.625238: Pseudo dice [np.float32(0.8067)] 
2025-08-30 08:34:39.633768: Epoch time: 27.03 s 
2025-08-30 08:34:40.446559:  
2025-08-30 08:34:40.454952: Epoch 740 
2025-08-30 08:34:40.459270: Current learning rate: 0.0003 
2025-08-30 08:35:07.156503: train_loss -0.6355 
2025-08-30 08:35:07.164869: val_loss -0.6051 
2025-08-30 08:35:07.169027: Pseudo dice [np.float32(0.8114)] 
2025-08-30 08:35:07.175177: Epoch time: 26.71 s 
2025-08-30 08:35:07.828306:  
2025-08-30 08:35:07.837567: Epoch 741 
2025-08-30 08:35:07.842698: Current learning rate: 0.0003 
2025-08-30 08:35:35.365465: train_loss -0.6296 
2025-08-30 08:35:35.372178: val_loss -0.6138 
2025-08-30 08:35:35.380529: Pseudo dice [np.float32(0.8242)] 
2025-08-30 08:35:35.386114: Epoch time: 27.54 s 
2025-08-30 08:35:36.047892:  
2025-08-30 08:35:36.056221: Epoch 742 
2025-08-30 08:35:36.064567: Current learning rate: 0.0003 
2025-08-30 08:36:02.728725: train_loss -0.6455 
2025-08-30 08:36:02.737025: val_loss -0.5789 
2025-08-30 08:36:02.741197: Pseudo dice [np.float32(0.7851)] 
2025-08-30 08:36:02.749547: Epoch time: 26.68 s 
2025-08-30 08:36:03.396078:  
2025-08-30 08:36:03.404419: Epoch 743 
2025-08-30 08:36:03.408616: Current learning rate: 0.00029 
2025-08-30 08:36:30.122680: train_loss -0.6425 
2025-08-30 08:36:30.131078: val_loss -0.5981 
2025-08-30 08:36:30.139407: Pseudo dice [np.float32(0.8154)] 
2025-08-30 08:36:30.144816: Epoch time: 26.73 s 
2025-08-30 08:36:30.785842:  
2025-08-30 08:36:30.794508: Epoch 744 
2025-08-30 08:36:30.798697: Current learning rate: 0.00029 
2025-08-30 08:36:57.812841: train_loss -0.6436 
2025-08-30 08:36:57.821227: val_loss -0.6096 
2025-08-30 08:36:57.825375: Pseudo dice [np.float32(0.7788)] 
2025-08-30 08:36:57.831605: Epoch time: 27.03 s 
2025-08-30 08:36:58.480493:  
2025-08-30 08:36:58.488892: Epoch 745 
2025-08-30 08:36:58.493044: Current learning rate: 0.00029 
2025-08-30 08:37:25.765829: train_loss -0.6378 
2025-08-30 08:37:25.774177: val_loss -0.6131 
2025-08-30 08:37:25.778337: Pseudo dice [np.float32(0.813)] 
2025-08-30 08:37:25.787377: Epoch time: 27.29 s 
2025-08-30 08:37:26.599916:  
2025-08-30 08:37:26.608287: Epoch 746 
2025-08-30 08:37:26.616632: Current learning rate: 0.00029 
2025-08-30 08:37:53.740325: train_loss -0.6321 
2025-08-30 08:37:53.752112: val_loss -0.7032 
2025-08-30 08:37:53.756602: Pseudo dice [np.float32(0.8497)] 
2025-08-30 08:37:53.764530: Epoch time: 27.14 s 
2025-08-30 08:37:54.411103:  
2025-08-30 08:37:54.419700: Epoch 747 
2025-08-30 08:37:54.423852: Current learning rate: 0.00029 
2025-08-30 08:38:21.355224: train_loss -0.622 
2025-08-30 08:38:21.362987: val_loss -0.5989 
2025-08-30 08:38:21.367116: Pseudo dice [np.float32(0.7862)] 
2025-08-30 08:38:21.373149: Epoch time: 26.95 s 
2025-08-30 08:38:22.017820:  
2025-08-30 08:38:22.026185: Epoch 748 
2025-08-30 08:38:22.030377: Current learning rate: 0.00029 
2025-08-30 08:38:48.765612: train_loss -0.6423 
2025-08-30 08:38:48.778212: val_loss -0.6073 
2025-08-30 08:38:48.782219: Pseudo dice [np.float32(0.7976)] 
2025-08-30 08:38:48.790408: Epoch time: 26.75 s 
2025-08-30 08:38:49.432635:  
2025-08-30 08:38:49.440993: Epoch 749 
2025-08-30 08:38:49.449556: Current learning rate: 0.00029 
2025-08-30 08:39:16.213858: train_loss -0.6201 
2025-08-30 08:39:16.222261: val_loss -0.5955 
2025-08-30 08:39:16.226387: Pseudo dice [np.float32(0.8209)] 
2025-08-30 08:39:16.233386: Epoch time: 26.78 s 
2025-08-30 08:39:17.085324:  
2025-08-30 08:39:17.093651: Epoch 750 
2025-08-30 08:39:17.101974: Current learning rate: 0.00029 
2025-08-30 08:39:43.783471: train_loss -0.6103 
2025-08-30 08:39:43.791458: val_loss -0.6205 
2025-08-30 08:39:43.795268: Pseudo dice [np.float32(0.8317)] 
2025-08-30 08:39:43.803395: Epoch time: 26.7 s 
2025-08-30 08:39:44.454278:  
2025-08-30 08:39:44.462608: Epoch 751 
2025-08-30 08:39:44.466794: Current learning rate: 0.00029 
2025-08-30 08:40:11.390299: train_loss -0.6182 
2025-08-30 08:40:11.397816: val_loss -0.6405 
2025-08-30 08:40:11.402379: Pseudo dice [np.float32(0.807)] 
2025-08-30 08:40:11.409207: Epoch time: 26.94 s 
2025-08-30 08:40:12.060992:  
2025-08-30 08:40:12.069362: Epoch 752 
2025-08-30 08:40:12.073685: Current learning rate: 0.00029 
2025-08-30 08:40:39.092464: train_loss -0.6537 
2025-08-30 08:40:39.100479: val_loss -0.6498 
2025-08-30 08:40:39.108829: Pseudo dice [np.float32(0.8144)] 
2025-08-30 08:40:39.113030: Epoch time: 27.04 s 
2025-08-30 08:40:39.780329:  
2025-08-30 08:40:39.788703: Epoch 753 
2025-08-30 08:40:39.792867: Current learning rate: 0.00028 
2025-08-30 08:41:06.736770: train_loss -0.6702 
2025-08-30 08:41:06.748740: val_loss -0.6012 
2025-08-30 08:41:06.753401: Pseudo dice [np.float32(0.8069)] 
2025-08-30 08:41:06.760173: Epoch time: 26.96 s 
2025-08-30 08:41:07.407911:  
2025-08-30 08:41:07.416498: Epoch 754 
2025-08-30 08:41:07.424597: Current learning rate: 0.00028 
2025-08-30 08:41:34.460420: train_loss -0.6287 
2025-08-30 08:41:34.468287: val_loss -0.6835 
2025-08-30 08:41:34.476626: Pseudo dice [np.float32(0.8143)] 
2025-08-30 08:41:34.482856: Epoch time: 27.05 s 
2025-08-30 08:41:35.135593:  
2025-08-30 08:41:35.143965: Epoch 755 
2025-08-30 08:41:35.148104: Current learning rate: 0.00028 
2025-08-30 08:42:01.983843: train_loss -0.6635 
2025-08-30 08:42:01.991623: val_loss -0.6644 
2025-08-30 08:42:01.996160: Pseudo dice [np.float32(0.8278)] 
2025-08-30 08:42:02.004252: Epoch time: 26.85 s 
2025-08-30 08:42:02.646476:  
2025-08-30 08:42:02.655130: Epoch 756 
2025-08-30 08:42:02.663438: Current learning rate: 0.00028 
2025-08-30 08:42:29.631914: train_loss -0.6439 
2025-08-30 08:42:29.644047: val_loss -0.6462 
2025-08-30 08:42:29.648670: Pseudo dice [np.float32(0.8463)] 
2025-08-30 08:42:29.654708: Epoch time: 26.99 s 
2025-08-30 08:42:30.307691:  
2025-08-30 08:42:30.315714: Epoch 757 
2025-08-30 08:42:30.319907: Current learning rate: 0.00028 
2025-08-30 08:42:57.218015: train_loss -0.6373 
2025-08-30 08:42:57.229856: val_loss -0.5774 
2025-08-30 08:42:57.234587: Pseudo dice [np.float32(0.8233)] 
2025-08-30 08:42:57.239898: Epoch time: 26.91 s 
2025-08-30 08:42:57.905758:  
2025-08-30 08:42:57.914509: Epoch 758 
2025-08-30 08:42:57.918691: Current learning rate: 0.00028 
2025-08-30 08:43:25.045712: train_loss -0.6524 
2025-08-30 08:43:25.053717: val_loss -0.6201 
2025-08-30 08:43:25.057898: Pseudo dice [np.float32(0.7757)] 
2025-08-30 08:43:25.065990: Epoch time: 27.14 s 
2025-08-30 08:43:25.862917:  
2025-08-30 08:43:25.871234: Epoch 759 
2025-08-30 08:43:25.879550: Current learning rate: 0.00028 
2025-08-30 08:43:52.835585: train_loss -0.6243 
2025-08-30 08:43:52.846288: val_loss -0.6607 
2025-08-30 08:43:52.852315: Pseudo dice [np.float32(0.8351)] 
2025-08-30 08:43:52.857336: Epoch time: 26.97 s 
2025-08-30 08:43:53.532452:  
2025-08-30 08:43:53.540479: Epoch 760 
2025-08-30 08:43:53.548859: Current learning rate: 0.00028 
2025-08-30 08:44:20.333885: train_loss -0.6629 
2025-08-30 08:44:20.341053: val_loss -0.6295 
2025-08-30 08:44:20.348827: Pseudo dice [np.float32(0.8189)] 
2025-08-30 08:44:20.354434: Epoch time: 26.8 s 
2025-08-30 08:44:21.051709:  
2025-08-30 08:44:21.064337: Epoch 761 
2025-08-30 08:44:21.072689: Current learning rate: 0.00028 
2025-08-30 08:44:47.815904: train_loss -0.643 
2025-08-30 08:44:47.823870: val_loss -0.5757 
2025-08-30 08:44:47.832224: Pseudo dice [np.float32(0.7361)] 
2025-08-30 08:44:47.838614: Epoch time: 26.77 s 
2025-08-30 08:44:48.478681:  
2025-08-30 08:44:48.487004: Epoch 762 
2025-08-30 08:44:48.491212: Current learning rate: 0.00027 
2025-08-30 08:45:15.364168: train_loss -0.6662 
2025-08-30 08:45:15.372257: val_loss -0.7011 
2025-08-30 08:45:15.380566: Pseudo dice [np.float32(0.8295)] 
2025-08-30 08:45:15.386862: Epoch time: 26.89 s 
2025-08-30 08:45:16.044040:  
2025-08-30 08:45:16.052078: Epoch 763 
2025-08-30 08:45:16.057283: Current learning rate: 0.00027 
2025-08-30 08:45:43.179151: train_loss -0.6417 
2025-08-30 08:45:43.191664: val_loss -0.6958 
2025-08-30 08:45:43.195837: Pseudo dice [np.float32(0.8188)] 
2025-08-30 08:45:43.201381: Epoch time: 27.14 s 
2025-08-30 08:45:43.855146:  
2025-08-30 08:45:43.863503: Epoch 764 
2025-08-30 08:45:43.867345: Current learning rate: 0.00027 
2025-08-30 08:46:11.219695: train_loss -0.5839 
2025-08-30 08:46:11.228251: val_loss -0.6035 
2025-08-30 08:46:11.232244: Pseudo dice [np.float32(0.808)] 
2025-08-30 08:46:11.240310: Epoch time: 27.37 s 
2025-08-30 08:46:12.062123:  
2025-08-30 08:46:12.070492: Epoch 765 
2025-08-30 08:46:12.074659: Current learning rate: 0.00027 
2025-08-30 08:46:38.901829: train_loss -0.658 
2025-08-30 08:46:38.914270: val_loss -0.66 
2025-08-30 08:46:38.918507: Pseudo dice [np.float32(0.8462)] 
2025-08-30 08:46:38.925314: Epoch time: 26.84 s 
2025-08-30 08:46:39.581306:  
2025-08-30 08:46:39.590075: Epoch 766 
2025-08-30 08:46:39.593802: Current learning rate: 0.00027 
2025-08-30 08:47:06.324718: train_loss -0.6495 
2025-08-30 08:47:06.333041: val_loss -0.6524 
2025-08-30 08:47:06.338385: Pseudo dice [np.float32(0.7978)] 
2025-08-30 08:47:06.345431: Epoch time: 26.74 s 
2025-08-30 08:47:06.996181:  
2025-08-30 08:47:07.004534: Epoch 767 
2025-08-30 08:47:07.012887: Current learning rate: 0.00027 
2025-08-30 08:47:33.928005: train_loss -0.6232 
2025-08-30 08:47:33.935585: val_loss -0.608 
2025-08-30 08:47:33.939731: Pseudo dice [np.float32(0.8317)] 
2025-08-30 08:47:33.948009: Epoch time: 26.93 s 
2025-08-30 08:47:34.623508:  
2025-08-30 08:47:34.627996: Epoch 768 
2025-08-30 08:47:34.636659: Current learning rate: 0.00027 
2025-08-30 08:48:01.647060: train_loss -0.6611 
2025-08-30 08:48:01.654943: val_loss -0.6487 
2025-08-30 08:48:01.659142: Pseudo dice [np.float32(0.8446)] 
2025-08-30 08:48:01.667138: Epoch time: 27.03 s 
2025-08-30 08:48:02.326400:  
2025-08-30 08:48:02.334752: Epoch 769 
2025-08-30 08:48:02.342135: Current learning rate: 0.00027 
2025-08-30 08:48:29.449413: train_loss -0.6334 
2025-08-30 08:48:29.457763: val_loss -0.6462 
2025-08-30 08:48:29.462131: Pseudo dice [np.float32(0.7997)] 
2025-08-30 08:48:29.470285: Epoch time: 27.12 s 
2025-08-30 08:48:30.117020:  
2025-08-30 08:48:30.125006: Epoch 770 
2025-08-30 08:48:30.129172: Current learning rate: 0.00027 
2025-08-30 08:48:57.456511: train_loss -0.6537 
2025-08-30 08:48:57.464836: val_loss -0.6344 
2025-08-30 08:48:57.469315: Pseudo dice [np.float32(0.8174)] 
2025-08-30 08:48:57.475144: Epoch time: 27.34 s 
2025-08-30 08:48:58.282680:  
2025-08-30 08:48:58.294528: Epoch 771 
2025-08-30 08:48:58.299251: Current learning rate: 0.00027 
2025-08-30 08:49:25.388453: train_loss -0.6487 
2025-08-30 08:49:25.396892: val_loss -0.6713 
2025-08-30 08:49:25.401060: Pseudo dice [np.float32(0.8164)] 
2025-08-30 08:49:25.409148: Epoch time: 27.11 s 
2025-08-30 08:49:26.097925:  
2025-08-30 08:49:26.105906: Epoch 772 
2025-08-30 08:49:26.110414: Current learning rate: 0.00026 
2025-08-30 08:49:52.686567: train_loss -0.6536 
2025-08-30 08:49:52.694993: val_loss -0.6512 
2025-08-30 08:49:52.703904: Pseudo dice [np.float32(0.8312)] 
2025-08-30 08:49:52.709562: Epoch time: 26.59 s 
2025-08-30 08:49:53.358145:  
2025-08-30 08:49:53.362314: Epoch 773 
2025-08-30 08:49:53.370638: Current learning rate: 0.00026 
2025-08-30 08:50:20.109885: train_loss -0.6476 
2025-08-30 08:50:20.118425: val_loss -0.5801 
2025-08-30 08:50:20.122366: Pseudo dice [np.float32(0.796)] 
2025-08-30 08:50:20.131570: Epoch time: 26.76 s 
2025-08-30 08:50:20.781348:  
2025-08-30 08:50:20.789743: Epoch 774 
2025-08-30 08:50:20.793941: Current learning rate: 0.00026 
2025-08-30 08:50:47.550058: train_loss -0.6614 
2025-08-30 08:50:47.558042: val_loss -0.633 
2025-08-30 08:50:47.568384: Pseudo dice [np.float32(0.8306)] 
2025-08-30 08:50:47.574757: Epoch time: 26.77 s 
2025-08-30 08:50:48.233727:  
2025-08-30 08:50:48.242116: Epoch 775 
2025-08-30 08:50:48.246627: Current learning rate: 0.00026 
2025-08-30 08:51:15.177593: train_loss -0.6441 
2025-08-30 08:51:15.185674: val_loss -0.6733 
2025-08-30 08:51:15.194112: Pseudo dice [np.float32(0.7719)] 
2025-08-30 08:51:15.198962: Epoch time: 26.95 s 
2025-08-30 08:51:15.857141:  
2025-08-30 08:51:15.865480: Epoch 776 
2025-08-30 08:51:15.869636: Current learning rate: 0.00026 
2025-08-30 08:51:42.943013: train_loss -0.6678 
2025-08-30 08:51:42.955043: val_loss -0.684 
2025-08-30 08:51:42.959249: Pseudo dice [np.float32(0.8121)] 
2025-08-30 08:51:42.966373: Epoch time: 27.09 s 
2025-08-30 08:51:43.622697:  
2025-08-30 08:51:43.631043: Epoch 777 
2025-08-30 08:51:43.638929: Current learning rate: 0.00026 
2025-08-30 08:52:10.395377: train_loss -0.6154 
2025-08-30 08:52:10.403604: val_loss -0.6664 
2025-08-30 08:52:10.407464: Pseudo dice [np.float32(0.8433)] 
2025-08-30 08:52:10.414760: Epoch time: 26.78 s 
2025-08-30 08:52:11.229106:  
2025-08-30 08:52:11.241961: Epoch 778 
2025-08-30 08:52:11.248960: Current learning rate: 0.00026 
2025-08-30 08:52:38.231087: train_loss -0.6525 
2025-08-30 08:52:38.243631: val_loss -0.6364 
2025-08-30 08:52:38.247791: Pseudo dice [np.float32(0.8221)] 
2025-08-30 08:52:38.255001: Epoch time: 27.0 s 
2025-08-30 08:52:38.910951:  
2025-08-30 08:52:38.919652: Epoch 779 
2025-08-30 08:52:38.923689: Current learning rate: 0.00026 
2025-08-30 08:53:05.837794: train_loss -0.6528 
2025-08-30 08:53:05.846639: val_loss -0.6584 
2025-08-30 08:53:05.851875: Pseudo dice [np.float32(0.8094)] 
2025-08-30 08:53:05.857441: Epoch time: 26.93 s 
2025-08-30 08:53:06.513587:  
2025-08-30 08:53:06.521862: Epoch 780 
2025-08-30 08:53:06.526366: Current learning rate: 0.00026 
2025-08-30 08:53:33.648935: train_loss -0.6109 
2025-08-30 08:53:33.661456: val_loss -0.6271 
2025-08-30 08:53:33.665635: Pseudo dice [np.float32(0.7968)] 
2025-08-30 08:53:33.673860: Epoch time: 27.14 s 
2025-08-30 08:53:34.324567:  
2025-08-30 08:53:34.332924: Epoch 781 
2025-08-30 08:53:34.338342: Current learning rate: 0.00025 
2025-08-30 08:54:00.852009: train_loss -0.6382 
2025-08-30 08:54:00.859701: val_loss -0.6663 
2025-08-30 08:54:00.863891: Pseudo dice [np.float32(0.8276)] 
2025-08-30 08:54:00.871656: Epoch time: 26.53 s 
2025-08-30 08:54:01.522588:  
2025-08-30 08:54:01.531270: Epoch 782 
2025-08-30 08:54:01.539300: Current learning rate: 0.00025 
2025-08-30 08:54:28.687194: train_loss -0.6119 
2025-08-30 08:54:28.699714: val_loss -0.6605 
2025-08-30 08:54:28.704322: Pseudo dice [np.float32(0.798)] 
2025-08-30 08:54:28.712067: Epoch time: 27.16 s 
2025-08-30 08:54:29.396277:  
2025-08-30 08:54:29.404874: Epoch 783 
2025-08-30 08:54:29.409094: Current learning rate: 0.00025 
2025-08-30 08:54:56.679699: train_loss -0.6619 
2025-08-30 08:54:56.690482: val_loss -0.6335 
2025-08-30 08:54:56.694645: Pseudo dice [np.float32(0.8052)] 
2025-08-30 08:54:56.703568: Epoch time: 27.29 s 
2025-08-30 08:54:57.515967:  
2025-08-30 08:54:57.524334: Epoch 784 
2025-08-30 08:54:57.532898: Current learning rate: 0.00025 
2025-08-30 08:55:24.555535: train_loss -0.6473 
2025-08-30 08:55:24.563867: val_loss -0.631 
2025-08-30 08:55:24.572221: Pseudo dice [np.float32(0.7953)] 
2025-08-30 08:55:24.577174: Epoch time: 27.04 s 
2025-08-30 08:55:25.231190:  
2025-08-30 08:55:25.239528: Epoch 785 
2025-08-30 08:55:25.243670: Current learning rate: 0.00025 
2025-08-30 08:55:51.866403: train_loss -0.6607 
2025-08-30 08:55:51.878602: val_loss -0.5796 
2025-08-30 08:55:51.882772: Pseudo dice [np.float32(0.7607)] 
2025-08-30 08:55:51.890902: Epoch time: 26.64 s 
2025-08-30 08:55:52.554276:  
2025-08-30 08:55:52.562652: Epoch 786 
2025-08-30 08:55:52.566808: Current learning rate: 0.00025 
2025-08-30 08:56:19.322657: train_loss -0.6492 
2025-08-30 08:56:19.331022: val_loss -0.6484 
2025-08-30 08:56:19.335196: Pseudo dice [np.float32(0.8132)] 
2025-08-30 08:56:19.344244: Epoch time: 26.77 s 
2025-08-30 08:56:20.006988:  
2025-08-30 08:56:20.015343: Epoch 787 
2025-08-30 08:56:20.019300: Current learning rate: 0.00025 
2025-08-30 08:56:46.741756: train_loss -0.6447 
2025-08-30 08:56:46.750058: val_loss -0.6509 
2025-08-30 08:56:46.754206: Pseudo dice [np.float32(0.8123)] 
2025-08-30 08:56:46.763344: Epoch time: 26.74 s 
2025-08-30 08:56:47.409425:  
2025-08-30 08:56:47.417695: Epoch 788 
2025-08-30 08:56:47.421578: Current learning rate: 0.00025 
2025-08-30 08:57:14.073179: train_loss -0.6718 
2025-08-30 08:57:14.081827: val_loss -0.6051 
2025-08-30 08:57:14.085990: Pseudo dice [np.float32(0.8519)] 
2025-08-30 08:57:14.092852: Epoch time: 26.66 s 
2025-08-30 08:57:14.753073:  
2025-08-30 08:57:14.761438: Epoch 789 
2025-08-30 08:57:14.769806: Current learning rate: 0.00025 
2025-08-30 08:57:41.572145: train_loss -0.6668 
2025-08-30 08:57:41.584391: val_loss -0.7214 
2025-08-30 08:57:41.592773: Pseudo dice [np.float32(0.845)] 
2025-08-30 08:57:41.601063: Epoch time: 26.82 s 
2025-08-30 08:57:42.405715:  
2025-08-30 08:57:42.413965: Epoch 790 
2025-08-30 08:57:42.418424: Current learning rate: 0.00025 
2025-08-30 08:58:09.078187: train_loss -0.6653 
2025-08-30 08:58:09.086715: val_loss -0.6795 
2025-08-30 08:58:09.094850: Pseudo dice [np.float32(0.8078)] 
2025-08-30 08:58:09.100172: Epoch time: 26.67 s 
2025-08-30 08:58:09.749633:  
2025-08-30 08:58:09.757954: Epoch 791 
2025-08-30 08:58:09.762144: Current learning rate: 0.00024 
2025-08-30 08:58:37.110264: train_loss -0.6492 
2025-08-30 08:58:37.122798: val_loss -0.6253 
2025-08-30 08:58:37.126990: Pseudo dice [np.float32(0.8207)] 
2025-08-30 08:58:37.134542: Epoch time: 27.36 s 
2025-08-30 08:58:37.777579:  
2025-08-30 08:58:37.786304: Epoch 792 
2025-08-30 08:58:37.790391: Current learning rate: 0.00024 
2025-08-30 08:59:04.955249: train_loss -0.6275 
2025-08-30 08:59:04.963068: val_loss -0.7148 
2025-08-30 08:59:04.971402: Pseudo dice [np.float32(0.8287)] 
2025-08-30 08:59:04.977728: Epoch time: 27.18 s 
2025-08-30 08:59:05.618268:  
2025-08-30 08:59:05.626565: Epoch 793 
2025-08-30 08:59:05.630721: Current learning rate: 0.00024 
2025-08-30 08:59:32.628207: train_loss -0.6477 
2025-08-30 08:59:32.640713: val_loss -0.6365 
2025-08-30 08:59:32.645122: Pseudo dice [np.float32(0.7496)] 
2025-08-30 08:59:32.652072: Epoch time: 27.01 s 
2025-08-30 08:59:33.320574:  
2025-08-30 08:59:33.328929: Epoch 794 
2025-08-30 08:59:33.338459: Current learning rate: 0.00024 
2025-08-30 08:59:59.734312: train_loss -0.6534 
2025-08-30 08:59:59.742854: val_loss -0.5931 
2025-08-30 08:59:59.747260: Pseudo dice [np.float32(0.7893)] 
2025-08-30 08:59:59.754238: Epoch time: 26.41 s 
2025-08-30 09:00:00.402059:  
2025-08-30 09:00:00.410094: Epoch 795 
2025-08-30 09:00:00.414248: Current learning rate: 0.00024 
2025-08-30 09:00:27.170368: train_loss -0.6431 
2025-08-30 09:00:27.178850: val_loss -0.6505 
2025-08-30 09:00:27.182989: Pseudo dice [np.float32(0.7821)] 
2025-08-30 09:00:27.190008: Epoch time: 26.77 s 
2025-08-30 09:00:27.840699:  
2025-08-30 09:00:27.852454: Epoch 796 
2025-08-30 09:00:27.858696: Current learning rate: 0.00024 
2025-08-30 09:00:54.238856: train_loss -0.648 
2025-08-30 09:00:54.247179: val_loss -0.641 
2025-08-30 09:00:54.255383: Pseudo dice [np.float32(0.803)] 
2025-08-30 09:00:54.261085: Epoch time: 26.4 s 
2025-08-30 09:00:55.077160:  
2025-08-30 09:00:55.085591: Epoch 797 
2025-08-30 09:00:55.089696: Current learning rate: 0.00024 
2025-08-30 09:01:21.211874: train_loss -0.6481 
2025-08-30 09:01:21.220289: val_loss -0.6712 
2025-08-30 09:01:21.224130: Pseudo dice [np.float32(0.81)] 
2025-08-30 09:01:21.230231: Epoch time: 26.14 s 
2025-08-30 09:01:21.874779:  
2025-08-30 09:01:21.883414: Epoch 798 
2025-08-30 09:01:21.887403: Current learning rate: 0.00024 
2025-08-30 09:01:48.372238: train_loss -0.6259 
2025-08-30 09:01:48.386897: val_loss -0.6322 
2025-08-30 09:01:48.393329: Pseudo dice [np.float32(0.8013)] 
2025-08-30 09:01:48.399218: Epoch time: 26.5 s 
2025-08-30 09:01:49.048096:  
2025-08-30 09:01:49.056071: Epoch 799 
2025-08-30 09:01:49.060495: Current learning rate: 0.00024 
2025-08-30 09:02:15.524170: train_loss -0.6421 
2025-08-30 09:02:15.532954: val_loss -0.6367 
2025-08-30 09:02:15.540851: Pseudo dice [np.float32(0.7728)] 
2025-08-30 09:02:15.546483: Epoch time: 26.48 s 
2025-08-30 09:02:16.416822:  
2025-08-30 09:02:16.425142: Epoch 800 
2025-08-30 09:02:16.429546: Current learning rate: 0.00023 
2025-08-30 09:02:43.850924: train_loss -0.6372 
2025-08-30 09:02:43.861129: val_loss -0.6836 
2025-08-30 09:02:43.864980: Pseudo dice [np.float32(0.8422)] 
2025-08-30 09:02:43.872178: Epoch time: 27.44 s 
2025-08-30 09:02:44.519775:  
2025-08-30 09:02:44.528134: Epoch 801 
2025-08-30 09:02:44.532332: Current learning rate: 0.00023 
2025-08-30 09:03:11.959684: train_loss -0.6544 
2025-08-30 09:03:11.968022: val_loss -0.5732 
2025-08-30 09:03:11.976368: Pseudo dice [np.float32(0.7512)] 
2025-08-30 09:03:11.982563: Epoch time: 27.44 s 
2025-08-30 09:03:12.640339:  
2025-08-30 09:03:12.647980: Epoch 802 
2025-08-30 09:03:12.656261: Current learning rate: 0.00023 
2025-08-30 09:03:40.271687: train_loss -0.6571 
2025-08-30 09:03:40.284096: val_loss -0.6973 
2025-08-30 09:03:40.288287: Pseudo dice [np.float32(0.7806)] 
2025-08-30 09:03:40.296319: Epoch time: 27.63 s 
2025-08-30 09:03:41.097382:  
2025-08-30 09:03:41.106557: Epoch 803 
2025-08-30 09:03:41.109727: Current learning rate: 0.00023 
2025-08-30 09:04:08.816590: train_loss -0.6502 
2025-08-30 09:04:08.825073: val_loss -0.6165 
2025-08-30 09:04:08.832900: Pseudo dice [np.float32(0.8098)] 
2025-08-30 09:04:08.839192: Epoch time: 27.72 s 
2025-08-30 09:04:09.479608:  
2025-08-30 09:04:09.487982: Epoch 804 
2025-08-30 09:04:09.492119: Current learning rate: 0.00023 
2025-08-30 09:04:36.707377: train_loss -0.6132 
2025-08-30 09:04:36.715164: val_loss -0.6373 
2025-08-30 09:04:36.723889: Pseudo dice [np.float32(0.7813)] 
2025-08-30 09:04:36.728975: Epoch time: 27.23 s 
2025-08-30 09:04:37.378302:  
2025-08-30 09:04:37.386660: Epoch 805 
2025-08-30 09:04:37.390785: Current learning rate: 0.00023 
2025-08-30 09:05:04.953062: train_loss -0.5935 
2025-08-30 09:05:04.960027: val_loss -0.5828 
2025-08-30 09:05:04.964411: Pseudo dice [np.float32(0.7943)] 
2025-08-30 09:05:04.972386: Epoch time: 27.57 s 
2025-08-30 09:05:05.615327:  
2025-08-30 09:05:05.623516: Epoch 806 
2025-08-30 09:05:05.627662: Current learning rate: 0.00023 
2025-08-30 09:05:32.938361: train_loss -0.6547 
2025-08-30 09:05:32.946616: val_loss -0.6533 
2025-08-30 09:05:32.954650: Pseudo dice [np.float32(0.8323)] 
2025-08-30 09:05:32.960005: Epoch time: 27.32 s 
2025-08-30 09:05:33.601110:  
2025-08-30 09:05:33.609462: Epoch 807 
2025-08-30 09:05:33.613630: Current learning rate: 0.00023 
2025-08-30 09:06:00.687253: train_loss -0.6412 
2025-08-30 09:06:00.695148: val_loss -0.6019 
2025-08-30 09:06:00.702936: Pseudo dice [np.float32(0.8164)] 
2025-08-30 09:06:00.707362: Epoch time: 27.09 s 
2025-08-30 09:06:01.357997:  
2025-08-30 09:06:01.366354: Epoch 808 
2025-08-30 09:06:01.374691: Current learning rate: 0.00023 
2025-08-30 09:06:28.564507: train_loss -0.6389 
2025-08-30 09:06:28.572740: val_loss -0.7143 
2025-08-30 09:06:28.581096: Pseudo dice [np.float32(0.8316)] 
2025-08-30 09:06:28.587356: Epoch time: 27.21 s 
2025-08-30 09:06:29.240080:  
2025-08-30 09:06:29.248574: Epoch 809 
2025-08-30 09:06:29.256686: Current learning rate: 0.00023 
2025-08-30 09:06:56.371289: train_loss -0.6094 
2025-08-30 09:06:56.379619: val_loss -0.6966 
2025-08-30 09:06:56.387943: Pseudo dice [np.float32(0.8098)] 
2025-08-30 09:06:56.392930: Epoch time: 27.13 s 
2025-08-30 09:06:57.197349:  
2025-08-30 09:06:57.209354: Epoch 810 
2025-08-30 09:06:57.214160: Current learning rate: 0.00022 
2025-08-30 09:07:24.553882: train_loss -0.657 
2025-08-30 09:07:24.561958: val_loss -0.6002 
2025-08-30 09:07:24.566194: Pseudo dice [np.float32(0.8292)] 
2025-08-30 09:07:24.574431: Epoch time: 27.36 s 
2025-08-30 09:07:25.304338:  
2025-08-30 09:07:25.312662: Epoch 811 
2025-08-30 09:07:25.316818: Current learning rate: 0.00022 
2025-08-30 09:07:53.011167: train_loss -0.684 
2025-08-30 09:07:53.019511: val_loss -0.6111 
2025-08-30 09:07:53.027844: Pseudo dice [np.float32(0.8111)] 
2025-08-30 09:07:53.033420: Epoch time: 27.71 s 
2025-08-30 09:07:53.686830:  
2025-08-30 09:07:53.695284: Epoch 812 
2025-08-30 09:07:53.699692: Current learning rate: 0.00022 
2025-08-30 09:08:20.889323: train_loss -0.6335 
2025-08-30 09:08:20.897381: val_loss -0.6928 
2025-08-30 09:08:20.905684: Pseudo dice [np.float32(0.8481)] 
2025-08-30 09:08:20.910708: Epoch time: 27.21 s 
2025-08-30 09:08:21.560540:  
2025-08-30 09:08:21.568867: Epoch 813 
2025-08-30 09:08:21.573299: Current learning rate: 0.00022 
2025-08-30 09:08:48.474710: train_loss -0.6332 
2025-08-30 09:08:48.483298: val_loss -0.6268 
2025-08-30 09:08:48.487632: Pseudo dice [np.float32(0.8241)] 
2025-08-30 09:08:48.495740: Epoch time: 26.92 s 
2025-08-30 09:08:49.150595:  
2025-08-30 09:08:49.158918: Epoch 814 
2025-08-30 09:08:49.163078: Current learning rate: 0.00022 
2025-08-30 09:09:16.419751: train_loss -0.638 
2025-08-30 09:09:16.427867: val_loss -0.6105 
2025-08-30 09:09:16.436221: Pseudo dice [np.float32(0.7912)] 
2025-08-30 09:09:16.441723: Epoch time: 27.27 s 
2025-08-30 09:09:17.111864:  
2025-08-30 09:09:17.120502: Epoch 815 
2025-08-30 09:09:17.124616: Current learning rate: 0.00022 
2025-08-30 09:09:44.672736: train_loss -0.6463 
2025-08-30 09:09:44.685014: val_loss -0.601 
2025-08-30 09:09:44.689660: Pseudo dice [np.float32(0.8221)] 
2025-08-30 09:09:44.696762: Epoch time: 27.57 s 
2025-08-30 09:09:45.507066:  
2025-08-30 09:09:45.515194: Epoch 816 
2025-08-30 09:09:45.519326: Current learning rate: 0.00022 
2025-08-30 09:10:12.951253: train_loss -0.6328 
2025-08-30 09:10:12.959527: val_loss -0.6325 
2025-08-30 09:10:12.967250: Pseudo dice [np.float32(0.8111)] 
2025-08-30 09:10:12.971755: Epoch time: 27.45 s 
2025-08-30 09:10:13.622401:  
2025-08-30 09:10:13.631118: Epoch 817 
2025-08-30 09:10:13.639073: Current learning rate: 0.00022 
2025-08-30 09:10:40.532731: train_loss -0.6713 
2025-08-30 09:10:40.541236: val_loss -0.674 
2025-08-30 09:10:40.545406: Pseudo dice [np.float32(0.8136)] 
2025-08-30 09:10:40.552329: Epoch time: 26.91 s 
2025-08-30 09:10:41.225197:  
2025-08-30 09:10:41.229131: Epoch 818 
2025-08-30 09:10:41.237784: Current learning rate: 0.00022 
2025-08-30 09:11:08.990508: train_loss -0.6291 
2025-08-30 09:11:08.998568: val_loss -0.6391 
2025-08-30 09:11:09.003020: Pseudo dice [np.float32(0.8116)] 
2025-08-30 09:11:09.009787: Epoch time: 27.77 s 
2025-08-30 09:11:09.653323:  
2025-08-30 09:11:09.661923: Epoch 819 
2025-08-30 09:11:09.665844: Current learning rate: 0.00021 
2025-08-30 09:11:36.926626: train_loss -0.6485 
2025-08-30 09:11:36.935110: val_loss -0.676 
2025-08-30 09:11:36.943432: Pseudo dice [np.float32(0.8489)] 
2025-08-30 09:11:36.948564: Epoch time: 27.27 s 
2025-08-30 09:11:37.568769:  
2025-08-30 09:11:37.577128: Epoch 820 
2025-08-30 09:11:37.585475: Current learning rate: 0.00021 
2025-08-30 09:12:05.194215: train_loss -0.6467 
2025-08-30 09:12:05.200779: val_loss -0.6354 
2025-08-30 09:12:05.208821: Pseudo dice [np.float32(0.8177)] 
2025-08-30 09:12:05.217086: Epoch time: 27.63 s 
2025-08-30 09:12:05.845424:  
2025-08-30 09:12:05.851500: Epoch 821 
2025-08-30 09:12:05.859473: Current learning rate: 0.00021 
2025-08-30 09:12:33.195208: train_loss -0.6743 
2025-08-30 09:12:33.207380: val_loss -0.6851 
2025-08-30 09:12:33.212014: Pseudo dice [np.float32(0.8232)] 
2025-08-30 09:12:33.218042: Epoch time: 27.35 s 
2025-08-30 09:12:33.848161:  
2025-08-30 09:12:33.854448: Epoch 822 
2025-08-30 09:12:33.862197: Current learning rate: 0.00021 
2025-08-30 09:13:01.289805: train_loss -0.6529 
2025-08-30 09:13:01.298194: val_loss -0.6833 
2025-08-30 09:13:01.306546: Pseudo dice [np.float32(0.8472)] 
2025-08-30 09:13:01.311503: Epoch time: 27.44 s 
2025-08-30 09:13:01.315696: Yayy! New best EMA pseudo Dice: 0.8198999762535095 
2025-08-30 09:13:02.407594:  
2025-08-30 09:13:02.415949: Epoch 823 
2025-08-30 09:13:02.420345: Current learning rate: 0.00021 
2025-08-30 09:13:30.039381: train_loss -0.6726 
2025-08-30 09:13:30.051908: val_loss -0.649 
2025-08-30 09:13:30.056264: Pseudo dice [np.float32(0.8405)] 
2025-08-30 09:13:30.065326: Epoch time: 27.63 s 
2025-08-30 09:13:30.070917: Yayy! New best EMA pseudo Dice: 0.8220000267028809 
2025-08-30 09:13:30.927828:  
2025-08-30 09:13:30.936082: Epoch 824 
2025-08-30 09:13:30.940475: Current learning rate: 0.00021 
2025-08-30 09:13:56.891167: train_loss -0.7069 
2025-08-30 09:13:56.899532: val_loss -0.667 
2025-08-30 09:13:56.904055: Pseudo dice [np.float32(0.8451)] 
2025-08-30 09:13:56.910845: Epoch time: 25.96 s 
2025-08-30 09:13:56.916512: Yayy! New best EMA pseudo Dice: 0.8242999911308289 
2025-08-30 09:13:57.763288:  
2025-08-30 09:13:57.771224: Epoch 825 
2025-08-30 09:13:57.775979: Current learning rate: 0.00021 
2025-08-30 09:14:24.853457: train_loss -0.6394 
2025-08-30 09:14:24.861047: val_loss -0.6115 
2025-08-30 09:14:24.869438: Pseudo dice [np.float32(0.7982)] 
2025-08-30 09:14:24.874365: Epoch time: 27.09 s 
2025-08-30 09:14:25.491021:  
2025-08-30 09:14:25.498914: Epoch 826 
2025-08-30 09:14:25.506978: Current learning rate: 0.00021 
2025-08-30 09:14:52.746989: train_loss -0.6899 
2025-08-30 09:14:52.759462: val_loss -0.6281 
2025-08-30 09:14:52.763628: Pseudo dice [np.float32(0.8162)] 
2025-08-30 09:14:52.772974: Epoch time: 27.26 s 
2025-08-30 09:14:53.393692:  
2025-08-30 09:14:53.401772: Epoch 827 
2025-08-30 09:14:53.406494: Current learning rate: 0.00021 
2025-08-30 09:15:20.537245: train_loss -0.633 
2025-08-30 09:15:20.545534: val_loss -0.6208 
2025-08-30 09:15:20.549670: Pseudo dice [np.float32(0.8254)] 
2025-08-30 09:15:20.559096: Epoch time: 27.15 s 
2025-08-30 09:15:21.183887:  
2025-08-30 09:15:21.192017: Epoch 828 
2025-08-30 09:15:21.196185: Current learning rate: 0.00021 
2025-08-30 09:15:48.435872: train_loss -0.6369 
2025-08-30 09:15:48.444225: val_loss -0.5704 
2025-08-30 09:15:48.454467: Pseudo dice [np.float32(0.7657)] 
2025-08-30 09:15:48.459080: Epoch time: 27.26 s 
2025-08-30 09:15:49.228328:  
2025-08-30 09:15:49.236691: Epoch 829 
2025-08-30 09:15:49.240832: Current learning rate: 0.0002 
2025-08-30 09:16:16.547714: train_loss -0.6584 
2025-08-30 09:16:16.555973: val_loss -0.6482 
2025-08-30 09:16:16.560105: Pseudo dice [np.float32(0.7915)] 
2025-08-30 09:16:16.567967: Epoch time: 27.32 s 
2025-08-30 09:16:17.189579:  
2025-08-30 09:16:17.197944: Epoch 830 
2025-08-30 09:16:17.202459: Current learning rate: 0.0002 
2025-08-30 09:16:44.383732: train_loss -0.6597 
2025-08-30 09:16:44.395962: val_loss -0.6301 
2025-08-30 09:16:44.400105: Pseudo dice [np.float32(0.8649)] 
2025-08-30 09:16:44.408472: Epoch time: 27.2 s 
2025-08-30 09:16:45.030976:  
2025-08-30 09:16:45.038237: Epoch 831 
2025-08-30 09:16:45.042708: Current learning rate: 0.0002 
2025-08-30 09:17:12.636909: train_loss -0.6509 
2025-08-30 09:17:12.645286: val_loss -0.6648 
2025-08-30 09:17:12.653048: Pseudo dice [np.float32(0.818)] 
2025-08-30 09:17:12.658450: Epoch time: 27.61 s 
2025-08-30 09:17:13.287257:  
2025-08-30 09:17:13.295594: Epoch 832 
2025-08-30 09:17:13.299816: Current learning rate: 0.0002 
2025-08-30 09:17:40.527301: train_loss -0.6281 
2025-08-30 09:17:40.539566: val_loss -0.6176 
2025-08-30 09:17:40.544770: Pseudo dice [np.float32(0.8257)] 
2025-08-30 09:17:40.551106: Epoch time: 27.24 s 
2025-08-30 09:17:41.165136:  
2025-08-30 09:17:41.173786: Epoch 833 
2025-08-30 09:17:41.178103: Current learning rate: 0.0002 
2025-08-30 09:18:08.117335: train_loss -0.6455 
2025-08-30 09:18:08.125567: val_loss -0.6705 
2025-08-30 09:18:08.134070: Pseudo dice [np.float32(0.7985)] 
2025-08-30 09:18:08.139338: Epoch time: 26.95 s 
2025-08-30 09:18:08.767862:  
2025-08-30 09:18:08.776365: Epoch 834 
2025-08-30 09:18:08.780167: Current learning rate: 0.0002 
2025-08-30 09:18:35.724079: train_loss -0.649 
2025-08-30 09:18:35.736347: val_loss -0.647 
2025-08-30 09:18:35.740782: Pseudo dice [np.float32(0.8103)] 
2025-08-30 09:18:35.748670: Epoch time: 26.96 s 
2025-08-30 09:18:36.395634:  
2025-08-30 09:18:36.403952: Epoch 835 
2025-08-30 09:18:36.412276: Current learning rate: 0.0002 
2025-08-30 09:19:03.881289: train_loss -0.6674 
2025-08-30 09:19:03.889351: val_loss -0.6633 
2025-08-30 09:19:03.893938: Pseudo dice [np.float32(0.8434)] 
2025-08-30 09:19:03.902877: Epoch time: 27.49 s 
2025-08-30 09:19:04.698500:  
2025-08-30 09:19:04.706849: Epoch 836 
2025-08-30 09:19:04.711305: Current learning rate: 0.0002 
2025-08-30 09:19:31.366868: train_loss -0.6266 
2025-08-30 09:19:31.375180: val_loss -0.6686 
2025-08-30 09:19:31.383504: Pseudo dice [np.float32(0.8487)] 
2025-08-30 09:19:31.388428: Epoch time: 26.67 s 
2025-08-30 09:19:32.000854:  
2025-08-30 09:19:32.009509: Epoch 837 
2025-08-30 09:19:32.020585: Current learning rate: 0.0002 
2025-08-30 09:19:59.245134: train_loss -0.65 
2025-08-30 09:19:59.252970: val_loss -0.6132 
2025-08-30 09:19:59.261481: Pseudo dice [np.float32(0.8064)] 
2025-08-30 09:19:59.268612: Epoch time: 27.24 s 
2025-08-30 09:19:59.891153:  
2025-08-30 09:19:59.899507: Epoch 838 
2025-08-30 09:19:59.905916: Current learning rate: 0.00019 
2025-08-30 09:20:27.070357: train_loss -0.6534 
2025-08-30 09:20:27.081870: val_loss -0.6487 
2025-08-30 09:20:27.089568: Pseudo dice [np.float32(0.8124)] 
2025-08-30 09:20:27.101601: Epoch time: 27.18 s 
2025-08-30 09:20:27.756461:  
2025-08-30 09:20:27.769364: Epoch 839 
2025-08-30 09:20:27.777637: Current learning rate: 0.00019 
2025-08-30 09:20:55.000285: train_loss -0.6227 
2025-08-30 09:20:55.009154: val_loss -0.6293 
2025-08-30 09:20:55.012856: Pseudo dice [np.float32(0.8473)] 
2025-08-30 09:20:55.020020: Epoch time: 27.24 s 
2025-08-30 09:20:55.634266:  
2025-08-30 09:20:55.642615: Epoch 840 
2025-08-30 09:20:55.651286: Current learning rate: 0.00019 
2025-08-30 09:21:22.565671: train_loss -0.6545 
2025-08-30 09:21:22.573701: val_loss -0.6529 
2025-08-30 09:21:22.582533: Pseudo dice [np.float32(0.8361)] 
2025-08-30 09:21:22.587524: Epoch time: 26.93 s 
2025-08-30 09:21:23.211901:  
2025-08-30 09:21:23.220272: Epoch 841 
2025-08-30 09:21:23.224389: Current learning rate: 0.00019 
2025-08-30 09:21:50.422554: train_loss -0.6676 
2025-08-30 09:21:50.434816: val_loss -0.7068 
2025-08-30 09:21:50.438996: Pseudo dice [np.float32(0.8587)] 
2025-08-30 09:21:50.447241: Epoch time: 27.21 s 
2025-08-30 09:21:50.452897: Yayy! New best EMA pseudo Dice: 0.8274000287055969 
2025-08-30 09:21:51.373610:  
2025-08-30 09:21:51.381646: Epoch 842 
2025-08-30 09:21:51.386092: Current learning rate: 0.00019 
2025-08-30 09:22:18.558779: train_loss -0.65 
2025-08-30 09:22:18.567092: val_loss -0.6684 
2025-08-30 09:22:18.571638: Pseudo dice [np.float32(0.8225)] 
2025-08-30 09:22:18.577530: Epoch time: 27.19 s 
2025-08-30 09:22:19.401277:  
2025-08-30 09:22:19.409606: Epoch 843 
2025-08-30 09:22:19.413755: Current learning rate: 0.00019 
2025-08-30 09:22:46.511964: train_loss -0.6745 
2025-08-30 09:22:46.520036: val_loss -0.6668 
2025-08-30 09:22:46.524174: Pseudo dice [np.float32(0.822)] 
2025-08-30 09:22:46.532612: Epoch time: 27.11 s 
2025-08-30 09:22:47.145926:  
2025-08-30 09:22:47.158463: Epoch 844 
2025-08-30 09:22:47.162684: Current learning rate: 0.00019 
2025-08-30 09:23:14.327444: train_loss -0.6559 
2025-08-30 09:23:14.335267: val_loss -0.6163 
2025-08-30 09:23:14.341644: Pseudo dice [np.float32(0.8097)] 
2025-08-30 09:23:14.348748: Epoch time: 27.18 s 
2025-08-30 09:23:14.973811:  
2025-08-30 09:23:14.981761: Epoch 845 
2025-08-30 09:23:14.990100: Current learning rate: 0.00019 
2025-08-30 09:23:42.204828: train_loss -0.6554 
2025-08-30 09:23:42.217281: val_loss -0.7253 
2025-08-30 09:23:42.221713: Pseudo dice [np.float32(0.8535)] 
2025-08-30 09:23:42.227588: Epoch time: 27.23 s 
2025-08-30 09:23:42.234324: Yayy! New best EMA pseudo Dice: 0.8276000022888184 
2025-08-30 09:23:43.059784:  
2025-08-30 09:23:43.068175: Epoch 846 
2025-08-30 09:23:43.076467: Current learning rate: 0.00019 
2025-08-30 09:24:10.457980: train_loss -0.6741 
2025-08-30 09:24:10.466691: val_loss -0.6635 
2025-08-30 09:24:10.474945: Pseudo dice [np.float32(0.8458)] 
2025-08-30 09:24:10.480840: Epoch time: 27.4 s 
2025-08-30 09:24:10.487158: Yayy! New best EMA pseudo Dice: 0.8294000029563904 
2025-08-30 09:24:11.309127:  
2025-08-30 09:24:11.317524: Epoch 847 
2025-08-30 09:24:11.321681: Current learning rate: 0.00018 
2025-08-30 09:24:38.244785: train_loss -0.6527 
2025-08-30 09:24:38.256570: val_loss -0.6382 
2025-08-30 09:24:38.261002: Pseudo dice [np.float32(0.8411)] 
2025-08-30 09:24:38.267037: Epoch time: 26.94 s 
2025-08-30 09:24:38.274678: Yayy! New best EMA pseudo Dice: 0.8306000232696533 
2025-08-30 09:24:39.107398:  
2025-08-30 09:24:39.117022: Epoch 848 
2025-08-30 09:24:39.124462: Current learning rate: 0.00018 
2025-08-30 09:25:05.838923: train_loss -0.6535 
2025-08-30 09:25:05.848135: val_loss -0.6401 
2025-08-30 09:25:05.853455: Pseudo dice [np.float32(0.8102)] 
2025-08-30 09:25:05.858859: Epoch time: 26.73 s 
2025-08-30 09:25:06.480675:  
2025-08-30 09:25:06.489001: Epoch 849 
2025-08-30 09:25:06.497635: Current learning rate: 0.00018 
2025-08-30 09:25:33.499439: train_loss -0.6256 
2025-08-30 09:25:33.507595: val_loss -0.7143 
2025-08-30 09:25:33.511743: Pseudo dice [np.float32(0.8568)] 
2025-08-30 09:25:33.519865: Epoch time: 27.02 s 
2025-08-30 09:25:33.916388: Yayy! New best EMA pseudo Dice: 0.8313999772071838 
2025-08-30 09:25:34.771322:  
2025-08-30 09:25:34.779698: Epoch 850 
2025-08-30 09:25:34.788044: Current learning rate: 0.00018 
2025-08-30 09:26:02.170814: train_loss -0.6575 
2025-08-30 09:26:02.178199: val_loss -0.6369 
2025-08-30 09:26:02.182383: Pseudo dice [np.float32(0.8189)] 
2025-08-30 09:26:02.191245: Epoch time: 27.4 s 
2025-08-30 09:26:02.795454:  
2025-08-30 09:26:02.805410: Epoch 851 
2025-08-30 09:26:02.812176: Current learning rate: 0.00018 
2025-08-30 09:26:30.035002: train_loss -0.646 
2025-08-30 09:26:30.043180: val_loss -0.6299 
2025-08-30 09:26:30.051561: Pseudo dice [np.float32(0.8432)] 
2025-08-30 09:26:30.057072: Epoch time: 27.24 s 
2025-08-30 09:26:30.060864: Yayy! New best EMA pseudo Dice: 0.8313999772071838 
2025-08-30 09:26:30.877373:  
2025-08-30 09:26:30.886134: Epoch 852 
2025-08-30 09:26:30.894173: Current learning rate: 0.00018 
2025-08-30 09:26:56.949558: train_loss -0.623 
2025-08-30 09:26:56.957594: val_loss -0.6677 
2025-08-30 09:26:56.965940: Pseudo dice [np.float32(0.8199)] 
2025-08-30 09:26:56.970923: Epoch time: 26.07 s 
2025-08-30 09:26:57.587330:  
2025-08-30 09:26:57.595730: Epoch 853 
2025-08-30 09:26:57.600119: Current learning rate: 0.00018 
2025-08-30 09:27:23.813691: train_loss -0.6651 
2025-08-30 09:27:23.822234: val_loss -0.6284 
2025-08-30 09:27:23.826054: Pseudo dice [np.float32(0.8175)] 
2025-08-30 09:27:23.832271: Epoch time: 26.23 s 
2025-08-30 09:27:24.456164:  
2025-08-30 09:27:24.464550: Epoch 854 
2025-08-30 09:27:24.468368: Current learning rate: 0.00018 
2025-08-30 09:27:50.839357: train_loss -0.662 
2025-08-30 09:27:50.850416: val_loss -0.6297 
2025-08-30 09:27:50.853388: Pseudo dice [np.float32(0.8183)] 
2025-08-30 09:27:50.861470: Epoch time: 26.39 s 
2025-08-30 09:27:51.482851:  
2025-08-30 09:27:51.491205: Epoch 855 
2025-08-30 09:27:51.495304: Current learning rate: 0.00018 
2025-08-30 09:28:16.872950: train_loss -0.6428 
2025-08-30 09:28:16.879278: val_loss -0.6156 
2025-08-30 09:28:16.883132: Pseudo dice [np.float32(0.8405)] 
2025-08-30 09:28:16.891305: Epoch time: 25.39 s 
2025-08-30 09:28:17.654821:  
2025-08-30 09:28:17.663167: Epoch 856 
2025-08-30 09:28:17.671513: Current learning rate: 0.00017 
2025-08-30 09:28:43.768572: train_loss -0.6595 
2025-08-30 09:28:43.781010: val_loss -0.6112 
2025-08-30 09:28:43.785397: Pseudo dice [np.float32(0.8168)] 
2025-08-30 09:28:43.791235: Epoch time: 26.11 s 
2025-08-30 09:28:44.406498:  
2025-08-30 09:28:44.414885: Epoch 857 
2025-08-30 09:28:44.419015: Current learning rate: 0.00017 
2025-08-30 09:29:10.787155: train_loss -0.6636 
2025-08-30 09:29:10.795398: val_loss -0.6597 
2025-08-30 09:29:10.799498: Pseudo dice [np.float32(0.8318)] 
2025-08-30 09:29:10.805883: Epoch time: 26.38 s 
2025-08-30 09:29:11.429307:  
2025-08-30 09:29:11.433802: Epoch 858 
2025-08-30 09:29:11.441912: Current learning rate: 0.00017 
2025-08-30 09:29:37.939588: train_loss -0.6572 
2025-08-30 09:29:37.951975: val_loss -0.6442 
2025-08-30 09:29:37.956148: Pseudo dice [np.float32(0.8032)] 
2025-08-30 09:29:37.965024: Epoch time: 26.51 s 
2025-08-30 09:29:38.577284:  
2025-08-30 09:29:38.585623: Epoch 859 
2025-08-30 09:29:38.589728: Current learning rate: 0.00017 
2025-08-30 09:30:05.033217: train_loss -0.6387 
2025-08-30 09:30:05.041238: val_loss -0.6793 
2025-08-30 09:30:05.045369: Pseudo dice [np.float32(0.8083)] 
2025-08-30 09:30:05.052681: Epoch time: 26.46 s 
2025-08-30 09:30:05.671373:  
2025-08-30 09:30:05.679722: Epoch 860 
2025-08-30 09:30:05.683518: Current learning rate: 0.00017 
2025-08-30 09:30:32.005994: train_loss -0.6939 
2025-08-30 09:30:32.014305: val_loss -0.6302 
2025-08-30 09:30:32.018139: Pseudo dice [np.float32(0.8013)] 
2025-08-30 09:30:32.027396: Epoch time: 26.34 s 
2025-08-30 09:30:32.643753:  
2025-08-30 09:30:32.647969: Epoch 861 
2025-08-30 09:30:32.656673: Current learning rate: 0.00017 
2025-08-30 09:30:58.291293: train_loss -0.664 
2025-08-30 09:30:58.299150: val_loss -0.6086 
2025-08-30 09:30:58.307155: Pseudo dice [np.float32(0.815)] 
2025-08-30 09:30:58.314589: Epoch time: 25.65 s 
2025-08-30 09:30:58.932811:  
2025-08-30 09:30:58.940859: Epoch 862 
2025-08-30 09:30:58.945041: Current learning rate: 0.00017 
2025-08-30 09:31:24.658866: train_loss -0.6472 
2025-08-30 09:31:24.666981: val_loss -0.6617 
2025-08-30 09:31:24.670966: Pseudo dice [np.float32(0.8182)] 
2025-08-30 09:31:24.680036: Epoch time: 25.73 s 
2025-08-30 09:31:25.304668:  
2025-08-30 09:31:25.313230: Epoch 863 
2025-08-30 09:31:25.317134: Current learning rate: 0.00017 
2025-08-30 09:31:52.732070: train_loss -0.6382 
2025-08-30 09:31:52.744579: val_loss -0.5519 
2025-08-30 09:31:52.752946: Pseudo dice [np.float32(0.8041)] 
2025-08-30 09:31:52.758431: Epoch time: 27.43 s 
2025-08-30 09:31:53.370255:  
2025-08-30 09:31:53.378602: Epoch 864 
2025-08-30 09:31:53.383060: Current learning rate: 0.00017 
2025-08-30 09:32:20.354680: train_loss -0.6551 
2025-08-30 09:32:20.363823: val_loss -0.6431 
2025-08-30 09:32:20.367975: Pseudo dice [np.float32(0.839)] 
2025-08-30 09:32:20.375067: Epoch time: 26.99 s 
2025-08-30 09:32:20.985783:  
2025-08-30 09:32:20.993700: Epoch 865 
2025-08-30 09:32:20.998081: Current learning rate: 0.00016 
2025-08-30 09:32:47.586840: train_loss -0.6472 
2025-08-30 09:32:47.599686: val_loss -0.6839 
2025-08-30 09:32:47.603851: Pseudo dice [np.float32(0.8278)] 
2025-08-30 09:32:47.610664: Epoch time: 26.6 s 
2025-08-30 09:32:48.224971:  
2025-08-30 09:32:48.229179: Epoch 866 
2025-08-30 09:32:48.237512: Current learning rate: 0.00016 
2025-08-30 09:33:15.543916: train_loss -0.6161 
2025-08-30 09:33:15.552269: val_loss -0.6079 
2025-08-30 09:33:15.556430: Pseudo dice [np.float32(0.8359)] 
2025-08-30 09:33:15.563665: Epoch time: 27.32 s 
2025-08-30 09:33:16.207062:  
2025-08-30 09:33:16.215414: Epoch 867 
2025-08-30 09:33:16.219978: Current learning rate: 0.00016 
2025-08-30 09:33:43.400890: train_loss -0.6417 
2025-08-30 09:33:43.409281: val_loss -0.671 
2025-08-30 09:33:43.417610: Pseudo dice [np.float32(0.8298)] 
2025-08-30 09:33:43.423233: Epoch time: 27.2 s 
2025-08-30 09:33:44.039041:  
2025-08-30 09:33:44.047970: Epoch 868 
2025-08-30 09:33:44.051896: Current learning rate: 0.00016 
2025-08-30 09:34:11.487627: train_loss -0.6505 
2025-08-30 09:34:11.495933: val_loss -0.6475 
2025-08-30 09:34:11.503665: Pseudo dice [np.float32(0.8357)] 
2025-08-30 09:34:11.508197: Epoch time: 27.45 s 
2025-08-30 09:34:12.121239:  
2025-08-30 09:34:12.129582: Epoch 869 
2025-08-30 09:34:12.133745: Current learning rate: 0.00016 
2025-08-30 09:34:38.973344: train_loss -0.6568 
2025-08-30 09:34:38.981717: val_loss -0.5925 
2025-08-30 09:34:38.990052: Pseudo dice [np.float32(0.8202)] 
2025-08-30 09:34:38.995930: Epoch time: 26.86 s 
2025-08-30 09:34:39.615568:  
2025-08-30 09:34:39.623694: Epoch 870 
2025-08-30 09:34:39.632062: Current learning rate: 0.00016 
2025-08-30 09:35:06.963799: train_loss -0.6237 
2025-08-30 09:35:06.971893: val_loss -0.6093 
2025-08-30 09:35:06.980230: Pseudo dice [np.float32(0.823)] 
2025-08-30 09:35:06.985663: Epoch time: 27.35 s 
2025-08-30 09:35:07.593259:  
2025-08-30 09:35:07.601672: Epoch 871 
2025-08-30 09:35:07.606138: Current learning rate: 0.00016 
2025-08-30 09:35:34.570774: train_loss -0.6321 
2025-08-30 09:35:34.578899: val_loss -0.7097 
2025-08-30 09:35:34.582736: Pseudo dice [np.float32(0.8445)] 
2025-08-30 09:35:34.592275: Epoch time: 26.98 s 
2025-08-30 09:35:35.208356:  
2025-08-30 09:35:35.212863: Epoch 872 
2025-08-30 09:35:35.220884: Current learning rate: 0.00016 
2025-08-30 09:36:02.068513: train_loss -0.6267 
2025-08-30 09:36:02.076862: val_loss -0.6016 
2025-08-30 09:36:02.085545: Pseudo dice [np.float32(0.8193)] 
2025-08-30 09:36:02.092459: Epoch time: 26.86 s 
2025-08-30 09:36:02.702806:  
2025-08-30 09:36:02.711123: Epoch 873 
2025-08-30 09:36:02.720038: Current learning rate: 0.00016 
2025-08-30 09:36:29.191262: train_loss -0.6326 
2025-08-30 09:36:29.199861: val_loss -0.6356 
2025-08-30 09:36:29.204015: Pseudo dice [np.float32(0.8087)] 
2025-08-30 09:36:29.213156: Epoch time: 26.49 s 
2025-08-30 09:36:29.967208:  
2025-08-30 09:36:29.975586: Epoch 874 
2025-08-30 09:36:29.980160: Current learning rate: 0.00016 
2025-08-30 09:36:56.694813: train_loss -0.6358 
2025-08-30 09:36:56.702553: val_loss -0.7174 
2025-08-30 09:36:56.706492: Pseudo dice [np.float32(0.8678)] 
2025-08-30 09:36:56.715778: Epoch time: 26.73 s 
2025-08-30 09:36:57.327599:  
2025-08-30 09:36:57.332113: Epoch 875 
2025-08-30 09:36:57.339135: Current learning rate: 0.00015 
2025-08-30 09:37:24.146296: train_loss -0.6432 
2025-08-30 09:37:24.154638: val_loss -0.6667 
2025-08-30 09:37:24.162994: Pseudo dice [np.float32(0.8193)] 
2025-08-30 09:37:24.169180: Epoch time: 26.82 s 
2025-08-30 09:37:24.792817:  
2025-08-30 09:37:24.801249: Epoch 876 
2025-08-30 09:37:24.805315: Current learning rate: 0.00015 
2025-08-30 09:37:51.607059: train_loss -0.6718 
2025-08-30 09:37:51.619901: val_loss -0.7182 
2025-08-30 09:37:51.623761: Pseudo dice [np.float32(0.8602)] 
2025-08-30 09:37:51.631880: Epoch time: 26.81 s 
2025-08-30 09:37:52.245301:  
2025-08-30 09:37:52.253636: Epoch 877 
2025-08-30 09:37:52.258044: Current learning rate: 0.00015 
2025-08-30 09:38:19.414026: train_loss -0.6927 
2025-08-30 09:38:19.422347: val_loss -0.633 
2025-08-30 09:38:19.426509: Pseudo dice [np.float32(0.8097)] 
2025-08-30 09:38:19.435616: Epoch time: 27.17 s 
2025-08-30 09:38:20.064932:  
2025-08-30 09:38:20.072994: Epoch 878 
2025-08-30 09:38:20.077160: Current learning rate: 0.00015 
2025-08-30 09:38:46.920600: train_loss -0.6394 
2025-08-30 09:38:46.933137: val_loss -0.6498 
2025-08-30 09:38:46.937316: Pseudo dice [np.float32(0.8554)] 
2025-08-30 09:38:46.946486: Epoch time: 26.86 s 
2025-08-30 09:38:47.554916:  
2025-08-30 09:38:47.562975: Epoch 879 
2025-08-30 09:38:47.567412: Current learning rate: 0.00015 
2025-08-30 09:39:14.560728: train_loss -0.6623 
2025-08-30 09:39:14.569093: val_loss -0.6296 
2025-08-30 09:39:14.577446: Pseudo dice [np.float32(0.8114)] 
2025-08-30 09:39:14.582734: Epoch time: 27.01 s 
2025-08-30 09:39:15.207194:  
2025-08-30 09:39:15.211711: Epoch 880 
2025-08-30 09:39:15.219733: Current learning rate: 0.00015 
2025-08-30 09:39:42.017748: train_loss -0.6433 
2025-08-30 09:39:42.029820: val_loss -0.6552 
2025-08-30 09:39:42.033996: Pseudo dice [np.float32(0.8601)] 
2025-08-30 09:39:42.041419: Epoch time: 26.81 s 
2025-08-30 09:39:42.046942: Yayy! New best EMA pseudo Dice: 0.8324000239372253 
2025-08-30 09:39:42.885237:  
2025-08-30 09:39:42.893469: Epoch 881 
2025-08-30 09:39:42.901216: Current learning rate: 0.00015 
2025-08-30 09:40:09.324039: train_loss -0.6666 
2025-08-30 09:40:09.332411: val_loss -0.6055 
2025-08-30 09:40:09.339022: Pseudo dice [np.float32(0.8235)] 
2025-08-30 09:40:09.346042: Epoch time: 26.44 s 
2025-08-30 09:40:09.961977:  
2025-08-30 09:40:09.972320: Epoch 882 
2025-08-30 09:40:09.978953: Current learning rate: 0.00015 
2025-08-30 09:40:36.826186: train_loss -0.6592 
2025-08-30 09:40:36.834549: val_loss -0.6666 
2025-08-30 09:40:36.840909: Pseudo dice [np.float32(0.8081)] 
2025-08-30 09:40:36.846701: Epoch time: 26.86 s 
2025-08-30 09:40:37.460478:  
2025-08-30 09:40:37.468595: Epoch 883 
2025-08-30 09:40:37.476606: Current learning rate: 0.00014 
2025-08-30 09:41:04.650223: train_loss -0.6629 
2025-08-30 09:41:04.658365: val_loss -0.6789 
2025-08-30 09:41:04.662365: Pseudo dice [np.float32(0.8427)] 
2025-08-30 09:41:04.672156: Epoch time: 27.19 s 
2025-08-30 09:41:05.442322:  
2025-08-30 09:41:05.446506: Epoch 884 
2025-08-30 09:41:05.454894: Current learning rate: 0.00014 
2025-08-30 09:41:32.202661: train_loss -0.6472 
2025-08-30 09:41:32.215084: val_loss -0.5934 
2025-08-30 09:41:32.219285: Pseudo dice [np.float32(0.8214)] 
2025-08-30 09:41:32.228803: Epoch time: 26.76 s 
2025-08-30 09:41:32.846165:  
2025-08-30 09:41:32.853300: Epoch 885 
2025-08-30 09:41:32.857255: Current learning rate: 0.00014 
2025-08-30 09:41:59.879982: train_loss -0.625 
2025-08-30 09:41:59.888481: val_loss -0.6763 
2025-08-30 09:41:59.892691: Pseudo dice [np.float32(0.8438)] 
2025-08-30 09:41:59.902237: Epoch time: 27.03 s 
2025-08-30 09:42:00.518450:  
2025-08-30 09:42:00.526494: Epoch 886 
2025-08-30 09:42:00.530625: Current learning rate: 0.00014 
2025-08-30 09:42:27.253127: train_loss -0.6442 
2025-08-30 09:42:27.261851: val_loss -0.6181 
2025-08-30 09:42:27.270163: Pseudo dice [np.float32(0.8072)] 
2025-08-30 09:42:27.274931: Epoch time: 26.73 s 
2025-08-30 09:42:27.887148:  
2025-08-30 09:42:27.895720: Epoch 887 
2025-08-30 09:42:27.903783: Current learning rate: 0.00014 
2025-08-30 09:42:54.760194: train_loss -0.6415 
2025-08-30 09:42:54.768461: val_loss -0.6756 
2025-08-30 09:42:54.776464: Pseudo dice [np.float32(0.8492)] 
2025-08-30 09:42:54.782861: Epoch time: 26.88 s 
2025-08-30 09:42:55.410435:  
2025-08-30 09:42:55.418755: Epoch 888 
2025-08-30 09:42:55.422925: Current learning rate: 0.00014 
2025-08-30 09:43:22.162463: train_loss -0.6765 
2025-08-30 09:43:22.170815: val_loss -0.5692 
2025-08-30 09:43:22.178821: Pseudo dice [np.float32(0.7972)] 
2025-08-30 09:43:22.185349: Epoch time: 26.76 s 
2025-08-30 09:43:22.800344:  
2025-08-30 09:43:22.808610: Epoch 889 
2025-08-30 09:43:22.812981: Current learning rate: 0.00014 
2025-08-30 09:43:50.073695: train_loss -0.6667 
2025-08-30 09:43:50.086161: val_loss -0.6361 
2025-08-30 09:43:50.090111: Pseudo dice [np.float32(0.7889)] 
2025-08-30 09:43:50.099042: Epoch time: 27.27 s 
2025-08-30 09:43:50.719855:  
2025-08-30 09:43:50.728234: Epoch 890 
2025-08-30 09:43:50.732609: Current learning rate: 0.00014 
2025-08-30 09:44:17.601598: train_loss -0.6648 
2025-08-30 09:44:17.609464: val_loss -0.6284 
2025-08-30 09:44:17.613312: Pseudo dice [np.float32(0.8117)] 
2025-08-30 09:44:17.622751: Epoch time: 26.88 s 
2025-08-30 09:44:18.251900:  
2025-08-30 09:44:18.260110: Epoch 891 
2025-08-30 09:44:18.264259: Current learning rate: 0.00014 
2025-08-30 09:44:45.658023: train_loss -0.623 
2025-08-30 09:44:45.666360: val_loss -0.6046 
2025-08-30 09:44:45.674669: Pseudo dice [np.float32(0.7713)] 
2025-08-30 09:44:45.680205: Epoch time: 27.41 s 
2025-08-30 09:44:46.462949:  
2025-08-30 09:44:46.471312: Epoch 892 
2025-08-30 09:44:46.475473: Current learning rate: 0.00013 
2025-08-30 09:45:13.293921: train_loss -0.6847 
2025-08-30 09:45:13.302263: val_loss -0.706 
2025-08-30 09:45:13.310609: Pseudo dice [np.float32(0.8072)] 
2025-08-30 09:45:13.316890: Epoch time: 26.83 s 
2025-08-30 09:45:13.932083:  
2025-08-30 09:45:13.940466: Epoch 893 
2025-08-30 09:45:13.948774: Current learning rate: 0.00013 
2025-08-30 09:45:41.092615: train_loss -0.6458 
2025-08-30 09:45:41.100887: val_loss -0.641 
2025-08-30 09:45:41.105409: Pseudo dice [np.float32(0.8079)] 
2025-08-30 09:45:41.112146: Epoch time: 27.16 s 
2025-08-30 09:45:41.722341:  
2025-08-30 09:45:41.730626: Epoch 894 
2025-08-30 09:45:41.735178: Current learning rate: 0.00013 
2025-08-30 09:46:08.520241: train_loss -0.6776 
2025-08-30 09:46:08.528220: val_loss -0.6781 
2025-08-30 09:46:08.532406: Pseudo dice [np.float32(0.8259)] 
2025-08-30 09:46:08.540543: Epoch time: 26.8 s 
2025-08-30 09:46:09.166698:  
2025-08-30 09:46:09.174713: Epoch 895 
2025-08-30 09:46:09.178917: Current learning rate: 0.00013 
2025-08-30 09:46:36.469013: train_loss -0.6464 
2025-08-30 09:46:36.481491: val_loss -0.6571 
2025-08-30 09:46:36.485344: Pseudo dice [np.float32(0.8259)] 
2025-08-30 09:46:36.492576: Epoch time: 27.3 s 
2025-08-30 09:46:37.144303:  
2025-08-30 09:46:37.153037: Epoch 896 
2025-08-30 09:46:37.156802: Current learning rate: 0.00013 
2025-08-30 09:47:03.847310: train_loss -0.6735 
2025-08-30 09:47:03.854656: val_loss -0.6364 
2025-08-30 09:47:03.858784: Pseudo dice [np.float32(0.7953)] 
2025-08-30 09:47:03.866590: Epoch time: 26.71 s 
2025-08-30 09:47:04.476069:  
2025-08-30 09:47:04.484110: Epoch 897 
2025-08-30 09:47:04.488546: Current learning rate: 0.00013 
2025-08-30 09:47:31.774171: train_loss -0.6568 
2025-08-30 09:47:31.786844: val_loss -0.6696 
2025-08-30 09:47:31.790865: Pseudo dice [np.float32(0.8224)] 
2025-08-30 09:47:31.797837: Epoch time: 27.3 s 
2025-08-30 09:47:32.415994:  
2025-08-30 09:47:32.420313: Epoch 898 
2025-08-30 09:47:32.428633: Current learning rate: 0.00013 
2025-08-30 09:47:58.913440: train_loss -0.6668 
2025-08-30 09:47:58.925962: val_loss -0.5883 
2025-08-30 09:47:58.930125: Pseudo dice [np.float32(0.8252)] 
2025-08-30 09:47:58.937438: Epoch time: 26.5 s 
2025-08-30 09:47:59.701730:  
2025-08-30 09:47:59.710090: Epoch 899 
2025-08-30 09:47:59.714253: Current learning rate: 0.00013 
2025-08-30 09:48:26.983127: train_loss -0.6671 
2025-08-30 09:48:26.991479: val_loss -0.6929 
2025-08-30 09:48:27.000120: Pseudo dice [np.float32(0.8557)] 
2025-08-30 09:48:27.009340: Epoch time: 27.28 s 
2025-08-30 09:48:27.852230:  
2025-08-30 09:48:27.863569: Epoch 900 
2025-08-30 09:48:27.867365: Current learning rate: 0.00013 
2025-08-30 09:48:55.311415: train_loss -0.6301 
2025-08-30 09:48:55.319999: val_loss -0.6435 
2025-08-30 09:48:55.328125: Pseudo dice [np.float32(0.7906)] 
2025-08-30 09:48:55.333032: Epoch time: 27.46 s 
2025-08-30 09:48:55.949846:  
2025-08-30 09:48:55.958252: Epoch 901 
2025-08-30 09:48:55.966957: Current learning rate: 0.00012 
2025-08-30 09:49:23.269055: train_loss -0.6434 
2025-08-30 09:49:23.277236: val_loss -0.6078 
2025-08-30 09:49:23.281031: Pseudo dice [np.float32(0.7924)] 
2025-08-30 09:49:23.289462: Epoch time: 27.32 s 
2025-08-30 09:49:23.902451:  
2025-08-30 09:49:23.910825: Epoch 902 
2025-08-30 09:49:23.914992: Current learning rate: 0.00012 
2025-08-30 09:49:50.971397: train_loss -0.6781 
2025-08-30 09:49:50.979508: val_loss -0.6133 
2025-08-30 09:49:50.988174: Pseudo dice [np.float32(0.7993)] 
2025-08-30 09:49:50.993264: Epoch time: 27.07 s 
2025-08-30 09:49:51.609287:  
2025-08-30 09:49:51.617644: Epoch 903 
2025-08-30 09:49:51.621828: Current learning rate: 0.00012 
2025-08-30 09:50:18.282100: train_loss -0.6644 
2025-08-30 09:50:18.290111: val_loss -0.6217 
2025-08-30 09:50:18.298541: Pseudo dice [np.float32(0.7903)] 
2025-08-30 09:50:18.304088: Epoch time: 26.67 s 
2025-08-30 09:50:18.924087:  
2025-08-30 09:50:18.932767: Epoch 904 
2025-08-30 09:50:18.936898: Current learning rate: 0.00012 
2025-08-30 09:50:46.042943: train_loss -0.6734 
2025-08-30 09:50:46.051400: val_loss -0.6087 
2025-08-30 09:50:46.055320: Pseudo dice [np.float32(0.8068)] 
2025-08-30 09:50:46.064919: Epoch time: 27.12 s 
2025-08-30 09:50:46.676859:  
2025-08-30 09:50:46.689325: Epoch 905 
2025-08-30 09:50:46.697737: Current learning rate: 0.00012 
2025-08-30 09:51:13.595343: train_loss -0.6482 
2025-08-30 09:51:13.603677: val_loss -0.592 
2025-08-30 09:51:13.607853: Pseudo dice [np.float32(0.8108)] 
2025-08-30 09:51:13.616503: Epoch time: 26.92 s 
2025-08-30 09:51:14.387802:  
2025-08-30 09:51:14.396132: Epoch 906 
2025-08-30 09:51:14.404475: Current learning rate: 0.00012 
2025-08-30 09:51:41.748985: train_loss -0.6363 
2025-08-30 09:51:41.760982: val_loss -0.5888 
2025-08-30 09:51:41.765496: Pseudo dice [np.float32(0.817)] 
2025-08-30 09:51:41.773356: Epoch time: 27.36 s 
2025-08-30 09:51:42.391040:  
2025-08-30 09:51:42.399405: Epoch 907 
2025-08-30 09:51:42.407476: Current learning rate: 0.00012 
2025-08-30 09:52:09.092778: train_loss -0.6706 
2025-08-30 09:52:09.101156: val_loss -0.6727 
2025-08-30 09:52:09.109425: Pseudo dice [np.float32(0.8253)] 
2025-08-30 09:52:09.115399: Epoch time: 26.7 s 
2025-08-30 09:52:09.730566:  
2025-08-30 09:52:09.738895: Epoch 908 
2025-08-30 09:52:09.743062: Current learning rate: 0.00012 
2025-08-30 09:52:36.865808: train_loss -0.6656 
2025-08-30 09:52:36.874372: val_loss -0.6682 
2025-08-30 09:52:36.878553: Pseudo dice [np.float32(0.8657)] 
2025-08-30 09:52:36.886820: Epoch time: 27.14 s 
2025-08-30 09:52:37.499956:  
2025-08-30 09:52:37.508329: Epoch 909 
2025-08-30 09:52:37.512497: Current learning rate: 0.00012 
2025-08-30 09:53:04.652533: train_loss -0.6676 
2025-08-30 09:53:04.660393: val_loss -0.5939 
2025-08-30 09:53:04.668787: Pseudo dice [np.float32(0.8086)] 
2025-08-30 09:53:04.678033: Epoch time: 27.16 s 
2025-08-30 09:53:05.306864:  
2025-08-30 09:53:05.315248: Epoch 910 
2025-08-30 09:53:05.319421: Current learning rate: 0.00011 
2025-08-30 09:53:32.292147: train_loss -0.6627 
2025-08-30 09:53:32.300789: val_loss -0.6071 
2025-08-30 09:53:32.308856: Pseudo dice [np.float32(0.7824)] 
2025-08-30 09:53:32.316252: Epoch time: 26.99 s 
2025-08-30 09:53:32.968151:  
2025-08-30 09:53:32.976543: Epoch 911 
2025-08-30 09:53:32.984859: Current learning rate: 0.00011 
2025-08-30 09:54:00.065731: train_loss -0.6656 
2025-08-30 09:54:00.074060: val_loss -0.6689 
2025-08-30 09:54:00.082443: Pseudo dice [np.float32(0.8081)] 
2025-08-30 09:54:00.088733: Epoch time: 27.1 s 
2025-08-30 09:54:00.704174:  
2025-08-30 09:54:00.712435: Epoch 912 
2025-08-30 09:54:00.716408: Current learning rate: 0.00011 
2025-08-30 09:54:27.697686: train_loss -0.6649 
2025-08-30 09:54:27.705841: val_loss -0.6172 
2025-08-30 09:54:27.714169: Pseudo dice [np.float32(0.7815)] 
2025-08-30 09:54:27.720122: Epoch time: 26.99 s 
2025-08-30 09:54:28.338599:  
2025-08-30 09:54:28.350657: Epoch 913 
2025-08-30 09:54:28.352614: Current learning rate: 0.00011 
2025-08-30 09:54:55.633703: train_loss -0.6578 
2025-08-30 09:54:55.642183: val_loss -0.6631 
2025-08-30 09:54:55.650741: Pseudo dice [np.float32(0.8175)] 
2025-08-30 09:54:55.655326: Epoch time: 27.3 s 
2025-08-30 09:54:56.271839:  
2025-08-30 09:54:56.284361: Epoch 914 
2025-08-30 09:54:56.288724: Current learning rate: 0.00011 
2025-08-30 09:55:22.990361: train_loss -0.6888 
2025-08-30 09:55:22.998667: val_loss -0.5799 
2025-08-30 09:55:23.007294: Pseudo dice [np.float32(0.8113)] 
2025-08-30 09:55:23.015199: Epoch time: 26.72 s 
2025-08-30 09:55:23.653419:  
2025-08-30 09:55:23.662083: Epoch 915 
2025-08-30 09:55:23.665904: Current learning rate: 0.00011 
2025-08-30 09:55:50.609419: train_loss -0.6478 
2025-08-30 09:55:50.621951: val_loss -0.6409 
2025-08-30 09:55:50.630269: Pseudo dice [np.float32(0.8094)] 
2025-08-30 09:55:50.636468: Epoch time: 26.96 s 
2025-08-30 09:55:51.251762:  
2025-08-30 09:55:51.260453: Epoch 916 
2025-08-30 09:55:51.264251: Current learning rate: 0.00011 
2025-08-30 09:56:18.328758: train_loss -0.6553 
2025-08-30 09:56:18.336987: val_loss -0.6646 
2025-08-30 09:56:18.345827: Pseudo dice [np.float32(0.8167)] 
2025-08-30 09:56:18.352653: Epoch time: 27.08 s 
2025-08-30 09:56:18.966896:  
2025-08-30 09:56:18.975600: Epoch 917 
2025-08-30 09:56:18.979716: Current learning rate: 0.00011 
2025-08-30 09:56:45.806195: train_loss -0.6609 
2025-08-30 09:56:45.814549: val_loss -0.6416 
2025-08-30 09:56:45.822880: Pseudo dice [np.float32(0.8094)] 
2025-08-30 09:56:45.830142: Epoch time: 26.84 s 
2025-08-30 09:56:46.440167:  
2025-08-30 09:56:46.444336: Epoch 918 
2025-08-30 09:56:46.452928: Current learning rate: 0.00011 
2025-08-30 09:57:13.263152: train_loss -0.6541 
2025-08-30 09:57:13.271128: val_loss -0.6309 
2025-08-30 09:57:13.275328: Pseudo dice [np.float32(0.8141)] 
2025-08-30 09:57:13.283449: Epoch time: 26.83 s 
2025-08-30 09:57:13.905081:  
2025-08-30 09:57:13.913802: Epoch 919 
2025-08-30 09:57:13.917917: Current learning rate: 0.0001 
2025-08-30 09:57:40.673472: train_loss -0.6455 
2025-08-30 09:57:40.682105: val_loss -0.6302 
2025-08-30 09:57:40.694020: Pseudo dice [np.float32(0.8175)] 
2025-08-30 09:57:40.700154: Epoch time: 26.77 s 
2025-08-30 09:57:41.470155:  
2025-08-30 09:57:41.479260: Epoch 920 
2025-08-30 09:57:41.482722: Current learning rate: 0.0001 
2025-08-30 09:58:08.381004: train_loss -0.6625 
2025-08-30 09:58:08.388660: val_loss -0.6436 
2025-08-30 09:58:08.392825: Pseudo dice [np.float32(0.8319)] 
2025-08-30 09:58:08.401893: Epoch time: 26.91 s 
2025-08-30 09:58:09.018496:  
2025-08-30 09:58:09.026837: Epoch 921 
2025-08-30 09:58:09.031301: Current learning rate: 0.0001 
2025-08-30 09:58:36.049651: train_loss -0.6835 
2025-08-30 09:58:36.057950: val_loss -0.5421 
2025-08-30 09:58:36.066320: Pseudo dice [np.float32(0.7864)] 
2025-08-30 09:58:36.071774: Epoch time: 27.03 s 
2025-08-30 09:58:36.683940:  
2025-08-30 09:58:36.692204: Epoch 922 
2025-08-30 09:58:36.696490: Current learning rate: 0.0001 
2025-08-30 09:59:03.522847: train_loss -0.6114 
2025-08-30 09:59:03.527063: val_loss -0.6762 
2025-08-30 09:59:03.535410: Pseudo dice [np.float32(0.8206)] 
2025-08-30 09:59:03.540817: Epoch time: 26.84 s 
2025-08-30 09:59:04.156826:  
2025-08-30 09:59:04.165506: Epoch 923 
2025-08-30 09:59:04.173539: Current learning rate: 0.0001 
2025-08-30 09:59:31.205222: train_loss -0.6565 
2025-08-30 09:59:31.217193: val_loss -0.6072 
2025-08-30 09:59:31.221325: Pseudo dice [np.float32(0.81)] 
2025-08-30 09:59:31.229661: Epoch time: 27.05 s 
2025-08-30 09:59:31.848401:  
2025-08-30 09:59:31.855634: Epoch 924 
2025-08-30 09:59:31.859812: Current learning rate: 0.0001 
2025-08-30 09:59:59.266006: train_loss -0.6679 
2025-08-30 09:59:59.275012: val_loss -0.6489 
2025-08-30 09:59:59.278547: Pseudo dice [np.float32(0.8498)] 
2025-08-30 09:59:59.285864: Epoch time: 27.42 s 
2025-08-30 09:59:59.891629:  
2025-08-30 09:59:59.900024: Epoch 925 
2025-08-30 09:59:59.904122: Current learning rate: 0.0001 
2025-08-30 10:00:26.656195: train_loss -0.6802 
2025-08-30 10:00:26.664225: val_loss -0.6225 
2025-08-30 10:00:26.668753: Pseudo dice [np.float32(0.8109)] 
2025-08-30 10:00:26.676526: Epoch time: 26.76 s 
2025-08-30 10:00:27.323205:  
2025-08-30 10:00:27.327407: Epoch 926 
2025-08-30 10:00:27.335763: Current learning rate: 0.0001 
2025-08-30 10:00:54.229275: train_loss -0.6776 
2025-08-30 10:00:54.237568: val_loss -0.6779 
2025-08-30 10:00:54.241726: Pseudo dice [np.float32(0.8196)] 
2025-08-30 10:00:54.250998: Epoch time: 26.91 s 
2025-08-30 10:00:54.876509:  
2025-08-30 10:00:54.884100: Epoch 927 
2025-08-30 10:00:54.888622: Current learning rate: 9e-05 
2025-08-30 10:01:22.069365: train_loss -0.6275 
2025-08-30 10:01:22.077977: val_loss -0.6498 
2025-08-30 10:01:22.082357: Pseudo dice [np.float32(0.8483)] 
2025-08-30 10:01:22.088710: Epoch time: 27.19 s 
2025-08-30 10:01:22.885587:  
2025-08-30 10:01:22.891186: Epoch 928 
2025-08-30 10:01:22.899532: Current learning rate: 9e-05 
2025-08-30 10:01:49.951887: train_loss -0.6394 
2025-08-30 10:01:49.964355: val_loss -0.6208 
2025-08-30 10:01:49.968554: Pseudo dice [np.float32(0.8306)] 
2025-08-30 10:01:49.976376: Epoch time: 27.07 s 
2025-08-30 10:01:50.597999:  
2025-08-30 10:01:50.606352: Epoch 929 
2025-08-30 10:01:50.615178: Current learning rate: 9e-05 
2025-08-30 10:02:17.712640: train_loss -0.6728 
2025-08-30 10:02:17.721236: val_loss -0.6907 
2025-08-30 10:02:17.725180: Pseudo dice [np.float32(0.7716)] 
2025-08-30 10:02:17.733430: Epoch time: 27.12 s 
2025-08-30 10:02:18.351113:  
2025-08-30 10:02:18.360966: Epoch 930 
2025-08-30 10:02:18.363612: Current learning rate: 9e-05 
2025-08-30 10:02:45.598764: train_loss -0.6699 
2025-08-30 10:02:45.611288: val_loss -0.6528 
2025-08-30 10:02:45.615489: Pseudo dice [np.float32(0.8322)] 
2025-08-30 10:02:45.624852: Epoch time: 27.25 s 
2025-08-30 10:02:46.249411:  
2025-08-30 10:02:46.257781: Epoch 931 
2025-08-30 10:02:46.261960: Current learning rate: 9e-05 
2025-08-30 10:03:13.284779: train_loss -0.6506 
2025-08-30 10:03:13.293086: val_loss -0.6566 
2025-08-30 10:03:13.297520: Pseudo dice [np.float32(0.8047)] 
2025-08-30 10:03:13.306556: Epoch time: 27.04 s 
2025-08-30 10:03:13.918467:  
2025-08-30 10:03:13.925166: Epoch 932 
2025-08-30 10:03:13.931315: Current learning rate: 9e-05 
2025-08-30 10:03:40.912320: train_loss -0.6479 
2025-08-30 10:03:40.924884: val_loss -0.6475 
2025-08-30 10:03:40.929038: Pseudo dice [np.float32(0.8334)] 
2025-08-30 10:03:40.934416: Epoch time: 27.0 s 
2025-08-30 10:03:41.546338:  
2025-08-30 10:03:41.554720: Epoch 933 
2025-08-30 10:03:41.558899: Current learning rate: 9e-05 
2025-08-30 10:04:08.649641: train_loss -0.6515 
2025-08-30 10:04:08.657250: val_loss -0.5891 
2025-08-30 10:04:08.661998: Pseudo dice [np.float32(0.7758)] 
2025-08-30 10:04:08.670328: Epoch time: 27.11 s 
2025-08-30 10:04:09.294923:  
2025-08-30 10:04:09.303259: Epoch 934 
2025-08-30 10:04:09.307345: Current learning rate: 9e-05 
2025-08-30 10:04:36.509540: train_loss -0.6769 
2025-08-30 10:04:36.522383: val_loss -0.6632 
2025-08-30 10:04:36.530200: Pseudo dice [np.float32(0.8146)] 
2025-08-30 10:04:36.535887: Epoch time: 27.21 s 
2025-08-30 10:04:37.310301:  
2025-08-30 10:04:37.318704: Epoch 935 
2025-08-30 10:04:37.323067: Current learning rate: 9e-05 
2025-08-30 10:05:04.504437: train_loss -0.6617 
2025-08-30 10:05:04.516353: val_loss -0.6479 
2025-08-30 10:05:04.520905: Pseudo dice [np.float32(0.8108)] 
2025-08-30 10:05:04.526981: Epoch time: 27.2 s 
2025-08-30 10:05:05.146726:  
2025-08-30 10:05:05.154779: Epoch 936 
2025-08-30 10:05:05.159303: Current learning rate: 8e-05 
2025-08-30 10:05:32.098897: train_loss -0.6582 
2025-08-30 10:05:32.110845: val_loss -0.6574 
2025-08-30 10:05:32.115339: Pseudo dice [np.float32(0.8148)] 
2025-08-30 10:05:32.122671: Epoch time: 26.96 s 
2025-08-30 10:05:32.736534:  
2025-08-30 10:05:32.744924: Epoch 937 
2025-08-30 10:05:32.753557: Current learning rate: 8e-05 
2025-08-30 10:05:59.717299: train_loss -0.6549 
2025-08-30 10:05:59.725729: val_loss -0.6719 
2025-08-30 10:05:59.730473: Pseudo dice [np.float32(0.8145)] 
2025-08-30 10:05:59.737531: Epoch time: 26.98 s 
2025-08-30 10:06:00.350850:  
2025-08-30 10:06:00.355801: Epoch 938 
2025-08-30 10:06:00.364159: Current learning rate: 8e-05 
2025-08-30 10:06:27.578763: train_loss -0.6338 
2025-08-30 10:06:27.587085: val_loss -0.6054 
2025-08-30 10:06:27.595451: Pseudo dice [np.float32(0.8209)] 
2025-08-30 10:06:27.601731: Epoch time: 27.23 s 
2025-08-30 10:06:28.208567:  
2025-08-30 10:06:28.221084: Epoch 939 
2025-08-30 10:06:28.225233: Current learning rate: 8e-05 
2025-08-30 10:06:55.319129: train_loss -0.6643 
2025-08-30 10:06:55.327293: val_loss -0.6614 
2025-08-30 10:06:55.331701: Pseudo dice [np.float32(0.8116)] 
2025-08-30 10:06:55.338779: Epoch time: 27.11 s 
2025-08-30 10:06:55.957436:  
2025-08-30 10:06:55.965755: Epoch 940 
2025-08-30 10:06:55.969623: Current learning rate: 8e-05 
2025-08-30 10:07:22.813063: train_loss -0.688 
2025-08-30 10:07:22.821430: val_loss -0.5739 
2025-08-30 10:07:22.825602: Pseudo dice [np.float32(0.7537)] 
2025-08-30 10:07:22.832898: Epoch time: 26.86 s 
2025-08-30 10:07:23.447014:  
2025-08-30 10:07:23.455752: Epoch 941 
2025-08-30 10:07:23.464064: Current learning rate: 8e-05 
2025-08-30 10:07:50.874398: train_loss -0.6483 
2025-08-30 10:07:50.882828: val_loss -0.6537 
2025-08-30 10:07:50.891147: Pseudo dice [np.float32(0.7759)] 
2025-08-30 10:07:50.896548: Epoch time: 27.43 s 
2025-08-30 10:07:51.516698:  
2025-08-30 10:07:51.525059: Epoch 942 
2025-08-30 10:07:51.533436: Current learning rate: 8e-05 
2025-08-30 10:08:18.906962: train_loss -0.6755 
2025-08-30 10:08:18.915200: val_loss -0.5802 
2025-08-30 10:08:18.923280: Pseudo dice [np.float32(0.7734)] 
2025-08-30 10:08:18.929308: Epoch time: 27.39 s 
2025-08-30 10:08:19.703233:  
2025-08-30 10:08:19.715470: Epoch 943 
2025-08-30 10:08:19.719982: Current learning rate: 8e-05 
2025-08-30 10:08:46.821923: train_loss -0.6548 
2025-08-30 10:08:46.834434: val_loss -0.6085 
2025-08-30 10:08:46.841340: Pseudo dice [np.float32(0.8205)] 
2025-08-30 10:08:46.848436: Epoch time: 27.12 s 
2025-08-30 10:08:47.460059:  
2025-08-30 10:08:47.468759: Epoch 944 
2025-08-30 10:08:47.476775: Current learning rate: 7e-05 
2025-08-30 10:09:14.208506: train_loss -0.6552 
2025-08-30 10:09:14.216203: val_loss -0.6524 
2025-08-30 10:09:14.220506: Pseudo dice [np.float32(0.8446)] 
2025-08-30 10:09:14.227373: Epoch time: 26.75 s 
2025-08-30 10:09:14.837402:  
2025-08-30 10:09:14.845736: Epoch 945 
2025-08-30 10:09:14.851496: Current learning rate: 7e-05 
2025-08-30 10:09:41.926996: train_loss -0.6577 
2025-08-30 10:09:41.940230: val_loss -0.6426 
2025-08-30 10:09:41.946548: Pseudo dice [np.float32(0.7852)] 
2025-08-30 10:09:41.952821: Epoch time: 27.09 s 
2025-08-30 10:09:42.565449:  
2025-08-30 10:09:42.573209: Epoch 946 
2025-08-30 10:09:42.578149: Current learning rate: 7e-05 
2025-08-30 10:10:09.446095: train_loss -0.6818 
2025-08-30 10:10:09.454459: val_loss -0.6021 
2025-08-30 10:10:09.462793: Pseudo dice [np.float32(0.8284)] 
2025-08-30 10:10:09.468172: Epoch time: 26.88 s 
2025-08-30 10:10:10.080392:  
2025-08-30 10:10:10.088769: Epoch 947 
2025-08-30 10:10:10.092604: Current learning rate: 7e-05 
2025-08-30 10:10:37.511602: train_loss -0.6902 
2025-08-30 10:10:37.520000: val_loss -0.6794 
2025-08-30 10:10:37.524448: Pseudo dice [np.float32(0.8322)] 
2025-08-30 10:10:37.533281: Epoch time: 27.44 s 
2025-08-30 10:10:38.149787:  
2025-08-30 10:10:38.158094: Epoch 948 
2025-08-30 10:10:38.162265: Current learning rate: 7e-05 
2025-08-30 10:11:04.788862: train_loss -0.6983 
2025-08-30 10:11:04.797204: val_loss -0.6315 
2025-08-30 10:11:04.801393: Pseudo dice [np.float32(0.8006)] 
2025-08-30 10:11:04.810424: Epoch time: 26.64 s 
2025-08-30 10:11:05.448206:  
2025-08-30 10:11:05.456192: Epoch 949 
2025-08-30 10:11:05.464532: Current learning rate: 7e-05 
2025-08-30 10:11:33.088559: train_loss -0.6617 
2025-08-30 10:11:33.100451: val_loss -0.6086 
2025-08-30 10:11:33.106498: Pseudo dice [np.float32(0.8151)] 
2025-08-30 10:11:33.112521: Epoch time: 27.64 s 
2025-08-30 10:11:34.148406:  
2025-08-30 10:11:34.156686: Epoch 950 
2025-08-30 10:11:34.165150: Current learning rate: 7e-05 
2025-08-30 10:11:59.847800: train_loss -0.6377 
2025-08-30 10:11:59.856029: val_loss -0.6182 
2025-08-30 10:11:59.861551: Pseudo dice [np.float32(0.7688)] 
2025-08-30 10:11:59.866478: Epoch time: 25.7 s 
2025-08-30 10:12:00.477719:  
2025-08-30 10:12:00.486017: Epoch 951 
2025-08-30 10:12:00.491299: Current learning rate: 7e-05 
2025-08-30 10:12:25.946700: train_loss -0.6761 
2025-08-30 10:12:25.953226: val_loss -0.6208 
2025-08-30 10:12:25.957665: Pseudo dice [np.float32(0.8061)] 
2025-08-30 10:12:25.966580: Epoch time: 25.47 s 
2025-08-30 10:12:26.585015:  
2025-08-30 10:12:26.594358: Epoch 952 
2025-08-30 10:12:26.602716: Current learning rate: 7e-05 
2025-08-30 10:12:51.654062: train_loss -0.6687 
2025-08-30 10:12:51.666412: val_loss -0.6215 
2025-08-30 10:12:51.670522: Pseudo dice [np.float32(0.8002)] 
2025-08-30 10:12:51.677654: Epoch time: 25.07 s 
2025-08-30 10:12:52.277383:  
2025-08-30 10:12:52.285695: Epoch 953 
2025-08-30 10:12:52.291972: Current learning rate: 6e-05 
2025-08-30 10:13:17.575842: train_loss -0.6799 
2025-08-30 10:13:17.583934: val_loss -0.6641 
2025-08-30 10:13:17.592309: Pseudo dice [np.float32(0.851)] 
2025-08-30 10:13:17.597596: Epoch time: 25.3 s 
2025-08-30 10:13:18.218927:  
2025-08-30 10:13:18.227276: Epoch 954 
2025-08-30 10:13:18.233416: Current learning rate: 6e-05 
2025-08-30 10:13:42.267040: train_loss -0.6671 
2025-08-30 10:13:42.275271: val_loss -0.6401 
2025-08-30 10:13:42.279710: Pseudo dice [np.float32(0.8064)] 
2025-08-30 10:13:42.286368: Epoch time: 24.05 s 
2025-08-30 10:13:42.897727:  
2025-08-30 10:13:42.906187: Epoch 955 
2025-08-30 10:13:42.911208: Current learning rate: 6e-05 
2025-08-30 10:14:06.245021: train_loss -0.6763 
2025-08-30 10:14:06.253815: val_loss -0.6176 
2025-08-30 10:14:06.261695: Pseudo dice [np.float32(0.8101)] 
2025-08-30 10:14:06.266666: Epoch time: 23.35 s 
2025-08-30 10:14:06.877887:  
2025-08-30 10:14:06.886270: Epoch 956 
2025-08-30 10:14:06.893515: Current learning rate: 6e-05 
2025-08-30 10:14:30.361053: train_loss -0.6582 
2025-08-30 10:14:30.373313: val_loss -0.6273 
2025-08-30 10:14:30.377472: Pseudo dice [np.float32(0.8356)] 
2025-08-30 10:14:30.385644: Epoch time: 23.48 s 
2025-08-30 10:14:31.007148:  
2025-08-30 10:14:31.016666: Epoch 957 
2025-08-30 10:14:31.021794: Current learning rate: 6e-05 
2025-08-30 10:14:54.489513: train_loss -0.6529 
2025-08-30 10:14:54.497675: val_loss -0.605 
2025-08-30 10:14:54.506040: Pseudo dice [np.float32(0.8037)] 
2025-08-30 10:14:54.512939: Epoch time: 23.48 s 
2025-08-30 10:14:55.126016:  
2025-08-30 10:14:55.133383: Epoch 958 
2025-08-30 10:14:55.139606: Current learning rate: 6e-05 
2025-08-30 10:15:18.308482: train_loss -0.6347 
2025-08-30 10:15:18.312892: val_loss -0.6672 
2025-08-30 10:15:18.321460: Pseudo dice [np.float32(0.8281)] 
2025-08-30 10:15:18.328293: Epoch time: 23.18 s 
2025-08-30 10:15:18.938380:  
2025-08-30 10:15:18.947809: Epoch 959 
2025-08-30 10:15:18.955312: Current learning rate: 6e-05 
2025-08-30 10:15:42.390986: train_loss -0.6792 
2025-08-30 10:15:42.399409: val_loss -0.6434 
2025-08-30 10:15:42.403647: Pseudo dice [np.float32(0.8418)] 
2025-08-30 10:15:42.410566: Epoch time: 23.45 s 
2025-08-30 10:15:43.021930:  
2025-08-30 10:15:43.030185: Epoch 960 
2025-08-30 10:15:43.038538: Current learning rate: 6e-05 
2025-08-30 10:16:08.029186: train_loss -0.6436 
2025-08-30 10:16:08.037519: val_loss -0.6247 
2025-08-30 10:16:08.045860: Pseudo dice [np.float32(0.8381)] 
2025-08-30 10:16:08.051346: Epoch time: 25.01 s 
2025-08-30 10:16:08.726700:  
2025-08-30 10:16:08.735051: Epoch 961 
2025-08-30 10:16:08.740225: Current learning rate: 5e-05 
2025-08-30 10:16:34.438870: train_loss -0.647 
2025-08-30 10:16:34.447490: val_loss -0.5823 
2025-08-30 10:16:34.451359: Pseudo dice [np.float32(0.8042)] 
2025-08-30 10:16:34.458564: Epoch time: 25.71 s 
2025-08-30 10:16:35.141579:  
2025-08-30 10:16:35.149925: Epoch 962 
2025-08-30 10:16:35.155147: Current learning rate: 5e-05 
2025-08-30 10:17:00.756896: train_loss -0.6713 
2025-08-30 10:17:00.765409: val_loss -0.7025 
2025-08-30 10:17:00.773473: Pseudo dice [np.float32(0.8413)] 
2025-08-30 10:17:00.778430: Epoch time: 25.62 s 
2025-08-30 10:17:01.602418:  
2025-08-30 10:17:01.610725: Epoch 963 
2025-08-30 10:17:01.618169: Current learning rate: 5e-05 
2025-08-30 10:17:27.137576: train_loss -0.6728 
2025-08-30 10:17:27.145939: val_loss -0.5941 
2025-08-30 10:17:27.153631: Pseudo dice [np.float32(0.8352)] 
2025-08-30 10:17:27.159028: Epoch time: 25.54 s 
2025-08-30 10:17:27.819171:  
2025-08-30 10:17:27.826605: Epoch 964 
2025-08-30 10:17:27.832684: Current learning rate: 5e-05 
2025-08-30 10:17:53.306600: train_loss -0.6754 
2025-08-30 10:17:53.313474: val_loss -0.6857 
2025-08-30 10:17:53.317603: Pseudo dice [np.float32(0.8338)] 
2025-08-30 10:17:53.326733: Epoch time: 25.49 s 
2025-08-30 10:17:53.982872:  
2025-08-30 10:17:53.993281: Epoch 965 
2025-08-30 10:17:53.998534: Current learning rate: 5e-05 
2025-08-30 10:18:19.644214: train_loss -0.6942 
2025-08-30 10:18:19.652234: val_loss -0.652 
2025-08-30 10:18:19.660952: Pseudo dice [np.float32(0.8515)] 
2025-08-30 10:18:19.666965: Epoch time: 25.66 s 
2025-08-30 10:18:20.334167:  
2025-08-30 10:18:20.344528: Epoch 966 
2025-08-30 10:18:20.352847: Current learning rate: 5e-05 
2025-08-30 10:18:45.941764: train_loss -0.6481 
2025-08-30 10:18:45.949342: val_loss -0.6545 
2025-08-30 10:18:45.962287: Pseudo dice [np.float32(0.8276)] 
2025-08-30 10:18:45.971781: Epoch time: 25.61 s 
2025-08-30 10:18:46.689358:  
2025-08-30 10:18:46.697962: Epoch 967 
2025-08-30 10:18:46.705264: Current learning rate: 5e-05 
2025-08-30 10:19:12.388535: train_loss -0.6604 
2025-08-30 10:19:12.396606: val_loss -0.6271 
2025-08-30 10:19:12.401093: Pseudo dice [np.float32(0.83)] 
2025-08-30 10:19:12.409062: Epoch time: 25.7 s 
2025-08-30 10:19:13.104487:  
2025-08-30 10:19:13.115012: Epoch 968 
2025-08-30 10:19:13.120245: Current learning rate: 5e-05 
2025-08-30 10:19:38.519532: train_loss -0.6881 
2025-08-30 10:19:38.526847: val_loss -0.6728 
2025-08-30 10:19:38.530989: Pseudo dice [np.float32(0.85)] 
2025-08-30 10:19:38.539345: Epoch time: 25.42 s 
2025-08-30 10:19:39.207710:  
2025-08-30 10:19:39.214875: Epoch 969 
2025-08-30 10:19:39.222270: Current learning rate: 4e-05 
2025-08-30 10:20:04.519529: train_loss -0.6818 
2025-08-30 10:20:04.528106: val_loss -0.689 
2025-08-30 10:20:04.536166: Pseudo dice [np.float32(0.8372)] 
2025-08-30 10:20:04.540687: Epoch time: 25.31 s 
2025-08-30 10:20:05.378601:  
2025-08-30 10:20:05.386931: Epoch 970 
2025-08-30 10:20:05.392172: Current learning rate: 4e-05 
2025-08-30 10:20:30.741308: train_loss -0.6555 
2025-08-30 10:20:30.749882: val_loss -0.6207 
2025-08-30 10:20:30.753983: Pseudo dice [np.float32(0.8024)] 
2025-08-30 10:20:30.762102: Epoch time: 25.36 s 
2025-08-30 10:20:31.450394:  
2025-08-30 10:20:31.460090: Epoch 971 
2025-08-30 10:20:31.466076: Current learning rate: 4e-05 
2025-08-30 10:20:56.855118: train_loss -0.6706 
2025-08-30 10:20:56.863748: val_loss -0.6614 
2025-08-30 10:20:56.867563: Pseudo dice [np.float32(0.8343)] 
2025-08-30 10:20:56.873753: Epoch time: 25.41 s 
2025-08-30 10:20:57.536940:  
2025-08-30 10:20:57.546387: Epoch 972 
2025-08-30 10:20:57.553675: Current learning rate: 4e-05 
2025-08-30 10:21:23.035945: train_loss -0.6968 
2025-08-30 10:21:23.043722: val_loss -0.5811 
2025-08-30 10:21:23.048147: Pseudo dice [np.float32(0.7829)] 
2025-08-30 10:21:23.054184: Epoch time: 25.5 s 
2025-08-30 10:21:23.733899:  
2025-08-30 10:21:23.743280: Epoch 973 
2025-08-30 10:21:23.749694: Current learning rate: 4e-05 
2025-08-30 10:21:49.129190: train_loss -0.672 
2025-08-30 10:21:49.136434: val_loss -0.6599 
2025-08-30 10:21:49.144789: Pseudo dice [np.float32(0.825)] 
2025-08-30 10:21:49.149701: Epoch time: 25.4 s 
2025-08-30 10:21:49.816149:  
2025-08-30 10:21:49.823549: Epoch 974 
2025-08-30 10:21:49.829874: Current learning rate: 4e-05 
2025-08-30 10:22:15.250165: train_loss -0.6633 
2025-08-30 10:22:15.258726: val_loss -0.63 
2025-08-30 10:22:15.262511: Pseudo dice [np.float32(0.7748)] 
2025-08-30 10:22:15.269609: Epoch time: 25.44 s 
2025-08-30 10:22:15.945451:  
2025-08-30 10:22:15.954689: Epoch 975 
2025-08-30 10:22:15.963158: Current learning rate: 4e-05 
2025-08-30 10:22:41.522152: train_loss -0.6356 
2025-08-30 10:22:41.530442: val_loss -0.6887 
2025-08-30 10:22:41.538747: Pseudo dice [np.float32(0.8454)] 
2025-08-30 10:22:41.545044: Epoch time: 25.58 s 
2025-08-30 10:22:42.219693:  
2025-08-30 10:22:42.228943: Epoch 976 
2025-08-30 10:22:42.237356: Current learning rate: 3e-05 
2025-08-30 10:23:07.860947: train_loss -0.6685 
2025-08-30 10:23:07.869532: val_loss -0.7195 
2025-08-30 10:23:07.873356: Pseudo dice [np.float32(0.8472)] 
2025-08-30 10:23:07.880602: Epoch time: 25.64 s 
2025-08-30 10:23:08.552080:  
2025-08-30 10:23:08.560510: Epoch 977 
2025-08-30 10:23:08.567902: Current learning rate: 3e-05 
2025-08-30 10:23:34.345658: train_loss -0.6659 
2025-08-30 10:23:34.353988: val_loss -0.6399 
2025-08-30 10:23:34.358457: Pseudo dice [np.float32(0.8229)] 
2025-08-30 10:23:34.365514: Epoch time: 25.8 s 
2025-08-30 10:23:35.242310:  
2025-08-30 10:23:35.252779: Epoch 978 
2025-08-30 10:23:35.260211: Current learning rate: 3e-05 
2025-08-30 10:24:00.822909: train_loss -0.6943 
2025-08-30 10:24:00.830438: val_loss -0.6733 
2025-08-30 10:24:00.834928: Pseudo dice [np.float32(0.8329)] 
2025-08-30 10:24:00.842835: Epoch time: 25.58 s 
2025-08-30 10:24:01.499110:  
2025-08-30 10:24:01.508111: Epoch 979 
2025-08-30 10:24:01.516459: Current learning rate: 3e-05 
2025-08-30 10:24:27.044086: train_loss -0.6393 
2025-08-30 10:24:27.052808: val_loss -0.6334 
2025-08-30 10:24:27.060804: Pseudo dice [np.float32(0.825)] 
2025-08-30 10:24:27.066291: Epoch time: 25.55 s 
2025-08-30 10:24:27.746435:  
2025-08-30 10:24:27.755128: Epoch 980 
2025-08-30 10:24:27.761394: Current learning rate: 3e-05 
2025-08-30 10:24:53.303654: train_loss -0.6429 
2025-08-30 10:24:53.312036: val_loss -0.6285 
2025-08-30 10:24:53.320365: Pseudo dice [np.float32(0.81)] 
2025-08-30 10:24:53.325872: Epoch time: 25.56 s 
2025-08-30 10:24:54.012496:  
2025-08-30 10:24:54.022140: Epoch 981 
2025-08-30 10:24:54.029340: Current learning rate: 3e-05 
2025-08-30 10:25:19.605455: train_loss -0.6797 
2025-08-30 10:25:19.613285: val_loss -0.6352 
2025-08-30 10:25:19.617422: Pseudo dice [np.float32(0.7961)] 
2025-08-30 10:25:19.627070: Epoch time: 25.6 s 
2025-08-30 10:25:20.302507:  
2025-08-30 10:25:20.312023: Epoch 982 
2025-08-30 10:25:20.318042: Current learning rate: 3e-05 
2025-08-30 10:25:45.760426: train_loss -0.6821 
2025-08-30 10:25:45.768571: val_loss -0.6714 
2025-08-30 10:25:45.772726: Pseudo dice [np.float32(0.7626)] 
2025-08-30 10:25:45.779890: Epoch time: 25.46 s 
2025-08-30 10:25:46.484952:  
2025-08-30 10:25:46.494066: Epoch 983 
2025-08-30 10:25:46.500638: Current learning rate: 3e-05 
2025-08-30 10:26:11.844654: train_loss -0.6656 
2025-08-30 10:26:11.852982: val_loss -0.6302 
2025-08-30 10:26:11.857273: Pseudo dice [np.float32(0.791)] 
2025-08-30 10:26:11.866189: Epoch time: 25.36 s 
2025-08-30 10:26:12.669333:  
2025-08-30 10:26:12.679943: Epoch 984 
2025-08-30 10:26:12.688155: Current learning rate: 2e-05 
2025-08-30 10:26:38.116451: train_loss -0.6795 
2025-08-30 10:26:38.125087: val_loss -0.7196 
2025-08-30 10:26:38.129497: Pseudo dice [np.float32(0.8484)] 
2025-08-30 10:26:38.135426: Epoch time: 25.45 s 
2025-08-30 10:26:38.832946:  
2025-08-30 10:26:38.841308: Epoch 985 
2025-08-30 10:26:38.846387: Current learning rate: 2e-05 
2025-08-30 10:27:04.393530: train_loss -0.6535 
2025-08-30 10:27:04.401588: val_loss -0.5945 
2025-08-30 10:27:04.405444: Pseudo dice [np.float32(0.7442)] 
2025-08-30 10:27:04.412670: Epoch time: 25.56 s 
2025-08-30 10:27:05.089363:  
2025-08-30 10:27:05.097637: Epoch 986 
2025-08-30 10:27:05.104001: Current learning rate: 2e-05 
2025-08-30 10:27:30.564880: train_loss -0.6654 
2025-08-30 10:27:30.577400: val_loss -0.6013 
2025-08-30 10:27:30.581833: Pseudo dice [np.float32(0.7889)] 
2025-08-30 10:27:30.588851: Epoch time: 25.48 s 
2025-08-30 10:27:31.282122:  
2025-08-30 10:27:31.291639: Epoch 987 
2025-08-30 10:27:31.296808: Current learning rate: 2e-05 
2025-08-30 10:27:56.661489: train_loss -0.6642 
2025-08-30 10:27:56.670163: val_loss -0.6606 
2025-08-30 10:27:56.674549: Pseudo dice [np.float32(0.8533)] 
2025-08-30 10:27:56.682683: Epoch time: 25.38 s 
2025-08-30 10:27:57.366596:  
2025-08-30 10:27:57.376028: Epoch 988 
2025-08-30 10:27:57.382153: Current learning rate: 2e-05 
2025-08-30 10:28:22.687820: train_loss -0.6341 
2025-08-30 10:28:22.696124: val_loss -0.625 
2025-08-30 10:28:22.700201: Pseudo dice [np.float32(0.856)] 
2025-08-30 10:28:22.709452: Epoch time: 25.32 s 
2025-08-30 10:28:23.392551:  
2025-08-30 10:28:23.400898: Epoch 989 
2025-08-30 10:28:23.407271: Current learning rate: 2e-05 
2025-08-30 10:28:48.780827: train_loss -0.691 
2025-08-30 10:28:48.788813: val_loss -0.6112 
2025-08-30 10:28:48.793285: Pseudo dice [np.float32(0.7963)] 
2025-08-30 10:28:48.801129: Epoch time: 25.39 s 
2025-08-30 10:28:49.464938:  
2025-08-30 10:28:49.473832: Epoch 990 
2025-08-30 10:28:49.481150: Current learning rate: 2e-05 
2025-08-30 10:29:15.123457: train_loss -0.674 
2025-08-30 10:29:15.132138: val_loss -0.653 
2025-08-30 10:29:15.136001: Pseudo dice [np.float32(0.7985)] 
2025-08-30 10:29:15.142158: Epoch time: 25.66 s 
2025-08-30 10:29:15.818865:  
2025-08-30 10:29:15.826158: Epoch 991 
2025-08-30 10:29:15.832388: Current learning rate: 1e-05 
2025-08-30 10:29:41.628637: train_loss -0.6768 
2025-08-30 10:29:41.637463: val_loss -0.6668 
2025-08-30 10:29:41.642056: Pseudo dice [np.float32(0.8327)] 
2025-08-30 10:29:41.648667: Epoch time: 25.81 s 
2025-08-30 10:29:42.490390:  
2025-08-30 10:29:42.498696: Epoch 992 
2025-08-30 10:29:42.503801: Current learning rate: 1e-05 
2025-08-30 10:30:07.805696: train_loss -0.6452 
2025-08-30 10:30:07.813599: val_loss -0.6789 
2025-08-30 10:30:07.818018: Pseudo dice [np.float32(0.849)] 
2025-08-30 10:30:07.825786: Epoch time: 25.32 s 
2025-08-30 10:30:08.500772:  
2025-08-30 10:30:08.509052: Epoch 993 
2025-08-30 10:30:08.515354: Current learning rate: 1e-05 
2025-08-30 10:30:34.031798: train_loss -0.6649 
2025-08-30 10:30:34.040092: val_loss -0.6428 
2025-08-30 10:30:34.043949: Pseudo dice [np.float32(0.8214)] 
2025-08-30 10:30:34.050133: Epoch time: 25.53 s 
2025-08-30 10:30:34.700752:  
2025-08-30 10:30:34.711290: Epoch 994 
2025-08-30 10:30:34.717430: Current learning rate: 1e-05 
2025-08-30 10:30:59.986909: train_loss -0.6436 
2025-08-30 10:30:59.994823: val_loss -0.5903 
2025-08-30 10:31:00.003179: Pseudo dice [np.float32(0.7521)] 
2025-08-30 10:31:00.009393: Epoch time: 25.29 s 
2025-08-30 10:31:00.710187:  
2025-08-30 10:31:00.718492: Epoch 995 
2025-08-30 10:31:00.725797: Current learning rate: 1e-05 
2025-08-30 10:31:26.141932: train_loss -0.6979 
2025-08-30 10:31:26.150477: val_loss -0.6609 
2025-08-30 10:31:26.158485: Pseudo dice [np.float32(0.8523)] 
2025-08-30 10:31:26.163937: Epoch time: 25.43 s 
2025-08-30 10:31:26.842365:  
2025-08-30 10:31:26.850652: Epoch 996 
2025-08-30 10:31:26.856055: Current learning rate: 1e-05 
2025-08-30 10:31:52.376683: train_loss -0.6632 
2025-08-30 10:31:52.384671: val_loss -0.6079 
2025-08-30 10:31:52.393360: Pseudo dice [np.float32(0.8286)] 
2025-08-30 10:31:52.398508: Epoch time: 25.54 s 
2025-08-30 10:31:53.082215:  
2025-08-30 10:31:53.091522: Epoch 997 
2025-08-30 10:31:53.097832: Current learning rate: 1e-05 
2025-08-30 10:32:18.473387: train_loss -0.6891 
2025-08-30 10:32:18.481549: val_loss -0.603 
2025-08-30 10:32:18.485705: Pseudo dice [np.float32(0.7856)] 
2025-08-30 10:32:18.493994: Epoch time: 25.39 s 
2025-08-30 10:32:19.338019:  
2025-08-30 10:32:19.346916: Epoch 998 
2025-08-30 10:32:19.356170: Current learning rate: 0.0 
2025-08-30 10:32:44.645368: train_loss -0.6599 
2025-08-30 10:32:44.657664: val_loss -0.6329 
2025-08-30 10:32:44.662228: Pseudo dice [np.float32(0.8163)] 
2025-08-30 10:32:44.668144: Epoch time: 25.31 s 
2025-08-30 10:32:45.352075:  
2025-08-30 10:32:45.362417: Epoch 999 
2025-08-30 10:32:45.368746: Current learning rate: 0.0 
2025-08-30 10:33:10.738540: train_loss -0.6378 
2025-08-30 10:33:10.746232: val_loss -0.6562 
2025-08-30 10:33:10.750417: Pseudo dice [np.float32(0.8232)] 
2025-08-30 10:33:10.758913: Epoch time: 25.39 s 
2025-08-30 10:33:11.712752: Training done. 
2025-08-30 10:33:11.872607: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-30 10:33:11.885500: The split file contains 5 splits. 
2025-08-30 10:33:11.899169: Desired fold for training: 4 
2025-08-30 10:33:11.907284: This split has 524 training and 131 validation cases. 
2025-08-30 10:33:11.920828: predicting sub-r001s006 
2025-08-30 10:33:12.189835: sub-r001s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:33:31.771383: predicting sub-r001s024 
2025-08-30 10:33:32.000792: sub-r001s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:33:50.965556: predicting sub-r001s030 
2025-08-30 10:33:51.203287: sub-r001s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:34:12.474862: predicting sub-r001s033 
2025-08-30 10:34:12.695951: sub-r001s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:34:31.368373: predicting sub-r001s036 
2025-08-30 10:34:31.643920: sub-r001s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:34:50.187464: predicting sub-r001s038 
2025-08-30 10:34:50.428985: sub-r001s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:35:08.918329: predicting sub-r002s006 
2025-08-30 10:35:09.206178: sub-r002s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:35:27.061491: predicting sub-r003s009 
2025-08-30 10:35:27.290859: sub-r003s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:35:44.466333: predicting sub-r003s010 
2025-08-30 10:35:44.716872: sub-r003s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:36:02.380009: predicting sub-r003s014 
2025-08-30 10:36:02.620828: sub-r003s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:36:21.178214: predicting sub-r004s005 
2025-08-30 10:36:21.407353: sub-r004s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:36:40.459991: predicting sub-r004s008 
2025-08-30 10:36:40.715149: sub-r004s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:36:59.858235: predicting sub-r004s012 
2025-08-30 10:37:00.108490: sub-r004s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:37:18.868879: predicting sub-r004s013 
2025-08-30 10:37:19.086155: sub-r004s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:37:38.125618: predicting sub-r004s014 
2025-08-30 10:37:38.380047: sub-r004s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:37:57.328125: predicting sub-r004s017 
2025-08-30 10:37:57.565867: sub-r004s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:38:16.488976: predicting sub-r004s019 
2025-08-30 10:38:16.710016: sub-r004s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:38:34.498590: predicting sub-r004s022 
2025-08-30 10:38:34.736311: sub-r004s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:38:52.617003: predicting sub-r004s027 
2025-08-30 10:38:52.833591: sub-r004s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:39:11.602607: predicting sub-r004s028 
2025-08-30 10:39:11.823412: sub-r004s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:39:28.915391: predicting sub-r004s030 
2025-08-30 10:39:29.165701: sub-r004s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:39:46.353642: predicting sub-r004s032 
2025-08-30 10:39:46.583085: sub-r004s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:40:05.377143: predicting sub-r005s045 
2025-08-30 10:40:05.619064: sub-r005s045, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:40:23.711779: predicting sub-r005s048 
2025-08-30 10:40:23.953712: sub-r005s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:40:42.951835: predicting sub-r005s049 
2025-08-30 10:40:43.202256: sub-r005s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:41:01.645485: predicting sub-r005s075 
2025-08-30 10:41:01.862455: sub-r005s075, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:41:21.031506: predicting sub-r005s077 
2025-08-30 10:41:21.269566: sub-r005s077, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:41:40.413442: predicting sub-r009s002 
2025-08-30 10:41:40.688604: sub-r009s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:41:59.148981: predicting sub-r009s005 
2025-08-30 10:41:59.365657: sub-r009s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:42:16.962331: predicting sub-r009s006 
2025-08-30 10:42:17.170947: sub-r009s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:42:33.570610: predicting sub-r009s007 
2025-08-30 10:42:33.799993: sub-r009s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:42:49.995122: predicting sub-r009s010 
2025-08-30 10:42:50.228957: sub-r009s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:43:06.508172: predicting sub-r009s026 
2025-08-30 10:43:06.741483: sub-r009s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:43:25.430713: predicting sub-r009s029 
2025-08-30 10:43:25.652207: sub-r009s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:43:43.265188: predicting sub-r009s039 
2025-08-30 10:43:43.507123: sub-r009s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:43:59.631546: predicting sub-r009s052 
2025-08-30 10:43:59.848437: sub-r009s052, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:44:18.521228: predicting sub-r009s053 
2025-08-30 10:44:18.734183: sub-r009s053, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:44:37.957305: predicting sub-r009s058 
2025-08-30 10:44:38.186726: sub-r009s058, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:44:54.603118: predicting sub-r009s063 
2025-08-30 10:44:54.824154: sub-r009s063, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:45:11.019415: predicting sub-r009s075 
2025-08-30 10:45:11.257241: sub-r009s075, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:45:27.185633: predicting sub-r009s100 
2025-08-30 10:45:27.427581: sub-r009s100, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:45:44.286122: predicting sub-r009s106 
2025-08-30 10:45:44.515489: sub-r009s106, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:46:03.083970: predicting sub-r009s108 
2025-08-30 10:46:03.321739: sub-r009s108, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:46:20.660201: predicting sub-r009s120 
2025-08-30 10:46:20.895755: sub-r009s120, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:46:38.824169: predicting sub-r009s121 
2025-08-30 10:46:39.095184: sub-r009s121, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:46:57.238062: predicting sub-r009s122 
2025-08-30 10:46:57.492502: sub-r009s122, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:47:16.632407: predicting sub-r009s123 
2025-08-30 10:47:16.866003: sub-r009s123, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:47:34.984076: predicting sub-r009s124 
2025-08-30 10:47:35.251050: sub-r009s124, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:47:54.340957: predicting sub-r010s001 
2025-08-30 10:47:54.578649: sub-r010s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:48:12.075288: predicting sub-r010s002 
2025-08-30 10:48:12.325543: sub-r010s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:48:29.080218: predicting sub-r010s006 
2025-08-30 10:48:29.334191: sub-r010s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:48:46.422107: predicting sub-r010s012 
2025-08-30 10:48:46.659813: sub-r010s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:49:05.649603: predicting sub-r010s016 
2025-08-30 10:49:05.883175: sub-r010s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:49:23.647093: predicting sub-r010s024 
2025-08-30 10:49:23.884502: sub-r010s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:49:41.181353: predicting sub-r011s003 
2025-08-30 10:49:41.468721: sub-r011s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:50:00.487692: predicting sub-r011s010 
2025-08-30 10:50:00.721272: sub-r011s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:50:19.632066: predicting sub-r011s012 
2025-08-30 10:50:19.861210: sub-r011s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:50:39.080699: predicting sub-r011s013 
2025-08-30 10:50:39.355684: sub-r011s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:50:58.495878: predicting sub-r011s016 
2025-08-30 10:50:58.745874: sub-r011s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:51:15.792062: predicting sub-r011s018 
2025-08-30 10:51:16.017361: sub-r011s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:51:33.789199: predicting sub-r011s028 
2025-08-30 10:51:34.060327: sub-r011s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:51:51.748771: predicting sub-r011s034 
2025-08-30 10:51:51.982363: sub-r011s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:52:08.907613: predicting sub-r014s004 
2025-08-30 10:52:09.174533: sub-r014s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:52:26.329160: predicting sub-r014s008 
2025-08-30 10:52:26.575229: sub-r014s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:52:44.213690: predicting sub-r015s008 
2025-08-30 10:52:44.455808: sub-r015s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:53:01.497920: predicting sub-r015s009 
2025-08-30 10:53:01.743730: sub-r015s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:53:20.141548: predicting sub-r015s016 
2025-08-30 10:53:20.359203: sub-r015s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:53:38.004924: predicting sub-r015s026 
2025-08-30 10:53:38.263530: sub-r015s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:53:57.461838: predicting sub-r015s027 
2025-08-30 10:53:57.674550: sub-r015s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:54:15.400676: predicting sub-r017s116 
2025-08-30 10:54:15.629994: sub-r017s116, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:54:34.620083: predicting sub-r017s118 
2025-08-30 10:54:34.882555: sub-r017s118, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:54:52.525446: predicting sub-r018s011 
2025-08-30 10:54:52.754543: sub-r018s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:55:11.581786: predicting sub-r019s004 
2025-08-30 10:55:11.811054: sub-r019s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:55:29.378608: predicting sub-r019s009 
2025-08-30 10:55:29.628911: sub-r019s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:55:47.021237: predicting sub-r024s003 
2025-08-30 10:55:47.242313: sub-r024s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:56:05.093468: predicting sub-r024s012 
2025-08-30 10:56:05.364588: sub-r024s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:56:24.396044: predicting sub-r024s018 
2025-08-30 10:56:24.642205: sub-r024s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:56:44.061526: predicting sub-r027s006 
2025-08-30 10:56:44.311764: sub-r027s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:57:03.276825: predicting sub-r027s041 
2025-08-30 10:57:03.501760: sub-r027s041, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:57:22.596089: predicting sub-r027s050 
2025-08-30 10:57:22.812751: sub-r027s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:57:40.701425: predicting sub-r028s017 
2025-08-30 10:57:40.939125: sub-r028s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:58:00.125100: predicting sub-r028s026 
2025-08-30 10:58:00.346077: sub-r028s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:58:19.690635: predicting sub-r029s007 
2025-08-30 10:58:19.940595: sub-r029s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:58:37.465042: predicting sub-r031s006 
2025-08-30 10:58:37.712920: sub-r031s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:58:55.396854: predicting sub-r031s011 
2025-08-30 10:58:55.605631: sub-r031s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:59:12.701620: predicting sub-r031s013 
2025-08-30 10:59:12.914397: sub-r031s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:59:30.202427: predicting sub-r031s016 
2025-08-30 10:59:30.465184: sub-r031s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 10:59:49.317329: predicting sub-r031s017 
2025-08-30 10:59:49.534224: sub-r031s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:00:08.186178: predicting sub-r031s022 
2025-08-30 11:00:08.394726: sub-r031s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:00:27.255422: predicting sub-r031s026 
2025-08-30 11:00:27.496937: sub-r031s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:00:46.294725: predicting sub-r031s029 
2025-08-30 11:00:46.503658: sub-r031s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:01:04.947014: predicting sub-r031s033 
2025-08-30 11:01:05.159826: sub-r031s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:01:24.061933: predicting sub-r031s034 
2025-08-30 11:01:24.291339: sub-r031s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:01:43.226926: predicting sub-r034s010 
2025-08-30 11:01:43.493856: sub-r034s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:02:03.234407: predicting sub-r034s011 
2025-08-30 11:02:03.463795: sub-r034s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:02:22.211612: predicting sub-r034s021 
2025-08-30 11:02:22.457745: sub-r034s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:02:40.142318: predicting sub-r035s005 
2025-08-30 11:02:40.396792: sub-r035s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:02:57.421817: predicting sub-r035s007 
2025-08-30 11:02:57.651232: sub-r035s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:03:15.569108: predicting sub-r038s007 
2025-08-30 11:03:15.823552: sub-r038s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:03:33.507895: predicting sub-r038s022 
2025-08-30 11:03:33.754246: sub-r038s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:03:51.146397: predicting sub-r038s025 
2025-08-30 11:03:51.391683: sub-r038s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:04:10.194834: predicting sub-r038s054 
2025-08-30 11:04:10.444757: sub-r038s054, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:04:28.229515: predicting sub-r038s069 
2025-08-30 11:04:28.458629: sub-r038s069, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:04:47.260987: predicting sub-r038s078 
2025-08-30 11:04:47.477570: sub-r038s078, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:05:06.546636: predicting sub-r038s093 
2025-08-30 11:05:06.784700: sub-r038s093, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:05:25.624335: predicting sub-r040s001 
2025-08-30 11:05:25.866119: sub-r040s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:05:44.847603: predicting sub-r040s031 
2025-08-30 11:05:45.097970: sub-r040s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:06:04.230162: predicting sub-r040s037 
2025-08-30 11:06:04.441968: sub-r040s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:06:22.601987: predicting sub-r040s044 
2025-08-30 11:06:22.856158: sub-r040s044, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:06:40.657316: predicting sub-r040s051 
2025-08-30 11:06:40.932543: sub-r040s051, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:06:58.220619: predicting sub-r040s086 
2025-08-30 11:06:58.462538: sub-r040s086, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:07:15.608798: predicting sub-r042s010 
2025-08-30 11:07:15.846560: sub-r042s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:07:33.097125: predicting sub-r042s013 
2025-08-30 11:07:33.339820: sub-r042s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:07:50.464680: predicting sub-r042s021 
2025-08-30 11:07:50.698355: sub-r042s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:08:07.990550: predicting sub-r042s029 
2025-08-30 11:08:08.203015: sub-r042s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:08:27.088752: predicting sub-r046s011 
2025-08-30 11:08:27.326284: sub-r046s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:08:44.622715: predicting sub-r047s001 
2025-08-30 11:08:44.885481: sub-r047s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:09:02.152766: predicting sub-r047s010 
2025-08-30 11:09:02.382100: sub-r047s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:09:19.582619: predicting sub-r047s014 
2025-08-30 11:09:19.812329: sub-r047s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:09:37.404767: predicting sub-r047s036 
2025-08-30 11:09:37.667580: sub-r047s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:09:55.468792: predicting sub-r047s044 
2025-08-30 11:09:55.697883: sub-r047s044, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:10:13.115237: predicting sub-r047s048 
2025-08-30 11:10:13.361334: sub-r047s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:10:30.878803: predicting sub-r048s010 
2025-08-30 11:10:31.104033: sub-r048s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:10:49.088673: predicting sub-r048s016 
2025-08-30 11:10:49.305594: sub-r048s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:11:08.270372: predicting sub-r048s018 
2025-08-30 11:11:08.478895: sub-r048s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:11:26.046421: predicting sub-r048s021 
2025-08-30 11:11:26.259119: sub-r048s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:11:45.962074: predicting sub-r048s029 
2025-08-30 11:11:46.208231: sub-r048s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:12:03.358668: predicting sub-r048s031 
2025-08-30 11:12:03.625645: sub-r048s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:12:22.732166: predicting sub-r048s034 
2025-08-30 11:12:22.944905: sub-r048s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:12:42.172468: predicting sub-r048s039 
2025-08-30 11:12:42.406035: sub-r048s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:12:59.902801: predicting sub-r049s007 
2025-08-30 11:13:00.152888: sub-r049s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-30 11:13:26.587629: Validation complete 
2025-08-30 11:13:26.599777: Mean Validation Dice:  0.5658872579700678 
