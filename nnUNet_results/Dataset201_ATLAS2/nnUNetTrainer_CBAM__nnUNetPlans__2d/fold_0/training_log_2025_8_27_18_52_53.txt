
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-27 18:52:54.181623: do_dummy_2d_data_aug: False 
2025-08-27 18:52:54.181623: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-27 18:52:54.189886: The split file contains 5 splits. 
2025-08-27 18:52:54.196078: Desired fold for training: 0 
2025-08-27 18:52:54.197077: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-27 18:52:54.338974: Unable to plot network architecture: 
2025-08-27 18:52:54.346106: No module named 'hiddenlayer' 
2025-08-27 18:52:54.383081:  
2025-08-27 18:52:54.390432: Epoch 0 
2025-08-27 18:52:54.398394: Current learning rate: 0.01 
2025-08-27 18:53:20.528645: train_loss 0.0563 
2025-08-27 18:53:20.537031: val_loss 0.0121 
2025-08-27 18:53:20.545370: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:53:20.550550: Epoch time: 26.15 s 
2025-08-27 18:53:20.552638: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-27 18:53:21.212995:  
2025-08-27 18:53:21.221395: Epoch 1 
2025-08-27 18:53:21.229294: Current learning rate: 0.00999 
2025-08-27 18:53:45.866769: train_loss 0.0104 
2025-08-27 18:53:45.874813: val_loss 0.0167 
2025-08-27 18:53:45.883108: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:53:45.888178: Epoch time: 24.65 s 
2025-08-27 18:53:46.479543:  
2025-08-27 18:53:46.487937: Epoch 2 
2025-08-27 18:53:46.496275: Current learning rate: 0.00998 
2025-08-27 18:54:12.701939: train_loss 0.0163 
2025-08-27 18:54:12.709884: val_loss 0.0051 
2025-08-27 18:54:12.714055: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:54:12.722420: Epoch time: 26.22 s 
2025-08-27 18:54:13.306330:  
2025-08-27 18:54:13.311024: Epoch 3 
2025-08-27 18:54:13.318841: Current learning rate: 0.00997 
2025-08-27 18:54:37.526530: train_loss 0.0134 
2025-08-27 18:54:37.534695: val_loss 0.0426 
2025-08-27 18:54:37.539293: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:54:37.544458: Epoch time: 24.22 s 
2025-08-27 18:54:38.106143:  
2025-08-27 18:54:38.114436: Epoch 4 
2025-08-27 18:54:38.118688: Current learning rate: 0.00996 
2025-08-27 18:55:02.635114: train_loss 0.0136 
2025-08-27 18:55:02.643071: val_loss 0.009 
2025-08-27 18:55:02.651413: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:55:02.656623: Epoch time: 24.53 s 
2025-08-27 18:55:03.245905:  
2025-08-27 18:55:03.254024: Epoch 5 
2025-08-27 18:55:03.259226: Current learning rate: 0.00995 
2025-08-27 18:55:29.178775: train_loss 0.0128 
2025-08-27 18:55:29.186234: val_loss 0.0081 
2025-08-27 18:55:29.190395: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:55:29.199422: Epoch time: 25.93 s 
2025-08-27 18:55:29.760060:  
2025-08-27 18:55:29.769154: Epoch 6 
2025-08-27 18:55:29.774471: Current learning rate: 0.00995 
2025-08-27 18:55:54.428104: train_loss 0.0116 
2025-08-27 18:55:54.436445: val_loss 0.0165 
2025-08-27 18:55:54.440615: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:55:54.448030: Epoch time: 24.67 s 
2025-08-27 18:55:55.150889:  
2025-08-27 18:55:55.157964: Epoch 7 
2025-08-27 18:55:55.164149: Current learning rate: 0.00994 
2025-08-27 18:56:19.319663: train_loss 0.0076 
2025-08-27 18:56:19.328013: val_loss 0.009 
2025-08-27 18:56:19.336288: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:56:19.341336: Epoch time: 24.17 s 
2025-08-27 18:56:19.948059:  
2025-08-27 18:56:19.958952: Epoch 8 
2025-08-27 18:56:19.969134: Current learning rate: 0.00993 
2025-08-27 18:56:45.587481: train_loss 0.0076 
2025-08-27 18:56:45.595851: val_loss 0.005 
2025-08-27 18:56:45.604181: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:56:45.609257: Epoch time: 25.64 s 
2025-08-27 18:56:46.193287:  
2025-08-27 18:56:46.201631: Epoch 9 
2025-08-27 18:56:46.206797: Current learning rate: 0.00992 
2025-08-27 18:57:11.367466: train_loss 0.0089 
2025-08-27 18:57:11.375741: val_loss 0.0066 
2025-08-27 18:57:11.380221: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:57:11.387372: Epoch time: 25.18 s 
2025-08-27 18:57:11.949172:  
2025-08-27 18:57:11.957502: Epoch 10 
2025-08-27 18:57:11.964831: Current learning rate: 0.00991 
2025-08-27 18:57:36.446656: train_loss 0.011 
2025-08-27 18:57:36.454940: val_loss 0.0048 
2025-08-27 18:57:36.459118: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:57:36.466518: Epoch time: 24.5 s 
2025-08-27 18:57:37.028363:  
2025-08-27 18:57:37.035707: Epoch 11 
2025-08-27 18:57:37.040870: Current learning rate: 0.0099 
2025-08-27 18:58:02.778498: train_loss 0.0075 
2025-08-27 18:58:02.786298: val_loss 0.0081 
2025-08-27 18:58:02.790459: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:58:02.798513: Epoch time: 25.75 s 
2025-08-27 18:58:03.373360:  
2025-08-27 18:58:03.382865: Epoch 12 
2025-08-27 18:58:03.390111: Current learning rate: 0.00989 
2025-08-27 18:58:28.265254: train_loss 0.0066 
2025-08-27 18:58:28.273394: val_loss 0.0068 
2025-08-27 18:58:28.277508: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:58:28.285851: Epoch time: 24.89 s 
2025-08-27 18:58:28.868697:  
2025-08-27 18:58:28.876938: Epoch 13 
2025-08-27 18:58:28.882107: Current learning rate: 0.00988 
2025-08-27 18:58:53.978165: train_loss 0.0098 
2025-08-27 18:58:53.986522: val_loss 0.0062 
2025-08-27 18:58:53.994834: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:58:53.999572: Epoch time: 25.11 s 
2025-08-27 18:58:54.565076:  
2025-08-27 18:58:54.572605: Epoch 14 
2025-08-27 18:58:54.581017: Current learning rate: 0.00987 
2025-08-27 18:59:20.346226: train_loss 0.0065 
2025-08-27 18:59:20.354498: val_loss 0.0112 
2025-08-27 18:59:20.358975: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:59:20.363144: Epoch time: 25.78 s 
2025-08-27 18:59:20.948766:  
2025-08-27 18:59:20.957108: Epoch 15 
2025-08-27 18:59:20.964447: Current learning rate: 0.00986 
2025-08-27 18:59:45.905525: train_loss 0.0066 
2025-08-27 18:59:45.913668: val_loss 0.0082 
2025-08-27 18:59:45.922012: Pseudo dice [np.float32(0.0)] 
2025-08-27 18:59:45.926035: Epoch time: 24.96 s 
2025-08-27 18:59:46.572206:  
2025-08-27 18:59:46.582204: Epoch 16 
2025-08-27 18:59:46.589210: Current learning rate: 0.00986 
2025-08-27 19:00:11.898178: train_loss 0.0056 
2025-08-27 19:00:11.905128: val_loss 0.0052 
2025-08-27 19:00:11.912513: Pseudo dice [np.float32(0.0354)] 
2025-08-27 19:00:11.919281: Epoch time: 25.33 s 
2025-08-27 19:00:11.924749: Yayy! New best EMA pseudo Dice: 0.0035000001080334187 
2025-08-27 19:00:12.722822:  
2025-08-27 19:00:12.731069: Epoch 17 
2025-08-27 19:00:12.740069: Current learning rate: 0.00985 
2025-08-27 19:00:38.440778: train_loss 0.0028 
2025-08-27 19:00:38.449446: val_loss 0.0143 
2025-08-27 19:00:38.453589: Pseudo dice [np.float32(0.1314)] 
2025-08-27 19:00:38.459041: Epoch time: 25.72 s 
2025-08-27 19:00:38.462488: Yayy! New best EMA pseudo Dice: 0.016300000250339508 
2025-08-27 19:00:39.280102:  
2025-08-27 19:00:39.288476: Epoch 18 
2025-08-27 19:00:39.293675: Current learning rate: 0.00984 
2025-08-27 19:01:03.386486: train_loss 0.009 
2025-08-27 19:01:03.394831: val_loss 0.0066 
2025-08-27 19:01:03.399018: Pseudo dice [np.float32(0.0507)] 
2025-08-27 19:01:03.404816: Epoch time: 24.11 s 
2025-08-27 19:01:03.405816: Yayy! New best EMA pseudo Dice: 0.01979999989271164 
2025-08-27 19:01:04.335322:  
2025-08-27 19:01:04.344631: Epoch 19 
2025-08-27 19:01:04.352180: Current learning rate: 0.00983 
2025-08-27 19:01:29.237555: train_loss 0.0066 
2025-08-27 19:01:29.245678: val_loss 0.0012 
2025-08-27 19:01:29.249807: Pseudo dice [np.float32(0.0886)] 
2025-08-27 19:01:29.258234: Epoch time: 24.9 s 
2025-08-27 19:01:29.263092: Yayy! New best EMA pseudo Dice: 0.026599999517202377 
2025-08-27 19:01:30.050498:  
2025-08-27 19:01:30.057819: Epoch 20 
2025-08-27 19:01:30.065148: Current learning rate: 0.00982 
2025-08-27 19:01:55.514136: train_loss 0.0054 
2025-08-27 19:01:55.521893: val_loss 0.0105 
2025-08-27 19:01:55.526251: Pseudo dice [np.float32(0.0283)] 
2025-08-27 19:01:55.533951: Epoch time: 25.47 s 
2025-08-27 19:01:55.539176: Yayy! New best EMA pseudo Dice: 0.026799999177455902 
2025-08-27 19:01:56.312293:  
2025-08-27 19:01:56.321560: Epoch 21 
2025-08-27 19:01:56.328892: Current learning rate: 0.00981 
2025-08-27 19:02:20.651127: train_loss 0.0055 
2025-08-27 19:02:20.660071: val_loss 0.0081 
2025-08-27 19:02:20.663625: Pseudo dice [np.float32(0.0965)] 
2025-08-27 19:02:20.671616: Epoch time: 24.34 s 
2025-08-27 19:02:20.676706: Yayy! New best EMA pseudo Dice: 0.033799998462200165 
2025-08-27 19:02:21.433119:  
2025-08-27 19:02:21.441453: Epoch 22 
2025-08-27 19:02:21.446596: Current learning rate: 0.0098 
2025-08-27 19:02:46.410561: train_loss 0.0059 
2025-08-27 19:02:46.418512: val_loss -0.0047 
2025-08-27 19:02:46.426841: Pseudo dice [np.float32(0.3796)] 
2025-08-27 19:02:46.432156: Epoch time: 24.98 s 
2025-08-27 19:02:46.433862: Yayy! New best EMA pseudo Dice: 0.06840000301599503 
2025-08-27 19:02:47.174282:  
2025-08-27 19:02:47.182740: Epoch 23 
2025-08-27 19:02:47.186902: Current learning rate: 0.00979 
2025-08-27 19:03:12.757594: train_loss 0.0084 
2025-08-27 19:03:12.765349: val_loss 0.0055 
2025-08-27 19:03:12.771574: Pseudo dice [np.float32(0.0521)] 
2025-08-27 19:03:12.779034: Epoch time: 25.58 s 
2025-08-27 19:03:13.403631:  
2025-08-27 19:03:13.411082: Epoch 24 
2025-08-27 19:03:13.416142: Current learning rate: 0.00978 
2025-08-27 19:03:37.845178: train_loss 0.0054 
2025-08-27 19:03:37.853231: val_loss 0.0036 
2025-08-27 19:03:37.857666: Pseudo dice [np.float32(0.1467)] 
2025-08-27 19:03:37.864566: Epoch time: 24.44 s 
2025-08-27 19:03:37.870759: Yayy! New best EMA pseudo Dice: 0.0746999979019165 
2025-08-27 19:03:38.618483:  
2025-08-27 19:03:38.626905: Epoch 25 
2025-08-27 19:03:38.633019: Current learning rate: 0.00977 
2025-08-27 19:04:03.674978: train_loss 0.0082 
2025-08-27 19:04:03.685436: val_loss 0.0027 
2025-08-27 19:04:03.687576: Pseudo dice [np.float32(0.0671)] 
2025-08-27 19:04:03.695468: Epoch time: 25.06 s 
2025-08-27 19:04:04.273279:  
2025-08-27 19:04:04.280616: Epoch 26 
2025-08-27 19:04:04.285835: Current learning rate: 0.00977 
2025-08-27 19:04:29.792859: train_loss 0.0038 
2025-08-27 19:04:29.801282: val_loss 0.0027 
2025-08-27 19:04:29.805392: Pseudo dice [np.float32(0.1022)] 
2025-08-27 19:04:29.813135: Epoch time: 25.52 s 
2025-08-27 19:04:29.818304: Yayy! New best EMA pseudo Dice: 0.07680000364780426 
2025-08-27 19:04:30.564002:  
2025-08-27 19:04:30.570337: Epoch 27 
2025-08-27 19:04:30.575489: Current learning rate: 0.00976 
2025-08-27 19:04:55.021884: train_loss 0.0047 
2025-08-27 19:04:55.030540: val_loss -0.0027 
2025-08-27 19:04:55.034443: Pseudo dice [np.float32(0.3388)] 
2025-08-27 19:04:55.041444: Epoch time: 24.46 s 
2025-08-27 19:04:55.047732: Yayy! New best EMA pseudo Dice: 0.10300000011920929 
2025-08-27 19:04:55.796565:  
2025-08-27 19:04:55.803896: Epoch 28 
2025-08-27 19:04:55.811235: Current learning rate: 0.00975 
2025-08-27 19:05:20.143512: train_loss 0.0069 
2025-08-27 19:05:20.151198: val_loss 0.0026 
2025-08-27 19:05:20.155653: Pseudo dice [np.float32(0.2203)] 
2025-08-27 19:05:20.161066: Epoch time: 24.35 s 
2025-08-27 19:05:20.164515: Yayy! New best EMA pseudo Dice: 0.11469999700784683 
2025-08-27 19:05:20.943568:  
2025-08-27 19:05:20.951869: Epoch 29 
2025-08-27 19:05:20.958149: Current learning rate: 0.00974 
2025-08-27 19:05:45.426693: train_loss 0.003 
2025-08-27 19:05:45.435006: val_loss -0.0068 
2025-08-27 19:05:45.439163: Pseudo dice [np.float32(0.2901)] 
2025-08-27 19:05:45.447650: Epoch time: 24.49 s 
2025-08-27 19:05:45.452708: Yayy! New best EMA pseudo Dice: 0.13230000436306 
2025-08-27 19:05:46.217153:  
2025-08-27 19:05:46.224061: Epoch 30 
2025-08-27 19:05:46.229252: Current learning rate: 0.00973 
2025-08-27 19:06:11.394092: train_loss 0.003 
2025-08-27 19:06:11.402482: val_loss 0.003 
2025-08-27 19:06:11.406511: Pseudo dice [np.float32(0.0812)] 
2025-08-27 19:06:11.412274: Epoch time: 25.18 s 
2025-08-27 19:06:12.148760:  
2025-08-27 19:06:12.156098: Epoch 31 
2025-08-27 19:06:12.163524: Current learning rate: 0.00972 
2025-08-27 19:06:36.744391: train_loss 0.0049 
2025-08-27 19:06:36.752639: val_loss 0.0026 
2025-08-27 19:06:36.756792: Pseudo dice [np.float32(0.0843)] 
2025-08-27 19:06:36.763944: Epoch time: 24.6 s 
2025-08-27 19:06:37.352133:  
2025-08-27 19:06:37.358433: Epoch 32 
2025-08-27 19:06:37.364606: Current learning rate: 0.00971 
2025-08-27 19:07:02.657631: train_loss 0.0077 
2025-08-27 19:07:02.665995: val_loss 0.0052 
2025-08-27 19:07:02.670761: Pseudo dice [np.float32(0.0933)] 
2025-08-27 19:07:02.675907: Epoch time: 25.31 s 
2025-08-27 19:07:03.261362:  
2025-08-27 19:07:03.268976: Epoch 33 
2025-08-27 19:07:03.276069: Current learning rate: 0.0097 
2025-08-27 19:07:28.437616: train_loss 0.0021 
2025-08-27 19:07:28.445930: val_loss 0.011 
2025-08-27 19:07:28.450097: Pseudo dice [np.float32(0.0002)] 
2025-08-27 19:07:28.455821: Epoch time: 25.18 s 
2025-08-27 19:07:29.046310:  
2025-08-27 19:07:29.052687: Epoch 34 
2025-08-27 19:07:29.059163: Current learning rate: 0.00969 
2025-08-27 19:07:54.109027: train_loss 0.0029 
2025-08-27 19:07:54.117380: val_loss 0.0023 
2025-08-27 19:07:54.121580: Pseudo dice [np.float32(0.1201)] 
2025-08-27 19:07:54.129874: Epoch time: 25.06 s 
2025-08-27 19:07:54.721965:  
2025-08-27 19:07:54.730320: Epoch 35 
2025-08-27 19:07:54.735648: Current learning rate: 0.00968 
2025-08-27 19:08:19.467786: train_loss 0.0031 
2025-08-27 19:08:19.476031: val_loss 0.0051 
2025-08-27 19:08:19.480187: Pseudo dice [np.float32(0.1122)] 
2025-08-27 19:08:19.488951: Epoch time: 24.75 s 
2025-08-27 19:08:20.151705:  
2025-08-27 19:08:20.160306: Epoch 36 
2025-08-27 19:08:20.164424: Current learning rate: 0.00968 
2025-08-27 19:08:46.223948: train_loss -0.0016 
2025-08-27 19:08:46.231893: val_loss -0.007 
2025-08-27 19:08:46.236215: Pseudo dice [np.float32(0.2061)] 
2025-08-27 19:08:46.243568: Epoch time: 26.07 s 
2025-08-27 19:08:46.893919:  
2025-08-27 19:08:46.902290: Epoch 37 
2025-08-27 19:08:46.907390: Current learning rate: 0.00967 
2025-08-27 19:09:12.750338: train_loss 0.0023 
2025-08-27 19:09:12.758115: val_loss 0.0085 
2025-08-27 19:09:12.762864: Pseudo dice [np.float32(0.0704)] 
2025-08-27 19:09:12.768444: Epoch time: 25.86 s 
2025-08-27 19:09:13.419373:  
2025-08-27 19:09:13.428706: Epoch 38 
2025-08-27 19:09:13.435044: Current learning rate: 0.00966 
2025-08-27 19:09:39.209763: train_loss -0.0025 
2025-08-27 19:09:39.218508: val_loss 0.001 
2025-08-27 19:09:39.222621: Pseudo dice [np.float32(0.2097)] 
2025-08-27 19:09:39.229357: Epoch time: 25.79 s 
2025-08-27 19:09:39.884280:  
2025-08-27 19:09:39.892627: Epoch 39 
2025-08-27 19:09:39.897863: Current learning rate: 0.00965 
2025-08-27 19:10:05.519349: train_loss 0.003 
2025-08-27 19:10:05.523888: val_loss 0.008 
2025-08-27 19:10:05.532223: Pseudo dice [np.float32(0.006)] 
2025-08-27 19:10:05.536586: Epoch time: 25.64 s 
2025-08-27 19:10:06.224394:  
2025-08-27 19:10:06.233389: Epoch 40 
2025-08-27 19:10:06.238359: Current learning rate: 0.00964 
2025-08-27 19:10:31.470487: train_loss 0.0018 
2025-08-27 19:10:31.478619: val_loss 0.0035 
2025-08-27 19:10:31.486977: Pseudo dice [np.float32(0.1459)] 
2025-08-27 19:10:31.491641: Epoch time: 25.25 s 
2025-08-27 19:10:32.151145:  
2025-08-27 19:10:32.159488: Epoch 41 
2025-08-27 19:10:32.164650: Current learning rate: 0.00963 
2025-08-27 19:10:57.438181: train_loss -1e-04 
2025-08-27 19:10:57.446557: val_loss -0.0014 
2025-08-27 19:10:57.450382: Pseudo dice [np.float32(0.1559)] 
2025-08-27 19:10:57.458750: Epoch time: 25.29 s 
2025-08-27 19:10:58.113493:  
2025-08-27 19:10:58.121744: Epoch 42 
2025-08-27 19:10:58.127099: Current learning rate: 0.00962 
2025-08-27 19:11:23.643211: train_loss 0.0115 
2025-08-27 19:11:23.651885: val_loss 0.0088 
2025-08-27 19:11:23.655963: Pseudo dice [np.float32(0.1361)] 
2025-08-27 19:11:23.664101: Epoch time: 25.53 s 
2025-08-27 19:11:24.451165:  
2025-08-27 19:11:24.458503: Epoch 43 
2025-08-27 19:11:24.464683: Current learning rate: 0.00961 
2025-08-27 19:11:50.216815: train_loss 0.0032 
2025-08-27 19:11:50.224193: val_loss 0.0003 
2025-08-27 19:11:50.228384: Pseudo dice [np.float32(0.1151)] 
2025-08-27 19:11:50.238595: Epoch time: 25.77 s 
2025-08-27 19:11:50.874432:  
2025-08-27 19:11:50.884955: Epoch 44 
2025-08-27 19:11:50.896425: Current learning rate: 0.0096 
2025-08-27 19:12:16.449954: train_loss 0.0002 
2025-08-27 19:12:16.454316: val_loss -0.002 
2025-08-27 19:12:16.462621: Pseudo dice [np.float32(0.2197)] 
2025-08-27 19:12:16.467485: Epoch time: 25.58 s 
2025-08-27 19:12:17.108976:  
2025-08-27 19:12:17.118560: Epoch 45 
2025-08-27 19:12:17.123598: Current learning rate: 0.00959 
2025-08-27 19:12:42.425902: train_loss 0.0013 
2025-08-27 19:12:42.430416: val_loss -0.0115 
2025-08-27 19:12:42.438538: Pseudo dice [np.float32(0.2852)] 
2025-08-27 19:12:42.443254: Epoch time: 25.32 s 
2025-08-27 19:12:42.445281: Yayy! New best EMA pseudo Dice: 0.14589999616146088 
2025-08-27 19:12:43.287230:  
2025-08-27 19:12:43.296607: Epoch 46 
2025-08-27 19:12:43.302902: Current learning rate: 0.00959 
2025-08-27 19:13:08.956698: train_loss 1e-04 
2025-08-27 19:13:08.964995: val_loss -0.0013 
2025-08-27 19:13:08.973340: Pseudo dice [np.float32(0.2563)] 
2025-08-27 19:13:08.977986: Epoch time: 25.67 s 
2025-08-27 19:13:08.980432: Yayy! New best EMA pseudo Dice: 0.15700000524520874 
2025-08-27 19:13:09.791835:  
2025-08-27 19:13:09.799037: Epoch 47 
2025-08-27 19:13:09.804342: Current learning rate: 0.00958 
2025-08-27 19:13:35.687542: train_loss 0.0016 
2025-08-27 19:13:35.696268: val_loss -0.0077 
2025-08-27 19:13:35.700325: Pseudo dice [np.float32(0.3069)] 
2025-08-27 19:13:35.706778: Epoch time: 25.9 s 
2025-08-27 19:13:35.711986: Yayy! New best EMA pseudo Dice: 0.17190000414848328 
2025-08-27 19:13:36.513160:  
2025-08-27 19:13:36.523724: Epoch 48 
2025-08-27 19:13:36.529900: Current learning rate: 0.00957 
2025-08-27 19:14:01.880305: train_loss -0.0043 
2025-08-27 19:14:01.888810: val_loss -0.0101 
2025-08-27 19:14:01.893043: Pseudo dice [np.float32(0.232)] 
2025-08-27 19:14:01.898514: Epoch time: 25.37 s 
2025-08-27 19:14:01.903573: Yayy! New best EMA pseudo Dice: 0.17800000309944153 
2025-08-27 19:14:02.715550:  
2025-08-27 19:14:02.722806: Epoch 49 
2025-08-27 19:14:02.728234: Current learning rate: 0.00956 
2025-08-27 19:14:28.003040: train_loss -0.0025 
2025-08-27 19:14:28.010606: val_loss -0.0093 
2025-08-27 19:14:28.014774: Pseudo dice [np.float32(0.2206)] 
2025-08-27 19:14:28.020411: Epoch time: 25.29 s 
2025-08-27 19:14:28.202174: Yayy! New best EMA pseudo Dice: 0.18219999969005585 
2025-08-27 19:14:29.047988:  
2025-08-27 19:14:29.054305: Epoch 50 
2025-08-27 19:14:29.060468: Current learning rate: 0.00955 
2025-08-27 19:14:54.258217: train_loss -0.0056 
2025-08-27 19:14:54.265943: val_loss 0.0098 
2025-08-27 19:14:54.270327: Pseudo dice [np.float32(0.0111)] 
2025-08-27 19:14:54.278340: Epoch time: 25.21 s 
2025-08-27 19:14:54.907196:  
2025-08-27 19:14:54.915460: Epoch 51 
2025-08-27 19:14:54.921790: Current learning rate: 0.00954 
2025-08-27 19:15:20.041768: train_loss -0.0025 
2025-08-27 19:15:20.050109: val_loss -0.0163 
2025-08-27 19:15:20.054261: Pseudo dice [np.float32(0.4353)] 
2025-08-27 19:15:20.060951: Epoch time: 25.14 s 
2025-08-27 19:15:20.065507: Yayy! New best EMA pseudo Dice: 0.19210000336170197 
2025-08-27 19:15:20.867345:  
2025-08-27 19:15:20.875710: Epoch 52 
2025-08-27 19:15:20.883259: Current learning rate: 0.00953 
2025-08-27 19:15:46.339287: train_loss -0.0075 
2025-08-27 19:15:46.347104: val_loss 0.0032 
2025-08-27 19:15:46.355443: Pseudo dice [np.float32(0.1295)] 
2025-08-27 19:15:46.360615: Epoch time: 25.47 s 
2025-08-27 19:15:46.935016:  
2025-08-27 19:15:46.942376: Epoch 53 
2025-08-27 19:15:46.946600: Current learning rate: 0.00952 
2025-08-27 19:16:11.951864: train_loss -0.0056 
2025-08-27 19:16:11.960469: val_loss 0.0048 
2025-08-27 19:16:11.964646: Pseudo dice [np.float32(0.1334)] 
2025-08-27 19:16:11.970152: Epoch time: 25.02 s 
2025-08-27 19:16:12.562764:  
2025-08-27 19:16:12.571125: Epoch 54 
2025-08-27 19:16:12.576283: Current learning rate: 0.00951 
2025-08-27 19:16:36.922874: train_loss -0.008 
2025-08-27 19:16:36.930915: val_loss -0.0072 
2025-08-27 19:16:36.935392: Pseudo dice [np.float32(0.1968)] 
2025-08-27 19:16:36.940343: Epoch time: 24.36 s 
2025-08-27 19:16:37.522061:  
2025-08-27 19:16:37.529384: Epoch 55 
2025-08-27 19:16:37.534830: Current learning rate: 0.0095 
2025-08-27 19:17:02.498398: train_loss -0.0096 
2025-08-27 19:17:02.506465: val_loss -0.0039 
2025-08-27 19:17:02.510892: Pseudo dice [np.float32(0.1442)] 
2025-08-27 19:17:02.516571: Epoch time: 24.98 s 
2025-08-27 19:17:03.102707:  
2025-08-27 19:17:03.111062: Epoch 56 
2025-08-27 19:17:03.118445: Current learning rate: 0.00949 
2025-08-27 19:17:27.914957: train_loss -0.009 
2025-08-27 19:17:27.919334: val_loss -0.0116 
2025-08-27 19:17:27.927656: Pseudo dice [np.float32(0.3216)] 
2025-08-27 19:17:27.931853: Epoch time: 24.81 s 
2025-08-27 19:17:27.938331: Yayy! New best EMA pseudo Dice: 0.19280000030994415 
2025-08-27 19:17:28.690784:  
2025-08-27 19:17:28.699094: Epoch 57 
2025-08-27 19:17:28.704260: Current learning rate: 0.00949 
2025-08-27 19:17:53.302850: train_loss -0.0035 
2025-08-27 19:17:53.307180: val_loss -0.0139 
2025-08-27 19:17:53.315521: Pseudo dice [np.float32(0.2672)] 
2025-08-27 19:17:53.320298: Epoch time: 24.61 s 
2025-08-27 19:17:53.325226: Yayy! New best EMA pseudo Dice: 0.20020000636577606 
2025-08-27 19:17:54.081784:  
2025-08-27 19:17:54.092293: Epoch 58 
2025-08-27 19:17:54.097475: Current learning rate: 0.00948 
2025-08-27 19:18:18.849405: train_loss -0.0012 
2025-08-27 19:18:18.857686: val_loss 0.0006 
2025-08-27 19:18:18.862159: Pseudo dice [np.float32(0.2065)] 
2025-08-27 19:18:18.869599: Epoch time: 24.77 s 
2025-08-27 19:18:18.874794: Yayy! New best EMA pseudo Dice: 0.20080000162124634 
2025-08-27 19:18:19.641627:  
2025-08-27 19:18:19.648982: Epoch 59 
2025-08-27 19:18:19.655327: Current learning rate: 0.00947 
2025-08-27 19:18:44.450422: train_loss -0.0075 
2025-08-27 19:18:44.458240: val_loss -0.0081 
2025-08-27 19:18:44.462396: Pseudo dice [np.float32(0.2421)] 
2025-08-27 19:18:44.468952: Epoch time: 24.81 s 
2025-08-27 19:18:44.474212: Yayy! New best EMA pseudo Dice: 0.20499999821186066 
2025-08-27 19:18:45.228657:  
2025-08-27 19:18:45.237014: Epoch 60 
2025-08-27 19:18:45.242187: Current learning rate: 0.00946 
2025-08-27 19:19:10.213190: train_loss -0.0076 
2025-08-27 19:19:10.221475: val_loss -0.0101 
2025-08-27 19:19:10.225631: Pseudo dice [np.float32(0.2342)] 
2025-08-27 19:19:10.231638: Epoch time: 24.99 s 
2025-08-27 19:19:10.234872: Yayy! New best EMA pseudo Dice: 0.2079000025987625 
2025-08-27 19:19:10.992901:  
2025-08-27 19:19:10.999236: Epoch 61 
2025-08-27 19:19:11.005388: Current learning rate: 0.00945 
2025-08-27 19:19:35.810011: train_loss -0.0107 
2025-08-27 19:19:35.817849: val_loss -0.0036 
2025-08-27 19:19:35.824940: Pseudo dice [np.float32(0.2307)] 
2025-08-27 19:19:35.829962: Epoch time: 24.82 s 
2025-08-27 19:19:35.834992: Yayy! New best EMA pseudo Dice: 0.2101999968290329 
2025-08-27 19:19:36.603985:  
2025-08-27 19:19:36.612311: Epoch 62 
2025-08-27 19:19:36.619641: Current learning rate: 0.00944 
2025-08-27 19:20:01.151436: train_loss -0.0016 
2025-08-27 19:20:01.155635: val_loss -0.0054 
2025-08-27 19:20:01.163980: Pseudo dice [np.float32(0.2445)] 
2025-08-27 19:20:01.168948: Epoch time: 24.55 s 
2025-08-27 19:20:01.173224: Yayy! New best EMA pseudo Dice: 0.21359999477863312 
2025-08-27 19:20:01.929251:  
2025-08-27 19:20:01.938643: Epoch 63 
2025-08-27 19:20:01.943757: Current learning rate: 0.00943 
2025-08-27 19:20:26.856290: train_loss -0.0015 
2025-08-27 19:20:26.864641: val_loss -0.015 
2025-08-27 19:20:26.868801: Pseudo dice [np.float32(0.1936)] 
2025-08-27 19:20:26.877134: Epoch time: 24.93 s 
2025-08-27 19:20:27.460887:  
2025-08-27 19:20:27.468284: Epoch 64 
2025-08-27 19:20:27.477616: Current learning rate: 0.00942 
2025-08-27 19:20:51.918930: train_loss -0.0097 
2025-08-27 19:20:51.927150: val_loss 0.0047 
2025-08-27 19:20:51.931320: Pseudo dice [np.float32(0.1251)] 
2025-08-27 19:20:51.939037: Epoch time: 24.46 s 
2025-08-27 19:20:52.537135:  
2025-08-27 19:20:52.544287: Epoch 65 
2025-08-27 19:20:52.550645: Current learning rate: 0.00941 
2025-08-27 19:21:16.864539: train_loss -0.001 
2025-08-27 19:21:16.872893: val_loss 0.0005 
2025-08-27 19:21:16.877371: Pseudo dice [np.float32(0.0127)] 
2025-08-27 19:21:16.884937: Epoch time: 24.33 s 
2025-08-27 19:21:17.485865:  
2025-08-27 19:21:17.495359: Epoch 66 
2025-08-27 19:21:17.500523: Current learning rate: 0.0094 
2025-08-27 19:21:43.116120: train_loss 0.0004 
2025-08-27 19:21:43.124109: val_loss -0.0261 
2025-08-27 19:21:43.128572: Pseudo dice [np.float32(0.5551)] 
2025-08-27 19:21:43.133655: Epoch time: 25.63 s 
2025-08-27 19:21:43.137446: Yayy! New best EMA pseudo Dice: 0.22100000083446503 
2025-08-27 19:21:44.051028:  
2025-08-27 19:21:44.060559: Epoch 67 
2025-08-27 19:21:44.066537: Current learning rate: 0.00939 
2025-08-27 19:22:08.955131: train_loss -0.008 
2025-08-27 19:22:08.962407: val_loss 0.0022 
2025-08-27 19:22:08.970756: Pseudo dice [np.float32(0.103)] 
2025-08-27 19:22:08.975747: Epoch time: 24.91 s 
2025-08-27 19:22:09.567014:  
2025-08-27 19:22:09.577579: Epoch 68 
2025-08-27 19:22:09.584700: Current learning rate: 0.00939 
2025-08-27 19:22:33.512286: train_loss -0.0031 
2025-08-27 19:22:33.520249: val_loss -0.0117 
2025-08-27 19:22:33.524716: Pseudo dice [np.float32(0.2559)] 
2025-08-27 19:22:33.530128: Epoch time: 23.95 s 
2025-08-27 19:22:34.169760:  
2025-08-27 19:22:34.179109: Epoch 69 
2025-08-27 19:22:34.184406: Current learning rate: 0.00938 
2025-08-27 19:22:59.867821: train_loss -0.0104 
2025-08-27 19:22:59.876083: val_loss -0.0117 
2025-08-27 19:22:59.880206: Pseudo dice [np.float32(0.3281)] 
2025-08-27 19:22:59.887296: Epoch time: 25.7 s 
2025-08-27 19:22:59.892870: Yayy! New best EMA pseudo Dice: 0.22529999911785126 
2025-08-27 19:23:00.654531:  
2025-08-27 19:23:00.660856: Epoch 70 
2025-08-27 19:23:00.667068: Current learning rate: 0.00937 
2025-08-27 19:23:25.747541: train_loss -0.0089 
2025-08-27 19:23:25.755711: val_loss 0.0036 
2025-08-27 19:23:25.760093: Pseudo dice [np.float32(0.1521)] 
2025-08-27 19:23:25.766976: Epoch time: 25.1 s 
2025-08-27 19:23:26.367669:  
2025-08-27 19:23:26.377026: Epoch 71 
2025-08-27 19:23:26.382360: Current learning rate: 0.00936 
2025-08-27 19:23:50.259368: train_loss -0.0057 
2025-08-27 19:23:50.267703: val_loss -0.0128 
2025-08-27 19:23:50.271867: Pseudo dice [np.float32(0.317)] 
2025-08-27 19:23:50.280204: Epoch time: 23.89 s 
2025-08-27 19:23:50.282866: Yayy! New best EMA pseudo Dice: 0.22789999842643738 
2025-08-27 19:23:51.061152:  
2025-08-27 19:23:51.068394: Epoch 72 
2025-08-27 19:23:51.073712: Current learning rate: 0.00935 
2025-08-27 19:24:16.732482: train_loss -0.0056 
2025-08-27 19:24:16.739990: val_loss -0.0136 
2025-08-27 19:24:16.744138: Pseudo dice [np.float32(0.2735)] 
2025-08-27 19:24:16.751155: Epoch time: 25.67 s 
2025-08-27 19:24:16.757058: Yayy! New best EMA pseudo Dice: 0.23240000009536743 
2025-08-27 19:24:17.532252:  
2025-08-27 19:24:17.539643: Epoch 73 
2025-08-27 19:24:17.544877: Current learning rate: 0.00934 
2025-08-27 19:24:41.860934: train_loss 0.0009 
2025-08-27 19:24:41.869589: val_loss -0.0141 
2025-08-27 19:24:41.877379: Pseudo dice [np.float32(0.2698)] 
2025-08-27 19:24:41.882670: Epoch time: 24.33 s 
2025-08-27 19:24:41.890049: Yayy! New best EMA pseudo Dice: 0.2362000048160553 
2025-08-27 19:24:42.690729:  
2025-08-27 19:24:42.701633: Epoch 74 
2025-08-27 19:24:42.711576: Current learning rate: 0.00933 
2025-08-27 19:25:06.139578: train_loss -0.0106 
2025-08-27 19:25:06.147722: val_loss 0.0028 
2025-08-27 19:25:06.155978: Pseudo dice [np.float32(0.0633)] 
2025-08-27 19:25:06.160699: Epoch time: 23.45 s 
2025-08-27 19:25:06.761298:  
2025-08-27 19:25:06.770086: Epoch 75 
2025-08-27 19:25:06.777383: Current learning rate: 0.00932 
2025-08-27 19:25:32.411813: train_loss -0.0091 
2025-08-27 19:25:32.419698: val_loss -0.0186 
2025-08-27 19:25:32.423885: Pseudo dice [np.float32(0.2924)] 
2025-08-27 19:25:32.431756: Epoch time: 25.65 s 
2025-08-27 19:25:33.035881:  
2025-08-27 19:25:33.044210: Epoch 76 
2025-08-27 19:25:33.050521: Current learning rate: 0.00931 
2025-08-27 19:25:57.415430: train_loss -0.0095 
2025-08-27 19:25:57.423801: val_loss -0.0142 
2025-08-27 19:25:57.427986: Pseudo dice [np.float32(0.3594)] 
2025-08-27 19:25:57.436034: Epoch time: 24.38 s 
2025-08-27 19:25:57.441143: Yayy! New best EMA pseudo Dice: 0.23960000276565552 
2025-08-27 19:25:58.232453:  
2025-08-27 19:25:58.242377: Epoch 77 
2025-08-27 19:25:58.249945: Current learning rate: 0.0093 
2025-08-27 19:26:21.848621: train_loss -0.0047 
2025-08-27 19:26:21.856526: val_loss -0.0069 
2025-08-27 19:26:21.860700: Pseudo dice [np.float32(0.3703)] 
2025-08-27 19:26:21.869413: Epoch time: 23.62 s 
2025-08-27 19:26:21.871983: Yayy! New best EMA pseudo Dice: 0.2526000142097473 
2025-08-27 19:26:22.658340:  
2025-08-27 19:26:22.667680: Epoch 78 
2025-08-27 19:26:22.673849: Current learning rate: 0.0093 
2025-08-27 19:26:48.320372: train_loss -0.0007 
2025-08-27 19:26:48.332991: val_loss -0.0024 
2025-08-27 19:26:48.337132: Pseudo dice [np.float32(0.1155)] 
2025-08-27 19:26:48.343937: Epoch time: 25.66 s 
2025-08-27 19:26:49.079396:  
2025-08-27 19:26:49.087730: Epoch 79 
2025-08-27 19:26:49.093099: Current learning rate: 0.00929 
2025-08-27 19:27:13.971070: train_loss -0.0113 
2025-08-27 19:27:13.979393: val_loss -0.005 
2025-08-27 19:27:13.983576: Pseudo dice [np.float32(0.1081)] 
2025-08-27 19:27:13.989344: Epoch time: 24.89 s 
2025-08-27 19:27:14.607075:  
2025-08-27 19:27:14.614406: Epoch 80 
2025-08-27 19:27:14.620595: Current learning rate: 0.00928 
2025-08-27 19:27:39.180206: train_loss -0.0145 
2025-08-27 19:27:39.188248: val_loss -0.0075 
2025-08-27 19:27:39.192069: Pseudo dice [np.float32(0.1745)] 
2025-08-27 19:27:39.199988: Epoch time: 24.58 s 
2025-08-27 19:27:39.864608:  
2025-08-27 19:27:39.871855: Epoch 81 
2025-08-27 19:27:39.877136: Current learning rate: 0.00927 
2025-08-27 19:28:05.448293: train_loss -0.0061 
2025-08-27 19:28:05.456090: val_loss -0.0137 
2025-08-27 19:28:05.460240: Pseudo dice [np.float32(0.1761)] 
2025-08-27 19:28:05.466638: Epoch time: 25.59 s 
2025-08-27 19:28:06.120963:  
2025-08-27 19:28:06.128334: Epoch 82 
2025-08-27 19:28:06.133496: Current learning rate: 0.00926 
2025-08-27 19:28:32.287044: train_loss -0.0065 
2025-08-27 19:28:32.295421: val_loss -0.0222 
2025-08-27 19:28:32.299592: Pseudo dice [np.float32(0.3331)] 
2025-08-27 19:28:32.305963: Epoch time: 26.17 s 
2025-08-27 19:28:32.947752:  
2025-08-27 19:28:32.958429: Epoch 83 
2025-08-27 19:28:32.965773: Current learning rate: 0.00925 
2025-08-27 19:28:58.355370: train_loss -0.0062 
2025-08-27 19:28:58.363127: val_loss -0.0118 
2025-08-27 19:28:58.367213: Pseudo dice [np.float32(0.2978)] 
2025-08-27 19:28:58.375135: Epoch time: 25.41 s 
2025-08-27 19:28:59.018596:  
2025-08-27 19:28:59.026951: Epoch 84 
2025-08-27 19:28:59.033132: Current learning rate: 0.00924 
2025-08-27 19:29:25.631649: train_loss -0.0125 
2025-08-27 19:29:25.640000: val_loss -0.0088 
2025-08-27 19:29:25.644166: Pseudo dice [np.float32(0.2981)] 
2025-08-27 19:29:25.652932: Epoch time: 26.62 s 
2025-08-27 19:29:26.307292:  
2025-08-27 19:29:26.314538: Epoch 85 
2025-08-27 19:29:26.319696: Current learning rate: 0.00923 
2025-08-27 19:29:52.141447: train_loss -0.0067 
2025-08-27 19:29:52.149816: val_loss 0.0033 
2025-08-27 19:29:52.154145: Pseudo dice [np.float32(0.1613)] 
2025-08-27 19:29:52.161053: Epoch time: 25.84 s 
2025-08-27 19:29:52.811830:  
2025-08-27 19:29:52.819191: Epoch 86 
2025-08-27 19:29:52.825695: Current learning rate: 0.00922 
2025-08-27 19:30:17.212309: train_loss -0.0093 
2025-08-27 19:30:17.220657: val_loss -0.0161 
2025-08-27 19:30:17.224776: Pseudo dice [np.float32(0.1325)] 
2025-08-27 19:30:17.230612: Epoch time: 24.4 s 
2025-08-27 19:30:17.827144:  
2025-08-27 19:30:17.834983: Epoch 87 
2025-08-27 19:30:17.840344: Current learning rate: 0.00921 
2025-08-27 19:30:43.409487: train_loss -0.0042 
2025-08-27 19:30:43.417306: val_loss -0.0003 
2025-08-27 19:30:43.422060: Pseudo dice [np.float32(0.2609)] 
2025-08-27 19:30:43.429910: Epoch time: 25.58 s 
2025-08-27 19:30:44.021281:  
2025-08-27 19:30:44.029629: Epoch 88 
2025-08-27 19:30:44.036938: Current learning rate: 0.0092 
2025-08-27 19:31:08.426215: train_loss -0.0062 
2025-08-27 19:31:08.434279: val_loss -0.0267 
2025-08-27 19:31:08.438799: Pseudo dice [np.float32(0.4088)] 
2025-08-27 19:31:08.444188: Epoch time: 24.41 s 
2025-08-27 19:31:09.045245:  
2025-08-27 19:31:09.051414: Epoch 89 
2025-08-27 19:31:09.056769: Current learning rate: 0.0092 
2025-08-27 19:31:33.246620: train_loss -0.0045 
2025-08-27 19:31:33.254991: val_loss 0.0032 
2025-08-27 19:31:33.259077: Pseudo dice [np.float32(0.0424)] 
2025-08-27 19:31:33.266101: Epoch time: 24.2 s 
2025-08-27 19:31:33.856528:  
2025-08-27 19:31:33.864861: Epoch 90 
2025-08-27 19:31:33.870038: Current learning rate: 0.00919 
2025-08-27 19:31:59.414362: train_loss -0.0097 
2025-08-27 19:31:59.422693: val_loss -0.0066 
2025-08-27 19:31:59.427165: Pseudo dice [np.float32(0.3387)] 
2025-08-27 19:31:59.433549: Epoch time: 25.56 s 
2025-08-27 19:32:00.023140:  
2025-08-27 19:32:00.030487: Epoch 91 
2025-08-27 19:32:00.035712: Current learning rate: 0.00918 
2025-08-27 19:32:24.910643: train_loss -0.0147 
2025-08-27 19:32:24.919247: val_loss -0.0167 
2025-08-27 19:32:24.927647: Pseudo dice [np.float32(0.3617)] 
2025-08-27 19:32:24.932117: Epoch time: 24.89 s 
2025-08-27 19:32:25.660238:  
2025-08-27 19:32:25.669717: Epoch 92 
2025-08-27 19:32:25.675919: Current learning rate: 0.00917 
2025-08-27 19:32:49.351695: train_loss -0.008 
2025-08-27 19:32:49.360057: val_loss -0.0316 
2025-08-27 19:32:49.368397: Pseudo dice [np.float32(0.3398)] 
2025-08-27 19:32:49.374139: Epoch time: 23.69 s 
2025-08-27 19:32:49.377551: Yayy! New best EMA pseudo Dice: 0.2578999996185303 
2025-08-27 19:32:50.142002:  
2025-08-27 19:32:50.149368: Epoch 93 
2025-08-27 19:32:50.157742: Current learning rate: 0.00916 
2025-08-27 19:33:15.640453: train_loss -0.0051 
2025-08-27 19:33:15.648886: val_loss -0.0248 
2025-08-27 19:33:15.652972: Pseudo dice [np.float32(0.3337)] 
2025-08-27 19:33:15.658671: Epoch time: 25.5 s 
2025-08-27 19:33:15.661137: Yayy! New best EMA pseudo Dice: 0.265500009059906 
2025-08-27 19:33:16.431746:  
2025-08-27 19:33:16.438096: Epoch 94 
2025-08-27 19:33:16.443277: Current learning rate: 0.00915 
2025-08-27 19:33:40.562688: train_loss -0.0097 
2025-08-27 19:33:40.569783: val_loss -0.024 
2025-08-27 19:33:40.573664: Pseudo dice [np.float32(0.4633)] 
2025-08-27 19:33:40.580709: Epoch time: 24.13 s 
2025-08-27 19:33:40.586883: Yayy! New best EMA pseudo Dice: 0.28529998660087585 
2025-08-27 19:33:41.355636:  
2025-08-27 19:33:41.364118: Epoch 95 
2025-08-27 19:33:41.369650: Current learning rate: 0.00914 
2025-08-27 19:34:04.931614: train_loss -0.0051 
2025-08-27 19:34:04.939754: val_loss -0.0133 
2025-08-27 19:34:04.943913: Pseudo dice [np.float32(0.2024)] 
2025-08-27 19:34:04.950521: Epoch time: 23.58 s 
2025-08-27 19:34:05.523423:  
2025-08-27 19:34:05.530793: Epoch 96 
2025-08-27 19:34:05.537298: Current learning rate: 0.00913 
2025-08-27 19:34:31.366123: train_loss -0.008 
2025-08-27 19:34:31.374423: val_loss -0.0196 
2025-08-27 19:34:31.378838: Pseudo dice [np.float32(0.2783)] 
2025-08-27 19:34:31.386715: Epoch time: 25.84 s 
2025-08-27 19:34:32.039548:  
2025-08-27 19:34:32.047921: Epoch 97 
2025-08-27 19:34:32.053215: Current learning rate: 0.00912 
2025-08-27 19:34:57.375348: train_loss -0.0018 
2025-08-27 19:34:57.383999: val_loss -0.0174 
2025-08-27 19:34:57.387954: Pseudo dice [np.float32(0.3211)] 
2025-08-27 19:34:57.394993: Epoch time: 25.34 s 
2025-08-27 19:34:58.035371:  
2025-08-27 19:34:58.042552: Epoch 98 
2025-08-27 19:34:58.047900: Current learning rate: 0.00911 
2025-08-27 19:35:23.439187: train_loss -0.0116 
2025-08-27 19:35:23.447385: val_loss -0.0109 
2025-08-27 19:35:23.455578: Pseudo dice [np.float32(0.1602)] 
2025-08-27 19:35:23.460299: Epoch time: 25.41 s 
2025-08-27 19:35:24.103046:  
2025-08-27 19:35:24.110249: Epoch 99 
2025-08-27 19:35:24.114412: Current learning rate: 0.0091 
2025-08-27 19:35:50.100003: train_loss -0.0104 
2025-08-27 19:35:50.107478: val_loss 0.0004 
2025-08-27 19:35:50.111316: Pseudo dice [np.float32(0.0517)] 
2025-08-27 19:35:50.119737: Epoch time: 26.0 s 
2025-08-27 19:35:50.942364:  
2025-08-27 19:35:50.949519: Epoch 100 
2025-08-27 19:35:50.954873: Current learning rate: 0.0091 
2025-08-27 19:36:16.218210: train_loss -0.0124 
2025-08-27 19:36:16.224921: val_loss -0.0209 
2025-08-27 19:36:16.229430: Pseudo dice [np.float32(0.2247)] 
2025-08-27 19:36:16.236869: Epoch time: 25.28 s 
2025-08-27 19:36:16.885021:  
2025-08-27 19:36:16.893287: Epoch 101 
2025-08-27 19:36:16.899471: Current learning rate: 0.00909 
2025-08-27 19:36:42.459427: train_loss -0.005 
2025-08-27 19:36:42.467779: val_loss 0.0039 
2025-08-27 19:36:42.476135: Pseudo dice [np.float32(0.1801)] 
2025-08-27 19:36:42.480850: Epoch time: 25.58 s 
2025-08-27 19:36:43.133979:  
2025-08-27 19:36:43.141305: Epoch 102 
2025-08-27 19:36:43.146473: Current learning rate: 0.00908 
2025-08-27 19:37:09.190259: train_loss -0.0073 
2025-08-27 19:37:09.198953: val_loss -0.0185 
2025-08-27 19:37:09.203115: Pseudo dice [np.float32(0.4209)] 
2025-08-27 19:37:09.209869: Epoch time: 26.06 s 
2025-08-27 19:37:09.872185:  
2025-08-27 19:37:09.879489: Epoch 103 
2025-08-27 19:37:09.885283: Current learning rate: 0.00907 
2025-08-27 19:37:35.320930: train_loss -0.01 
2025-08-27 19:37:35.328935: val_loss -0.0127 
2025-08-27 19:37:35.333004: Pseudo dice [np.float32(0.2867)] 
2025-08-27 19:37:35.338788: Epoch time: 25.45 s 
2025-08-27 19:37:35.980642:  
2025-08-27 19:37:35.988887: Epoch 104 
2025-08-27 19:37:35.994089: Current learning rate: 0.00906 
2025-08-27 19:38:01.242603: train_loss -0.0088 
2025-08-27 19:38:01.246770: val_loss -0.0095 
2025-08-27 19:38:01.254797: Pseudo dice [np.float32(0.2674)] 
2025-08-27 19:38:01.260483: Epoch time: 25.26 s 
2025-08-27 19:38:02.064921:  
2025-08-27 19:38:02.072091: Epoch 105 
2025-08-27 19:38:02.077949: Current learning rate: 0.00905 
2025-08-27 19:38:28.444735: train_loss -0.009 
2025-08-27 19:38:28.452764: val_loss -0.0074 
2025-08-27 19:38:28.461541: Pseudo dice [np.float32(0.165)] 
2025-08-27 19:38:28.466859: Epoch time: 26.38 s 
2025-08-27 19:38:29.124102:  
2025-08-27 19:38:29.131454: Epoch 106 
2025-08-27 19:38:29.139859: Current learning rate: 0.00904 
2025-08-27 19:38:55.040951: train_loss -0.0162 
2025-08-27 19:38:55.046276: val_loss -0.0131 
2025-08-27 19:38:55.054339: Pseudo dice [np.float32(0.2672)] 
2025-08-27 19:38:55.059078: Epoch time: 25.92 s 
2025-08-27 19:38:55.716344:  
2025-08-27 19:38:55.723645: Epoch 107 
2025-08-27 19:38:55.728800: Current learning rate: 0.00903 
2025-08-27 19:39:21.097500: train_loss -0.017 
2025-08-27 19:39:21.105385: val_loss -0.015 
2025-08-27 19:39:21.109467: Pseudo dice [np.float32(0.2974)] 
2025-08-27 19:39:21.117008: Epoch time: 25.38 s 
2025-08-27 19:39:21.750663:  
2025-08-27 19:39:21.759021: Epoch 108 
2025-08-27 19:39:21.764124: Current learning rate: 0.00902 
2025-08-27 19:39:47.323764: train_loss -0.0159 
2025-08-27 19:39:47.331498: val_loss -0.0201 
2025-08-27 19:39:47.339835: Pseudo dice [np.float32(0.2908)] 
2025-08-27 19:39:47.344575: Epoch time: 25.57 s 
2025-08-27 19:39:48.026856:  
2025-08-27 19:39:48.033226: Epoch 109 
2025-08-27 19:39:48.038373: Current learning rate: 0.00901 
2025-08-27 19:40:13.766419: train_loss -0.0125 
2025-08-27 19:40:13.774568: val_loss -0.0242 
2025-08-27 19:40:13.778927: Pseudo dice [np.float32(0.3636)] 
2025-08-27 19:40:13.784590: Epoch time: 25.74 s 
2025-08-27 19:40:14.440725:  
2025-08-27 19:40:14.448072: Epoch 110 
2025-08-27 19:40:14.453248: Current learning rate: 0.009 
2025-08-27 19:40:40.275990: train_loss -0.0155 
2025-08-27 19:40:40.284703: val_loss -0.0181 
2025-08-27 19:40:40.288826: Pseudo dice [np.float32(0.38)] 
2025-08-27 19:40:40.297357: Epoch time: 25.84 s 
2025-08-27 19:40:41.103378:  
2025-08-27 19:40:41.110360: Epoch 111 
2025-08-27 19:40:41.117604: Current learning rate: 0.009 
2025-08-27 19:41:06.585612: train_loss -0.0135 
2025-08-27 19:41:06.594304: val_loss -0.0045 
2025-08-27 19:41:06.598127: Pseudo dice [np.float32(0.1916)] 
2025-08-27 19:41:06.603842: Epoch time: 25.48 s 
2025-08-27 19:41:07.240412:  
2025-08-27 19:41:07.247589: Epoch 112 
2025-08-27 19:41:07.256022: Current learning rate: 0.00899 
2025-08-27 19:41:32.186180: train_loss -0.0081 
2025-08-27 19:41:32.194844: val_loss -0.0051 
2025-08-27 19:41:32.198986: Pseudo dice [np.float32(0.1328)] 
2025-08-27 19:41:32.204420: Epoch time: 24.95 s 
2025-08-27 19:41:32.844030:  
2025-08-27 19:41:32.853478: Epoch 113 
2025-08-27 19:41:32.858794: Current learning rate: 0.00898 
2025-08-27 19:41:57.886402: train_loss 0.0023 
2025-08-27 19:41:57.891055: val_loss -0.0196 
2025-08-27 19:41:57.899367: Pseudo dice [np.float32(0.3099)] 
2025-08-27 19:41:57.904083: Epoch time: 25.04 s 
2025-08-27 19:41:58.572701:  
2025-08-27 19:41:58.580282: Epoch 114 
2025-08-27 19:41:58.585793: Current learning rate: 0.00897 
2025-08-27 19:42:23.895835: train_loss -0.0102 
2025-08-27 19:42:23.900595: val_loss -0.0147 
2025-08-27 19:42:23.909073: Pseudo dice [np.float32(0.2555)] 
2025-08-27 19:42:23.913234: Epoch time: 25.33 s 
2025-08-27 19:42:24.573017:  
2025-08-27 19:42:24.583182: Epoch 115 
2025-08-27 19:42:24.589524: Current learning rate: 0.00896 
2025-08-27 19:42:50.043095: train_loss -0.016 
2025-08-27 19:42:50.051434: val_loss -0.0226 
2025-08-27 19:42:50.055630: Pseudo dice [np.float32(0.3651)] 
2025-08-27 19:42:50.063934: Epoch time: 25.47 s 
2025-08-27 19:42:50.761473:  
2025-08-27 19:42:50.768679: Epoch 116 
2025-08-27 19:42:50.774993: Current learning rate: 0.00895 
2025-08-27 19:43:16.161211: train_loss -0.0138 
2025-08-27 19:43:16.169151: val_loss -0.0129 
2025-08-27 19:43:16.173582: Pseudo dice [np.float32(0.2002)] 
2025-08-27 19:43:16.179058: Epoch time: 25.4 s 
2025-08-27 19:43:16.838479:  
2025-08-27 19:43:16.846881: Epoch 117 
2025-08-27 19:43:16.854171: Current learning rate: 0.00894 
2025-08-27 19:43:42.557973: train_loss -0.0054 
2025-08-27 19:43:42.566358: val_loss -0.0262 
2025-08-27 19:43:42.574710: Pseudo dice [np.float32(0.2946)] 
2025-08-27 19:43:42.579436: Epoch time: 25.72 s 
2025-08-27 19:43:43.233477:  
2025-08-27 19:43:43.241946: Epoch 118 
2025-08-27 19:43:43.247198: Current learning rate: 0.00893 
2025-08-27 19:44:08.784160: train_loss -0.0067 
2025-08-27 19:44:08.792510: val_loss -0.0151 
2025-08-27 19:44:08.800896: Pseudo dice [np.float32(0.4919)] 
2025-08-27 19:44:08.805556: Epoch time: 25.55 s 
2025-08-27 19:44:08.807579: Yayy! New best EMA pseudo Dice: 0.29109999537467957 
2025-08-27 19:44:09.667220:  
2025-08-27 19:44:09.674582: Epoch 119 
2025-08-27 19:44:09.679739: Current learning rate: 0.00892 
2025-08-27 19:44:34.910240: train_loss -0.0209 
2025-08-27 19:44:34.918920: val_loss -0.0127 
2025-08-27 19:44:34.922997: Pseudo dice [np.float32(0.293)] 
2025-08-27 19:44:34.930928: Epoch time: 25.24 s 
2025-08-27 19:44:34.936003: Yayy! New best EMA pseudo Dice: 0.2912999987602234 
2025-08-27 19:44:35.764137:  
2025-08-27 19:44:35.771452: Epoch 120 
2025-08-27 19:44:35.776624: Current learning rate: 0.00891 
2025-08-27 19:45:01.028147: train_loss -0.0075 
2025-08-27 19:45:01.036678: val_loss -0.0062 
2025-08-27 19:45:01.044712: Pseudo dice [np.float32(0.2844)] 
2025-08-27 19:45:01.050397: Epoch time: 25.27 s 
2025-08-27 19:45:01.715034:  
2025-08-27 19:45:01.722456: Epoch 121 
2025-08-27 19:45:01.728089: Current learning rate: 0.0089 
2025-08-27 19:45:26.641525: train_loss -0.0047 
2025-08-27 19:45:26.649445: val_loss -0.0206 
2025-08-27 19:45:26.653600: Pseudo dice [np.float32(0.2169)] 
2025-08-27 19:45:26.662199: Epoch time: 24.93 s 
2025-08-27 19:45:27.297888:  
2025-08-27 19:45:27.307302: Epoch 122 
2025-08-27 19:45:27.313588: Current learning rate: 0.00889 
2025-08-27 19:45:52.658924: train_loss -0.0124 
2025-08-27 19:45:52.667123: val_loss -0.0189 
2025-08-27 19:45:52.675416: Pseudo dice [np.float32(0.1995)] 
2025-08-27 19:45:52.682559: Epoch time: 25.36 s 
2025-08-27 19:45:53.327084:  
2025-08-27 19:45:53.336414: Epoch 123 
2025-08-27 19:45:53.341575: Current learning rate: 0.00889 
2025-08-27 19:46:19.018951: train_loss -0.0123 
2025-08-27 19:46:19.027020: val_loss -0.0222 
2025-08-27 19:46:19.031210: Pseudo dice [np.float32(0.282)] 
2025-08-27 19:46:19.038888: Epoch time: 25.69 s 
2025-08-27 19:46:19.684564:  
2025-08-27 19:46:19.691896: Epoch 124 
2025-08-27 19:46:19.697050: Current learning rate: 0.00888 
2025-08-27 19:46:45.398914: train_loss -0.0151 
2025-08-27 19:46:45.408406: val_loss -0.022 
2025-08-27 19:46:45.418784: Pseudo dice [np.float32(0.1929)] 
2025-08-27 19:46:45.428065: Epoch time: 25.72 s 
2025-08-27 19:46:46.074425:  
2025-08-27 19:46:46.084945: Epoch 125 
2025-08-27 19:46:46.092458: Current learning rate: 0.00887 
2025-08-27 19:47:10.198611: train_loss -0.0116 
2025-08-27 19:47:10.207266: val_loss -0.0126 
2025-08-27 19:47:10.211128: Pseudo dice [np.float32(0.1072)] 
2025-08-27 19:47:10.220254: Epoch time: 24.13 s 
2025-08-27 19:47:10.829452:  
2025-08-27 19:47:10.836586: Epoch 126 
2025-08-27 19:47:10.841933: Current learning rate: 0.00886 
2025-08-27 19:47:35.620216: train_loss -0.0064 
2025-08-27 19:47:35.628163: val_loss -0.0269 
2025-08-27 19:47:35.632363: Pseudo dice [np.float32(0.5211)] 
2025-08-27 19:47:35.640341: Epoch time: 24.79 s 
2025-08-27 19:47:36.253618:  
2025-08-27 19:47:36.261004: Epoch 127 
2025-08-27 19:47:36.269379: Current learning rate: 0.00885 
2025-08-27 19:48:01.307961: train_loss -0.012 
2025-08-27 19:48:01.316314: val_loss -0.0142 
2025-08-27 19:48:01.320513: Pseudo dice [np.float32(0.3359)] 
2025-08-27 19:48:01.326265: Epoch time: 25.06 s 
2025-08-27 19:48:01.932423:  
2025-08-27 19:48:01.939816: Epoch 128 
2025-08-27 19:48:01.944961: Current learning rate: 0.00884 
2025-08-27 19:48:25.653047: train_loss -0.0072 
2025-08-27 19:48:25.661458: val_loss -0.0125 
2025-08-27 19:48:25.665617: Pseudo dice [np.float32(0.2178)] 
2025-08-27 19:48:25.673765: Epoch time: 23.72 s 
2025-08-27 19:48:26.280808:  
2025-08-27 19:48:26.288119: Epoch 129 
2025-08-27 19:48:26.294276: Current learning rate: 0.00883 
2025-08-27 19:48:51.637470: train_loss -0.0157 
2025-08-27 19:48:51.646052: val_loss -0.0192 
2025-08-27 19:48:51.650224: Pseudo dice [np.float32(0.2927)] 
2025-08-27 19:48:51.657890: Epoch time: 25.36 s 
2025-08-27 19:48:52.283719:  
2025-08-27 19:48:52.291046: Epoch 130 
2025-08-27 19:48:52.296213: Current learning rate: 0.00882 
2025-08-27 19:49:17.388366: train_loss -0.0096 
2025-08-27 19:49:17.396459: val_loss -0.0189 
2025-08-27 19:49:17.400615: Pseudo dice [np.float32(0.3427)] 
2025-08-27 19:49:17.407250: Epoch time: 25.11 s 
2025-08-27 19:49:18.008377:  
2025-08-27 19:49:18.017902: Epoch 131 
2025-08-27 19:49:18.024074: Current learning rate: 0.00881 
2025-08-27 19:49:42.204771: train_loss -0.0094 
2025-08-27 19:49:42.208874: val_loss -0.0151 
2025-08-27 19:49:42.217054: Pseudo dice [np.float32(0.2347)] 
2025-08-27 19:49:42.222084: Epoch time: 24.2 s 
2025-08-27 19:49:42.827158:  
2025-08-27 19:49:42.835378: Epoch 132 
2025-08-27 19:49:42.843731: Current learning rate: 0.0088 
2025-08-27 19:50:08.443230: train_loss -0.0049 
2025-08-27 19:50:08.451576: val_loss -0.0201 
2025-08-27 19:50:08.459944: Pseudo dice [np.float32(0.2087)] 
2025-08-27 19:50:08.464114: Epoch time: 25.62 s 
2025-08-27 19:50:09.063553:  
2025-08-27 19:50:09.072847: Epoch 133 
2025-08-27 19:50:09.079286: Current learning rate: 0.00879 
2025-08-27 19:50:34.006220: train_loss -0.0115 
2025-08-27 19:50:34.014615: val_loss -0.0191 
2025-08-27 19:50:34.018804: Pseudo dice [np.float32(0.2608)] 
2025-08-27 19:50:34.027136: Epoch time: 24.94 s 
2025-08-27 19:50:34.625562:  
2025-08-27 19:50:34.633906: Epoch 134 
2025-08-27 19:50:34.639060: Current learning rate: 0.00879 
2025-08-27 19:50:59.031232: train_loss -0.0121 
2025-08-27 19:50:59.039594: val_loss -0.011 
2025-08-27 19:50:59.043745: Pseudo dice [np.float32(0.2483)] 
2025-08-27 19:50:59.049802: Epoch time: 24.41 s 
2025-08-27 19:50:59.660924:  
2025-08-27 19:50:59.668266: Epoch 135 
2025-08-27 19:50:59.673376: Current learning rate: 0.00878 
2025-08-27 19:51:26.066802: train_loss -0.0137 
2025-08-27 19:51:26.070726: val_loss -0.0086 
2025-08-27 19:51:26.079047: Pseudo dice [np.float32(0.1108)] 
2025-08-27 19:51:26.084152: Epoch time: 26.41 s 
2025-08-27 19:51:26.701550:  
2025-08-27 19:51:26.711078: Epoch 136 
2025-08-27 19:51:26.717120: Current learning rate: 0.00877 
2025-08-27 19:51:51.079462: train_loss -0.0085 
2025-08-27 19:51:51.087376: val_loss -0.0016 
2025-08-27 19:51:51.091532: Pseudo dice [np.float32(0.164)] 
2025-08-27 19:51:51.097440: Epoch time: 24.38 s 
2025-08-27 19:51:51.704610:  
2025-08-27 19:51:51.714082: Epoch 137 
2025-08-27 19:51:51.719187: Current learning rate: 0.00876 
2025-08-27 19:52:15.587003: train_loss -0.0146 
2025-08-27 19:52:15.591244: val_loss -0.0404 
2025-08-27 19:52:15.599343: Pseudo dice [np.float32(0.4486)] 
2025-08-27 19:52:15.604654: Epoch time: 23.88 s 
2025-08-27 19:52:16.217641:  
2025-08-27 19:52:16.224889: Epoch 138 
2025-08-27 19:52:16.230232: Current learning rate: 0.00875 
2025-08-27 19:52:42.318128: train_loss -0.007 
2025-08-27 19:52:42.326027: val_loss 0.0007 
2025-08-27 19:52:42.330186: Pseudo dice [np.float32(0.167)] 
2025-08-27 19:52:42.336143: Epoch time: 26.1 s 
2025-08-27 19:52:42.963103:  
2025-08-27 19:52:42.970380: Epoch 139 
2025-08-27 19:52:42.976582: Current learning rate: 0.00874 
2025-08-27 19:53:07.634559: train_loss -0.0076 
2025-08-27 19:53:07.642950: val_loss -0.0108 
2025-08-27 19:53:07.651288: Pseudo dice [np.float32(0.1545)] 
2025-08-27 19:53:07.656176: Epoch time: 24.67 s 
2025-08-27 19:53:08.273780:  
2025-08-27 19:53:08.282098: Epoch 140 
2025-08-27 19:53:08.288302: Current learning rate: 0.00873 
2025-08-27 19:53:32.363479: train_loss -0.0084 
2025-08-27 19:53:32.367648: val_loss -0.0197 
2025-08-27 19:53:32.375981: Pseudo dice [np.float32(0.2524)] 
2025-08-27 19:53:32.381033: Epoch time: 24.09 s 
2025-08-27 19:53:33.127750:  
2025-08-27 19:53:33.135488: Epoch 141 
2025-08-27 19:53:33.141261: Current learning rate: 0.00872 
2025-08-27 19:53:58.902480: train_loss -0.0115 
2025-08-27 19:53:58.906875: val_loss -0.0166 
2025-08-27 19:53:58.914985: Pseudo dice [np.float32(0.2181)] 
2025-08-27 19:53:58.919942: Epoch time: 25.78 s 
2025-08-27 19:53:59.535291:  
2025-08-27 19:53:59.541702: Epoch 142 
2025-08-27 19:53:59.546781: Current learning rate: 0.00871 
2025-08-27 19:54:24.682985: train_loss -0.0155 
2025-08-27 19:54:24.690727: val_loss -0.0069 
2025-08-27 19:54:24.694884: Pseudo dice [np.float32(0.1707)] 
2025-08-27 19:54:24.701551: Epoch time: 25.15 s 
2025-08-27 19:54:25.312003:  
2025-08-27 19:54:25.318403: Epoch 143 
2025-08-27 19:54:25.323505: Current learning rate: 0.0087 
2025-08-27 19:54:49.006675: train_loss -0.0048 
2025-08-27 19:54:49.015449: val_loss -0.0008 
2025-08-27 19:54:49.021284: Pseudo dice [np.float32(0.0636)] 
2025-08-27 19:54:49.028464: Epoch time: 23.7 s 
2025-08-27 19:54:49.757859:  
2025-08-27 19:54:49.766947: Epoch 144 
2025-08-27 19:54:49.774048: Current learning rate: 0.00869 
2025-08-27 19:55:15.792163: train_loss -0.0146 
2025-08-27 19:55:15.804251: val_loss -0.0124 
2025-08-27 19:55:15.809072: Pseudo dice [np.float32(0.229)] 
2025-08-27 19:55:15.815792: Epoch time: 26.04 s 
2025-08-27 19:55:16.499650:  
2025-08-27 19:55:16.508648: Epoch 145 
2025-08-27 19:55:16.515649: Current learning rate: 0.00868 
2025-08-27 19:55:42.089511: train_loss -0.0077 
2025-08-27 19:55:42.097571: val_loss -0.0166 
2025-08-27 19:55:42.101384: Pseudo dice [np.float32(0.2855)] 
2025-08-27 19:55:42.109372: Epoch time: 25.59 s 
2025-08-27 19:55:42.760195:  
2025-08-27 19:55:42.768554: Epoch 146 
2025-08-27 19:55:42.774875: Current learning rate: 0.00868 
2025-08-27 19:56:07.856247: train_loss -0.011 
2025-08-27 19:56:07.864543: val_loss -0.0213 
2025-08-27 19:56:07.873209: Pseudo dice [np.float32(0.3426)] 
2025-08-27 19:56:07.878235: Epoch time: 25.1 s 
2025-08-27 19:56:08.560385:  
2025-08-27 19:56:08.566110: Epoch 147 
2025-08-27 19:56:08.574516: Current learning rate: 0.00867 
2025-08-27 19:56:34.598497: train_loss -0.0164 
2025-08-27 19:56:34.607846: val_loss -0.0114 
2025-08-27 19:56:34.614092: Pseudo dice [np.float32(0.3421)] 
2025-08-27 19:56:34.619653: Epoch time: 26.04 s 
2025-08-27 19:56:35.286119:  
2025-08-27 19:56:35.294120: Epoch 148 
2025-08-27 19:56:35.299119: Current learning rate: 0.00866 
2025-08-27 19:57:00.811482: train_loss -0.0108 
2025-08-27 19:57:00.821947: val_loss -0.0009 
2025-08-27 19:57:00.828455: Pseudo dice [np.float32(0.1478)] 
2025-08-27 19:57:00.834456: Epoch time: 25.53 s 
2025-08-27 19:57:01.515989:  
2025-08-27 19:57:01.525991: Epoch 149 
2025-08-27 19:57:01.534991: Current learning rate: 0.00865 
2025-08-27 19:57:26.704987: train_loss -0.018 
2025-08-27 19:57:26.712981: val_loss -0.0107 
2025-08-27 19:57:26.718679: Pseudo dice [np.float32(0.2548)] 
2025-08-27 19:57:26.724088: Epoch time: 25.19 s 
2025-08-27 19:57:27.583321:  
2025-08-27 19:57:27.591005: Epoch 150 
2025-08-27 19:57:27.597004: Current learning rate: 0.00864 
2025-08-27 19:57:53.240643: train_loss -0.0121 
2025-08-27 19:57:53.248976: val_loss -0.0009 
2025-08-27 19:57:53.253020: Pseudo dice [np.float32(0.2614)] 
2025-08-27 19:57:53.259166: Epoch time: 25.66 s 
2025-08-27 19:57:53.932833:  
2025-08-27 19:57:53.941129: Epoch 151 
2025-08-27 19:57:53.947569: Current learning rate: 0.00863 
2025-08-27 19:58:19.174840: train_loss -0.0175 
2025-08-27 19:58:19.179020: val_loss -0.011 
2025-08-27 19:58:19.187201: Pseudo dice [np.float32(0.2919)] 
2025-08-27 19:58:19.192210: Epoch time: 25.24 s 
2025-08-27 19:58:19.862843:  
2025-08-27 19:58:19.872448: Epoch 152 
2025-08-27 19:58:19.879528: Current learning rate: 0.00862 
2025-08-27 19:58:45.171616: train_loss -0.0136 
2025-08-27 19:58:45.179924: val_loss -0.0084 
2025-08-27 19:58:45.188313: Pseudo dice [np.float32(0.1874)] 
2025-08-27 19:58:45.194506: Epoch time: 25.31 s 
2025-08-27 19:58:46.044311:  
2025-08-27 19:58:46.051473: Epoch 153 
2025-08-27 19:58:46.059967: Current learning rate: 0.00861 
2025-08-27 19:59:12.231940: train_loss -0.0112 
2025-08-27 19:59:12.240226: val_loss -0.0244 
2025-08-27 19:59:12.248882: Pseudo dice [np.float32(0.3489)] 
2025-08-27 19:59:12.253636: Epoch time: 26.19 s 
2025-08-27 19:59:12.941724:  
2025-08-27 19:59:12.949722: Epoch 154 
2025-08-27 19:59:12.955722: Current learning rate: 0.0086 
2025-08-27 19:59:38.620517: train_loss -0.0108 
2025-08-27 19:59:38.625125: val_loss -0.0297 
2025-08-27 19:59:38.633295: Pseudo dice [np.float32(0.4018)] 
2025-08-27 19:59:38.638384: Epoch time: 25.68 s 
2025-08-27 19:59:39.305857:  
2025-08-27 19:59:39.312987: Epoch 155 
2025-08-27 19:59:39.318394: Current learning rate: 0.00859 
2025-08-27 20:00:04.818806: train_loss -0.0058 
2025-08-27 20:00:04.827121: val_loss -0.0107 
2025-08-27 20:00:04.832293: Pseudo dice [np.float32(0.3198)] 
2025-08-27 20:00:04.839368: Epoch time: 25.52 s 
2025-08-27 20:00:05.566364:  
2025-08-27 20:00:05.574696: Epoch 156 
2025-08-27 20:00:05.581021: Current learning rate: 0.00858 
2025-08-27 20:00:31.844763: train_loss -0.0167 
2025-08-27 20:00:31.853145: val_loss -0.0223 
2025-08-27 20:00:31.857532: Pseudo dice [np.float32(0.4398)] 
2025-08-27 20:00:31.864543: Epoch time: 26.28 s 
2025-08-27 20:00:32.562019:  
2025-08-27 20:00:32.569397: Epoch 157 
2025-08-27 20:00:32.574501: Current learning rate: 0.00858 
2025-08-27 20:00:58.458812: train_loss -0.0094 
2025-08-27 20:00:58.467171: val_loss 0.0029 
2025-08-27 20:00:58.475528: Pseudo dice [np.float32(0.1186)] 
2025-08-27 20:00:58.480925: Epoch time: 25.9 s 
2025-08-27 20:00:59.168860:  
2025-08-27 20:00:59.178645: Epoch 158 
2025-08-27 20:00:59.185000: Current learning rate: 0.00857 
2025-08-27 20:01:24.752325: train_loss -0.0168 
2025-08-27 20:01:24.760091: val_loss -0.0056 
2025-08-27 20:01:24.764242: Pseudo dice [np.float32(0.1128)] 
2025-08-27 20:01:24.773810: Epoch time: 25.59 s 
2025-08-27 20:01:25.409585:  
2025-08-27 20:01:25.417915: Epoch 159 
2025-08-27 20:01:25.424246: Current learning rate: 0.00856 
2025-08-27 20:01:50.861999: train_loss -0.0118 
2025-08-27 20:01:50.870483: val_loss -0.0084 
2025-08-27 20:01:50.877630: Pseudo dice [np.float32(0.2176)] 
2025-08-27 20:01:50.883127: Epoch time: 25.45 s 
2025-08-27 20:01:51.528356:  
2025-08-27 20:01:51.537813: Epoch 160 
2025-08-27 20:01:51.546307: Current learning rate: 0.00855 
2025-08-27 20:02:16.540924: train_loss -0.0096 
2025-08-27 20:02:16.549258: val_loss -0.0159 
2025-08-27 20:02:16.557475: Pseudo dice [np.float32(0.3173)] 
2025-08-27 20:02:16.562580: Epoch time: 25.01 s 
2025-08-27 20:02:17.195589:  
2025-08-27 20:02:17.202961: Epoch 161 
2025-08-27 20:02:17.208091: Current learning rate: 0.00854 
2025-08-27 20:02:41.733055: train_loss -0.0151 
2025-08-27 20:02:41.742172: val_loss -0.0323 
2025-08-27 20:02:41.749417: Pseudo dice [np.float32(0.3469)] 
2025-08-27 20:02:41.756563: Epoch time: 24.54 s 
2025-08-27 20:02:42.401067:  
2025-08-27 20:02:42.409420: Epoch 162 
2025-08-27 20:02:42.415612: Current learning rate: 0.00853 
2025-08-27 20:03:07.917244: train_loss -0.0087 
2025-08-27 20:03:07.925563: val_loss -0.0074 
2025-08-27 20:03:07.933725: Pseudo dice [np.float32(0.2561)] 
2025-08-27 20:03:07.939265: Epoch time: 25.52 s 
2025-08-27 20:03:08.562534:  
2025-08-27 20:03:08.569870: Epoch 163 
2025-08-27 20:03:08.575026: Current learning rate: 0.00852 
2025-08-27 20:03:33.663771: train_loss -0.0107 
2025-08-27 20:03:33.672096: val_loss -0.0164 
2025-08-27 20:03:33.676260: Pseudo dice [np.float32(0.261)] 
2025-08-27 20:03:33.684389: Epoch time: 25.1 s 
2025-08-27 20:03:34.359173:  
2025-08-27 20:03:34.367534: Epoch 164 
2025-08-27 20:03:34.374888: Current learning rate: 0.00851 
2025-08-27 20:03:59.156121: train_loss -0.0051 
2025-08-27 20:03:59.164722: val_loss -0.0113 
2025-08-27 20:03:59.168648: Pseudo dice [np.float32(0.2832)] 
2025-08-27 20:03:59.175404: Epoch time: 24.8 s 
2025-08-27 20:03:59.940988:  
2025-08-27 20:03:59.948195: Epoch 165 
2025-08-27 20:03:59.953196: Current learning rate: 0.0085 
2025-08-27 20:04:25.189087: train_loss -0.0108 
2025-08-27 20:04:25.198879: val_loss -0.0039 
2025-08-27 20:04:25.205879: Pseudo dice [np.float32(0.167)] 
2025-08-27 20:04:25.212917: Epoch time: 25.25 s 
2025-08-27 20:04:25.837702:  
2025-08-27 20:04:25.846034: Epoch 166 
2025-08-27 20:04:25.852216: Current learning rate: 0.00849 
2025-08-27 20:04:51.555620: train_loss -0.0094 
2025-08-27 20:04:51.564643: val_loss -0.0235 
2025-08-27 20:04:51.571697: Pseudo dice [np.float32(0.4152)] 
2025-08-27 20:04:51.577695: Epoch time: 25.72 s 
2025-08-27 20:04:52.301451:  
2025-08-27 20:04:52.313993: Epoch 167 
2025-08-27 20:04:52.323993: Current learning rate: 0.00848 
2025-08-27 20:05:17.918635: train_loss -0.0032 
2025-08-27 20:05:17.928169: val_loss -0.0209 
2025-08-27 20:05:17.934170: Pseudo dice [np.float32(0.4919)] 
2025-08-27 20:05:17.939170: Epoch time: 25.62 s 
2025-08-27 20:05:17.944862: Yayy! New best EMA pseudo Dice: 0.29510000348091125 
2025-08-27 20:05:18.901663:  
2025-08-27 20:05:18.909663: Epoch 168 
2025-08-27 20:05:18.916664: Current learning rate: 0.00847 
2025-08-27 20:05:44.239608: train_loss -0.0179 
2025-08-27 20:05:44.248611: val_loss -0.0055 
2025-08-27 20:05:44.252463: Pseudo dice [np.float32(0.1283)] 
2025-08-27 20:05:44.259190: Epoch time: 25.34 s 
2025-08-27 20:05:44.950985:  
2025-08-27 20:05:44.958379: Epoch 169 
2025-08-27 20:05:44.964546: Current learning rate: 0.00847 
2025-08-27 20:06:10.596071: train_loss -0.0076 
2025-08-27 20:06:10.605688: val_loss -0.0033 
2025-08-27 20:06:10.626404: Pseudo dice [np.float32(0.3748)] 
2025-08-27 20:06:10.638113: Epoch time: 25.65 s 
2025-08-27 20:06:11.450312:  
2025-08-27 20:06:11.458654: Epoch 170 
2025-08-27 20:06:11.467654: Current learning rate: 0.00846 
2025-08-27 20:06:37.247352: train_loss -0.0063 
2025-08-27 20:06:37.255694: val_loss 0.0063 
2025-08-27 20:06:37.264103: Pseudo dice [np.float32(0.0413)] 
2025-08-27 20:06:37.269500: Epoch time: 25.8 s 
2025-08-27 20:06:38.159295:  
2025-08-27 20:06:38.170865: Epoch 171 
2025-08-27 20:06:38.179168: Current learning rate: 0.00845 
2025-08-27 20:07:04.794800: train_loss -0.0098 
2025-08-27 20:07:04.804332: val_loss -0.0032 
2025-08-27 20:07:04.813396: Pseudo dice [np.float32(0.2963)] 
2025-08-27 20:07:04.824528: Epoch time: 26.64 s 
2025-08-27 20:07:05.646216:  
2025-08-27 20:07:05.655593: Epoch 172 
2025-08-27 20:07:05.661744: Current learning rate: 0.00844 
2025-08-27 20:07:31.280160: train_loss -0.0058 
2025-08-27 20:07:31.288473: val_loss -0.0064 
2025-08-27 20:07:31.292634: Pseudo dice [np.float32(0.2052)] 
2025-08-27 20:07:31.299614: Epoch time: 25.64 s 
2025-08-27 20:07:31.922293:  
2025-08-27 20:07:31.929606: Epoch 173 
2025-08-27 20:07:31.934866: Current learning rate: 0.00843 
2025-08-27 20:07:57.181041: train_loss -0.0081 
2025-08-27 20:07:57.189611: val_loss -0.02 
2025-08-27 20:07:57.193533: Pseudo dice [np.float32(0.1921)] 
2025-08-27 20:07:57.202233: Epoch time: 25.26 s 
2025-08-27 20:07:57.873250:  
2025-08-27 20:07:57.883379: Epoch 174 
2025-08-27 20:07:57.892205: Current learning rate: 0.00842 
2025-08-27 20:08:23.200143: train_loss -0.0087 
2025-08-27 20:08:23.208967: val_loss -0.0127 
2025-08-27 20:08:23.215301: Pseudo dice [np.float32(0.2918)] 
2025-08-27 20:08:23.220016: Epoch time: 25.33 s 
2025-08-27 20:08:24.057712:  
2025-08-27 20:08:24.066157: Epoch 175 
2025-08-27 20:08:24.072355: Current learning rate: 0.00841 
2025-08-27 20:08:49.192738: train_loss -0.0121 
2025-08-27 20:08:49.203729: val_loss -0.0005 
2025-08-27 20:08:49.209441: Pseudo dice [np.float32(0.0849)] 
2025-08-27 20:08:49.215442: Epoch time: 25.14 s 
2025-08-27 20:08:49.889765:  
2025-08-27 20:08:49.899207: Epoch 176 
2025-08-27 20:08:49.905470: Current learning rate: 0.0084 
2025-08-27 20:09:15.063434: train_loss -0.0073 
2025-08-27 20:09:15.071528: val_loss -0.0093 
2025-08-27 20:09:15.080295: Pseudo dice [np.float32(0.2771)] 
2025-08-27 20:09:15.085313: Epoch time: 25.18 s 
2025-08-27 20:09:15.739664:  
2025-08-27 20:09:15.747903: Epoch 177 
2025-08-27 20:09:15.754094: Current learning rate: 0.00839 
2025-08-27 20:09:40.872318: train_loss -0.0168 
2025-08-27 20:09:40.880720: val_loss -0.0422 
2025-08-27 20:09:40.888492: Pseudo dice [np.float32(0.3195)] 
2025-08-27 20:09:40.893408: Epoch time: 25.13 s 
2025-08-27 20:09:41.542367:  
2025-08-27 20:09:41.553862: Epoch 178 
2025-08-27 20:09:41.559863: Current learning rate: 0.00838 
2025-08-27 20:10:06.397525: train_loss -0.0142 
2025-08-27 20:10:06.405813: val_loss -0.0056 
2025-08-27 20:10:06.409975: Pseudo dice [np.float32(0.2232)] 
2025-08-27 20:10:06.416711: Epoch time: 24.86 s 
2025-08-27 20:10:07.047945:  
2025-08-27 20:10:07.057523: Epoch 179 
2025-08-27 20:10:07.064669: Current learning rate: 0.00837 
2025-08-27 20:10:31.847929: train_loss -0.0096 
2025-08-27 20:10:31.856157: val_loss -0.0193 
2025-08-27 20:10:31.860489: Pseudo dice [np.float32(0.2437)] 
2025-08-27 20:10:31.868284: Epoch time: 24.8 s 
2025-08-27 20:10:32.497376:  
2025-08-27 20:10:32.506722: Epoch 180 
2025-08-27 20:10:32.513165: Current learning rate: 0.00836 
2025-08-27 20:10:57.306953: train_loss -0.0165 
2025-08-27 20:10:57.315287: val_loss -0.0177 
2025-08-27 20:10:57.319490: Pseudo dice [np.float32(0.3819)] 
2025-08-27 20:10:57.327456: Epoch time: 24.81 s 
2025-08-27 20:10:57.970806:  
2025-08-27 20:10:57.978986: Epoch 181 
2025-08-27 20:10:57.985983: Current learning rate: 0.00836 
2025-08-27 20:11:21.243379: train_loss -0.0159 
2025-08-27 20:11:21.251490: val_loss -0.0229 
2025-08-27 20:11:21.255548: Pseudo dice [np.float32(0.2852)] 
2025-08-27 20:11:21.264640: Epoch time: 23.27 s 
2025-08-27 20:11:21.891510:  
2025-08-27 20:11:21.898858: Epoch 182 
2025-08-27 20:11:21.905014: Current learning rate: 0.00835 
2025-08-27 20:11:47.040055: train_loss -0.0086 
2025-08-27 20:11:47.052098: val_loss -0.025 
2025-08-27 20:11:47.056453: Pseudo dice [np.float32(0.2814)] 
2025-08-27 20:11:47.063583: Epoch time: 25.15 s 
2025-08-27 20:11:47.840244:  
2025-08-27 20:11:47.850757: Epoch 183 
2025-08-27 20:11:47.857235: Current learning rate: 0.00834 
2025-08-27 20:12:13.002994: train_loss -0.0124 
2025-08-27 20:12:13.011677: val_loss 0.0018 
2025-08-27 20:12:13.015519: Pseudo dice [np.float32(0.107)] 
2025-08-27 20:12:13.022210: Epoch time: 25.16 s 
2025-08-27 20:12:13.654798:  
2025-08-27 20:12:13.663080: Epoch 184 
2025-08-27 20:12:13.670208: Current learning rate: 0.00833 
2025-08-27 20:12:38.699552: train_loss -0.0131 
2025-08-27 20:12:38.707829: val_loss -0.0346 
2025-08-27 20:12:38.711985: Pseudo dice [np.float32(0.3811)] 
2025-08-27 20:12:38.718742: Epoch time: 25.05 s 
2025-08-27 20:12:39.364686:  
2025-08-27 20:12:39.374026: Epoch 185 
2025-08-27 20:12:39.381515: Current learning rate: 0.00832 
2025-08-27 20:13:03.979072: train_loss -0.0102 
2025-08-27 20:13:03.987232: val_loss -0.0426 
2025-08-27 20:13:03.991405: Pseudo dice [np.float32(0.2935)] 
2025-08-27 20:13:03.998279: Epoch time: 24.62 s 
2025-08-27 20:13:04.631536:  
2025-08-27 20:13:04.639943: Epoch 186 
2025-08-27 20:13:04.646065: Current learning rate: 0.00831 
2025-08-27 20:13:30.188401: train_loss -0.0165 
2025-08-27 20:13:30.196733: val_loss -0.0127 
2025-08-27 20:13:30.200898: Pseudo dice [np.float32(0.2325)] 
2025-08-27 20:13:30.208113: Epoch time: 25.56 s 
2025-08-27 20:13:30.853570:  
2025-08-27 20:13:30.862944: Epoch 187 
2025-08-27 20:13:30.873396: Current learning rate: 0.0083 
2025-08-27 20:13:56.522998: train_loss -0.0143 
2025-08-27 20:13:56.531338: val_loss 1e-04 
2025-08-27 20:13:56.535501: Pseudo dice [np.float32(0.0833)] 
2025-08-27 20:13:56.541878: Epoch time: 25.67 s 
2025-08-27 20:13:57.174686:  
2025-08-27 20:13:57.183031: Epoch 188 
2025-08-27 20:13:57.189191: Current learning rate: 0.00829 
2025-08-27 20:14:21.861205: train_loss -0.015 
2025-08-27 20:14:21.871142: val_loss -0.0069 
2025-08-27 20:14:21.877156: Pseudo dice [np.float32(0.2052)] 
2025-08-27 20:14:21.881356: Epoch time: 24.69 s 
2025-08-27 20:14:22.574339:  
2025-08-27 20:14:22.582729: Epoch 189 
2025-08-27 20:14:22.590676: Current learning rate: 0.00828 
2025-08-27 20:14:45.192570: train_loss -0.01 
2025-08-27 20:14:45.200948: val_loss -0.0128 
2025-08-27 20:14:45.208977: Pseudo dice [np.float32(0.2988)] 
2025-08-27 20:14:45.213054: Epoch time: 22.62 s 
2025-08-27 20:14:45.844327:  
2025-08-27 20:14:45.852905: Epoch 190 
2025-08-27 20:14:45.857316: Current learning rate: 0.00827 
2025-08-27 20:15:08.332237: train_loss -0.0163 
2025-08-27 20:15:08.338649: val_loss -0.0266 
2025-08-27 20:15:08.343044: Pseudo dice [np.float32(0.3333)] 
2025-08-27 20:15:08.347117: Epoch time: 22.49 s 
2025-08-27 20:15:08.999485:  
2025-08-27 20:15:09.007676: Epoch 191 
2025-08-27 20:15:09.012939: Current learning rate: 0.00826 
2025-08-27 20:15:31.918063: train_loss -0.0086 
2025-08-27 20:15:31.922316: val_loss -0.0323 
2025-08-27 20:15:31.931068: Pseudo dice [np.float32(0.4447)] 
2025-08-27 20:15:31.936365: Epoch time: 22.92 s 
2025-08-27 20:15:32.584367:  
2025-08-27 20:15:32.591256: Epoch 192 
2025-08-27 20:15:32.597310: Current learning rate: 0.00825 
2025-08-27 20:15:55.692784: train_loss -0.0086 
2025-08-27 20:15:55.705184: val_loss -0.0159 
2025-08-27 20:15:55.709570: Pseudo dice [np.float32(0.1763)] 
2025-08-27 20:15:55.717797: Epoch time: 23.11 s 
2025-08-27 20:15:56.388859:  
2025-08-27 20:15:56.397911: Epoch 193 
2025-08-27 20:15:56.401883: Current learning rate: 0.00824 
2025-08-27 20:16:19.190672: train_loss -0.0111 
2025-08-27 20:16:19.198916: val_loss -0.0339 
2025-08-27 20:16:19.203387: Pseudo dice [np.float32(0.3628)] 
2025-08-27 20:16:19.207621: Epoch time: 22.8 s 
2025-08-27 20:16:19.843947:  
2025-08-27 20:16:19.848404: Epoch 194 
2025-08-27 20:16:19.856602: Current learning rate: 0.00824 
2025-08-27 20:16:42.652827: train_loss -0.019 
2025-08-27 20:16:42.661514: val_loss -0.0192 
2025-08-27 20:16:42.668461: Pseudo dice [np.float32(0.4721)] 
2025-08-27 20:16:42.672616: Epoch time: 22.81 s 
2025-08-27 20:16:43.513733:  
2025-08-27 20:16:43.520914: Epoch 195 
2025-08-27 20:16:43.528497: Current learning rate: 0.00823 
2025-08-27 20:17:06.187303: train_loss -0.0087 
2025-08-27 20:17:06.195754: val_loss -0.0192 
2025-08-27 20:17:06.200918: Pseudo dice [np.float32(0.2465)] 
2025-08-27 20:17:06.203917: Epoch time: 22.67 s 
2025-08-27 20:17:06.861145:  
2025-08-27 20:17:06.869215: Epoch 196 
2025-08-27 20:17:06.873377: Current learning rate: 0.00822 
2025-08-27 20:17:29.941557: train_loss -0.0136 
2025-08-27 20:17:29.949696: val_loss -0.0406 
2025-08-27 20:17:29.953824: Pseudo dice [np.float32(0.3448)] 
2025-08-27 20:17:29.957887: Epoch time: 23.08 s 
2025-08-27 20:17:30.588474:  
2025-08-27 20:17:30.596560: Epoch 197 
2025-08-27 20:17:30.600770: Current learning rate: 0.00821 
2025-08-27 20:17:53.193636: train_loss -0.0054 
2025-08-27 20:17:53.200768: val_loss -0.0156 
2025-08-27 20:17:53.204803: Pseudo dice [np.float32(0.3849)] 
2025-08-27 20:17:53.212854: Epoch time: 22.61 s 
2025-08-27 20:17:53.216884: Yayy! New best EMA pseudo Dice: 0.30379998683929443 
2025-08-27 20:17:54.027495:  
2025-08-27 20:17:54.035621: Epoch 198 
2025-08-27 20:17:54.039675: Current learning rate: 0.0082 
2025-08-27 20:18:16.526197: train_loss -0.0157 
2025-08-27 20:18:16.534220: val_loss -0.0101 
2025-08-27 20:18:16.542376: Pseudo dice [np.float32(0.1176)] 
2025-08-27 20:18:16.546799: Epoch time: 22.5 s 
2025-08-27 20:18:17.203973:  
2025-08-27 20:18:17.208344: Epoch 199 
2025-08-27 20:18:17.217169: Current learning rate: 0.00819 
2025-08-27 20:18:39.692077: train_loss -0.0185 
2025-08-27 20:18:39.700135: val_loss -0.0299 
2025-08-27 20:18:39.704211: Pseudo dice [np.float32(0.365)] 
2025-08-27 20:18:39.712727: Epoch time: 22.49 s 
2025-08-27 20:18:40.552341:  
2025-08-27 20:18:40.560493: Epoch 200 
2025-08-27 20:18:40.564565: Current learning rate: 0.00818 
2025-08-27 20:19:02.716217: train_loss -0.0101 
2025-08-27 20:19:02.728251: val_loss -0.0245 
2025-08-27 20:19:02.732267: Pseudo dice [np.float32(0.2688)] 
2025-08-27 20:19:02.736277: Epoch time: 22.16 s 
2025-08-27 20:19:03.531392:  
2025-08-27 20:19:03.539585: Epoch 201 
2025-08-27 20:19:03.543761: Current learning rate: 0.00817 
2025-08-27 20:19:25.619471: train_loss -0.0148 
2025-08-27 20:19:25.625481: val_loss -0.0037 
2025-08-27 20:19:25.634004: Pseudo dice [np.float32(0.0701)] 
2025-08-27 20:19:25.638011: Epoch time: 22.09 s 
2025-08-27 20:19:26.269000:  
2025-08-27 20:19:26.277081: Epoch 202 
2025-08-27 20:19:26.281094: Current learning rate: 0.00816 
2025-08-27 20:19:48.545296: train_loss -0.0127 
2025-08-27 20:19:48.553329: val_loss -0.0166 
2025-08-27 20:19:48.561374: Pseudo dice [np.float32(0.3494)] 
2025-08-27 20:19:48.565399: Epoch time: 22.28 s 
2025-08-27 20:19:49.293972:  
2025-08-27 20:19:49.300002: Epoch 203 
2025-08-27 20:19:49.308016: Current learning rate: 0.00815 
2025-08-27 20:20:11.437463: train_loss -0.0101 
2025-08-27 20:20:11.443521: val_loss -0.0105 
2025-08-27 20:20:11.451535: Pseudo dice [np.float32(0.2087)] 
2025-08-27 20:20:11.456057: Epoch time: 22.15 s 
2025-08-27 20:20:12.094919:  
2025-08-27 20:20:12.101379: Epoch 204 
2025-08-27 20:20:12.107393: Current learning rate: 0.00814 
2025-08-27 20:20:34.145292: train_loss -0.0165 
2025-08-27 20:20:34.153495: val_loss -0.0133 
2025-08-27 20:20:34.157749: Pseudo dice [np.float32(0.2071)] 
2025-08-27 20:20:34.161887: Epoch time: 22.05 s 
2025-08-27 20:20:34.839491:  
2025-08-27 20:20:34.848043: Epoch 205 
2025-08-27 20:20:34.856452: Current learning rate: 0.00813 
2025-08-27 20:20:56.996365: train_loss -0.0107 
2025-08-27 20:20:57.002403: val_loss -0.027 
2025-08-27 20:20:57.010432: Pseudo dice [np.float32(0.3555)] 
2025-08-27 20:20:57.014560: Epoch time: 22.16 s 
2025-08-27 20:20:57.703487:  
2025-08-27 20:20:57.709672: Epoch 206 
2025-08-27 20:20:57.713762: Current learning rate: 0.00813 
2025-08-27 20:21:20.119328: train_loss -0.0166 
2025-08-27 20:21:20.124205: val_loss -0.0073 
2025-08-27 20:21:20.132530: Pseudo dice [np.float32(0.163)] 
2025-08-27 20:21:20.138374: Epoch time: 22.42 s 
2025-08-27 20:21:20.792528:  
2025-08-27 20:21:20.800855: Epoch 207 
2025-08-27 20:21:20.807040: Current learning rate: 0.00812 
2025-08-27 20:21:45.689148: train_loss -0.0119 
2025-08-27 20:21:45.700575: val_loss -0.0294 
2025-08-27 20:21:45.704849: Pseudo dice [np.float32(0.4317)] 
2025-08-27 20:21:45.712279: Epoch time: 24.9 s 
2025-08-27 20:21:46.341877:  
2025-08-27 20:21:46.350199: Epoch 208 
2025-08-27 20:21:46.356559: Current learning rate: 0.00811 
2025-08-27 20:22:12.489213: train_loss -0.0144 
2025-08-27 20:22:12.497586: val_loss -0.0273 
2025-08-27 20:22:12.505965: Pseudo dice [np.float32(0.2928)] 
2025-08-27 20:22:12.512030: Epoch time: 26.15 s 
2025-08-27 20:22:13.153492:  
2025-08-27 20:22:13.160724: Epoch 209 
2025-08-27 20:22:13.169413: Current learning rate: 0.0081 
2025-08-27 20:22:37.864726: train_loss -0.0175 
2025-08-27 20:22:37.872628: val_loss -0.0158 
2025-08-27 20:22:37.876797: Pseudo dice [np.float32(0.3507)] 
2025-08-27 20:22:37.884620: Epoch time: 24.71 s 
2025-08-27 20:22:38.507884:  
2025-08-27 20:22:38.514831: Epoch 210 
2025-08-27 20:22:38.520215: Current learning rate: 0.00809 
2025-08-27 20:23:02.572276: train_loss -0.0017 
2025-08-27 20:23:02.580620: val_loss -0.0019 
2025-08-27 20:23:02.589333: Pseudo dice [np.float32(0.1409)] 
2025-08-27 20:23:02.594800: Epoch time: 24.07 s 
2025-08-27 20:23:03.217593:  
2025-08-27 20:23:03.225985: Epoch 211 
2025-08-27 20:23:03.233327: Current learning rate: 0.00808 
2025-08-27 20:23:28.723357: train_loss -0.014 
2025-08-27 20:23:28.731819: val_loss -0.0032 
2025-08-27 20:23:28.740102: Pseudo dice [np.float32(0.3078)] 
2025-08-27 20:23:28.744964: Epoch time: 25.51 s 
2025-08-27 20:23:29.363548:  
2025-08-27 20:23:29.370862: Epoch 212 
2025-08-27 20:23:29.376061: Current learning rate: 0.00807 
2025-08-27 20:23:53.777542: train_loss -0.0095 
2025-08-27 20:23:53.785989: val_loss -0.0146 
2025-08-27 20:23:53.790160: Pseudo dice [np.float32(0.3589)] 
2025-08-27 20:23:53.797909: Epoch time: 24.41 s 
2025-08-27 20:23:54.416703:  
2025-08-27 20:23:54.425058: Epoch 213 
2025-08-27 20:23:54.430211: Current learning rate: 0.00806 
2025-08-27 20:24:18.573142: train_loss -0.0137 
2025-08-27 20:24:18.581801: val_loss -0.0206 
2025-08-27 20:24:18.586021: Pseudo dice [np.float32(0.2693)] 
2025-08-27 20:24:18.594028: Epoch time: 24.16 s 
2025-08-27 20:24:19.370820:  
2025-08-27 20:24:19.379222: Epoch 214 
2025-08-27 20:24:19.385279: Current learning rate: 0.00805 
2025-08-27 20:24:44.578264: train_loss -0.0109 
2025-08-27 20:24:44.586627: val_loss -0.0276 
2025-08-27 20:24:44.590788: Pseudo dice [np.float32(0.3216)] 
2025-08-27 20:24:44.598586: Epoch time: 25.21 s 
2025-08-27 20:24:45.215279:  
2025-08-27 20:24:45.227802: Epoch 215 
2025-08-27 20:24:45.234145: Current learning rate: 0.00804 
2025-08-27 20:25:10.237901: train_loss -0.0164 
2025-08-27 20:25:10.245565: val_loss -0.008 
2025-08-27 20:25:10.249994: Pseudo dice [np.float32(0.1589)] 
2025-08-27 20:25:10.258913: Epoch time: 25.02 s 
2025-08-27 20:25:10.881557:  
2025-08-27 20:25:10.889891: Epoch 216 
2025-08-27 20:25:10.896049: Current learning rate: 0.00803 
2025-08-27 20:25:35.374847: train_loss -0.0102 
2025-08-27 20:25:35.383553: val_loss 0.0015 
2025-08-27 20:25:35.391528: Pseudo dice [np.float32(0.0339)] 
2025-08-27 20:25:35.395715: Epoch time: 24.49 s 
2025-08-27 20:25:36.005630:  
2025-08-27 20:25:36.012831: Epoch 217 
2025-08-27 20:25:36.020366: Current learning rate: 0.00802 
2025-08-27 20:26:01.088457: train_loss -0.0196 
2025-08-27 20:26:01.096349: val_loss -0.0102 
2025-08-27 20:26:01.100938: Pseudo dice [np.float32(0.5183)] 
2025-08-27 20:26:01.106803: Epoch time: 25.08 s 
2025-08-27 20:26:01.728029:  
2025-08-27 20:26:01.736573: Epoch 218 
2025-08-27 20:26:01.741670: Current learning rate: 0.00801 
2025-08-27 20:26:26.242325: train_loss -0.0092 
2025-08-27 20:26:26.250914: val_loss 0.0012 
2025-08-27 20:26:26.255070: Pseudo dice [np.float32(0.0909)] 
2025-08-27 20:26:26.264040: Epoch time: 24.52 s 
2025-08-27 20:26:26.895991:  
2025-08-27 20:26:26.905276: Epoch 219 
2025-08-27 20:26:26.911646: Current learning rate: 0.00801 
2025-08-27 20:26:51.504982: train_loss -0.0187 
2025-08-27 20:26:51.513634: val_loss -0.0054 
2025-08-27 20:26:51.521291: Pseudo dice [np.float32(0.1686)] 
2025-08-27 20:26:51.525864: Epoch time: 24.61 s 
2025-08-27 20:26:52.141988:  
2025-08-27 20:26:52.151419: Epoch 220 
2025-08-27 20:26:52.157650: Current learning rate: 0.008 
2025-08-27 20:27:17.126384: train_loss -0.0075 
2025-08-27 20:27:17.134731: val_loss -0.0071 
2025-08-27 20:27:17.143084: Pseudo dice [np.float32(0.4575)] 
2025-08-27 20:27:17.149067: Epoch time: 24.99 s 
2025-08-27 20:27:17.773931:  
2025-08-27 20:27:17.782225: Epoch 221 
2025-08-27 20:27:17.788415: Current learning rate: 0.00799 
2025-08-27 20:27:42.230903: train_loss -0.0094 
2025-08-27 20:27:42.238962: val_loss -0.0128 
2025-08-27 20:27:42.243114: Pseudo dice [np.float32(0.2234)] 
2025-08-27 20:27:42.250025: Epoch time: 24.46 s 
2025-08-27 20:27:42.871015:  
2025-08-27 20:27:42.879094: Epoch 222 
2025-08-27 20:27:42.884314: Current learning rate: 0.00798 
2025-08-27 20:28:07.581078: train_loss -0.0192 
2025-08-27 20:28:07.589272: val_loss -0.0257 
2025-08-27 20:28:07.597622: Pseudo dice [np.float32(0.3905)] 
2025-08-27 20:28:07.602691: Epoch time: 24.71 s 
2025-08-27 20:28:08.213744:  
2025-08-27 20:28:08.221124: Epoch 223 
2025-08-27 20:28:08.226260: Current learning rate: 0.00797 
2025-08-27 20:28:33.598589: train_loss -0.0082 
2025-08-27 20:28:33.606913: val_loss -0.0166 
2025-08-27 20:28:33.611083: Pseudo dice [np.float32(0.3156)] 
2025-08-27 20:28:33.618089: Epoch time: 25.39 s 
2025-08-27 20:28:34.233613:  
2025-08-27 20:28:34.240744: Epoch 224 
2025-08-27 20:28:34.247049: Current learning rate: 0.00796 
2025-08-27 20:28:58.319855: train_loss -0.0121 
2025-08-27 20:28:58.327782: val_loss -0.0094 
2025-08-27 20:28:58.331952: Pseudo dice [np.float32(0.2918)] 
2025-08-27 20:28:58.338039: Epoch time: 24.09 s 
2025-08-27 20:28:58.956075:  
2025-08-27 20:28:58.965433: Epoch 225 
2025-08-27 20:28:58.971766: Current learning rate: 0.00795 
2025-08-27 20:29:23.515074: train_loss -0.0032 
2025-08-27 20:29:23.519608: val_loss -0.0398 
2025-08-27 20:29:23.527861: Pseudo dice [np.float32(0.4632)] 
2025-08-27 20:29:23.533577: Epoch time: 24.56 s 
2025-08-27 20:29:24.150066:  
2025-08-27 20:29:24.157276: Epoch 226 
2025-08-27 20:29:24.162592: Current learning rate: 0.00794 
2025-08-27 20:29:49.100322: train_loss -0.0157 
2025-08-27 20:29:49.107584: val_loss -0.0056 
2025-08-27 20:29:49.115978: Pseudo dice [np.float32(0.3383)] 
2025-08-27 20:29:49.120989: Epoch time: 24.95 s 
2025-08-27 20:29:49.124724: Yayy! New best EMA pseudo Dice: 0.304500013589859 
2025-08-27 20:29:50.067593:  
2025-08-27 20:29:50.075963: Epoch 227 
2025-08-27 20:29:50.081110: Current learning rate: 0.00793 
2025-08-27 20:30:14.978844: train_loss -0.0183 
2025-08-27 20:30:14.983535: val_loss -0.0034 
2025-08-27 20:30:14.991895: Pseudo dice [np.float32(0.2213)] 
2025-08-27 20:30:14.996908: Epoch time: 24.91 s 
2025-08-27 20:30:15.655654:  
2025-08-27 20:30:15.664216: Epoch 228 
2025-08-27 20:30:15.670164: Current learning rate: 0.00792 
2025-08-27 20:30:41.180672: train_loss -0.0137 
2025-08-27 20:30:41.188486: val_loss -0.0368 
2025-08-27 20:30:41.192886: Pseudo dice [np.float32(0.3875)] 
2025-08-27 20:30:41.198797: Epoch time: 25.53 s 
2025-08-27 20:30:41.201721: Yayy! New best EMA pseudo Dice: 0.3052999973297119 
2025-08-27 20:30:42.048673:  
2025-08-27 20:30:42.056707: Epoch 229 
2025-08-27 20:30:42.063179: Current learning rate: 0.00791 
2025-08-27 20:31:07.189744: train_loss -0.0194 
2025-08-27 20:31:07.198066: val_loss -0.0175 
2025-08-27 20:31:07.205777: Pseudo dice [np.float32(0.2605)] 
2025-08-27 20:31:07.210334: Epoch time: 25.14 s 
2025-08-27 20:31:07.860781:  
2025-08-27 20:31:07.869101: Epoch 230 
2025-08-27 20:31:07.874435: Current learning rate: 0.0079 
2025-08-27 20:31:32.798690: train_loss -0.0093 
2025-08-27 20:31:32.806650: val_loss -0.0205 
2025-08-27 20:31:32.810827: Pseudo dice [np.float32(0.2447)] 
2025-08-27 20:31:32.819748: Epoch time: 24.94 s 
2025-08-27 20:31:33.480222:  
2025-08-27 20:31:33.487504: Epoch 231 
2025-08-27 20:31:33.492661: Current learning rate: 0.00789 
2025-08-27 20:31:58.463092: train_loss -0.0091 
2025-08-27 20:31:58.474271: val_loss -0.0016 
2025-08-27 20:31:58.478487: Pseudo dice [np.float32(0.0784)] 
2025-08-27 20:31:58.485448: Epoch time: 24.99 s 
2025-08-27 20:31:59.148510:  
2025-08-27 20:31:59.159051: Epoch 232 
2025-08-27 20:31:59.169280: Current learning rate: 0.00789 
2025-08-27 20:32:24.162213: train_loss -0.0085 
2025-08-27 20:32:24.170761: val_loss -0.0154 
2025-08-27 20:32:24.175099: Pseudo dice [np.float32(0.2773)] 
2025-08-27 20:32:24.183655: Epoch time: 25.01 s 
2025-08-27 20:32:24.976826:  
2025-08-27 20:32:24.985754: Epoch 233 
2025-08-27 20:32:24.990920: Current learning rate: 0.00788 
2025-08-27 20:32:50.596841: train_loss -0.0179 
2025-08-27 20:32:50.605157: val_loss -0.0098 
2025-08-27 20:32:50.609647: Pseudo dice [np.float32(0.196)] 
2025-08-27 20:32:50.615356: Epoch time: 25.62 s 
2025-08-27 20:32:51.288012:  
2025-08-27 20:32:51.296393: Epoch 234 
2025-08-27 20:32:51.302360: Current learning rate: 0.00787 
2025-08-27 20:33:17.219211: train_loss -0.0156 
2025-08-27 20:33:17.227599: val_loss -0.0144 
2025-08-27 20:33:17.231742: Pseudo dice [np.float32(0.1747)] 
2025-08-27 20:33:17.239757: Epoch time: 25.93 s 
2025-08-27 20:33:17.889592:  
2025-08-27 20:33:17.897889: Epoch 235 
2025-08-27 20:33:17.903105: Current learning rate: 0.00786 
2025-08-27 20:33:43.925899: train_loss -0.0197 
2025-08-27 20:33:43.933386: val_loss -0.0258 
2025-08-27 20:33:43.937567: Pseudo dice [np.float32(0.3282)] 
2025-08-27 20:33:43.945935: Epoch time: 26.04 s 
2025-08-27 20:33:44.614303:  
2025-08-27 20:33:44.622587: Epoch 236 
2025-08-27 20:33:44.628753: Current learning rate: 0.00785 
2025-08-27 20:34:10.238829: train_loss -0.0144 
2025-08-27 20:34:10.247199: val_loss -0.0218 
2025-08-27 20:34:10.255889: Pseudo dice [np.float32(0.306)] 
2025-08-27 20:34:10.260580: Epoch time: 25.63 s 
2025-08-27 20:34:10.960947:  
2025-08-27 20:34:10.971749: Epoch 237 
2025-08-27 20:34:10.979157: Current learning rate: 0.00784 
2025-08-27 20:34:36.502813: train_loss -0.0105 
2025-08-27 20:34:36.510911: val_loss -0.0096 
2025-08-27 20:34:36.515080: Pseudo dice [np.float32(0.221)] 
2025-08-27 20:34:36.521176: Epoch time: 25.54 s 
2025-08-27 20:34:37.187597:  
2025-08-27 20:34:37.194736: Epoch 238 
2025-08-27 20:34:37.200925: Current learning rate: 0.00783 
2025-08-27 20:35:02.653901: train_loss -0.0117 
2025-08-27 20:35:02.661922: val_loss -0.0054 
2025-08-27 20:35:02.666482: Pseudo dice [np.float32(0.1468)] 
2025-08-27 20:35:02.675356: Epoch time: 25.47 s 
2025-08-27 20:35:03.377821:  
2025-08-27 20:35:03.387726: Epoch 239 
2025-08-27 20:35:03.393919: Current learning rate: 0.00782 
2025-08-27 20:35:29.001432: train_loss -0.009 
2025-08-27 20:35:29.009139: val_loss -0.0318 
2025-08-27 20:35:29.013519: Pseudo dice [np.float32(0.3662)] 
2025-08-27 20:35:29.019447: Epoch time: 25.63 s 
2025-08-27 20:35:29.868245:  
2025-08-27 20:35:29.876642: Epoch 240 
2025-08-27 20:35:29.882883: Current learning rate: 0.00781 
2025-08-27 20:35:55.227096: train_loss -0.0044 
2025-08-27 20:35:55.235383: val_loss -0.0257 
2025-08-27 20:35:55.243339: Pseudo dice [np.float32(0.385)] 
2025-08-27 20:35:55.248526: Epoch time: 25.36 s 
2025-08-27 20:35:55.908873:  
2025-08-27 20:35:55.917152: Epoch 241 
2025-08-27 20:35:55.925527: Current learning rate: 0.0078 
2025-08-27 20:36:20.836058: train_loss -0.014 
2025-08-27 20:36:20.844250: val_loss -0.029 
2025-08-27 20:36:20.848279: Pseudo dice [np.float32(0.4028)] 
2025-08-27 20:36:20.858139: Epoch time: 24.93 s 
2025-08-27 20:36:21.538914:  
2025-08-27 20:36:21.546858: Epoch 242 
2025-08-27 20:36:21.552123: Current learning rate: 0.00779 
2025-08-27 20:36:47.020634: train_loss -0.0215 
2025-08-27 20:36:47.028715: val_loss -0.007 
2025-08-27 20:36:47.037026: Pseudo dice [np.float32(0.5966)] 
2025-08-27 20:36:47.042072: Epoch time: 25.48 s 
2025-08-27 20:36:47.046161: Yayy! New best EMA pseudo Dice: 0.3190999925136566 
2025-08-27 20:36:47.920132:  
2025-08-27 20:36:47.929960: Epoch 243 
2025-08-27 20:36:47.936431: Current learning rate: 0.00778 
2025-08-27 20:37:13.209385: train_loss -0.0034 
2025-08-27 20:37:13.217363: val_loss -0.0065 
2025-08-27 20:37:13.223192: Pseudo dice [np.float32(0.3724)] 
2025-08-27 20:37:13.227565: Epoch time: 25.29 s 
2025-08-27 20:37:13.233974: Yayy! New best EMA pseudo Dice: 0.32440000772476196 
2025-08-27 20:37:14.125988:  
2025-08-27 20:37:14.133775: Epoch 244 
2025-08-27 20:37:14.143102: Current learning rate: 0.00777 
2025-08-27 20:37:39.593902: train_loss -0.021 
2025-08-27 20:37:39.602064: val_loss -0.0059 
2025-08-27 20:37:39.610458: Pseudo dice [np.float32(0.1994)] 
2025-08-27 20:37:39.615429: Epoch time: 25.47 s 
2025-08-27 20:37:40.276222:  
2025-08-27 20:37:40.283857: Epoch 245 
2025-08-27 20:37:40.290053: Current learning rate: 0.00777 
2025-08-27 20:38:05.252603: train_loss -0.0273 
2025-08-27 20:38:05.260954: val_loss -0.0011 
2025-08-27 20:38:05.269155: Pseudo dice [np.float32(0.0618)] 
2025-08-27 20:38:05.276372: Epoch time: 24.98 s 
2025-08-27 20:38:06.100259:  
2025-08-27 20:38:06.107887: Epoch 246 
2025-08-27 20:38:06.114392: Current learning rate: 0.00776 
2025-08-27 20:38:31.680310: train_loss -0.0138 
2025-08-27 20:38:31.687619: val_loss -0.0223 
2025-08-27 20:38:31.691803: Pseudo dice [np.float32(0.4693)] 
2025-08-27 20:38:31.698631: Epoch time: 25.58 s 
2025-08-27 20:38:32.372398:  
2025-08-27 20:38:32.379532: Epoch 247 
2025-08-27 20:38:32.387383: Current learning rate: 0.00775 
2025-08-27 20:38:58.009440: train_loss -0.0187 
2025-08-27 20:38:58.017792: val_loss -0.004 
2025-08-27 20:38:58.026038: Pseudo dice [np.float32(0.2639)] 
2025-08-27 20:38:58.031035: Epoch time: 25.64 s 
2025-08-27 20:38:58.682995:  
2025-08-27 20:38:58.691363: Epoch 248 
2025-08-27 20:38:58.698717: Current learning rate: 0.00774 
2025-08-27 20:39:23.814642: train_loss -0.0183 
2025-08-27 20:39:23.823033: val_loss -0.0171 
2025-08-27 20:39:23.831064: Pseudo dice [np.float32(0.5303)] 
2025-08-27 20:39:23.837250: Epoch time: 25.13 s 
2025-08-27 20:39:24.507759:  
2025-08-27 20:39:24.519224: Epoch 249 
2025-08-27 20:39:24.525165: Current learning rate: 0.00773 
2025-08-27 20:39:50.053428: train_loss -0.0154 
2025-08-27 20:39:50.061762: val_loss -0.0053 
2025-08-27 20:39:50.065928: Pseudo dice [np.float32(0.1525)] 
2025-08-27 20:39:50.073564: Epoch time: 25.55 s 
2025-08-27 20:39:50.930986:  
2025-08-27 20:39:50.940782: Epoch 250 
2025-08-27 20:39:50.946681: Current learning rate: 0.00772 
2025-08-27 20:40:16.917384: train_loss -0.0121 
2025-08-27 20:40:16.926098: val_loss -0.0162 
2025-08-27 20:40:16.930245: Pseudo dice [np.float32(0.2727)] 
2025-08-27 20:40:16.936112: Epoch time: 25.99 s 
2025-08-27 20:40:17.612767:  
2025-08-27 20:40:17.620110: Epoch 251 
2025-08-27 20:40:17.626281: Current learning rate: 0.00771 
2025-08-27 20:40:42.889365: train_loss -0.0111 
2025-08-27 20:40:42.897834: val_loss -0.0109 
2025-08-27 20:40:42.902006: Pseudo dice [np.float32(0.3095)] 
2025-08-27 20:40:42.907089: Epoch time: 25.28 s 
2025-08-27 20:40:43.577273:  
2025-08-27 20:40:43.586696: Epoch 252 
2025-08-27 20:40:43.591862: Current learning rate: 0.0077 
2025-08-27 20:41:09.357572: train_loss -0.0113 
2025-08-27 20:41:09.365945: val_loss -0.029 
2025-08-27 20:41:09.369765: Pseudo dice [np.float32(0.23)] 
2025-08-27 20:41:09.378790: Epoch time: 25.78 s 
2025-08-27 20:41:10.059954:  
2025-08-27 20:41:10.067288: Epoch 253 
2025-08-27 20:41:10.072557: Current learning rate: 0.00769 
2025-08-27 20:41:35.324815: train_loss -0.0184 
2025-08-27 20:41:35.333214: val_loss -0.0182 
2025-08-27 20:41:35.341545: Pseudo dice [np.float32(0.241)] 
2025-08-27 20:41:35.346543: Epoch time: 25.27 s 
2025-08-27 20:41:36.016165:  
2025-08-27 20:41:36.023400: Epoch 254 
2025-08-27 20:41:36.028543: Current learning rate: 0.00768 
2025-08-27 20:42:00.917300: train_loss -0.0133 
2025-08-27 20:42:00.925401: val_loss -0.0081 
2025-08-27 20:42:00.929549: Pseudo dice [np.float32(0.155)] 
2025-08-27 20:42:00.938662: Epoch time: 24.9 s 
2025-08-27 20:42:01.618056:  
2025-08-27 20:42:01.626095: Epoch 255 
2025-08-27 20:42:01.630579: Current learning rate: 0.00767 
2025-08-27 20:42:26.922163: train_loss -0.0089 
2025-08-27 20:42:26.926336: val_loss -0.0093 
2025-08-27 20:42:26.934690: Pseudo dice [np.float32(0.1046)] 
2025-08-27 20:42:26.939638: Epoch time: 25.31 s 
2025-08-27 20:42:27.610312:  
2025-08-27 20:42:27.619794: Epoch 256 
2025-08-27 20:42:27.628056: Current learning rate: 0.00766 
2025-08-27 20:42:53.194433: train_loss -0.0129 
2025-08-27 20:42:53.202615: val_loss -0.0139 
2025-08-27 20:42:53.206754: Pseudo dice [np.float32(0.1561)] 
2025-08-27 20:42:53.212708: Epoch time: 25.59 s 
2025-08-27 20:42:53.891811:  
2025-08-27 20:42:53.898947: Epoch 257 
2025-08-27 20:42:53.904388: Current learning rate: 0.00765 
2025-08-27 20:43:18.811848: train_loss -0.0193 
2025-08-27 20:43:18.819834: val_loss -0.02 
2025-08-27 20:43:18.824306: Pseudo dice [np.float32(0.2861)] 
2025-08-27 20:43:18.830557: Epoch time: 24.92 s 
2025-08-27 20:43:19.486990:  
2025-08-27 20:43:19.494441: Epoch 258 
2025-08-27 20:43:19.500693: Current learning rate: 0.00764 
2025-08-27 20:43:44.516633: train_loss -0.0131 
2025-08-27 20:43:44.524953: val_loss -0.0171 
2025-08-27 20:43:44.533002: Pseudo dice [np.float32(0.3768)] 
2025-08-27 20:43:44.538579: Epoch time: 25.03 s 
2025-08-27 20:43:45.200206:  
2025-08-27 20:43:45.207532: Epoch 259 
2025-08-27 20:43:45.212677: Current learning rate: 0.00764 
2025-08-27 20:44:10.450850: train_loss -0.0152 
2025-08-27 20:44:10.459229: val_loss -0.0204 
2025-08-27 20:44:10.467930: Pseudo dice [np.float32(0.3932)] 
2025-08-27 20:44:10.472635: Epoch time: 25.25 s 
2025-08-27 20:44:11.130230:  
2025-08-27 20:44:11.138564: Epoch 260 
2025-08-27 20:44:11.143908: Current learning rate: 0.00763 
2025-08-27 20:44:35.617322: train_loss -0.0112 
2025-08-27 20:44:35.626016: val_loss -0.0027 
2025-08-27 20:44:35.630188: Pseudo dice [np.float32(0.1592)] 
2025-08-27 20:44:35.636916: Epoch time: 24.49 s 
2025-08-27 20:44:36.314878:  
2025-08-27 20:44:36.324076: Epoch 261 
2025-08-27 20:44:36.329410: Current learning rate: 0.00762 
2025-08-27 20:45:01.543472: train_loss -0.007 
2025-08-27 20:45:01.551556: val_loss -0.0146 
2025-08-27 20:45:01.555684: Pseudo dice [np.float32(0.3265)] 
2025-08-27 20:45:01.561627: Epoch time: 25.23 s 
2025-08-27 20:45:02.242743:  
2025-08-27 20:45:02.250126: Epoch 262 
2025-08-27 20:45:02.255365: Current learning rate: 0.00761 
2025-08-27 20:45:27.610890: train_loss -0.0117 
2025-08-27 20:45:27.619328: val_loss -0.0178 
2025-08-27 20:45:27.627616: Pseudo dice [np.float32(0.2762)] 
2025-08-27 20:45:27.632597: Epoch time: 25.37 s 
2025-08-27 20:45:28.306270:  
2025-08-27 20:45:28.314613: Epoch 263 
2025-08-27 20:45:28.319843: Current learning rate: 0.0076 
2025-08-27 20:45:53.162107: train_loss -0.0149 
2025-08-27 20:45:53.172130: val_loss -0.0117 
2025-08-27 20:45:53.173839: Pseudo dice [np.float32(0.238)] 
2025-08-27 20:45:53.181590: Epoch time: 24.86 s 
2025-08-27 20:45:53.854827:  
2025-08-27 20:45:53.861988: Epoch 264 
2025-08-27 20:45:53.868320: Current learning rate: 0.00759 
2025-08-27 20:46:18.966646: train_loss -0.0121 
2025-08-27 20:46:18.975051: val_loss -0.0024 
2025-08-27 20:46:18.979168: Pseudo dice [np.float32(0.184)] 
2025-08-27 20:46:18.985937: Epoch time: 25.11 s 
2025-08-27 20:46:19.829566:  
2025-08-27 20:46:19.837906: Epoch 265 
2025-08-27 20:46:19.844223: Current learning rate: 0.00758 
2025-08-27 20:46:45.372511: train_loss -0.0078 
2025-08-27 20:46:45.384392: val_loss -0.0218 
2025-08-27 20:46:45.388899: Pseudo dice [np.float32(0.2755)] 
2025-08-27 20:46:45.394565: Epoch time: 25.54 s 
2025-08-27 20:46:46.072490:  
2025-08-27 20:46:46.079834: Epoch 266 
2025-08-27 20:46:46.084916: Current learning rate: 0.00757 
2025-08-27 20:47:11.101730: train_loss -0.016 
2025-08-27 20:47:11.110069: val_loss -0.0208 
2025-08-27 20:47:11.114486: Pseudo dice [np.float32(0.265)] 
2025-08-27 20:47:11.120371: Epoch time: 25.03 s 
2025-08-27 20:47:11.802292:  
2025-08-27 20:47:11.813801: Epoch 267 
2025-08-27 20:47:11.825392: Current learning rate: 0.00756 
2025-08-27 20:47:37.111025: train_loss -0.0159 
2025-08-27 20:47:37.119682: val_loss 0.0041 
2025-08-27 20:47:37.127712: Pseudo dice [np.float32(0.0838)] 
2025-08-27 20:47:37.133287: Epoch time: 25.31 s 
2025-08-27 20:47:37.813740:  
2025-08-27 20:47:37.824210: Epoch 268 
2025-08-27 20:47:37.830512: Current learning rate: 0.00755 
2025-08-27 20:48:03.216552: train_loss -0.0126 
2025-08-27 20:48:03.224898: val_loss -0.0414 
2025-08-27 20:48:03.233260: Pseudo dice [np.float32(0.4778)] 
2025-08-27 20:48:03.238328: Epoch time: 25.4 s 
2025-08-27 20:48:03.933475:  
2025-08-27 20:48:03.941369: Epoch 269 
2025-08-27 20:48:03.947374: Current learning rate: 0.00754 
2025-08-27 20:48:29.142121: train_loss -0.0261 
2025-08-27 20:48:29.150699: val_loss -0.024 
2025-08-27 20:48:29.154916: Pseudo dice [np.float32(0.3419)] 
2025-08-27 20:48:29.160662: Epoch time: 25.21 s 
2025-08-27 20:48:29.846862:  
2025-08-27 20:48:29.854205: Epoch 270 
2025-08-27 20:48:29.860207: Current learning rate: 0.00753 
2025-08-27 20:48:55.510123: train_loss -0.0078 
2025-08-27 20:48:55.518486: val_loss -0.0209 
2025-08-27 20:48:55.522850: Pseudo dice [np.float32(0.3095)] 
2025-08-27 20:48:55.530726: Epoch time: 25.67 s 
2025-08-27 20:48:56.211670:  
2025-08-27 20:48:56.219055: Epoch 271 
2025-08-27 20:48:56.225401: Current learning rate: 0.00752 
2025-08-27 20:49:21.536432: train_loss -0.0137 
2025-08-27 20:49:21.544785: val_loss -0.028 
2025-08-27 20:49:21.548937: Pseudo dice [np.float32(0.295)] 
2025-08-27 20:49:21.556592: Epoch time: 25.33 s 
2025-08-27 20:49:22.251338:  
2025-08-27 20:49:22.262741: Epoch 272 
2025-08-27 20:49:22.270665: Current learning rate: 0.00751 
2025-08-27 20:49:47.525301: train_loss -0.0129 
2025-08-27 20:49:47.533266: val_loss -0.01 
2025-08-27 20:49:47.541634: Pseudo dice [np.float32(0.1958)] 
2025-08-27 20:49:47.546649: Epoch time: 25.27 s 
2025-08-27 20:49:48.240839:  
2025-08-27 20:49:48.249202: Epoch 273 
2025-08-27 20:49:48.258272: Current learning rate: 0.00751 
2025-08-27 20:50:13.083874: train_loss -0.022 
2025-08-27 20:50:13.091941: val_loss 0.0066 
2025-08-27 20:50:13.096243: Pseudo dice [np.float32(0.097)] 
2025-08-27 20:50:13.103914: Epoch time: 24.84 s 
2025-08-27 20:50:13.770109:  
2025-08-27 20:50:13.778844: Epoch 274 
2025-08-27 20:50:13.789173: Current learning rate: 0.0075 
2025-08-27 20:50:39.326702: train_loss -0.0164 
2025-08-27 20:50:39.334952: val_loss -0.0137 
2025-08-27 20:50:39.339102: Pseudo dice [np.float32(0.4185)] 
2025-08-27 20:50:39.344784: Epoch time: 25.56 s 
2025-08-27 20:50:40.016479:  
2025-08-27 20:50:40.025440: Epoch 275 
2025-08-27 20:50:40.032185: Current learning rate: 0.00749 
2025-08-27 20:51:05.377270: train_loss -0.0202 
2025-08-27 20:51:05.385996: val_loss -0.0173 
2025-08-27 20:51:05.390136: Pseudo dice [np.float32(0.2054)] 
2025-08-27 20:51:05.396028: Epoch time: 25.36 s 
2025-08-27 20:51:06.073761:  
2025-08-27 20:51:06.081015: Epoch 276 
2025-08-27 20:51:06.086229: Current learning rate: 0.00748 
2025-08-27 20:51:31.282565: train_loss -0.0189 
2025-08-27 20:51:31.290939: val_loss -0.0022 
2025-08-27 20:51:31.298995: Pseudo dice [np.float32(0.1722)] 
2025-08-27 20:51:31.303185: Epoch time: 25.21 s 
2025-08-27 20:51:32.006929:  
2025-08-27 20:51:32.018118: Epoch 277 
2025-08-27 20:51:32.027663: Current learning rate: 0.00747 
2025-08-27 20:51:57.996609: train_loss -0.0195 
2025-08-27 20:51:58.004874: val_loss -0.0344 
2025-08-27 20:51:58.008981: Pseudo dice [np.float32(0.3861)] 
2025-08-27 20:51:58.017353: Epoch time: 25.99 s 
2025-08-27 20:51:58.700183:  
2025-08-27 20:51:58.709594: Epoch 278 
2025-08-27 20:51:58.718705: Current learning rate: 0.00746 
2025-08-27 20:52:23.872617: train_loss -0.0147 
2025-08-27 20:52:23.880728: val_loss -0.0075 
2025-08-27 20:52:23.885142: Pseudo dice [np.float32(0.1143)] 
2025-08-27 20:52:23.891026: Epoch time: 25.17 s 
2025-08-27 20:52:24.566712:  
2025-08-27 20:52:24.574601: Epoch 279 
2025-08-27 20:52:24.582547: Current learning rate: 0.00745 
2025-08-27 20:52:50.127911: train_loss -0.0186 
2025-08-27 20:52:50.136424: val_loss -0.021 
2025-08-27 20:52:50.140196: Pseudo dice [np.float32(0.3478)] 
2025-08-27 20:52:50.148552: Epoch time: 25.56 s 
2025-08-27 20:52:50.844939:  
2025-08-27 20:52:50.853073: Epoch 280 
2025-08-27 20:52:50.858670: Current learning rate: 0.00744 
2025-08-27 20:53:16.633322: train_loss -0.0148 
2025-08-27 20:53:16.642771: val_loss -0.0266 
2025-08-27 20:53:16.650461: Pseudo dice [np.float32(0.3858)] 
2025-08-27 20:53:16.656081: Epoch time: 25.79 s 
2025-08-27 20:53:17.361143:  
2025-08-27 20:53:17.369838: Epoch 281 
2025-08-27 20:53:17.375674: Current learning rate: 0.00743 
2025-08-27 20:53:42.467442: train_loss -0.0101 
2025-08-27 20:53:42.475803: val_loss -0.013 
2025-08-27 20:53:42.480190: Pseudo dice [np.float32(0.146)] 
2025-08-27 20:53:42.487006: Epoch time: 25.11 s 
2025-08-27 20:53:43.166032:  
2025-08-27 20:53:43.173327: Epoch 282 
2025-08-27 20:53:43.179497: Current learning rate: 0.00742 
2025-08-27 20:54:08.280844: train_loss -0.0115 
2025-08-27 20:54:08.289421: val_loss -0.013 
2025-08-27 20:54:08.293779: Pseudo dice [np.float32(0.3188)] 
2025-08-27 20:54:08.299346: Epoch time: 25.12 s 
2025-08-27 20:54:08.979329:  
2025-08-27 20:54:08.988084: Epoch 283 
2025-08-27 20:54:08.994939: Current learning rate: 0.00741 
2025-08-27 20:54:34.965818: train_loss -0.0151 
2025-08-27 20:54:34.974098: val_loss -0.0296 
2025-08-27 20:54:34.978224: Pseudo dice [np.float32(0.3769)] 
2025-08-27 20:54:34.984371: Epoch time: 25.99 s 
2025-08-27 20:54:35.797697:  
2025-08-27 20:54:35.805059: Epoch 284 
2025-08-27 20:54:35.812226: Current learning rate: 0.0074 
2025-08-27 20:55:01.029558: train_loss -0.0211 
2025-08-27 20:55:01.038294: val_loss -0.0384 
2025-08-27 20:55:01.041870: Pseudo dice [np.float32(0.3757)] 
2025-08-27 20:55:01.048872: Epoch time: 25.23 s 
2025-08-27 20:55:01.741253:  
2025-08-27 20:55:01.750659: Epoch 285 
2025-08-27 20:55:01.755524: Current learning rate: 0.00739 
2025-08-27 20:55:27.497308: train_loss -0.0044 
2025-08-27 20:55:27.505992: val_loss -0.0363 
2025-08-27 20:55:27.514360: Pseudo dice [np.float32(0.3977)] 
2025-08-27 20:55:27.519103: Epoch time: 25.76 s 
2025-08-27 20:55:28.218862:  
2025-08-27 20:55:28.228887: Epoch 286 
2025-08-27 20:55:28.237189: Current learning rate: 0.00738 
2025-08-27 20:55:53.869462: train_loss -0.0205 
2025-08-27 20:55:53.874023: val_loss -0.0353 
2025-08-27 20:55:53.882295: Pseudo dice [np.float32(0.3696)] 
2025-08-27 20:55:53.886924: Epoch time: 25.65 s 
2025-08-27 20:55:54.564921:  
2025-08-27 20:55:54.572176: Epoch 287 
2025-08-27 20:55:54.577366: Current learning rate: 0.00738 
2025-08-27 20:56:19.916289: train_loss -0.0062 
2025-08-27 20:56:19.924659: val_loss -0.0244 
2025-08-27 20:56:19.929169: Pseudo dice [np.float32(0.3344)] 
2025-08-27 20:56:19.934239: Epoch time: 25.35 s 
2025-08-27 20:56:20.622188:  
2025-08-27 20:56:20.630579: Epoch 288 
2025-08-27 20:56:20.634827: Current learning rate: 0.00737 
2025-08-27 20:56:45.725398: train_loss -0.0171 
2025-08-27 20:56:45.737927: val_loss -0.0249 
2025-08-27 20:56:45.742406: Pseudo dice [np.float32(0.2829)] 
2025-08-27 20:56:45.747596: Epoch time: 25.11 s 
2025-08-27 20:56:46.446094:  
2025-08-27 20:56:46.454132: Epoch 289 
2025-08-27 20:56:46.459508: Current learning rate: 0.00736 
2025-08-27 20:57:12.523073: train_loss -0.0021 
2025-08-27 20:57:12.531342: val_loss -0.0352 
2025-08-27 20:57:12.539700: Pseudo dice [np.float32(0.2738)] 
2025-08-27 20:57:12.545083: Epoch time: 26.08 s 
2025-08-27 20:57:13.402877:  
2025-08-27 20:57:13.409278: Epoch 290 
2025-08-27 20:57:13.412016: Current learning rate: 0.00735 
2025-08-27 20:57:38.503489: train_loss -0.0105 
2025-08-27 20:57:38.511811: val_loss 0.0024 
2025-08-27 20:57:38.515932: Pseudo dice [np.float32(0.0513)] 
2025-08-27 20:57:38.523973: Epoch time: 25.1 s 
2025-08-27 20:57:39.227664:  
2025-08-27 20:57:39.235040: Epoch 291 
2025-08-27 20:57:39.240169: Current learning rate: 0.00734 
2025-08-27 20:58:04.863082: train_loss -0.0191 
2025-08-27 20:58:04.871107: val_loss -0.019 
2025-08-27 20:58:04.875266: Pseudo dice [np.float32(0.2207)] 
2025-08-27 20:58:04.883717: Epoch time: 25.64 s 
2025-08-27 20:58:05.583141:  
2025-08-27 20:58:05.590574: Epoch 292 
2025-08-27 20:58:05.595379: Current learning rate: 0.00733 
2025-08-27 20:58:31.414191: train_loss -0.0132 
2025-08-27 20:58:31.422620: val_loss -0.0278 
2025-08-27 20:58:31.426809: Pseudo dice [np.float32(0.3736)] 
2025-08-27 20:58:31.432767: Epoch time: 25.83 s 
2025-08-27 20:58:32.116986:  
2025-08-27 20:58:32.124314: Epoch 293 
2025-08-27 20:58:32.130313: Current learning rate: 0.00732 
2025-08-27 20:58:57.833159: train_loss -0.0146 
2025-08-27 20:58:57.840635: val_loss -0.0102 
2025-08-27 20:58:57.845036: Pseudo dice [np.float32(0.2211)] 
2025-08-27 20:58:57.852792: Epoch time: 25.72 s 
2025-08-27 20:58:58.559032:  
2025-08-27 20:58:58.568213: Epoch 294 
2025-08-27 20:58:58.574586: Current learning rate: 0.00731 
2025-08-27 20:59:22.568325: train_loss -0.0172 
2025-08-27 20:59:22.573718: val_loss -0.0288 
2025-08-27 20:59:22.577874: Pseudo dice [np.float32(0.3176)] 
2025-08-27 20:59:22.585788: Epoch time: 24.01 s 
2025-08-27 20:59:23.225312:  
2025-08-27 20:59:23.233674: Epoch 295 
2025-08-27 20:59:23.240932: Current learning rate: 0.0073 
2025-08-27 20:59:49.659062: train_loss -0.0069 
2025-08-27 20:59:49.667383: val_loss -0.0048 
2025-08-27 20:59:49.671490: Pseudo dice [np.float32(0.1247)] 
2025-08-27 20:59:49.678421: Epoch time: 26.43 s 
2025-08-27 20:59:50.351619:  
2025-08-27 20:59:50.362773: Epoch 296 
2025-08-27 20:59:50.368486: Current learning rate: 0.00729 
2025-08-27 21:00:15.140597: train_loss -0.0201 
2025-08-27 21:00:15.148944: val_loss -0.0249 
2025-08-27 21:00:15.155763: Pseudo dice [np.float32(0.2414)] 
2025-08-27 21:00:15.160502: Epoch time: 24.79 s 
2025-08-27 21:00:15.951952:  
2025-08-27 21:00:15.956152: Epoch 297 
2025-08-27 21:00:15.964439: Current learning rate: 0.00728 
2025-08-27 21:00:39.405659: train_loss -0.0192 
2025-08-27 21:00:39.411804: val_loss -0.0098 
2025-08-27 21:00:39.415832: Pseudo dice [np.float32(0.393)] 
2025-08-27 21:00:39.419839: Epoch time: 23.46 s 
2025-08-27 21:00:40.042065:  
2025-08-27 21:00:40.050433: Epoch 298 
2025-08-27 21:00:40.056200: Current learning rate: 0.00727 
2025-08-27 21:01:02.129154: train_loss -0.0105 
2025-08-27 21:01:02.139749: val_loss -0.0161 
2025-08-27 21:01:02.144430: Pseudo dice [np.float32(0.326)] 
2025-08-27 21:01:02.148851: Epoch time: 22.09 s 
2025-08-27 21:01:02.768467:  
2025-08-27 21:01:02.777310: Epoch 299 
2025-08-27 21:01:02.781493: Current learning rate: 0.00726 
2025-08-27 21:01:25.763344: train_loss -0.0082 
2025-08-27 21:01:25.771655: val_loss -0.0269 
2025-08-27 21:01:25.775802: Pseudo dice [np.float32(0.2712)] 
2025-08-27 21:01:25.781791: Epoch time: 23.0 s 
2025-08-27 21:01:26.597476:  
2025-08-27 21:01:26.605844: Epoch 300 
2025-08-27 21:01:26.613662: Current learning rate: 0.00725 
2025-08-27 21:01:51.712056: train_loss -0.0183 
2025-08-27 21:01:51.723581: val_loss -0.0465 
2025-08-27 21:01:51.728747: Pseudo dice [np.float32(0.4026)] 
2025-08-27 21:01:51.736010: Epoch time: 25.11 s 
2025-08-27 21:01:52.410173:  
2025-08-27 21:01:52.418172: Epoch 301 
2025-08-27 21:01:52.423171: Current learning rate: 0.00724 
2025-08-27 21:02:18.532697: train_loss -0.0097 
2025-08-27 21:02:18.536989: val_loss -0.0152 
2025-08-27 21:02:18.545209: Pseudo dice [np.float32(0.3044)] 
2025-08-27 21:02:18.550723: Epoch time: 26.12 s 
2025-08-27 21:02:19.183767:  
2025-08-27 21:02:19.191687: Epoch 302 
2025-08-27 21:02:19.195842: Current learning rate: 0.00724 
2025-08-27 21:02:43.712062: train_loss -0.0126 
2025-08-27 21:02:43.720534: val_loss -0.0253 
2025-08-27 21:02:43.728683: Pseudo dice [np.float32(0.2903)] 
2025-08-27 21:02:43.733935: Epoch time: 24.53 s 
2025-08-27 21:02:44.575288:  
2025-08-27 21:02:44.583390: Epoch 303 
2025-08-27 21:02:44.587901: Current learning rate: 0.00723 
2025-08-27 21:03:09.021169: train_loss -0.0135 
2025-08-27 21:03:09.033098: val_loss -0.0101 
2025-08-27 21:03:09.037294: Pseudo dice [np.float32(0.1693)] 
2025-08-27 21:03:09.044337: Epoch time: 24.45 s 
2025-08-27 21:03:09.662904:  
2025-08-27 21:03:09.671236: Epoch 304 
2025-08-27 21:03:09.675458: Current learning rate: 0.00722 
2025-08-27 21:03:35.088565: train_loss -0.0137 
2025-08-27 21:03:35.096607: val_loss -0.0084 
2025-08-27 21:03:35.100775: Pseudo dice [np.float32(0.1371)] 
2025-08-27 21:03:35.109584: Epoch time: 25.43 s 
2025-08-27 21:03:35.738900:  
2025-08-27 21:03:35.747276: Epoch 305 
2025-08-27 21:03:35.751419: Current learning rate: 0.00721 
2025-08-27 21:04:00.059044: train_loss -0.0136 
2025-08-27 21:04:00.067403: val_loss -0.0258 
2025-08-27 21:04:00.071553: Pseudo dice [np.float32(0.3142)] 
2025-08-27 21:04:00.079964: Epoch time: 24.32 s 
2025-08-27 21:04:00.705534:  
2025-08-27 21:04:00.713884: Epoch 306 
2025-08-27 21:04:00.718006: Current learning rate: 0.0072 
2025-08-27 21:04:25.042530: train_loss -0.0239 
2025-08-27 21:04:25.050669: val_loss -0.0179 
2025-08-27 21:04:25.054817: Pseudo dice [np.float32(0.2773)] 
2025-08-27 21:04:25.061890: Epoch time: 24.34 s 
2025-08-27 21:04:25.688777:  
2025-08-27 21:04:25.696898: Epoch 307 
2025-08-27 21:04:25.705473: Current learning rate: 0.00719 
2025-08-27 21:04:51.406529: train_loss -0.0189 
2025-08-27 21:04:51.414463: val_loss -0.0222 
2025-08-27 21:04:51.422896: Pseudo dice [np.float32(0.3421)] 
2025-08-27 21:04:51.428104: Epoch time: 25.72 s 
2025-08-27 21:04:52.069339:  
2025-08-27 21:04:52.077648: Epoch 308 
2025-08-27 21:04:52.081833: Current learning rate: 0.00718 
2025-08-27 21:05:16.606662: train_loss -0.0157 
2025-08-27 21:05:16.614631: val_loss -0.0123 
2025-08-27 21:05:16.623008: Pseudo dice [np.float32(0.2259)] 
2025-08-27 21:05:16.628237: Epoch time: 24.54 s 
2025-08-27 21:05:17.261093:  
2025-08-27 21:05:17.265439: Epoch 309 
2025-08-27 21:05:17.273623: Current learning rate: 0.00717 
2025-08-27 21:05:41.611024: train_loss -0.0043 
2025-08-27 21:05:41.618746: val_loss -0.0202 
2025-08-27 21:05:41.623210: Pseudo dice [np.float32(0.297)] 
2025-08-27 21:05:41.630608: Epoch time: 24.35 s 
2025-08-27 21:05:42.256882:  
2025-08-27 21:05:42.265229: Epoch 310 
2025-08-27 21:05:42.269385: Current learning rate: 0.00716 
2025-08-27 21:06:07.461314: train_loss -0.0104 
2025-08-27 21:06:07.469677: val_loss -0.0228 
2025-08-27 21:06:07.473925: Pseudo dice [np.float32(0.3931)] 
2025-08-27 21:06:07.480584: Epoch time: 25.21 s 
2025-08-27 21:06:08.111876:  
2025-08-27 21:06:08.120189: Epoch 311 
2025-08-27 21:06:08.124417: Current learning rate: 0.00715 
2025-08-27 21:06:33.741683: train_loss -0.0098 
2025-08-27 21:06:33.749985: val_loss -0.0248 
2025-08-27 21:06:33.758365: Pseudo dice [np.float32(0.2749)] 
2025-08-27 21:06:33.763073: Epoch time: 25.63 s 
2025-08-27 21:06:34.433981:  
2025-08-27 21:06:34.442386: Epoch 312 
2025-08-27 21:06:34.446803: Current learning rate: 0.00714 
2025-08-27 21:06:59.784269: train_loss -0.0171 
2025-08-27 21:06:59.792636: val_loss -0.0217 
2025-08-27 21:06:59.796787: Pseudo dice [np.float32(0.3324)] 
2025-08-27 21:06:59.805661: Epoch time: 25.35 s 
2025-08-27 21:07:00.455808:  
2025-08-27 21:07:00.464318: Epoch 313 
2025-08-27 21:07:00.468349: Current learning rate: 0.00713 
2025-08-27 21:07:26.252383: train_loss -0.012 
2025-08-27 21:07:26.260739: val_loss -0.0138 
2025-08-27 21:07:26.265187: Pseudo dice [np.float32(0.183)] 
2025-08-27 21:07:26.270202: Epoch time: 25.8 s 
2025-08-27 21:07:26.919725:  
2025-08-27 21:07:26.928098: Epoch 314 
2025-08-27 21:07:26.932462: Current learning rate: 0.00712 
2025-08-27 21:07:51.586592: train_loss -0.012 
2025-08-27 21:07:51.598754: val_loss -0.0008 
2025-08-27 21:07:51.603055: Pseudo dice [np.float32(0.1082)] 
2025-08-27 21:07:51.609062: Epoch time: 24.67 s 
2025-08-27 21:07:52.245018:  
2025-08-27 21:07:52.253352: Epoch 315 
2025-08-27 21:07:52.257517: Current learning rate: 0.00711 
2025-08-27 21:08:16.725582: train_loss -0.0162 
2025-08-27 21:08:16.733894: val_loss -0.004 
2025-08-27 21:08:16.741277: Pseudo dice [np.float32(0.3104)] 
2025-08-27 21:08:16.746488: Epoch time: 24.48 s 
2025-08-27 21:08:17.390929:  
2025-08-27 21:08:17.399284: Epoch 316 
2025-08-27 21:08:17.404407: Current learning rate: 0.0071 
2025-08-27 21:08:42.253551: train_loss -0.0096 
2025-08-27 21:08:42.261860: val_loss -0.0208 
2025-08-27 21:08:42.270231: Pseudo dice [np.float32(0.302)] 
2025-08-27 21:08:42.274840: Epoch time: 24.87 s 
2025-08-27 21:08:43.018534:  
2025-08-27 21:08:43.025850: Epoch 317 
2025-08-27 21:08:43.032035: Current learning rate: 0.0071 
2025-08-27 21:09:08.763066: train_loss -0.0158 
2025-08-27 21:09:08.775598: val_loss -0.0314 
2025-08-27 21:09:08.779997: Pseudo dice [np.float32(0.5623)] 
2025-08-27 21:09:08.786523: Epoch time: 25.75 s 
2025-08-27 21:09:09.460681:  
2025-08-27 21:09:09.468848: Epoch 318 
2025-08-27 21:09:09.473616: Current learning rate: 0.00709 
2025-08-27 21:09:34.993675: train_loss -0.0114 
2025-08-27 21:09:35.001787: val_loss -0.0337 
2025-08-27 21:09:35.005975: Pseudo dice [np.float32(0.3784)] 
2025-08-27 21:09:35.014396: Epoch time: 25.53 s 
2025-08-27 21:09:35.690963:  
2025-08-27 21:09:35.699290: Epoch 319 
2025-08-27 21:09:35.706561: Current learning rate: 0.00708 
2025-08-27 21:10:01.499036: train_loss -0.0084 
2025-08-27 21:10:01.511578: val_loss -0.022 
2025-08-27 21:10:01.515851: Pseudo dice [np.float32(0.2764)] 
2025-08-27 21:10:01.523004: Epoch time: 25.81 s 
2025-08-27 21:10:02.195443:  
2025-08-27 21:10:02.200852: Epoch 320 
2025-08-27 21:10:02.207945: Current learning rate: 0.00707 
2025-08-27 21:10:27.279058: train_loss -0.0217 
2025-08-27 21:10:27.287638: val_loss -0.0317 
2025-08-27 21:10:27.291775: Pseudo dice [np.float32(0.3723)] 
2025-08-27 21:10:27.297325: Epoch time: 25.09 s 
2025-08-27 21:10:27.975458:  
2025-08-27 21:10:27.983669: Epoch 321 
2025-08-27 21:10:27.988891: Current learning rate: 0.00706 
2025-08-27 21:10:53.142274: train_loss -0.0201 
2025-08-27 21:10:53.154798: val_loss -0.0126 
2025-08-27 21:10:53.158983: Pseudo dice [np.float32(0.3686)] 
2025-08-27 21:10:53.164898: Epoch time: 25.17 s 
2025-08-27 21:10:53.835705:  
2025-08-27 21:10:53.843966: Epoch 322 
2025-08-27 21:10:53.848303: Current learning rate: 0.00705 
2025-08-27 21:11:18.943415: train_loss -0.0196 
2025-08-27 21:11:18.951379: val_loss -0.0028 
2025-08-27 21:11:18.955556: Pseudo dice [np.float32(0.0702)] 
2025-08-27 21:11:18.964302: Epoch time: 25.11 s 
2025-08-27 21:11:19.644712:  
2025-08-27 21:11:19.653019: Epoch 323 
2025-08-27 21:11:19.660434: Current learning rate: 0.00704 
2025-08-27 21:11:45.035870: train_loss -0.0163 
2025-08-27 21:11:45.044126: val_loss -0.0228 
2025-08-27 21:11:45.048545: Pseudo dice [np.float32(0.3406)] 
2025-08-27 21:11:45.056330: Epoch time: 25.39 s 
2025-08-27 21:11:45.720854:  
2025-08-27 21:11:45.732299: Epoch 324 
2025-08-27 21:11:45.737577: Current learning rate: 0.00703 
2025-08-27 21:12:10.757631: train_loss -0.0167 
2025-08-27 21:12:10.765605: val_loss -0.0288 
2025-08-27 21:12:10.769774: Pseudo dice [np.float32(0.3729)] 
2025-08-27 21:12:10.777087: Epoch time: 25.04 s 
2025-08-27 21:12:11.441178:  
2025-08-27 21:12:11.446558: Epoch 325 
2025-08-27 21:12:11.453770: Current learning rate: 0.00702 
2025-08-27 21:12:37.104490: train_loss -0.0193 
2025-08-27 21:12:37.112750: val_loss -0.0182 
2025-08-27 21:12:37.121537: Pseudo dice [np.float32(0.4887)] 
2025-08-27 21:12:37.126849: Epoch time: 25.67 s 
2025-08-27 21:12:37.801938:  
2025-08-27 21:12:37.809283: Epoch 326 
2025-08-27 21:12:37.814555: Current learning rate: 0.00701 
2025-08-27 21:13:02.838427: train_loss -0.0152 
2025-08-27 21:13:02.850954: val_loss -0.0094 
2025-08-27 21:13:02.855114: Pseudo dice [np.float32(0.4548)] 
2025-08-27 21:13:02.863724: Epoch time: 25.04 s 
2025-08-27 21:13:02.866432: Yayy! New best EMA pseudo Dice: 0.33649998903274536 
2025-08-27 21:13:03.751827:  
2025-08-27 21:13:03.760133: Epoch 327 
2025-08-27 21:13:03.765476: Current learning rate: 0.007 
2025-08-27 21:13:28.660027: train_loss -0.0109 
2025-08-27 21:13:28.668125: val_loss -0.0226 
2025-08-27 21:13:28.672668: Pseudo dice [np.float32(0.4032)] 
2025-08-27 21:13:28.678341: Epoch time: 24.91 s 
2025-08-27 21:13:28.681738: Yayy! New best EMA pseudo Dice: 0.34310001134872437 
2025-08-27 21:13:29.532787:  
2025-08-27 21:13:29.541115: Epoch 328 
2025-08-27 21:13:29.545165: Current learning rate: 0.00699 
2025-08-27 21:13:54.624417: train_loss -0.0145 
2025-08-27 21:13:54.636113: val_loss 0.0023 
2025-08-27 21:13:54.640141: Pseudo dice [np.float32(0.0974)] 
2025-08-27 21:13:54.645942: Epoch time: 25.09 s 
2025-08-27 21:13:55.308570:  
2025-08-27 21:13:55.316876: Epoch 329 
2025-08-27 21:13:55.321061: Current learning rate: 0.00698 
2025-08-27 21:14:19.882798: train_loss -0.0117 
2025-08-27 21:14:19.890448: val_loss -0.0279 
2025-08-27 21:14:19.894542: Pseudo dice [np.float32(0.386)] 
2025-08-27 21:14:19.900255: Epoch time: 24.58 s 
2025-08-27 21:14:20.646337:  
2025-08-27 21:14:20.653618: Epoch 330 
2025-08-27 21:14:20.658751: Current learning rate: 0.00697 
2025-08-27 21:14:45.716428: train_loss -0.0195 
2025-08-27 21:14:45.728993: val_loss -0.0329 
2025-08-27 21:14:45.732832: Pseudo dice [np.float32(0.4022)] 
2025-08-27 21:14:45.738751: Epoch time: 25.07 s 
2025-08-27 21:14:46.398003:  
2025-08-27 21:14:46.405295: Epoch 331 
2025-08-27 21:14:46.412470: Current learning rate: 0.00696 
2025-08-27 21:15:11.521356: train_loss -0.0212 
2025-08-27 21:15:11.529497: val_loss -0.0272 
2025-08-27 21:15:11.538073: Pseudo dice [np.float32(0.3952)] 
2025-08-27 21:15:11.544453: Epoch time: 25.12 s 
2025-08-27 21:15:12.214510:  
2025-08-27 21:15:12.221666: Epoch 332 
2025-08-27 21:15:12.227328: Current learning rate: 0.00696 
2025-08-27 21:15:37.205350: train_loss -0.0205 
2025-08-27 21:15:37.213696: val_loss -0.0349 
2025-08-27 21:15:37.221809: Pseudo dice [np.float32(0.396)] 
2025-08-27 21:15:37.227510: Epoch time: 25.0 s 
2025-08-27 21:15:37.235207: Yayy! New best EMA pseudo Dice: 0.3449000120162964 
2025-08-27 21:15:38.252951:  
2025-08-27 21:15:38.261343: Epoch 333 
2025-08-27 21:15:38.268454: Current learning rate: 0.00695 
2025-08-27 21:16:03.381171: train_loss -0.0112 
2025-08-27 21:16:03.389652: val_loss -0.0222 
2025-08-27 21:16:03.393912: Pseudo dice [np.float32(0.4017)] 
2025-08-27 21:16:03.402701: Epoch time: 25.13 s 
2025-08-27 21:16:03.408888: Yayy! New best EMA pseudo Dice: 0.350600004196167 
2025-08-27 21:16:04.283098:  
2025-08-27 21:16:04.290385: Epoch 334 
2025-08-27 21:16:04.295733: Current learning rate: 0.00694 
2025-08-27 21:16:29.753353: train_loss -0.0158 
2025-08-27 21:16:29.761791: val_loss -0.0121 
2025-08-27 21:16:29.765929: Pseudo dice [np.float32(0.2325)] 
2025-08-27 21:16:29.773063: Epoch time: 25.47 s 
2025-08-27 21:16:30.459259:  
2025-08-27 21:16:30.467550: Epoch 335 
2025-08-27 21:16:30.474659: Current learning rate: 0.00693 
2025-08-27 21:16:55.629189: train_loss -0.0158 
2025-08-27 21:16:55.637976: val_loss -0.0275 
2025-08-27 21:16:55.645855: Pseudo dice [np.float32(0.2974)] 
2025-08-27 21:16:55.650501: Epoch time: 25.17 s 
2025-08-27 21:16:56.326749:  
2025-08-27 21:16:56.335302: Epoch 336 
2025-08-27 21:16:56.339251: Current learning rate: 0.00692 
2025-08-27 21:17:21.254771: train_loss -0.0217 
2025-08-27 21:17:21.263454: val_loss -0.0036 
2025-08-27 21:17:21.271770: Pseudo dice [np.float32(0.257)] 
2025-08-27 21:17:21.276229: Epoch time: 24.93 s 
2025-08-27 21:17:21.981493:  
2025-08-27 21:17:21.989753: Epoch 337 
2025-08-27 21:17:21.997292: Current learning rate: 0.00691 
2025-08-27 21:17:47.367917: train_loss -0.0156 
2025-08-27 21:17:47.376901: val_loss -0.0245 
2025-08-27 21:17:47.381216: Pseudo dice [np.float32(0.4852)] 
2025-08-27 21:17:47.389799: Epoch time: 25.39 s 
2025-08-27 21:17:48.077354:  
2025-08-27 21:17:48.082700: Epoch 338 
2025-08-27 21:17:48.089725: Current learning rate: 0.0069 
2025-08-27 21:18:13.603008: train_loss -0.0111 
2025-08-27 21:18:13.611232: val_loss -0.0345 
2025-08-27 21:18:13.615337: Pseudo dice [np.float32(0.3537)] 
2025-08-27 21:18:13.623432: Epoch time: 25.53 s 
2025-08-27 21:18:14.300534:  
2025-08-27 21:18:14.307744: Epoch 339 
2025-08-27 21:18:14.312905: Current learning rate: 0.00689 
2025-08-27 21:18:40.263091: train_loss -0.0098 
2025-08-27 21:18:40.271470: val_loss -0.007 
2025-08-27 21:18:40.279484: Pseudo dice [np.float32(0.2284)] 
2025-08-27 21:18:40.284422: Epoch time: 25.96 s 
2025-08-27 21:18:40.992585:  
2025-08-27 21:18:41.000892: Epoch 340 
2025-08-27 21:18:41.006255: Current learning rate: 0.00688 
2025-08-27 21:19:07.085633: train_loss -0.0248 
2025-08-27 21:19:07.098026: val_loss -0.0071 
2025-08-27 21:19:07.102505: Pseudo dice [np.float32(0.2104)] 
2025-08-27 21:19:07.109946: Epoch time: 26.1 s 
2025-08-27 21:19:07.781988:  
2025-08-27 21:19:07.787293: Epoch 341 
2025-08-27 21:19:07.794354: Current learning rate: 0.00687 
2025-08-27 21:19:33.266093: train_loss -0.022 
2025-08-27 21:19:33.274349: val_loss -0.0296 
2025-08-27 21:19:33.278570: Pseudo dice [np.float32(0.3464)] 
2025-08-27 21:19:33.284069: Epoch time: 25.49 s 
2025-08-27 21:19:33.959095:  
2025-08-27 21:19:33.967604: Epoch 342 
2025-08-27 21:19:33.974764: Current learning rate: 0.00686 
2025-08-27 21:19:59.562896: train_loss -0.0088 
2025-08-27 21:19:59.571437: val_loss -0.0163 
2025-08-27 21:19:59.579555: Pseudo dice [np.float32(0.3899)] 
2025-08-27 21:19:59.584241: Epoch time: 25.6 s 
2025-08-27 21:20:00.264348:  
2025-08-27 21:20:00.272828: Epoch 343 
2025-08-27 21:20:00.277143: Current learning rate: 0.00685 
2025-08-27 21:20:26.098767: train_loss -0.0081 
2025-08-27 21:20:26.106363: val_loss -0.0335 
2025-08-27 21:20:26.112561: Pseudo dice [np.float32(0.4077)] 
2025-08-27 21:20:26.118330: Epoch time: 25.83 s 
2025-08-27 21:20:26.798360:  
2025-08-27 21:20:26.803401: Epoch 344 
2025-08-27 21:20:26.810661: Current learning rate: 0.00684 
2025-08-27 21:20:52.007838: train_loss -0.0153 
2025-08-27 21:20:52.015140: val_loss -0.0309 
2025-08-27 21:20:52.023496: Pseudo dice [np.float32(0.4387)] 
2025-08-27 21:20:52.029206: Epoch time: 25.21 s 
2025-08-27 21:20:52.854540:  
2025-08-27 21:20:52.863675: Epoch 345 
2025-08-27 21:20:52.871009: Current learning rate: 0.00683 
2025-08-27 21:21:18.270524: train_loss -0.0155 
2025-08-27 21:21:18.278877: val_loss -0.0294 
2025-08-27 21:21:18.283728: Pseudo dice [np.float32(0.3246)] 
2025-08-27 21:21:18.291328: Epoch time: 25.42 s 
2025-08-27 21:21:18.960165:  
2025-08-27 21:21:18.968181: Epoch 346 
2025-08-27 21:21:18.972295: Current learning rate: 0.00682 
2025-08-27 21:21:44.388575: train_loss -0.0085 
2025-08-27 21:21:44.396626: val_loss -0.022 
2025-08-27 21:21:44.400790: Pseudo dice [np.float32(0.4316)] 
2025-08-27 21:21:44.406827: Epoch time: 25.43 s 
2025-08-27 21:21:44.413568: Yayy! New best EMA pseudo Dice: 0.3537999987602234 
2025-08-27 21:21:45.265593:  
2025-08-27 21:21:45.273497: Epoch 347 
2025-08-27 21:21:45.281971: Current learning rate: 0.00681 
2025-08-27 21:22:10.364416: train_loss -0.0167 
2025-08-27 21:22:10.377708: val_loss -0.0104 
2025-08-27 21:22:10.384758: Pseudo dice [np.float32(0.1565)] 
2025-08-27 21:22:10.389889: Epoch time: 25.1 s 
2025-08-27 21:22:11.066051:  
2025-08-27 21:22:11.074223: Epoch 348 
2025-08-27 21:22:11.078576: Current learning rate: 0.0068 
2025-08-27 21:22:36.256741: train_loss -0.0236 
2025-08-27 21:22:36.265054: val_loss -0.0234 
2025-08-27 21:22:36.269238: Pseudo dice [np.float32(0.3099)] 
2025-08-27 21:22:36.276402: Epoch time: 25.19 s 
2025-08-27 21:22:36.944809:  
2025-08-27 21:22:36.950146: Epoch 349 
2025-08-27 21:22:36.957307: Current learning rate: 0.0068 
2025-08-27 21:23:02.378995: train_loss -0.0125 
2025-08-27 21:23:02.391488: val_loss -0.0077 
2025-08-27 21:23:02.395677: Pseudo dice [np.float32(0.0845)] 
2025-08-27 21:23:02.402385: Epoch time: 25.44 s 
2025-08-27 21:23:03.296215:  
2025-08-27 21:23:03.301325: Epoch 350 
2025-08-27 21:23:03.308674: Current learning rate: 0.00679 
2025-08-27 21:23:28.583951: train_loss -0.0203 
2025-08-27 21:23:28.592361: val_loss -0.0022 
2025-08-27 21:23:28.600303: Pseudo dice [np.float32(0.1131)] 
2025-08-27 21:23:28.605283: Epoch time: 25.29 s 
2025-08-27 21:23:29.440103:  
2025-08-27 21:23:29.447318: Epoch 351 
2025-08-27 21:23:29.452492: Current learning rate: 0.00678 
2025-08-27 21:23:54.388879: train_loss -0.0216 
2025-08-27 21:23:54.401391: val_loss -0.0312 
2025-08-27 21:23:54.405571: Pseudo dice [np.float32(0.498)] 
2025-08-27 21:23:54.413513: Epoch time: 24.95 s 
2025-08-27 21:23:55.093699:  
2025-08-27 21:23:55.099035: Epoch 352 
2025-08-27 21:23:55.106122: Current learning rate: 0.00677 
2025-08-27 21:24:20.961237: train_loss -0.012 
2025-08-27 21:24:20.969596: val_loss -0.0096 
2025-08-27 21:24:20.973952: Pseudo dice [np.float32(0.2278)] 
2025-08-27 21:24:20.980539: Epoch time: 25.87 s 
2025-08-27 21:24:21.650382:  
2025-08-27 21:24:21.658890: Epoch 353 
2025-08-27 21:24:21.662893: Current learning rate: 0.00676 
2025-08-27 21:24:47.204139: train_loss -0.0201 
2025-08-27 21:24:47.216897: val_loss -0.0239 
2025-08-27 21:24:47.220863: Pseudo dice [np.float32(0.4274)] 
2025-08-27 21:24:47.229172: Epoch time: 25.55 s 
2025-08-27 21:24:47.905707:  
2025-08-27 21:24:47.914099: Epoch 354 
2025-08-27 21:24:47.921453: Current learning rate: 0.00675 
2025-08-27 21:25:13.159190: train_loss -0.0077 
2025-08-27 21:25:13.167593: val_loss -0.0389 
2025-08-27 21:25:13.172001: Pseudo dice [np.float32(0.3573)] 
2025-08-27 21:25:13.179644: Epoch time: 25.25 s 
2025-08-27 21:25:13.860999:  
2025-08-27 21:25:13.869282: Epoch 355 
2025-08-27 21:25:13.876745: Current learning rate: 0.00674 
2025-08-27 21:25:39.548708: train_loss -0.0202 
2025-08-27 21:25:39.556709: val_loss -0.0418 
2025-08-27 21:25:39.560814: Pseudo dice [np.float32(0.3966)] 
2025-08-27 21:25:39.569358: Epoch time: 25.69 s 
2025-08-27 21:25:40.270633:  
2025-08-27 21:25:40.279164: Epoch 356 
2025-08-27 21:25:40.283324: Current learning rate: 0.00673 
2025-08-27 21:26:05.641053: train_loss -0.0095 
2025-08-27 21:26:05.649191: val_loss -0.0323 
2025-08-27 21:26:05.657186: Pseudo dice [np.float32(0.3783)] 
2025-08-27 21:26:05.661302: Epoch time: 25.37 s 
2025-08-27 21:26:06.480104:  
2025-08-27 21:26:06.487301: Epoch 357 
2025-08-27 21:26:06.492705: Current learning rate: 0.00672 
2025-08-27 21:26:31.575102: train_loss -0.0168 
2025-08-27 21:26:31.583313: val_loss -0.024 
2025-08-27 21:26:31.587692: Pseudo dice [np.float32(0.4645)] 
2025-08-27 21:26:31.595537: Epoch time: 25.1 s 
2025-08-27 21:26:32.293358:  
2025-08-27 21:26:32.301812: Epoch 358 
2025-08-27 21:26:32.305987: Current learning rate: 0.00671 
2025-08-27 21:26:58.009782: train_loss -0.0231 
2025-08-27 21:26:58.018049: val_loss -0.0342 
2025-08-27 21:26:58.026415: Pseudo dice [np.float32(0.384)] 
2025-08-27 21:26:58.031540: Epoch time: 25.72 s 
2025-08-27 21:26:58.719810:  
2025-08-27 21:26:58.728100: Epoch 359 
2025-08-27 21:26:58.732247: Current learning rate: 0.0067 
2025-08-27 21:27:24.511207: train_loss -0.018 
2025-08-27 21:27:24.519568: val_loss -0.0223 
2025-08-27 21:27:24.523677: Pseudo dice [np.float32(0.2823)] 
2025-08-27 21:27:24.530371: Epoch time: 25.79 s 
2025-08-27 21:27:25.217152:  
2025-08-27 21:27:25.225431: Epoch 360 
2025-08-27 21:27:25.229831: Current learning rate: 0.00669 
2025-08-27 21:27:50.445714: train_loss -0.0191 
2025-08-27 21:27:50.457778: val_loss -0.0212 
2025-08-27 21:27:50.465049: Pseudo dice [np.float32(0.1999)] 
2025-08-27 21:27:50.471048: Epoch time: 25.23 s 
2025-08-27 21:27:51.184742:  
2025-08-27 21:27:51.193034: Epoch 361 
2025-08-27 21:27:51.197081: Current learning rate: 0.00668 
2025-08-27 21:28:16.926011: train_loss -0.0188 
2025-08-27 21:28:16.933153: val_loss -0.0239 
2025-08-27 21:28:16.938915: Pseudo dice [np.float32(0.3545)] 
2025-08-27 21:28:16.943591: Epoch time: 25.74 s 
2025-08-27 21:28:17.630854:  
2025-08-27 21:28:17.636076: Epoch 362 
2025-08-27 21:28:17.640139: Current learning rate: 0.00667 
2025-08-27 21:28:43.281767: train_loss -0.0191 
2025-08-27 21:28:43.289805: val_loss -0.0292 
2025-08-27 21:28:43.294497: Pseudo dice [np.float32(0.3435)] 
2025-08-27 21:28:43.301102: Epoch time: 25.65 s 
2025-08-27 21:28:44.146428:  
2025-08-27 21:28:44.154186: Epoch 363 
2025-08-27 21:28:44.158338: Current learning rate: 0.00666 
2025-08-27 21:29:09.482997: train_loss -0.0089 
2025-08-27 21:29:09.491226: val_loss -0.0204 
2025-08-27 21:29:09.495405: Pseudo dice [np.float32(0.2685)] 
2025-08-27 21:29:09.502029: Epoch time: 25.34 s 
2025-08-27 21:29:10.209338:  
2025-08-27 21:29:10.217912: Epoch 364 
2025-08-27 21:29:10.226317: Current learning rate: 0.00665 
2025-08-27 21:29:36.522121: train_loss -0.027 
2025-08-27 21:29:36.526294: val_loss -0.0052 
2025-08-27 21:29:36.534653: Pseudo dice [np.float32(0.2487)] 
2025-08-27 21:29:36.540335: Epoch time: 26.31 s 
2025-08-27 21:29:37.223922:  
2025-08-27 21:29:37.232149: Epoch 365 
2025-08-27 21:29:37.236323: Current learning rate: 0.00665 
2025-08-27 21:30:02.915659: train_loss -0.0215 
2025-08-27 21:30:02.927644: val_loss -0.036 
2025-08-27 21:30:02.931827: Pseudo dice [np.float32(0.4796)] 
2025-08-27 21:30:02.939101: Epoch time: 25.69 s 
2025-08-27 21:30:03.628359:  
2025-08-27 21:30:03.636701: Epoch 366 
2025-08-27 21:30:03.641919: Current learning rate: 0.00664 
2025-08-27 21:30:29.120454: train_loss -0.0123 
2025-08-27 21:30:29.128822: val_loss -0.0164 
2025-08-27 21:30:29.132942: Pseudo dice [np.float32(0.3115)] 
2025-08-27 21:30:29.139580: Epoch time: 25.49 s 
2025-08-27 21:30:29.834699:  
2025-08-27 21:30:29.843029: Epoch 367 
2025-08-27 21:30:29.847083: Current learning rate: 0.00663 
2025-08-27 21:30:55.717837: train_loss -0.018 
2025-08-27 21:30:55.730357: val_loss -0.0296 
2025-08-27 21:30:55.734678: Pseudo dice [np.float32(0.4467)] 
2025-08-27 21:30:55.743514: Epoch time: 25.88 s 
2025-08-27 21:30:56.438231:  
2025-08-27 21:30:56.444672: Epoch 368 
2025-08-27 21:30:56.452776: Current learning rate: 0.00662 
2025-08-27 21:31:21.797432: train_loss -0.0241 
2025-08-27 21:31:21.804541: val_loss -0.0084 
2025-08-27 21:31:21.810648: Pseudo dice [np.float32(0.1068)] 
2025-08-27 21:31:21.815646: Epoch time: 25.36 s 
2025-08-27 21:31:22.512669:  
2025-08-27 21:31:22.520774: Epoch 369 
2025-08-27 21:31:22.525820: Current learning rate: 0.00661 
2025-08-27 21:31:48.195181: train_loss -0.0126 
2025-08-27 21:31:48.205594: val_loss -0.0153 
2025-08-27 21:31:48.210745: Pseudo dice [np.float32(0.2922)] 
2025-08-27 21:31:48.215920: Epoch time: 25.68 s 
2025-08-27 21:31:48.917834:  
2025-08-27 21:31:48.924954: Epoch 370 
2025-08-27 21:31:48.929183: Current learning rate: 0.0066 
2025-08-27 21:32:14.151402: train_loss -0.0292 
2025-08-27 21:32:14.159731: val_loss -0.0277 
2025-08-27 21:32:14.163800: Pseudo dice [np.float32(0.3924)] 
2025-08-27 21:32:14.171850: Epoch time: 25.24 s 
2025-08-27 21:32:14.825762:  
2025-08-27 21:32:14.834060: Epoch 371 
2025-08-27 21:32:14.839476: Current learning rate: 0.00659 
2025-08-27 21:32:39.755021: train_loss -0.0157 
2025-08-27 21:32:39.763699: val_loss -0.01 
2025-08-27 21:32:39.767572: Pseudo dice [np.float32(0.1399)] 
2025-08-27 21:32:39.772432: Epoch time: 24.93 s 
2025-08-27 21:32:40.418565:  
2025-08-27 21:32:40.422385: Epoch 372 
2025-08-27 21:32:40.431278: Current learning rate: 0.00658 
2025-08-27 21:33:04.867938: train_loss -0.0243 
2025-08-27 21:33:04.879970: val_loss -0.044 
2025-08-27 21:33:04.884269: Pseudo dice [np.float32(0.3708)] 
2025-08-27 21:33:04.891150: Epoch time: 24.45 s 
2025-08-27 21:33:05.535230:  
2025-08-27 21:33:05.543880: Epoch 373 
2025-08-27 21:33:05.547519: Current learning rate: 0.00657 
2025-08-27 21:33:31.252285: train_loss -0.0156 
2025-08-27 21:33:31.260646: val_loss -0.0311 
2025-08-27 21:33:31.268627: Pseudo dice [np.float32(0.2986)] 
2025-08-27 21:33:31.273124: Epoch time: 25.72 s 
2025-08-27 21:33:31.915783:  
2025-08-27 21:33:31.924117: Epoch 374 
2025-08-27 21:33:31.932112: Current learning rate: 0.00656 
2025-08-27 21:33:56.969649: train_loss -0.0224 
2025-08-27 21:33:56.978904: val_loss -0.039 
2025-08-27 21:33:56.984067: Pseudo dice [np.float32(0.3656)] 
2025-08-27 21:33:56.991284: Epoch time: 25.05 s 
2025-08-27 21:33:57.795425:  
2025-08-27 21:33:57.799646: Epoch 375 
2025-08-27 21:33:57.808140: Current learning rate: 0.00655 
2025-08-27 21:34:22.032143: train_loss -0.0263 
2025-08-27 21:34:22.040514: val_loss -0.0436 
2025-08-27 21:34:22.044625: Pseudo dice [np.float32(0.4485)] 
2025-08-27 21:34:22.051765: Epoch time: 24.24 s 
2025-08-27 21:34:22.691177:  
2025-08-27 21:34:22.695297: Epoch 376 
2025-08-27 21:34:22.703685: Current learning rate: 0.00654 
2025-08-27 21:34:48.305915: train_loss -0.0306 
2025-08-27 21:34:48.316688: val_loss -0.0262 
2025-08-27 21:34:48.320905: Pseudo dice [np.float32(0.3043)] 
2025-08-27 21:34:48.326869: Epoch time: 25.62 s 
2025-08-27 21:34:48.979848:  
2025-08-27 21:34:48.984510: Epoch 377 
2025-08-27 21:34:48.992449: Current learning rate: 0.00653 
2025-08-27 21:35:13.112254: train_loss -0.0187 
2025-08-27 21:35:13.120633: val_loss -0.0046 
2025-08-27 21:35:13.124795: Pseudo dice [np.float32(0.0852)] 
2025-08-27 21:35:13.131113: Epoch time: 24.14 s 
2025-08-27 21:35:13.784322:  
2025-08-27 21:35:13.792467: Epoch 378 
2025-08-27 21:35:13.796646: Current learning rate: 0.00652 
2025-08-27 21:35:37.590879: train_loss -0.0211 
2025-08-27 21:35:37.599111: val_loss -0.0435 
2025-08-27 21:35:37.603331: Pseudo dice [np.float32(0.4884)] 
2025-08-27 21:35:37.609389: Epoch time: 23.81 s 
2025-08-27 21:35:38.262447:  
2025-08-27 21:35:38.270751: Epoch 379 
2025-08-27 21:35:38.279108: Current learning rate: 0.00651 
2025-08-27 21:36:03.825422: train_loss -0.0169 
2025-08-27 21:36:03.833723: val_loss -0.0171 
2025-08-27 21:36:03.837895: Pseudo dice [np.float32(0.214)] 
2025-08-27 21:36:03.846957: Epoch time: 25.56 s 
2025-08-27 21:36:04.496935:  
2025-08-27 21:36:04.505289: Epoch 380 
2025-08-27 21:36:04.509439: Current learning rate: 0.0065 
2025-08-27 21:36:29.307654: train_loss -0.0405 
2025-08-27 21:36:29.314783: val_loss -0.0398 
2025-08-27 21:36:29.319980: Pseudo dice [np.float32(0.3973)] 
2025-08-27 21:36:29.325980: Epoch time: 24.81 s 
2025-08-27 21:36:30.180865:  
2025-08-27 21:36:30.189174: Epoch 381 
2025-08-27 21:36:30.193674: Current learning rate: 0.00649 
2025-08-27 21:36:54.801574: train_loss -0.0165 
2025-08-27 21:36:54.813918: val_loss -0.0087 
2025-08-27 21:36:54.818878: Pseudo dice [np.float32(0.1943)] 
2025-08-27 21:36:54.827839: Epoch time: 24.62 s 
2025-08-27 21:36:55.514741:  
2025-08-27 21:36:55.522961: Epoch 382 
2025-08-27 21:36:55.527057: Current learning rate: 0.00648 
2025-08-27 21:37:20.939958: train_loss -0.0154 
2025-08-27 21:37:20.948256: val_loss -0.0352 
2025-08-27 21:37:20.956636: Pseudo dice [np.float32(0.4457)] 
2025-08-27 21:37:20.961582: Epoch time: 25.43 s 
2025-08-27 21:37:21.628084:  
2025-08-27 21:37:21.636452: Epoch 383 
2025-08-27 21:37:21.641016: Current learning rate: 0.00648 
2025-08-27 21:37:46.890922: train_loss -0.0196 
2025-08-27 21:37:46.903306: val_loss -0.0371 
2025-08-27 21:37:46.908884: Pseudo dice [np.float32(0.4233)] 
2025-08-27 21:37:46.917034: Epoch time: 25.26 s 
2025-08-27 21:37:47.599845:  
2025-08-27 21:37:47.604323: Epoch 384 
2025-08-27 21:37:47.612456: Current learning rate: 0.00647 
2025-08-27 21:38:12.986632: train_loss -0.0313 
2025-08-27 21:38:12.995980: val_loss -0.0175 
2025-08-27 21:38:13.000334: Pseudo dice [np.float32(0.162)] 
2025-08-27 21:38:13.006499: Epoch time: 25.39 s 
2025-08-27 21:38:13.680089:  
2025-08-27 21:38:13.688412: Epoch 385 
2025-08-27 21:38:13.692559: Current learning rate: 0.00646 
2025-08-27 21:38:39.076249: train_loss -0.0388 
2025-08-27 21:38:39.085022: val_loss -0.0182 
2025-08-27 21:38:39.088744: Pseudo dice [np.float32(0.2138)] 
2025-08-27 21:38:39.096025: Epoch time: 25.4 s 
2025-08-27 21:38:39.781112:  
2025-08-27 21:38:39.785300: Epoch 386 
2025-08-27 21:38:39.793673: Current learning rate: 0.00645 
2025-08-27 21:39:04.572522: train_loss -0.03 
2025-08-27 21:39:04.585041: val_loss -0.0043 
2025-08-27 21:39:04.589258: Pseudo dice [np.float32(0.0836)] 
2025-08-27 21:39:04.596297: Epoch time: 24.8 s 
2025-08-27 21:39:05.269061:  
2025-08-27 21:39:05.277402: Epoch 387 
2025-08-27 21:39:05.281576: Current learning rate: 0.00644 
2025-08-27 21:39:29.964836: train_loss -0.0309 
2025-08-27 21:39:29.972903: val_loss -0.0342 
2025-08-27 21:39:29.977385: Pseudo dice [np.float32(0.4209)] 
2025-08-27 21:39:29.984324: Epoch time: 24.7 s 
2025-08-27 21:39:30.662094:  
2025-08-27 21:39:30.669729: Epoch 388 
2025-08-27 21:39:30.675578: Current learning rate: 0.00643 
2025-08-27 21:39:55.932142: train_loss -0.0272 
2025-08-27 21:39:55.944770: val_loss -0.0229 
2025-08-27 21:39:55.948855: Pseudo dice [np.float32(0.2621)] 
2025-08-27 21:39:55.955970: Epoch time: 25.27 s 
2025-08-27 21:39:56.620328:  
2025-08-27 21:39:56.628678: Epoch 389 
2025-08-27 21:39:56.632820: Current learning rate: 0.00642 
2025-08-27 21:40:21.853834: train_loss -0.0408 
2025-08-27 21:40:21.862198: val_loss -0.0313 
2025-08-27 21:40:21.870549: Pseudo dice [np.float32(0.3853)] 
2025-08-27 21:40:21.874780: Epoch time: 25.23 s 
2025-08-27 21:40:22.550683:  
2025-08-27 21:40:22.559036: Epoch 390 
2025-08-27 21:40:22.562864: Current learning rate: 0.00641 
2025-08-27 21:40:47.692474: train_loss -0.0374 
2025-08-27 21:40:47.700775: val_loss -0.0233 
2025-08-27 21:40:47.709143: Pseudo dice [np.float32(0.1946)] 
2025-08-27 21:40:47.715171: Epoch time: 25.14 s 
2025-08-27 21:40:48.405400:  
2025-08-27 21:40:48.413958: Epoch 391 
2025-08-27 21:40:48.418406: Current learning rate: 0.0064 
2025-08-27 21:41:14.189757: train_loss -0.0286 
2025-08-27 21:41:14.198120: val_loss -0.0217 
2025-08-27 21:41:14.205928: Pseudo dice [np.float32(0.3559)] 
2025-08-27 21:41:14.211134: Epoch time: 25.78 s 
2025-08-27 21:41:14.890142:  
2025-08-27 21:41:14.898480: Epoch 392 
2025-08-27 21:41:14.902657: Current learning rate: 0.00639 
2025-08-27 21:41:40.483575: train_loss -0.0152 
2025-08-27 21:41:40.491296: val_loss -0.0282 
2025-08-27 21:41:40.494828: Pseudo dice [np.float32(0.3667)] 
2025-08-27 21:41:40.503308: Epoch time: 25.59 s 
2025-08-27 21:41:41.337371:  
2025-08-27 21:41:41.345726: Epoch 393 
2025-08-27 21:41:41.350122: Current learning rate: 0.00638 
2025-08-27 21:42:06.483456: train_loss -0.0203 
2025-08-27 21:42:06.495821: val_loss -0.0174 
2025-08-27 21:42:06.499994: Pseudo dice [np.float32(0.1685)] 
2025-08-27 21:42:06.506123: Epoch time: 25.15 s 
2025-08-27 21:42:07.188144:  
2025-08-27 21:42:07.196518: Epoch 394 
2025-08-27 21:42:07.200984: Current learning rate: 0.00637 
2025-08-27 21:42:33.105753: train_loss -0.0298 
2025-08-27 21:42:33.114048: val_loss -0.0048 
2025-08-27 21:42:33.118602: Pseudo dice [np.float32(0.1745)] 
2025-08-27 21:42:33.126376: Epoch time: 25.92 s 
2025-08-27 21:42:33.823105:  
2025-08-27 21:42:33.831451: Epoch 395 
2025-08-27 21:42:33.835596: Current learning rate: 0.00636 
2025-08-27 21:42:59.081902: train_loss -0.0276 
2025-08-27 21:42:59.094149: val_loss -0.044 
2025-08-27 21:42:59.098666: Pseudo dice [np.float32(0.3963)] 
2025-08-27 21:42:59.107491: Epoch time: 25.26 s 
2025-08-27 21:42:59.803194:  
2025-08-27 21:42:59.811721: Epoch 396 
2025-08-27 21:42:59.815690: Current learning rate: 0.00635 
2025-08-27 21:43:25.341504: train_loss -0.0304 
2025-08-27 21:43:25.349536: val_loss -0.026 
2025-08-27 21:43:25.358623: Pseudo dice [np.float32(0.2673)] 
2025-08-27 21:43:25.364043: Epoch time: 25.54 s 
2025-08-27 21:43:26.071182:  
2025-08-27 21:43:26.080769: Epoch 397 
2025-08-27 21:43:26.083609: Current learning rate: 0.00634 
2025-08-27 21:43:51.988618: train_loss -0.0365 
2025-08-27 21:43:51.997159: val_loss -0.0253 
2025-08-27 21:43:52.001129: Pseudo dice [np.float32(0.2626)] 
2025-08-27 21:43:52.010276: Epoch time: 25.92 s 
2025-08-27 21:43:52.714415:  
2025-08-27 21:43:52.723043: Epoch 398 
2025-08-27 21:43:52.731074: Current learning rate: 0.00633 
2025-08-27 21:44:18.302390: train_loss -0.0374 
2025-08-27 21:44:18.310739: val_loss -0.0273 
2025-08-27 21:44:18.315274: Pseudo dice [np.float32(0.2078)] 
2025-08-27 21:44:18.324137: Epoch time: 25.59 s 
2025-08-27 21:44:19.182429:  
2025-08-27 21:44:19.186997: Epoch 399 
2025-08-27 21:44:19.195279: Current learning rate: 0.00632 
2025-08-27 21:44:44.541421: train_loss -0.0166 
2025-08-27 21:44:44.549432: val_loss -0.0202 
2025-08-27 21:44:44.557803: Pseudo dice [np.float32(0.1872)] 
2025-08-27 21:44:44.563305: Epoch time: 25.36 s 
2025-08-27 21:44:45.462840:  
2025-08-27 21:44:45.467382: Epoch 400 
2025-08-27 21:44:45.475731: Current learning rate: 0.00631 
2025-08-27 21:45:11.418230: train_loss -0.0261 
2025-08-27 21:45:11.430453: val_loss -0.0118 
2025-08-27 21:45:11.434606: Pseudo dice [np.float32(0.255)] 
2025-08-27 21:45:11.441813: Epoch time: 25.96 s 
2025-08-27 21:45:12.127282:  
2025-08-27 21:45:12.135619: Epoch 401 
2025-08-27 21:45:12.139463: Current learning rate: 0.0063 
2025-08-27 21:45:37.740014: train_loss -0.0304 
2025-08-27 21:45:37.748387: val_loss -0.0252 
2025-08-27 21:45:37.756712: Pseudo dice [np.float32(0.2726)] 
2025-08-27 21:45:37.761701: Epoch time: 25.61 s 
2025-08-27 21:45:38.436890:  
2025-08-27 21:45:38.445051: Epoch 402 
2025-08-27 21:45:38.449089: Current learning rate: 0.0063 
2025-08-27 21:46:03.536889: train_loss -0.0371 
2025-08-27 21:46:03.545051: val_loss -0.0765 
2025-08-27 21:46:03.553727: Pseudo dice [np.float32(0.4924)] 
2025-08-27 21:46:03.560058: Epoch time: 25.1 s 
2025-08-27 21:46:04.237589:  
2025-08-27 21:46:04.245662: Epoch 403 
2025-08-27 21:46:04.249917: Current learning rate: 0.00629 
2025-08-27 21:46:29.550340: train_loss -0.0398 
2025-08-27 21:46:29.558722: val_loss -0.043 
2025-08-27 21:46:29.562862: Pseudo dice [np.float32(0.4074)] 
2025-08-27 21:46:29.571746: Epoch time: 25.31 s 
2025-08-27 21:46:30.284163:  
2025-08-27 21:46:30.292495: Epoch 404 
2025-08-27 21:46:30.296883: Current learning rate: 0.00628 
2025-08-27 21:46:55.963938: train_loss -0.0282 
2025-08-27 21:46:55.976773: val_loss -0.0494 
2025-08-27 21:46:55.980962: Pseudo dice [np.float32(0.5017)] 
2025-08-27 21:46:55.988775: Epoch time: 25.68 s 
2025-08-27 21:46:56.848097:  
2025-08-27 21:46:56.856520: Epoch 405 
2025-08-27 21:46:56.861001: Current learning rate: 0.00627 
2025-08-27 21:47:22.328087: train_loss -0.0353 
2025-08-27 21:47:22.336124: val_loss -0.0416 
2025-08-27 21:47:22.344198: Pseudo dice [np.float32(0.2222)] 
2025-08-27 21:47:22.348703: Epoch time: 25.48 s 
2025-08-27 21:47:23.024290:  
2025-08-27 21:47:23.032669: Epoch 406 
2025-08-27 21:47:23.036821: Current learning rate: 0.00626 
2025-08-27 21:47:48.412537: train_loss -0.0268 
2025-08-27 21:47:48.424655: val_loss -0.01 
2025-08-27 21:47:48.428822: Pseudo dice [np.float32(0.1087)] 
2025-08-27 21:47:48.435000: Epoch time: 25.39 s 
2025-08-27 21:47:49.112877:  
2025-08-27 21:47:49.121206: Epoch 407 
2025-08-27 21:47:49.125669: Current learning rate: 0.00625 
2025-08-27 21:48:14.263255: train_loss -0.0346 
2025-08-27 21:48:14.271370: val_loss -0.0412 
2025-08-27 21:48:14.275524: Pseudo dice [np.float32(0.3357)] 
2025-08-27 21:48:14.283519: Epoch time: 25.15 s 
2025-08-27 21:48:14.988755:  
2025-08-27 21:48:14.997364: Epoch 408 
2025-08-27 21:48:15.001231: Current learning rate: 0.00624 
2025-08-27 21:48:40.751966: train_loss -0.033 
2025-08-27 21:48:40.763986: val_loss -0.025 
2025-08-27 21:48:40.768926: Pseudo dice [np.float32(0.3136)] 
2025-08-27 21:48:40.774662: Epoch time: 25.76 s 
2025-08-27 21:48:41.465106:  
2025-08-27 21:48:41.473654: Epoch 409 
2025-08-27 21:48:41.478133: Current learning rate: 0.00623 
2025-08-27 21:49:06.970890: train_loss -0.0254 
2025-08-27 21:49:06.982337: val_loss -0.017 
2025-08-27 21:49:06.986414: Pseudo dice [np.float32(0.2006)] 
2025-08-27 21:49:06.992795: Epoch time: 25.51 s 
2025-08-27 21:49:07.712134:  
2025-08-27 21:49:07.720513: Epoch 410 
2025-08-27 21:49:07.724709: Current learning rate: 0.00622 
2025-08-27 21:49:33.116941: train_loss 0.0051 
2025-08-27 21:49:33.125347: val_loss -0.0328 
2025-08-27 21:49:33.133469: Pseudo dice [np.float32(0.3485)] 
2025-08-27 21:49:33.139114: Epoch time: 25.41 s 
2025-08-27 21:49:33.971737:  
2025-08-27 21:49:33.975915: Epoch 411 
2025-08-27 21:49:33.984274: Current learning rate: 0.00621 
2025-08-27 21:49:59.155406: train_loss -0.018 
2025-08-27 21:49:59.163644: val_loss -0.0291 
2025-08-27 21:49:59.171853: Pseudo dice [np.float32(0.2533)] 
2025-08-27 21:49:59.177226: Epoch time: 25.19 s 
2025-08-27 21:49:59.835048:  
2025-08-27 21:49:59.843674: Epoch 412 
2025-08-27 21:49:59.847829: Current learning rate: 0.0062 
2025-08-27 21:50:25.828025: train_loss -0.0234 
2025-08-27 21:50:25.836276: val_loss -0.0051 
2025-08-27 21:50:25.840120: Pseudo dice [np.float32(0.1642)] 
2025-08-27 21:50:25.848323: Epoch time: 25.99 s 
2025-08-27 21:50:26.507550:  
2025-08-27 21:50:26.516101: Epoch 413 
2025-08-27 21:50:26.520309: Current learning rate: 0.00619 
2025-08-27 21:50:51.820259: train_loss -0.0037 
2025-08-27 21:50:51.832761: val_loss -0.0167 
2025-08-27 21:50:51.836916: Pseudo dice [np.float32(0.2752)] 
2025-08-27 21:50:51.846151: Epoch time: 25.32 s 
2025-08-27 21:50:52.529621:  
2025-08-27 21:50:52.537626: Epoch 414 
2025-08-27 21:50:52.542072: Current learning rate: 0.00618 
2025-08-27 21:51:17.746415: train_loss -0.0061 
2025-08-27 21:51:17.754591: val_loss -0.0119 
2025-08-27 21:51:17.762830: Pseudo dice [np.float32(0.2588)] 
2025-08-27 21:51:17.767064: Epoch time: 25.22 s 
2025-08-27 21:51:18.450974:  
2025-08-27 21:51:18.459346: Epoch 415 
2025-08-27 21:51:18.467680: Current learning rate: 0.00617 
2025-08-27 21:51:44.239241: train_loss -0.0135 
2025-08-27 21:51:44.247666: val_loss -0.0243 
2025-08-27 21:51:44.255615: Pseudo dice [np.float32(0.3643)] 
2025-08-27 21:51:44.260192: Epoch time: 25.79 s 
2025-08-27 21:51:44.935775:  
2025-08-27 21:51:44.944120: Epoch 416 
2025-08-27 21:51:44.948493: Current learning rate: 0.00616 
2025-08-27 21:52:10.299286: train_loss -0.014 
2025-08-27 21:52:10.311411: val_loss -0.0116 
2025-08-27 21:52:10.315629: Pseudo dice [np.float32(0.333)] 
2025-08-27 21:52:10.322362: Epoch time: 25.36 s 
2025-08-27 21:52:10.987017:  
2025-08-27 21:52:10.997098: Epoch 417 
2025-08-27 21:52:11.003411: Current learning rate: 0.00615 
2025-08-27 21:52:36.321417: train_loss -0.0122 
2025-08-27 21:52:36.328745: val_loss -0.0195 
2025-08-27 21:52:36.332839: Pseudo dice [np.float32(0.312)] 
2025-08-27 21:52:36.341924: Epoch time: 25.33 s 
2025-08-27 21:52:37.008588:  
2025-08-27 21:52:37.017258: Epoch 418 
2025-08-27 21:52:37.022362: Current learning rate: 0.00614 
2025-08-27 21:53:02.609349: train_loss -0.0198 
2025-08-27 21:53:02.621665: val_loss -0.0078 
2025-08-27 21:53:02.625826: Pseudo dice [np.float32(0.1344)] 
2025-08-27 21:53:02.632896: Epoch time: 25.6 s 
2025-08-27 21:53:03.301816:  
2025-08-27 21:53:03.310169: Epoch 419 
2025-08-27 21:53:03.314310: Current learning rate: 0.00613 
2025-08-27 21:53:28.910409: train_loss -0.0162 
2025-08-27 21:53:28.914923: val_loss -0.0237 
2025-08-27 21:53:28.923246: Pseudo dice [np.float32(0.3566)] 
2025-08-27 21:53:28.930030: Epoch time: 25.61 s 
2025-08-27 21:53:29.582013:  
2025-08-27 21:53:29.590348: Epoch 420 
2025-08-27 21:53:29.594513: Current learning rate: 0.00612 
2025-08-27 21:53:55.365982: train_loss -0.0213 
2025-08-27 21:53:55.378703: val_loss -0.0268 
2025-08-27 21:53:55.383002: Pseudo dice [np.float32(0.2923)] 
2025-08-27 21:53:55.390638: Epoch time: 25.78 s 
2025-08-27 21:53:56.046110:  
2025-08-27 21:53:56.054180: Epoch 421 
2025-08-27 21:53:56.062547: Current learning rate: 0.00612 
2025-08-27 21:54:21.454741: train_loss -0.0219 
2025-08-27 21:54:21.462929: val_loss -0.0328 
2025-08-27 21:54:21.471215: Pseudo dice [np.float32(0.4587)] 
2025-08-27 21:54:21.476215: Epoch time: 25.41 s 
2025-08-27 21:54:22.138533:  
2025-08-27 21:54:22.142726: Epoch 422 
2025-08-27 21:54:22.151027: Current learning rate: 0.00611 
2025-08-27 21:54:47.864527: train_loss -0.0186 
2025-08-27 21:54:47.872552: val_loss -0.0017 
2025-08-27 21:54:47.876712: Pseudo dice [np.float32(0.1333)] 
2025-08-27 21:54:47.885087: Epoch time: 25.73 s 
2025-08-27 21:54:48.552911:  
2025-08-27 21:54:48.561198: Epoch 423 
2025-08-27 21:54:48.569039: Current learning rate: 0.0061 
2025-08-27 21:55:14.271863: train_loss -0.0099 
2025-08-27 21:55:14.278388: val_loss -0.0103 
2025-08-27 21:55:14.282565: Pseudo dice [np.float32(0.3407)] 
2025-08-27 21:55:14.292028: Epoch time: 25.72 s 
2025-08-27 21:55:14.978794:  
2025-08-27 21:55:14.987378: Epoch 424 
2025-08-27 21:55:14.991379: Current learning rate: 0.00609 
2025-08-27 21:55:40.338492: train_loss -0.0324 
2025-08-27 21:55:40.346845: val_loss -0.0288 
2025-08-27 21:55:40.355214: Pseudo dice [np.float32(0.3009)] 
2025-08-27 21:55:40.367615: Epoch time: 25.36 s 
2025-08-27 21:55:41.100697:  
2025-08-27 21:55:41.109035: Epoch 425 
2025-08-27 21:55:41.113197: Current learning rate: 0.00608 
2025-08-27 21:56:06.956450: train_loss -0.0436 
2025-08-27 21:56:06.968161: val_loss -0.0293 
2025-08-27 21:56:06.976473: Pseudo dice [np.float32(0.2123)] 
2025-08-27 21:56:06.984841: Epoch time: 25.86 s 
2025-08-27 21:56:07.708504:  
2025-08-27 21:56:07.716957: Epoch 426 
2025-08-27 21:56:07.721890: Current learning rate: 0.00607 
2025-08-27 21:56:33.690652: train_loss -0.0314 
2025-08-27 21:56:33.694857: val_loss -0.0162 
2025-08-27 21:56:33.703195: Pseudo dice [np.float32(0.327)] 
2025-08-27 21:56:33.709143: Epoch time: 25.98 s 
2025-08-27 21:56:34.337152:  
2025-08-27 21:56:34.345494: Epoch 427 
2025-08-27 21:56:34.349923: Current learning rate: 0.00606 
2025-08-27 21:56:58.716431: train_loss -0.0072 
2025-08-27 21:56:58.728472: val_loss -0.0103 
2025-08-27 21:56:58.732578: Pseudo dice [np.float32(0.18)] 
2025-08-27 21:56:58.740628: Epoch time: 24.38 s 
2025-08-27 21:56:59.374639:  
2025-08-27 21:56:59.383322: Epoch 428 
2025-08-27 21:56:59.387159: Current learning rate: 0.00605 
2025-08-27 21:57:24.132804: train_loss -0.0451 
2025-08-27 21:57:24.141047: val_loss -0.0449 
2025-08-27 21:57:24.145214: Pseudo dice [np.float32(0.3909)] 
2025-08-27 21:57:24.153310: Epoch time: 24.76 s 
2025-08-27 21:57:24.783354:  
2025-08-27 21:57:24.791689: Epoch 429 
2025-08-27 21:57:24.796067: Current learning rate: 0.00604 
2025-08-27 21:57:49.299749: train_loss -0.0419 
2025-08-27 21:57:49.307863: val_loss -0.0333 
2025-08-27 21:57:49.316168: Pseudo dice [np.float32(0.2538)] 
2025-08-27 21:57:49.322257: Epoch time: 24.52 s 
2025-08-27 21:57:49.983928:  
2025-08-27 21:57:49.994193: Epoch 430 
2025-08-27 21:57:50.002216: Current learning rate: 0.00603 
2025-08-27 21:58:15.217332: train_loss -0.0282 
2025-08-27 21:58:15.225682: val_loss -0.0374 
2025-08-27 21:58:15.229530: Pseudo dice [np.float32(0.3043)] 
2025-08-27 21:58:15.237557: Epoch time: 25.24 s 
2025-08-27 21:58:15.863514:  
2025-08-27 21:58:15.871868: Epoch 431 
2025-08-27 21:58:15.876282: Current learning rate: 0.00602 
2025-08-27 21:58:40.684350: train_loss -0.0525 
2025-08-27 21:58:40.692491: val_loss 0.0041 
2025-08-27 21:58:40.696674: Pseudo dice [np.float32(0.0804)] 
2025-08-27 21:58:40.704535: Epoch time: 24.82 s 
2025-08-27 21:58:41.351435:  
2025-08-27 21:58:41.355568: Epoch 432 
2025-08-27 21:58:41.359816: Current learning rate: 0.00601 
2025-08-27 21:59:06.088895: train_loss -0.0327 
2025-08-27 21:59:06.096990: val_loss -0.0246 
2025-08-27 21:59:06.101168: Pseudo dice [np.float32(0.282)] 
2025-08-27 21:59:06.110400: Epoch time: 24.74 s 
2025-08-27 21:59:06.764312:  
2025-08-27 21:59:06.772664: Epoch 433 
2025-08-27 21:59:06.776825: Current learning rate: 0.006 
2025-08-27 21:59:31.881306: train_loss -0.0408 
2025-08-27 21:59:31.889406: val_loss -0.0369 
2025-08-27 21:59:31.897400: Pseudo dice [np.float32(0.2334)] 
2025-08-27 21:59:31.903152: Epoch time: 25.12 s 
2025-08-27 21:59:32.544309:  
2025-08-27 21:59:32.552640: Epoch 434 
2025-08-27 21:59:32.557008: Current learning rate: 0.00599 
2025-08-27 21:59:57.273129: train_loss -0.0522 
2025-08-27 21:59:57.290055: val_loss -0.0598 
2025-08-27 21:59:57.294156: Pseudo dice [np.float32(0.3914)] 
2025-08-27 21:59:57.301846: Epoch time: 24.73 s 
2025-08-27 21:59:57.948757:  
2025-08-27 21:59:57.957093: Epoch 435 
2025-08-27 21:59:57.961179: Current learning rate: 0.00598 
2025-08-27 22:00:22.698927: train_loss -0.0385 
2025-08-27 22:00:22.706795: val_loss -0.0326 
2025-08-27 22:00:22.710963: Pseudo dice [np.float32(0.2308)] 
2025-08-27 22:00:22.717997: Epoch time: 24.75 s 
2025-08-27 22:00:23.357444:  
2025-08-27 22:00:23.365782: Epoch 436 
2025-08-27 22:00:23.369983: Current learning rate: 0.00597 
2025-08-27 22:00:48.557587: train_loss -0.047 
2025-08-27 22:00:48.570099: val_loss -0.0339 
2025-08-27 22:00:48.574296: Pseudo dice [np.float32(0.2702)] 
2025-08-27 22:00:48.582453: Epoch time: 25.2 s 
2025-08-27 22:00:49.262557:  
2025-08-27 22:00:49.266977: Epoch 437 
2025-08-27 22:00:49.275321: Current learning rate: 0.00596 
2025-08-27 22:01:14.266702: train_loss -0.0376 
2025-08-27 22:01:14.274992: val_loss -0.0353 
2025-08-27 22:01:14.279427: Pseudo dice [np.float32(0.2806)] 
2025-08-27 22:01:14.285340: Epoch time: 25.01 s 
2025-08-27 22:01:14.942255:  
2025-08-27 22:01:14.946484: Epoch 438 
2025-08-27 22:01:14.954806: Current learning rate: 0.00595 
2025-08-27 22:01:40.830610: train_loss -0.0612 
2025-08-27 22:01:40.839298: val_loss -0.0536 
2025-08-27 22:01:40.843134: Pseudo dice [np.float32(0.3655)] 
2025-08-27 22:01:40.848082: Epoch time: 25.89 s 
2025-08-27 22:01:41.498056:  
2025-08-27 22:01:41.506333: Epoch 439 
2025-08-27 22:01:41.510803: Current learning rate: 0.00594 
2025-08-27 22:02:06.144474: train_loss -0.0615 
2025-08-27 22:02:06.151745: val_loss -0.0376 
2025-08-27 22:02:06.160410: Pseudo dice [np.float32(0.2793)] 
2025-08-27 22:02:06.167183: Epoch time: 24.65 s 
2025-08-27 22:02:06.815827:  
2025-08-27 22:02:06.823552: Epoch 440 
2025-08-27 22:02:06.827737: Current learning rate: 0.00593 
2025-08-27 22:02:31.723079: train_loss -0.046 
2025-08-27 22:02:31.731482: val_loss -0.0573 
2025-08-27 22:02:31.735498: Pseudo dice [np.float32(0.4095)] 
2025-08-27 22:02:31.743713: Epoch time: 24.91 s 
2025-08-27 22:02:32.390443:  
2025-08-27 22:02:32.399098: Epoch 441 
2025-08-27 22:02:32.403229: Current learning rate: 0.00592 
2025-08-27 22:02:57.732387: train_loss -0.0298 
2025-08-27 22:02:57.740934: val_loss -0.0427 
2025-08-27 22:02:57.744901: Pseudo dice [np.float32(0.3033)] 
2025-08-27 22:02:57.751136: Epoch time: 25.34 s 
2025-08-27 22:02:58.399758:  
2025-08-27 22:02:58.408405: Epoch 442 
2025-08-27 22:02:58.412272: Current learning rate: 0.00592 
2025-08-27 22:03:23.921048: train_loss -0.0179 
2025-08-27 22:03:23.929733: val_loss -0.0274 
2025-08-27 22:03:23.933780: Pseudo dice [np.float32(0.1707)] 
2025-08-27 22:03:23.941992: Epoch time: 25.53 s 
2025-08-27 22:03:24.588463:  
2025-08-27 22:03:24.596747: Epoch 443 
2025-08-27 22:03:24.605215: Current learning rate: 0.00591 
2025-08-27 22:03:49.604995: train_loss -0.0481 
2025-08-27 22:03:49.613395: val_loss -0.0492 
2025-08-27 22:03:49.617476: Pseudo dice [np.float32(0.318)] 
2025-08-27 22:03:49.625948: Epoch time: 25.02 s 
2025-08-27 22:03:50.276590:  
2025-08-27 22:03:50.284950: Epoch 444 
2025-08-27 22:03:50.289313: Current learning rate: 0.0059 
2025-08-27 22:04:14.876051: train_loss -0.0421 
2025-08-27 22:04:14.880501: val_loss -0.0539 
2025-08-27 22:04:14.888589: Pseudo dice [np.float32(0.2818)] 
2025-08-27 22:04:14.894158: Epoch time: 24.6 s 
2025-08-27 22:04:15.535057:  
2025-08-27 22:04:15.543471: Epoch 445 
2025-08-27 22:04:15.547717: Current learning rate: 0.00589 
2025-08-27 22:04:40.927130: train_loss -0.0529 
2025-08-27 22:04:40.935470: val_loss -0.0479 
2025-08-27 22:04:40.943580: Pseudo dice [np.float32(0.5036)] 
2025-08-27 22:04:40.947949: Epoch time: 25.39 s 
2025-08-27 22:04:41.594535:  
2025-08-27 22:04:41.603075: Epoch 446 
2025-08-27 22:04:41.607247: Current learning rate: 0.00588 
2025-08-27 22:05:06.598536: train_loss -0.0762 
2025-08-27 22:05:06.606987: val_loss -0.0886 
2025-08-27 22:05:06.615260: Pseudo dice [np.float32(0.6529)] 
2025-08-27 22:05:06.620372: Epoch time: 25.0 s 
2025-08-27 22:05:07.270061:  
2025-08-27 22:05:07.278408: Epoch 447 
2025-08-27 22:05:07.282858: Current learning rate: 0.00587 
2025-08-27 22:05:32.553617: train_loss -0.0518 
2025-08-27 22:05:32.562001: val_loss -0.0383 
2025-08-27 22:05:32.566148: Pseudo dice [np.float32(0.3024)] 
2025-08-27 22:05:32.574583: Epoch time: 25.29 s 
2025-08-27 22:05:33.208790:  
2025-08-27 22:05:33.217124: Epoch 448 
2025-08-27 22:05:33.221258: Current learning rate: 0.00586 
2025-08-27 22:05:58.287737: train_loss -0.0367 
2025-08-27 22:05:58.296075: val_loss -0.0435 
2025-08-27 22:05:58.300506: Pseudo dice [np.float32(0.2664)] 
2025-08-27 22:05:58.306239: Epoch time: 25.08 s 
2025-08-27 22:05:58.946649:  
2025-08-27 22:05:58.951159: Epoch 449 
2025-08-27 22:05:58.959182: Current learning rate: 0.00585 
2025-08-27 22:06:23.988609: train_loss -0.0375 
2025-08-27 22:06:23.997004: val_loss -0.0723 
2025-08-27 22:06:24.004926: Pseudo dice [np.float32(0.4975)] 
2025-08-27 22:06:24.010383: Epoch time: 25.05 s 
2025-08-27 22:06:24.835282:  
2025-08-27 22:06:24.843835: Epoch 450 
2025-08-27 22:06:24.847806: Current learning rate: 0.00584 
2025-08-27 22:06:49.459888: train_loss -0.0438 
2025-08-27 22:06:49.472105: val_loss -0.0726 
2025-08-27 22:06:49.476256: Pseudo dice [np.float32(0.4723)] 
2025-08-27 22:06:49.481751: Epoch time: 24.62 s 
2025-08-27 22:06:49.486370: Yayy! New best EMA pseudo Dice: 0.3603000044822693 
2025-08-27 22:06:50.314587:  
2025-08-27 22:06:50.318778: Epoch 451 
2025-08-27 22:06:50.327431: Current learning rate: 0.00583 
2025-08-27 22:07:15.294031: train_loss -0.0352 
2025-08-27 22:07:15.302079: val_loss -0.0568 
2025-08-27 22:07:15.310418: Pseudo dice [np.float32(0.3497)] 
2025-08-27 22:07:15.315409: Epoch time: 24.98 s 
2025-08-27 22:07:15.952718:  
2025-08-27 22:07:15.956838: Epoch 452 
2025-08-27 22:07:15.965235: Current learning rate: 0.00582 
2025-08-27 22:07:41.941652: train_loss -0.0448 
2025-08-27 22:07:41.949457: val_loss -0.027 
2025-08-27 22:07:41.953989: Pseudo dice [np.float32(0.4196)] 
2025-08-27 22:07:41.960788: Epoch time: 25.99 s 
2025-08-27 22:07:41.966745: Yayy! New best EMA pseudo Dice: 0.3652999997138977 
2025-08-27 22:07:42.809739:  
2025-08-27 22:07:42.817050: Epoch 453 
2025-08-27 22:07:42.821362: Current learning rate: 0.00581 
2025-08-27 22:08:07.946575: train_loss -0.0396 
2025-08-27 22:08:07.959166: val_loss -0.0017 
2025-08-27 22:08:07.962961: Pseudo dice [np.float32(0.1378)] 
2025-08-27 22:08:07.970100: Epoch time: 25.14 s 
2025-08-27 22:08:08.763745:  
2025-08-27 22:08:08.767951: Epoch 454 
2025-08-27 22:08:08.776319: Current learning rate: 0.0058 
2025-08-27 22:08:33.913859: train_loss -0.0571 
2025-08-27 22:08:33.922230: val_loss -0.0609 
2025-08-27 22:08:33.926398: Pseudo dice [np.float32(0.334)] 
2025-08-27 22:08:33.932671: Epoch time: 25.15 s 
2025-08-27 22:08:34.577327:  
2025-08-27 22:08:34.585760: Epoch 455 
2025-08-27 22:08:34.589562: Current learning rate: 0.00579 
2025-08-27 22:09:00.386088: train_loss -0.0258 
2025-08-27 22:09:00.394461: val_loss -0.0492 
2025-08-27 22:09:00.398656: Pseudo dice [np.float32(0.4595)] 
2025-08-27 22:09:00.407371: Epoch time: 25.81 s 
2025-08-27 22:09:01.045943:  
2025-08-27 22:09:01.053544: Epoch 456 
2025-08-27 22:09:01.061854: Current learning rate: 0.00578 
2025-08-27 22:09:26.649827: train_loss -0.0647 
2025-08-27 22:09:26.658198: val_loss -0.0011 
2025-08-27 22:09:26.662346: Pseudo dice [np.float32(0.0502)] 
2025-08-27 22:09:26.671486: Epoch time: 25.6 s 
2025-08-27 22:09:27.313194:  
2025-08-27 22:09:27.317493: Epoch 457 
2025-08-27 22:09:27.325536: Current learning rate: 0.00577 
2025-08-27 22:09:52.638277: train_loss -0.038 
2025-08-27 22:09:52.646651: val_loss -0.0566 
2025-08-27 22:09:52.650787: Pseudo dice [np.float32(0.4004)] 
2025-08-27 22:09:52.658819: Epoch time: 25.33 s 
2025-08-27 22:09:53.301440:  
2025-08-27 22:09:53.305870: Epoch 458 
2025-08-27 22:09:53.313982: Current learning rate: 0.00576 
2025-08-27 22:10:18.593336: train_loss -0.0478 
2025-08-27 22:10:18.601739: val_loss -0.0659 
2025-08-27 22:10:18.605855: Pseudo dice [np.float32(0.5484)] 
2025-08-27 22:10:18.614316: Epoch time: 25.3 s 
2025-08-27 22:10:19.256524:  
2025-08-27 22:10:19.264958: Epoch 459 
2025-08-27 22:10:19.269248: Current learning rate: 0.00575 
2025-08-27 22:10:45.258277: train_loss -0.0632 
2025-08-27 22:10:45.266775: val_loss -0.0248 
2025-08-27 22:10:45.274115: Pseudo dice [np.float32(0.1641)] 
2025-08-27 22:10:45.279181: Epoch time: 26.0 s 
2025-08-27 22:10:46.046899:  
2025-08-27 22:10:46.055537: Epoch 460 
2025-08-27 22:10:46.062449: Current learning rate: 0.00574 
2025-08-27 22:11:11.200022: train_loss -0.0283 
2025-08-27 22:11:11.204233: val_loss -0.0418 
2025-08-27 22:11:11.212670: Pseudo dice [np.float32(0.4377)] 
2025-08-27 22:11:11.217839: Epoch time: 25.15 s 
2025-08-27 22:11:11.885222:  
2025-08-27 22:11:11.894421: Epoch 461 
2025-08-27 22:11:11.902820: Current learning rate: 0.00573 
2025-08-27 22:11:36.980406: train_loss -0.0351 
2025-08-27 22:11:36.988284: val_loss -0.0615 
2025-08-27 22:11:36.992491: Pseudo dice [np.float32(0.4843)] 
2025-08-27 22:11:37.001147: Epoch time: 25.1 s 
2025-08-27 22:11:37.630808:  
2025-08-27 22:11:37.638889: Epoch 462 
2025-08-27 22:11:37.644246: Current learning rate: 0.00572 
2025-08-27 22:12:03.039313: train_loss -0.0334 
2025-08-27 22:12:03.047634: val_loss -0.0296 
2025-08-27 22:12:03.051829: Pseudo dice [np.float32(0.2766)] 
2025-08-27 22:12:03.057073: Epoch time: 25.41 s 
2025-08-27 22:12:03.701280:  
2025-08-27 22:12:03.709714: Epoch 463 
2025-08-27 22:12:03.715984: Current learning rate: 0.00571 
2025-08-27 22:12:28.581863: train_loss -0.0351 
2025-08-27 22:12:28.589788: val_loss -0.0941 
2025-08-27 22:12:28.594201: Pseudo dice [np.float32(0.5044)] 
2025-08-27 22:12:28.602957: Epoch time: 24.88 s 
2025-08-27 22:12:28.607028: Yayy! New best EMA pseudo Dice: 0.3653999865055084 
2025-08-27 22:12:29.459358:  
2025-08-27 22:12:29.467708: Epoch 464 
2025-08-27 22:12:29.472860: Current learning rate: 0.0057 
2025-08-27 22:12:53.819181: train_loss -0.0381 
2025-08-27 22:12:53.831676: val_loss -0.0243 
2025-08-27 22:12:53.837613: Pseudo dice [np.float32(0.2094)] 
2025-08-27 22:12:53.842959: Epoch time: 24.36 s 
2025-08-27 22:12:54.488514:  
2025-08-27 22:12:54.496831: Epoch 465 
2025-08-27 22:12:54.503003: Current learning rate: 0.0057 
2025-08-27 22:13:19.661623: train_loss -0.0481 
2025-08-27 22:13:19.669961: val_loss -0.0324 
2025-08-27 22:13:19.678288: Pseudo dice [np.float32(0.3853)] 
2025-08-27 22:13:19.683558: Epoch time: 25.17 s 
2025-08-27 22:13:20.469682:  
2025-08-27 22:13:20.477966: Epoch 466 
2025-08-27 22:13:20.486462: Current learning rate: 0.00569 
2025-08-27 22:13:44.770097: train_loss -0.0382 
2025-08-27 22:13:44.778331: val_loss -0.0408 
2025-08-27 22:13:44.782559: Pseudo dice [np.float32(0.3684)] 
2025-08-27 22:13:44.789207: Epoch time: 24.3 s 
2025-08-27 22:13:45.425866:  
2025-08-27 22:13:45.435216: Epoch 467 
2025-08-27 22:13:45.441345: Current learning rate: 0.00568 
2025-08-27 22:14:09.974335: train_loss -0.0238 
2025-08-27 22:14:09.978524: val_loss -0.0111 
2025-08-27 22:14:09.986887: Pseudo dice [np.float32(0.3702)] 
2025-08-27 22:14:09.992115: Epoch time: 24.55 s 
2025-08-27 22:14:10.628037:  
2025-08-27 22:14:10.636383: Epoch 468 
2025-08-27 22:14:10.642698: Current learning rate: 0.00567 
2025-08-27 22:14:35.345914: train_loss -0.0192 
2025-08-27 22:14:35.353874: val_loss -0.049 
2025-08-27 22:14:35.357955: Pseudo dice [np.float32(0.3126)] 
2025-08-27 22:14:35.363303: Epoch time: 24.72 s 
2025-08-27 22:14:35.991851:  
2025-08-27 22:14:35.999141: Epoch 469 
2025-08-27 22:14:36.004312: Current learning rate: 0.00566 
2025-08-27 22:14:59.907142: train_loss -0.0206 
2025-08-27 22:14:59.915922: val_loss -0.0158 
2025-08-27 22:14:59.920037: Pseudo dice [np.float32(0.1399)] 
2025-08-27 22:14:59.927745: Epoch time: 23.92 s 
2025-08-27 22:15:00.570649:  
2025-08-27 22:15:00.577906: Epoch 470 
2025-08-27 22:15:00.583083: Current learning rate: 0.00565 
2025-08-27 22:15:24.757424: train_loss -0.0305 
2025-08-27 22:15:24.765692: val_loss -0.0194 
2025-08-27 22:15:24.769851: Pseudo dice [np.float32(0.385)] 
2025-08-27 22:15:24.775070: Epoch time: 24.19 s 
2025-08-27 22:15:25.423510:  
2025-08-27 22:15:25.431850: Epoch 471 
2025-08-27 22:15:25.437029: Current learning rate: 0.00564 
2025-08-27 22:15:50.704153: train_loss -0.0334 
2025-08-27 22:15:50.716604: val_loss -0.0201 
2025-08-27 22:15:50.721063: Pseudo dice [np.float32(0.2022)] 
2025-08-27 22:15:50.727739: Epoch time: 25.28 s 
2025-08-27 22:15:51.444348:  
2025-08-27 22:15:51.453562: Epoch 472 
2025-08-27 22:15:51.461476: Current learning rate: 0.00563 
2025-08-27 22:16:16.217290: train_loss -0.0254 
2025-08-27 22:16:16.225435: val_loss -0.0641 
2025-08-27 22:16:16.229592: Pseudo dice [np.float32(0.452)] 
2025-08-27 22:16:16.238433: Epoch time: 24.78 s 
2025-08-27 22:16:17.024091:  
2025-08-27 22:16:17.032418: Epoch 473 
2025-08-27 22:16:17.038531: Current learning rate: 0.00562 
2025-08-27 22:16:41.671637: train_loss -0.037 
2025-08-27 22:16:41.679966: val_loss -0.0242 
2025-08-27 22:16:41.684212: Pseudo dice [np.float32(0.2173)] 
2025-08-27 22:16:41.691201: Epoch time: 24.65 s 
2025-08-27 22:16:42.334965:  
2025-08-27 22:16:42.342988: Epoch 474 
2025-08-27 22:16:42.349427: Current learning rate: 0.00561 
2025-08-27 22:17:07.510092: train_loss -0.0435 
2025-08-27 22:17:07.518272: val_loss -0.05 
2025-08-27 22:17:07.522439: Pseudo dice [np.float32(0.5529)] 
2025-08-27 22:17:07.529397: Epoch time: 25.18 s 
2025-08-27 22:17:08.169933:  
2025-08-27 22:17:08.177110: Epoch 475 
2025-08-27 22:17:08.183470: Current learning rate: 0.0056 
2025-08-27 22:17:33.081752: train_loss -0.0594 
2025-08-27 22:17:33.089637: val_loss -0.038 
2025-08-27 22:17:33.093809: Pseudo dice [np.float32(0.2877)] 
2025-08-27 22:17:33.100618: Epoch time: 24.91 s 
2025-08-27 22:17:33.742396:  
2025-08-27 22:17:33.750637: Epoch 476 
2025-08-27 22:17:33.756870: Current learning rate: 0.00559 
2025-08-27 22:17:58.819657: train_loss -0.0314 
2025-08-27 22:17:58.828074: val_loss -0.1055 
2025-08-27 22:17:58.832000: Pseudo dice [np.float32(0.4594)] 
2025-08-27 22:17:58.840339: Epoch time: 25.08 s 
2025-08-27 22:17:59.473145:  
2025-08-27 22:17:59.483766: Epoch 477 
2025-08-27 22:17:59.490916: Current learning rate: 0.00558 
2025-08-27 22:18:24.278476: train_loss -0.0582 
2025-08-27 22:18:24.286568: val_loss -0.0564 
2025-08-27 22:18:24.290741: Pseudo dice [np.float32(0.3689)] 
2025-08-27 22:18:24.296726: Epoch time: 24.81 s 
2025-08-27 22:18:24.938249:  
2025-08-27 22:18:24.945419: Epoch 478 
2025-08-27 22:18:24.950776: Current learning rate: 0.00557 
2025-08-27 22:18:49.708456: train_loss -0.0376 
2025-08-27 22:18:49.720312: val_loss -0.0406 
2025-08-27 22:18:49.724509: Pseudo dice [np.float32(0.4589)] 
2025-08-27 22:18:49.731703: Epoch time: 24.77 s 
2025-08-27 22:18:50.599060:  
2025-08-27 22:18:50.608859: Epoch 479 
2025-08-27 22:18:50.613596: Current learning rate: 0.00556 
2025-08-27 22:19:16.385156: train_loss -0.0378 
2025-08-27 22:19:16.392767: val_loss -0.0708 
2025-08-27 22:19:16.397335: Pseudo dice [np.float32(0.4409)] 
2025-08-27 22:19:16.405024: Epoch time: 25.79 s 
2025-08-27 22:19:16.410111: Yayy! New best EMA pseudo Dice: 0.3723999857902527 
2025-08-27 22:19:17.312418:  
2025-08-27 22:19:17.324401: Epoch 480 
2025-08-27 22:19:17.332100: Current learning rate: 0.00555 
2025-08-27 22:19:42.911235: train_loss -0.0304 
2025-08-27 22:19:42.919297: val_loss -0.0158 
2025-08-27 22:19:42.927276: Pseudo dice [np.float32(0.2384)] 
2025-08-27 22:19:42.931786: Epoch time: 25.6 s 
2025-08-27 22:19:43.653547:  
2025-08-27 22:19:43.661845: Epoch 481 
2025-08-27 22:19:43.667843: Current learning rate: 0.00554 
2025-08-27 22:20:09.066405: train_loss -0.0466 
2025-08-27 22:20:09.074605: val_loss -0.0069 
2025-08-27 22:20:09.082549: Pseudo dice [np.float32(0.0913)] 
2025-08-27 22:20:09.087066: Epoch time: 25.41 s 
2025-08-27 22:20:09.808703:  
2025-08-27 22:20:09.816934: Epoch 482 
2025-08-27 22:20:09.821082: Current learning rate: 0.00553 
2025-08-27 22:20:35.447318: train_loss -0.041 
2025-08-27 22:20:35.455119: val_loss -0.0561 
2025-08-27 22:20:35.459198: Pseudo dice [np.float32(0.3798)] 
2025-08-27 22:20:35.468453: Epoch time: 25.64 s 
2025-08-27 22:20:36.194428:  
2025-08-27 22:20:36.202656: Epoch 483 
2025-08-27 22:20:36.209792: Current learning rate: 0.00552 
2025-08-27 22:21:01.862991: train_loss -0.036 
2025-08-27 22:21:01.871288: val_loss -0.0297 
2025-08-27 22:21:01.876128: Pseudo dice [np.float32(0.311)] 
2025-08-27 22:21:01.881273: Epoch time: 25.67 s 
2025-08-27 22:21:02.587513:  
2025-08-27 22:21:02.595542: Epoch 484 
2025-08-27 22:21:02.601863: Current learning rate: 0.00551 
2025-08-27 22:21:28.282954: train_loss -0.0348 
2025-08-27 22:21:28.291213: val_loss -0.0591 
2025-08-27 22:21:28.295635: Pseudo dice [np.float32(0.4434)] 
2025-08-27 22:21:28.301334: Epoch time: 25.7 s 
2025-08-27 22:21:29.006320:  
2025-08-27 22:21:29.014681: Epoch 485 
2025-08-27 22:21:29.021048: Current learning rate: 0.0055 
2025-08-27 22:21:54.208630: train_loss -0.0257 
2025-08-27 22:21:54.216993: val_loss -0.044 
2025-08-27 22:21:54.225337: Pseudo dice [np.float32(0.378)] 
2025-08-27 22:21:54.231461: Epoch time: 25.2 s 
2025-08-27 22:21:54.932363:  
2025-08-27 22:21:54.941530: Epoch 486 
2025-08-27 22:21:54.947248: Current learning rate: 0.00549 
2025-08-27 22:22:20.601642: train_loss -0.061 
2025-08-27 22:22:20.610014: val_loss -0.0606 
2025-08-27 22:22:20.618366: Pseudo dice [np.float32(0.3074)] 
2025-08-27 22:22:20.622546: Epoch time: 25.67 s 
2025-08-27 22:22:21.346086:  
2025-08-27 22:22:21.353438: Epoch 487 
2025-08-27 22:22:21.358612: Current learning rate: 0.00548 
2025-08-27 22:22:47.123961: train_loss -0.0608 
2025-08-27 22:22:47.132357: val_loss -0.073 
2025-08-27 22:22:47.140669: Pseudo dice [np.float32(0.5006)] 
2025-08-27 22:22:47.145675: Epoch time: 25.78 s 
2025-08-27 22:22:47.863799:  
2025-08-27 22:22:47.874122: Epoch 488 
2025-08-27 22:22:47.880945: Current learning rate: 0.00547 
2025-08-27 22:23:13.412241: train_loss -0.0678 
2025-08-27 22:23:13.419207: val_loss -0.0322 
2025-08-27 22:23:13.425188: Pseudo dice [np.float32(0.3529)] 
2025-08-27 22:23:13.430176: Epoch time: 25.55 s 
2025-08-27 22:23:14.150805:  
2025-08-27 22:23:14.158783: Epoch 489 
2025-08-27 22:23:14.167624: Current learning rate: 0.00546 
2025-08-27 22:23:39.897499: train_loss -0.0629 
2025-08-27 22:23:39.905879: val_loss -0.0505 
2025-08-27 22:23:39.909986: Pseudo dice [np.float32(0.443)] 
2025-08-27 22:23:39.918127: Epoch time: 25.75 s 
2025-08-27 22:23:40.622072:  
2025-08-27 22:23:40.630446: Epoch 490 
2025-08-27 22:23:40.635756: Current learning rate: 0.00546 
2025-08-27 22:24:06.286353: train_loss -0.0477 
2025-08-27 22:24:06.294712: val_loss -0.0152 
2025-08-27 22:24:06.303055: Pseudo dice [np.float32(0.1952)] 
2025-08-27 22:24:06.308024: Epoch time: 25.67 s 
2025-08-27 22:24:07.014131:  
2025-08-27 22:24:07.021433: Epoch 491 
2025-08-27 22:24:07.027592: Current learning rate: 0.00545 
2025-08-27 22:24:32.508617: train_loss -0.0664 
2025-08-27 22:24:32.516716: val_loss -0.0305 
2025-08-27 22:24:32.520962: Pseudo dice [np.float32(0.2181)] 
2025-08-27 22:24:32.529325: Epoch time: 25.5 s 
2025-08-27 22:24:33.240954:  
2025-08-27 22:24:33.249597: Epoch 492 
2025-08-27 22:24:33.255965: Current learning rate: 0.00544 
2025-08-27 22:24:59.001479: train_loss -0.0434 
2025-08-27 22:24:59.009819: val_loss -0.1451 
2025-08-27 22:24:59.013978: Pseudo dice [np.float32(0.5387)] 
2025-08-27 22:24:59.020129: Epoch time: 25.76 s 
2025-08-27 22:24:59.712529:  
2025-08-27 22:24:59.719873: Epoch 493 
2025-08-27 22:24:59.727912: Current learning rate: 0.00543 
2025-08-27 22:25:25.277742: train_loss -0.0348 
2025-08-27 22:25:25.286056: val_loss -0.0094 
2025-08-27 22:25:25.290210: Pseudo dice [np.float32(0.1736)] 
2025-08-27 22:25:25.296369: Epoch time: 25.57 s 
2025-08-27 22:25:26.008335:  
2025-08-27 22:25:26.018062: Epoch 494 
2025-08-27 22:25:26.024100: Current learning rate: 0.00542 
2025-08-27 22:25:51.078521: train_loss -0.0267 
2025-08-27 22:25:51.086889: val_loss -0.0733 
2025-08-27 22:25:51.095186: Pseudo dice [np.float32(0.4618)] 
2025-08-27 22:25:51.100242: Epoch time: 25.07 s 
2025-08-27 22:25:51.787359:  
2025-08-27 22:25:51.795704: Epoch 495 
2025-08-27 22:25:51.805562: Current learning rate: 0.00541 
2025-08-27 22:26:17.971960: train_loss -0.0357 
2025-08-27 22:26:17.980311: val_loss -0.0814 
2025-08-27 22:26:17.988662: Pseudo dice [np.float32(0.4571)] 
2025-08-27 22:26:17.993620: Epoch time: 26.19 s 
2025-08-27 22:26:18.639152:  
2025-08-27 22:26:18.646520: Epoch 496 
2025-08-27 22:26:18.651989: Current learning rate: 0.0054 
2025-08-27 22:26:43.147383: train_loss -0.0585 
2025-08-27 22:26:43.155461: val_loss -0.06 
2025-08-27 22:26:43.163799: Pseudo dice [np.float32(0.3441)] 
2025-08-27 22:26:43.168711: Epoch time: 24.51 s 
2025-08-27 22:26:43.817463:  
2025-08-27 22:26:43.824852: Epoch 497 
2025-08-27 22:26:43.832181: Current learning rate: 0.00539 
2025-08-27 22:27:08.255495: train_loss -0.064 
2025-08-27 22:27:08.263869: val_loss -0.1111 
2025-08-27 22:27:08.268008: Pseudo dice [np.float32(0.4941)] 
2025-08-27 22:27:08.277309: Epoch time: 24.44 s 
2025-08-27 22:27:08.283051: Yayy! New best EMA pseudo Dice: 0.3734999895095825 
2025-08-27 22:27:09.104219:  
2025-08-27 22:27:09.112526: Epoch 498 
2025-08-27 22:27:09.119990: Current learning rate: 0.00538 
2025-08-27 22:27:34.485510: train_loss -0.067 
2025-08-27 22:27:34.490793: val_loss -0.0719 
2025-08-27 22:27:34.498460: Pseudo dice [np.float32(0.3781)] 
2025-08-27 22:27:34.505336: Epoch time: 25.38 s 
2025-08-27 22:27:34.512501: Yayy! New best EMA pseudo Dice: 0.37400001287460327 
2025-08-27 22:27:35.341870:  
2025-08-27 22:27:35.350232: Epoch 499 
2025-08-27 22:27:35.358132: Current learning rate: 0.00537 
2025-08-27 22:27:59.519364: train_loss -0.048 
2025-08-27 22:27:59.527527: val_loss -0.0565 
2025-08-27 22:27:59.535900: Pseudo dice [np.float32(0.2717)] 
2025-08-27 22:27:59.542011: Epoch time: 24.18 s 
2025-08-27 22:28:00.367876:  
2025-08-27 22:28:00.376199: Epoch 500 
2025-08-27 22:28:00.381374: Current learning rate: 0.00536 
2025-08-27 22:28:25.115552: train_loss -0.0664 
2025-08-27 22:28:25.124270: val_loss -0.0566 
2025-08-27 22:28:25.128056: Pseudo dice [np.float32(0.3176)] 
2025-08-27 22:28:25.137260: Epoch time: 24.75 s 
2025-08-27 22:28:25.775612:  
2025-08-27 22:28:25.783991: Epoch 501 
2025-08-27 22:28:25.791898: Current learning rate: 0.00535 
2025-08-27 22:28:51.329660: train_loss -0.0725 
2025-08-27 22:28:51.337576: val_loss -0.0399 
2025-08-27 22:28:51.342052: Pseudo dice [np.float32(0.3248)] 
2025-08-27 22:28:51.349844: Epoch time: 25.56 s 
2025-08-27 22:28:51.996410:  
2025-08-27 22:28:52.004889: Epoch 502 
2025-08-27 22:28:52.012115: Current learning rate: 0.00534 
2025-08-27 22:29:16.149850: train_loss -0.0449 
2025-08-27 22:29:16.158179: val_loss -0.0754 
2025-08-27 22:29:16.162359: Pseudo dice [np.float32(0.4675)] 
2025-08-27 22:29:16.169504: Epoch time: 24.16 s 
2025-08-27 22:29:16.944353:  
2025-08-27 22:29:16.952771: Epoch 503 
2025-08-27 22:29:16.956818: Current learning rate: 0.00533 
2025-08-27 22:29:41.608575: train_loss -0.0458 
2025-08-27 22:29:41.616942: val_loss -0.0696 
2025-08-27 22:29:41.621385: Pseudo dice [np.float32(0.4294)] 
2025-08-27 22:29:41.628122: Epoch time: 24.67 s 
2025-08-27 22:29:42.272770:  
2025-08-27 22:29:42.282135: Epoch 504 
2025-08-27 22:29:42.287260: Current learning rate: 0.00532 
2025-08-27 22:30:07.413613: train_loss -0.0678 
2025-08-27 22:30:07.421869: val_loss -0.0402 
2025-08-27 22:30:07.426047: Pseudo dice [np.float32(0.2893)] 
2025-08-27 22:30:07.433110: Epoch time: 25.14 s 
2025-08-27 22:30:08.080696:  
2025-08-27 22:30:08.089039: Epoch 505 
2025-08-27 22:30:08.093296: Current learning rate: 0.00531 
2025-08-27 22:30:33.514565: train_loss -0.0397 
2025-08-27 22:30:33.523195: val_loss -0.0472 
2025-08-27 22:30:33.531591: Pseudo dice [np.float32(0.394)] 
2025-08-27 22:30:33.537406: Epoch time: 25.43 s 
2025-08-27 22:30:34.255304:  
2025-08-27 22:30:34.263502: Epoch 506 
2025-08-27 22:30:34.270592: Current learning rate: 0.0053 
2025-08-27 22:30:59.841266: train_loss -0.0448 
2025-08-27 22:30:59.849490: val_loss -0.0444 
2025-08-27 22:30:59.853367: Pseudo dice [np.float32(0.2843)] 
2025-08-27 22:30:59.862512: Epoch time: 25.59 s 
2025-08-27 22:31:00.598813:  
2025-08-27 22:31:00.607308: Epoch 507 
2025-08-27 22:31:00.612332: Current learning rate: 0.00529 
2025-08-27 22:31:25.633232: train_loss -0.0656 
2025-08-27 22:31:25.641694: val_loss -0.0367 
2025-08-27 22:31:25.645797: Pseudo dice [np.float32(0.3119)] 
2025-08-27 22:31:25.651627: Epoch time: 25.04 s 
2025-08-27 22:31:26.347517:  
2025-08-27 22:31:26.356085: Epoch 508 
2025-08-27 22:31:26.363789: Current learning rate: 0.00528 
2025-08-27 22:31:51.730690: train_loss -0.0592 
2025-08-27 22:31:51.738512: val_loss -0.0493 
2025-08-27 22:31:51.746852: Pseudo dice [np.float32(0.2363)] 
2025-08-27 22:31:51.752174: Epoch time: 25.39 s 
2025-08-27 22:31:52.476402:  
2025-08-27 22:31:52.483215: Epoch 509 
2025-08-27 22:31:52.490933: Current learning rate: 0.00527 
2025-08-27 22:32:17.973103: train_loss -0.0689 
2025-08-27 22:32:17.981445: val_loss -0.0418 
2025-08-27 22:32:17.990048: Pseudo dice [np.float32(0.2489)] 
2025-08-27 22:32:17.995074: Epoch time: 25.5 s 
2025-08-27 22:32:18.712350:  
2025-08-27 22:32:18.720039: Epoch 510 
2025-08-27 22:32:18.727107: Current learning rate: 0.00526 
2025-08-27 22:32:44.816492: train_loss -0.0641 
2025-08-27 22:32:44.824844: val_loss -0.0841 
2025-08-27 22:32:44.833185: Pseudo dice [np.float32(0.5305)] 
2025-08-27 22:32:44.838858: Epoch time: 26.11 s 
2025-08-27 22:32:45.526579:  
2025-08-27 22:32:45.533884: Epoch 511 
2025-08-27 22:32:45.537996: Current learning rate: 0.00525 
2025-08-27 22:33:10.555485: train_loss -0.0443 
2025-08-27 22:33:10.563048: val_loss -0.0725 
2025-08-27 22:33:10.567215: Pseudo dice [np.float32(0.5008)] 
2025-08-27 22:33:10.575368: Epoch time: 25.03 s 
2025-08-27 22:33:11.279262:  
2025-08-27 22:33:11.287146: Epoch 512 
2025-08-27 22:33:11.293312: Current learning rate: 0.00524 
2025-08-27 22:33:36.285472: train_loss -0.0606 
2025-08-27 22:33:36.293114: val_loss -0.1019 
2025-08-27 22:33:36.297143: Pseudo dice [np.float32(0.6179)] 
2025-08-27 22:33:36.305295: Epoch time: 25.01 s 
2025-08-27 22:33:36.310104: Yayy! New best EMA pseudo Dice: 0.3928999900817871 
2025-08-27 22:33:37.213484:  
2025-08-27 22:33:37.220872: Epoch 513 
2025-08-27 22:33:37.227000: Current learning rate: 0.00523 
2025-08-27 22:34:02.765128: train_loss -0.0698 
2025-08-27 22:34:02.773500: val_loss -0.0725 
2025-08-27 22:34:02.777910: Pseudo dice [np.float32(0.3488)] 
2025-08-27 22:34:02.784827: Epoch time: 25.55 s 
2025-08-27 22:34:03.582492:  
2025-08-27 22:34:03.591996: Epoch 514 
2025-08-27 22:34:03.598168: Current learning rate: 0.00522 
2025-08-27 22:34:28.503327: train_loss -0.0678 
2025-08-27 22:34:28.511678: val_loss 0.0036 
2025-08-27 22:34:28.520282: Pseudo dice [np.float32(0.1343)] 
2025-08-27 22:34:28.526141: Epoch time: 24.92 s 
2025-08-27 22:34:29.171703:  
2025-08-27 22:34:29.181049: Epoch 515 
2025-08-27 22:34:29.186212: Current learning rate: 0.00521 
2025-08-27 22:34:53.887410: train_loss -0.0251 
2025-08-27 22:34:53.895350: val_loss -0.0538 
2025-08-27 22:34:53.899533: Pseudo dice [np.float32(0.459)] 
2025-08-27 22:34:53.907428: Epoch time: 24.72 s 
2025-08-27 22:34:54.554192:  
2025-08-27 22:34:54.561537: Epoch 516 
2025-08-27 22:34:54.566705: Current learning rate: 0.0052 
2025-08-27 22:35:20.134298: train_loss -0.0733 
2025-08-27 22:35:20.142382: val_loss -0.0685 
2025-08-27 22:35:20.146544: Pseudo dice [np.float32(0.3699)] 
2025-08-27 22:35:20.153302: Epoch time: 25.58 s 
2025-08-27 22:35:20.806557:  
2025-08-27 22:35:20.813765: Epoch 517 
2025-08-27 22:35:20.819072: Current learning rate: 0.00519 
2025-08-27 22:35:44.817080: train_loss -0.0558 
2025-08-27 22:35:44.825356: val_loss -0.0452 
2025-08-27 22:35:44.829463: Pseudo dice [np.float32(0.3488)] 
2025-08-27 22:35:44.837756: Epoch time: 24.01 s 
2025-08-27 22:35:45.488376:  
2025-08-27 22:35:45.495725: Epoch 518 
2025-08-27 22:35:45.504201: Current learning rate: 0.00518 
2025-08-27 22:36:09.821143: train_loss -0.0509 
2025-08-27 22:36:09.829490: val_loss -0.0609 
2025-08-27 22:36:09.833645: Pseudo dice [np.float32(0.4851)] 
2025-08-27 22:36:09.841470: Epoch time: 24.33 s 
2025-08-27 22:36:10.486347:  
2025-08-27 22:36:10.494722: Epoch 519 
2025-08-27 22:36:10.499840: Current learning rate: 0.00518 
2025-08-27 22:36:35.884642: train_loss -0.0617 
2025-08-27 22:36:35.893019: val_loss -0.0111 
2025-08-27 22:36:35.897453: Pseudo dice [np.float32(0.1818)] 
2025-08-27 22:36:35.903176: Epoch time: 25.4 s 
2025-08-27 22:36:36.556049:  
2025-08-27 22:36:36.564384: Epoch 520 
2025-08-27 22:36:36.570727: Current learning rate: 0.00517 
2025-08-27 22:37:00.780400: train_loss -0.0307 
2025-08-27 22:37:00.788724: val_loss -0.0565 
2025-08-27 22:37:00.793240: Pseudo dice [np.float32(0.3418)] 
2025-08-27 22:37:00.801723: Epoch time: 24.23 s 
2025-08-27 22:37:01.448696:  
2025-08-27 22:37:01.455875: Epoch 521 
2025-08-27 22:37:01.461221: Current learning rate: 0.00516 
2025-08-27 22:37:26.255841: train_loss -0.0458 
2025-08-27 22:37:26.260043: val_loss -0.0499 
2025-08-27 22:37:26.268322: Pseudo dice [np.float32(0.3061)] 
2025-08-27 22:37:26.273304: Epoch time: 24.81 s 
2025-08-27 22:37:26.914723:  
2025-08-27 22:37:26.925153: Epoch 522 
2025-08-27 22:37:26.931309: Current learning rate: 0.00515 
2025-08-27 22:37:52.248390: train_loss -0.0525 
2025-08-27 22:37:52.256761: val_loss -0.0298 
2025-08-27 22:37:52.260925: Pseudo dice [np.float32(0.2779)] 
2025-08-27 22:37:52.267015: Epoch time: 25.33 s 
2025-08-27 22:37:52.922940:  
2025-08-27 22:37:52.931334: Epoch 523 
2025-08-27 22:37:52.938874: Current learning rate: 0.00514 
2025-08-27 22:38:17.131577: train_loss -0.0625 
2025-08-27 22:38:17.140690: val_loss -0.0244 
2025-08-27 22:38:17.148283: Pseudo dice [np.float32(0.2503)] 
2025-08-27 22:38:17.153192: Epoch time: 24.21 s 
2025-08-27 22:38:17.869683:  
2025-08-27 22:38:17.877872: Epoch 524 
2025-08-27 22:38:17.886500: Current learning rate: 0.00513 
2025-08-27 22:38:43.015499: train_loss -0.0477 
2025-08-27 22:38:43.020287: val_loss -0.0268 
2025-08-27 22:38:43.028724: Pseudo dice [np.float32(0.3944)] 
2025-08-27 22:38:43.038005: Epoch time: 25.15 s 
2025-08-27 22:38:43.748464:  
2025-08-27 22:38:43.755817: Epoch 525 
2025-08-27 22:38:43.764359: Current learning rate: 0.00512 
2025-08-27 22:39:09.304724: train_loss -0.0568 
2025-08-27 22:39:09.312941: val_loss -0.0273 
2025-08-27 22:39:09.321473: Pseudo dice [np.float32(0.198)] 
2025-08-27 22:39:09.326684: Epoch time: 25.56 s 
2025-08-27 22:39:10.046111:  
2025-08-27 22:39:10.054202: Epoch 526 
2025-08-27 22:39:10.061322: Current learning rate: 0.00511 
2025-08-27 22:39:34.788229: train_loss -0.0501 
2025-08-27 22:39:34.792795: val_loss -0.0434 
2025-08-27 22:39:34.801524: Pseudo dice [np.float32(0.3244)] 
2025-08-27 22:39:34.806521: Epoch time: 24.74 s 
2025-08-27 22:39:35.530695:  
2025-08-27 22:39:35.538930: Epoch 527 
2025-08-27 22:39:35.546332: Current learning rate: 0.0051 
2025-08-27 22:40:00.739178: train_loss -0.0584 
2025-08-27 22:40:00.747547: val_loss -0.073 
2025-08-27 22:40:00.751765: Pseudo dice [np.float32(0.4849)] 
2025-08-27 22:40:00.759752: Epoch time: 25.21 s 
2025-08-27 22:40:01.464812:  
2025-08-27 22:40:01.474703: Epoch 528 
2025-08-27 22:40:01.481381: Current learning rate: 0.00509 
2025-08-27 22:40:26.156226: train_loss -0.0663 
2025-08-27 22:40:26.164913: val_loss -0.1169 
2025-08-27 22:40:26.173229: Pseudo dice [np.float32(0.5886)] 
2025-08-27 22:40:26.178479: Epoch time: 24.69 s 
2025-08-27 22:40:26.860960:  
2025-08-27 22:40:26.868303: Epoch 529 
2025-08-27 22:40:26.874641: Current learning rate: 0.00508 
2025-08-27 22:40:52.123876: train_loss -0.0443 
2025-08-27 22:40:52.132181: val_loss -0.0544 
2025-08-27 22:40:52.140494: Pseudo dice [np.float32(0.3728)] 
2025-08-27 22:40:52.146040: Epoch time: 25.26 s 
2025-08-27 22:40:52.849438:  
2025-08-27 22:40:52.860012: Epoch 530 
2025-08-27 22:40:52.866520: Current learning rate: 0.00507 
2025-08-27 22:41:18.783863: train_loss -0.0449 
2025-08-27 22:41:18.792126: val_loss -0.0376 
2025-08-27 22:41:18.796283: Pseudo dice [np.float32(0.406)] 
2025-08-27 22:41:18.804487: Epoch time: 25.94 s 
2025-08-27 22:41:19.504927:  
2025-08-27 22:41:19.512583: Epoch 531 
2025-08-27 22:41:19.518878: Current learning rate: 0.00506 
2025-08-27 22:41:44.918154: train_loss -0.055 
2025-08-27 22:41:44.926561: val_loss -0.0234 
2025-08-27 22:41:44.930636: Pseudo dice [np.float32(0.2431)] 
2025-08-27 22:41:44.938770: Epoch time: 25.42 s 
2025-08-27 22:41:45.618735:  
2025-08-27 22:41:45.627253: Epoch 532 
2025-08-27 22:41:45.632415: Current learning rate: 0.00505 
2025-08-27 22:42:10.906927: train_loss -0.0732 
2025-08-27 22:42:10.919025: val_loss -0.1055 
2025-08-27 22:42:10.923445: Pseudo dice [np.float32(0.4543)] 
2025-08-27 22:42:10.929435: Epoch time: 25.29 s 
2025-08-27 22:42:11.633381:  
2025-08-27 22:42:11.643758: Epoch 533 
2025-08-27 22:42:11.652075: Current learning rate: 0.00504 
2025-08-27 22:42:37.233243: train_loss -0.0414 
2025-08-27 22:42:37.241303: val_loss -0.0462 
2025-08-27 22:42:37.245497: Pseudo dice [np.float32(0.3776)] 
2025-08-27 22:42:37.253870: Epoch time: 25.6 s 
2025-08-27 22:42:37.953467:  
2025-08-27 22:42:37.961691: Epoch 534 
2025-08-27 22:42:37.972066: Current learning rate: 0.00503 
2025-08-27 22:43:03.939129: train_loss -0.0707 
2025-08-27 22:43:03.947098: val_loss -0.0545 
2025-08-27 22:43:03.951275: Pseudo dice [np.float32(0.262)] 
2025-08-27 22:43:03.961045: Epoch time: 25.99 s 
2025-08-27 22:43:04.693616:  
2025-08-27 22:43:04.704024: Epoch 535 
2025-08-27 22:43:04.710422: Current learning rate: 0.00502 
2025-08-27 22:43:29.456151: train_loss -0.0381 
2025-08-27 22:43:29.464602: val_loss -0.0752 
2025-08-27 22:43:29.468710: Pseudo dice [np.float32(0.5563)] 
2025-08-27 22:43:29.474728: Epoch time: 24.76 s 
2025-08-27 22:43:30.196120:  
2025-08-27 22:43:30.202700: Epoch 536 
2025-08-27 22:43:30.209626: Current learning rate: 0.00501 
2025-08-27 22:43:55.403404: train_loss -0.0669 
2025-08-27 22:43:55.410983: val_loss -0.0217 
2025-08-27 22:43:55.415371: Pseudo dice [np.float32(0.1054)] 
2025-08-27 22:43:55.423334: Epoch time: 25.21 s 
2025-08-27 22:43:56.122219:  
2025-08-27 22:43:56.132334: Epoch 537 
2025-08-27 22:43:56.139752: Current learning rate: 0.005 
2025-08-27 22:44:21.862377: train_loss -0.0499 
2025-08-27 22:44:21.870736: val_loss -0.0457 
2025-08-27 22:44:21.879081: Pseudo dice [np.float32(0.3372)] 
2025-08-27 22:44:21.884631: Epoch time: 25.74 s 
2025-08-27 22:44:22.583906:  
2025-08-27 22:44:22.592119: Epoch 538 
2025-08-27 22:44:22.601723: Current learning rate: 0.00499 
2025-08-27 22:44:48.372177: train_loss -0.0621 
2025-08-27 22:44:48.384713: val_loss -0.0143 
2025-08-27 22:44:48.389057: Pseudo dice [np.float32(0.1596)] 
2025-08-27 22:44:48.396856: Epoch time: 25.79 s 
2025-08-27 22:44:49.117693:  
2025-08-27 22:44:49.127868: Epoch 539 
2025-08-27 22:44:49.139652: Current learning rate: 0.00498 
2025-08-27 22:45:15.007082: train_loss -0.0408 
2025-08-27 22:45:15.015846: val_loss -0.032 
2025-08-27 22:45:15.019996: Pseudo dice [np.float32(0.3361)] 
2025-08-27 22:45:15.026702: Epoch time: 25.89 s 
2025-08-27 22:45:15.766378:  
2025-08-27 22:45:15.777327: Epoch 540 
2025-08-27 22:45:15.784961: Current learning rate: 0.00497 
2025-08-27 22:45:41.892326: train_loss -0.0738 
2025-08-27 22:45:41.900675: val_loss -0.0452 
2025-08-27 22:45:41.908993: Pseudo dice [np.float32(0.2701)] 
2025-08-27 22:45:41.913238: Epoch time: 26.13 s 
2025-08-27 22:45:42.617892:  
2025-08-27 22:45:42.625181: Epoch 541 
2025-08-27 22:45:42.631523: Current learning rate: 0.00496 
2025-08-27 22:46:08.065230: train_loss -0.0672 
2025-08-27 22:46:08.072587: val_loss -0.0692 
2025-08-27 22:46:08.080931: Pseudo dice [np.float32(0.426)] 
2025-08-27 22:46:08.085894: Epoch time: 25.45 s 
2025-08-27 22:46:08.788445:  
2025-08-27 22:46:08.797400: Epoch 542 
2025-08-27 22:46:08.803518: Current learning rate: 0.00495 
2025-08-27 22:46:34.086030: train_loss -0.0415 
2025-08-27 22:46:34.094424: val_loss -0.0153 
2025-08-27 22:46:34.098558: Pseudo dice [np.float32(0.2379)] 
2025-08-27 22:46:34.106744: Epoch time: 25.3 s 
2025-08-27 22:46:34.809714:  
2025-08-27 22:46:34.816989: Epoch 543 
2025-08-27 22:46:34.824990: Current learning rate: 0.00494 
2025-08-27 22:46:59.974380: train_loss -0.0404 
2025-08-27 22:46:59.983144: val_loss -0.0423 
2025-08-27 22:46:59.987224: Pseudo dice [np.float32(0.4705)] 
2025-08-27 22:46:59.993935: Epoch time: 25.17 s 
2025-08-27 22:47:00.708304:  
2025-08-27 22:47:00.716663: Epoch 544 
2025-08-27 22:47:00.722982: Current learning rate: 0.00493 
2025-08-27 22:47:26.439216: train_loss -0.0558 
2025-08-27 22:47:26.446992: val_loss -0.0835 
2025-08-27 22:47:26.455424: Pseudo dice [np.float32(0.3707)] 
2025-08-27 22:47:26.461460: Epoch time: 25.73 s 
2025-08-27 22:47:27.313034:  
2025-08-27 22:47:27.324539: Epoch 545 
2025-08-27 22:47:27.331461: Current learning rate: 0.00492 
2025-08-27 22:47:51.926255: train_loss -0.0668 
2025-08-27 22:47:51.934643: val_loss -0.0378 
2025-08-27 22:47:51.938774: Pseudo dice [np.float32(0.3396)] 
2025-08-27 22:47:51.947188: Epoch time: 24.62 s 
2025-08-27 22:47:52.643960:  
2025-08-27 22:47:52.653473: Epoch 546 
2025-08-27 22:47:52.660218: Current learning rate: 0.00491 
2025-08-27 22:48:17.706756: train_loss -0.0792 
2025-08-27 22:48:17.714554: val_loss -0.0584 
2025-08-27 22:48:17.719015: Pseudo dice [np.float32(0.3093)] 
2025-08-27 22:48:17.726659: Epoch time: 25.06 s 
2025-08-27 22:48:18.437107:  
2025-08-27 22:48:18.444344: Epoch 547 
2025-08-27 22:48:18.449588: Current learning rate: 0.0049 
2025-08-27 22:48:43.574496: train_loss -0.0445 
2025-08-27 22:48:43.581948: val_loss -0.0553 
2025-08-27 22:48:43.586191: Pseudo dice [np.float32(0.4685)] 
2025-08-27 22:48:43.593189: Epoch time: 25.14 s 
2025-08-27 22:48:44.263847:  
2025-08-27 22:48:44.272187: Epoch 548 
2025-08-27 22:48:44.277358: Current learning rate: 0.00489 
2025-08-27 22:49:08.094285: train_loss -0.0692 
2025-08-27 22:49:08.102344: val_loss -0.0603 
2025-08-27 22:49:08.106776: Pseudo dice [np.float32(0.3578)] 
2025-08-27 22:49:08.112508: Epoch time: 23.83 s 
2025-08-27 22:49:08.763440:  
2025-08-27 22:49:08.771749: Epoch 549 
2025-08-27 22:49:08.777805: Current learning rate: 0.00488 
2025-08-27 22:49:34.745631: train_loss -0.0556 
2025-08-27 22:49:34.753955: val_loss -0.0534 
2025-08-27 22:49:34.758096: Pseudo dice [np.float32(0.3983)] 
2025-08-27 22:49:34.766103: Epoch time: 25.98 s 
2025-08-27 22:49:35.594425:  
2025-08-27 22:49:35.602597: Epoch 550 
2025-08-27 22:49:35.609088: Current learning rate: 0.00487 
2025-08-27 22:49:59.520296: train_loss -0.0515 
2025-08-27 22:49:59.532550: val_loss -0.084 
2025-08-27 22:49:59.537330: Pseudo dice [np.float32(0.3865)] 
2025-08-27 22:49:59.543458: Epoch time: 23.93 s 
2025-08-27 22:50:00.201246:  
2025-08-27 22:50:00.208360: Epoch 551 
2025-08-27 22:50:00.213702: Current learning rate: 0.00486 
2025-08-27 22:50:24.190939: train_loss -0.0665 
2025-08-27 22:50:24.199154: val_loss -0.0738 
2025-08-27 22:50:24.203581: Pseudo dice [np.float32(0.6241)] 
2025-08-27 22:50:24.211206: Epoch time: 23.99 s 
2025-08-27 22:50:24.861110:  
2025-08-27 22:50:24.868465: Epoch 552 
2025-08-27 22:50:24.874623: Current learning rate: 0.00485 
2025-08-27 22:50:50.800662: train_loss -0.0415 
2025-08-27 22:50:50.809004: val_loss -0.0517 
2025-08-27 22:50:50.817353: Pseudo dice [np.float32(0.1737)] 
2025-08-27 22:50:50.822268: Epoch time: 25.94 s 
2025-08-27 22:50:51.467861:  
2025-08-27 22:50:51.474153: Epoch 553 
2025-08-27 22:50:51.480356: Current learning rate: 0.00484 
2025-08-27 22:51:15.646307: train_loss -0.0863 
2025-08-27 22:51:15.654676: val_loss -0.1361 
2025-08-27 22:51:15.659302: Pseudo dice [np.float32(0.6527)] 
2025-08-27 22:51:15.666886: Epoch time: 24.18 s 
2025-08-27 22:51:15.671905: Yayy! New best EMA pseudo Dice: 0.39419999718666077 
2025-08-27 22:51:16.521071:  
2025-08-27 22:51:16.528357: Epoch 554 
2025-08-27 22:51:16.533565: Current learning rate: 0.00484 
2025-08-27 22:51:40.308481: train_loss -0.0976 
2025-08-27 22:51:40.316786: val_loss -0.0771 
2025-08-27 22:51:40.320983: Pseudo dice [np.float32(0.4989)] 
2025-08-27 22:51:40.329830: Epoch time: 23.79 s 
2025-08-27 22:51:40.334991: Yayy! New best EMA pseudo Dice: 0.40459999442100525 
2025-08-27 22:51:41.195655:  
2025-08-27 22:51:41.205144: Epoch 555 
2025-08-27 22:51:41.211343: Current learning rate: 0.00483 
2025-08-27 22:52:06.881194: train_loss -0.0662 
2025-08-27 22:52:06.889148: val_loss -0.0915 
2025-08-27 22:52:06.893607: Pseudo dice [np.float32(0.4703)] 
2025-08-27 22:52:06.899270: Epoch time: 25.69 s 
2025-08-27 22:52:06.902497: Yayy! New best EMA pseudo Dice: 0.41119998693466187 
2025-08-27 22:52:07.752339:  
2025-08-27 22:52:07.759678: Epoch 556 
2025-08-27 22:52:07.766029: Current learning rate: 0.00482 
2025-08-27 22:52:32.206048: train_loss -0.046 
2025-08-27 22:52:32.214431: val_loss -0.0877 
2025-08-27 22:52:32.222741: Pseudo dice [np.float32(0.5816)] 
2025-08-27 22:52:32.228203: Epoch time: 24.45 s 
2025-08-27 22:52:32.231987: Yayy! New best EMA pseudo Dice: 0.42820000648498535 
2025-08-27 22:52:33.202810:  
2025-08-27 22:52:33.211080: Epoch 557 
2025-08-27 22:52:33.216423: Current learning rate: 0.00481 
2025-08-27 22:52:58.550154: train_loss -0.0543 
2025-08-27 22:52:58.557719: val_loss -0.0588 
2025-08-27 22:52:58.566203: Pseudo dice [np.float32(0.2839)] 
2025-08-27 22:52:58.574089: Epoch time: 25.35 s 
2025-08-27 22:52:59.290324:  
2025-08-27 22:52:59.297763: Epoch 558 
2025-08-27 22:52:59.303797: Current learning rate: 0.0048 
2025-08-27 22:53:24.591711: train_loss -0.0494 
2025-08-27 22:53:24.600088: val_loss -0.0385 
2025-08-27 22:53:24.604229: Pseudo dice [np.float32(0.3879)] 
2025-08-27 22:53:24.612664: Epoch time: 25.3 s 
2025-08-27 22:53:25.330306:  
2025-08-27 22:53:25.339331: Epoch 559 
2025-08-27 22:53:25.344496: Current learning rate: 0.00479 
2025-08-27 22:53:50.914362: train_loss -0.0482 
2025-08-27 22:53:50.926359: val_loss -0.063 
2025-08-27 22:53:50.930476: Pseudo dice [np.float32(0.4872)] 
2025-08-27 22:53:50.936674: Epoch time: 25.59 s 
2025-08-27 22:53:51.642581:  
2025-08-27 22:53:51.650009: Epoch 560 
2025-08-27 22:53:51.657008: Current learning rate: 0.00478 
2025-08-27 22:54:17.428145: train_loss -0.0741 
2025-08-27 22:54:17.436548: val_loss -0.1088 
2025-08-27 22:54:17.440326: Pseudo dice [np.float32(0.4248)] 
2025-08-27 22:54:17.446437: Epoch time: 25.79 s 
2025-08-27 22:54:18.161749:  
2025-08-27 22:54:18.169060: Epoch 561 
2025-08-27 22:54:18.175418: Current learning rate: 0.00477 
2025-08-27 22:54:43.395360: train_loss -0.0623 
2025-08-27 22:54:43.403727: val_loss -0.0544 
2025-08-27 22:54:43.407913: Pseudo dice [np.float32(0.3117)] 
2025-08-27 22:54:43.415950: Epoch time: 25.24 s 
2025-08-27 22:54:44.131459:  
2025-08-27 22:54:44.139407: Epoch 562 
2025-08-27 22:54:44.145009: Current learning rate: 0.00476 
2025-08-27 22:55:09.592408: train_loss -0.088 
2025-08-27 22:55:09.601593: val_loss -0.0487 
2025-08-27 22:55:09.605154: Pseudo dice [np.float32(0.3944)] 
2025-08-27 22:55:09.611091: Epoch time: 25.46 s 
2025-08-27 22:55:10.458797:  
2025-08-27 22:55:10.466882: Epoch 563 
2025-08-27 22:55:10.472403: Current learning rate: 0.00475 
2025-08-27 22:55:35.551737: train_loss -0.058 
2025-08-27 22:55:35.560045: val_loss -0.0701 
2025-08-27 22:55:35.564210: Pseudo dice [np.float32(0.4393)] 
2025-08-27 22:55:35.572139: Epoch time: 25.09 s 
2025-08-27 22:55:36.287688:  
2025-08-27 22:55:36.298621: Epoch 564 
2025-08-27 22:55:36.306528: Current learning rate: 0.00474 
2025-08-27 22:56:01.840370: train_loss -0.0489 
2025-08-27 22:56:01.849715: val_loss -0.0971 
2025-08-27 22:56:01.855915: Pseudo dice [np.float32(0.4721)] 
2025-08-27 22:56:01.863244: Epoch time: 25.55 s 
2025-08-27 22:56:02.591634:  
2025-08-27 22:56:02.599394: Epoch 565 
2025-08-27 22:56:02.605689: Current learning rate: 0.00473 
2025-08-27 22:56:28.058197: train_loss -0.0631 
2025-08-27 22:56:28.066571: val_loss -0.0954 
2025-08-27 22:56:28.070717: Pseudo dice [np.float32(0.5348)] 
2025-08-27 22:56:28.079160: Epoch time: 25.47 s 
2025-08-27 22:56:28.084008: Yayy! New best EMA pseudo Dice: 0.4284000098705292 
2025-08-27 22:56:28.991298:  
2025-08-27 22:56:28.998667: Epoch 566 
2025-08-27 22:56:29.004132: Current learning rate: 0.00472 
2025-08-27 22:56:54.159567: train_loss -0.0838 
2025-08-27 22:56:54.167958: val_loss -0.0272 
2025-08-27 22:56:54.176050: Pseudo dice [np.float32(0.2355)] 
2025-08-27 22:56:54.181583: Epoch time: 25.17 s 
2025-08-27 22:56:54.876488:  
2025-08-27 22:56:54.883912: Epoch 567 
2025-08-27 22:56:54.891030: Current learning rate: 0.00471 
2025-08-27 22:57:20.711053: train_loss -0.0505 
2025-08-27 22:57:20.719144: val_loss -0.0629 
2025-08-27 22:57:20.723294: Pseudo dice [np.float32(0.4793)] 
2025-08-27 22:57:20.731658: Epoch time: 25.84 s 
2025-08-27 22:57:21.426043:  
2025-08-27 22:57:21.434607: Epoch 568 
2025-08-27 22:57:21.440525: Current learning rate: 0.0047 
2025-08-27 22:57:46.841008: train_loss -0.0521 
2025-08-27 22:57:46.858248: val_loss -0.055 
2025-08-27 22:57:46.866652: Pseudo dice [np.float32(0.3652)] 
2025-08-27 22:57:46.875934: Epoch time: 25.42 s 
2025-08-27 22:57:47.767972:  
2025-08-27 22:57:47.775244: Epoch 569 
2025-08-27 22:57:47.781340: Current learning rate: 0.00469 
2025-08-27 22:58:12.887844: train_loss -0.0598 
2025-08-27 22:58:12.896512: val_loss -0.0292 
2025-08-27 22:58:12.900390: Pseudo dice [np.float32(0.2747)] 
2025-08-27 22:58:12.906622: Epoch time: 25.12 s 
2025-08-27 22:58:13.620787:  
2025-08-27 22:58:13.628139: Epoch 570 
2025-08-27 22:58:13.633393: Current learning rate: 0.00468 
2025-08-27 22:58:39.864786: train_loss -0.0571 
2025-08-27 22:58:39.869204: val_loss -0.0252 
2025-08-27 22:58:39.877350: Pseudo dice [np.float32(0.3196)] 
2025-08-27 22:58:39.882270: Epoch time: 26.25 s 
2025-08-27 22:58:40.580139:  
2025-08-27 22:58:40.587398: Epoch 571 
2025-08-27 22:58:40.592566: Current learning rate: 0.00467 
2025-08-27 22:59:05.953492: train_loss -0.0659 
2025-08-27 22:59:05.961412: val_loss -0.0757 
2025-08-27 22:59:05.967523: Pseudo dice [np.float32(0.5353)] 
2025-08-27 22:59:05.972856: Epoch time: 25.38 s 
2025-08-27 22:59:06.696927:  
2025-08-27 22:59:06.709133: Epoch 572 
2025-08-27 22:59:06.717069: Current learning rate: 0.00466 
2025-08-27 22:59:30.986661: train_loss -0.0355 
2025-08-27 22:59:30.990849: val_loss -0.0703 
2025-08-27 22:59:30.999187: Pseudo dice [np.float32(0.434)] 
2025-08-27 22:59:31.004606: Epoch time: 24.29 s 
2025-08-27 22:59:31.663357:  
2025-08-27 22:59:31.671696: Epoch 573 
2025-08-27 22:59:31.675872: Current learning rate: 0.00465 
2025-08-27 22:59:57.321639: train_loss -0.0669 
2025-08-27 22:59:57.329629: val_loss -0.0473 
2025-08-27 22:59:57.333770: Pseudo dice [np.float32(0.16)] 
2025-08-27 22:59:57.340677: Epoch time: 25.66 s 
2025-08-27 22:59:58.006183:  
2025-08-27 22:59:58.013531: Epoch 574 
2025-08-27 22:59:58.018841: Current learning rate: 0.00464 
2025-08-27 23:00:22.383794: train_loss -0.0605 
2025-08-27 23:00:22.392139: val_loss -0.0449 
2025-08-27 23:00:22.400514: Pseudo dice [np.float32(0.4215)] 
2025-08-27 23:00:22.405876: Epoch time: 24.38 s 
2025-08-27 23:00:23.060507:  
2025-08-27 23:00:23.068820: Epoch 575 
2025-08-27 23:00:23.073016: Current learning rate: 0.00463 
2025-08-27 23:00:46.958340: train_loss -0.0496 
2025-08-27 23:00:46.970860: val_loss -0.0676 
2025-08-27 23:00:46.975039: Pseudo dice [np.float32(0.3417)] 
2025-08-27 23:00:46.982851: Epoch time: 23.9 s 
2025-08-27 23:00:47.639210:  
2025-08-27 23:00:47.647599: Epoch 576 
2025-08-27 23:00:47.653715: Current learning rate: 0.00462 
2025-08-27 23:01:13.422269: train_loss -0.0558 
2025-08-27 23:01:13.430598: val_loss -0.0801 
2025-08-27 23:01:13.438931: Pseudo dice [np.float32(0.4205)] 
2025-08-27 23:01:13.444385: Epoch time: 25.78 s 
2025-08-27 23:01:14.104139:  
2025-08-27 23:01:14.112468: Epoch 577 
2025-08-27 23:01:14.117636: Current learning rate: 0.00461 
2025-08-27 23:01:38.297585: train_loss -0.0588 
2025-08-27 23:01:38.305426: val_loss -0.0686 
2025-08-27 23:01:38.310279: Pseudo dice [np.float32(0.3794)] 
2025-08-27 23:01:38.317687: Epoch time: 24.19 s 
2025-08-27 23:01:38.988294:  
2025-08-27 23:01:38.995654: Epoch 578 
2025-08-27 23:01:39.001815: Current learning rate: 0.0046 
2025-08-27 23:02:02.754832: train_loss -0.079 
2025-08-27 23:02:02.763209: val_loss -0.1131 
2025-08-27 23:02:02.767335: Pseudo dice [np.float32(0.5336)] 
2025-08-27 23:02:02.775710: Epoch time: 23.77 s 
2025-08-27 23:02:03.433699:  
2025-08-27 23:02:03.441916: Epoch 579 
2025-08-27 23:02:03.447039: Current learning rate: 0.00459 
2025-08-27 23:02:28.798079: train_loss -0.073 
2025-08-27 23:02:28.805852: val_loss -0.0814 
2025-08-27 23:02:28.810266: Pseudo dice [np.float32(0.5532)] 
2025-08-27 23:02:28.819178: Epoch time: 25.37 s 
2025-08-27 23:02:29.471051:  
2025-08-27 23:02:29.478408: Epoch 580 
2025-08-27 23:02:29.485597: Current learning rate: 0.00458 
2025-08-27 23:02:53.952632: train_loss -0.0664 
2025-08-27 23:02:53.960461: val_loss -0.0898 
2025-08-27 23:02:53.968492: Pseudo dice [np.float32(0.526)] 
2025-08-27 23:02:53.973449: Epoch time: 24.48 s 
2025-08-27 23:02:54.637820:  
2025-08-27 23:02:54.645192: Epoch 581 
2025-08-27 23:02:54.650381: Current learning rate: 0.00457 
2025-08-27 23:03:18.730845: train_loss -0.0892 
2025-08-27 23:03:18.739050: val_loss -0.097 
2025-08-27 23:03:18.743535: Pseudo dice [np.float32(0.4428)] 
2025-08-27 23:03:18.751310: Epoch time: 24.1 s 
2025-08-27 23:03:19.497008:  
2025-08-27 23:03:19.506515: Epoch 582 
2025-08-27 23:03:19.513053: Current learning rate: 0.00456 
2025-08-27 23:03:45.567348: train_loss -0.0849 
2025-08-27 23:03:45.574184: val_loss -0.0847 
2025-08-27 23:03:45.578350: Pseudo dice [np.float32(0.5666)] 
2025-08-27 23:03:45.585535: Epoch time: 26.07 s 
2025-08-27 23:03:45.591376: Yayy! New best EMA pseudo Dice: 0.44190001487731934 
2025-08-27 23:03:46.498945:  
2025-08-27 23:03:46.509106: Epoch 583 
2025-08-27 23:03:46.517407: Current learning rate: 0.00455 
2025-08-27 23:04:11.304222: train_loss -0.0509 
2025-08-27 23:04:11.312376: val_loss -0.1024 
2025-08-27 23:04:11.320727: Pseudo dice [np.float32(0.6097)] 
2025-08-27 23:04:11.325758: Epoch time: 24.81 s 
2025-08-27 23:04:11.330029: Yayy! New best EMA pseudo Dice: 0.4586000144481659 
2025-08-27 23:04:12.227840:  
2025-08-27 23:04:12.236136: Epoch 584 
2025-08-27 23:04:12.241314: Current learning rate: 0.00454 
2025-08-27 23:04:37.388473: train_loss -0.0468 
2025-08-27 23:04:37.396797: val_loss -0.0928 
2025-08-27 23:04:37.400904: Pseudo dice [np.float32(0.4922)] 
2025-08-27 23:04:37.410158: Epoch time: 25.16 s 
2025-08-27 23:04:37.417936: Yayy! New best EMA pseudo Dice: 0.4620000123977661 
2025-08-27 23:04:38.342655:  
2025-08-27 23:04:38.350720: Epoch 585 
2025-08-27 23:04:38.359758: Current learning rate: 0.00453 
2025-08-27 23:05:04.248579: train_loss -0.0696 
2025-08-27 23:05:04.256973: val_loss -0.0966 
2025-08-27 23:05:04.261367: Pseudo dice [np.float32(0.5475)] 
2025-08-27 23:05:04.268337: Epoch time: 25.91 s 
2025-08-27 23:05:04.275164: Yayy! New best EMA pseudo Dice: 0.4706000089645386 
2025-08-27 23:05:05.220386:  
2025-08-27 23:05:05.228534: Epoch 586 
2025-08-27 23:05:05.235987: Current learning rate: 0.00452 
2025-08-27 23:05:30.199854: train_loss -0.0663 
2025-08-27 23:05:30.207814: val_loss -0.0735 
2025-08-27 23:05:30.211982: Pseudo dice [np.float32(0.3688)] 
2025-08-27 23:05:30.219207: Epoch time: 24.98 s 
2025-08-27 23:05:31.056231:  
2025-08-27 23:05:31.063388: Epoch 587 
2025-08-27 23:05:31.072190: Current learning rate: 0.00451 
2025-08-27 23:05:56.222998: train_loss -0.0801 
2025-08-27 23:05:56.229610: val_loss -0.0552 
2025-08-27 23:05:56.237976: Pseudo dice [np.float32(0.4131)] 
2025-08-27 23:05:56.243539: Epoch time: 25.17 s 
2025-08-27 23:05:56.949013:  
2025-08-27 23:05:56.957259: Epoch 588 
2025-08-27 23:05:56.963573: Current learning rate: 0.0045 
2025-08-27 23:06:22.400831: train_loss -0.0522 
2025-08-27 23:06:22.405928: val_loss -0.0654 
2025-08-27 23:06:22.414103: Pseudo dice [np.float32(0.4953)] 
2025-08-27 23:06:22.419558: Epoch time: 25.45 s 
2025-08-27 23:06:23.146074:  
2025-08-27 23:06:23.156902: Epoch 589 
2025-08-27 23:06:23.161021: Current learning rate: 0.00449 
2025-08-27 23:06:48.352817: train_loss -0.0655 
2025-08-27 23:06:48.360845: val_loss -0.0503 
2025-08-27 23:06:48.365025: Pseudo dice [np.float32(0.5223)] 
2025-08-27 23:06:48.373615: Epoch time: 25.21 s 
2025-08-27 23:06:49.105324:  
2025-08-27 23:06:49.113311: Epoch 590 
2025-08-27 23:06:49.119945: Current learning rate: 0.00448 
2025-08-27 23:07:15.079308: train_loss -0.0858 
2025-08-27 23:07:15.087877: val_loss -0.0375 
2025-08-27 23:07:15.091954: Pseudo dice [np.float32(0.1573)] 
2025-08-27 23:07:15.099736: Epoch time: 25.98 s 
2025-08-27 23:07:15.832050:  
2025-08-27 23:07:15.842357: Epoch 591 
2025-08-27 23:07:15.850183: Current learning rate: 0.00447 
2025-08-27 23:07:41.897964: train_loss -0.0721 
2025-08-27 23:07:41.905961: val_loss -0.1472 
2025-08-27 23:07:41.914670: Pseudo dice [np.float32(0.6213)] 
2025-08-27 23:07:41.920366: Epoch time: 26.07 s 
2025-08-27 23:07:42.693086:  
2025-08-27 23:07:42.701432: Epoch 592 
2025-08-27 23:07:42.707759: Current learning rate: 0.00446 
2025-08-27 23:08:07.936681: train_loss -0.0628 
2025-08-27 23:08:07.944462: val_loss -0.128 
2025-08-27 23:08:07.952806: Pseudo dice [np.float32(0.5135)] 
2025-08-27 23:08:07.958952: Epoch time: 25.24 s 
2025-08-27 23:08:08.833400:  
2025-08-27 23:08:08.840955: Epoch 593 
2025-08-27 23:08:08.846223: Current learning rate: 0.00445 
2025-08-27 23:08:34.296081: train_loss -0.0652 
2025-08-27 23:08:34.304120: val_loss -0.0294 
2025-08-27 23:08:34.312537: Pseudo dice [np.float32(0.3973)] 
2025-08-27 23:08:34.317432: Epoch time: 25.46 s 
2025-08-27 23:08:35.044871:  
2025-08-27 23:08:35.051805: Epoch 594 
2025-08-27 23:08:35.055807: Current learning rate: 0.00444 
2025-08-27 23:09:01.226923: train_loss -0.0574 
2025-08-27 23:09:01.235158: val_loss -0.0663 
2025-08-27 23:09:01.239336: Pseudo dice [np.float32(0.4269)] 
2025-08-27 23:09:01.248530: Epoch time: 26.18 s 
2025-08-27 23:09:01.989951:  
2025-08-27 23:09:01.997372: Epoch 595 
2025-08-27 23:09:02.006764: Current learning rate: 0.00443 
2025-08-27 23:09:27.436655: train_loss -0.068 
2025-08-27 23:09:27.445008: val_loss -0.0496 
2025-08-27 23:09:27.448853: Pseudo dice [np.float32(0.421)] 
2025-08-27 23:09:27.455197: Epoch time: 25.45 s 
2025-08-27 23:09:28.184899:  
2025-08-27 23:09:28.191522: Epoch 596 
2025-08-27 23:09:28.201684: Current learning rate: 0.00442 
2025-08-27 23:09:53.529280: train_loss -0.055 
2025-08-27 23:09:53.537368: val_loss -0.0651 
2025-08-27 23:09:53.546025: Pseudo dice [np.float32(0.4368)] 
2025-08-27 23:09:53.551121: Epoch time: 25.35 s 
2025-08-27 23:09:54.275576:  
2025-08-27 23:09:54.281842: Epoch 597 
2025-08-27 23:09:54.288140: Current learning rate: 0.00441 
2025-08-27 23:10:19.998422: train_loss -0.065 
2025-08-27 23:10:20.005546: val_loss -0.0867 
2025-08-27 23:10:20.009893: Pseudo dice [np.float32(0.576)] 
2025-08-27 23:10:20.016873: Epoch time: 25.73 s 
2025-08-27 23:10:20.762451:  
2025-08-27 23:10:20.770637: Epoch 598 
2025-08-27 23:10:20.776958: Current learning rate: 0.0044 
2025-08-27 23:10:46.490235: train_loss -0.0535 
2025-08-27 23:10:46.503099: val_loss -0.0632 
2025-08-27 23:10:46.506954: Pseudo dice [np.float32(0.5308)] 
2025-08-27 23:10:46.513125: Epoch time: 25.73 s 
2025-08-27 23:10:47.229505:  
2025-08-27 23:10:47.237854: Epoch 599 
2025-08-27 23:10:47.242805: Current learning rate: 0.00439 
2025-08-27 23:11:12.582939: train_loss -0.0616 
2025-08-27 23:11:12.591643: val_loss -0.0637 
2025-08-27 23:11:12.595505: Pseudo dice [np.float32(0.4348)] 
2025-08-27 23:11:12.602768: Epoch time: 25.36 s 
2025-08-27 23:11:13.518231:  
2025-08-27 23:11:13.524435: Epoch 600 
2025-08-27 23:11:13.530172: Current learning rate: 0.00438 
2025-08-27 23:11:39.317971: train_loss -0.0573 
2025-08-27 23:11:39.326362: val_loss -0.0764 
2025-08-27 23:11:39.330496: Pseudo dice [np.float32(0.4008)] 
2025-08-27 23:11:39.338919: Epoch time: 25.8 s 
2025-08-27 23:11:40.071811:  
2025-08-27 23:11:40.079110: Epoch 601 
2025-08-27 23:11:40.084355: Current learning rate: 0.00437 
2025-08-27 23:12:05.239671: train_loss -0.0823 
2025-08-27 23:12:05.248050: val_loss -0.0586 
2025-08-27 23:12:05.256379: Pseudo dice [np.float32(0.3236)] 
2025-08-27 23:12:05.260559: Epoch time: 25.17 s 
2025-08-27 23:12:05.956961:  
2025-08-27 23:12:05.965258: Epoch 602 
2025-08-27 23:12:05.970615: Current learning rate: 0.00436 
2025-08-27 23:12:30.831897: train_loss -0.0589 
2025-08-27 23:12:30.840292: val_loss -0.063 
2025-08-27 23:12:30.848920: Pseudo dice [np.float32(0.3732)] 
2025-08-27 23:12:30.854134: Epoch time: 24.88 s 
2025-08-27 23:12:31.583200:  
2025-08-27 23:12:31.591260: Epoch 603 
2025-08-27 23:12:31.601583: Current learning rate: 0.00435 
2025-08-27 23:12:56.991345: train_loss -0.0835 
2025-08-27 23:12:56.999741: val_loss -0.0768 
2025-08-27 23:12:57.004189: Pseudo dice [np.float32(0.5294)] 
2025-08-27 23:12:57.011961: Epoch time: 25.41 s 
2025-08-27 23:12:57.750293:  
2025-08-27 23:12:57.757421: Epoch 604 
2025-08-27 23:12:57.762998: Current learning rate: 0.00434 
2025-08-27 23:13:23.221726: train_loss -0.0654 
2025-08-27 23:13:23.230064: val_loss -0.0485 
2025-08-27 23:13:23.234427: Pseudo dice [np.float32(0.5279)] 
2025-08-27 23:13:23.240830: Epoch time: 25.47 s 
2025-08-27 23:13:24.130855:  
2025-08-27 23:13:24.139663: Epoch 605 
2025-08-27 23:13:24.147657: Current learning rate: 0.00433 
2025-08-27 23:13:49.022767: train_loss -0.073 
2025-08-27 23:13:49.035178: val_loss -0.0662 
2025-08-27 23:13:49.042290: Pseudo dice [np.float32(0.3253)] 
2025-08-27 23:13:49.049502: Epoch time: 24.89 s 
2025-08-27 23:13:49.783593:  
2025-08-27 23:13:49.791942: Epoch 606 
2025-08-27 23:13:49.798064: Current learning rate: 0.00432 
2025-08-27 23:14:15.232002: train_loss -0.0809 
2025-08-27 23:14:15.240313: val_loss -0.0538 
2025-08-27 23:14:15.249192: Pseudo dice [np.float32(0.1746)] 
2025-08-27 23:14:15.253700: Epoch time: 25.45 s 
2025-08-27 23:14:15.971242:  
2025-08-27 23:14:15.979563: Epoch 607 
2025-08-27 23:14:15.984723: Current learning rate: 0.00431 
2025-08-27 23:14:41.108235: train_loss -0.0554 
2025-08-27 23:14:41.116148: val_loss -0.033 
2025-08-27 23:14:41.120516: Pseudo dice [np.float32(0.2167)] 
2025-08-27 23:14:41.129375: Epoch time: 25.14 s 
2025-08-27 23:14:41.857489:  
2025-08-27 23:14:41.865845: Epoch 608 
2025-08-27 23:14:41.870902: Current learning rate: 0.0043 
2025-08-27 23:15:07.180136: train_loss -0.0832 
2025-08-27 23:15:07.188365: val_loss -0.048 
2025-08-27 23:15:07.192658: Pseudo dice [np.float32(0.5255)] 
2025-08-27 23:15:07.200209: Epoch time: 25.32 s 
2025-08-27 23:15:07.966778:  
2025-08-27 23:15:07.975135: Epoch 609 
2025-08-27 23:15:07.981501: Current learning rate: 0.00429 
2025-08-27 23:15:33.681100: train_loss -0.0782 
2025-08-27 23:15:33.689467: val_loss -0.0544 
2025-08-27 23:15:33.697810: Pseudo dice [np.float32(0.4842)] 
2025-08-27 23:15:33.703991: Epoch time: 25.72 s 
2025-08-27 23:15:34.408870:  
2025-08-27 23:15:34.418752: Epoch 610 
2025-08-27 23:15:34.426679: Current learning rate: 0.00429 
2025-08-27 23:15:59.748815: train_loss -0.0664 
2025-08-27 23:15:59.757152: val_loss -0.0391 
2025-08-27 23:15:59.765508: Pseudo dice [np.float32(0.2159)] 
2025-08-27 23:15:59.770905: Epoch time: 25.34 s 
2025-08-27 23:16:00.619395:  
2025-08-27 23:16:00.626697: Epoch 611 
2025-08-27 23:16:00.631848: Current learning rate: 0.00428 
2025-08-27 23:16:25.791934: train_loss -0.0658 
2025-08-27 23:16:25.800109: val_loss -0.0256 
2025-08-27 23:16:25.808180: Pseudo dice [np.float32(0.2027)] 
2025-08-27 23:16:25.813699: Epoch time: 25.17 s 
2025-08-27 23:16:26.554755:  
2025-08-27 23:16:26.562915: Epoch 612 
2025-08-27 23:16:26.567716: Current learning rate: 0.00427 
2025-08-27 23:16:51.934318: train_loss -0.0466 
2025-08-27 23:16:51.942750: val_loss -0.0417 
2025-08-27 23:16:51.946759: Pseudo dice [np.float32(0.4962)] 
2025-08-27 23:16:51.955173: Epoch time: 25.38 s 
2025-08-27 23:16:52.677013:  
2025-08-27 23:16:52.686634: Epoch 613 
2025-08-27 23:16:52.694377: Current learning rate: 0.00426 
2025-08-27 23:17:18.202705: train_loss -0.071 
2025-08-27 23:17:18.210479: val_loss -0.0848 
2025-08-27 23:17:18.214641: Pseudo dice [np.float32(0.6111)] 
2025-08-27 23:17:18.222744: Epoch time: 25.53 s 
2025-08-27 23:17:18.925729:  
2025-08-27 23:17:18.933072: Epoch 614 
2025-08-27 23:17:18.939230: Current learning rate: 0.00425 
2025-08-27 23:17:43.920419: train_loss -0.0577 
2025-08-27 23:17:43.927914: val_loss -0.0584 
2025-08-27 23:17:43.936224: Pseudo dice [np.float32(0.3952)] 
2025-08-27 23:17:43.941245: Epoch time: 25.0 s 
2025-08-27 23:17:44.662885:  
2025-08-27 23:17:44.670165: Epoch 615 
2025-08-27 23:17:44.675410: Current learning rate: 0.00424 
2025-08-27 23:18:10.555257: train_loss -0.066 
2025-08-27 23:18:10.562757: val_loss -0.0803 
2025-08-27 23:18:10.571081: Pseudo dice [np.float32(0.4348)] 
2025-08-27 23:18:10.576458: Epoch time: 25.9 s 
2025-08-27 23:18:11.325250:  
2025-08-27 23:18:11.333343: Epoch 616 
2025-08-27 23:18:11.339573: Current learning rate: 0.00423 
2025-08-27 23:18:37.247586: train_loss -0.0939 
2025-08-27 23:18:37.256407: val_loss -0.0909 
2025-08-27 23:18:37.264165: Pseudo dice [np.float32(0.4586)] 
2025-08-27 23:18:37.269799: Epoch time: 25.92 s 
2025-08-27 23:18:38.161972:  
2025-08-27 23:18:38.169463: Epoch 617 
2025-08-27 23:18:38.177759: Current learning rate: 0.00422 
2025-08-27 23:19:03.152965: train_loss -0.0642 
2025-08-27 23:19:03.161171: val_loss -0.0246 
2025-08-27 23:19:03.165349: Pseudo dice [np.float32(0.2543)] 
2025-08-27 23:19:03.173324: Epoch time: 24.99 s 
2025-08-27 23:19:03.919038:  
2025-08-27 23:19:03.931790: Epoch 618 
2025-08-27 23:19:03.936890: Current learning rate: 0.00421 
2025-08-27 23:19:29.358085: train_loss -0.0658 
2025-08-27 23:19:29.366416: val_loss -0.047 
2025-08-27 23:19:29.370625: Pseudo dice [np.float32(0.3803)] 
2025-08-27 23:19:29.377718: Epoch time: 25.44 s 
2025-08-27 23:19:30.116137:  
2025-08-27 23:19:30.124363: Epoch 619 
2025-08-27 23:19:30.130680: Current learning rate: 0.0042 
2025-08-27 23:19:56.272507: train_loss -0.0694 
2025-08-27 23:19:56.281596: val_loss -0.0419 
2025-08-27 23:19:56.285307: Pseudo dice [np.float32(0.4707)] 
2025-08-27 23:19:56.292016: Epoch time: 26.16 s 
2025-08-27 23:19:57.021055:  
2025-08-27 23:19:57.033544: Epoch 620 
2025-08-27 23:19:57.040899: Current learning rate: 0.00419 
2025-08-27 23:20:22.544816: train_loss -0.0604 
2025-08-27 23:20:22.553195: val_loss -0.1059 
2025-08-27 23:20:22.557014: Pseudo dice [np.float32(0.6338)] 
2025-08-27 23:20:22.564194: Epoch time: 25.52 s 
2025-08-27 23:20:23.272251:  
2025-08-27 23:20:23.280704: Epoch 621 
2025-08-27 23:20:23.288056: Current learning rate: 0.00418 
2025-08-27 23:20:48.595652: train_loss -0.066 
2025-08-27 23:20:48.603922: val_loss -0.0702 
2025-08-27 23:20:48.612584: Pseudo dice [np.float32(0.4945)] 
2025-08-27 23:20:48.618435: Epoch time: 25.33 s 
2025-08-27 23:20:49.341072:  
2025-08-27 23:20:49.349772: Epoch 622 
2025-08-27 23:20:49.356646: Current learning rate: 0.00417 
2025-08-27 23:21:14.467172: train_loss -0.0639 
2025-08-27 23:21:14.475527: val_loss -0.1191 
2025-08-27 23:21:14.484193: Pseudo dice [np.float32(0.702)] 
2025-08-27 23:21:14.490099: Epoch time: 25.13 s 
2025-08-27 23:21:15.367952:  
2025-08-27 23:21:15.377062: Epoch 623 
2025-08-27 23:21:15.386515: Current learning rate: 0.00416 
2025-08-27 23:21:40.155533: train_loss -0.0823 
2025-08-27 23:21:40.167443: val_loss -0.0814 
2025-08-27 23:21:40.172029: Pseudo dice [np.float32(0.6292)] 
2025-08-27 23:21:40.177526: Epoch time: 24.79 s 
2025-08-27 23:21:40.181330: Yayy! New best EMA pseudo Dice: 0.478300005197525 
2025-08-27 23:21:41.100114:  
2025-08-27 23:21:41.110819: Epoch 624 
2025-08-27 23:21:41.118152: Current learning rate: 0.00415 
2025-08-27 23:22:06.978249: train_loss -0.0527 
2025-08-27 23:22:06.986637: val_loss -0.0749 
2025-08-27 23:22:06.994674: Pseudo dice [np.float32(0.5489)] 
2025-08-27 23:22:06.999660: Epoch time: 25.88 s 
2025-08-27 23:22:07.003767: Yayy! New best EMA pseudo Dice: 0.48539999127388 
2025-08-27 23:22:07.919367:  
2025-08-27 23:22:07.931526: Epoch 625 
2025-08-27 23:22:07.942558: Current learning rate: 0.00414 
2025-08-27 23:22:33.358714: train_loss -0.0652 
2025-08-27 23:22:33.366859: val_loss -0.0845 
2025-08-27 23:22:33.374953: Pseudo dice [np.float32(0.5243)] 
2025-08-27 23:22:33.380921: Epoch time: 25.44 s 
2025-08-27 23:22:33.387614: Yayy! New best EMA pseudo Dice: 0.489300012588501 
2025-08-27 23:22:34.328116:  
2025-08-27 23:22:34.336509: Epoch 626 
2025-08-27 23:22:34.343267: Current learning rate: 0.00413 
2025-08-27 23:22:59.588831: train_loss -0.0788 
2025-08-27 23:22:59.597147: val_loss -0.0789 
2025-08-27 23:22:59.605448: Pseudo dice [np.float32(0.4323)] 
2025-08-27 23:22:59.610424: Epoch time: 25.26 s 
2025-08-27 23:23:00.341605:  
2025-08-27 23:23:00.352545: Epoch 627 
2025-08-27 23:23:00.360909: Current learning rate: 0.00412 
2025-08-27 23:23:25.823364: train_loss -0.0824 
2025-08-27 23:23:25.831704: val_loss -0.072 
2025-08-27 23:23:25.835842: Pseudo dice [np.float32(0.5365)] 
2025-08-27 23:23:25.845070: Epoch time: 25.48 s 
2025-08-27 23:23:26.581331:  
2025-08-27 23:23:26.588593: Epoch 628 
2025-08-27 23:23:26.594592: Current learning rate: 0.00411 
2025-08-27 23:23:52.383411: train_loss -0.0701 
2025-08-27 23:23:52.391869: val_loss -0.0989 
2025-08-27 23:23:52.396010: Pseudo dice [np.float32(0.4262)] 
2025-08-27 23:23:52.404717: Epoch time: 25.81 s 
2025-08-27 23:23:53.273586:  
2025-08-27 23:23:53.283117: Epoch 629 
2025-08-27 23:23:53.292952: Current learning rate: 0.0041 
2025-08-27 23:24:18.309098: train_loss -0.0524 
2025-08-27 23:24:18.317442: val_loss -0.0927 
2025-08-27 23:24:18.325332: Pseudo dice [np.float32(0.4719)] 
2025-08-27 23:24:18.330017: Epoch time: 25.04 s 
2025-08-27 23:24:19.078197:  
2025-08-27 23:24:19.087910: Epoch 630 
2025-08-27 23:24:19.096666: Current learning rate: 0.00409 
2025-08-27 23:24:44.723142: train_loss -0.0511 
2025-08-27 23:24:44.731306: val_loss -0.0873 
2025-08-27 23:24:44.735410: Pseudo dice [np.float32(0.4114)] 
2025-08-27 23:24:44.743552: Epoch time: 25.65 s 
2025-08-27 23:24:45.471839:  
2025-08-27 23:24:45.478282: Epoch 631 
2025-08-27 23:24:45.487154: Current learning rate: 0.00408 
2025-08-27 23:25:10.694955: train_loss -0.0732 
2025-08-27 23:25:10.703023: val_loss -0.0765 
2025-08-27 23:25:10.707520: Pseudo dice [np.float32(0.4059)] 
2025-08-27 23:25:10.716444: Epoch time: 25.23 s 
2025-08-27 23:25:11.443291:  
2025-08-27 23:25:11.452874: Epoch 632 
2025-08-27 23:25:11.461964: Current learning rate: 0.00407 
2025-08-27 23:25:36.727990: train_loss -0.0733 
2025-08-27 23:25:36.733225: val_loss -0.0667 
2025-08-27 23:25:36.741942: Pseudo dice [np.float32(0.4087)] 
2025-08-27 23:25:36.746870: Epoch time: 25.29 s 
2025-08-27 23:25:37.483063:  
2025-08-27 23:25:37.488929: Epoch 633 
2025-08-27 23:25:37.497071: Current learning rate: 0.00406 
2025-08-27 23:26:02.834237: train_loss -0.0706 
2025-08-27 23:26:02.842620: val_loss -0.0533 
2025-08-27 23:26:02.846763: Pseudo dice [np.float32(0.3655)] 
2025-08-27 23:26:02.854940: Epoch time: 25.35 s 
2025-08-27 23:26:03.594491:  
2025-08-27 23:26:03.602491: Epoch 634 
2025-08-27 23:26:03.611646: Current learning rate: 0.00405 
2025-08-27 23:26:29.623518: train_loss -0.0905 
2025-08-27 23:26:29.636011: val_loss -0.0537 
2025-08-27 23:26:29.640207: Pseudo dice [np.float32(0.3868)] 
2025-08-27 23:26:29.645742: Epoch time: 26.03 s 
2025-08-27 23:26:30.526510:  
2025-08-27 23:26:30.536896: Epoch 635 
2025-08-27 23:26:30.543777: Current learning rate: 0.00404 
2025-08-27 23:26:55.925422: train_loss -0.0992 
2025-08-27 23:26:55.933429: val_loss -0.0741 
2025-08-27 23:26:55.937610: Pseudo dice [np.float32(0.3651)] 
2025-08-27 23:26:55.945432: Epoch time: 25.4 s 
2025-08-27 23:26:56.676361:  
2025-08-27 23:26:56.687445: Epoch 636 
2025-08-27 23:26:56.694200: Current learning rate: 0.00403 
2025-08-27 23:27:22.017788: train_loss -0.0938 
2025-08-27 23:27:22.025832: val_loss -0.1054 
2025-08-27 23:27:22.029978: Pseudo dice [np.float32(0.4295)] 
2025-08-27 23:27:22.038041: Epoch time: 25.34 s 
2025-08-27 23:27:22.781406:  
2025-08-27 23:27:22.792063: Epoch 637 
2025-08-27 23:27:22.799484: Current learning rate: 0.00402 
2025-08-27 23:27:48.069371: train_loss -0.0656 
2025-08-27 23:27:48.077151: val_loss -0.074 
2025-08-27 23:27:48.085051: Pseudo dice [np.float32(0.6468)] 
2025-08-27 23:27:48.090208: Epoch time: 25.29 s 
2025-08-27 23:27:48.808811:  
2025-08-27 23:27:48.820867: Epoch 638 
2025-08-27 23:27:48.828036: Current learning rate: 0.00401 
2025-08-27 23:28:14.194815: train_loss -0.0642 
2025-08-27 23:28:14.203150: val_loss -0.0256 
2025-08-27 23:28:14.207432: Pseudo dice [np.float32(0.2284)] 
2025-08-27 23:28:14.215208: Epoch time: 25.39 s 
2025-08-27 23:28:14.936876:  
2025-08-27 23:28:14.947272: Epoch 639 
2025-08-27 23:28:14.953484: Current learning rate: 0.004 
2025-08-27 23:28:40.675470: train_loss -0.0626 
2025-08-27 23:28:40.683843: val_loss -0.0412 
2025-08-27 23:28:40.687706: Pseudo dice [np.float32(0.6226)] 
2025-08-27 23:28:40.695074: Epoch time: 25.74 s 
2025-08-27 23:28:41.432821:  
2025-08-27 23:28:41.439667: Epoch 640 
2025-08-27 23:28:41.443283: Current learning rate: 0.00399 
2025-08-27 23:29:07.034878: train_loss -0.044 
2025-08-27 23:29:07.045092: val_loss -0.098 
2025-08-27 23:29:07.051533: Pseudo dice [np.float32(0.5737)] 
2025-08-27 23:29:07.057173: Epoch time: 25.6 s 
2025-08-27 23:29:07.921069:  
2025-08-27 23:29:07.929554: Epoch 641 
2025-08-27 23:29:07.935596: Current learning rate: 0.00398 
2025-08-27 23:29:33.406952: train_loss -0.0641 
2025-08-27 23:29:33.415361: val_loss -0.1393 
2025-08-27 23:29:33.419721: Pseudo dice [np.float32(0.6382)] 
2025-08-27 23:29:33.427853: Epoch time: 25.49 s 
2025-08-27 23:29:34.145025:  
2025-08-27 23:29:34.151586: Epoch 642 
2025-08-27 23:29:34.158736: Current learning rate: 0.00397 
2025-08-27 23:29:59.199457: train_loss -0.0894 
2025-08-27 23:29:59.207745: val_loss -0.064 
2025-08-27 23:29:59.211927: Pseudo dice [np.float32(0.5427)] 
2025-08-27 23:29:59.218431: Epoch time: 25.06 s 
2025-08-27 23:29:59.965671:  
2025-08-27 23:29:59.971221: Epoch 643 
2025-08-27 23:29:59.981416: Current learning rate: 0.00396 
2025-08-27 23:30:27.014693: train_loss -0.0532 
2025-08-27 23:30:27.023037: val_loss -0.0802 
2025-08-27 23:30:27.031328: Pseudo dice [np.float32(0.7062)] 
2025-08-27 23:30:27.037560: Epoch time: 27.05 s 
2025-08-27 23:30:27.044414: Yayy! New best EMA pseudo Dice: 0.5105999708175659 
2025-08-27 23:30:28.035426:  
2025-08-27 23:30:28.047505: Epoch 644 
2025-08-27 23:30:28.057418: Current learning rate: 0.00395 
2025-08-27 23:30:57.883377: train_loss -0.0612 
2025-08-27 23:30:57.891342: val_loss -0.1589 
2025-08-27 23:30:57.895514: Pseudo dice [np.float32(0.6734)] 
2025-08-27 23:30:57.902642: Epoch time: 29.85 s 
2025-08-27 23:30:57.908391: Yayy! New best EMA pseudo Dice: 0.5268999934196472 
2025-08-27 23:30:58.820385:  
2025-08-27 23:30:58.828596: Epoch 645 
2025-08-27 23:30:58.835037: Current learning rate: 0.00394 
2025-08-27 23:31:26.123674: train_loss -0.0482 
2025-08-27 23:31:26.132008: val_loss -0.1292 
2025-08-27 23:31:26.139101: Pseudo dice [np.float32(0.5703)] 
2025-08-27 23:31:26.146547: Epoch time: 27.31 s 
2025-08-27 23:31:26.154411: Yayy! New best EMA pseudo Dice: 0.5311999917030334 
2025-08-27 23:31:27.052046:  
2025-08-27 23:31:27.059036: Epoch 646 
2025-08-27 23:31:27.068361: Current learning rate: 0.00393 
2025-08-27 23:31:53.934768: train_loss -0.0723 
2025-08-27 23:31:53.943460: val_loss -0.0818 
2025-08-27 23:31:53.947654: Pseudo dice [np.float32(0.3807)] 
2025-08-27 23:31:53.956468: Epoch time: 26.88 s 
2025-08-27 23:31:54.846038:  
2025-08-27 23:31:54.855350: Epoch 647 
2025-08-27 23:31:54.863759: Current learning rate: 0.00392 
2025-08-27 23:32:21.245403: train_loss -0.0608 
2025-08-27 23:32:21.253775: val_loss -0.0599 
2025-08-27 23:32:21.258191: Pseudo dice [np.float32(0.3753)] 
2025-08-27 23:32:21.263891: Epoch time: 26.4 s 
2025-08-27 23:32:21.992943:  
2025-08-27 23:32:22.002159: Epoch 648 
2025-08-27 23:32:22.007476: Current learning rate: 0.00391 
2025-08-27 23:32:48.380975: train_loss -0.0621 
2025-08-27 23:32:48.389129: val_loss -0.1048 
2025-08-27 23:32:48.397469: Pseudo dice [np.float32(0.4925)] 
2025-08-27 23:32:48.402961: Epoch time: 26.39 s 
2025-08-27 23:32:49.136356:  
2025-08-27 23:32:49.146260: Epoch 649 
2025-08-27 23:32:49.157562: Current learning rate: 0.0039 
2025-08-27 23:33:15.041298: train_loss -0.0704 
2025-08-27 23:33:15.049115: val_loss -0.0958 
2025-08-27 23:33:15.053268: Pseudo dice [np.float32(0.4407)] 
2025-08-27 23:33:15.060378: Epoch time: 25.91 s 
2025-08-27 23:33:15.998855:  
2025-08-27 23:33:16.006566: Epoch 650 
2025-08-27 23:33:16.012382: Current learning rate: 0.00389 
2025-08-27 23:33:41.771997: train_loss -0.0729 
2025-08-27 23:33:41.779925: val_loss -0.0764 
2025-08-27 23:33:41.784377: Pseudo dice [np.float32(0.5413)] 
2025-08-27 23:33:41.790190: Epoch time: 25.78 s 
2025-08-27 23:33:42.506648:  
2025-08-27 23:33:42.515885: Epoch 651 
2025-08-27 23:33:42.524444: Current learning rate: 0.00388 
2025-08-27 23:34:07.972744: train_loss -0.0731 
2025-08-27 23:34:07.981081: val_loss -0.0674 
2025-08-27 23:34:07.985592: Pseudo dice [np.float32(0.4461)] 
2025-08-27 23:34:07.992446: Epoch time: 25.47 s 
2025-08-27 23:34:08.700590:  
2025-08-27 23:34:08.710283: Epoch 652 
2025-08-27 23:34:08.715580: Current learning rate: 0.00387 
2025-08-27 23:34:33.848778: train_loss -0.071 
2025-08-27 23:34:33.856918: val_loss -0.0608 
2025-08-27 23:34:33.865235: Pseudo dice [np.float32(0.4096)] 
2025-08-27 23:34:33.871358: Epoch time: 25.15 s 
2025-08-27 23:34:34.730702:  
2025-08-27 23:34:34.739581: Epoch 653 
2025-08-27 23:34:34.746359: Current learning rate: 0.00386 
2025-08-27 23:35:00.354075: train_loss -0.0533 
2025-08-27 23:35:00.362553: val_loss -0.0529 
2025-08-27 23:35:00.366714: Pseudo dice [np.float32(0.3395)] 
2025-08-27 23:35:00.373841: Epoch time: 25.62 s 
2025-08-27 23:35:01.121610:  
2025-08-27 23:35:01.129945: Epoch 654 
2025-08-27 23:35:01.136164: Current learning rate: 0.00385 
2025-08-27 23:35:26.601218: train_loss -0.0602 
2025-08-27 23:35:26.609622: val_loss -0.1079 
2025-08-27 23:35:26.613784: Pseudo dice [np.float32(0.5569)] 
2025-08-27 23:35:26.623147: Epoch time: 25.48 s 
2025-08-27 23:35:27.390551:  
2025-08-27 23:35:27.402848: Epoch 655 
2025-08-27 23:35:27.407126: Current learning rate: 0.00384 
2025-08-27 23:35:52.889962: train_loss -0.1003 
2025-08-27 23:35:52.898431: val_loss -0.1282 
2025-08-27 23:35:52.902564: Pseudo dice [np.float32(0.3843)] 
2025-08-27 23:35:52.910622: Epoch time: 25.5 s 
2025-08-27 23:35:53.634631:  
2025-08-27 23:35:53.644559: Epoch 656 
2025-08-27 23:35:53.649524: Current learning rate: 0.00383 
2025-08-27 23:36:19.266572: train_loss -0.0664 
2025-08-27 23:36:19.274718: val_loss -0.0401 
2025-08-27 23:36:19.278867: Pseudo dice [np.float32(0.1349)] 
2025-08-27 23:36:19.285009: Epoch time: 25.63 s 
2025-08-27 23:36:20.005590:  
2025-08-27 23:36:20.013870: Epoch 657 
2025-08-27 23:36:20.019096: Current learning rate: 0.00382 
2025-08-27 23:36:44.929603: train_loss -0.0722 
2025-08-27 23:36:44.937800: val_loss -0.072 
2025-08-27 23:36:44.946131: Pseudo dice [np.float32(0.4282)] 
2025-08-27 23:36:44.951260: Epoch time: 24.93 s 
2025-08-27 23:36:45.705113:  
2025-08-27 23:36:45.713384: Epoch 658 
2025-08-27 23:36:45.721889: Current learning rate: 0.00381 
2025-08-27 23:37:11.327060: train_loss -0.0808 
2025-08-27 23:37:11.335286: val_loss -0.0641 
2025-08-27 23:37:11.339128: Pseudo dice [np.float32(0.3769)] 
2025-08-27 23:37:11.348205: Epoch time: 25.62 s 
2025-08-27 23:37:12.078148:  
2025-08-27 23:37:12.091021: Epoch 659 
2025-08-27 23:37:12.106530: Current learning rate: 0.0038 
2025-08-27 23:37:37.532484: train_loss -0.0981 
2025-08-27 23:37:37.540283: val_loss -0.0569 
2025-08-27 23:37:37.544461: Pseudo dice [np.float32(0.3963)] 
2025-08-27 23:37:37.552900: Epoch time: 25.46 s 
2025-08-27 23:37:38.251360:  
2025-08-27 23:37:38.259695: Epoch 660 
2025-08-27 23:37:38.265841: Current learning rate: 0.00379 
2025-08-27 23:38:03.253479: train_loss -0.0918 
2025-08-27 23:38:03.261816: val_loss -0.1335 
2025-08-27 23:38:03.265976: Pseudo dice [np.float32(0.6292)] 
2025-08-27 23:38:03.272006: Epoch time: 25.0 s 
2025-08-27 23:38:03.994671:  
2025-08-27 23:38:04.003101: Epoch 661 
2025-08-27 23:38:04.010649: Current learning rate: 0.00378 
2025-08-27 23:38:29.333655: train_loss -0.077 
2025-08-27 23:38:29.341996: val_loss -0.1013 
2025-08-27 23:38:29.350350: Pseudo dice [np.float32(0.5278)] 
2025-08-27 23:38:29.355837: Epoch time: 25.34 s 
2025-08-27 23:38:30.058229:  
2025-08-27 23:38:30.065685: Epoch 662 
2025-08-27 23:38:30.071731: Current learning rate: 0.00377 
2025-08-27 23:38:55.848505: train_loss -0.0695 
2025-08-27 23:38:55.855983: val_loss -0.059 
2025-08-27 23:38:55.864058: Pseudo dice [np.float32(0.4157)] 
2025-08-27 23:38:55.869359: Epoch time: 25.79 s 
2025-08-27 23:38:56.690110:  
2025-08-27 23:38:56.698476: Epoch 663 
2025-08-27 23:38:56.705712: Current learning rate: 0.00376 
2025-08-27 23:39:22.165560: train_loss -0.0706 
2025-08-27 23:39:22.173983: val_loss -0.0981 
2025-08-27 23:39:22.178134: Pseudo dice [np.float32(0.5562)] 
2025-08-27 23:39:22.183666: Epoch time: 25.48 s 
2025-08-27 23:39:22.925974:  
2025-08-27 23:39:22.937408: Epoch 664 
2025-08-27 23:39:22.943389: Current learning rate: 0.00375 
2025-08-27 23:39:47.978846: train_loss -0.0525 
2025-08-27 23:39:47.989936: val_loss -0.0771 
2025-08-27 23:39:47.996100: Pseudo dice [np.float32(0.5624)] 
2025-08-27 23:39:48.002664: Epoch time: 25.05 s 
2025-08-27 23:39:48.858745:  
2025-08-27 23:39:48.867106: Epoch 665 
2025-08-27 23:39:48.871249: Current learning rate: 0.00374 
2025-08-27 23:40:14.189422: train_loss -0.0591 
2025-08-27 23:40:14.197025: val_loss -0.0705 
2025-08-27 23:40:14.205364: Pseudo dice [np.float32(0.4348)] 
2025-08-27 23:40:14.210566: Epoch time: 25.33 s 
2025-08-27 23:40:14.938909:  
2025-08-27 23:40:14.947423: Epoch 666 
2025-08-27 23:40:14.952682: Current learning rate: 0.00373 
2025-08-27 23:40:40.030786: train_loss -0.0589 
2025-08-27 23:40:40.039147: val_loss -0.097 
2025-08-27 23:40:40.047966: Pseudo dice [np.float32(0.3778)] 
2025-08-27 23:40:40.052529: Epoch time: 25.09 s 
2025-08-27 23:40:40.795115:  
2025-08-27 23:40:40.802900: Epoch 667 
2025-08-27 23:40:40.808650: Current learning rate: 0.00372 
2025-08-27 23:41:05.856930: train_loss -0.0798 
2025-08-27 23:41:05.865293: val_loss -0.0678 
2025-08-27 23:41:05.869437: Pseudo dice [np.float32(0.4754)] 
2025-08-27 23:41:05.875249: Epoch time: 25.07 s 
2025-08-27 23:41:06.586520:  
2025-08-27 23:41:06.594841: Epoch 668 
2025-08-27 23:41:06.601771: Current learning rate: 0.00371 
2025-08-27 23:41:32.153662: train_loss -0.0671 
2025-08-27 23:41:32.166191: val_loss -0.1075 
2025-08-27 23:41:32.170368: Pseudo dice [np.float32(0.5494)] 
2025-08-27 23:41:32.177557: Epoch time: 25.57 s 
2025-08-27 23:41:32.875059:  
2025-08-27 23:41:32.884718: Epoch 669 
2025-08-27 23:41:32.894433: Current learning rate: 0.0037 
2025-08-27 23:41:57.796815: train_loss -0.0687 
2025-08-27 23:41:57.804296: val_loss -0.0653 
2025-08-27 23:41:57.808702: Pseudo dice [np.float32(0.3817)] 
2025-08-27 23:41:57.816540: Epoch time: 24.92 s 
2025-08-27 23:41:58.576914:  
2025-08-27 23:41:58.586078: Epoch 670 
2025-08-27 23:41:58.595164: Current learning rate: 0.00369 
2025-08-27 23:42:23.472396: train_loss -0.0491 
2025-08-27 23:42:23.479935: val_loss -0.0548 
2025-08-27 23:42:23.484104: Pseudo dice [np.float32(0.4405)] 
2025-08-27 23:42:23.490143: Epoch time: 24.9 s 
2025-08-27 23:42:24.277310:  
2025-08-27 23:42:24.287325: Epoch 671 
2025-08-27 23:42:24.294272: Current learning rate: 0.00368 
2025-08-27 23:42:49.547662: train_loss -0.0855 
2025-08-27 23:42:49.555955: val_loss -0.0792 
2025-08-27 23:42:49.560167: Pseudo dice [np.float32(0.4331)] 
2025-08-27 23:42:49.566251: Epoch time: 25.27 s 
2025-08-27 23:42:50.284673:  
2025-08-27 23:42:50.294468: Epoch 672 
2025-08-27 23:42:50.302567: Current learning rate: 0.00367 
2025-08-27 23:43:15.527728: train_loss -0.0633 
2025-08-27 23:43:15.536073: val_loss -0.1541 
2025-08-27 23:43:15.540237: Pseudo dice [np.float32(0.6042)] 
2025-08-27 23:43:15.548322: Epoch time: 25.25 s 
2025-08-27 23:43:16.312336:  
2025-08-27 23:43:16.319017: Epoch 673 
2025-08-27 23:43:16.325401: Current learning rate: 0.00366 
2025-08-27 23:43:41.332636: train_loss -0.0827 
2025-08-27 23:43:41.340972: val_loss -0.1235 
2025-08-27 23:43:41.349345: Pseudo dice [np.float32(0.5191)] 
2025-08-27 23:43:41.355472: Epoch time: 25.02 s 
2025-08-27 23:43:42.092223:  
2025-08-27 23:43:42.100013: Epoch 674 
2025-08-27 23:43:42.105243: Current learning rate: 0.00365 
2025-08-27 23:44:07.600521: train_loss -0.0691 
2025-08-27 23:44:07.608920: val_loss -0.0569 
2025-08-27 23:44:07.613040: Pseudo dice [np.float32(0.4223)] 
2025-08-27 23:44:07.620309: Epoch time: 25.51 s 
2025-08-27 23:44:08.349151:  
2025-08-27 23:44:08.357471: Epoch 675 
2025-08-27 23:44:08.363619: Current learning rate: 0.00364 
2025-08-27 23:44:33.672383: train_loss -0.0724 
2025-08-27 23:44:33.680779: val_loss -0.0937 
2025-08-27 23:44:33.689106: Pseudo dice [np.float32(0.6498)] 
2025-08-27 23:44:33.694094: Epoch time: 25.33 s 
2025-08-27 23:44:34.429695:  
2025-08-27 23:44:34.438673: Epoch 676 
2025-08-27 23:44:34.445459: Current learning rate: 0.00363 
2025-08-27 23:44:59.327171: train_loss -0.0866 
2025-08-27 23:44:59.335536: val_loss -0.0863 
2025-08-27 23:44:59.339684: Pseudo dice [np.float32(0.4724)] 
2025-08-27 23:44:59.345861: Epoch time: 24.9 s 
2025-08-27 23:45:00.233209:  
2025-08-27 23:45:00.240496: Epoch 677 
2025-08-27 23:45:00.244722: Current learning rate: 0.00362 
2025-08-27 23:45:26.008463: train_loss -0.0793 
2025-08-27 23:45:26.016337: val_loss -0.0707 
2025-08-27 23:45:26.020783: Pseudo dice [np.float32(0.5923)] 
2025-08-27 23:45:26.027686: Epoch time: 25.78 s 
2025-08-27 23:45:26.751381:  
2025-08-27 23:45:26.759743: Epoch 678 
2025-08-27 23:45:26.764910: Current learning rate: 0.00361 
2025-08-27 23:45:51.863032: train_loss -0.0742 
2025-08-27 23:45:51.871298: val_loss -0.049 
2025-08-27 23:45:51.875468: Pseudo dice [np.float32(0.5296)] 
2025-08-27 23:45:51.883510: Epoch time: 25.11 s 
2025-08-27 23:45:52.609693:  
2025-08-27 23:45:52.617710: Epoch 679 
2025-08-27 23:45:52.624915: Current learning rate: 0.0036 
2025-08-27 23:46:17.472363: train_loss -0.0535 
2025-08-27 23:46:17.480244: val_loss -0.0951 
2025-08-27 23:46:17.484676: Pseudo dice [np.float32(0.5769)] 
2025-08-27 23:46:17.491468: Epoch time: 24.87 s 
2025-08-27 23:46:18.223579:  
2025-08-27 23:46:18.230777: Epoch 680 
2025-08-27 23:46:18.237119: Current learning rate: 0.00359 
2025-08-27 23:46:44.081762: train_loss -0.0675 
2025-08-27 23:46:44.090109: val_loss -0.0661 
2025-08-27 23:46:44.099072: Pseudo dice [np.float32(0.3264)] 
2025-08-27 23:46:44.103837: Epoch time: 25.86 s 
2025-08-27 23:46:44.853396:  
2025-08-27 23:46:44.863247: Epoch 681 
2025-08-27 23:46:44.865867: Current learning rate: 0.00358 
2025-08-27 23:47:10.016013: train_loss -0.0569 
2025-08-27 23:47:10.028861: val_loss -0.0647 
2025-08-27 23:47:10.033035: Pseudo dice [np.float32(0.3031)] 
2025-08-27 23:47:10.041934: Epoch time: 25.16 s 
2025-08-27 23:47:10.786512:  
2025-08-27 23:47:10.796637: Epoch 682 
2025-08-27 23:47:10.804954: Current learning rate: 0.00357 
2025-08-27 23:47:36.492890: train_loss -0.084 
2025-08-27 23:47:36.504929: val_loss -0.113 
2025-08-27 23:47:36.509093: Pseudo dice [np.float32(0.598)] 
2025-08-27 23:47:36.515253: Epoch time: 25.71 s 
2025-08-27 23:47:37.280649:  
2025-08-27 23:47:37.289634: Epoch 683 
2025-08-27 23:47:37.293671: Current learning rate: 0.00356 
2025-08-27 23:48:03.215005: train_loss -0.0738 
2025-08-27 23:48:03.223583: val_loss -0.0551 
2025-08-27 23:48:03.231992: Pseudo dice [np.float32(0.4565)] 
2025-08-27 23:48:03.236717: Epoch time: 25.94 s 
2025-08-27 23:48:03.994757:  
2025-08-27 23:48:04.003055: Epoch 684 
2025-08-27 23:48:04.009391: Current learning rate: 0.00355 
2025-08-27 23:48:29.399395: train_loss -0.0599 
2025-08-27 23:48:29.407731: val_loss -0.1273 
2025-08-27 23:48:29.411906: Pseudo dice [np.float32(0.5947)] 
2025-08-27 23:48:29.419794: Epoch time: 25.41 s 
2025-08-27 23:48:30.086447:  
2025-08-27 23:48:30.095855: Epoch 685 
2025-08-27 23:48:30.102124: Current learning rate: 0.00354 
2025-08-27 23:48:54.516148: train_loss -0.0601 
2025-08-27 23:48:54.524479: val_loss -0.051 
2025-08-27 23:48:54.532425: Pseudo dice [np.float32(0.3015)] 
2025-08-27 23:48:54.537683: Epoch time: 24.43 s 
2025-08-27 23:48:55.202170:  
2025-08-27 23:48:55.209493: Epoch 686 
2025-08-27 23:48:55.214680: Current learning rate: 0.00353 
2025-08-27 23:49:21.355583: train_loss -0.0619 
2025-08-27 23:49:21.363771: val_loss -0.059 
2025-08-27 23:49:21.367943: Pseudo dice [np.float32(0.6682)] 
2025-08-27 23:49:21.376287: Epoch time: 26.15 s 
2025-08-27 23:49:22.050810:  
2025-08-27 23:49:22.059146: Epoch 687 
2025-08-27 23:49:22.064300: Current learning rate: 0.00352 
2025-08-27 23:49:46.317849: train_loss -0.0553 
2025-08-27 23:49:46.326196: val_loss -0.0717 
2025-08-27 23:49:46.334547: Pseudo dice [np.float32(0.5501)] 
2025-08-27 23:49:46.339610: Epoch time: 24.27 s 
2025-08-27 23:49:47.016418:  
2025-08-27 23:49:47.023813: Epoch 688 
2025-08-27 23:49:47.029929: Current learning rate: 0.00351 
2025-08-27 23:50:11.569308: train_loss -0.074 
2025-08-27 23:50:11.576542: val_loss -0.0596 
2025-08-27 23:50:11.580556: Pseudo dice [np.float32(0.6058)] 
2025-08-27 23:50:11.588908: Epoch time: 24.56 s 
2025-08-27 23:50:12.407714:  
2025-08-27 23:50:12.414655: Epoch 689 
2025-08-27 23:50:12.420918: Current learning rate: 0.0035 
2025-08-27 23:50:38.378476: train_loss -0.0679 
2025-08-27 23:50:38.387035: val_loss -0.0971 
2025-08-27 23:50:38.395091: Pseudo dice [np.float32(0.5307)] 
2025-08-27 23:50:38.400481: Epoch time: 25.97 s 
2025-08-27 23:50:39.080898:  
2025-08-27 23:50:39.088202: Epoch 690 
2025-08-27 23:50:39.093394: Current learning rate: 0.00349 
2025-08-27 23:51:03.528251: train_loss -0.0939 
2025-08-27 23:51:03.536657: val_loss -0.0701 
2025-08-27 23:51:03.540797: Pseudo dice [np.float32(0.3468)] 
2025-08-27 23:51:03.548711: Epoch time: 24.45 s 
2025-08-27 23:51:04.213279:  
2025-08-27 23:51:04.221666: Epoch 691 
2025-08-27 23:51:04.226821: Current learning rate: 0.00348 
2025-08-27 23:51:28.670094: train_loss -0.0671 
2025-08-27 23:51:28.678379: val_loss -0.101 
2025-08-27 23:51:28.686717: Pseudo dice [np.float32(0.4809)] 
2025-08-27 23:51:28.692667: Epoch time: 24.46 s 
2025-08-27 23:51:29.371746:  
2025-08-27 23:51:29.378905: Epoch 692 
2025-08-27 23:51:29.384245: Current learning rate: 0.00346 
2025-08-27 23:51:55.672207: train_loss -0.0716 
2025-08-27 23:51:55.681101: val_loss -0.0686 
2025-08-27 23:51:55.685153: Pseudo dice [np.float32(0.4671)] 
2025-08-27 23:51:55.693725: Epoch time: 26.3 s 
2025-08-27 23:51:56.363199:  
2025-08-27 23:51:56.371565: Epoch 693 
2025-08-27 23:51:56.376716: Current learning rate: 0.00345 
2025-08-27 23:52:20.680495: train_loss -0.0816 
2025-08-27 23:52:20.688638: val_loss -0.0697 
2025-08-27 23:52:20.696969: Pseudo dice [np.float32(0.528)] 
2025-08-27 23:52:20.702401: Epoch time: 24.32 s 
2025-08-27 23:52:21.457105:  
2025-08-27 23:52:21.465427: Epoch 694 
2025-08-27 23:52:21.470629: Current learning rate: 0.00344 
2025-08-27 23:52:46.256123: train_loss -0.0926 
2025-08-27 23:52:46.264171: val_loss -0.0613 
2025-08-27 23:52:46.268338: Pseudo dice [np.float32(0.3369)] 
2025-08-27 23:52:46.274437: Epoch time: 24.8 s 
2025-08-27 23:52:47.098208:  
2025-08-27 23:52:47.106649: Epoch 695 
2025-08-27 23:52:47.112875: Current learning rate: 0.00343 
2025-08-27 23:53:12.971695: train_loss -0.0576 
2025-08-27 23:53:12.978325: val_loss -0.1203 
2025-08-27 23:53:12.982478: Pseudo dice [np.float32(0.5579)] 
2025-08-27 23:53:12.991665: Epoch time: 25.87 s 
2025-08-27 23:53:13.733102:  
2025-08-27 23:53:13.741655: Epoch 696 
2025-08-27 23:53:13.747950: Current learning rate: 0.00342 
2025-08-27 23:53:38.679003: train_loss -0.0525 
2025-08-27 23:53:38.687346: val_loss -0.1251 
2025-08-27 23:53:38.691540: Pseudo dice [np.float32(0.6621)] 
2025-08-27 23:53:38.697616: Epoch time: 24.95 s 
2025-08-27 23:53:39.408725:  
2025-08-27 23:53:39.416078: Epoch 697 
2025-08-27 23:53:39.421222: Current learning rate: 0.00341 
2025-08-27 23:54:04.671660: train_loss -0.0751 
2025-08-27 23:54:04.679999: val_loss -0.1058 
2025-08-27 23:54:04.684426: Pseudo dice [np.float32(0.4542)] 
2025-08-27 23:54:04.690279: Epoch time: 25.26 s 
2025-08-27 23:54:05.399324:  
2025-08-27 23:54:05.408712: Epoch 698 
2025-08-27 23:54:05.415115: Current learning rate: 0.0034 
2025-08-27 23:54:31.106611: train_loss -0.0853 
2025-08-27 23:54:31.114982: val_loss -0.0428 
2025-08-27 23:54:31.123015: Pseudo dice [np.float32(0.4621)] 
2025-08-27 23:54:31.129117: Epoch time: 25.71 s 
2025-08-27 23:54:31.863417:  
2025-08-27 23:54:31.871460: Epoch 699 
2025-08-27 23:54:31.877777: Current learning rate: 0.00339 
2025-08-27 23:54:57.107372: train_loss -0.0763 
2025-08-27 23:54:57.115628: val_loss -0.0789 
2025-08-27 23:54:57.120102: Pseudo dice [np.float32(0.559)] 
2025-08-27 23:54:57.126878: Epoch time: 25.25 s 
2025-08-27 23:54:58.026890:  
2025-08-27 23:54:58.035206: Epoch 700 
2025-08-27 23:54:58.040366: Current learning rate: 0.00338 
2025-08-27 23:55:22.761925: train_loss -0.0609 
2025-08-27 23:55:22.770497: val_loss -0.1268 
2025-08-27 23:55:22.774873: Pseudo dice [np.float32(0.7136)] 
2025-08-27 23:55:22.780527: Epoch time: 24.74 s 
2025-08-27 23:55:23.691229:  
2025-08-27 23:55:23.696756: Epoch 701 
2025-08-27 23:55:23.707182: Current learning rate: 0.00337 
2025-08-27 23:55:48.421179: train_loss -0.0766 
2025-08-27 23:55:48.429370: val_loss -0.0714 
2025-08-27 23:55:48.437723: Pseudo dice [np.float32(0.4991)] 
2025-08-27 23:55:48.443156: Epoch time: 24.73 s 
2025-08-27 23:55:49.188631:  
2025-08-27 23:55:49.193016: Epoch 702 
2025-08-27 23:55:49.203619: Current learning rate: 0.00336 
2025-08-27 23:56:13.913160: train_loss -0.0863 
2025-08-27 23:56:13.921690: val_loss -0.0915 
2025-08-27 23:56:13.925676: Pseudo dice [np.float32(0.4439)] 
2025-08-27 23:56:13.934748: Epoch time: 24.73 s 
2025-08-27 23:56:14.676322:  
2025-08-27 23:56:14.685804: Epoch 703 
2025-08-27 23:56:14.690953: Current learning rate: 0.00335 
2025-08-27 23:56:40.556718: train_loss -0.0606 
2025-08-27 23:56:40.565027: val_loss -0.0646 
2025-08-27 23:56:40.573114: Pseudo dice [np.float32(0.3419)] 
2025-08-27 23:56:40.578625: Epoch time: 25.88 s 
2025-08-27 23:56:41.357026:  
2025-08-27 23:56:41.364387: Epoch 704 
2025-08-27 23:56:41.370709: Current learning rate: 0.00334 
2025-08-27 23:57:06.870213: train_loss -0.1085 
2025-08-27 23:57:06.878517: val_loss -0.1004 
2025-08-27 23:57:06.882712: Pseudo dice [np.float32(0.6195)] 
2025-08-27 23:57:06.889654: Epoch time: 25.52 s 
2025-08-27 23:57:07.660518:  
2025-08-27 23:57:07.669818: Epoch 705 
2025-08-27 23:57:07.680485: Current learning rate: 0.00333 
2025-08-27 23:57:32.276895: train_loss -0.0811 
2025-08-27 23:57:32.287551: val_loss -0.1555 
2025-08-27 23:57:32.297930: Pseudo dice [np.float32(0.6172)] 
2025-08-27 23:57:32.305698: Epoch time: 24.62 s 
2025-08-27 23:57:33.064066:  
2025-08-27 23:57:33.073014: Epoch 706 
2025-08-27 23:57:33.082277: Current learning rate: 0.00332 
2025-08-27 23:57:58.713572: train_loss -0.0793 
2025-08-27 23:57:58.721972: val_loss -0.0536 
2025-08-27 23:57:58.726180: Pseudo dice [np.float32(0.3678)] 
2025-08-27 23:57:58.734071: Epoch time: 25.65 s 
2025-08-27 23:57:59.481315:  
2025-08-27 23:57:59.489234: Epoch 707 
2025-08-27 23:57:59.495549: Current learning rate: 0.00331 
2025-08-27 23:58:25.436083: train_loss -0.0703 
2025-08-27 23:58:25.444079: val_loss -0.049 
2025-08-27 23:58:25.448641: Pseudo dice [np.float32(0.4833)] 
2025-08-27 23:58:25.453984: Epoch time: 25.96 s 
2025-08-27 23:58:26.188979:  
2025-08-27 23:58:26.199338: Epoch 708 
2025-08-27 23:58:26.207646: Current learning rate: 0.0033 
2025-08-27 23:58:51.424605: train_loss -0.066 
2025-08-27 23:58:51.432925: val_loss -0.1054 
2025-08-27 23:58:51.437098: Pseudo dice [np.float32(0.5088)] 
2025-08-27 23:58:51.444548: Epoch time: 25.24 s 
2025-08-27 23:58:52.191943:  
2025-08-27 23:58:52.200171: Epoch 709 
2025-08-27 23:58:52.210947: Current learning rate: 0.00329 
2025-08-27 23:59:17.488062: train_loss -0.0791 
2025-08-27 23:59:17.496715: val_loss -0.0412 
2025-08-27 23:59:17.504771: Pseudo dice [np.float32(0.2429)] 
2025-08-27 23:59:17.510890: Epoch time: 25.3 s 
2025-08-27 23:59:18.232028:  
2025-08-27 23:59:18.244156: Epoch 710 
2025-08-27 23:59:18.252750: Current learning rate: 0.00328 
2025-08-27 23:59:43.256062: train_loss -0.053 
2025-08-27 23:59:43.263854: val_loss -0.0857 
2025-08-27 23:59:43.267977: Pseudo dice [np.float32(0.4945)] 
2025-08-27 23:59:43.275043: Epoch time: 25.03 s 
2025-08-27 23:59:43.994695:  
2025-08-27 23:59:44.002858: Epoch 711 
2025-08-27 23:59:44.010453: Current learning rate: 0.00327 
2025-08-28 00:00:09.102123: train_loss -0.0683 
2025-08-28 00:00:09.110426: val_loss -0.1334 
2025-08-28 00:00:09.114988: Pseudo dice [np.float32(0.7139)] 
2025-08-28 00:00:09.121696: Epoch time: 25.11 s 
2025-08-28 00:00:09.856861:  
2025-08-28 00:00:09.868364: Epoch 712 
2025-08-28 00:00:09.876189: Current learning rate: 0.00326 
2025-08-28 00:00:35.353613: train_loss -0.076 
2025-08-28 00:00:35.361654: val_loss -0.0319 
2025-08-28 00:00:35.369976: Pseudo dice [np.float32(0.4961)] 
2025-08-28 00:00:35.375595: Epoch time: 25.5 s 
2025-08-28 00:00:36.280264:  
2025-08-28 00:00:36.287816: Epoch 713 
2025-08-28 00:00:36.295859: Current learning rate: 0.00325 
2025-08-28 00:01:02.743213: train_loss -0.0903 
2025-08-28 00:01:02.751483: val_loss -0.0896 
2025-08-28 00:01:02.755645: Pseudo dice [np.float32(0.4916)] 
2025-08-28 00:01:02.763992: Epoch time: 26.47 s 
2025-08-28 00:01:03.501115:  
2025-08-28 00:01:03.508405: Epoch 714 
2025-08-28 00:01:03.514632: Current learning rate: 0.00324 
2025-08-28 00:01:29.136645: train_loss -0.1092 
2025-08-28 00:01:29.144497: val_loss -0.0778 
2025-08-28 00:01:29.148822: Pseudo dice [np.float32(0.4142)] 
2025-08-28 00:01:29.157882: Epoch time: 25.64 s 
2025-08-28 00:01:29.884007:  
2025-08-28 00:01:29.892089: Epoch 715 
2025-08-28 00:01:29.897250: Current learning rate: 0.00323 
2025-08-28 00:01:55.161974: train_loss -0.0547 
2025-08-28 00:01:55.170590: val_loss -0.0833 
2025-08-28 00:01:55.174967: Pseudo dice [np.float32(0.6383)] 
2025-08-28 00:01:55.180918: Epoch time: 25.28 s 
2025-08-28 00:01:55.895044:  
2025-08-28 00:01:55.904461: Epoch 716 
2025-08-28 00:01:55.910748: Current learning rate: 0.00322 
2025-08-28 00:02:22.059789: train_loss -0.0855 
2025-08-28 00:02:22.064250: val_loss -0.0674 
2025-08-28 00:02:22.072941: Pseudo dice [np.float32(0.4698)] 
2025-08-28 00:02:22.077803: Epoch time: 26.17 s 
2025-08-28 00:02:22.817610:  
2025-08-28 00:02:22.827101: Epoch 717 
2025-08-28 00:02:22.835477: Current learning rate: 0.00321 
2025-08-28 00:02:48.824267: train_loss -0.0778 
2025-08-28 00:02:48.836555: val_loss -0.1176 
2025-08-28 00:02:48.840741: Pseudo dice [np.float32(0.5975)] 
2025-08-28 00:02:48.846898: Epoch time: 26.01 s 
2025-08-28 00:02:49.583070:  
2025-08-28 00:02:49.591246: Epoch 718 
2025-08-28 00:02:49.598652: Current learning rate: 0.0032 
2025-08-28 00:03:14.670665: train_loss -0.069 
2025-08-28 00:03:14.679032: val_loss -0.025 
2025-08-28 00:03:14.683147: Pseudo dice [np.float32(0.1251)] 
2025-08-28 00:03:14.689405: Epoch time: 25.09 s 
2025-08-28 00:03:15.577975:  
2025-08-28 00:03:15.587786: Epoch 719 
2025-08-28 00:03:15.592909: Current learning rate: 0.00319 
2025-08-28 00:03:41.156187: train_loss -0.069 
2025-08-28 00:03:41.163786: val_loss -0.0978 
2025-08-28 00:03:41.167938: Pseudo dice [np.float32(0.5484)] 
2025-08-28 00:03:41.176071: Epoch time: 25.58 s 
2025-08-28 00:03:41.916540:  
2025-08-28 00:03:41.926727: Epoch 720 
2025-08-28 00:03:41.933997: Current learning rate: 0.00318 
2025-08-28 00:04:07.460875: train_loss -0.0891 
2025-08-28 00:04:07.469214: val_loss -0.0447 
2025-08-28 00:04:07.473390: Pseudo dice [np.float32(0.1694)] 
2025-08-28 00:04:07.482466: Epoch time: 25.55 s 
2025-08-28 00:04:08.228901:  
2025-08-28 00:04:08.236649: Epoch 721 
2025-08-28 00:04:08.242232: Current learning rate: 0.00317 
2025-08-28 00:04:33.378942: train_loss -0.0862 
2025-08-28 00:04:33.391243: val_loss -0.0944 
2025-08-28 00:04:33.395086: Pseudo dice [np.float32(0.5949)] 
2025-08-28 00:04:33.402358: Epoch time: 25.15 s 
2025-08-28 00:04:34.154147:  
2025-08-28 00:04:34.162509: Epoch 722 
2025-08-28 00:04:34.169693: Current learning rate: 0.00316 
2025-08-28 00:05:00.559728: train_loss -0.0962 
2025-08-28 00:05:00.568055: val_loss -0.0618 
2025-08-28 00:05:00.572258: Pseudo dice [np.float32(0.5087)] 
2025-08-28 00:05:00.579242: Epoch time: 26.41 s 
2025-08-28 00:05:01.332473:  
2025-08-28 00:05:01.344282: Epoch 723 
2025-08-28 00:05:01.348419: Current learning rate: 0.00315 
2025-08-28 00:05:26.322933: train_loss -0.0826 
2025-08-28 00:05:26.331506: val_loss -0.0597 
2025-08-28 00:05:26.335766: Pseudo dice [np.float32(0.528)] 
2025-08-28 00:05:26.341717: Epoch time: 24.99 s 
2025-08-28 00:05:27.096202:  
2025-08-28 00:05:27.104926: Epoch 724 
2025-08-28 00:05:27.113268: Current learning rate: 0.00314 
2025-08-28 00:05:52.507524: train_loss -0.0759 
2025-08-28 00:05:52.516111: val_loss -0.1145 
2025-08-28 00:05:52.520264: Pseudo dice [np.float32(0.5553)] 
2025-08-28 00:05:52.526088: Epoch time: 25.41 s 
2025-08-28 00:05:53.269542:  
2025-08-28 00:05:53.277759: Epoch 725 
2025-08-28 00:05:53.286898: Current learning rate: 0.00313 
2025-08-28 00:06:19.229902: train_loss -0.0748 
2025-08-28 00:06:19.234127: val_loss -0.0857 
2025-08-28 00:06:19.242766: Pseudo dice [np.float32(0.5912)] 
2025-08-28 00:06:19.247885: Epoch time: 25.96 s 
2025-08-28 00:06:19.996219:  
2025-08-28 00:06:20.006514: Epoch 726 
2025-08-28 00:06:20.014508: Current learning rate: 0.00312 
2025-08-28 00:06:45.302105: train_loss -0.0542 
2025-08-28 00:06:45.310504: val_loss -0.0744 
2025-08-28 00:06:45.318501: Pseudo dice [np.float32(0.4015)] 
2025-08-28 00:06:45.323904: Epoch time: 25.31 s 
2025-08-28 00:06:46.082237:  
2025-08-28 00:06:46.092508: Epoch 727 
2025-08-28 00:06:46.098277: Current learning rate: 0.00311 
2025-08-28 00:07:10.877371: train_loss -0.0905 
2025-08-28 00:07:10.885712: val_loss -0.1358 
2025-08-28 00:07:10.889899: Pseudo dice [np.float32(0.6281)] 
2025-08-28 00:07:10.897931: Epoch time: 24.8 s 
2025-08-28 00:07:11.641211:  
2025-08-28 00:07:11.649147: Epoch 728 
2025-08-28 00:07:11.653543: Current learning rate: 0.0031 
2025-08-28 00:07:37.387100: train_loss -0.0592 
2025-08-28 00:07:37.395968: val_loss -0.0632 
2025-08-28 00:07:37.399839: Pseudo dice [np.float32(0.5337)] 
2025-08-28 00:07:37.409451: Epoch time: 25.75 s 
2025-08-28 00:07:38.171223:  
2025-08-28 00:07:38.175889: Epoch 729 
2025-08-28 00:07:38.184316: Current learning rate: 0.00309 
2025-08-28 00:08:03.005006: train_loss -0.0766 
2025-08-28 00:08:03.013044: val_loss -0.0493 
2025-08-28 00:08:03.021018: Pseudo dice [np.float32(0.2773)] 
2025-08-28 00:08:03.027335: Epoch time: 24.84 s 
2025-08-28 00:08:03.782172:  
2025-08-28 00:08:03.788543: Epoch 730 
2025-08-28 00:08:03.797881: Current learning rate: 0.00308 
2025-08-28 00:08:28.880174: train_loss -0.0923 
2025-08-28 00:08:28.888526: val_loss -0.0539 
2025-08-28 00:08:28.896890: Pseudo dice [np.float32(0.5655)] 
2025-08-28 00:08:28.902261: Epoch time: 25.1 s 
2025-08-28 00:08:29.796221:  
2025-08-28 00:08:29.805967: Epoch 731 
2025-08-28 00:08:29.810524: Current learning rate: 0.00307 
2025-08-28 00:08:55.994743: train_loss -0.0948 
2025-08-28 00:08:56.003082: val_loss -0.088 
2025-08-28 00:08:56.007260: Pseudo dice [np.float32(0.4955)] 
2025-08-28 00:08:56.014742: Epoch time: 26.2 s 
2025-08-28 00:08:56.762854:  
2025-08-28 00:08:56.769702: Epoch 732 
2025-08-28 00:08:56.774973: Current learning rate: 0.00306 
2025-08-28 00:09:22.454524: train_loss -0.1 
2025-08-28 00:09:22.462915: val_loss -0.0905 
2025-08-28 00:09:22.467826: Pseudo dice [np.float32(0.5507)] 
2025-08-28 00:09:22.474270: Epoch time: 25.69 s 
2025-08-28 00:09:23.204134:  
2025-08-28 00:09:23.213973: Epoch 733 
2025-08-28 00:09:23.221810: Current learning rate: 0.00305 
2025-08-28 00:09:48.288612: train_loss -0.0624 
2025-08-28 00:09:48.296953: val_loss -0.0966 
2025-08-28 00:09:48.301166: Pseudo dice [np.float32(0.5704)] 
2025-08-28 00:09:48.308186: Epoch time: 25.09 s 
2025-08-28 00:09:49.031052:  
2025-08-28 00:09:49.039325: Epoch 734 
2025-08-28 00:09:49.043972: Current learning rate: 0.00304 
2025-08-28 00:10:14.011214: train_loss -0.0918 
2025-08-28 00:10:14.018474: val_loss -0.1229 
2025-08-28 00:10:14.022653: Pseudo dice [np.float32(0.5595)] 
2025-08-28 00:10:14.031075: Epoch time: 24.98 s 
2025-08-28 00:10:14.783847:  
2025-08-28 00:10:14.791087: Epoch 735 
2025-08-28 00:10:14.796347: Current learning rate: 0.00303 
2025-08-28 00:10:39.769173: train_loss -0.059 
2025-08-28 00:10:39.781716: val_loss -0.1115 
2025-08-28 00:10:39.785912: Pseudo dice [np.float32(0.5203)] 
2025-08-28 00:10:39.792032: Epoch time: 24.99 s 
2025-08-28 00:10:40.544780:  
2025-08-28 00:10:40.550671: Epoch 736 
2025-08-28 00:10:40.558246: Current learning rate: 0.00302 
2025-08-28 00:11:05.423963: train_loss -0.0949 
2025-08-28 00:11:05.432606: val_loss -0.0853 
2025-08-28 00:11:05.436867: Pseudo dice [np.float32(0.3571)] 
2025-08-28 00:11:05.445539: Epoch time: 24.88 s 
2025-08-28 00:11:06.327789:  
2025-08-28 00:11:06.335282: Epoch 737 
2025-08-28 00:11:06.341443: Current learning rate: 0.00301 
2025-08-28 00:11:32.313349: train_loss -0.1142 
2025-08-28 00:11:32.321435: val_loss -0.055 
2025-08-28 00:11:32.326140: Pseudo dice [np.float32(0.2444)] 
2025-08-28 00:11:32.331296: Epoch time: 25.99 s 
2025-08-28 00:11:33.065154:  
2025-08-28 00:11:33.077293: Epoch 738 
2025-08-28 00:11:33.084837: Current learning rate: 0.003 
2025-08-28 00:11:58.282346: train_loss -0.0811 
2025-08-28 00:11:58.289246: val_loss -0.0806 
2025-08-28 00:11:58.293731: Pseudo dice [np.float32(0.5657)] 
2025-08-28 00:11:58.301456: Epoch time: 25.22 s 
2025-08-28 00:11:59.043304:  
2025-08-28 00:11:59.052787: Epoch 739 
2025-08-28 00:11:59.056997: Current learning rate: 0.00299 
2025-08-28 00:12:24.423916: train_loss -0.0818 
2025-08-28 00:12:24.432014: val_loss -0.1296 
2025-08-28 00:12:24.438370: Pseudo dice [np.float32(0.5873)] 
2025-08-28 00:12:24.444160: Epoch time: 25.38 s 
2025-08-28 00:12:25.170075:  
2025-08-28 00:12:25.177412: Epoch 740 
2025-08-28 00:12:25.183862: Current learning rate: 0.00297 
2025-08-28 00:12:50.624799: train_loss -0.0695 
2025-08-28 00:12:50.633142: val_loss -0.0268 
2025-08-28 00:12:50.641485: Pseudo dice [np.float32(0.0775)] 
2025-08-28 00:12:50.647799: Epoch time: 25.46 s 
2025-08-28 00:12:51.395266:  
2025-08-28 00:12:51.402579: Epoch 741 
2025-08-28 00:12:51.407751: Current learning rate: 0.00296 
2025-08-28 00:13:17.193095: train_loss -0.0857 
2025-08-28 00:13:17.201335: val_loss -0.0892 
2025-08-28 00:13:17.205551: Pseudo dice [np.float32(0.7157)] 
2025-08-28 00:13:17.211667: Epoch time: 25.8 s 
2025-08-28 00:13:17.972082:  
2025-08-28 00:13:17.977505: Epoch 742 
2025-08-28 00:13:17.986713: Current learning rate: 0.00295 
2025-08-28 00:13:43.077169: train_loss -0.0979 
2025-08-28 00:13:43.085855: val_loss -0.0653 
2025-08-28 00:13:43.093873: Pseudo dice [np.float32(0.291)] 
2025-08-28 00:13:43.100128: Epoch time: 25.11 s 
2025-08-28 00:13:43.833130:  
2025-08-28 00:13:43.841467: Epoch 743 
2025-08-28 00:13:43.848451: Current learning rate: 0.00294 
2025-08-28 00:14:09.337061: train_loss -0.0873 
2025-08-28 00:14:09.345179: val_loss -0.0483 
2025-08-28 00:14:09.349560: Pseudo dice [np.float32(0.417)] 
2025-08-28 00:14:09.356498: Epoch time: 25.51 s 
2025-08-28 00:14:10.104115:  
2025-08-28 00:14:10.112527: Epoch 744 
2025-08-28 00:14:10.118680: Current learning rate: 0.00293 
2025-08-28 00:14:35.137506: train_loss -0.0722 
2025-08-28 00:14:35.149996: val_loss -0.052 
2025-08-28 00:14:35.154098: Pseudo dice [np.float32(0.5663)] 
2025-08-28 00:14:35.163253: Epoch time: 25.04 s 
2025-08-28 00:14:35.917722:  
2025-08-28 00:14:35.926936: Epoch 745 
2025-08-28 00:14:35.934002: Current learning rate: 0.00292 
2025-08-28 00:15:00.992454: train_loss -0.0844 
2025-08-28 00:15:01.000813: val_loss -0.0848 
2025-08-28 00:15:01.009858: Pseudo dice [np.float32(0.5668)] 
2025-08-28 00:15:01.015223: Epoch time: 25.08 s 
2025-08-28 00:15:01.775529:  
2025-08-28 00:15:01.781775: Epoch 746 
2025-08-28 00:15:01.785631: Current learning rate: 0.00291 
2025-08-28 00:15:27.694091: train_loss -0.0743 
2025-08-28 00:15:27.702468: val_loss -0.1047 
2025-08-28 00:15:27.710801: Pseudo dice [np.float32(0.5431)] 
2025-08-28 00:15:27.716844: Epoch time: 25.92 s 
2025-08-28 00:15:28.535624:  
2025-08-28 00:15:28.541856: Epoch 747 
2025-08-28 00:15:28.548009: Current learning rate: 0.0029 
2025-08-28 00:15:54.143501: train_loss -0.0798 
2025-08-28 00:15:54.149766: val_loss -0.0576 
2025-08-28 00:15:54.157695: Pseudo dice [np.float32(0.4869)] 
2025-08-28 00:15:54.162275: Epoch time: 25.61 s 
2025-08-28 00:15:54.919956:  
2025-08-28 00:15:54.926821: Epoch 748 
2025-08-28 00:15:54.935629: Current learning rate: 0.00289 
2025-08-28 00:16:20.371930: train_loss -0.1153 
2025-08-28 00:16:20.380154: val_loss -0.0865 
2025-08-28 00:16:20.384537: Pseudo dice [np.float32(0.5934)] 
2025-08-28 00:16:20.391380: Epoch time: 25.45 s 
2025-08-28 00:16:21.277823:  
2025-08-28 00:16:21.287133: Epoch 749 
2025-08-28 00:16:21.294226: Current learning rate: 0.00288 
2025-08-28 00:16:46.622925: train_loss -0.0816 
2025-08-28 00:16:46.631264: val_loss -0.1146 
2025-08-28 00:16:46.639420: Pseudo dice [np.float32(0.5988)] 
2025-08-28 00:16:46.644612: Epoch time: 25.35 s 
2025-08-28 00:16:47.584235:  
2025-08-28 00:16:47.593555: Epoch 750 
2025-08-28 00:16:47.603697: Current learning rate: 0.00287 
2025-08-28 00:17:12.937028: train_loss -0.0736 
2025-08-28 00:17:12.945041: val_loss -0.0628 
2025-08-28 00:17:12.953695: Pseudo dice [np.float32(0.4784)] 
2025-08-28 00:17:12.958329: Epoch time: 25.35 s 
2025-08-28 00:17:13.724918:  
2025-08-28 00:17:13.736438: Epoch 751 
2025-08-28 00:17:13.742682: Current learning rate: 0.00286 
2025-08-28 00:17:38.491352: train_loss -0.1169 
2025-08-28 00:17:38.500093: val_loss -0.1043 
2025-08-28 00:17:38.508060: Pseudo dice [np.float32(0.5997)] 
2025-08-28 00:17:38.514207: Epoch time: 24.77 s 
2025-08-28 00:17:39.262826:  
2025-08-28 00:17:39.274428: Epoch 752 
2025-08-28 00:17:39.283659: Current learning rate: 0.00285 
2025-08-28 00:18:04.910041: train_loss -0.0877 
2025-08-28 00:18:04.918075: val_loss -0.0556 
2025-08-28 00:18:04.926098: Pseudo dice [np.float32(0.4403)] 
2025-08-28 00:18:04.932497: Epoch time: 25.65 s 
2025-08-28 00:18:05.683090:  
2025-08-28 00:18:05.693388: Epoch 753 
2025-08-28 00:18:05.700242: Current learning rate: 0.00284 
2025-08-28 00:18:31.056354: train_loss -0.0774 
2025-08-28 00:18:31.064766: val_loss -0.0548 
2025-08-28 00:18:31.068883: Pseudo dice [np.float32(0.4021)] 
2025-08-28 00:18:31.075185: Epoch time: 25.38 s 
2025-08-28 00:18:31.829633:  
2025-08-28 00:18:31.837937: Epoch 754 
2025-08-28 00:18:31.844586: Current learning rate: 0.00283 
2025-08-28 00:18:57.308043: train_loss -0.0676 
2025-08-28 00:18:57.315891: val_loss -0.0674 
2025-08-28 00:18:57.324254: Pseudo dice [np.float32(0.5333)] 
2025-08-28 00:18:57.329661: Epoch time: 25.48 s 
2025-08-28 00:18:58.215649:  
2025-08-28 00:18:58.223959: Epoch 755 
2025-08-28 00:18:58.230359: Current learning rate: 0.00282 
2025-08-28 00:19:23.842370: train_loss -0.0816 
2025-08-28 00:19:23.850749: val_loss -0.0978 
2025-08-28 00:19:23.858739: Pseudo dice [np.float32(0.5058)] 
2025-08-28 00:19:23.863305: Epoch time: 25.63 s 
2025-08-28 00:19:24.603529:  
2025-08-28 00:19:24.610814: Epoch 756 
2025-08-28 00:19:24.616000: Current learning rate: 0.00281 
2025-08-28 00:19:50.164504: train_loss -0.087 
2025-08-28 00:19:50.172906: val_loss -0.1395 
2025-08-28 00:19:50.177340: Pseudo dice [np.float32(0.7172)] 
2025-08-28 00:19:50.186342: Epoch time: 25.56 s 
2025-08-28 00:19:50.945549:  
2025-08-28 00:19:50.953876: Epoch 757 
2025-08-28 00:19:50.961097: Current learning rate: 0.0028 
2025-08-28 00:20:16.641012: train_loss -0.0846 
2025-08-28 00:20:16.649277: val_loss -0.0419 
2025-08-28 00:20:16.654000: Pseudo dice [np.float32(0.443)] 
2025-08-28 00:20:16.661631: Epoch time: 25.7 s 
2025-08-28 00:20:17.409441:  
2025-08-28 00:20:17.419392: Epoch 758 
2025-08-28 00:20:17.426193: Current learning rate: 0.00279 
2025-08-28 00:20:43.100974: train_loss -0.0868 
2025-08-28 00:20:43.113257: val_loss -0.0896 
2025-08-28 00:20:43.117651: Pseudo dice [np.float32(0.6593)] 
2025-08-28 00:20:43.124440: Epoch time: 25.69 s 
2025-08-28 00:20:43.909636:  
2025-08-28 00:20:43.919160: Epoch 759 
2025-08-28 00:20:43.928651: Current learning rate: 0.00278 
2025-08-28 00:21:09.644083: train_loss -0.0947 
2025-08-28 00:21:09.656083: val_loss -0.1151 
2025-08-28 00:21:09.660624: Pseudo dice [np.float32(0.6277)] 
2025-08-28 00:21:09.666685: Epoch time: 25.74 s 
2025-08-28 00:21:09.673584: Yayy! New best EMA pseudo Dice: 0.5372999906539917 
2025-08-28 00:21:10.592399:  
2025-08-28 00:21:10.599404: Epoch 760 
2025-08-28 00:21:10.607945: Current learning rate: 0.00277 
2025-08-28 00:21:36.011912: train_loss -0.0731 
2025-08-28 00:21:36.020152: val_loss -0.1002 
2025-08-28 00:21:36.028514: Pseudo dice [np.float32(0.4923)] 
2025-08-28 00:21:36.034553: Epoch time: 25.42 s 
2025-08-28 00:21:36.908467:  
2025-08-28 00:21:36.917337: Epoch 761 
2025-08-28 00:21:36.922562: Current learning rate: 0.00276 
2025-08-28 00:22:02.880299: train_loss -0.0674 
2025-08-28 00:22:02.888680: val_loss -0.147 
2025-08-28 00:22:02.892785: Pseudo dice [np.float32(0.5525)] 
2025-08-28 00:22:02.900819: Epoch time: 25.97 s 
2025-08-28 00:22:03.660296:  
2025-08-28 00:22:03.668479: Epoch 762 
2025-08-28 00:22:03.677048: Current learning rate: 0.00275 
2025-08-28 00:22:29.181569: train_loss -0.0866 
2025-08-28 00:22:29.194060: val_loss -0.1161 
2025-08-28 00:22:29.198500: Pseudo dice [np.float32(0.4464)] 
2025-08-28 00:22:29.205289: Epoch time: 25.53 s 
2025-08-28 00:22:29.947875:  
2025-08-28 00:22:29.956171: Epoch 763 
2025-08-28 00:22:29.961340: Current learning rate: 0.00274 
2025-08-28 00:22:55.662205: train_loss -0.1038 
2025-08-28 00:22:55.670513: val_loss -0.0761 
2025-08-28 00:22:55.679445: Pseudo dice [np.float32(0.4821)] 
2025-08-28 00:22:55.684290: Epoch time: 25.72 s 
2025-08-28 00:22:56.429435:  
2025-08-28 00:22:56.439074: Epoch 764 
2025-08-28 00:22:56.449449: Current learning rate: 0.00273 
2025-08-28 00:23:21.617466: train_loss -0.0958 
2025-08-28 00:23:21.625606: val_loss -0.0292 
2025-08-28 00:23:21.630074: Pseudo dice [np.float32(0.4193)] 
2025-08-28 00:23:21.637463: Epoch time: 25.19 s 
2025-08-28 00:23:22.369994:  
2025-08-28 00:23:22.377339: Epoch 765 
2025-08-28 00:23:22.383851: Current learning rate: 0.00272 
2025-08-28 00:23:47.552196: train_loss -0.0648 
2025-08-28 00:23:47.564024: val_loss -0.1161 
2025-08-28 00:23:47.568164: Pseudo dice [np.float32(0.6275)] 
2025-08-28 00:23:47.574265: Epoch time: 25.18 s 
2025-08-28 00:23:48.353314:  
2025-08-28 00:23:48.361640: Epoch 766 
2025-08-28 00:23:48.367791: Current learning rate: 0.00271 
2025-08-28 00:24:14.457713: train_loss -0.0671 
2025-08-28 00:24:14.465951: val_loss -0.0883 
2025-08-28 00:24:14.470093: Pseudo dice [np.float32(0.5609)] 
2025-08-28 00:24:14.479189: Epoch time: 26.11 s 
2025-08-28 00:24:15.441800:  
2025-08-28 00:24:15.452650: Epoch 767 
2025-08-28 00:24:15.461230: Current learning rate: 0.0027 
2025-08-28 00:24:40.450465: train_loss -0.08 
2025-08-28 00:24:40.458826: val_loss -0.1685 
2025-08-28 00:24:40.462616: Pseudo dice [np.float32(0.6702)] 
2025-08-28 00:24:40.471051: Epoch time: 25.01 s 
2025-08-28 00:24:40.476141: Yayy! New best EMA pseudo Dice: 0.541100025177002 
2025-08-28 00:24:41.448982:  
2025-08-28 00:24:41.458379: Epoch 768 
2025-08-28 00:24:41.469740: Current learning rate: 0.00268 
2025-08-28 00:25:06.788879: train_loss -0.0806 
2025-08-28 00:25:06.797289: val_loss -0.0517 
2025-08-28 00:25:06.801757: Pseudo dice [np.float32(0.5878)] 
2025-08-28 00:25:06.809433: Epoch time: 25.34 s 
2025-08-28 00:25:06.815489: Yayy! New best EMA pseudo Dice: 0.545799970626831 
2025-08-28 00:25:07.752384:  
2025-08-28 00:25:07.760741: Epoch 769 
2025-08-28 00:25:07.767894: Current learning rate: 0.00267 
2025-08-28 00:25:32.878045: train_loss -0.0813 
2025-08-28 00:25:32.885817: val_loss -0.0887 
2025-08-28 00:25:32.889977: Pseudo dice [np.float32(0.6948)] 
2025-08-28 00:25:32.899534: Epoch time: 25.13 s 
2025-08-28 00:25:32.903276: Yayy! New best EMA pseudo Dice: 0.560699999332428 
2025-08-28 00:25:33.881495:  
2025-08-28 00:25:33.894056: Epoch 770 
2025-08-28 00:25:33.899149: Current learning rate: 0.00266 
2025-08-28 00:25:58.612028: train_loss -0.08 
2025-08-28 00:25:58.619829: val_loss -0.059 
2025-08-28 00:25:58.624282: Pseudo dice [np.float32(0.6148)] 
2025-08-28 00:25:58.633067: Epoch time: 24.73 s 
2025-08-28 00:25:58.639086: Yayy! New best EMA pseudo Dice: 0.566100001335144 
2025-08-28 00:25:59.606726:  
2025-08-28 00:25:59.615186: Epoch 771 
2025-08-28 00:25:59.622543: Current learning rate: 0.00265 
2025-08-28 00:26:24.700558: train_loss -0.0602 
2025-08-28 00:26:24.708972: val_loss -0.1148 
2025-08-28 00:26:24.712884: Pseudo dice [np.float32(0.5198)] 
2025-08-28 00:26:24.719720: Epoch time: 25.1 s 
2025-08-28 00:26:25.620666:  
2025-08-28 00:26:25.627977: Epoch 772 
2025-08-28 00:26:25.633135: Current learning rate: 0.00264 
2025-08-28 00:26:50.713598: train_loss -0.0893 
2025-08-28 00:26:50.721855: val_loss -0.1471 
2025-08-28 00:26:50.726213: Pseudo dice [np.float32(0.5666)] 
2025-08-28 00:26:50.734087: Epoch time: 25.09 s 
2025-08-28 00:26:51.469444:  
2025-08-28 00:26:51.477789: Epoch 773 
2025-08-28 00:26:51.485041: Current learning rate: 0.00263 
2025-08-28 00:27:16.502482: train_loss -0.1046 
2025-08-28 00:27:16.510090: val_loss -0.1259 
2025-08-28 00:27:16.518459: Pseudo dice [np.float32(0.5462)] 
2025-08-28 00:27:16.523995: Epoch time: 25.03 s 
2025-08-28 00:27:17.264871:  
2025-08-28 00:27:17.273236: Epoch 774 
2025-08-28 00:27:17.281600: Current learning rate: 0.00262 
2025-08-28 00:27:42.169033: train_loss -0.0919 
2025-08-28 00:27:42.177419: val_loss -0.1305 
2025-08-28 00:27:42.185726: Pseudo dice [np.float32(0.6126)] 
2025-08-28 00:27:42.191148: Epoch time: 24.91 s 
2025-08-28 00:27:42.951071:  
2025-08-28 00:27:42.960192: Epoch 775 
2025-08-28 00:27:42.967762: Current learning rate: 0.00261 
2025-08-28 00:28:08.186653: train_loss -0.0859 
2025-08-28 00:28:08.195010: val_loss -0.0751 
2025-08-28 00:28:08.199589: Pseudo dice [np.float32(0.3909)] 
2025-08-28 00:28:08.208373: Epoch time: 25.24 s 
2025-08-28 00:28:08.955732:  
2025-08-28 00:28:08.963590: Epoch 776 
2025-08-28 00:28:08.970641: Current learning rate: 0.0026 
2025-08-28 00:28:34.304496: train_loss -0.0534 
2025-08-28 00:28:34.312836: val_loss -0.1101 
2025-08-28 00:28:34.321115: Pseudo dice [np.float32(0.516)] 
2025-08-28 00:28:34.326627: Epoch time: 25.35 s 
2025-08-28 00:28:35.065538:  
2025-08-28 00:28:35.074867: Epoch 777 
2025-08-28 00:28:35.081200: Current learning rate: 0.00259 
2025-08-28 00:29:00.572066: train_loss -0.0835 
2025-08-28 00:29:00.581040: val_loss -0.0575 
2025-08-28 00:29:00.585167: Pseudo dice [np.float32(0.4748)] 
2025-08-28 00:29:00.593864: Epoch time: 25.51 s 
2025-08-28 00:29:01.505428:  
2025-08-28 00:29:01.517160: Epoch 778 
2025-08-28 00:29:01.525513: Current learning rate: 0.00258 
2025-08-28 00:29:26.681957: train_loss -0.0853 
2025-08-28 00:29:26.690084: val_loss -0.0596 
2025-08-28 00:29:26.698649: Pseudo dice [np.float32(0.6002)] 
2025-08-28 00:29:26.704076: Epoch time: 25.18 s 
2025-08-28 00:29:27.448018:  
2025-08-28 00:29:27.456425: Epoch 779 
2025-08-28 00:29:27.462666: Current learning rate: 0.00257 
2025-08-28 00:29:52.632946: train_loss -0.0793 
2025-08-28 00:29:52.640952: val_loss -0.0456 
2025-08-28 00:29:52.649616: Pseudo dice [np.float32(0.31)] 
2025-08-28 00:29:52.656599: Epoch time: 25.19 s 
2025-08-28 00:29:53.414566:  
2025-08-28 00:29:53.421145: Epoch 780 
2025-08-28 00:29:53.430305: Current learning rate: 0.00256 
2025-08-28 00:30:18.788019: train_loss -0.0691 
2025-08-28 00:30:18.796243: val_loss -0.058 
2025-08-28 00:30:18.804656: Pseudo dice [np.float32(0.4594)] 
2025-08-28 00:30:18.810682: Epoch time: 25.38 s 
2025-08-28 00:30:19.572016:  
2025-08-28 00:30:19.580203: Epoch 781 
2025-08-28 00:30:19.585536: Current learning rate: 0.00255 
2025-08-28 00:30:44.580286: train_loss -0.0762 
2025-08-28 00:30:44.588621: val_loss -0.1275 
2025-08-28 00:30:44.592752: Pseudo dice [np.float32(0.5452)] 
2025-08-28 00:30:44.602487: Epoch time: 25.01 s 
2025-08-28 00:30:45.355930:  
2025-08-28 00:30:45.364333: Epoch 782 
2025-08-28 00:30:45.370747: Current learning rate: 0.00254 
2025-08-28 00:31:10.610842: train_loss -0.089 
2025-08-28 00:31:10.619049: val_loss -0.0873 
2025-08-28 00:31:10.623325: Pseudo dice [np.float32(0.424)] 
2025-08-28 00:31:10.631084: Epoch time: 25.26 s 
2025-08-28 00:31:11.370591:  
2025-08-28 00:31:11.379901: Epoch 783 
2025-08-28 00:31:11.385085: Current learning rate: 0.00253 
2025-08-28 00:31:36.878666: train_loss -0.105 
2025-08-28 00:31:36.890937: val_loss -0.1051 
2025-08-28 00:31:36.895036: Pseudo dice [np.float32(0.6752)] 
2025-08-28 00:31:36.901113: Epoch time: 25.51 s 
2025-08-28 00:31:37.825104:  
2025-08-28 00:31:37.832484: Epoch 784 
2025-08-28 00:31:37.840885: Current learning rate: 0.00252 
2025-08-28 00:32:03.046236: train_loss -0.0879 
2025-08-28 00:32:03.054479: val_loss -0.0832 
2025-08-28 00:32:03.059273: Pseudo dice [np.float32(0.5871)] 
2025-08-28 00:32:03.067945: Epoch time: 25.23 s 
2025-08-28 00:32:03.836569:  
2025-08-28 00:32:03.847334: Epoch 785 
2025-08-28 00:32:03.856294: Current learning rate: 0.00251 
2025-08-28 00:32:29.460226: train_loss -0.1057 
2025-08-28 00:32:29.471536: val_loss -0.0996 
2025-08-28 00:32:29.478384: Pseudo dice [np.float32(0.5893)] 
2025-08-28 00:32:29.483842: Epoch time: 25.62 s 
2025-08-28 00:32:30.230444:  
2025-08-28 00:32:30.241311: Epoch 786 
2025-08-28 00:32:30.249734: Current learning rate: 0.0025 
2025-08-28 00:32:54.960445: train_loss -0.0878 
2025-08-28 00:32:54.969301: val_loss -0.1118 
2025-08-28 00:32:54.977198: Pseudo dice [np.float32(0.6256)] 
2025-08-28 00:32:54.982284: Epoch time: 24.73 s 
2025-08-28 00:32:55.739264:  
2025-08-28 00:32:55.748394: Epoch 787 
2025-08-28 00:32:55.755005: Current learning rate: 0.00249 
2025-08-28 00:33:20.911376: train_loss -0.0917 
2025-08-28 00:33:20.919719: val_loss -0.129 
2025-08-28 00:33:20.928102: Pseudo dice [np.float32(0.6225)] 
2025-08-28 00:33:20.933631: Epoch time: 25.17 s 
2025-08-28 00:33:21.682840:  
2025-08-28 00:33:21.690164: Epoch 788 
2025-08-28 00:33:21.697530: Current learning rate: 0.00248 
2025-08-28 00:33:47.116754: train_loss -0.0993 
2025-08-28 00:33:47.125091: val_loss -0.1071 
2025-08-28 00:33:47.134036: Pseudo dice [np.float32(0.5717)] 
2025-08-28 00:33:47.138922: Epoch time: 25.44 s 
2025-08-28 00:33:47.964385:  
2025-08-28 00:33:47.972742: Epoch 789 
2025-08-28 00:33:47.983972: Current learning rate: 0.00247 
2025-08-28 00:34:13.526394: train_loss -0.0935 
2025-08-28 00:34:13.534762: val_loss -0.1198 
2025-08-28 00:34:13.539132: Pseudo dice [np.float32(0.6087)] 
2025-08-28 00:34:13.546961: Epoch time: 25.56 s 
2025-08-28 00:34:14.470013:  
2025-08-28 00:34:14.478659: Epoch 790 
2025-08-28 00:34:14.485597: Current learning rate: 0.00245 
2025-08-28 00:34:40.261635: train_loss -0.0871 
2025-08-28 00:34:40.269810: val_loss -0.0994 
2025-08-28 00:34:40.278140: Pseudo dice [np.float32(0.6094)] 
2025-08-28 00:34:40.283109: Epoch time: 25.79 s 
2025-08-28 00:34:41.033034:  
2025-08-28 00:34:41.041429: Epoch 791 
2025-08-28 00:34:41.048716: Current learning rate: 0.00244 
2025-08-28 00:35:06.450125: train_loss -0.0809 
2025-08-28 00:35:06.458411: val_loss -0.05 
2025-08-28 00:35:06.462622: Pseudo dice [np.float32(0.4421)] 
2025-08-28 00:35:06.470776: Epoch time: 25.42 s 
2025-08-28 00:35:07.187206:  
2025-08-28 00:35:07.195515: Epoch 792 
2025-08-28 00:35:07.201921: Current learning rate: 0.00243 
2025-08-28 00:35:32.271999: train_loss -0.0755 
2025-08-28 00:35:32.280258: val_loss -0.0778 
2025-08-28 00:35:32.288388: Pseudo dice [np.float32(0.35)] 
2025-08-28 00:35:32.294322: Epoch time: 25.09 s 
2025-08-28 00:35:33.030673:  
2025-08-28 00:35:33.038967: Epoch 793 
2025-08-28 00:35:33.049502: Current learning rate: 0.00242 
2025-08-28 00:35:58.422519: train_loss -0.0752 
2025-08-28 00:35:58.431136: val_loss -0.0642 
2025-08-28 00:35:58.435662: Pseudo dice [np.float32(0.3038)] 
2025-08-28 00:35:58.442397: Epoch time: 25.39 s 
2025-08-28 00:35:59.220482:  
2025-08-28 00:35:59.229998: Epoch 794 
2025-08-28 00:35:59.237653: Current learning rate: 0.00241 
2025-08-28 00:36:24.728461: train_loss -0.1012 
2025-08-28 00:36:24.736664: val_loss -0.062 
2025-08-28 00:36:24.740819: Pseudo dice [np.float32(0.5141)] 
2025-08-28 00:36:24.749926: Epoch time: 25.51 s 
2025-08-28 00:36:25.513498:  
2025-08-28 00:36:25.521044: Epoch 795 
2025-08-28 00:36:25.529061: Current learning rate: 0.0024 
2025-08-28 00:36:51.066862: train_loss -0.0961 
2025-08-28 00:36:51.075723: val_loss -0.0966 
2025-08-28 00:36:51.079629: Pseudo dice [np.float32(0.5697)] 
2025-08-28 00:36:51.085711: Epoch time: 25.55 s 
2025-08-28 00:36:52.005282:  
2025-08-28 00:36:52.014454: Epoch 796 
2025-08-28 00:36:52.024575: Current learning rate: 0.00239 
2025-08-28 00:37:18.114898: train_loss -0.0864 
2025-08-28 00:37:18.127424: val_loss -0.1201 
2025-08-28 00:37:18.131558: Pseudo dice [np.float32(0.6685)] 
2025-08-28 00:37:18.137633: Epoch time: 26.11 s 
2025-08-28 00:37:18.892101:  
2025-08-28 00:37:18.899423: Epoch 797 
2025-08-28 00:37:18.907184: Current learning rate: 0.00238 
2025-08-28 00:37:44.182597: train_loss -0.0757 
2025-08-28 00:37:44.191228: val_loss -0.1412 
2025-08-28 00:37:44.199342: Pseudo dice [np.float32(0.722)] 
2025-08-28 00:37:44.204771: Epoch time: 25.29 s 
2025-08-28 00:37:44.964403:  
2025-08-28 00:37:44.975440: Epoch 798 
2025-08-28 00:37:44.979668: Current learning rate: 0.00237 
2025-08-28 00:38:10.379510: train_loss -0.0883 
2025-08-28 00:38:10.387906: val_loss -0.1666 
2025-08-28 00:38:10.396218: Pseudo dice [np.float32(0.6157)] 
2025-08-28 00:38:10.402360: Epoch time: 25.42 s 
2025-08-28 00:38:11.155143:  
2025-08-28 00:38:11.163482: Epoch 799 
2025-08-28 00:38:11.170945: Current learning rate: 0.00236 
2025-08-28 00:38:36.885164: train_loss -0.101 
2025-08-28 00:38:36.897708: val_loss -0.1204 
2025-08-28 00:38:36.901884: Pseudo dice [np.float32(0.6057)] 
2025-08-28 00:38:36.908037: Epoch time: 25.73 s 
2025-08-28 00:38:37.885070:  
2025-08-28 00:38:37.895232: Epoch 800 
2025-08-28 00:38:37.902373: Current learning rate: 0.00235 
2025-08-28 00:39:03.432784: train_loss -0.0815 
2025-08-28 00:39:03.440871: val_loss -0.1392 
2025-08-28 00:39:03.445019: Pseudo dice [np.float32(0.7578)] 
2025-08-28 00:39:03.452373: Epoch time: 25.55 s 
2025-08-28 00:39:03.459098: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-08-28 00:39:04.422113:  
2025-08-28 00:39:04.430764: Epoch 801 
2025-08-28 00:39:04.438709: Current learning rate: 0.00234 
2025-08-28 00:39:29.842188: train_loss -0.1036 
2025-08-28 00:39:29.850569: val_loss -0.09 
2025-08-28 00:39:29.858906: Pseudo dice [np.float32(0.6144)] 
2025-08-28 00:39:29.863960: Epoch time: 25.42 s 
2025-08-28 00:39:29.868752: Yayy! New best EMA pseudo Dice: 0.5848000049591064 
2025-08-28 00:39:30.973181:  
2025-08-28 00:39:30.984870: Epoch 802 
2025-08-28 00:39:30.989561: Current learning rate: 0.00233 
2025-08-28 00:39:56.464333: train_loss -0.0736 
2025-08-28 00:39:56.472991: val_loss -0.1264 
2025-08-28 00:39:56.477352: Pseudo dice [np.float32(0.6767)] 
2025-08-28 00:39:56.484236: Epoch time: 25.49 s 
2025-08-28 00:39:56.491233: Yayy! New best EMA pseudo Dice: 0.593999981880188 
2025-08-28 00:39:57.436831:  
2025-08-28 00:39:57.446380: Epoch 803 
2025-08-28 00:39:57.452673: Current learning rate: 0.00232 
2025-08-28 00:40:22.632726: train_loss -0.0775 
2025-08-28 00:40:22.640778: val_loss -0.1594 
2025-08-28 00:40:22.649112: Pseudo dice [np.float32(0.5373)] 
2025-08-28 00:40:22.655408: Epoch time: 25.2 s 
2025-08-28 00:40:23.421858:  
2025-08-28 00:40:23.431762: Epoch 804 
2025-08-28 00:40:23.438376: Current learning rate: 0.00231 
2025-08-28 00:40:48.424803: train_loss -0.0828 
2025-08-28 00:40:48.433193: val_loss -0.1585 
2025-08-28 00:40:48.441791: Pseudo dice [np.float32(0.6489)] 
2025-08-28 00:40:48.446935: Epoch time: 25.01 s 
2025-08-28 00:40:48.450706: Yayy! New best EMA pseudo Dice: 0.5943999886512756 
2025-08-28 00:40:49.430127:  
2025-08-28 00:40:49.438634: Epoch 805 
2025-08-28 00:40:49.447725: Current learning rate: 0.0023 
2025-08-28 00:41:15.977328: train_loss -0.0865 
2025-08-28 00:41:15.985667: val_loss -0.1232 
2025-08-28 00:41:15.994043: Pseudo dice [np.float32(0.6409)] 
2025-08-28 00:41:15.999458: Epoch time: 26.55 s 
2025-08-28 00:41:16.003187: Yayy! New best EMA pseudo Dice: 0.5990999937057495 
2025-08-28 00:41:16.961637:  
2025-08-28 00:41:16.971680: Epoch 806 
2025-08-28 00:41:16.978346: Current learning rate: 0.00229 
2025-08-28 00:41:42.491332: train_loss -0.0934 
2025-08-28 00:41:42.499661: val_loss -0.1191 
2025-08-28 00:41:42.503810: Pseudo dice [np.float32(0.6298)] 
2025-08-28 00:41:42.512998: Epoch time: 25.53 s 
2025-08-28 00:41:42.517202: Yayy! New best EMA pseudo Dice: 0.6021000146865845 
2025-08-28 00:41:43.590896:  
2025-08-28 00:41:43.597787: Epoch 807 
2025-08-28 00:41:43.606964: Current learning rate: 0.00228 
2025-08-28 00:42:07.970586: train_loss -0.0832 
2025-08-28 00:42:07.979032: val_loss -0.1088 
2025-08-28 00:42:07.983739: Pseudo dice [np.float32(0.7565)] 
2025-08-28 00:42:07.989491: Epoch time: 24.38 s 
2025-08-28 00:42:07.992726: Yayy! New best EMA pseudo Dice: 0.6176000237464905 
2025-08-28 00:42:08.918732:  
2025-08-28 00:42:08.928999: Epoch 808 
2025-08-28 00:42:08.936405: Current learning rate: 0.00226 
2025-08-28 00:42:34.643347: train_loss -0.073 
2025-08-28 00:42:34.651806: val_loss -0.1282 
2025-08-28 00:42:34.655869: Pseudo dice [np.float32(0.769)] 
2025-08-28 00:42:34.663183: Epoch time: 25.73 s 
2025-08-28 00:42:34.669918: Yayy! New best EMA pseudo Dice: 0.6327000260353088 
2025-08-28 00:42:35.657613:  
2025-08-28 00:42:35.665758: Epoch 809 
2025-08-28 00:42:35.675582: Current learning rate: 0.00225 
2025-08-28 00:43:00.982483: train_loss -0.0908 
2025-08-28 00:43:00.990498: val_loss -0.0478 
2025-08-28 00:43:00.998832: Pseudo dice [np.float32(0.568)] 
2025-08-28 00:43:01.004246: Epoch time: 25.33 s 
2025-08-28 00:43:01.787425:  
2025-08-28 00:43:01.796959: Epoch 810 
2025-08-28 00:43:01.803727: Current learning rate: 0.00224 
2025-08-28 00:43:26.920518: train_loss -0.0806 
2025-08-28 00:43:26.928926: val_loss -0.0801 
2025-08-28 00:43:26.933238: Pseudo dice [np.float32(0.6798)] 
2025-08-28 00:43:26.942135: Epoch time: 25.13 s 
2025-08-28 00:43:27.725881:  
2025-08-28 00:43:27.734926: Epoch 811 
2025-08-28 00:43:27.742082: Current learning rate: 0.00223 
2025-08-28 00:43:53.497453: train_loss -0.0599 
2025-08-28 00:43:53.505491: val_loss -0.1015 
2025-08-28 00:43:53.514019: Pseudo dice [np.float32(0.5708)] 
2025-08-28 00:43:53.520724: Epoch time: 25.77 s 
2025-08-28 00:43:54.351973:  
2025-08-28 00:43:54.362445: Epoch 812 
2025-08-28 00:43:54.368633: Current learning rate: 0.00222 
2025-08-28 00:44:19.327072: train_loss -0.0709 
2025-08-28 00:44:19.335171: val_loss -0.1151 
2025-08-28 00:44:19.339847: Pseudo dice [np.float32(0.6279)] 
2025-08-28 00:44:19.345820: Epoch time: 24.98 s 
2025-08-28 00:44:20.092771:  
2025-08-28 00:44:20.100531: Epoch 813 
2025-08-28 00:44:20.107359: Current learning rate: 0.00221 
2025-08-28 00:44:45.232048: train_loss -0.0929 
2025-08-28 00:44:45.240441: val_loss -0.0934 
2025-08-28 00:44:45.244614: Pseudo dice [np.float32(0.6154)] 
2025-08-28 00:44:45.250901: Epoch time: 25.14 s 
2025-08-28 00:44:46.018159:  
2025-08-28 00:44:46.024725: Epoch 814 
2025-08-28 00:44:46.033185: Current learning rate: 0.0022 
2025-08-28 00:45:12.017115: train_loss -0.0552 
2025-08-28 00:45:12.025512: val_loss -0.1335 
2025-08-28 00:45:12.033861: Pseudo dice [np.float32(0.6448)] 
2025-08-28 00:45:12.039317: Epoch time: 26.0 s 
2025-08-28 00:45:12.795905:  
2025-08-28 00:45:12.802738: Epoch 815 
2025-08-28 00:45:12.811594: Current learning rate: 0.00219 
2025-08-28 00:45:38.377115: train_loss -0.1134 
2025-08-28 00:45:38.389623: val_loss -0.0912 
2025-08-28 00:45:38.393503: Pseudo dice [np.float32(0.5668)] 
2025-08-28 00:45:38.400767: Epoch time: 25.58 s 
2025-08-28 00:45:39.161604:  
2025-08-28 00:45:39.169729: Epoch 816 
2025-08-28 00:45:39.177432: Current learning rate: 0.00218 
2025-08-28 00:46:03.982036: train_loss -0.0988 
2025-08-28 00:46:03.989888: val_loss -0.0958 
2025-08-28 00:46:03.994053: Pseudo dice [np.float32(0.4321)] 
2025-08-28 00:46:04.000178: Epoch time: 24.82 s 
2025-08-28 00:46:04.788500:  
2025-08-28 00:46:04.795240: Epoch 817 
2025-08-28 00:46:04.804214: Current learning rate: 0.00217 
2025-08-28 00:46:30.286401: train_loss -0.0871 
2025-08-28 00:46:30.291152: val_loss -0.095 
2025-08-28 00:46:30.299488: Pseudo dice [np.float32(0.5274)] 
2025-08-28 00:46:30.304891: Epoch time: 25.5 s 
2025-08-28 00:46:31.210447:  
2025-08-28 00:46:31.220108: Epoch 818 
2025-08-28 00:46:31.227379: Current learning rate: 0.00216 
2025-08-28 00:46:56.550886: train_loss -0.0843 
2025-08-28 00:46:56.559399: val_loss -0.0693 
2025-08-28 00:46:56.567369: Pseudo dice [np.float32(0.3714)] 
2025-08-28 00:46:56.572427: Epoch time: 25.34 s 
2025-08-28 00:46:57.335007:  
2025-08-28 00:46:57.342987: Epoch 819 
2025-08-28 00:46:57.352923: Current learning rate: 0.00215 
2025-08-28 00:47:22.059475: train_loss -0.0753 
2025-08-28 00:47:22.067838: val_loss -0.1356 
2025-08-28 00:47:22.071924: Pseudo dice [np.float32(0.7373)] 
2025-08-28 00:47:22.079578: Epoch time: 24.73 s 
2025-08-28 00:47:22.796274:  
2025-08-28 00:47:22.803769: Epoch 820 
2025-08-28 00:47:22.810526: Current learning rate: 0.00214 
2025-08-28 00:47:47.760108: train_loss -0.0728 
2025-08-28 00:47:47.768776: val_loss -0.0412 
2025-08-28 00:47:47.777171: Pseudo dice [np.float32(0.2899)] 
2025-08-28 00:47:47.783943: Epoch time: 24.97 s 
2025-08-28 00:47:48.524943:  
2025-08-28 00:47:48.534735: Epoch 821 
2025-08-28 00:47:48.540262: Current learning rate: 0.00213 
2025-08-28 00:48:13.531613: train_loss -0.0877 
2025-08-28 00:48:13.540020: val_loss -0.0577 
2025-08-28 00:48:13.544108: Pseudo dice [np.float32(0.6213)] 
2025-08-28 00:48:13.552788: Epoch time: 25.01 s 
2025-08-28 00:48:14.293415:  
2025-08-28 00:48:14.301153: Epoch 822 
2025-08-28 00:48:14.307774: Current learning rate: 0.00212 
2025-08-28 00:48:39.879139: train_loss -0.0976 
2025-08-28 00:48:39.891336: val_loss -0.1081 
2025-08-28 00:48:39.895491: Pseudo dice [np.float32(0.587)] 
2025-08-28 00:48:39.903636: Epoch time: 25.59 s 
2025-08-28 00:48:40.667082:  
2025-08-28 00:48:40.675294: Epoch 823 
2025-08-28 00:48:40.681665: Current learning rate: 0.0021 
2025-08-28 00:49:05.955597: train_loss -0.0802 
2025-08-28 00:49:05.963520: val_loss -0.1161 
2025-08-28 00:49:05.967698: Pseudo dice [np.float32(0.6142)] 
2025-08-28 00:49:05.976465: Epoch time: 25.29 s 
2025-08-28 00:49:06.726148:  
2025-08-28 00:49:06.736443: Epoch 824 
2025-08-28 00:49:06.743699: Current learning rate: 0.00209 
2025-08-28 00:49:31.497553: train_loss -0.0864 
2025-08-28 00:49:31.505369: val_loss -0.1156 
2025-08-28 00:49:31.513751: Pseudo dice [np.float32(0.5904)] 
2025-08-28 00:49:31.519189: Epoch time: 24.77 s 
2025-08-28 00:49:32.224341:  
2025-08-28 00:49:32.234129: Epoch 825 
2025-08-28 00:49:32.241226: Current learning rate: 0.00208 
2025-08-28 00:49:57.673148: train_loss -0.0847 
2025-08-28 00:49:57.681525: val_loss -0.0311 
2025-08-28 00:49:57.689873: Pseudo dice [np.float32(0.207)] 
2025-08-28 00:49:57.695180: Epoch time: 25.45 s 
2025-08-28 00:49:58.446776:  
2025-08-28 00:49:58.456198: Epoch 826 
2025-08-28 00:49:58.461998: Current learning rate: 0.00207 
2025-08-28 00:50:23.695016: train_loss -0.1046 
2025-08-28 00:50:23.703296: val_loss -0.0678 
2025-08-28 00:50:23.709804: Pseudo dice [np.float32(0.4839)] 
2025-08-28 00:50:23.715466: Epoch time: 25.25 s 
2025-08-28 00:50:24.445663:  
2025-08-28 00:50:24.453924: Epoch 827 
2025-08-28 00:50:24.458483: Current learning rate: 0.00206 
2025-08-28 00:50:49.333309: train_loss -0.095 
2025-08-28 00:50:49.341388: val_loss -0.1566 
2025-08-28 00:50:49.345559: Pseudo dice [np.float32(0.5685)] 
2025-08-28 00:50:49.354616: Epoch time: 24.89 s 
2025-08-28 00:50:50.059800:  
2025-08-28 00:50:50.068138: Epoch 828 
2025-08-28 00:50:50.073324: Current learning rate: 0.00205 
2025-08-28 00:51:14.658566: train_loss -0.1002 
2025-08-28 00:51:14.666687: val_loss -0.1355 
2025-08-28 00:51:14.670863: Pseudo dice [np.float32(0.6279)] 
2025-08-28 00:51:14.677068: Epoch time: 24.6 s 
2025-08-28 00:51:15.421900:  
2025-08-28 00:51:15.431035: Epoch 829 
2025-08-28 00:51:15.437177: Current learning rate: 0.00204 
2025-08-28 00:51:40.976272: train_loss -0.0975 
2025-08-28 00:51:40.988837: val_loss -0.1139 
2025-08-28 00:51:40.992967: Pseudo dice [np.float32(0.6236)] 
2025-08-28 00:51:41.000980: Epoch time: 25.56 s 
2025-08-28 00:51:41.744767:  
2025-08-28 00:51:41.752388: Epoch 830 
2025-08-28 00:51:41.759477: Current learning rate: 0.00203 
2025-08-28 00:52:06.794076: train_loss -0.096 
2025-08-28 00:52:06.802145: val_loss -0.0885 
2025-08-28 00:52:06.806307: Pseudo dice [np.float32(0.4719)] 
2025-08-28 00:52:06.813402: Epoch time: 25.05 s 
2025-08-28 00:52:07.542282:  
2025-08-28 00:52:07.552821: Epoch 831 
2025-08-28 00:52:07.558988: Current learning rate: 0.00202 
2025-08-28 00:52:32.102378: train_loss -0.0934 
2025-08-28 00:52:32.111028: val_loss -0.0929 
2025-08-28 00:52:32.119021: Pseudo dice [np.float32(0.5576)] 
2025-08-28 00:52:32.125468: Epoch time: 24.56 s 
2025-08-28 00:52:32.875013:  
2025-08-28 00:52:32.883474: Epoch 832 
2025-08-28 00:52:32.890545: Current learning rate: 0.00201 
2025-08-28 00:52:58.099167: train_loss -0.0931 
2025-08-28 00:52:58.107449: val_loss -0.1341 
2025-08-28 00:52:58.115828: Pseudo dice [np.float32(0.602)] 
2025-08-28 00:52:58.122896: Epoch time: 25.23 s 
2025-08-28 00:52:58.878898:  
2025-08-28 00:52:58.885248: Epoch 833 
2025-08-28 00:52:58.887843: Current learning rate: 0.002 
2025-08-28 00:53:23.495316: train_loss -0.0997 
2025-08-28 00:53:23.503698: val_loss -0.0333 
2025-08-28 00:53:23.508151: Pseudo dice [np.float32(0.3762)] 
2025-08-28 00:53:23.516156: Epoch time: 24.62 s 
2025-08-28 00:53:24.263926:  
2025-08-28 00:53:24.271076: Epoch 834 
2025-08-28 00:53:24.279387: Current learning rate: 0.00199 
2025-08-28 00:53:49.295801: train_loss -0.0813 
2025-08-28 00:53:49.304481: val_loss -0.1201 
2025-08-28 00:53:49.308637: Pseudo dice [np.float32(0.6688)] 
2025-08-28 00:53:49.314633: Epoch time: 25.04 s 
2025-08-28 00:53:50.053962:  
2025-08-28 00:53:50.061380: Epoch 835 
2025-08-28 00:53:50.064334: Current learning rate: 0.00198 
2025-08-28 00:54:15.868423: train_loss -0.0845 
2025-08-28 00:54:15.876766: val_loss -0.0875 
2025-08-28 00:54:15.885136: Pseudo dice [np.float32(0.6575)] 
2025-08-28 00:54:15.890164: Epoch time: 25.82 s 
2025-08-28 00:54:16.648382:  
2025-08-28 00:54:16.657753: Epoch 836 
2025-08-28 00:54:16.663881: Current learning rate: 0.00196 
2025-08-28 00:54:41.940153: train_loss -0.0747 
2025-08-28 00:54:41.948696: val_loss -0.0624 
2025-08-28 00:54:41.953118: Pseudo dice [np.float32(0.5563)] 
2025-08-28 00:54:41.960082: Epoch time: 25.29 s 
2025-08-28 00:54:42.714056:  
2025-08-28 00:54:42.722209: Epoch 837 
2025-08-28 00:54:42.728870: Current learning rate: 0.00195 
2025-08-28 00:55:10.068553: train_loss -0.0713 
2025-08-28 00:55:10.076709: val_loss -0.0992 
2025-08-28 00:55:10.081108: Pseudo dice [np.float32(0.7068)] 
2025-08-28 00:55:10.089070: Epoch time: 27.36 s 
2025-08-28 00:55:10.992239:  
2025-08-28 00:55:11.000468: Epoch 838 
2025-08-28 00:55:11.006635: Current learning rate: 0.00194 
2025-08-28 00:55:36.882625: train_loss -0.1093 
2025-08-28 00:55:36.891075: val_loss -0.044 
2025-08-28 00:55:36.899648: Pseudo dice [np.float32(0.3027)] 
2025-08-28 00:55:36.904320: Epoch time: 25.89 s 
2025-08-28 00:55:37.680993:  
2025-08-28 00:55:37.688257: Epoch 839 
2025-08-28 00:55:37.695798: Current learning rate: 0.00193 
2025-08-28 00:56:03.192595: train_loss -0.0772 
2025-08-28 00:56:03.204836: val_loss -0.0411 
2025-08-28 00:56:03.209221: Pseudo dice [np.float32(0.3284)] 
2025-08-28 00:56:03.216231: Epoch time: 25.52 s 
2025-08-28 00:56:03.990338:  
2025-08-28 00:56:03.998284: Epoch 840 
2025-08-28 00:56:04.005440: Current learning rate: 0.00192 
2025-08-28 00:56:30.419469: train_loss -0.1091 
2025-08-28 00:56:30.427773: val_loss -0.1225 
2025-08-28 00:56:30.432113: Pseudo dice [np.float32(0.6274)] 
2025-08-28 00:56:30.438918: Epoch time: 26.43 s 
2025-08-28 00:56:31.245578:  
2025-08-28 00:56:31.257560: Epoch 841 
2025-08-28 00:56:31.264715: Current learning rate: 0.00191 
2025-08-28 00:56:56.807997: train_loss -0.0743 
2025-08-28 00:56:56.816609: val_loss -0.0622 
2025-08-28 00:56:56.820759: Pseudo dice [np.float32(0.5777)] 
2025-08-28 00:56:56.827952: Epoch time: 25.56 s 
2025-08-28 00:56:57.581895:  
2025-08-28 00:56:57.590225: Epoch 842 
2025-08-28 00:56:57.597438: Current learning rate: 0.0019 
2025-08-28 00:57:22.647587: train_loss -0.0991 
2025-08-28 00:57:22.655195: val_loss -0.0888 
2025-08-28 00:57:22.659384: Pseudo dice [np.float32(0.5338)] 
2025-08-28 00:57:22.668073: Epoch time: 25.07 s 
2025-08-28 00:57:23.416976:  
2025-08-28 00:57:23.425447: Epoch 843 
2025-08-28 00:57:23.436846: Current learning rate: 0.00189 
2025-08-28 00:57:48.514121: train_loss -0.0709 
2025-08-28 00:57:48.526550: val_loss -0.1079 
2025-08-28 00:57:48.530708: Pseudo dice [np.float32(0.4746)] 
2025-08-28 00:57:48.539879: Epoch time: 25.1 s 
2025-08-28 00:57:49.291826:  
2025-08-28 00:57:49.302771: Epoch 844 
2025-08-28 00:57:49.313592: Current learning rate: 0.00188 
2025-08-28 00:58:14.973804: train_loss -0.089 
2025-08-28 00:58:14.982517: val_loss -0.0946 
2025-08-28 00:58:14.986634: Pseudo dice [np.float32(0.739)] 
2025-08-28 00:58:14.993305: Epoch time: 25.68 s 
2025-08-28 00:58:15.736921:  
2025-08-28 00:58:15.745244: Epoch 845 
2025-08-28 00:58:15.750599: Current learning rate: 0.00187 
2025-08-28 00:58:41.308896: train_loss -0.0807 
2025-08-28 00:58:41.320920: val_loss -0.0608 
2025-08-28 00:58:41.325093: Pseudo dice [np.float32(0.5034)] 
2025-08-28 00:58:41.333207: Epoch time: 25.57 s 
2025-08-28 00:58:42.091175:  
2025-08-28 00:58:42.102916: Epoch 846 
2025-08-28 00:58:42.113098: Current learning rate: 0.00186 
2025-08-28 00:59:07.422299: train_loss -0.1028 
2025-08-28 00:59:07.430338: val_loss -0.1375 
2025-08-28 00:59:07.434496: Pseudo dice [np.float32(0.5635)] 
2025-08-28 00:59:07.441711: Epoch time: 25.33 s 
2025-08-28 00:59:08.176775:  
2025-08-28 00:59:08.185080: Epoch 847 
2025-08-28 00:59:08.192418: Current learning rate: 0.00185 
2025-08-28 00:59:33.894293: train_loss -0.0747 
2025-08-28 00:59:33.902582: val_loss -0.0957 
2025-08-28 00:59:33.910938: Pseudo dice [np.float32(0.5218)] 
2025-08-28 00:59:33.918122: Epoch time: 25.72 s 
2025-08-28 00:59:34.650190:  
2025-08-28 00:59:34.658514: Epoch 848 
2025-08-28 00:59:34.664680: Current learning rate: 0.00184 
2025-08-28 01:00:00.366479: train_loss -0.0892 
2025-08-28 01:00:00.374846: val_loss -0.0795 
2025-08-28 01:00:00.383180: Pseudo dice [np.float32(0.6122)] 
2025-08-28 01:00:00.388078: Epoch time: 25.72 s 
2025-08-28 01:00:01.120293:  
2025-08-28 01:00:01.130749: Epoch 849 
2025-08-28 01:00:01.138490: Current learning rate: 0.00182 
2025-08-28 01:00:26.797060: train_loss -0.061 
2025-08-28 01:00:26.805604: val_loss -0.0715 
2025-08-28 01:00:26.809568: Pseudo dice [np.float32(0.5523)] 
2025-08-28 01:00:26.816746: Epoch time: 25.68 s 
2025-08-28 01:00:27.762531:  
2025-08-28 01:00:27.774298: Epoch 850 
2025-08-28 01:00:27.782020: Current learning rate: 0.00181 
2025-08-28 01:00:53.696315: train_loss -0.1046 
2025-08-28 01:00:53.703088: val_loss -0.0827 
2025-08-28 01:00:53.711428: Pseudo dice [np.float32(0.7235)] 
2025-08-28 01:00:53.716713: Epoch time: 25.94 s 
2025-08-28 01:00:54.444360:  
2025-08-28 01:00:54.452360: Epoch 851 
2025-08-28 01:00:54.461789: Current learning rate: 0.0018 
2025-08-28 01:01:20.012706: train_loss -0.0665 
2025-08-28 01:01:20.021039: val_loss -0.1036 
2025-08-28 01:01:20.029387: Pseudo dice [np.float32(0.5485)] 
2025-08-28 01:01:20.034355: Epoch time: 25.57 s 
2025-08-28 01:01:20.792583:  
2025-08-28 01:01:20.800159: Epoch 852 
2025-08-28 01:01:20.809741: Current learning rate: 0.00179 
2025-08-28 01:01:45.734491: train_loss -0.0625 
2025-08-28 01:01:45.742546: val_loss -0.0563 
2025-08-28 01:01:45.746976: Pseudo dice [np.float32(0.325)] 
2025-08-28 01:01:45.755716: Epoch time: 24.94 s 
2025-08-28 01:01:46.506438:  
2025-08-28 01:01:46.516154: Epoch 853 
2025-08-28 01:01:46.524513: Current learning rate: 0.00178 
2025-08-28 01:02:12.552618: train_loss -0.1208 
2025-08-28 01:02:12.561014: val_loss -0.0865 
2025-08-28 01:02:12.569371: Pseudo dice [np.float32(0.5775)] 
2025-08-28 01:02:12.574296: Epoch time: 26.05 s 
2025-08-28 01:02:13.318416:  
2025-08-28 01:02:13.327296: Epoch 854 
2025-08-28 01:02:13.336686: Current learning rate: 0.00177 
2025-08-28 01:02:39.621595: train_loss -0.0732 
2025-08-28 01:02:39.633878: val_loss -0.0827 
2025-08-28 01:02:39.638288: Pseudo dice [np.float32(0.3991)] 
2025-08-28 01:02:39.647077: Epoch time: 26.31 s 
2025-08-28 01:02:40.405778:  
2025-08-28 01:02:40.414526: Epoch 855 
2025-08-28 01:02:40.419318: Current learning rate: 0.00176 
2025-08-28 01:03:05.601726: train_loss -0.0713 
2025-08-28 01:03:05.610102: val_loss -0.0798 
2025-08-28 01:03:05.613948: Pseudo dice [np.float32(0.4847)] 
2025-08-28 01:03:05.621954: Epoch time: 25.2 s 
2025-08-28 01:03:06.367760:  
2025-08-28 01:03:06.377513: Epoch 856 
2025-08-28 01:03:06.387022: Current learning rate: 0.00175 
2025-08-28 01:03:32.738830: train_loss -0.0809 
2025-08-28 01:03:32.744954: val_loss -0.1638 
2025-08-28 01:03:32.753297: Pseudo dice [np.float32(0.6419)] 
2025-08-28 01:03:32.760097: Epoch time: 26.37 s 
2025-08-28 01:03:33.480261:  
2025-08-28 01:03:33.490712: Epoch 857 
2025-08-28 01:03:33.498031: Current learning rate: 0.00174 
2025-08-28 01:03:59.063153: train_loss -0.1229 
2025-08-28 01:03:59.071491: val_loss -0.1147 
2025-08-28 01:03:59.075663: Pseudo dice [np.float32(0.7055)] 
2025-08-28 01:03:59.082130: Epoch time: 25.59 s 
2025-08-28 01:03:59.760663:  
2025-08-28 01:03:59.769028: Epoch 858 
2025-08-28 01:03:59.777920: Current learning rate: 0.00173 
2025-08-28 01:04:23.929661: train_loss -0.0898 
2025-08-28 01:04:23.937960: val_loss -0.0887 
2025-08-28 01:04:23.942154: Pseudo dice [np.float32(0.5652)] 
2025-08-28 01:04:23.951349: Epoch time: 24.17 s 
2025-08-28 01:04:24.638494:  
2025-08-28 01:04:24.646829: Epoch 859 
2025-08-28 01:04:24.652170: Current learning rate: 0.00172 
2025-08-28 01:04:50.247554: train_loss -0.0886 
2025-08-28 01:04:50.255905: val_loss -0.081 
2025-08-28 01:04:50.260072: Pseudo dice [np.float32(0.617)] 
2025-08-28 01:04:50.268036: Epoch time: 25.61 s 
2025-08-28 01:04:50.956497:  
2025-08-28 01:04:50.964782: Epoch 860 
2025-08-28 01:04:50.971116: Current learning rate: 0.0017 
2025-08-28 01:05:15.485256: train_loss -0.0905 
2025-08-28 01:05:15.493648: val_loss -0.1195 
2025-08-28 01:05:15.497765: Pseudo dice [np.float32(0.5958)] 
2025-08-28 01:05:15.504829: Epoch time: 24.53 s 
2025-08-28 01:05:16.331757:  
2025-08-28 01:05:16.339236: Epoch 861 
2025-08-28 01:05:16.344316: Current learning rate: 0.00169 
2025-08-28 01:05:40.551932: train_loss -0.1036 
2025-08-28 01:05:40.560542: val_loss -0.0987 
2025-08-28 01:05:40.568635: Pseudo dice [np.float32(0.5452)] 
2025-08-28 01:05:40.573612: Epoch time: 24.22 s 
2025-08-28 01:05:41.250501:  
2025-08-28 01:05:41.258842: Epoch 862 
2025-08-28 01:05:41.265010: Current learning rate: 0.00168 
2025-08-28 01:06:06.911605: train_loss -0.1137 
2025-08-28 01:06:06.919938: val_loss -0.113 
2025-08-28 01:06:06.924097: Pseudo dice [np.float32(0.5565)] 
2025-08-28 01:06:06.931985: Epoch time: 25.66 s 
2025-08-28 01:06:07.606955:  
2025-08-28 01:06:07.615389: Epoch 863 
2025-08-28 01:06:07.620474: Current learning rate: 0.00167 
2025-08-28 01:06:32.275497: train_loss -0.0989 
2025-08-28 01:06:32.282763: val_loss -0.112 
2025-08-28 01:06:32.291115: Pseudo dice [np.float32(0.5797)] 
2025-08-28 01:06:32.296558: Epoch time: 24.67 s 
2025-08-28 01:06:32.967606:  
2025-08-28 01:06:32.975111: Epoch 864 
2025-08-28 01:06:32.981326: Current learning rate: 0.00166 
2025-08-28 01:06:57.103697: train_loss -0.1106 
2025-08-28 01:06:57.111790: val_loss -0.1563 
2025-08-28 01:06:57.115885: Pseudo dice [np.float32(0.7263)] 
2025-08-28 01:06:57.123773: Epoch time: 24.14 s 
2025-08-28 01:06:57.803926:  
2025-08-28 01:06:57.812347: Epoch 865 
2025-08-28 01:06:57.818680: Current learning rate: 0.00165 
2025-08-28 01:07:23.479647: train_loss -0.1097 
2025-08-28 01:07:23.488054: val_loss -0.1002 
2025-08-28 01:07:23.492216: Pseudo dice [np.float32(0.5506)] 
2025-08-28 01:07:23.500298: Epoch time: 25.68 s 
2025-08-28 01:07:24.182413:  
2025-08-28 01:07:24.192900: Epoch 866 
2025-08-28 01:07:24.198102: Current learning rate: 0.00164 
2025-08-28 01:07:49.448866: train_loss -0.0955 
2025-08-28 01:07:49.455639: val_loss -0.2041 
2025-08-28 01:07:49.464525: Pseudo dice [np.float32(0.7381)] 
2025-08-28 01:07:49.469714: Epoch time: 25.27 s 
2025-08-28 01:07:50.275167:  
2025-08-28 01:07:50.284527: Epoch 867 
2025-08-28 01:07:50.290823: Current learning rate: 0.00163 
2025-08-28 01:08:14.597832: train_loss -0.107 
2025-08-28 01:08:14.605762: val_loss -0.0947 
2025-08-28 01:08:14.614113: Pseudo dice [np.float32(0.559)] 
2025-08-28 01:08:14.619116: Epoch time: 24.32 s 
2025-08-28 01:08:15.343946:  
2025-08-28 01:08:15.352721: Epoch 868 
2025-08-28 01:08:15.358717: Current learning rate: 0.00162 
2025-08-28 01:08:41.048808: train_loss -0.1106 
2025-08-28 01:08:41.061321: val_loss -0.1331 
2025-08-28 01:08:41.065698: Pseudo dice [np.float32(0.6728)] 
2025-08-28 01:08:41.073701: Epoch time: 25.71 s 
2025-08-28 01:08:41.805299:  
2025-08-28 01:08:41.812531: Epoch 869 
2025-08-28 01:08:41.820437: Current learning rate: 0.00161 
2025-08-28 01:09:07.571347: train_loss -0.1179 
2025-08-28 01:09:07.579489: val_loss -0.0958 
2025-08-28 01:09:07.583616: Pseudo dice [np.float32(0.5455)] 
2025-08-28 01:09:07.592750: Epoch time: 25.77 s 
2025-08-28 01:09:08.314410:  
2025-08-28 01:09:08.327275: Epoch 870 
2025-08-28 01:09:08.335951: Current learning rate: 0.00159 
2025-08-28 01:09:33.388586: train_loss -0.0933 
2025-08-28 01:09:33.396907: val_loss -0.1096 
2025-08-28 01:09:33.401073: Pseudo dice [np.float32(0.8006)] 
2025-08-28 01:09:33.409253: Epoch time: 25.08 s 
2025-08-28 01:09:34.169548:  
2025-08-28 01:09:34.180195: Epoch 871 
2025-08-28 01:09:34.185651: Current learning rate: 0.00158 
2025-08-28 01:09:59.589445: train_loss -0.0837 
2025-08-28 01:09:59.598172: val_loss -0.0972 
2025-08-28 01:09:59.602302: Pseudo dice [np.float32(0.6003)] 
2025-08-28 01:09:59.608516: Epoch time: 25.42 s 
2025-08-28 01:10:00.363401:  
2025-08-28 01:10:00.372217: Epoch 872 
2025-08-28 01:10:00.379578: Current learning rate: 0.00157 
2025-08-28 01:10:25.181606: train_loss -0.0918 
2025-08-28 01:10:25.186158: val_loss -0.1005 
2025-08-28 01:10:25.194485: Pseudo dice [np.float32(0.6285)] 
2025-08-28 01:10:25.199832: Epoch time: 24.82 s 
2025-08-28 01:10:25.927405:  
2025-08-28 01:10:25.937727: Epoch 873 
2025-08-28 01:10:25.941485: Current learning rate: 0.00156 
2025-08-28 01:10:51.596129: train_loss -0.0935 
2025-08-28 01:10:51.604461: val_loss -0.0824 
2025-08-28 01:10:51.608735: Pseudo dice [np.float32(0.5687)] 
2025-08-28 01:10:51.617394: Epoch time: 25.67 s 
2025-08-28 01:10:52.355077:  
2025-08-28 01:10:52.365088: Epoch 874 
2025-08-28 01:10:52.373863: Current learning rate: 0.00155 
2025-08-28 01:11:18.093976: train_loss -0.0938 
2025-08-28 01:11:18.103921: val_loss -0.0601 
2025-08-28 01:11:18.109924: Pseudo dice [np.float32(0.3383)] 
2025-08-28 01:11:18.115099: Epoch time: 25.74 s 
2025-08-28 01:11:18.861232:  
2025-08-28 01:11:18.871493: Epoch 875 
2025-08-28 01:11:18.879260: Current learning rate: 0.00154 
2025-08-28 01:11:43.994411: train_loss -0.0933 
2025-08-28 01:11:44.002302: val_loss -0.0939 
2025-08-28 01:11:44.011034: Pseudo dice [np.float32(0.5761)] 
2025-08-28 01:11:44.016191: Epoch time: 25.13 s 
2025-08-28 01:11:44.766062:  
2025-08-28 01:11:44.776594: Epoch 876 
2025-08-28 01:11:44.783271: Current learning rate: 0.00153 
2025-08-28 01:12:10.061628: train_loss -0.0794 
2025-08-28 01:12:10.070018: val_loss -0.0607 
2025-08-28 01:12:10.074192: Pseudo dice [np.float32(0.4706)] 
2025-08-28 01:12:10.082133: Epoch time: 25.3 s 
2025-08-28 01:12:10.814009:  
2025-08-28 01:12:10.823523: Epoch 877 
2025-08-28 01:12:10.829443: Current learning rate: 0.00152 
2025-08-28 01:12:36.709219: train_loss -0.1189 
2025-08-28 01:12:36.717751: val_loss -0.0394 
2025-08-28 01:12:36.721856: Pseudo dice [np.float32(0.3278)] 
2025-08-28 01:12:36.730708: Epoch time: 25.9 s 
2025-08-28 01:12:37.451358:  
2025-08-28 01:12:37.459660: Epoch 878 
2025-08-28 01:12:37.466023: Current learning rate: 0.00151 
2025-08-28 01:13:03.132000: train_loss -0.0565 
2025-08-28 01:13:03.139998: val_loss -0.1395 
2025-08-28 01:13:03.148014: Pseudo dice [np.float32(0.7651)] 
2025-08-28 01:13:03.152996: Epoch time: 25.68 s 
2025-08-28 01:13:03.895575:  
2025-08-28 01:13:03.904686: Epoch 879 
2025-08-28 01:13:03.911145: Current learning rate: 0.00149 
2025-08-28 01:13:29.791622: train_loss -0.0763 
2025-08-28 01:13:29.799707: val_loss -0.1577 
2025-08-28 01:13:29.803802: Pseudo dice [np.float32(0.6453)] 
2025-08-28 01:13:29.812333: Epoch time: 25.9 s 
2025-08-28 01:13:30.661817:  
2025-08-28 01:13:30.673457: Epoch 880 
2025-08-28 01:13:30.683113: Current learning rate: 0.00148 
2025-08-28 01:13:56.084503: train_loss -0.0961 
2025-08-28 01:13:56.092546: val_loss -0.0683 
2025-08-28 01:13:56.096684: Pseudo dice [np.float32(0.5287)] 
2025-08-28 01:13:56.105818: Epoch time: 25.42 s 
2025-08-28 01:13:56.852010:  
2025-08-28 01:13:56.860269: Epoch 881 
2025-08-28 01:13:56.865444: Current learning rate: 0.00147 
2025-08-28 01:14:22.727736: train_loss -0.0774 
2025-08-28 01:14:22.735815: val_loss -0.1495 
2025-08-28 01:14:22.739913: Pseudo dice [np.float32(0.6946)] 
2025-08-28 01:14:22.748121: Epoch time: 25.88 s 
2025-08-28 01:14:23.481221:  
2025-08-28 01:14:23.489524: Epoch 882 
2025-08-28 01:14:23.496870: Current learning rate: 0.00146 
2025-08-28 01:14:49.333175: train_loss -0.0929 
2025-08-28 01:14:49.341505: val_loss -0.0971 
2025-08-28 01:14:49.345903: Pseudo dice [np.float32(0.5402)] 
2025-08-28 01:14:49.353753: Epoch time: 25.86 s 
2025-08-28 01:14:50.096875:  
2025-08-28 01:14:50.106782: Epoch 883 
2025-08-28 01:14:50.113164: Current learning rate: 0.00145 
2025-08-28 01:15:16.001461: train_loss -0.0975 
2025-08-28 01:15:16.009809: val_loss -0.0859 
2025-08-28 01:15:16.013959: Pseudo dice [np.float32(0.1807)] 
2025-08-28 01:15:16.022974: Epoch time: 25.9 s 
2025-08-28 01:15:16.764422:  
2025-08-28 01:15:16.771936: Epoch 884 
2025-08-28 01:15:16.780395: Current learning rate: 0.00144 
2025-08-28 01:15:42.590915: train_loss -0.118 
2025-08-28 01:15:42.603062: val_loss -0.1397 
2025-08-28 01:15:42.607455: Pseudo dice [np.float32(0.6747)] 
2025-08-28 01:15:42.615415: Epoch time: 25.83 s 
2025-08-28 01:15:43.365195:  
2025-08-28 01:15:43.377203: Epoch 885 
2025-08-28 01:15:43.383397: Current learning rate: 0.00143 
2025-08-28 01:16:08.449383: train_loss -0.0824 
2025-08-28 01:16:08.453819: val_loss -0.1365 
2025-08-28 01:16:08.462182: Pseudo dice [np.float32(0.6905)] 
2025-08-28 01:16:08.468273: Epoch time: 25.08 s 
2025-08-28 01:16:09.192044:  
2025-08-28 01:16:09.200246: Epoch 886 
2025-08-28 01:16:09.208405: Current learning rate: 0.00142 
2025-08-28 01:16:34.333855: train_loss -0.1128 
2025-08-28 01:16:34.342537: val_loss -0.1024 
2025-08-28 01:16:34.346347: Pseudo dice [np.float32(0.6136)] 
2025-08-28 01:16:34.353417: Epoch time: 25.14 s 
2025-08-28 01:16:35.090959:  
2025-08-28 01:16:35.099140: Epoch 887 
2025-08-28 01:16:35.101487: Current learning rate: 0.00141 
2025-08-28 01:17:00.864781: train_loss -0.1055 
2025-08-28 01:17:00.873155: val_loss -0.1044 
2025-08-28 01:17:00.881198: Pseudo dice [np.float32(0.6168)] 
2025-08-28 01:17:00.886535: Epoch time: 25.78 s 
2025-08-28 01:17:01.616248:  
2025-08-28 01:17:01.627095: Epoch 888 
2025-08-28 01:17:01.639041: Current learning rate: 0.00139 
2025-08-28 01:17:27.086219: train_loss -0.1154 
2025-08-28 01:17:27.090721: val_loss -0.1022 
2025-08-28 01:17:27.099027: Pseudo dice [np.float32(0.5661)] 
2025-08-28 01:17:27.104560: Epoch time: 25.47 s 
2025-08-28 01:17:27.820434:  
2025-08-28 01:17:27.828738: Epoch 889 
2025-08-28 01:17:27.835070: Current learning rate: 0.00138 
2025-08-28 01:17:53.371815: train_loss -0.093 
2025-08-28 01:17:53.379746: val_loss -0.1101 
2025-08-28 01:17:53.388032: Pseudo dice [np.float32(0.6696)] 
2025-08-28 01:17:53.393944: Epoch time: 25.55 s 
2025-08-28 01:17:54.144083:  
2025-08-28 01:17:54.152396: Epoch 890 
2025-08-28 01:17:54.158256: Current learning rate: 0.00137 
2025-08-28 01:18:20.010495: train_loss -0.0715 
2025-08-28 01:18:20.018492: val_loss -0.0767 
2025-08-28 01:18:20.026921: Pseudo dice [np.float32(0.512)] 
2025-08-28 01:18:20.031938: Epoch time: 25.87 s 
2025-08-28 01:18:20.751674:  
2025-08-28 01:18:20.758341: Epoch 891 
2025-08-28 01:18:20.768058: Current learning rate: 0.00136 
2025-08-28 01:18:45.865139: train_loss -0.1002 
2025-08-28 01:18:45.877644: val_loss -0.0915 
2025-08-28 01:18:45.881822: Pseudo dice [np.float32(0.7025)] 
2025-08-28 01:18:45.888513: Epoch time: 25.12 s 
2025-08-28 01:18:46.565659:  
2025-08-28 01:18:46.573024: Epoch 892 
2025-08-28 01:18:46.578224: Current learning rate: 0.00135 
2025-08-28 01:19:10.239449: train_loss -0.1127 
2025-08-28 01:19:10.247793: val_loss -0.1186 
2025-08-28 01:19:10.252297: Pseudo dice [np.float32(0.6869)] 
2025-08-28 01:19:10.258780: Epoch time: 23.68 s 
2025-08-28 01:19:11.078812:  
2025-08-28 01:19:11.088202: Epoch 893 
2025-08-28 01:19:11.097435: Current learning rate: 0.00134 
2025-08-28 01:19:35.744121: train_loss -0.0857 
2025-08-28 01:19:35.752424: val_loss -0.1658 
2025-08-28 01:19:35.761082: Pseudo dice [np.float32(0.7162)] 
2025-08-28 01:19:35.767456: Epoch time: 24.67 s 
2025-08-28 01:19:36.439443:  
2025-08-28 01:19:36.447783: Epoch 894 
2025-08-28 01:19:36.454140: Current learning rate: 0.00133 
2025-08-28 01:20:00.852595: train_loss -0.0784 
2025-08-28 01:20:00.861125: val_loss -0.1689 
2025-08-28 01:20:00.865052: Pseudo dice [np.float32(0.758)] 
2025-08-28 01:20:00.873687: Epoch time: 24.42 s 
2025-08-28 01:20:01.539497:  
2025-08-28 01:20:01.545865: Epoch 895 
2025-08-28 01:20:01.553027: Current learning rate: 0.00132 
2025-08-28 01:20:26.687270: train_loss -0.1175 
2025-08-28 01:20:26.694933: val_loss -0.0631 
2025-08-28 01:20:26.699114: Pseudo dice [np.float32(0.6248)] 
2025-08-28 01:20:26.708914: Epoch time: 25.15 s 
2025-08-28 01:20:27.380993:  
2025-08-28 01:20:27.389378: Epoch 896 
2025-08-28 01:20:27.394468: Current learning rate: 0.0013 
2025-08-28 01:20:52.641975: train_loss -0.1027 
2025-08-28 01:20:52.650093: val_loss -0.0954 
2025-08-28 01:20:52.654198: Pseudo dice [np.float32(0.5956)] 
2025-08-28 01:20:52.661085: Epoch time: 25.26 s 
2025-08-28 01:20:53.327713:  
2025-08-28 01:20:53.336041: Epoch 897 
2025-08-28 01:20:53.341221: Current learning rate: 0.00129 
2025-08-28 01:21:18.067268: train_loss -0.0806 
2025-08-28 01:21:18.075403: val_loss -0.0707 
2025-08-28 01:21:18.079567: Pseudo dice [np.float32(0.5737)] 
2025-08-28 01:21:18.086444: Epoch time: 24.74 s 
2025-08-28 01:21:18.755087:  
2025-08-28 01:21:18.763423: Epoch 898 
2025-08-28 01:21:18.769879: Current learning rate: 0.00128 
2025-08-28 01:21:43.317637: train_loss -0.0725 
2025-08-28 01:21:43.325625: val_loss -0.0914 
2025-08-28 01:21:43.333951: Pseudo dice [np.float32(0.4156)] 
2025-08-28 01:21:43.339118: Epoch time: 24.56 s 
2025-08-28 01:21:44.150271:  
2025-08-28 01:21:44.159710: Epoch 899 
2025-08-28 01:21:44.166984: Current learning rate: 0.00127 
2025-08-28 01:22:08.859805: train_loss -0.1119 
2025-08-28 01:22:08.867785: val_loss -0.07 
2025-08-28 01:22:08.871855: Pseudo dice [np.float32(0.4791)] 
2025-08-28 01:22:08.881256: Epoch time: 24.71 s 
2025-08-28 01:22:09.748857:  
2025-08-28 01:22:09.757178: Epoch 900 
2025-08-28 01:22:09.763359: Current learning rate: 0.00126 
2025-08-28 01:22:34.013724: train_loss -0.106 
2025-08-28 01:22:34.022075: val_loss -0.0546 
2025-08-28 01:22:34.030408: Pseudo dice [np.float32(0.5446)] 
2025-08-28 01:22:34.034672: Epoch time: 24.27 s 
2025-08-28 01:22:34.715437:  
2025-08-28 01:22:34.723794: Epoch 901 
2025-08-28 01:22:34.731424: Current learning rate: 0.00125 
2025-08-28 01:22:59.722995: train_loss -0.1051 
2025-08-28 01:22:59.731065: val_loss -0.0889 
2025-08-28 01:22:59.735548: Pseudo dice [np.float32(0.3922)] 
2025-08-28 01:22:59.743985: Epoch time: 25.01 s 
2025-08-28 01:23:00.412929:  
2025-08-28 01:23:00.421256: Epoch 902 
2025-08-28 01:23:00.426401: Current learning rate: 0.00124 
2025-08-28 01:23:25.732304: train_loss -0.1116 
2025-08-28 01:23:25.740431: val_loss -0.0724 
2025-08-28 01:23:25.748713: Pseudo dice [np.float32(0.5921)] 
2025-08-28 01:23:25.754504: Epoch time: 25.32 s 
2025-08-28 01:23:26.483747:  
2025-08-28 01:23:26.491010: Epoch 903 
2025-08-28 01:23:26.496725: Current learning rate: 0.00122 
2025-08-28 01:23:51.862302: train_loss -0.1156 
2025-08-28 01:23:51.870655: val_loss -0.0501 
2025-08-28 01:23:51.874865: Pseudo dice [np.float32(0.4612)] 
2025-08-28 01:23:51.883642: Epoch time: 25.38 s 
2025-08-28 01:23:52.643268:  
2025-08-28 01:23:52.650837: Epoch 904 
2025-08-28 01:23:52.658534: Current learning rate: 0.00121 
2025-08-28 01:24:18.514067: train_loss -0.0881 
2025-08-28 01:24:18.522241: val_loss -0.087 
2025-08-28 01:24:18.526436: Pseudo dice [np.float32(0.6534)] 
2025-08-28 01:24:18.533569: Epoch time: 25.87 s 
2025-08-28 01:24:19.251960:  
2025-08-28 01:24:19.260318: Epoch 905 
2025-08-28 01:24:19.266790: Current learning rate: 0.0012 
2025-08-28 01:24:44.965202: train_loss -0.1027 
2025-08-28 01:24:44.977866: val_loss -0.1983 
2025-08-28 01:24:44.982360: Pseudo dice [np.float32(0.7424)] 
2025-08-28 01:24:44.987898: Epoch time: 25.71 s 
2025-08-28 01:24:45.895726:  
2025-08-28 01:24:45.903937: Epoch 906 
2025-08-28 01:24:45.910941: Current learning rate: 0.00119 
2025-08-28 01:25:10.887358: train_loss -0.0832 
2025-08-28 01:25:10.895633: val_loss -0.1307 
2025-08-28 01:25:10.899527: Pseudo dice [np.float32(0.5797)] 
2025-08-28 01:25:10.908551: Epoch time: 24.99 s 
2025-08-28 01:25:11.614810:  
2025-08-28 01:25:11.624078: Epoch 907 
2025-08-28 01:25:11.630512: Current learning rate: 0.00118 
2025-08-28 01:25:37.409752: train_loss -0.096 
2025-08-28 01:25:37.417663: val_loss -0.0836 
2025-08-28 01:25:37.425858: Pseudo dice [np.float32(0.4806)] 
2025-08-28 01:25:37.430959: Epoch time: 25.8 s 
2025-08-28 01:25:38.198733:  
2025-08-28 01:25:38.210142: Epoch 908 
2025-08-28 01:25:38.217834: Current learning rate: 0.00117 
2025-08-28 01:26:03.769317: train_loss -0.0812 
2025-08-28 01:26:03.777591: val_loss -0.0596 
2025-08-28 01:26:03.781510: Pseudo dice [np.float32(0.4631)] 
2025-08-28 01:26:03.789382: Epoch time: 25.57 s 
2025-08-28 01:26:04.529064:  
2025-08-28 01:26:04.536245: Epoch 909 
2025-08-28 01:26:04.542616: Current learning rate: 0.00116 
2025-08-28 01:26:30.174797: train_loss -0.0893 
2025-08-28 01:26:30.182848: val_loss -0.0827 
2025-08-28 01:26:30.191273: Pseudo dice [np.float32(0.4524)] 
2025-08-28 01:26:30.197129: Epoch time: 25.65 s 
2025-08-28 01:26:30.941892:  
2025-08-28 01:26:30.952118: Epoch 910 
2025-08-28 01:26:30.961742: Current learning rate: 0.00115 
2025-08-28 01:26:56.534412: train_loss -0.1112 
2025-08-28 01:26:56.542481: val_loss -0.0962 
2025-08-28 01:26:56.550826: Pseudo dice [np.float32(0.7264)] 
2025-08-28 01:26:56.556988: Epoch time: 25.59 s 
2025-08-28 01:26:57.287907:  
2025-08-28 01:26:57.296195: Epoch 911 
2025-08-28 01:26:57.302621: Current learning rate: 0.00113 
2025-08-28 01:27:22.995167: train_loss -0.1098 
2025-08-28 01:27:23.002173: val_loss -0.0175 
2025-08-28 01:27:23.010581: Pseudo dice [np.float32(0.0756)] 
2025-08-28 01:27:23.016131: Epoch time: 25.71 s 
2025-08-28 01:27:23.907309:  
2025-08-28 01:27:23.918693: Epoch 912 
2025-08-28 01:27:23.927147: Current learning rate: 0.00112 
2025-08-28 01:27:49.929385: train_loss -0.0709 
2025-08-28 01:27:49.937567: val_loss -0.1707 
2025-08-28 01:27:49.941851: Pseudo dice [np.float32(0.6769)] 
2025-08-28 01:27:49.950590: Epoch time: 26.02 s 
2025-08-28 01:27:50.700680:  
2025-08-28 01:27:50.709301: Epoch 913 
2025-08-28 01:27:50.716124: Current learning rate: 0.00111 
2025-08-28 01:28:16.169278: train_loss -0.0942 
2025-08-28 01:28:16.176159: val_loss -0.0646 
2025-08-28 01:28:16.184835: Pseudo dice [np.float32(0.324)] 
2025-08-28 01:28:16.189779: Epoch time: 25.47 s 
2025-08-28 01:28:16.936238:  
2025-08-28 01:28:16.945584: Epoch 914 
2025-08-28 01:28:16.954970: Current learning rate: 0.0011 
2025-08-28 01:28:42.477448: train_loss -0.092 
2025-08-28 01:28:42.489911: val_loss -0.0992 
2025-08-28 01:28:42.494130: Pseudo dice [np.float32(0.5411)] 
2025-08-28 01:28:42.501185: Epoch time: 25.54 s 
2025-08-28 01:28:43.235380:  
2025-08-28 01:28:43.244363: Epoch 915 
2025-08-28 01:28:43.250048: Current learning rate: 0.00109 
2025-08-28 01:29:08.557589: train_loss -0.1032 
2025-08-28 01:29:08.566089: val_loss -0.0989 
2025-08-28 01:29:08.574351: Pseudo dice [np.float32(0.7101)] 
2025-08-28 01:29:08.580718: Epoch time: 25.32 s 
2025-08-28 01:29:09.318233:  
2025-08-28 01:29:09.327070: Epoch 916 
2025-08-28 01:29:09.333423: Current learning rate: 0.00108 
2025-08-28 01:29:35.201577: train_loss -0.1053 
2025-08-28 01:29:35.209225: val_loss -0.0379 
2025-08-28 01:29:35.213688: Pseudo dice [np.float32(0.2343)] 
2025-08-28 01:29:35.221227: Epoch time: 25.88 s 
2025-08-28 01:29:35.958895:  
2025-08-28 01:29:35.966158: Epoch 917 
2025-08-28 01:29:35.972341: Current learning rate: 0.00106 
2025-08-28 01:30:01.477100: train_loss -0.0943 
2025-08-28 01:30:01.485451: val_loss -0.1112 
2025-08-28 01:30:01.493792: Pseudo dice [np.float32(0.7009)] 
2025-08-28 01:30:01.500841: Epoch time: 25.52 s 
2025-08-28 01:30:02.271260:  
2025-08-28 01:30:02.278913: Epoch 918 
2025-08-28 01:30:02.285913: Current learning rate: 0.00105 
2025-08-28 01:30:28.203770: train_loss -0.0996 
2025-08-28 01:30:28.212167: val_loss -0.1467 
2025-08-28 01:30:28.220167: Pseudo dice [np.float32(0.7868)] 
2025-08-28 01:30:28.225266: Epoch time: 25.93 s 
2025-08-28 01:30:29.117047:  
2025-08-28 01:30:29.128571: Epoch 919 
2025-08-28 01:30:29.139545: Current learning rate: 0.00104 
2025-08-28 01:30:54.559312: train_loss -0.1131 
2025-08-28 01:30:54.567608: val_loss -0.0779 
2025-08-28 01:30:54.571770: Pseudo dice [np.float32(0.339)] 
2025-08-28 01:30:54.580831: Epoch time: 25.44 s 
2025-08-28 01:30:55.319434:  
2025-08-28 01:30:55.328852: Epoch 920 
2025-08-28 01:30:55.339350: Current learning rate: 0.00103 
2025-08-28 01:31:20.614437: train_loss -0.1134 
2025-08-28 01:31:20.622787: val_loss -0.0569 
2025-08-28 01:31:20.627220: Pseudo dice [np.float32(0.4599)] 
2025-08-28 01:31:20.633870: Epoch time: 25.3 s 
2025-08-28 01:31:21.393239:  
2025-08-28 01:31:21.402377: Epoch 921 
2025-08-28 01:31:21.413230: Current learning rate: 0.00102 
2025-08-28 01:31:46.944893: train_loss -0.1014 
2025-08-28 01:31:46.953548: val_loss -0.0609 
2025-08-28 01:31:46.961595: Pseudo dice [np.float32(0.5284)] 
2025-08-28 01:31:46.966882: Epoch time: 25.55 s 
2025-08-28 01:31:47.735293:  
2025-08-28 01:31:47.749114: Epoch 922 
2025-08-28 01:31:47.756691: Current learning rate: 0.00101 
2025-08-28 01:32:13.379175: train_loss -0.1222 
2025-08-28 01:32:13.387545: val_loss -0.101 
2025-08-28 01:32:13.392180: Pseudo dice [np.float32(0.7027)] 
2025-08-28 01:32:13.399619: Epoch time: 25.65 s 
2025-08-28 01:32:14.150081:  
2025-08-28 01:32:14.159536: Epoch 923 
2025-08-28 01:32:14.166743: Current learning rate: 0.001 
2025-08-28 01:32:39.271715: train_loss -0.0835 
2025-08-28 01:32:39.280530: val_loss -0.1644 
2025-08-28 01:32:39.288981: Pseudo dice [np.float32(0.6913)] 
2025-08-28 01:32:39.294198: Epoch time: 25.12 s 
2025-08-28 01:32:40.035231:  
2025-08-28 01:32:40.043566: Epoch 924 
2025-08-28 01:32:40.051257: Current learning rate: 0.00098 
2025-08-28 01:33:05.527499: train_loss -0.0861 
2025-08-28 01:33:05.536196: val_loss -0.1411 
2025-08-28 01:33:05.540296: Pseudo dice [np.float32(0.6274)] 
2025-08-28 01:33:05.549126: Epoch time: 25.49 s 
2025-08-28 01:33:06.440920:  
2025-08-28 01:33:06.449398: Epoch 925 
2025-08-28 01:33:06.457672: Current learning rate: 0.00097 
2025-08-28 01:33:31.170528: train_loss -0.089 
2025-08-28 01:33:31.178440: val_loss -0.0994 
2025-08-28 01:33:31.182281: Pseudo dice [np.float32(0.5804)] 
2025-08-28 01:33:31.190966: Epoch time: 24.73 s 
2025-08-28 01:33:31.936036:  
2025-08-28 01:33:31.946742: Epoch 926 
2025-08-28 01:33:31.957164: Current learning rate: 0.00096 
2025-08-28 01:33:56.653539: train_loss -0.1208 
2025-08-28 01:33:56.661933: val_loss -0.0772 
2025-08-28 01:33:56.666268: Pseudo dice [np.float32(0.6005)] 
2025-08-28 01:33:56.673100: Epoch time: 24.72 s 
2025-08-28 01:33:57.414676:  
2025-08-28 01:33:57.422992: Epoch 927 
2025-08-28 01:33:57.429989: Current learning rate: 0.00095 
2025-08-28 01:34:22.704384: train_loss -0.0867 
2025-08-28 01:34:22.713010: val_loss -0.1095 
2025-08-28 01:34:22.717383: Pseudo dice [np.float32(0.6748)] 
2025-08-28 01:34:22.723145: Epoch time: 25.29 s 
2025-08-28 01:34:23.427148:  
2025-08-28 01:34:23.435467: Epoch 928 
2025-08-28 01:34:23.441748: Current learning rate: 0.00094 
2025-08-28 01:34:48.643632: train_loss -0.1001 
2025-08-28 01:34:48.651618: val_loss -0.0892 
2025-08-28 01:34:48.659643: Pseudo dice [np.float32(0.526)] 
2025-08-28 01:34:48.664456: Epoch time: 25.22 s 
2025-08-28 01:34:49.388544:  
2025-08-28 01:34:49.397774: Epoch 929 
2025-08-28 01:34:49.404661: Current learning rate: 0.00092 
2025-08-28 01:35:14.564739: train_loss -0.1016 
2025-08-28 01:35:14.573062: val_loss -0.1433 
2025-08-28 01:35:14.577179: Pseudo dice [np.float32(0.6657)] 
2025-08-28 01:35:14.584271: Epoch time: 25.18 s 
2025-08-28 01:35:15.306953:  
2025-08-28 01:35:15.316435: Epoch 930 
2025-08-28 01:35:15.323795: Current learning rate: 0.00091 
2025-08-28 01:35:40.696620: train_loss -0.0781 
2025-08-28 01:35:40.707429: val_loss -0.1134 
2025-08-28 01:35:40.711955: Pseudo dice [np.float32(0.485)] 
2025-08-28 01:35:40.718184: Epoch time: 25.39 s 
2025-08-28 01:35:41.589492:  
2025-08-28 01:35:41.597836: Epoch 931 
2025-08-28 01:35:41.604077: Current learning rate: 0.0009 
2025-08-28 01:36:06.362203: train_loss -0.1123 
2025-08-28 01:36:06.370564: val_loss -0.0905 
2025-08-28 01:36:06.374700: Pseudo dice [np.float32(0.5855)] 
2025-08-28 01:36:06.383759: Epoch time: 24.77 s 
2025-08-28 01:36:07.087771:  
2025-08-28 01:36:07.097280: Epoch 932 
2025-08-28 01:36:07.102460: Current learning rate: 0.00089 
2025-08-28 01:36:32.442720: train_loss -0.1109 
2025-08-28 01:36:32.451077: val_loss -0.0445 
2025-08-28 01:36:32.454960: Pseudo dice [np.float32(0.4956)] 
2025-08-28 01:36:32.460907: Epoch time: 25.36 s 
2025-08-28 01:36:33.176434:  
2025-08-28 01:36:33.184648: Epoch 933 
2025-08-28 01:36:33.192072: Current learning rate: 0.00088 
2025-08-28 01:36:59.043829: train_loss -0.1006 
2025-08-28 01:36:59.052342: val_loss -0.119 
2025-08-28 01:36:59.060218: Pseudo dice [np.float32(0.6435)] 
2025-08-28 01:36:59.064820: Epoch time: 25.87 s 
2025-08-28 01:36:59.823764:  
2025-08-28 01:36:59.834522: Epoch 934 
2025-08-28 01:36:59.841201: Current learning rate: 0.00087 
2025-08-28 01:37:24.435990: train_loss -0.0928 
2025-08-28 01:37:24.444354: val_loss -0.1128 
2025-08-28 01:37:24.448572: Pseudo dice [np.float32(0.5797)] 
2025-08-28 01:37:24.456516: Epoch time: 24.61 s 
2025-08-28 01:37:25.208147:  
2025-08-28 01:37:25.215787: Epoch 935 
2025-08-28 01:37:25.223239: Current learning rate: 0.00085 
2025-08-28 01:37:49.815363: train_loss -0.1025 
2025-08-28 01:37:49.823893: val_loss -0.1594 
2025-08-28 01:37:49.828002: Pseudo dice [np.float32(0.6592)] 
2025-08-28 01:37:49.835184: Epoch time: 24.61 s 
2025-08-28 01:37:50.558079:  
2025-08-28 01:37:50.566080: Epoch 936 
2025-08-28 01:37:50.571679: Current learning rate: 0.00084 
2025-08-28 01:38:15.767512: train_loss -0.0874 
2025-08-28 01:38:15.775145: val_loss -0.1584 
2025-08-28 01:38:15.783082: Pseudo dice [np.float32(0.6609)] 
2025-08-28 01:38:15.788358: Epoch time: 25.21 s 
2025-08-28 01:38:16.555688:  
2025-08-28 01:38:16.564688: Epoch 937 
2025-08-28 01:38:16.575401: Current learning rate: 0.00083 
2025-08-28 01:38:41.801063: train_loss -0.1211 
2025-08-28 01:38:41.809358: val_loss -0.0893 
2025-08-28 01:38:41.817405: Pseudo dice [np.float32(0.6369)] 
2025-08-28 01:38:41.822855: Epoch time: 25.25 s 
2025-08-28 01:38:42.701334:  
2025-08-28 01:38:42.708803: Epoch 938 
2025-08-28 01:38:42.716356: Current learning rate: 0.00082 
2025-08-28 01:39:07.697387: train_loss -0.1082 
2025-08-28 01:39:07.705785: val_loss -0.0363 
2025-08-28 01:39:07.709914: Pseudo dice [np.float32(0.216)] 
2025-08-28 01:39:07.716907: Epoch time: 25.0 s 
2025-08-28 01:39:08.458531:  
2025-08-28 01:39:08.467941: Epoch 939 
2025-08-28 01:39:08.478177: Current learning rate: 0.00081 
2025-08-28 01:39:34.336292: train_loss -0.1057 
2025-08-28 01:39:34.344615: val_loss -0.1175 
2025-08-28 01:39:34.349309: Pseudo dice [np.float32(0.7759)] 
2025-08-28 01:39:34.354968: Epoch time: 25.88 s 
2025-08-28 01:39:35.139675:  
2025-08-28 01:39:35.147673: Epoch 940 
2025-08-28 01:39:35.156022: Current learning rate: 0.00079 
2025-08-28 01:40:00.088516: train_loss -0.1259 
2025-08-28 01:40:00.095850: val_loss -0.1253 
2025-08-28 01:40:00.103894: Pseudo dice [np.float32(0.5684)] 
2025-08-28 01:40:00.109133: Epoch time: 24.95 s 
2025-08-28 01:40:00.842096:  
2025-08-28 01:40:00.853544: Epoch 941 
2025-08-28 01:40:00.863048: Current learning rate: 0.00078 
2025-08-28 01:40:26.613680: train_loss -0.1031 
2025-08-28 01:40:26.622039: val_loss -0.0743 
2025-08-28 01:40:26.626206: Pseudo dice [np.float32(0.6384)] 
2025-08-28 01:40:26.633306: Epoch time: 25.77 s 
2025-08-28 01:40:27.400210:  
2025-08-28 01:40:27.415485: Epoch 942 
2025-08-28 01:40:27.423016: Current learning rate: 0.00077 
2025-08-28 01:40:52.723104: train_loss -0.0988 
2025-08-28 01:40:52.731439: val_loss -0.115 
2025-08-28 01:40:52.739508: Pseudo dice [np.float32(0.5247)] 
2025-08-28 01:40:52.744927: Epoch time: 25.33 s 
2025-08-28 01:40:53.478817:  
2025-08-28 01:40:53.486900: Epoch 943 
2025-08-28 01:40:53.492796: Current learning rate: 0.00076 
2025-08-28 01:41:18.866581: train_loss -0.0982 
2025-08-28 01:41:18.874544: val_loss -0.1343 
2025-08-28 01:41:18.878644: Pseudo dice [np.float32(0.7071)] 
2025-08-28 01:41:18.887371: Epoch time: 25.39 s 
2025-08-28 01:41:19.784276:  
2025-08-28 01:41:19.792282: Epoch 944 
2025-08-28 01:41:19.798979: Current learning rate: 0.00075 
2025-08-28 01:41:45.338395: train_loss -0.1339 
2025-08-28 01:41:45.346457: val_loss -0.0615 
2025-08-28 01:41:45.354807: Pseudo dice [np.float32(0.2781)] 
2025-08-28 01:41:45.359986: Epoch time: 25.56 s 
2025-08-28 01:41:46.110720:  
2025-08-28 01:41:46.120550: Epoch 945 
2025-08-28 01:41:46.126354: Current learning rate: 0.00074 
2025-08-28 01:42:11.577095: train_loss -0.1244 
2025-08-28 01:42:11.585141: val_loss -0.1079 
2025-08-28 01:42:11.589600: Pseudo dice [np.float32(0.4842)] 
2025-08-28 01:42:11.598185: Epoch time: 25.47 s 
2025-08-28 01:42:12.328636:  
2025-08-28 01:42:12.337341: Epoch 946 
2025-08-28 01:42:12.340421: Current learning rate: 0.00072 
2025-08-28 01:42:37.515341: train_loss -0.0878 
2025-08-28 01:42:37.523551: val_loss -0.1104 
2025-08-28 01:42:37.527698: Pseudo dice [np.float32(0.7315)] 
2025-08-28 01:42:37.536709: Epoch time: 25.19 s 
2025-08-28 01:42:38.266103:  
2025-08-28 01:42:38.275694: Epoch 947 
2025-08-28 01:42:38.283209: Current learning rate: 0.00071 
2025-08-28 01:43:04.095949: train_loss -0.073 
2025-08-28 01:43:04.104287: val_loss -0.1652 
2025-08-28 01:43:04.112593: Pseudo dice [np.float32(0.654)] 
2025-08-28 01:43:04.117754: Epoch time: 25.83 s 
2025-08-28 01:43:04.869783:  
2025-08-28 01:43:04.879692: Epoch 948 
2025-08-28 01:43:04.884578: Current learning rate: 0.0007 
2025-08-28 01:43:30.826741: train_loss -0.1236 
2025-08-28 01:43:30.831291: val_loss -0.0687 
2025-08-28 01:43:30.839576: Pseudo dice [np.float32(0.6507)] 
2025-08-28 01:43:30.844610: Epoch time: 25.96 s 
2025-08-28 01:43:31.590012:  
2025-08-28 01:43:31.594514: Epoch 949 
2025-08-28 01:43:31.603166: Current learning rate: 0.00069 
2025-08-28 01:43:57.053161: train_loss -0.0957 
2025-08-28 01:43:57.061350: val_loss -0.1215 
2025-08-28 01:43:57.069629: Pseudo dice [np.float32(0.4683)] 
2025-08-28 01:43:57.074898: Epoch time: 25.47 s 
2025-08-28 01:43:58.026760:  
2025-08-28 01:43:58.037138: Epoch 950 
2025-08-28 01:43:58.045139: Current learning rate: 0.00067 
2025-08-28 01:44:23.859184: train_loss -0.0855 
2025-08-28 01:44:23.867215: val_loss -0.1194 
2025-08-28 01:44:23.875415: Pseudo dice [np.float32(0.6742)] 
2025-08-28 01:44:23.880417: Epoch time: 25.83 s 
2025-08-28 01:44:24.628916:  
2025-08-28 01:44:24.637485: Epoch 951 
2025-08-28 01:44:24.644021: Current learning rate: 0.00066 
2025-08-28 01:44:50.497858: train_loss -0.122 
2025-08-28 01:44:50.506390: val_loss -0.073 
2025-08-28 01:44:50.510471: Pseudo dice [np.float32(0.5542)] 
2025-08-28 01:44:50.517494: Epoch time: 25.87 s 
2025-08-28 01:44:51.264872:  
2025-08-28 01:44:51.273431: Epoch 952 
2025-08-28 01:44:51.278251: Current learning rate: 0.00065 
2025-08-28 01:45:16.745493: train_loss -0.1031 
2025-08-28 01:45:16.753572: val_loss -0.106 
2025-08-28 01:45:16.757609: Pseudo dice [np.float32(0.714)] 
2025-08-28 01:45:16.764647: Epoch time: 25.48 s 
2025-08-28 01:45:17.516455:  
2025-08-28 01:45:17.521163: Epoch 953 
2025-08-28 01:45:17.530152: Current learning rate: 0.00064 
2025-08-28 01:45:42.554118: train_loss -0.1103 
2025-08-28 01:45:42.566615: val_loss -0.0981 
2025-08-28 01:45:42.570785: Pseudo dice [np.float32(0.4815)] 
2025-08-28 01:45:42.578627: Epoch time: 25.04 s 
2025-08-28 01:45:43.327845:  
2025-08-28 01:45:43.335172: Epoch 954 
2025-08-28 01:45:43.345029: Current learning rate: 0.00063 
2025-08-28 01:46:08.892484: train_loss -0.1379 
2025-08-28 01:46:08.901235: val_loss -0.0841 
2025-08-28 01:46:08.905406: Pseudo dice [np.float32(0.4045)] 
2025-08-28 01:46:08.913356: Epoch time: 25.57 s 
2025-08-28 01:46:09.664766:  
2025-08-28 01:46:09.674852: Epoch 955 
2025-08-28 01:46:09.682304: Current learning rate: 0.00061 
2025-08-28 01:46:34.993580: train_loss -0.1097 
2025-08-28 01:46:34.998152: val_loss -0.1698 
2025-08-28 01:46:35.006492: Pseudo dice [np.float32(0.7144)] 
2025-08-28 01:46:35.011816: Epoch time: 25.33 s 
2025-08-28 01:46:35.752970:  
2025-08-28 01:46:35.761184: Epoch 956 
2025-08-28 01:46:35.768821: Current learning rate: 0.0006 
2025-08-28 01:47:01.499552: train_loss -0.0845 
2025-08-28 01:47:01.507952: val_loss -0.1485 
2025-08-28 01:47:01.512020: Pseudo dice [np.float32(0.6835)] 
2025-08-28 01:47:01.520204: Epoch time: 25.75 s 
2025-08-28 01:47:02.259668:  
2025-08-28 01:47:02.268584: Epoch 957 
2025-08-28 01:47:02.275643: Current learning rate: 0.00059 
2025-08-28 01:47:28.522722: train_loss -0.1167 
2025-08-28 01:47:28.531125: val_loss -0.173 
2025-08-28 01:47:28.534907: Pseudo dice [np.float32(0.7036)] 
2025-08-28 01:47:28.542112: Epoch time: 26.27 s 
2025-08-28 01:47:29.303149:  
2025-08-28 01:47:29.314824: Epoch 958 
2025-08-28 01:47:29.319284: Current learning rate: 0.00058 
2025-08-28 01:47:54.803041: train_loss -0.1017 
2025-08-28 01:47:54.811234: val_loss -0.119 
2025-08-28 01:47:54.815324: Pseudo dice [np.float32(0.5193)] 
2025-08-28 01:47:54.823423: Epoch time: 25.5 s 
2025-08-28 01:47:55.559407:  
2025-08-28 01:47:55.571366: Epoch 959 
2025-08-28 01:47:55.577391: Current learning rate: 0.00056 
2025-08-28 01:48:20.445125: train_loss -0.1181 
2025-08-28 01:48:20.453440: val_loss -0.0498 
2025-08-28 01:48:20.461762: Pseudo dice [np.float32(0.3646)] 
2025-08-28 01:48:20.467095: Epoch time: 24.89 s 
2025-08-28 01:48:21.225399:  
2025-08-28 01:48:21.235974: Epoch 960 
2025-08-28 01:48:21.242736: Current learning rate: 0.00055 
2025-08-28 01:48:46.500521: train_loss -0.0882 
2025-08-28 01:48:46.508894: val_loss -0.0715 
2025-08-28 01:48:46.512984: Pseudo dice [np.float32(0.5747)] 
2025-08-28 01:48:46.521970: Epoch time: 25.28 s 
2025-08-28 01:48:47.278098:  
2025-08-28 01:48:47.286401: Epoch 961 
2025-08-28 01:48:47.292549: Current learning rate: 0.00054 
2025-08-28 01:49:11.967659: train_loss -0.1117 
2025-08-28 01:49:11.975690: val_loss -0.1111 
2025-08-28 01:49:11.979853: Pseudo dice [np.float32(0.5094)] 
2025-08-28 01:49:11.987751: Epoch time: 24.69 s 
2025-08-28 01:49:12.750115:  
2025-08-28 01:49:12.759685: Epoch 962 
2025-08-28 01:49:12.765602: Current learning rate: 0.00053 
2025-08-28 01:49:37.935179: train_loss -0.0917 
2025-08-28 01:49:37.943265: val_loss -0.1175 
2025-08-28 01:49:37.947774: Pseudo dice [np.float32(0.5886)] 
2025-08-28 01:49:37.955390: Epoch time: 25.19 s 
2025-08-28 01:49:38.697055:  
2025-08-28 01:49:38.707989: Epoch 963 
2025-08-28 01:49:38.714803: Current learning rate: 0.00051 
2025-08-28 01:50:04.223907: train_loss -0.0927 
2025-08-28 01:50:04.232338: val_loss -0.1135 
2025-08-28 01:50:04.236201: Pseudo dice [np.float32(0.7183)] 
2025-08-28 01:50:04.244173: Epoch time: 25.53 s 
2025-08-28 01:50:04.988506:  
2025-08-28 01:50:04.999289: Epoch 964 
2025-08-28 01:50:05.006164: Current learning rate: 0.0005 
2025-08-28 01:50:30.179156: train_loss -0.1108 
2025-08-28 01:50:30.187444: val_loss -0.1311 
2025-08-28 01:50:30.191767: Pseudo dice [np.float32(0.7152)] 
2025-08-28 01:50:30.198223: Epoch time: 25.19 s 
2025-08-28 01:50:30.927345:  
2025-08-28 01:50:30.936699: Epoch 965 
2025-08-28 01:50:30.945484: Current learning rate: 0.00049 
2025-08-28 01:50:55.860221: train_loss -0.1219 
2025-08-28 01:50:55.867190: val_loss -0.085 
2025-08-28 01:50:55.875230: Pseudo dice [np.float32(0.6223)] 
2025-08-28 01:50:55.881313: Epoch time: 24.93 s 
2025-08-28 01:50:56.622398:  
2025-08-28 01:50:56.630244: Epoch 966 
2025-08-28 01:50:56.637304: Current learning rate: 0.00048 
2025-08-28 01:51:21.922036: train_loss -0.1369 
2025-08-28 01:51:21.930437: val_loss -0.1362 
2025-08-28 01:51:21.934584: Pseudo dice [np.float32(0.4479)] 
2025-08-28 01:51:21.940723: Epoch time: 25.3 s 
2025-08-28 01:51:22.676094:  
2025-08-28 01:51:22.685314: Epoch 967 
2025-08-28 01:51:22.691592: Current learning rate: 0.00046 
2025-08-28 01:51:48.128039: train_loss -0.1009 
2025-08-28 01:51:48.135742: val_loss -0.1267 
2025-08-28 01:51:48.144431: Pseudo dice [np.float32(0.7619)] 
2025-08-28 01:51:48.150124: Epoch time: 25.45 s 
2025-08-28 01:51:48.865481:  
2025-08-28 01:51:48.876010: Epoch 968 
2025-08-28 01:51:48.885336: Current learning rate: 0.00045 
2025-08-28 01:52:14.090849: train_loss -0.1192 
2025-08-28 01:52:14.099365: val_loss -0.0849 
2025-08-28 01:52:14.107492: Pseudo dice [np.float32(0.5623)] 
2025-08-28 01:52:14.112888: Epoch time: 25.23 s 
2025-08-28 01:52:14.849832:  
2025-08-28 01:52:14.859387: Epoch 969 
2025-08-28 01:52:14.868500: Current learning rate: 0.00044 
2025-08-28 01:52:40.062519: train_loss -0.1186 
2025-08-28 01:52:40.075113: val_loss -0.0851 
2025-08-28 01:52:40.079500: Pseudo dice [np.float32(0.6211)] 
2025-08-28 01:52:40.087302: Epoch time: 25.21 s 
2025-08-28 01:52:40.846995:  
2025-08-28 01:52:40.856713: Epoch 970 
2025-08-28 01:52:40.863205: Current learning rate: 0.00043 
2025-08-28 01:53:05.933923: train_loss -0.108 
2025-08-28 01:53:05.942306: val_loss -0.1514 
2025-08-28 01:53:05.947022: Pseudo dice [np.float32(0.7651)] 
2025-08-28 01:53:05.953883: Epoch time: 25.09 s 
2025-08-28 01:53:06.686968:  
2025-08-28 01:53:06.696433: Epoch 971 
2025-08-28 01:53:06.703142: Current learning rate: 0.00041 
2025-08-28 01:53:31.597612: train_loss -0.1171 
2025-08-28 01:53:31.605697: val_loss -0.1713 
2025-08-28 01:53:31.609862: Pseudo dice [np.float32(0.7526)] 
2025-08-28 01:53:31.616000: Epoch time: 24.91 s 
2025-08-28 01:53:32.368932:  
2025-08-28 01:53:32.377094: Epoch 972 
2025-08-28 01:53:32.383513: Current learning rate: 0.0004 
2025-08-28 01:53:58.098837: train_loss -0.1213 
2025-08-28 01:53:58.107157: val_loss -0.0979 
2025-08-28 01:53:58.111361: Pseudo dice [np.float32(0.564)] 
2025-08-28 01:53:58.121324: Epoch time: 25.73 s 
2025-08-28 01:53:58.859970:  
2025-08-28 01:53:58.868244: Epoch 973 
2025-08-28 01:53:58.874582: Current learning rate: 0.00039 
2025-08-28 01:54:24.793257: train_loss -0.1307 
2025-08-28 01:54:24.800838: val_loss -0.1352 
2025-08-28 01:54:24.808831: Pseudo dice [np.float32(0.6156)] 
2025-08-28 01:54:24.814312: Epoch time: 25.94 s 
2025-08-28 01:54:25.563653:  
2025-08-28 01:54:25.571903: Epoch 974 
2025-08-28 01:54:25.578508: Current learning rate: 0.00037 
2025-08-28 01:54:50.710647: train_loss -0.1191 
2025-08-28 01:54:50.720986: val_loss -0.1625 
2025-08-28 01:54:50.728350: Pseudo dice [np.float32(0.5939)] 
2025-08-28 01:54:50.744957: Epoch time: 25.15 s 
2025-08-28 01:54:51.501103:  
2025-08-28 01:54:51.510573: Epoch 975 
2025-08-28 01:54:51.516660: Current learning rate: 0.00036 
2025-08-28 01:55:16.756486: train_loss -0.1355 
2025-08-28 01:55:16.765157: val_loss -0.0735 
2025-08-28 01:55:16.773543: Pseudo dice [np.float32(0.4903)] 
2025-08-28 01:55:16.778572: Epoch time: 25.26 s 
2025-08-28 01:55:17.519708:  
2025-08-28 01:55:17.524356: Epoch 976 
2025-08-28 01:55:17.532687: Current learning rate: 0.00035 
2025-08-28 01:55:42.803380: train_loss -0.1219 
2025-08-28 01:55:42.816148: val_loss -0.1331 
2025-08-28 01:55:42.820017: Pseudo dice [np.float32(0.7196)] 
2025-08-28 01:55:42.829970: Epoch time: 25.29 s 
2025-08-28 01:55:43.605076:  
2025-08-28 01:55:43.615301: Epoch 977 
2025-08-28 01:55:43.622884: Current learning rate: 0.00034 
2025-08-28 01:56:08.524827: train_loss -0.114 
2025-08-28 01:56:08.533326: val_loss -0.1287 
2025-08-28 01:56:08.541585: Pseudo dice [np.float32(0.6293)] 
2025-08-28 01:56:08.547346: Epoch time: 24.92 s 
2025-08-28 01:56:09.237892:  
2025-08-28 01:56:09.246039: Epoch 978 
2025-08-28 01:56:09.255789: Current learning rate: 0.00032 
2025-08-28 01:56:35.076327: train_loss -0.0977 
2025-08-28 01:56:35.084686: val_loss -0.0794 
2025-08-28 01:56:35.088793: Pseudo dice [np.float32(0.586)] 
2025-08-28 01:56:35.096763: Epoch time: 25.84 s 
2025-08-28 01:56:35.783208:  
2025-08-28 01:56:35.790691: Epoch 979 
2025-08-28 01:56:35.797749: Current learning rate: 0.00031 
2025-08-28 01:57:00.843723: train_loss -0.1152 
2025-08-28 01:57:00.852089: val_loss -0.0941 
2025-08-28 01:57:00.856484: Pseudo dice [np.float32(0.6856)] 
2025-08-28 01:57:00.865258: Epoch time: 25.06 s 
2025-08-28 01:57:01.555865:  
2025-08-28 01:57:01.564237: Epoch 980 
2025-08-28 01:57:01.569309: Current learning rate: 0.0003 
2025-08-28 01:57:25.497935: train_loss -0.1245 
2025-08-28 01:57:25.505856: val_loss -0.1723 
2025-08-28 01:57:25.509888: Pseudo dice [np.float32(0.6399)] 
2025-08-28 01:57:25.518865: Epoch time: 23.94 s 
2025-08-28 01:57:26.202229:  
2025-08-28 01:57:26.212204: Epoch 981 
2025-08-28 01:57:26.220530: Current learning rate: 0.00028 
2025-08-28 01:57:51.965608: train_loss -0.1122 
2025-08-28 01:57:51.973959: val_loss -0.1211 
2025-08-28 01:57:51.978119: Pseudo dice [np.float32(0.5796)] 
2025-08-28 01:57:51.985120: Epoch time: 25.77 s 
2025-08-28 01:57:52.667347:  
2025-08-28 01:57:52.678756: Epoch 982 
2025-08-28 01:57:52.684477: Current learning rate: 0.00027 
2025-08-28 01:58:17.174433: train_loss -0.1307 
2025-08-28 01:58:17.182461: val_loss -0.1229 
2025-08-28 01:58:17.186608: Pseudo dice [np.float32(0.4622)] 
2025-08-28 01:58:17.194952: Epoch time: 24.51 s 
2025-08-28 01:58:17.893550:  
2025-08-28 01:58:17.900839: Epoch 983 
2025-08-28 01:58:17.906003: Current learning rate: 0.00026 
2025-08-28 01:58:42.561954: train_loss -0.1088 
2025-08-28 01:58:42.570754: val_loss -0.1366 
2025-08-28 01:58:42.579038: Pseudo dice [np.float32(0.6056)] 
2025-08-28 01:58:42.583710: Epoch time: 24.67 s 
2025-08-28 01:58:43.276205:  
2025-08-28 01:58:43.284602: Epoch 984 
2025-08-28 01:58:43.294777: Current learning rate: 0.00024 
2025-08-28 01:59:09.034196: train_loss -0.0979 
2025-08-28 01:59:09.042551: val_loss -0.0559 
2025-08-28 01:59:09.046998: Pseudo dice [np.float32(0.3921)] 
2025-08-28 01:59:09.053711: Epoch time: 25.76 s 
2025-08-28 01:59:09.747474:  
2025-08-28 01:59:09.755611: Epoch 985 
2025-08-28 01:59:09.762952: Current learning rate: 0.00023 
2025-08-28 01:59:34.547710: train_loss -0.1225 
2025-08-28 01:59:34.555528: val_loss -0.0921 
2025-08-28 01:59:34.559982: Pseudo dice [np.float32(0.6688)] 
2025-08-28 01:59:34.567588: Epoch time: 24.8 s 
2025-08-28 01:59:35.260221:  
2025-08-28 01:59:35.267567: Epoch 986 
2025-08-28 01:59:35.272809: Current learning rate: 0.00021 
2025-08-28 01:59:59.939463: train_loss -0.0985 
2025-08-28 01:59:59.948212: val_loss -0.1373 
2025-08-28 01:59:59.953038: Pseudo dice [np.float32(0.5302)] 
2025-08-28 01:59:59.960758: Epoch time: 24.68 s 
2025-08-28 02:00:00.651646:  
2025-08-28 02:00:00.660993: Epoch 987 
2025-08-28 02:00:00.671144: Current learning rate: 0.0002 
2025-08-28 02:00:26.857719: train_loss -0.114 
2025-08-28 02:00:26.866121: val_loss -0.0786 
2025-08-28 02:00:26.874427: Pseudo dice [np.float32(0.6752)] 
2025-08-28 02:00:26.879381: Epoch time: 26.21 s 
2025-08-28 02:00:27.650580:  
2025-08-28 02:00:27.660560: Epoch 988 
2025-08-28 02:00:27.666890: Current learning rate: 0.00019 
2025-08-28 02:00:53.851431: train_loss -0.1016 
2025-08-28 02:00:53.859734: val_loss -0.1263 
2025-08-28 02:00:53.868083: Pseudo dice [np.float32(0.6832)] 
2025-08-28 02:00:53.873641: Epoch time: 26.2 s 
2025-08-28 02:00:54.689525:  
2025-08-28 02:00:54.699099: Epoch 989 
2025-08-28 02:00:54.705243: Current learning rate: 0.00017 
2025-08-28 02:01:20.060841: train_loss -0.1089 
2025-08-28 02:01:20.069236: val_loss -0.1389 
2025-08-28 02:01:20.073371: Pseudo dice [np.float32(0.6108)] 
2025-08-28 02:01:20.081369: Epoch time: 25.37 s 
2025-08-28 02:01:20.826462:  
2025-08-28 02:01:20.836941: Epoch 990 
2025-08-28 02:01:20.844880: Current learning rate: 0.00016 
2025-08-28 02:01:46.783369: train_loss -0.0951 
2025-08-28 02:01:46.791751: val_loss -0.0895 
2025-08-28 02:01:46.800095: Pseudo dice [np.float32(0.4813)] 
2025-08-28 02:01:46.806376: Epoch time: 25.96 s 
2025-08-28 02:01:47.558483:  
2025-08-28 02:01:47.566380: Epoch 991 
2025-08-28 02:01:47.572059: Current learning rate: 0.00014 
2025-08-28 02:02:13.059580: train_loss -0.0967 
2025-08-28 02:02:13.067984: val_loss -0.1228 
2025-08-28 02:02:13.072455: Pseudo dice [np.float32(0.6919)] 
2025-08-28 02:02:13.080195: Epoch time: 25.5 s 
2025-08-28 02:02:13.836711:  
2025-08-28 02:02:13.846690: Epoch 992 
2025-08-28 02:02:13.852423: Current learning rate: 0.00013 
2025-08-28 02:02:38.843694: train_loss -0.1009 
2025-08-28 02:02:38.852045: val_loss -0.0944 
2025-08-28 02:02:38.856202: Pseudo dice [np.float32(0.5015)] 
2025-08-28 02:02:38.864346: Epoch time: 25.01 s 
2025-08-28 02:02:39.622618:  
2025-08-28 02:02:39.632001: Epoch 993 
2025-08-28 02:02:39.649709: Current learning rate: 0.00011 
2025-08-28 02:03:05.670568: train_loss -0.1169 
2025-08-28 02:03:05.678837: val_loss -0.1669 
2025-08-28 02:03:05.687181: Pseudo dice [np.float32(0.7112)] 
2025-08-28 02:03:05.693321: Epoch time: 26.05 s 
2025-08-28 02:03:06.470165:  
2025-08-28 02:03:06.479632: Epoch 994 
2025-08-28 02:03:06.487814: Current learning rate: 0.0001 
2025-08-28 02:03:30.820551: train_loss -0.1044 
2025-08-28 02:03:30.828927: val_loss -0.0746 
2025-08-28 02:03:30.837635: Pseudo dice [np.float32(0.59)] 
2025-08-28 02:03:30.842919: Epoch time: 24.35 s 
2025-08-28 02:03:31.612970:  
2025-08-28 02:03:31.624399: Epoch 995 
2025-08-28 02:03:31.630798: Current learning rate: 8e-05 
2025-08-28 02:03:56.254282: train_loss -0.1242 
2025-08-28 02:03:56.266806: val_loss -0.1087 
2025-08-28 02:03:56.271006: Pseudo dice [np.float32(0.7151)] 
2025-08-28 02:03:56.277121: Epoch time: 24.64 s 
2025-08-28 02:03:57.021169:  
2025-08-28 02:03:57.030026: Epoch 996 
2025-08-28 02:03:57.036335: Current learning rate: 7e-05 
2025-08-28 02:04:22.660133: train_loss -0.0901 
2025-08-28 02:04:22.668185: val_loss -0.1453 
2025-08-28 02:04:22.676542: Pseudo dice [np.float32(0.6673)] 
2025-08-28 02:04:22.681605: Epoch time: 25.64 s 
2025-08-28 02:04:23.440066:  
2025-08-28 02:04:23.449139: Epoch 997 
2025-08-28 02:04:23.456304: Current learning rate: 5e-05 
2025-08-28 02:04:47.868962: train_loss -0.1147 
2025-08-28 02:04:47.876710: val_loss -0.1157 
2025-08-28 02:04:47.885005: Pseudo dice [np.float32(0.5346)] 
2025-08-28 02:04:47.890241: Epoch time: 24.43 s 
2025-08-28 02:04:48.711828:  
2025-08-28 02:04:48.722202: Epoch 998 
2025-08-28 02:04:48.732285: Current learning rate: 4e-05 
2025-08-28 02:05:12.709768: train_loss -0.1087 
2025-08-28 02:05:12.709768: val_loss -0.1293 
2025-08-28 02:05:12.718152: Pseudo dice [np.float32(0.704)] 
2025-08-28 02:05:12.723312: Epoch time: 24.0 s 
2025-08-28 02:05:13.532456:  
2025-08-28 02:05:13.532456: Epoch 999 
2025-08-28 02:05:13.543873: Current learning rate: 2e-05 
2025-08-28 02:05:39.269908: train_loss -0.1119 
2025-08-28 02:05:39.269908: val_loss -0.0848 
2025-08-28 02:05:39.278306: Pseudo dice [np.float32(0.6377)] 
2025-08-28 02:05:39.285251: Epoch time: 25.74 s 
2025-08-28 02:05:40.214464: Training done. 
2025-08-28 02:05:40.259197: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 02:05:40.282111: The split file contains 5 splits. 
2025-08-28 02:05:40.289994: Desired fold for training: 0 
2025-08-28 02:05:40.296695: This split has 524 training and 131 validation cases. 
2025-08-28 02:05:40.304967: predicting sub-r001s001 
2025-08-28 02:05:40.521402: sub-r001s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:05:50.372371: predicting sub-r001s005 
2025-08-28 02:05:50.593464: sub-r001s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:05:59.540132: predicting sub-r001s007 
2025-08-28 02:05:59.760216: sub-r001s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:09.816810: predicting sub-r001s011 
2025-08-28 02:06:10.026229: sub-r001s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:18.638381: predicting sub-r001s023 
2025-08-28 02:06:18.848078: sub-r001s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:29.136082: predicting sub-r001s026 
2025-08-28 02:06:29.363685: sub-r001s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:38.545808: predicting sub-r002s009 
2025-08-28 02:06:38.754415: sub-r002s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:47.337623: predicting sub-r002s011 
2025-08-28 02:06:47.550372: sub-r002s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:06:56.284047: predicting sub-r003s005 
2025-08-28 02:06:56.493921: sub-r003s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:06.965588: predicting sub-r003s006 
2025-08-28 02:07:07.204721: sub-r003s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:16.124624: predicting sub-r003s007 
2025-08-28 02:07:16.345664: sub-r003s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:26.580949: predicting sub-r003s008 
2025-08-28 02:07:26.802231: sub-r003s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:36.274328: predicting sub-r004s003 
2025-08-28 02:07:36.490804: sub-r004s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:46.768192: predicting sub-r004s023 
2025-08-28 02:07:46.984270: sub-r004s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:07:55.935326: predicting sub-r004s026 
2025-08-28 02:07:56.156282: sub-r004s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:06.717167: predicting sub-r005s068 
2025-08-28 02:08:06.932039: sub-r005s068, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:15.609088: predicting sub-r005s074 
2025-08-28 02:08:15.821730: sub-r005s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:25.744216: predicting sub-r005s081 
2025-08-28 02:08:25.957253: sub-r005s081, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:34.990921: predicting sub-r009s004 
2025-08-28 02:08:35.211915: sub-r009s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:45.184434: predicting sub-r009s011 
2025-08-28 02:08:45.405495: sub-r009s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:08:54.944132: predicting sub-r009s014 
2025-08-28 02:08:55.170258: sub-r009s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:04.425051: predicting sub-r009s015 
2025-08-28 02:09:04.658968: sub-r009s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:13.997404: predicting sub-r009s016 
2025-08-28 02:09:14.211326: sub-r009s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:24.448625: predicting sub-r009s017 
2025-08-28 02:09:24.667508: sub-r009s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:35.054438: predicting sub-r009s020 
2025-08-28 02:09:35.269064: sub-r009s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:45.465706: predicting sub-r009s038 
2025-08-28 02:09:45.703194: sub-r009s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:09:56.230504: predicting sub-r009s043 
2025-08-28 02:09:56.442989: sub-r009s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:05.777483: predicting sub-r009s049 
2025-08-28 02:10:06.006800: sub-r009s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:15.115869: predicting sub-r009s050 
2025-08-28 02:10:15.346625: sub-r009s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:25.592863: predicting sub-r009s054 
2025-08-28 02:10:25.859875: sub-r009s054, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:37.281401: predicting sub-r009s064 
2025-08-28 02:10:37.547275: sub-r009s064, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:48.220022: predicting sub-r009s067 
2025-08-28 02:10:48.439903: sub-r009s067, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:10:57.938044: predicting sub-r009s074 
2025-08-28 02:10:58.171426: sub-r009s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:08.673549: predicting sub-r009s078 
2025-08-28 02:11:08.915678: sub-r009s078, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:19.263262: predicting sub-r009s082 
2025-08-28 02:11:19.501034: sub-r009s082, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:29.932270: predicting sub-r009s083 
2025-08-28 02:11:30.182844: sub-r009s083, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:39.825638: predicting sub-r009s085 
2025-08-28 02:11:40.067383: sub-r009s085, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:49.856369: predicting sub-r009s087 
2025-08-28 02:11:50.110848: sub-r009s087, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:11:59.729037: predicting sub-r009s088 
2025-08-28 02:11:59.970901: sub-r009s088, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:09.859637: predicting sub-r009s089 
2025-08-28 02:12:10.109893: sub-r009s089, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:19.394125: predicting sub-r009s090 
2025-08-28 02:12:19.631875: sub-r009s090, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:29.834025: predicting sub-r009s091 
2025-08-28 02:12:30.083992: sub-r009s091, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:39.548701: predicting sub-r009s095 
2025-08-28 02:12:39.789459: sub-r009s095, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:49.290687: predicting sub-r009s098 
2025-08-28 02:12:49.532581: sub-r009s098, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:12:59.610163: predicting sub-r009s107 
2025-08-28 02:12:59.876240: sub-r009s107, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:09.344275: predicting sub-r009s115 
2025-08-28 02:13:09.586282: sub-r009s115, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:18.907990: predicting sub-r009s117 
2025-08-28 02:13:19.166323: sub-r009s117, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:29.439410: predicting sub-r010s008 
2025-08-28 02:13:29.676851: sub-r010s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:38.994489: predicting sub-r010s009 
2025-08-28 02:13:39.236356: sub-r010s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:49.751239: predicting sub-r010s010 
2025-08-28 02:13:49.976539: sub-r010s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:13:59.531631: predicting sub-r010s011 
2025-08-28 02:13:59.769797: sub-r010s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:09.687646: predicting sub-r010s027 
2025-08-28 02:14:09.927424: sub-r010s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:19.589172: predicting sub-r010s028 
2025-08-28 02:14:19.839458: sub-r010s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:30.257939: predicting sub-r011s001 
2025-08-28 02:14:30.526409: sub-r011s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:40.355968: predicting sub-r011s002 
2025-08-28 02:14:40.565219: sub-r011s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:50.912297: predicting sub-r011s024 
2025-08-28 02:14:51.156996: sub-r011s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:14:59.783429: predicting sub-r011s029 
2025-08-28 02:14:59.987751: sub-r011s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:10.108872: predicting sub-r011s032 
2025-08-28 02:15:10.344237: sub-r011s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:19.177881: predicting sub-r011s033 
2025-08-28 02:15:19.413380: sub-r011s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:29.508838: predicting sub-r014s002 
2025-08-28 02:15:29.738333: sub-r014s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:38.663911: predicting sub-r015s001 
2025-08-28 02:15:38.893330: sub-r015s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:49.311817: predicting sub-r015s025 
2025-08-28 02:15:49.528925: sub-r015s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:15:59.030104: predicting sub-r017s104 
2025-08-28 02:15:59.254368: sub-r017s104, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:08.397730: predicting sub-r017s105 
2025-08-28 02:16:08.627355: sub-r017s105, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:17.461048: predicting sub-r017s119 
2025-08-28 02:16:17.687360: sub-r017s119, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:27.141753: predicting sub-r018s010 
2025-08-28 02:16:27.362493: sub-r018s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:36.204688: predicting sub-r023s009 
2025-08-28 02:16:36.434276: sub-r023s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:46.323426: predicting sub-r023s014 
2025-08-28 02:16:46.556766: sub-r023s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:16:55.444722: predicting sub-r024s005 
2025-08-28 02:16:55.665780: sub-r024s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:05.614228: predicting sub-r024s019 
2025-08-28 02:17:05.842642: sub-r024s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:15.106276: predicting sub-r027s031 
2025-08-28 02:17:15.318795: sub-r027s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:25.474956: predicting sub-r027s032 
2025-08-28 02:17:25.695762: sub-r027s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:34.758727: predicting sub-r027s048 
2025-08-28 02:17:34.976133: sub-r027s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:44.739789: predicting sub-r028s002 
2025-08-28 02:17:44.956671: sub-r028s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:17:54.295083: predicting sub-r028s013 
2025-08-28 02:17:54.512045: sub-r028s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:03.037123: predicting sub-r029s009 
2025-08-28 02:18:03.271299: sub-r029s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:13.827493: predicting sub-r031s004 
2025-08-28 02:18:14.039876: sub-r031s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:22.561134: predicting sub-r031s005 
2025-08-28 02:18:22.790640: sub-r031s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:33.309858: predicting sub-r031s010 
2025-08-28 02:18:33.534343: sub-r031s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:41.976004: predicting sub-r031s012 
2025-08-28 02:18:42.201308: sub-r031s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:18:52.486429: predicting sub-r031s015 
2025-08-28 02:18:52.716053: sub-r031s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:01.220313: predicting sub-r031s019 
2025-08-28 02:19:01.433029: sub-r031s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:10.133682: predicting sub-r031s027 
2025-08-28 02:19:10.366913: sub-r031s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:18.984246: predicting sub-r031s035 
2025-08-28 02:19:19.221662: sub-r031s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:29.898687: predicting sub-r031s037 
2025-08-28 02:19:30.115933: sub-r031s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:38.741110: predicting sub-r034s007 
2025-08-28 02:19:38.970486: sub-r034s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:49.192830: predicting sub-r034s008 
2025-08-28 02:19:49.430950: sub-r034s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:19:58.106258: predicting sub-r034s015 
2025-08-28 02:19:58.318996: sub-r034s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:07.661648: predicting sub-r034s025 
2025-08-28 02:20:07.891327: sub-r034s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:16.608067: predicting sub-r034s048 
2025-08-28 02:20:16.833377: sub-r034s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:26.826764: predicting sub-r035s003 
2025-08-28 02:20:27.051840: sub-r035s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:35.823152: predicting sub-r038s024 
2025-08-28 02:20:36.052501: sub-r038s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:46.262946: predicting sub-r038s026 
2025-08-28 02:20:46.500421: sub-r038s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:20:55.309209: predicting sub-r038s032 
2025-08-28 02:20:55.530277: sub-r038s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:05.682335: predicting sub-r038s036 
2025-08-28 02:21:05.911504: sub-r038s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:16.205355: predicting sub-r038s049 
2025-08-28 02:21:16.426140: sub-r038s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:25.160129: predicting sub-r038s057 
2025-08-28 02:21:25.376891: sub-r038s057, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:35.427796: predicting sub-r038s071 
2025-08-28 02:21:35.682901: sub-r038s071, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:44.704278: predicting sub-r038s081 
2025-08-28 02:21:44.938315: sub-r038s081, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:21:54.739391: predicting sub-r038s097 
2025-08-28 02:21:54.964652: sub-r038s097, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:03.877625: predicting sub-r040s008 
2025-08-28 02:22:04.107253: sub-r040s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:14.250587: predicting sub-r040s017 
2025-08-28 02:22:14.492719: sub-r040s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:23.405519: predicting sub-r040s020 
2025-08-28 02:22:23.636656: sub-r040s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:32.714803: predicting sub-r040s042 
2025-08-28 02:22:32.944209: sub-r040s042, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:41.632286: predicting sub-r040s043 
2025-08-28 02:22:41.857263: sub-r040s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:22:51.879722: predicting sub-r040s045 
2025-08-28 02:22:52.113367: sub-r040s045, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:01.251920: predicting sub-r040s047 
2025-08-28 02:23:01.476858: sub-r040s047, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:11.574469: predicting sub-r040s064 
2025-08-28 02:23:11.812191: sub-r040s064, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:20.666817: predicting sub-r040s072 
2025-08-28 02:23:20.904568: sub-r040s072, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:30.980874: predicting sub-r042s003 
2025-08-28 02:23:31.227402: sub-r042s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:40.336752: predicting sub-r042s004 
2025-08-28 02:23:40.561705: sub-r042s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:23:50.917857: predicting sub-r042s025 
2025-08-28 02:23:51.147255: sub-r042s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:01.395202: predicting sub-r046s006 
2025-08-28 02:24:01.624415: sub-r046s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:11.580151: predicting sub-r046s012 
2025-08-28 02:24:11.822114: sub-r046s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:20.793529: predicting sub-r047s018 
2025-08-28 02:24:21.010492: sub-r047s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:29.752758: predicting sub-r047s050 
2025-08-28 02:24:29.977734: sub-r047s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:39.103797: predicting sub-r048s006 
2025-08-28 02:24:39.332886: sub-r048s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:24:49.221928: predicting sub-r048s015 
2025-08-28 02:24:49.459687: sub-r048s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:00.170360: predicting sub-r048s032 
2025-08-28 02:25:00.383093: sub-r048s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:10.263530: predicting sub-r048s037 
2025-08-28 02:25:10.509851: sub-r048s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:19.238823: predicting sub-r049s005 
2025-08-28 02:25:19.468783: sub-r049s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:29.616674: predicting sub-r049s024 
2025-08-28 02:25:29.845809: sub-r049s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:39.680661: predicting sub-r049s026 
2025-08-28 02:25:39.905865: sub-r049s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:49.381803: predicting sub-r050s002 
2025-08-28 02:25:49.623942: sub-r050s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:25:58.482682: predicting sub-r050s008 
2025-08-28 02:25:58.720458: sub-r050s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:08.559431: predicting sub-r050s015 
2025-08-28 02:26:08.799898: sub-r050s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:18.878105: predicting sub-r052s001 
2025-08-28 02:26:19.108231: sub-r052s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:28.145678: predicting sub-r052s014 
2025-08-28 02:26:28.383494: sub-r052s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:38.372561: predicting sub-r052s016 
2025-08-28 02:26:38.606683: sub-r052s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:47.773979: predicting sub-r052s019 
2025-08-28 02:26:48.016495: sub-r052s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:26:57.283411: predicting sub-r052s023 
2025-08-28 02:26:57.520912: sub-r052s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 02:27:22.629521: Validation complete 
2025-08-28 02:27:22.637605: Mean Validation Dice:  0.3604744868828291 
