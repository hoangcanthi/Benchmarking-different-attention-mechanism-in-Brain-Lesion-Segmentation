
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-28 07:58:50.600569: do_dummy_2d_data_aug: False 
2025-08-28 07:58:50.605151: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 07:58:50.614650: The split file contains 5 splits. 
2025-08-28 07:58:50.618764: Desired fold for training: 2 
2025-08-28 07:58:50.624311: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-28 07:58:57.595600: Unable to plot network architecture: 
2025-08-28 07:58:57.603377: No module named 'hiddenlayer' 
2025-08-28 07:58:57.649295:  
2025-08-28 07:58:57.656147: Epoch 0 
2025-08-28 07:58:57.662112: Current learning rate: 0.01 
2025-08-28 07:59:15.012656: train_loss 0.0738 
2025-08-28 07:59:15.020820: val_loss 0.0248 
2025-08-28 07:59:15.025048: Pseudo dice [np.float32(0.0)] 
2025-08-28 07:59:15.033182: Epoch time: 17.37 s 
2025-08-28 07:59:15.037957: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-28 07:59:15.734082:  
2025-08-28 07:59:15.738266: Epoch 1 
2025-08-28 07:59:15.746168: Current learning rate: 0.00999 
2025-08-28 07:59:32.004627: train_loss 0.0224 
2025-08-28 07:59:32.012757: val_loss 0.0195 
2025-08-28 07:59:32.016905: Pseudo dice [np.float32(0.0)] 
2025-08-28 07:59:32.026080: Epoch time: 16.27 s 
2025-08-28 07:59:32.721773:  
2025-08-28 07:59:32.730138: Epoch 2 
2025-08-28 07:59:32.734293: Current learning rate: 0.00998 
2025-08-28 07:59:49.421842: train_loss 0.0094 
2025-08-28 07:59:49.430159: val_loss 0.01 
2025-08-28 07:59:49.434855: Pseudo dice [np.float32(0.0)] 
2025-08-28 07:59:49.439300: Epoch time: 16.7 s 
2025-08-28 07:59:50.064497:  
2025-08-28 07:59:50.072468: Epoch 3 
2025-08-28 07:59:50.080636: Current learning rate: 0.00997 
2025-08-28 08:00:06.822845: train_loss -0.0181 
2025-08-28 08:00:06.830992: val_loss -0.0555 
2025-08-28 08:00:06.839187: Pseudo dice [np.float32(0.0)] 
2025-08-28 08:00:06.844705: Epoch time: 16.76 s 
2025-08-28 08:00:07.481528:  
2025-08-28 08:00:07.489858: Epoch 4 
2025-08-28 08:00:07.494786: Current learning rate: 0.00996 
2025-08-28 08:00:24.552756: train_loss -0.0493 
2025-08-28 08:00:24.561085: val_loss -0.0341 
2025-08-28 08:00:24.565244: Pseudo dice [np.float32(0.1677)] 
2025-08-28 08:00:24.572639: Epoch time: 17.07 s 
2025-08-28 08:00:24.578132: Yayy! New best EMA pseudo Dice: 0.01679999940097332 
2025-08-28 08:00:25.407753:  
2025-08-28 08:00:25.416128: Epoch 5 
2025-08-28 08:00:25.420290: Current learning rate: 0.00995 
2025-08-28 08:00:42.412264: train_loss -0.0277 
2025-08-28 08:00:42.420613: val_loss -0.0158 
2025-08-28 08:00:42.424771: Pseudo dice [np.float32(0.1033)] 
2025-08-28 08:00:42.428959: Epoch time: 17.0 s 
2025-08-28 08:00:42.436181: Yayy! New best EMA pseudo Dice: 0.02539999969303608 
2025-08-28 08:00:43.217226:  
2025-08-28 08:00:43.225649: Epoch 6 
2025-08-28 08:00:43.233538: Current learning rate: 0.00995 
2025-08-28 08:01:00.380246: train_loss -0.0491 
2025-08-28 08:01:00.388544: val_loss -0.0406 
2025-08-28 08:01:00.396842: Pseudo dice [np.float32(0.2127)] 
2025-08-28 08:01:00.401831: Epoch time: 17.16 s 
2025-08-28 08:01:00.405966: Yayy! New best EMA pseudo Dice: 0.04410000145435333 
2025-08-28 08:01:01.193505:  
2025-08-28 08:01:01.202194: Epoch 7 
2025-08-28 08:01:01.205994: Current learning rate: 0.00994 
2025-08-28 08:01:18.356720: train_loss -0.043 
2025-08-28 08:01:18.364781: val_loss -0.0453 
2025-08-28 08:01:18.368829: Pseudo dice [np.float32(0.1575)] 
2025-08-28 08:01:18.377644: Epoch time: 17.16 s 
2025-08-28 08:01:18.384123: Yayy! New best EMA pseudo Dice: 0.05550000071525574 
2025-08-28 08:01:19.315835:  
2025-08-28 08:01:19.324143: Epoch 8 
2025-08-28 08:01:19.332123: Current learning rate: 0.00993 
2025-08-28 08:01:36.028203: train_loss -0.0302 
2025-08-28 08:01:36.036599: val_loss -0.0382 
2025-08-28 08:01:36.044946: Pseudo dice [np.float32(0.1126)] 
2025-08-28 08:01:36.050721: Epoch time: 16.71 s 
2025-08-28 08:01:36.054778: Yayy! New best EMA pseudo Dice: 0.06120000034570694 
2025-08-28 08:01:36.866944:  
2025-08-28 08:01:36.874932: Epoch 9 
2025-08-28 08:01:36.879397: Current learning rate: 0.00992 
2025-08-28 08:01:53.492160: train_loss -0.0151 
2025-08-28 08:01:53.504034: val_loss -0.0149 
2025-08-28 08:01:53.508221: Pseudo dice [np.float32(0.0905)] 
2025-08-28 08:01:53.516658: Epoch time: 16.63 s 
2025-08-28 08:01:53.523293: Yayy! New best EMA pseudo Dice: 0.0640999972820282 
2025-08-28 08:01:54.304834:  
2025-08-28 08:01:54.313192: Epoch 10 
2025-08-28 08:01:54.317334: Current learning rate: 0.00991 
2025-08-28 08:02:10.771300: train_loss -0.0524 
2025-08-28 08:02:10.780137: val_loss -0.0602 
2025-08-28 08:02:10.788609: Pseudo dice [np.float32(0.1742)] 
2025-08-28 08:02:10.795746: Epoch time: 16.47 s 
2025-08-28 08:02:10.802119: Yayy! New best EMA pseudo Dice: 0.07509999722242355 
2025-08-28 08:02:11.597394:  
2025-08-28 08:02:11.605957: Epoch 11 
2025-08-28 08:02:11.609625: Current learning rate: 0.0099 
2025-08-28 08:02:27.946752: train_loss -0.0581 
2025-08-28 08:02:27.955116: val_loss -0.0619 
2025-08-28 08:02:27.959335: Pseudo dice [np.float32(0.1529)] 
2025-08-28 08:02:27.966561: Epoch time: 16.35 s 
2025-08-28 08:02:27.973134: Yayy! New best EMA pseudo Dice: 0.08290000259876251 
2025-08-28 08:02:28.756271:  
2025-08-28 08:02:28.764251: Epoch 12 
2025-08-28 08:02:28.768727: Current learning rate: 0.00989 
2025-08-28 08:02:45.831459: train_loss -0.0551 
2025-08-28 08:02:45.843810: val_loss -0.071 
2025-08-28 08:02:45.848230: Pseudo dice [np.float32(0.1933)] 
2025-08-28 08:02:45.855267: Epoch time: 17.08 s 
2025-08-28 08:02:45.861793: Yayy! New best EMA pseudo Dice: 0.09390000253915787 
2025-08-28 08:02:46.724195:  
2025-08-28 08:02:46.732206: Epoch 13 
2025-08-28 08:02:46.736735: Current learning rate: 0.00988 
2025-08-28 08:03:03.957960: train_loss -0.0469 
2025-08-28 08:03:03.965973: val_loss -0.0807 
2025-08-28 08:03:03.974412: Pseudo dice [np.float32(0.25)] 
2025-08-28 08:03:03.980020: Epoch time: 17.23 s 
2025-08-28 08:03:03.983642: Yayy! New best EMA pseudo Dice: 0.10949999839067459 
2025-08-28 08:03:04.783913:  
2025-08-28 08:03:04.791916: Epoch 14 
2025-08-28 08:03:04.796120: Current learning rate: 0.00987 
2025-08-28 08:03:22.326398: train_loss -0.0589 
2025-08-28 08:03:22.336531: val_loss -0.0596 
2025-08-28 08:03:22.343232: Pseudo dice [np.float32(0.1548)] 
2025-08-28 08:03:22.348299: Epoch time: 17.54 s 
2025-08-28 08:03:22.352005: Yayy! New best EMA pseudo Dice: 0.11410000175237656 
2025-08-28 08:03:23.172771:  
2025-08-28 08:03:23.181123: Epoch 15 
2025-08-28 08:03:23.185283: Current learning rate: 0.00986 
2025-08-28 08:03:39.109855: train_loss -0.084 
2025-08-28 08:03:39.117847: val_loss -0.0804 
2025-08-28 08:03:39.122330: Pseudo dice [np.float32(0.2612)] 
2025-08-28 08:03:39.130158: Epoch time: 15.94 s 
2025-08-28 08:03:39.136086: Yayy! New best EMA pseudo Dice: 0.12880000472068787 
2025-08-28 08:03:39.935362:  
2025-08-28 08:03:39.943648: Epoch 16 
2025-08-28 08:03:39.947799: Current learning rate: 0.00986 
2025-08-28 08:03:56.944006: train_loss -0.057 
2025-08-28 08:03:56.952311: val_loss -0.0725 
2025-08-28 08:03:56.956496: Pseudo dice [np.float32(0.199)] 
2025-08-28 08:03:56.964835: Epoch time: 17.01 s 
2025-08-28 08:03:56.969788: Yayy! New best EMA pseudo Dice: 0.13580000400543213 
2025-08-28 08:03:57.790691:  
2025-08-28 08:03:57.799004: Epoch 17 
2025-08-28 08:03:57.806832: Current learning rate: 0.00985 
2025-08-28 08:04:15.262604: train_loss -0.0631 
2025-08-28 08:04:15.270591: val_loss -0.0777 
2025-08-28 08:04:15.274744: Pseudo dice [np.float32(0.1933)] 
2025-08-28 08:04:15.283051: Epoch time: 17.47 s 
2025-08-28 08:04:15.288748: Yayy! New best EMA pseudo Dice: 0.14159999787807465 
2025-08-28 08:04:16.100579:  
2025-08-28 08:04:16.108926: Epoch 18 
2025-08-28 08:04:16.113088: Current learning rate: 0.00984 
2025-08-28 08:04:33.025918: train_loss -0.0556 
2025-08-28 08:04:33.034489: val_loss -0.0845 
2025-08-28 08:04:33.038614: Pseudo dice [np.float32(0.1831)] 
2025-08-28 08:04:33.045637: Epoch time: 16.93 s 
2025-08-28 08:04:33.051351: Yayy! New best EMA pseudo Dice: 0.14569999277591705 
2025-08-28 08:04:33.864152:  
2025-08-28 08:04:33.868335: Epoch 19 
2025-08-28 08:04:33.876685: Current learning rate: 0.00983 
2025-08-28 08:04:50.818608: train_loss -0.0688 
2025-08-28 08:04:50.830980: val_loss -0.0754 
2025-08-28 08:04:50.836470: Pseudo dice [np.float32(0.1923)] 
2025-08-28 08:04:50.842304: Epoch time: 16.96 s 
2025-08-28 08:04:50.848155: Yayy! New best EMA pseudo Dice: 0.15039999783039093 
2025-08-28 08:04:51.790431:  
2025-08-28 08:04:51.798967: Epoch 20 
2025-08-28 08:04:51.803293: Current learning rate: 0.00982 
2025-08-28 08:05:08.052855: train_loss -0.0872 
2025-08-28 08:05:08.060869: val_loss -0.1157 
2025-08-28 08:05:08.069209: Pseudo dice [np.float32(0.2787)] 
2025-08-28 08:05:08.075233: Epoch time: 16.26 s 
2025-08-28 08:05:08.078429: Yayy! New best EMA pseudo Dice: 0.1632000058889389 
2025-08-28 08:05:08.894978:  
2025-08-28 08:05:08.903322: Epoch 21 
2025-08-28 08:05:08.907489: Current learning rate: 0.00981 
2025-08-28 08:05:26.057953: train_loss -0.0871 
2025-08-28 08:05:26.066312: val_loss -0.0629 
2025-08-28 08:05:26.070851: Pseudo dice [np.float32(0.17)] 
2025-08-28 08:05:26.078098: Epoch time: 17.16 s 
2025-08-28 08:05:26.084547: Yayy! New best EMA pseudo Dice: 0.1639000028371811 
2025-08-28 08:05:26.871275:  
2025-08-28 08:05:26.879602: Epoch 22 
2025-08-28 08:05:26.883848: Current learning rate: 0.0098 
2025-08-28 08:05:42.711848: train_loss -0.1005 
2025-08-28 08:05:42.720438: val_loss -0.0898 
2025-08-28 08:05:42.724712: Pseudo dice [np.float32(0.2383)] 
2025-08-28 08:05:42.732060: Epoch time: 15.84 s 
2025-08-28 08:05:42.738819: Yayy! New best EMA pseudo Dice: 0.1712999939918518 
2025-08-28 08:05:43.537918:  
2025-08-28 08:05:43.546261: Epoch 23 
2025-08-28 08:05:43.554609: Current learning rate: 0.00979 
2025-08-28 08:06:00.709330: train_loss -0.0789 
2025-08-28 08:06:00.717860: val_loss -0.063 
2025-08-28 08:06:00.726220: Pseudo dice [np.float32(0.1708)] 
2025-08-28 08:06:00.730886: Epoch time: 17.17 s 
2025-08-28 08:06:01.347608:  
2025-08-28 08:06:01.356033: Epoch 24 
2025-08-28 08:06:01.360236: Current learning rate: 0.00978 
2025-08-28 08:06:18.356069: train_loss -0.0778 
2025-08-28 08:06:18.364370: val_loss -0.0855 
2025-08-28 08:06:18.368773: Pseudo dice [np.float32(0.2267)] 
2025-08-28 08:06:18.377682: Epoch time: 17.01 s 
2025-08-28 08:06:18.383579: Yayy! New best EMA pseudo Dice: 0.17679999768733978 
2025-08-28 08:06:19.256947:  
2025-08-28 08:06:19.265265: Epoch 25 
2025-08-28 08:06:19.269412: Current learning rate: 0.00977 
2025-08-28 08:06:36.758045: train_loss -0.0703 
2025-08-28 08:06:36.766073: val_loss -0.0732 
2025-08-28 08:06:36.770594: Pseudo dice [np.float32(0.1989)] 
2025-08-28 08:06:36.778775: Epoch time: 17.5 s 
2025-08-28 08:06:36.784560: Yayy! New best EMA pseudo Dice: 0.17900000512599945 
2025-08-28 08:06:37.679528:  
2025-08-28 08:06:37.683701: Epoch 26 
2025-08-28 08:06:37.687864: Current learning rate: 0.00977 
2025-08-28 08:06:54.729840: train_loss -0.0748 
2025-08-28 08:06:54.740386: val_loss -0.0714 
2025-08-28 08:06:54.746548: Pseudo dice [np.float32(0.2264)] 
2025-08-28 08:06:54.753824: Epoch time: 17.05 s 
2025-08-28 08:06:54.759487: Yayy! New best EMA pseudo Dice: 0.18379999697208405 
2025-08-28 08:06:55.781229:  
2025-08-28 08:06:55.789332: Epoch 27 
2025-08-28 08:06:55.793486: Current learning rate: 0.00976 
2025-08-28 08:07:12.898077: train_loss -0.0745 
2025-08-28 08:07:12.906598: val_loss -0.0857 
2025-08-28 08:07:12.910856: Pseudo dice [np.float32(0.1717)] 
2025-08-28 08:07:12.918728: Epoch time: 17.12 s 
2025-08-28 08:07:13.540285:  
2025-08-28 08:07:13.548682: Epoch 28 
2025-08-28 08:07:13.552820: Current learning rate: 0.00975 
2025-08-28 08:07:30.448856: train_loss -0.0937 
2025-08-28 08:07:30.457197: val_loss -0.0948 
2025-08-28 08:07:30.461362: Pseudo dice [np.float32(0.2338)] 
2025-08-28 08:07:30.468487: Epoch time: 16.91 s 
2025-08-28 08:07:30.475287: Yayy! New best EMA pseudo Dice: 0.18770000338554382 
2025-08-28 08:07:31.283068:  
2025-08-28 08:07:31.292274: Epoch 29 
2025-08-28 08:07:31.295760: Current learning rate: 0.00974 
2025-08-28 08:07:48.387585: train_loss -0.0815 
2025-08-28 08:07:48.391812: val_loss -0.105 
2025-08-28 08:07:48.400110: Pseudo dice [np.float32(0.2534)] 
2025-08-28 08:07:48.405601: Epoch time: 17.1 s 
2025-08-28 08:07:48.409328: Yayy! New best EMA pseudo Dice: 0.19429999589920044 
2025-08-28 08:07:49.213428:  
2025-08-28 08:07:49.222028: Epoch 30 
2025-08-28 08:07:49.229834: Current learning rate: 0.00973 
2025-08-28 08:08:06.151471: train_loss -0.0916 
2025-08-28 08:08:06.159796: val_loss -0.1174 
2025-08-28 08:08:06.163928: Pseudo dice [np.float32(0.213)] 
2025-08-28 08:08:06.171014: Epoch time: 16.94 s 
2025-08-28 08:08:06.176752: Yayy! New best EMA pseudo Dice: 0.19609999656677246 
2025-08-28 08:08:06.981192:  
2025-08-28 08:08:06.989520: Epoch 31 
2025-08-28 08:08:06.994073: Current learning rate: 0.00972 
2025-08-28 08:08:23.986628: train_loss -0.0935 
2025-08-28 08:08:23.994043: val_loss -0.1155 
2025-08-28 08:08:23.998195: Pseudo dice [np.float32(0.2367)] 
2025-08-28 08:08:24.005327: Epoch time: 17.01 s 
2025-08-28 08:08:24.011150: Yayy! New best EMA pseudo Dice: 0.20020000636577606 
2025-08-28 08:08:25.028368:  
2025-08-28 08:08:25.037077: Epoch 32 
2025-08-28 08:08:25.041152: Current learning rate: 0.00971 
2025-08-28 08:08:41.962455: train_loss -0.08 
2025-08-28 08:08:41.970325: val_loss -0.0926 
2025-08-28 08:08:41.979000: Pseudo dice [np.float32(0.2102)] 
2025-08-28 08:08:41.984257: Epoch time: 16.93 s 
2025-08-28 08:08:41.987911: Yayy! New best EMA pseudo Dice: 0.2011999934911728 
2025-08-28 08:08:43.008837:  
2025-08-28 08:08:43.017373: Epoch 33 
2025-08-28 08:08:43.025522: Current learning rate: 0.0097 
2025-08-28 08:08:59.638004: train_loss -0.0875 
2025-08-28 08:08:59.650510: val_loss -0.0817 
2025-08-28 08:08:59.654644: Pseudo dice [np.float32(0.2333)] 
2025-08-28 08:08:59.662797: Epoch time: 16.63 s 
2025-08-28 08:08:59.669637: Yayy! New best EMA pseudo Dice: 0.20440000295639038 
2025-08-28 08:09:00.476246:  
2025-08-28 08:09:00.484598: Epoch 34 
2025-08-28 08:09:00.488785: Current learning rate: 0.00969 
2025-08-28 08:09:16.892722: train_loss -0.072 
2025-08-28 08:09:16.901068: val_loss -0.1115 
2025-08-28 08:09:16.905443: Pseudo dice [np.float32(0.2566)] 
2025-08-28 08:09:16.912351: Epoch time: 16.42 s 
2025-08-28 08:09:16.918120: Yayy! New best EMA pseudo Dice: 0.20960000157356262 
2025-08-28 08:09:17.743878:  
2025-08-28 08:09:17.751896: Epoch 35 
2025-08-28 08:09:17.756321: Current learning rate: 0.00968 
2025-08-28 08:09:34.614838: train_loss -0.0988 
2025-08-28 08:09:34.622921: val_loss -0.1021 
2025-08-28 08:09:34.631504: Pseudo dice [np.float32(0.2776)] 
2025-08-28 08:09:34.636506: Epoch time: 16.87 s 
2025-08-28 08:09:34.640411: Yayy! New best EMA pseudo Dice: 0.21639999747276306 
2025-08-28 08:09:35.465680:  
2025-08-28 08:09:35.473976: Epoch 36 
2025-08-28 08:09:35.477882: Current learning rate: 0.00968 
2025-08-28 08:09:52.119495: train_loss -0.0853 
2025-08-28 08:09:52.127853: val_loss -0.1023 
2025-08-28 08:09:52.132047: Pseudo dice [np.float32(0.2232)] 
2025-08-28 08:09:52.141181: Epoch time: 16.65 s 
2025-08-28 08:09:52.145427: Yayy! New best EMA pseudo Dice: 0.21709999442100525 
2025-08-28 08:09:52.970344:  
2025-08-28 08:09:52.978692: Epoch 37 
2025-08-28 08:09:52.983196: Current learning rate: 0.00967 
2025-08-28 08:10:09.298549: train_loss -0.0802 
2025-08-28 08:10:09.303620: val_loss -0.0789 
2025-08-28 08:10:09.311764: Pseudo dice [np.float32(0.2805)] 
2025-08-28 08:10:09.318025: Epoch time: 16.33 s 
2025-08-28 08:10:09.324021: Yayy! New best EMA pseudo Dice: 0.22339999675750732 
2025-08-28 08:10:10.141699:  
2025-08-28 08:10:10.150046: Epoch 38 
2025-08-28 08:10:10.154433: Current learning rate: 0.00966 
2025-08-28 08:10:27.292485: train_loss -0.0746 
2025-08-28 08:10:27.300835: val_loss -0.1373 
2025-08-28 08:10:27.309242: Pseudo dice [np.float32(0.3116)] 
2025-08-28 08:10:27.315435: Epoch time: 17.15 s 
2025-08-28 08:10:27.322785: Yayy! New best EMA pseudo Dice: 0.2321999967098236 
2025-08-28 08:10:28.460362:  
2025-08-28 08:10:28.470320: Epoch 39 
2025-08-28 08:10:28.477690: Current learning rate: 0.00965 
2025-08-28 08:10:45.068620: train_loss -0.0924 
2025-08-28 08:10:45.076725: val_loss -0.1068 
2025-08-28 08:10:45.084776: Pseudo dice [np.float32(0.2801)] 
2025-08-28 08:10:45.090512: Epoch time: 16.61 s 
2025-08-28 08:10:45.097231: Yayy! New best EMA pseudo Dice: 0.2370000034570694 
2025-08-28 08:10:45.902373:  
2025-08-28 08:10:45.910736: Epoch 40 
2025-08-28 08:10:45.914817: Current learning rate: 0.00964 
2025-08-28 08:11:02.982286: train_loss -0.0915 
2025-08-28 08:11:02.994566: val_loss -0.0697 
2025-08-28 08:11:02.998974: Pseudo dice [np.float32(0.1663)] 
2025-08-28 08:11:03.006068: Epoch time: 17.08 s 
2025-08-28 08:11:03.632684:  
2025-08-28 08:11:03.640707: Epoch 41 
2025-08-28 08:11:03.645198: Current learning rate: 0.00963 
2025-08-28 08:11:20.591172: train_loss -0.0858 
2025-08-28 08:11:20.599530: val_loss -0.1417 
2025-08-28 08:11:20.603707: Pseudo dice [np.float32(0.292)] 
2025-08-28 08:11:20.613420: Epoch time: 16.96 s 
2025-08-28 08:11:21.216803:  
2025-08-28 08:11:21.221286: Epoch 42 
2025-08-28 08:11:21.229391: Current learning rate: 0.00962 
2025-08-28 08:11:38.129363: train_loss -0.1039 
2025-08-28 08:11:38.138000: val_loss -0.1086 
2025-08-28 08:11:38.142159: Pseudo dice [np.float32(0.1737)] 
2025-08-28 08:11:38.148272: Epoch time: 16.92 s 
2025-08-28 08:11:38.751010:  
2025-08-28 08:11:38.759371: Epoch 43 
2025-08-28 08:11:38.763528: Current learning rate: 0.00961 
2025-08-28 08:11:55.684185: train_loss -0.0844 
2025-08-28 08:11:55.692913: val_loss -0.0992 
2025-08-28 08:11:55.697656: Pseudo dice [np.float32(0.2478)] 
2025-08-28 08:11:55.704304: Epoch time: 16.93 s 
2025-08-28 08:11:56.314708:  
2025-08-28 08:11:56.322753: Epoch 44 
2025-08-28 08:11:56.327255: Current learning rate: 0.0096 
2025-08-28 08:12:13.227205: train_loss -0.1127 
2025-08-28 08:12:13.235708: val_loss -0.0999 
2025-08-28 08:12:13.243717: Pseudo dice [np.float32(0.2038)] 
2025-08-28 08:12:13.250064: Epoch time: 16.91 s 
2025-08-28 08:12:13.856980:  
2025-08-28 08:12:13.865307: Epoch 45 
2025-08-28 08:12:13.869786: Current learning rate: 0.00959 
2025-08-28 08:12:30.699023: train_loss -0.0901 
2025-08-28 08:12:30.707273: val_loss -0.1449 
2025-08-28 08:12:30.711215: Pseudo dice [np.float32(0.3059)] 
2025-08-28 08:12:30.719639: Epoch time: 16.84 s 
2025-08-28 08:12:31.482848:  
2025-08-28 08:12:31.487035: Epoch 46 
2025-08-28 08:12:31.495380: Current learning rate: 0.00959 
2025-08-28 08:12:48.554665: train_loss -0.0846 
2025-08-28 08:12:48.562434: val_loss -0.1353 
2025-08-28 08:12:48.566840: Pseudo dice [np.float32(0.2756)] 
2025-08-28 08:12:48.572772: Epoch time: 17.08 s 
2025-08-28 08:12:48.578905: Yayy! New best EMA pseudo Dice: 0.24050000309944153 
2025-08-28 08:12:49.371513:  
2025-08-28 08:12:49.379919: Epoch 47 
2025-08-28 08:12:49.383962: Current learning rate: 0.00958 
2025-08-28 08:13:05.725675: train_loss -0.091 
2025-08-28 08:13:05.733689: val_loss -0.0942 
2025-08-28 08:13:05.742409: Pseudo dice [np.float32(0.239)] 
2025-08-28 08:13:05.747478: Epoch time: 16.35 s 
2025-08-28 08:13:06.350971:  
2025-08-28 08:13:06.359356: Epoch 48 
2025-08-28 08:13:06.363499: Current learning rate: 0.00957 
2025-08-28 08:13:22.500804: train_loss -0.1052 
2025-08-28 08:13:22.509085: val_loss -0.1032 
2025-08-28 08:13:22.512975: Pseudo dice [np.float32(0.2106)] 
2025-08-28 08:13:22.519095: Epoch time: 16.15 s 
2025-08-28 08:13:23.122096:  
2025-08-28 08:13:23.130260: Epoch 49 
2025-08-28 08:13:23.134416: Current learning rate: 0.00956 
2025-08-28 08:13:39.021993: train_loss -0.0852 
2025-08-28 08:13:39.029428: val_loss -0.1156 
2025-08-28 08:13:39.033924: Pseudo dice [np.float32(0.3364)] 
2025-08-28 08:13:39.041688: Epoch time: 15.9 s 
2025-08-28 08:13:39.212993: Yayy! New best EMA pseudo Dice: 0.24729999899864197 
2025-08-28 08:13:40.009593:  
2025-08-28 08:13:40.017950: Epoch 50 
2025-08-28 08:13:40.022125: Current learning rate: 0.00955 
2025-08-28 08:13:57.222627: train_loss -0.0906 
2025-08-28 08:13:57.231240: val_loss -0.1558 
2025-08-28 08:13:57.238951: Pseudo dice [np.float32(0.3017)] 
2025-08-28 08:13:57.244447: Epoch time: 17.21 s 
2025-08-28 08:13:57.248455: Yayy! New best EMA pseudo Dice: 0.25270000100135803 
2025-08-28 08:13:58.044293:  
2025-08-28 08:13:58.052646: Epoch 51 
2025-08-28 08:13:58.057048: Current learning rate: 0.00954 
2025-08-28 08:14:14.538292: train_loss -0.0847 
2025-08-28 08:14:14.544383: val_loss -0.1153 
2025-08-28 08:14:14.548233: Pseudo dice [np.float32(0.2456)] 
2025-08-28 08:14:14.556659: Epoch time: 16.49 s 
2025-08-28 08:14:15.311597:  
2025-08-28 08:14:15.320166: Epoch 52 
2025-08-28 08:14:15.324027: Current learning rate: 0.00953 
2025-08-28 08:14:31.385896: train_loss -0.0991 
2025-08-28 08:14:31.393797: val_loss -0.1162 
2025-08-28 08:14:31.398410: Pseudo dice [np.float32(0.2509)] 
2025-08-28 08:14:31.404614: Epoch time: 16.07 s 
2025-08-28 08:14:32.020323:  
2025-08-28 08:14:32.028525: Epoch 53 
2025-08-28 08:14:32.032360: Current learning rate: 0.00952 
2025-08-28 08:14:48.307680: train_loss -0.1001 
2025-08-28 08:14:48.315288: val_loss -0.1472 
2025-08-28 08:14:48.319467: Pseudo dice [np.float32(0.2916)] 
2025-08-28 08:14:48.328845: Epoch time: 16.29 s 
2025-08-28 08:14:48.335461: Yayy! New best EMA pseudo Dice: 0.25589999556541443 
2025-08-28 08:14:49.128680:  
2025-08-28 08:14:49.133037: Epoch 54 
2025-08-28 08:14:49.141645: Current learning rate: 0.00951 
2025-08-28 08:15:05.515730: train_loss -0.0955 
2025-08-28 08:15:05.524495: val_loss -0.0892 
2025-08-28 08:15:05.528318: Pseudo dice [np.float32(0.2432)] 
2025-08-28 08:15:05.537435: Epoch time: 16.39 s 
2025-08-28 08:15:06.153991:  
2025-08-28 08:15:06.162220: Epoch 55 
2025-08-28 08:15:06.166760: Current learning rate: 0.0095 
2025-08-28 08:15:23.339874: train_loss -0.0858 
2025-08-28 08:15:23.348516: val_loss -0.0864 
2025-08-28 08:15:23.354476: Pseudo dice [np.float32(0.1854)] 
2025-08-28 08:15:23.359980: Epoch time: 17.19 s 
2025-08-28 08:15:23.971736:  
2025-08-28 08:15:23.975909: Epoch 56 
2025-08-28 08:15:23.980068: Current learning rate: 0.00949 
2025-08-28 08:15:40.905328: train_loss -0.0808 
2025-08-28 08:15:40.913989: val_loss -0.1162 
2025-08-28 08:15:40.918191: Pseudo dice [np.float32(0.236)] 
2025-08-28 08:15:40.924107: Epoch time: 16.94 s 
2025-08-28 08:15:41.543512:  
2025-08-28 08:15:41.551883: Epoch 57 
2025-08-28 08:15:41.556049: Current learning rate: 0.00949 
2025-08-28 08:15:58.719379: train_loss -0.0911 
2025-08-28 08:15:58.727351: val_loss -0.1055 
2025-08-28 08:15:58.731701: Pseudo dice [np.float32(0.2348)] 
2025-08-28 08:15:58.739860: Epoch time: 17.18 s 
2025-08-28 08:15:59.553391:  
2025-08-28 08:15:59.561519: Epoch 58 
2025-08-28 08:15:59.565923: Current learning rate: 0.00948 
2025-08-28 08:16:16.390981: train_loss -0.0845 
2025-08-28 08:16:16.399341: val_loss -0.1212 
2025-08-28 08:16:16.403507: Pseudo dice [np.float32(0.2689)] 
2025-08-28 08:16:16.411403: Epoch time: 16.84 s 
2025-08-28 08:16:17.028887:  
2025-08-28 08:16:17.037229: Epoch 59 
2025-08-28 08:16:17.041444: Current learning rate: 0.00947 
2025-08-28 08:16:34.070903: train_loss -0.1008 
2025-08-28 08:16:34.079255: val_loss -0.0754 
2025-08-28 08:16:34.087640: Pseudo dice [np.float32(0.2251)] 
2025-08-28 08:16:34.093369: Epoch time: 17.04 s 
2025-08-28 08:16:34.709049:  
2025-08-28 08:16:34.717419: Epoch 60 
2025-08-28 08:16:34.721572: Current learning rate: 0.00946 
2025-08-28 08:16:51.438267: train_loss -0.0887 
2025-08-28 08:16:51.450778: val_loss -0.1164 
2025-08-28 08:16:51.454984: Pseudo dice [np.float32(0.2661)] 
2025-08-28 08:16:51.462083: Epoch time: 16.73 s 
2025-08-28 08:16:52.080613:  
2025-08-28 08:16:52.088954: Epoch 61 
2025-08-28 08:16:52.093124: Current learning rate: 0.00945 
2025-08-28 08:17:09.147612: train_loss -0.1002 
2025-08-28 08:17:09.155998: val_loss -0.1559 
2025-08-28 08:17:09.160165: Pseudo dice [np.float32(0.3122)] 
2025-08-28 08:17:09.168271: Epoch time: 17.07 s 
2025-08-28 08:17:09.794123:  
2025-08-28 08:17:09.802440: Epoch 62 
2025-08-28 08:17:09.806641: Current learning rate: 0.00944 
2025-08-28 08:17:26.761043: train_loss -0.1073 
2025-08-28 08:17:26.769393: val_loss -0.1116 
2025-08-28 08:17:26.773580: Pseudo dice [np.float32(0.1765)] 
2025-08-28 08:17:26.781755: Epoch time: 16.97 s 
2025-08-28 08:17:27.403509:  
2025-08-28 08:17:27.409721: Epoch 63 
2025-08-28 08:17:27.416187: Current learning rate: 0.00943 
2025-08-28 08:17:44.257650: train_loss -0.1014 
2025-08-28 08:17:44.266056: val_loss -0.1193 
2025-08-28 08:17:44.270525: Pseudo dice [np.float32(0.1963)] 
2025-08-28 08:17:44.278625: Epoch time: 16.86 s 
2025-08-28 08:17:44.900005:  
2025-08-28 08:17:44.904053: Epoch 64 
2025-08-28 08:17:44.912493: Current learning rate: 0.00942 
2025-08-28 08:18:01.887913: train_loss -0.0747 
2025-08-28 08:18:01.900044: val_loss -0.0294 
2025-08-28 08:18:01.904460: Pseudo dice [np.float32(0.1543)] 
2025-08-28 08:18:01.911658: Epoch time: 16.99 s 
2025-08-28 08:18:02.692777:  
2025-08-28 08:18:02.701094: Epoch 65 
2025-08-28 08:18:02.705291: Current learning rate: 0.00941 
2025-08-28 08:18:19.592945: train_loss -0.0854 
2025-08-28 08:18:19.601296: val_loss -0.1176 
2025-08-28 08:18:19.605456: Pseudo dice [np.float32(0.2656)] 
2025-08-28 08:18:19.614641: Epoch time: 16.9 s 
2025-08-28 08:18:20.243638:  
2025-08-28 08:18:20.252243: Epoch 66 
2025-08-28 08:18:20.256328: Current learning rate: 0.0094 
2025-08-28 08:18:36.798023: train_loss -0.091 
2025-08-28 08:18:36.806005: val_loss -0.1132 
2025-08-28 08:18:36.814310: Pseudo dice [np.float32(0.2406)] 
2025-08-28 08:18:36.820671: Epoch time: 16.55 s 
2025-08-28 08:18:37.448309:  
2025-08-28 08:18:37.456649: Epoch 67 
2025-08-28 08:18:37.460841: Current learning rate: 0.00939 
2025-08-28 08:18:53.668666: train_loss -0.0843 
2025-08-28 08:18:53.681202: val_loss -0.1172 
2025-08-28 08:18:53.685673: Pseudo dice [np.float32(0.2661)] 
2025-08-28 08:18:53.692680: Epoch time: 16.22 s 
2025-08-28 08:18:54.327644:  
2025-08-28 08:18:54.336022: Epoch 68 
2025-08-28 08:18:54.342515: Current learning rate: 0.00939 
2025-08-28 08:19:10.677657: train_loss -0.1143 
2025-08-28 08:19:10.685986: val_loss -0.1724 
2025-08-28 08:19:10.694448: Pseudo dice [np.float32(0.3001)] 
2025-08-28 08:19:10.700342: Epoch time: 16.35 s 
2025-08-28 08:19:11.352978:  
2025-08-28 08:19:11.361333: Epoch 69 
2025-08-28 08:19:11.365726: Current learning rate: 0.00938 
2025-08-28 08:19:27.973749: train_loss -0.1004 
2025-08-28 08:19:27.982098: val_loss -0.0971 
2025-08-28 08:19:27.990583: Pseudo dice [np.float32(0.1882)] 
2025-08-28 08:19:27.996202: Epoch time: 16.62 s 
2025-08-28 08:19:28.637256:  
2025-08-28 08:19:28.645255: Epoch 70 
2025-08-28 08:19:28.649427: Current learning rate: 0.00937 
2025-08-28 08:19:45.408098: train_loss -0.1087 
2025-08-28 08:19:45.416220: val_loss -0.1632 
2025-08-28 08:19:45.424535: Pseudo dice [np.float32(0.3393)] 
2025-08-28 08:19:45.430725: Epoch time: 16.77 s 
2025-08-28 08:19:46.217026:  
2025-08-28 08:19:46.225379: Epoch 71 
2025-08-28 08:19:46.229508: Current learning rate: 0.00936 
2025-08-28 08:20:02.571537: train_loss -0.1211 
2025-08-28 08:20:02.583500: val_loss -0.1074 
2025-08-28 08:20:02.587481: Pseudo dice [np.float32(0.2601)] 
2025-08-28 08:20:02.594756: Epoch time: 16.35 s 
2025-08-28 08:20:03.230157:  
2025-08-28 08:20:03.238259: Epoch 72 
2025-08-28 08:20:03.242615: Current learning rate: 0.00935 
2025-08-28 08:20:19.275022: train_loss -0.1096 
2025-08-28 08:20:19.283386: val_loss -0.1379 
2025-08-28 08:20:19.287860: Pseudo dice [np.float32(0.3714)] 
2025-08-28 08:20:19.293792: Epoch time: 16.05 s 
2025-08-28 08:20:19.296773: Yayy! New best EMA pseudo Dice: 0.26269999146461487 
2025-08-28 08:20:20.105276:  
2025-08-28 08:20:20.113351: Epoch 73 
2025-08-28 08:20:20.117512: Current learning rate: 0.00934 
2025-08-28 08:20:35.921046: train_loss -0.1177 
2025-08-28 08:20:35.929135: val_loss -0.0811 
2025-08-28 08:20:35.933285: Pseudo dice [np.float32(0.2818)] 
2025-08-28 08:20:35.939713: Epoch time: 15.82 s 
2025-08-28 08:20:35.946375: Yayy! New best EMA pseudo Dice: 0.26460000872612 
2025-08-28 08:20:36.767744:  
2025-08-28 08:20:36.771606: Epoch 74 
2025-08-28 08:20:36.779993: Current learning rate: 0.00933 
2025-08-28 08:20:52.562555: train_loss -0.1155 
2025-08-28 08:20:52.575230: val_loss -0.1335 
2025-08-28 08:20:52.579425: Pseudo dice [np.float32(0.2032)] 
2025-08-28 08:20:52.586670: Epoch time: 15.8 s 
2025-08-28 08:20:53.217178:  
2025-08-28 08:20:53.225576: Epoch 75 
2025-08-28 08:20:53.229745: Current learning rate: 0.00932 
2025-08-28 08:21:08.991494: train_loss -0.1097 
2025-08-28 08:21:08.999966: val_loss -0.1339 
2025-08-28 08:21:09.004228: Pseudo dice [np.float32(0.3681)] 
2025-08-28 08:21:09.013768: Epoch time: 15.77 s 
2025-08-28 08:21:09.020471: Yayy! New best EMA pseudo Dice: 0.2694999873638153 
2025-08-28 08:21:09.837964:  
2025-08-28 08:21:09.845498: Epoch 76 
2025-08-28 08:21:09.850964: Current learning rate: 0.00931 
2025-08-28 08:21:25.657979: train_loss -0.1099 
2025-08-28 08:21:25.666291: val_loss -0.1369 
2025-08-28 08:21:25.674645: Pseudo dice [np.float32(0.3289)] 
2025-08-28 08:21:25.680858: Epoch time: 15.82 s 
2025-08-28 08:21:25.683877: Yayy! New best EMA pseudo Dice: 0.2754000127315521 
2025-08-28 08:21:26.682357:  
2025-08-28 08:21:26.688374: Epoch 77 
2025-08-28 08:21:26.692526: Current learning rate: 0.0093 
2025-08-28 08:21:42.304201: train_loss -0.11 
2025-08-28 08:21:42.312233: val_loss -0.0981 
2025-08-28 08:21:42.316406: Pseudo dice [np.float32(0.289)] 
2025-08-28 08:21:42.324693: Epoch time: 15.62 s 
2025-08-28 08:21:42.330491: Yayy! New best EMA pseudo Dice: 0.2768000066280365 
2025-08-28 08:21:43.142430:  
2025-08-28 08:21:43.150452: Epoch 78 
2025-08-28 08:21:43.158613: Current learning rate: 0.0093 
2025-08-28 08:21:59.917153: train_loss -0.1013 
2025-08-28 08:21:59.925857: val_loss -0.1337 
2025-08-28 08:21:59.933787: Pseudo dice [np.float32(0.2558)] 
2025-08-28 08:21:59.939378: Epoch time: 16.77 s 
2025-08-28 08:22:00.622029:  
2025-08-28 08:22:00.630404: Epoch 79 
2025-08-28 08:22:00.634551: Current learning rate: 0.00929 
2025-08-28 08:22:17.655722: train_loss -0.1262 
2025-08-28 08:22:17.664420: val_loss -0.1728 
2025-08-28 08:22:17.672712: Pseudo dice [np.float32(0.3433)] 
2025-08-28 08:22:17.678764: Epoch time: 17.04 s 
2025-08-28 08:22:17.684746: Yayy! New best EMA pseudo Dice: 0.2815000116825104 
2025-08-28 08:22:18.527737:  
2025-08-28 08:22:18.535789: Epoch 80 
2025-08-28 08:22:18.539908: Current learning rate: 0.00928 
2025-08-28 08:22:35.515701: train_loss -0.1088 
2025-08-28 08:22:35.524328: val_loss -0.1743 
2025-08-28 08:22:35.528224: Pseudo dice [np.float32(0.3235)] 
2025-08-28 08:22:35.532233: Epoch time: 16.99 s 
2025-08-28 08:22:35.541222: Yayy! New best EMA pseudo Dice: 0.2856999933719635 
2025-08-28 08:22:36.370208:  
2025-08-28 08:22:36.378585: Epoch 81 
2025-08-28 08:22:36.382743: Current learning rate: 0.00927 
2025-08-28 08:22:52.890917: train_loss -0.12 
2025-08-28 08:22:52.899228: val_loss -0.1098 
2025-08-28 08:22:52.907917: Pseudo dice [np.float32(0.2207)] 
2025-08-28 08:22:52.912685: Epoch time: 16.52 s 
2025-08-28 08:22:53.554041:  
2025-08-28 08:22:53.562398: Epoch 82 
2025-08-28 08:22:53.571523: Current learning rate: 0.00926 
2025-08-28 08:23:10.308607: train_loss -0.0909 
2025-08-28 08:23:10.316943: val_loss -0.1387 
2025-08-28 08:23:10.320791: Pseudo dice [np.float32(0.29)] 
2025-08-28 08:23:10.328968: Epoch time: 16.75 s 
2025-08-28 08:23:11.109118:  
2025-08-28 08:23:11.117473: Epoch 83 
2025-08-28 08:23:11.121634: Current learning rate: 0.00925 
2025-08-28 08:23:28.163710: train_loss -0.088 
2025-08-28 08:23:28.171967: val_loss -0.1195 
2025-08-28 08:23:28.176141: Pseudo dice [np.float32(0.2909)] 
2025-08-28 08:23:28.184562: Epoch time: 17.05 s 
2025-08-28 08:23:28.818736:  
2025-08-28 08:23:28.826820: Epoch 84 
2025-08-28 08:23:28.831336: Current learning rate: 0.00924 
2025-08-28 08:23:45.468398: train_loss -0.0755 
2025-08-28 08:23:45.476737: val_loss -0.1272 
2025-08-28 08:23:45.485102: Pseudo dice [np.float32(0.2576)] 
2025-08-28 08:23:45.490086: Epoch time: 16.65 s 
2025-08-28 08:23:46.106539:  
2025-08-28 08:23:46.110705: Epoch 85 
2025-08-28 08:23:46.119048: Current learning rate: 0.00923 
2025-08-28 08:24:02.894123: train_loss -0.1109 
2025-08-28 08:24:02.902483: val_loss -0.1331 
2025-08-28 08:24:02.910860: Pseudo dice [np.float32(0.2217)] 
2025-08-28 08:24:02.916238: Epoch time: 16.79 s 
2025-08-28 08:24:03.536484:  
2025-08-28 08:24:03.540647: Epoch 86 
2025-08-28 08:24:03.544854: Current learning rate: 0.00922 
2025-08-28 08:24:20.198929: train_loss -0.1052 
2025-08-28 08:24:20.207358: val_loss -0.1426 
2025-08-28 08:24:20.211707: Pseudo dice [np.float32(0.2941)] 
2025-08-28 08:24:20.218706: Epoch time: 16.67 s 
2025-08-28 08:24:20.837703:  
2025-08-28 08:24:20.845112: Epoch 87 
2025-08-28 08:24:20.849603: Current learning rate: 0.00921 
2025-08-28 08:24:37.762294: train_loss -0.1124 
2025-08-28 08:24:37.770676: val_loss -0.1118 
2025-08-28 08:24:37.774803: Pseudo dice [np.float32(0.2535)] 
2025-08-28 08:24:37.782200: Epoch time: 16.93 s 
2025-08-28 08:24:38.400741:  
2025-08-28 08:24:38.408767: Epoch 88 
2025-08-28 08:24:38.412929: Current learning rate: 0.0092 
2025-08-28 08:24:55.426201: train_loss -0.0945 
2025-08-28 08:24:55.438362: val_loss -0.1239 
2025-08-28 08:24:55.442452: Pseudo dice [np.float32(0.211)] 
2025-08-28 08:24:55.447899: Epoch time: 17.03 s 
2025-08-28 08:24:56.068064:  
2025-08-28 08:24:56.072280: Epoch 89 
2025-08-28 08:24:56.080586: Current learning rate: 0.0092 
2025-08-28 08:25:13.001638: train_loss -0.1264 
2025-08-28 08:25:13.010361: val_loss -0.1158 
2025-08-28 08:25:13.016363: Pseudo dice [np.float32(0.3126)] 
2025-08-28 08:25:13.023563: Epoch time: 16.94 s 
2025-08-28 08:25:13.806701:  
2025-08-28 08:25:13.815066: Epoch 90 
2025-08-28 08:25:13.819428: Current learning rate: 0.00919 
2025-08-28 08:25:30.823614: train_loss -0.106 
2025-08-28 08:25:30.832177: val_loss -0.1462 
2025-08-28 08:25:30.838756: Pseudo dice [np.float32(0.2714)] 
2025-08-28 08:25:30.845641: Epoch time: 17.02 s 
2025-08-28 08:25:31.495138:  
2025-08-28 08:25:31.503490: Epoch 91 
2025-08-28 08:25:31.507626: Current learning rate: 0.00918 
2025-08-28 08:25:48.011610: train_loss -0.1316 
2025-08-28 08:25:48.020277: val_loss -0.1528 
2025-08-28 08:25:48.028529: Pseudo dice [np.float32(0.3594)] 
2025-08-28 08:25:48.033374: Epoch time: 16.52 s 
2025-08-28 08:25:48.658381:  
2025-08-28 08:25:48.666428: Epoch 92 
2025-08-28 08:25:48.670865: Current learning rate: 0.00917 
2025-08-28 08:26:05.362329: train_loss -0.1436 
2025-08-28 08:26:05.370607: val_loss -0.1499 
2025-08-28 08:26:05.378958: Pseudo dice [np.float32(0.3478)] 
2025-08-28 08:26:05.385392: Epoch time: 16.7 s 
2025-08-28 08:26:05.391457: Yayy! New best EMA pseudo Dice: 0.28700000047683716 
2025-08-28 08:26:06.179768:  
2025-08-28 08:26:06.184131: Epoch 93 
2025-08-28 08:26:06.188113: Current learning rate: 0.00916 
2025-08-28 08:26:23.097155: train_loss -0.1292 
2025-08-28 08:26:23.104983: val_loss -0.1385 
2025-08-28 08:26:23.113368: Pseudo dice [np.float32(0.3377)] 
2025-08-28 08:26:23.118856: Epoch time: 16.92 s 
2025-08-28 08:26:23.122576: Yayy! New best EMA pseudo Dice: 0.2921000123023987 
2025-08-28 08:26:23.926632:  
2025-08-28 08:26:23.935031: Epoch 94 
2025-08-28 08:26:23.939248: Current learning rate: 0.00915 
2025-08-28 08:26:40.255787: train_loss -0.1337 
2025-08-28 08:26:40.263819: val_loss -0.137 
2025-08-28 08:26:40.268298: Pseudo dice [np.float32(0.3469)] 
2025-08-28 08:26:40.274378: Epoch time: 16.33 s 
2025-08-28 08:26:40.281102: Yayy! New best EMA pseudo Dice: 0.29760000109672546 
2025-08-28 08:26:41.081253:  
2025-08-28 08:26:41.089648: Epoch 95 
2025-08-28 08:26:41.093802: Current learning rate: 0.00914 
2025-08-28 08:26:57.535558: train_loss -0.1091 
2025-08-28 08:26:57.543624: val_loss -0.1656 
2025-08-28 08:26:57.552150: Pseudo dice [np.float32(0.3619)] 
2025-08-28 08:26:57.558278: Epoch time: 16.45 s 
2025-08-28 08:26:57.564394: Yayy! New best EMA pseudo Dice: 0.30399999022483826 
2025-08-28 08:26:58.369451:  
2025-08-28 08:26:58.377720: Epoch 96 
2025-08-28 08:26:58.381963: Current learning rate: 0.00913 
2025-08-28 08:27:14.994633: train_loss -0.1286 
2025-08-28 08:27:15.002660: val_loss -0.1652 
2025-08-28 08:27:15.010986: Pseudo dice [np.float32(0.2885)] 
2025-08-28 08:27:15.017182: Epoch time: 16.63 s 
2025-08-28 08:27:15.795113:  
2025-08-28 08:27:15.803441: Epoch 97 
2025-08-28 08:27:15.807553: Current learning rate: 0.00912 
2025-08-28 08:27:32.094816: train_loss -0.1213 
2025-08-28 08:27:32.103327: val_loss -0.15 
2025-08-28 08:27:32.107233: Pseudo dice [np.float32(0.3413)] 
2025-08-28 08:27:32.115551: Epoch time: 16.3 s 
2025-08-28 08:27:32.121282: Yayy! New best EMA pseudo Dice: 0.30640000104904175 
2025-08-28 08:27:32.924731:  
2025-08-28 08:27:32.933082: Epoch 98 
2025-08-28 08:27:32.937285: Current learning rate: 0.00911 
2025-08-28 08:27:49.345806: train_loss -0.144 
2025-08-28 08:27:49.353668: val_loss -0.1515 
2025-08-28 08:27:49.357816: Pseudo dice [np.float32(0.3471)] 
2025-08-28 08:27:49.365891: Epoch time: 16.42 s 
2025-08-28 08:27:49.371752: Yayy! New best EMA pseudo Dice: 0.31040000915527344 
2025-08-28 08:27:50.171149:  
2025-08-28 08:27:50.179505: Epoch 99 
2025-08-28 08:27:50.187813: Current learning rate: 0.0091 
2025-08-28 08:28:06.566665: train_loss -0.1361 
2025-08-28 08:28:06.574988: val_loss -0.1741 
2025-08-28 08:28:06.583504: Pseudo dice [np.float32(0.3975)] 
2025-08-28 08:28:06.588843: Epoch time: 16.4 s 
2025-08-28 08:28:06.779368: Yayy! New best EMA pseudo Dice: 0.3190999925136566 
2025-08-28 08:28:07.584331:  
2025-08-28 08:28:07.592665: Epoch 100 
2025-08-28 08:28:07.596832: Current learning rate: 0.0091 
2025-08-28 08:28:24.580877: train_loss -0.1362 
2025-08-28 08:28:24.589116: val_loss -0.1771 
2025-08-28 08:28:24.593333: Pseudo dice [np.float32(0.3469)] 
2025-08-28 08:28:24.599249: Epoch time: 17.0 s 
2025-08-28 08:28:24.605501: Yayy! New best EMA pseudo Dice: 0.32190001010894775 
2025-08-28 08:28:25.410474:  
2025-08-28 08:28:25.418796: Epoch 101 
2025-08-28 08:28:25.422983: Current learning rate: 0.00909 
2025-08-28 08:28:41.689291: train_loss -0.1668 
2025-08-28 08:28:41.701763: val_loss -0.1552 
2025-08-28 08:28:41.706510: Pseudo dice [np.float32(0.2928)] 
2025-08-28 08:28:41.714287: Epoch time: 16.28 s 
2025-08-28 08:28:42.338608:  
2025-08-28 08:28:42.348557: Epoch 102 
2025-08-28 08:28:42.352624: Current learning rate: 0.00908 
2025-08-28 08:28:58.998440: train_loss -0.1409 
2025-08-28 08:28:59.006525: val_loss -0.1722 
2025-08-28 08:28:59.015366: Pseudo dice [np.float32(0.3268)] 
2025-08-28 08:28:59.023346: Epoch time: 16.66 s 
2025-08-28 08:28:59.648864:  
2025-08-28 08:28:59.657508: Epoch 103 
2025-08-28 08:28:59.661384: Current learning rate: 0.00907 
2025-08-28 08:29:16.077842: train_loss -0.1808 
2025-08-28 08:29:16.086102: val_loss -0.1458 
2025-08-28 08:29:16.094587: Pseudo dice [np.float32(0.3575)] 
2025-08-28 08:29:16.100668: Epoch time: 16.43 s 
2025-08-28 08:29:16.106910: Yayy! New best EMA pseudo Dice: 0.32359999418258667 
2025-08-28 08:29:17.166304:  
2025-08-28 08:29:17.170384: Epoch 104 
2025-08-28 08:29:17.178841: Current learning rate: 0.00906 
2025-08-28 08:29:33.474653: train_loss -0.1671 
2025-08-28 08:29:33.482663: val_loss -0.1862 
2025-08-28 08:29:33.491246: Pseudo dice [np.float32(0.3564)] 
2025-08-28 08:29:33.496501: Epoch time: 16.31 s 
2025-08-28 08:29:33.500185: Yayy! New best EMA pseudo Dice: 0.32679998874664307 
2025-08-28 08:29:34.316813:  
2025-08-28 08:29:34.321246: Epoch 105 
2025-08-28 08:29:34.330571: Current learning rate: 0.00905 
2025-08-28 08:29:50.691178: train_loss -0.1608 
2025-08-28 08:29:50.699809: val_loss -0.2068 
2025-08-28 08:29:50.703985: Pseudo dice [np.float32(0.424)] 
2025-08-28 08:29:50.713612: Epoch time: 16.37 s 
2025-08-28 08:29:50.720665: Yayy! New best EMA pseudo Dice: 0.33660000562667847 
2025-08-28 08:29:51.550661:  
2025-08-28 08:29:51.558992: Epoch 106 
2025-08-28 08:29:51.563503: Current learning rate: 0.00904 
2025-08-28 08:30:07.870869: train_loss -0.1567 
2025-08-28 08:30:07.875300: val_loss -0.2317 
2025-08-28 08:30:07.883696: Pseudo dice [np.float32(0.408)] 
2025-08-28 08:30:07.887883: Epoch time: 16.32 s 
2025-08-28 08:30:07.892820: Yayy! New best EMA pseudo Dice: 0.34369999170303345 
2025-08-28 08:30:08.705278:  
2025-08-28 08:30:08.709710: Epoch 107 
2025-08-28 08:30:08.718130: Current learning rate: 0.00903 
2025-08-28 08:30:25.192610: train_loss -0.175 
2025-08-28 08:30:25.201292: val_loss -0.1666 
2025-08-28 08:30:25.205411: Pseudo dice [np.float32(0.3547)] 
2025-08-28 08:30:25.212397: Epoch time: 16.49 s 
2025-08-28 08:30:25.218071: Yayy! New best EMA pseudo Dice: 0.3447999954223633 
2025-08-28 08:30:26.014601:  
2025-08-28 08:30:26.022560: Epoch 108 
2025-08-28 08:30:26.027060: Current learning rate: 0.00902 
2025-08-28 08:30:42.789713: train_loss -0.1574 
2025-08-28 08:30:42.797666: val_loss -0.2387 
2025-08-28 08:30:42.806358: Pseudo dice [np.float32(0.4517)] 
2025-08-28 08:30:42.811462: Epoch time: 16.78 s 
2025-08-28 08:30:42.815293: Yayy! New best EMA pseudo Dice: 0.3555000126361847 
2025-08-28 08:30:43.627660:  
2025-08-28 08:30:43.635991: Epoch 109 
2025-08-28 08:30:43.640150: Current learning rate: 0.00901 
2025-08-28 08:31:00.722048: train_loss -0.1607 
2025-08-28 08:31:00.732239: val_loss -0.2404 
2025-08-28 08:31:00.736792: Pseudo dice [np.float32(0.4821)] 
2025-08-28 08:31:00.745684: Epoch time: 17.09 s 
2025-08-28 08:31:00.751497: Yayy! New best EMA pseudo Dice: 0.36809998750686646 
2025-08-28 08:31:01.545585:  
2025-08-28 08:31:01.553943: Epoch 110 
2025-08-28 08:31:01.558109: Current learning rate: 0.009 
2025-08-28 08:31:18.424917: train_loss -0.1866 
2025-08-28 08:31:18.433245: val_loss -0.2483 
2025-08-28 08:31:18.437718: Pseudo dice [np.float32(0.4759)] 
2025-08-28 08:31:18.445573: Epoch time: 16.88 s 
2025-08-28 08:31:18.451270: Yayy! New best EMA pseudo Dice: 0.3788999915122986 
2025-08-28 08:31:19.409222:  
2025-08-28 08:31:19.413405: Epoch 111 
2025-08-28 08:31:19.421760: Current learning rate: 0.009 
2025-08-28 08:31:35.721750: train_loss -0.1701 
2025-08-28 08:31:35.729976: val_loss -0.1619 
2025-08-28 08:31:35.738066: Pseudo dice [np.float32(0.3585)] 
2025-08-28 08:31:35.742996: Epoch time: 16.32 s 
2025-08-28 08:31:36.363644:  
2025-08-28 08:31:36.372032: Epoch 112 
2025-08-28 08:31:36.376174: Current learning rate: 0.00899 
2025-08-28 08:31:52.684466: train_loss -0.1634 
2025-08-28 08:31:52.696672: val_loss -0.2402 
2025-08-28 08:31:52.701161: Pseudo dice [np.float32(0.4932)] 
2025-08-28 08:31:52.707315: Epoch time: 16.32 s 
2025-08-28 08:31:52.714025: Yayy! New best EMA pseudo Dice: 0.38850000500679016 
2025-08-28 08:31:53.497467:  
2025-08-28 08:31:53.505816: Epoch 113 
2025-08-28 08:31:53.510126: Current learning rate: 0.00898 
2025-08-28 08:32:10.669054: train_loss -0.2005 
2025-08-28 08:32:10.677103: val_loss -0.2621 
2025-08-28 08:32:10.685406: Pseudo dice [np.float32(0.4557)] 
2025-08-28 08:32:10.691525: Epoch time: 17.17 s 
2025-08-28 08:32:10.698390: Yayy! New best EMA pseudo Dice: 0.3952000141143799 
2025-08-28 08:32:11.502901:  
2025-08-28 08:32:11.511652: Epoch 114 
2025-08-28 08:32:11.515475: Current learning rate: 0.00897 
2025-08-28 08:32:27.681583: train_loss -0.1961 
2025-08-28 08:32:27.689913: val_loss -0.1574 
2025-08-28 08:32:27.698272: Pseudo dice [np.float32(0.3343)] 
2025-08-28 08:32:27.704896: Epoch time: 16.18 s 
2025-08-28 08:32:28.328070:  
2025-08-28 08:32:28.338839: Epoch 115 
2025-08-28 08:32:28.344692: Current learning rate: 0.00896 
2025-08-28 08:32:44.623728: train_loss -0.1793 
2025-08-28 08:32:44.631825: val_loss -0.2206 
2025-08-28 08:32:44.635999: Pseudo dice [np.float32(0.3375)] 
2025-08-28 08:32:44.644363: Epoch time: 16.3 s 
2025-08-28 08:32:45.274743:  
2025-08-28 08:32:45.282510: Epoch 116 
2025-08-28 08:32:45.287015: Current learning rate: 0.00895 
2025-08-28 08:33:01.407055: train_loss -0.2044 
2025-08-28 08:33:01.415316: val_loss -0.2884 
2025-08-28 08:33:01.419442: Pseudo dice [np.float32(0.5955)] 
2025-08-28 08:33:01.427120: Epoch time: 16.13 s 
2025-08-28 08:33:01.434285: Yayy! New best EMA pseudo Dice: 0.4050999879837036 
2025-08-28 08:33:02.487180:  
2025-08-28 08:33:02.495518: Epoch 117 
2025-08-28 08:33:02.499679: Current learning rate: 0.00894 
2025-08-28 08:33:18.774015: train_loss -0.2156 
2025-08-28 08:33:18.778718: val_loss -0.2614 
2025-08-28 08:33:18.787065: Pseudo dice [np.float32(0.489)] 
2025-08-28 08:33:18.792995: Epoch time: 16.29 s 
2025-08-28 08:33:18.796134: Yayy! New best EMA pseudo Dice: 0.41350001096725464 
2025-08-28 08:33:19.625110:  
2025-08-28 08:33:19.633524: Epoch 118 
2025-08-28 08:33:19.637590: Current learning rate: 0.00893 
2025-08-28 08:33:35.741549: train_loss -0.1581 
2025-08-28 08:33:35.749565: val_loss -0.224 
2025-08-28 08:33:35.753730: Pseudo dice [np.float32(0.423)] 
2025-08-28 08:33:35.759935: Epoch time: 16.12 s 
2025-08-28 08:33:35.763028: Yayy! New best EMA pseudo Dice: 0.41449999809265137 
2025-08-28 08:33:36.583959:  
2025-08-28 08:33:36.587902: Epoch 119 
2025-08-28 08:33:36.596892: Current learning rate: 0.00892 
2025-08-28 08:33:52.708226: train_loss -0.2003 
2025-08-28 08:33:52.716963: val_loss -0.2669 
2025-08-28 08:33:52.724876: Pseudo dice [np.float32(0.5185)] 
2025-08-28 08:33:52.731067: Epoch time: 16.13 s 
2025-08-28 08:33:52.734107: Yayy! New best EMA pseudo Dice: 0.42489999532699585 
2025-08-28 08:33:53.584387:  
2025-08-28 08:33:53.592457: Epoch 120 
2025-08-28 08:33:53.596861: Current learning rate: 0.00891 
2025-08-28 08:34:10.276000: train_loss -0.1943 
2025-08-28 08:34:10.284027: val_loss -0.1629 
2025-08-28 08:34:10.288550: Pseudo dice [np.float32(0.3761)] 
2025-08-28 08:34:10.296395: Epoch time: 16.7 s 
2025-08-28 08:34:10.926992:  
2025-08-28 08:34:10.930511: Epoch 121 
2025-08-28 08:34:10.938877: Current learning rate: 0.0089 
2025-08-28 08:34:27.655608: train_loss -0.1822 
2025-08-28 08:34:27.663971: val_loss -0.2315 
2025-08-28 08:34:27.668131: Pseudo dice [np.float32(0.4539)] 
2025-08-28 08:34:27.676225: Epoch time: 16.73 s 
2025-08-28 08:34:28.310362:  
2025-08-28 08:34:28.314549: Epoch 122 
2025-08-28 08:34:28.318731: Current learning rate: 0.00889 
2025-08-28 08:34:45.507326: train_loss -0.2065 
2025-08-28 08:34:45.515441: val_loss -0.2576 
2025-08-28 08:34:45.523400: Pseudo dice [np.float32(0.5037)] 
2025-08-28 08:34:45.528935: Epoch time: 17.2 s 
2025-08-28 08:34:45.532613: Yayy! New best EMA pseudo Dice: 0.43140000104904175 
2025-08-28 08:34:46.407504:  
2025-08-28 08:34:46.411794: Epoch 123 
2025-08-28 08:34:46.420143: Current learning rate: 0.00889 
2025-08-28 08:35:02.522748: train_loss -0.1919 
2025-08-28 08:35:02.532040: val_loss -0.2431 
2025-08-28 08:35:02.540170: Pseudo dice [np.float32(0.5264)] 
2025-08-28 08:35:02.545481: Epoch time: 16.12 s 
2025-08-28 08:35:02.549632: Yayy! New best EMA pseudo Dice: 0.4408999979496002 
2025-08-28 08:35:03.545548:  
2025-08-28 08:35:03.554231: Epoch 124 
2025-08-28 08:35:03.558318: Current learning rate: 0.00888 
2025-08-28 08:35:19.578249: train_loss -0.2182 
2025-08-28 08:35:19.586585: val_loss -0.2613 
2025-08-28 08:35:19.590987: Pseudo dice [np.float32(0.5175)] 
2025-08-28 08:35:19.597967: Epoch time: 16.03 s 
2025-08-28 08:35:19.603601: Yayy! New best EMA pseudo Dice: 0.44859999418258667 
2025-08-28 08:35:20.433340:  
2025-08-28 08:35:20.441616: Epoch 125 
2025-08-28 08:35:20.449672: Current learning rate: 0.00887 
2025-08-28 08:35:36.582715: train_loss -0.2158 
2025-08-28 08:35:36.591414: val_loss -0.2001 
2025-08-28 08:35:36.599727: Pseudo dice [np.float32(0.4374)] 
2025-08-28 08:35:36.604390: Epoch time: 16.15 s 
2025-08-28 08:35:37.237543:  
2025-08-28 08:35:37.245939: Epoch 126 
2025-08-28 08:35:37.250353: Current learning rate: 0.00886 
2025-08-28 08:35:53.528928: train_loss -0.193 
2025-08-28 08:35:53.541343: val_loss -0.2355 
2025-08-28 08:35:53.545765: Pseudo dice [np.float32(0.4647)] 
2025-08-28 08:35:53.555974: Epoch time: 16.29 s 
2025-08-28 08:35:53.565399: Yayy! New best EMA pseudo Dice: 0.44920000433921814 
2025-08-28 08:35:54.413056:  
2025-08-28 08:35:54.421398: Epoch 127 
2025-08-28 08:35:54.425530: Current learning rate: 0.00885 
2025-08-28 08:36:10.062006: train_loss -0.2031 
2025-08-28 08:36:10.070345: val_loss -0.1707 
2025-08-28 08:36:10.074499: Pseudo dice [np.float32(0.2795)] 
2025-08-28 08:36:10.082664: Epoch time: 15.65 s 
2025-08-28 08:36:10.720981:  
2025-08-28 08:36:10.729592: Epoch 128 
2025-08-28 08:36:10.733570: Current learning rate: 0.00884 
2025-08-28 08:36:26.491809: train_loss -0.1745 
2025-08-28 08:36:26.499275: val_loss -0.2277 
2025-08-28 08:36:26.507941: Pseudo dice [np.float32(0.4904)] 
2025-08-28 08:36:26.513367: Epoch time: 15.77 s 
2025-08-28 08:36:27.149893:  
2025-08-28 08:36:27.158255: Epoch 129 
2025-08-28 08:36:27.162430: Current learning rate: 0.00883 
2025-08-28 08:36:43.091208: train_loss -0.204 
2025-08-28 08:36:43.099252: val_loss -0.2071 
2025-08-28 08:36:43.103401: Pseudo dice [np.float32(0.4901)] 
2025-08-28 08:36:43.112554: Epoch time: 15.94 s 
2025-08-28 08:36:43.891687:  
2025-08-28 08:36:43.900283: Epoch 130 
2025-08-28 08:36:43.904146: Current learning rate: 0.00882 
2025-08-28 08:36:59.573967: train_loss -0.2195 
2025-08-28 08:36:59.582629: val_loss -0.1871 
2025-08-28 08:36:59.591026: Pseudo dice [np.float32(0.4162)] 
2025-08-28 08:36:59.596940: Epoch time: 15.68 s 
2025-08-28 08:37:00.232968:  
2025-08-28 08:37:00.241267: Epoch 131 
2025-08-28 08:37:00.245463: Current learning rate: 0.00881 
2025-08-28 08:37:15.994531: train_loss -0.224 
2025-08-28 08:37:16.002840: val_loss -0.2135 
2025-08-28 08:37:16.007249: Pseudo dice [np.float32(0.3949)] 
2025-08-28 08:37:16.014540: Epoch time: 15.76 s 
2025-08-28 08:37:16.653568:  
2025-08-28 08:37:16.661863: Epoch 132 
2025-08-28 08:37:16.666250: Current learning rate: 0.0088 
2025-08-28 08:37:32.320200: train_loss -0.2252 
2025-08-28 08:37:32.327735: val_loss -0.2831 
2025-08-28 08:37:32.335844: Pseudo dice [np.float32(0.5513)] 
2025-08-28 08:37:32.341694: Epoch time: 15.67 s 
2025-08-28 08:37:32.974003:  
2025-08-28 08:37:32.982638: Epoch 133 
2025-08-28 08:37:32.986589: Current learning rate: 0.00879 
2025-08-28 08:37:48.845821: train_loss -0.2176 
2025-08-28 08:37:48.852624: val_loss -0.2716 
2025-08-28 08:37:48.856726: Pseudo dice [np.float32(0.5017)] 
2025-08-28 08:37:48.865576: Epoch time: 15.87 s 
2025-08-28 08:37:48.869982: Yayy! New best EMA pseudo Dice: 0.4528999924659729 
2025-08-28 08:37:49.690684:  
2025-08-28 08:37:49.699078: Epoch 134 
2025-08-28 08:37:49.703211: Current learning rate: 0.00879 
2025-08-28 08:38:05.294725: train_loss -0.2368 
2025-08-28 08:38:05.306251: val_loss -0.2413 
2025-08-28 08:38:05.310424: Pseudo dice [np.float32(0.5317)] 
2025-08-28 08:38:05.317641: Epoch time: 15.6 s 
2025-08-28 08:38:05.323292: Yayy! New best EMA pseudo Dice: 0.4607999920845032 
2025-08-28 08:38:06.232179:  
2025-08-28 08:38:06.240543: Epoch 135 
2025-08-28 08:38:06.244662: Current learning rate: 0.00878 
2025-08-28 08:38:22.081526: train_loss -0.1935 
2025-08-28 08:38:22.089755: val_loss -0.2607 
2025-08-28 08:38:22.093760: Pseudo dice [np.float32(0.5476)] 
2025-08-28 08:38:22.102981: Epoch time: 15.85 s 
2025-08-28 08:38:22.107186: Yayy! New best EMA pseudo Dice: 0.46950000524520874 
2025-08-28 08:38:23.111659:  
2025-08-28 08:38:23.119871: Epoch 136 
2025-08-28 08:38:23.127798: Current learning rate: 0.00877 
2025-08-28 08:38:38.789557: train_loss -0.2114 
2025-08-28 08:38:38.797865: val_loss -0.2289 
2025-08-28 08:38:38.802257: Pseudo dice [np.float32(0.4678)] 
2025-08-28 08:38:38.808526: Epoch time: 15.68 s 
2025-08-28 08:38:39.449085:  
2025-08-28 08:38:39.457380: Epoch 137 
2025-08-28 08:38:39.461187: Current learning rate: 0.00876 
2025-08-28 08:38:56.432325: train_loss -0.1669 
2025-08-28 08:38:56.440632: val_loss -0.2079 
2025-08-28 08:38:56.449009: Pseudo dice [np.float32(0.4134)] 
2025-08-28 08:38:56.455313: Epoch time: 16.98 s 
2025-08-28 08:38:57.095548:  
2025-08-28 08:38:57.103845: Epoch 138 
2025-08-28 08:38:57.108019: Current learning rate: 0.00875 
2025-08-28 08:39:14.321330: train_loss -0.1731 
2025-08-28 08:39:14.329453: val_loss -0.239 
2025-08-28 08:39:14.335665: Pseudo dice [np.float32(0.5241)] 
2025-08-28 08:39:14.343179: Epoch time: 17.23 s 
2025-08-28 08:39:14.346996: Yayy! New best EMA pseudo Dice: 0.4697999954223633 
2025-08-28 08:39:15.176336:  
2025-08-28 08:39:15.184366: Epoch 139 
2025-08-28 08:39:15.188869: Current learning rate: 0.00874 
2025-08-28 08:39:31.546540: train_loss -0.2283 
2025-08-28 08:39:31.554880: val_loss -0.3073 
2025-08-28 08:39:31.559034: Pseudo dice [np.float32(0.5949)] 
2025-08-28 08:39:31.567392: Epoch time: 16.37 s 
2025-08-28 08:39:31.572364: Yayy! New best EMA pseudo Dice: 0.4823000133037567 
2025-08-28 08:39:32.393209:  
2025-08-28 08:39:32.397726: Epoch 140 
2025-08-28 08:39:32.405956: Current learning rate: 0.00873 
2025-08-28 08:39:49.164121: train_loss -0.221 
2025-08-28 08:39:49.172507: val_loss -0.3106 
2025-08-28 08:39:49.176995: Pseudo dice [np.float32(0.6333)] 
2025-08-28 08:39:49.183976: Epoch time: 16.78 s 
2025-08-28 08:39:49.189845: Yayy! New best EMA pseudo Dice: 0.4973999857902527 
2025-08-28 08:39:50.081980:  
2025-08-28 08:39:50.090393: Epoch 141 
2025-08-28 08:39:50.098431: Current learning rate: 0.00872 
2025-08-28 08:40:06.992647: train_loss -0.2475 
2025-08-28 08:40:06.998621: val_loss -0.3124 
2025-08-28 08:40:07.007027: Pseudo dice [np.float32(0.5938)] 
2025-08-28 08:40:07.011965: Epoch time: 16.91 s 
2025-08-28 08:40:07.016135: Yayy! New best EMA pseudo Dice: 0.5070000290870667 
2025-08-28 08:40:08.033352:  
2025-08-28 08:40:08.041327: Epoch 142 
2025-08-28 08:40:08.049544: Current learning rate: 0.00871 
2025-08-28 08:40:24.741686: train_loss -0.2634 
2025-08-28 08:40:24.750023: val_loss -0.3005 
2025-08-28 08:40:24.753861: Pseudo dice [np.float32(0.6093)] 
2025-08-28 08:40:24.760385: Epoch time: 16.71 s 
2025-08-28 08:40:24.766893: Yayy! New best EMA pseudo Dice: 0.5171999931335449 
2025-08-28 08:40:25.592156:  
2025-08-28 08:40:25.596628: Epoch 143 
2025-08-28 08:40:25.604724: Current learning rate: 0.0087 
2025-08-28 08:40:42.705435: train_loss -0.2331 
2025-08-28 08:40:42.713437: val_loss -0.2718 
2025-08-28 08:40:42.717914: Pseudo dice [np.float32(0.4722)] 
2025-08-28 08:40:42.725879: Epoch time: 17.12 s 
2025-08-28 08:40:43.368308:  
2025-08-28 08:40:43.377100: Epoch 144 
2025-08-28 08:40:43.380753: Current learning rate: 0.00869 
2025-08-28 08:41:00.218676: train_loss -0.2418 
2025-08-28 08:41:00.230958: val_loss -0.1988 
2025-08-28 08:41:00.235112: Pseudo dice [np.float32(0.428)] 
2025-08-28 08:41:00.242565: Epoch time: 16.85 s 
2025-08-28 08:41:00.877405:  
2025-08-28 08:41:00.881623: Epoch 145 
2025-08-28 08:41:00.889959: Current learning rate: 0.00868 
2025-08-28 08:41:17.994488: train_loss -0.2184 
2025-08-28 08:41:18.003078: val_loss -0.2774 
2025-08-28 08:41:18.007299: Pseudo dice [np.float32(0.4613)] 
2025-08-28 08:41:18.014479: Epoch time: 17.12 s 
2025-08-28 08:41:18.657651:  
2025-08-28 08:41:18.661839: Epoch 146 
2025-08-28 08:41:18.670181: Current learning rate: 0.00868 
2025-08-28 08:41:35.791498: train_loss -0.2519 
2025-08-28 08:41:35.800128: val_loss -0.2603 
2025-08-28 08:41:35.806223: Pseudo dice [np.float32(0.5088)] 
2025-08-28 08:41:35.812325: Epoch time: 17.14 s 
2025-08-28 08:41:36.446258:  
2025-08-28 08:41:36.454662: Epoch 147 
2025-08-28 08:41:36.458784: Current learning rate: 0.00867 
2025-08-28 08:41:53.784102: train_loss -0.2165 
2025-08-28 08:41:53.793044: val_loss -0.2401 
2025-08-28 08:41:53.796993: Pseudo dice [np.float32(0.4116)] 
2025-08-28 08:41:53.806233: Epoch time: 17.34 s 
2025-08-28 08:41:54.585526:  
2025-08-28 08:41:54.593820: Epoch 148 
2025-08-28 08:41:54.598008: Current learning rate: 0.00866 
2025-08-28 08:42:11.301801: train_loss -0.2106 
2025-08-28 08:42:11.310273: val_loss -0.2624 
2025-08-28 08:42:11.314426: Pseudo dice [np.float32(0.5005)] 
2025-08-28 08:42:11.321611: Epoch time: 16.72 s 
2025-08-28 08:42:11.965046:  
2025-08-28 08:42:11.969982: Epoch 149 
2025-08-28 08:42:11.973387: Current learning rate: 0.00865 
2025-08-28 08:42:28.940769: train_loss -0.2468 
2025-08-28 08:42:28.948697: val_loss -0.2382 
2025-08-28 08:42:28.957406: Pseudo dice [np.float32(0.5473)] 
2025-08-28 08:42:28.962450: Epoch time: 16.98 s 
2025-08-28 08:42:29.787029:  
2025-08-28 08:42:29.795367: Epoch 150 
2025-08-28 08:42:29.799533: Current learning rate: 0.00864 
2025-08-28 08:42:45.923989: train_loss -0.2261 
2025-08-28 08:42:45.932321: val_loss -0.2738 
2025-08-28 08:42:45.936442: Pseudo dice [np.float32(0.5918)] 
2025-08-28 08:42:45.942485: Epoch time: 16.14 s 
2025-08-28 08:42:46.587222:  
2025-08-28 08:42:46.595581: Epoch 151 
2025-08-28 08:42:46.599809: Current learning rate: 0.00863 
2025-08-28 08:43:02.315694: train_loss -0.2228 
2025-08-28 08:43:02.328032: val_loss -0.317 
2025-08-28 08:43:02.333292: Pseudo dice [np.float32(0.5291)] 
2025-08-28 08:43:02.338056: Epoch time: 15.73 s 
2025-08-28 08:43:02.983093:  
2025-08-28 08:43:02.991060: Epoch 152 
2025-08-28 08:43:02.995512: Current learning rate: 0.00862 
2025-08-28 08:43:18.665272: train_loss -0.2365 
2025-08-28 08:43:18.673449: val_loss -0.3037 
2025-08-28 08:43:18.677795: Pseudo dice [np.float32(0.5472)] 
2025-08-28 08:43:18.686808: Epoch time: 15.68 s 
2025-08-28 08:43:19.338957:  
2025-08-28 08:43:19.345201: Epoch 153 
2025-08-28 08:43:19.349321: Current learning rate: 0.00861 
2025-08-28 08:43:36.003601: train_loss -0.2414 
2025-08-28 08:43:36.011796: val_loss -0.2761 
2025-08-28 08:43:36.020119: Pseudo dice [np.float32(0.5198)] 
2025-08-28 08:43:36.025382: Epoch time: 16.67 s 
2025-08-28 08:43:36.679161:  
2025-08-28 08:43:36.686903: Epoch 154 
2025-08-28 08:43:36.691442: Current learning rate: 0.0086 
2025-08-28 08:43:53.641596: train_loss -0.2374 
2025-08-28 08:43:53.650231: val_loss -0.2619 
2025-08-28 08:43:53.657971: Pseudo dice [np.float32(0.4997)] 
2025-08-28 08:43:53.662702: Epoch time: 16.97 s 
2025-08-28 08:43:54.304763:  
2025-08-28 08:43:54.313145: Epoch 155 
2025-08-28 08:43:54.317259: Current learning rate: 0.00859 
2025-08-28 08:44:10.704479: train_loss -0.2258 
2025-08-28 08:44:10.712850: val_loss -0.3046 
2025-08-28 08:44:10.717417: Pseudo dice [np.float32(0.6017)] 
2025-08-28 08:44:10.725927: Epoch time: 16.4 s 
2025-08-28 08:44:10.732074: Yayy! New best EMA pseudo Dice: 0.5216000080108643 
2025-08-28 08:44:11.567948:  
2025-08-28 08:44:11.576355: Epoch 156 
2025-08-28 08:44:11.580608: Current learning rate: 0.00858 
2025-08-28 08:44:27.296134: train_loss -0.2397 
2025-08-28 08:44:27.304383: val_loss -0.2702 
2025-08-28 08:44:27.308592: Pseudo dice [np.float32(0.4618)] 
2025-08-28 08:44:27.316016: Epoch time: 15.73 s 
2025-08-28 08:44:27.967533:  
2025-08-28 08:44:27.975934: Epoch 157 
2025-08-28 08:44:27.980077: Current learning rate: 0.00858 
2025-08-28 08:44:44.871929: train_loss -0.2514 
2025-08-28 08:44:44.880277: val_loss -0.2301 
2025-08-28 08:44:44.884303: Pseudo dice [np.float32(0.4583)] 
2025-08-28 08:44:44.892872: Epoch time: 16.9 s 
2025-08-28 08:44:45.547597:  
2025-08-28 08:44:45.555988: Epoch 158 
2025-08-28 08:44:45.561118: Current learning rate: 0.00857 
2025-08-28 08:45:02.273016: train_loss -0.238 
2025-08-28 08:45:02.281029: val_loss -0.3128 
2025-08-28 08:45:02.289319: Pseudo dice [np.float32(0.522)] 
2025-08-28 08:45:02.295507: Epoch time: 16.73 s 
2025-08-28 08:45:02.952505:  
2025-08-28 08:45:02.956664: Epoch 159 
2025-08-28 08:45:02.960809: Current learning rate: 0.00856 
2025-08-28 08:45:19.373037: train_loss -0.2352 
2025-08-28 08:45:19.381416: val_loss -0.3124 
2025-08-28 08:45:19.385592: Pseudo dice [np.float32(0.6035)] 
2025-08-28 08:45:19.391509: Epoch time: 16.42 s 
2025-08-28 08:45:20.044629:  
2025-08-28 08:45:20.053000: Epoch 160 
2025-08-28 08:45:20.057179: Current learning rate: 0.00855 
2025-08-28 08:45:36.932243: train_loss -0.2546 
2025-08-28 08:45:36.940580: val_loss -0.3203 
2025-08-28 08:45:36.949250: Pseudo dice [np.float32(0.6357)] 
2025-08-28 08:45:36.955287: Epoch time: 16.89 s 
2025-08-28 08:45:36.958119: Yayy! New best EMA pseudo Dice: 0.5318999886512756 
2025-08-28 08:45:38.037511:  
2025-08-28 08:45:38.041720: Epoch 161 
2025-08-28 08:45:38.049707: Current learning rate: 0.00854 
2025-08-28 08:45:54.608757: train_loss -0.257 
2025-08-28 08:45:54.620790: val_loss -0.2955 
2025-08-28 08:45:54.625257: Pseudo dice [np.float32(0.5382)] 
2025-08-28 08:45:54.631341: Epoch time: 16.58 s 
2025-08-28 08:45:54.637446: Yayy! New best EMA pseudo Dice: 0.5325000286102295 
2025-08-28 08:45:55.471630:  
2025-08-28 08:45:55.479959: Epoch 162 
2025-08-28 08:45:55.484070: Current learning rate: 0.00853 
2025-08-28 08:46:12.530731: train_loss -0.2663 
2025-08-28 08:46:12.538651: val_loss -0.3287 
2025-08-28 08:46:12.547018: Pseudo dice [np.float32(0.6146)] 
2025-08-28 08:46:12.552016: Epoch time: 17.06 s 
2025-08-28 08:46:12.556240: Yayy! New best EMA pseudo Dice: 0.5407000184059143 
2025-08-28 08:46:13.402040:  
2025-08-28 08:46:13.410418: Epoch 163 
2025-08-28 08:46:13.414533: Current learning rate: 0.00852 
2025-08-28 08:46:29.974649: train_loss -0.2694 
2025-08-28 08:46:29.981062: val_loss -0.2909 
2025-08-28 08:46:29.989424: Pseudo dice [np.float32(0.5303)] 
2025-08-28 08:46:29.995617: Epoch time: 16.57 s 
2025-08-28 08:46:30.657000:  
2025-08-28 08:46:30.665148: Epoch 164 
2025-08-28 08:46:30.669545: Current learning rate: 0.00851 
2025-08-28 08:46:47.615319: train_loss -0.2361 
2025-08-28 08:46:47.627928: val_loss -0.2987 
2025-08-28 08:46:47.632287: Pseudo dice [np.float32(0.5914)] 
2025-08-28 08:46:47.640169: Epoch time: 16.96 s 
2025-08-28 08:46:47.647087: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-08-28 08:46:48.466199:  
2025-08-28 08:46:48.474534: Epoch 165 
2025-08-28 08:46:48.478689: Current learning rate: 0.0085 
2025-08-28 08:47:05.082809: train_loss -0.2511 
2025-08-28 08:47:05.095438: val_loss -0.3014 
2025-08-28 08:47:05.099463: Pseudo dice [np.float32(0.5189)] 
2025-08-28 08:47:05.106827: Epoch time: 16.62 s 
2025-08-28 08:47:05.896146:  
2025-08-28 08:47:05.904715: Epoch 166 
2025-08-28 08:47:05.912487: Current learning rate: 0.00849 
2025-08-28 08:47:22.839509: train_loss -0.2376 
2025-08-28 08:47:22.846757: val_loss -0.2888 
2025-08-28 08:47:22.850554: Pseudo dice [np.float32(0.5795)] 
2025-08-28 08:47:22.857819: Epoch time: 16.94 s 
2025-08-28 08:47:22.863522: Yayy! New best EMA pseudo Dice: 0.5460000038146973 
2025-08-28 08:47:23.689162:  
2025-08-28 08:47:23.697226: Epoch 167 
2025-08-28 08:47:23.701801: Current learning rate: 0.00848 
2025-08-28 08:47:39.980128: train_loss -0.2347 
2025-08-28 08:47:39.988503: val_loss -0.2819 
2025-08-28 08:47:39.992887: Pseudo dice [np.float32(0.4724)] 
2025-08-28 08:47:39.999809: Epoch time: 16.29 s 
2025-08-28 08:47:40.660289:  
2025-08-28 08:47:40.668373: Epoch 168 
2025-08-28 08:47:40.672862: Current learning rate: 0.00847 
2025-08-28 08:47:56.776223: train_loss -0.2337 
2025-08-28 08:47:56.788772: val_loss -0.2529 
2025-08-28 08:47:56.792747: Pseudo dice [np.float32(0.4517)] 
2025-08-28 08:47:56.802096: Epoch time: 16.12 s 
2025-08-28 08:47:57.497611:  
2025-08-28 08:47:57.506256: Epoch 169 
2025-08-28 08:47:57.510145: Current learning rate: 0.00847 
2025-08-28 08:48:13.905784: train_loss -0.2521 
2025-08-28 08:48:13.914020: val_loss -0.2953 
2025-08-28 08:48:13.918563: Pseudo dice [np.float32(0.5465)] 
2025-08-28 08:48:13.924768: Epoch time: 16.41 s 
2025-08-28 08:48:14.581394:  
2025-08-28 08:48:14.585710: Epoch 170 
2025-08-28 08:48:14.589705: Current learning rate: 0.00846 
2025-08-28 08:48:30.718329: train_loss -0.2466 
2025-08-28 08:48:30.727049: val_loss -0.2758 
2025-08-28 08:48:30.731159: Pseudo dice [np.float32(0.4795)] 
2025-08-28 08:48:30.737160: Epoch time: 16.14 s 
2025-08-28 08:48:31.398563:  
2025-08-28 08:48:31.406499: Epoch 171 
2025-08-28 08:48:31.410699: Current learning rate: 0.00845 
2025-08-28 08:48:48.098546: train_loss -0.2471 
2025-08-28 08:48:48.106499: val_loss -0.2247 
2025-08-28 08:48:48.111004: Pseudo dice [np.float32(0.5412)] 
2025-08-28 08:48:48.118849: Epoch time: 16.7 s 
2025-08-28 08:48:48.765495:  
2025-08-28 08:48:48.774149: Epoch 172 
2025-08-28 08:48:48.778093: Current learning rate: 0.00844 
2025-08-28 08:49:05.352986: train_loss -0.2827 
2025-08-28 08:49:05.365447: val_loss -0.2988 
2025-08-28 08:49:05.369600: Pseudo dice [np.float32(0.5614)] 
2025-08-28 08:49:05.376973: Epoch time: 16.59 s 
2025-08-28 08:49:06.199568:  
2025-08-28 08:49:06.207928: Epoch 173 
2025-08-28 08:49:06.212106: Current learning rate: 0.00843 
2025-08-28 08:49:23.179012: train_loss -0.2202 
2025-08-28 08:49:23.187379: val_loss -0.2817 
2025-08-28 08:49:23.195761: Pseudo dice [np.float32(0.5824)] 
2025-08-28 08:49:23.200656: Epoch time: 16.98 s 
2025-08-28 08:49:23.854799:  
2025-08-28 08:49:23.863050: Epoch 174 
2025-08-28 08:49:23.867260: Current learning rate: 0.00842 
2025-08-28 08:49:40.746853: train_loss -0.267 
2025-08-28 08:49:40.754970: val_loss -0.3561 
2025-08-28 08:49:40.759132: Pseudo dice [np.float32(0.5946)] 
2025-08-28 08:49:40.768370: Epoch time: 16.89 s 
2025-08-28 08:49:41.532713:  
2025-08-28 08:49:41.541039: Epoch 175 
2025-08-28 08:49:41.547178: Current learning rate: 0.00841 
2025-08-28 08:49:58.377172: train_loss -0.2739 
2025-08-28 08:49:58.389499: val_loss -0.2657 
2025-08-28 08:49:58.393359: Pseudo dice [np.float32(0.4871)] 
2025-08-28 08:49:58.401906: Epoch time: 16.85 s 
2025-08-28 08:49:59.035656:  
2025-08-28 08:49:59.044025: Epoch 176 
2025-08-28 08:49:59.048172: Current learning rate: 0.0084 
2025-08-28 08:50:15.965601: train_loss -0.242 
2025-08-28 08:50:15.973420: val_loss -0.2326 
2025-08-28 08:50:15.977626: Pseudo dice [np.float32(0.4796)] 
2025-08-28 08:50:15.985799: Epoch time: 16.93 s 
2025-08-28 08:50:16.661609:  
2025-08-28 08:50:16.669951: Epoch 177 
2025-08-28 08:50:16.674469: Current learning rate: 0.00839 
2025-08-28 08:50:33.370224: train_loss -0.2919 
2025-08-28 08:50:33.378253: val_loss -0.3259 
2025-08-28 08:50:33.386664: Pseudo dice [np.float32(0.6124)] 
2025-08-28 08:50:33.392863: Epoch time: 16.71 s 
2025-08-28 08:50:34.024782:  
2025-08-28 08:50:34.033141: Epoch 178 
2025-08-28 08:50:34.037298: Current learning rate: 0.00838 
2025-08-28 08:50:50.862715: train_loss -0.2593 
2025-08-28 08:50:50.874975: val_loss -0.3125 
2025-08-28 08:50:50.879113: Pseudo dice [np.float32(0.5923)] 
2025-08-28 08:50:50.885976: Epoch time: 16.84 s 
2025-08-28 08:50:51.688530:  
2025-08-28 08:50:51.696718: Epoch 179 
2025-08-28 08:50:51.700771: Current learning rate: 0.00837 
2025-08-28 08:51:08.363506: train_loss -0.252 
2025-08-28 08:51:08.371578: val_loss -0.3284 
2025-08-28 08:51:08.380296: Pseudo dice [np.float32(0.5511)] 
2025-08-28 08:51:08.385290: Epoch time: 16.68 s 
2025-08-28 08:51:09.030846:  
2025-08-28 08:51:09.034751: Epoch 180 
2025-08-28 08:51:09.043098: Current learning rate: 0.00836 
2025-08-28 08:51:25.467819: train_loss -0.251 
2025-08-28 08:51:25.471996: val_loss -0.2721 
2025-08-28 08:51:25.480961: Pseudo dice [np.float32(0.4923)] 
2025-08-28 08:51:25.485881: Epoch time: 16.44 s 
2025-08-28 08:51:26.118506:  
2025-08-28 08:51:26.126858: Epoch 181 
2025-08-28 08:51:26.130982: Current learning rate: 0.00836 
2025-08-28 08:51:42.947824: train_loss -0.2448 
2025-08-28 08:51:42.956421: val_loss -0.2766 
2025-08-28 08:51:42.960354: Pseudo dice [np.float32(0.4265)] 
2025-08-28 08:51:42.968587: Epoch time: 16.83 s 
2025-08-28 08:51:43.598409:  
2025-08-28 08:51:43.606775: Epoch 182 
2025-08-28 08:51:43.610928: Current learning rate: 0.00835 
2025-08-28 08:52:00.494456: train_loss -0.2522 
2025-08-28 08:52:00.506978: val_loss -0.2608 
2025-08-28 08:52:00.511145: Pseudo dice [np.float32(0.4733)] 
2025-08-28 08:52:00.517538: Epoch time: 16.9 s 
2025-08-28 08:52:01.157613:  
2025-08-28 08:52:01.161831: Epoch 183 
2025-08-28 08:52:01.165972: Current learning rate: 0.00834 
2025-08-28 08:52:17.866259: train_loss -0.2556 
2025-08-28 08:52:17.874636: val_loss -0.3445 
2025-08-28 08:52:17.878873: Pseudo dice [np.float32(0.6143)] 
2025-08-28 08:52:17.886062: Epoch time: 16.71 s 
2025-08-28 08:52:18.524950:  
2025-08-28 08:52:18.529107: Epoch 184 
2025-08-28 08:52:18.537551: Current learning rate: 0.00833 
2025-08-28 08:52:35.630169: train_loss -0.2451 
2025-08-28 08:52:35.637935: val_loss -0.2701 
2025-08-28 08:52:35.642075: Pseudo dice [np.float32(0.5185)] 
2025-08-28 08:52:35.651284: Epoch time: 17.11 s 
2025-08-28 08:52:36.438675:  
2025-08-28 08:52:36.447047: Epoch 185 
2025-08-28 08:52:36.451208: Current learning rate: 0.00832 
2025-08-28 08:52:53.080298: train_loss -0.26 
2025-08-28 08:52:53.088650: val_loss -0.3236 
2025-08-28 08:52:53.097037: Pseudo dice [np.float32(0.5251)] 
2025-08-28 08:52:53.102678: Epoch time: 16.64 s 
2025-08-28 08:52:53.731003:  
2025-08-28 08:52:53.739798: Epoch 186 
2025-08-28 08:52:53.743785: Current learning rate: 0.00831 
2025-08-28 08:53:10.622814: train_loss -0.2809 
2025-08-28 08:53:10.631492: val_loss -0.245 
2025-08-28 08:53:10.639520: Pseudo dice [np.float32(0.433)] 
2025-08-28 08:53:10.645191: Epoch time: 16.89 s 
2025-08-28 08:53:11.281966:  
2025-08-28 08:53:11.285987: Epoch 187 
2025-08-28 08:53:11.294349: Current learning rate: 0.0083 
2025-08-28 08:53:28.349123: train_loss -0.2534 
2025-08-28 08:53:28.357278: val_loss -0.3302 
2025-08-28 08:53:28.361639: Pseudo dice [np.float32(0.5346)] 
2025-08-28 08:53:28.369588: Epoch time: 17.07 s 
2025-08-28 08:53:29.003679:  
2025-08-28 08:53:29.012059: Epoch 188 
2025-08-28 08:53:29.016227: Current learning rate: 0.00829 
2025-08-28 08:53:45.908498: train_loss -0.2659 
2025-08-28 08:53:45.916407: val_loss -0.3591 
2025-08-28 08:53:45.920618: Pseudo dice [np.float32(0.6173)] 
2025-08-28 08:53:45.928885: Epoch time: 16.9 s 
2025-08-28 08:53:46.559031:  
2025-08-28 08:53:46.567099: Epoch 189 
2025-08-28 08:53:46.571526: Current learning rate: 0.00828 
2025-08-28 08:54:03.538229: train_loss -0.2573 
2025-08-28 08:54:03.550461: val_loss -0.3227 
2025-08-28 08:54:03.555138: Pseudo dice [np.float32(0.5905)] 
2025-08-28 08:54:03.562210: Epoch time: 16.98 s 
2025-08-28 08:54:04.193007:  
2025-08-28 08:54:04.201670: Epoch 190 
2025-08-28 08:54:04.205757: Current learning rate: 0.00827 
2025-08-28 08:54:20.972281: train_loss -0.2861 
2025-08-28 08:54:20.980950: val_loss -0.3132 
2025-08-28 08:54:20.985144: Pseudo dice [np.float32(0.6113)] 
2025-08-28 08:54:20.993078: Epoch time: 16.78 s 
2025-08-28 08:54:21.635441:  
2025-08-28 08:54:21.645273: Epoch 191 
2025-08-28 08:54:21.652107: Current learning rate: 0.00826 
2025-08-28 08:54:38.415030: train_loss -0.2659 
2025-08-28 08:54:38.423013: val_loss -0.2619 
2025-08-28 08:54:38.427184: Pseudo dice [np.float32(0.4552)] 
2025-08-28 08:54:38.435290: Epoch time: 16.78 s 
2025-08-28 08:54:39.240580:  
2025-08-28 08:54:39.244938: Epoch 192 
2025-08-28 08:54:39.248895: Current learning rate: 0.00825 
2025-08-28 08:54:55.957445: train_loss -0.246 
2025-08-28 08:54:55.969809: val_loss -0.3666 
2025-08-28 08:54:55.973971: Pseudo dice [np.float32(0.5663)] 
2025-08-28 08:54:55.982667: Epoch time: 16.72 s 
2025-08-28 08:54:56.628831:  
2025-08-28 08:54:56.637078: Epoch 193 
2025-08-28 08:54:56.641228: Current learning rate: 0.00824 
2025-08-28 08:55:13.679913: train_loss -0.2655 
2025-08-28 08:55:13.687800: val_loss -0.3083 
2025-08-28 08:55:13.700352: Pseudo dice [np.float32(0.5602)] 
2025-08-28 08:55:13.708214: Epoch time: 17.05 s 
2025-08-28 08:55:14.383976:  
2025-08-28 08:55:14.392838: Epoch 194 
2025-08-28 08:55:14.396450: Current learning rate: 0.00824 
2025-08-28 08:55:31.250751: train_loss -0.269 
2025-08-28 08:55:31.259140: val_loss -0.298 
2025-08-28 08:55:31.267794: Pseudo dice [np.float32(0.5087)] 
2025-08-28 08:55:31.272571: Epoch time: 16.87 s 
2025-08-28 08:55:31.913958:  
2025-08-28 08:55:31.922244: Epoch 195 
2025-08-28 08:55:31.926758: Current learning rate: 0.00823 
2025-08-28 08:55:49.202002: train_loss -0.2203 
2025-08-28 08:55:49.210364: val_loss -0.2673 
2025-08-28 08:55:49.214526: Pseudo dice [np.float32(0.5618)] 
2025-08-28 08:55:49.222722: Epoch time: 17.29 s 
2025-08-28 08:55:49.861207:  
2025-08-28 08:55:49.869638: Epoch 196 
2025-08-28 08:55:49.878036: Current learning rate: 0.00822 
2025-08-28 08:56:06.582294: train_loss -0.2553 
2025-08-28 08:56:06.590266: val_loss -0.3032 
2025-08-28 08:56:06.594404: Pseudo dice [np.float32(0.5368)] 
2025-08-28 08:56:06.603619: Epoch time: 16.72 s 
2025-08-28 08:56:07.257997:  
2025-08-28 08:56:07.265932: Epoch 197 
2025-08-28 08:56:07.270102: Current learning rate: 0.00821 
2025-08-28 08:56:24.130231: train_loss -0.2691 
2025-08-28 08:56:24.137140: val_loss -0.2966 
2025-08-28 08:56:24.145246: Pseudo dice [np.float32(0.6071)] 
2025-08-28 08:56:24.151388: Epoch time: 16.87 s 
2025-08-28 08:56:24.154558: Yayy! New best EMA pseudo Dice: 0.546500027179718 
2025-08-28 08:56:25.158742:  
2025-08-28 08:56:25.167153: Epoch 198 
2025-08-28 08:56:25.171631: Current learning rate: 0.0082 
2025-08-28 08:56:42.234148: train_loss -0.2825 
2025-08-28 08:56:42.242524: val_loss -0.2696 
2025-08-28 08:56:42.250835: Pseudo dice [np.float32(0.5039)] 
2025-08-28 08:56:42.255789: Epoch time: 17.08 s 
2025-08-28 08:56:42.893192:  
2025-08-28 08:56:42.901584: Epoch 199 
2025-08-28 08:56:42.909617: Current learning rate: 0.00819 
2025-08-28 08:56:59.918556: train_loss -0.2777 
2025-08-28 08:56:59.926923: val_loss -0.3101 
2025-08-28 08:56:59.931024: Pseudo dice [np.float32(0.4503)] 
2025-08-28 08:56:59.938121: Epoch time: 17.03 s 
2025-08-28 08:57:00.760981:  
2025-08-28 08:57:00.765223: Epoch 200 
2025-08-28 08:57:00.773921: Current learning rate: 0.00818 
2025-08-28 08:57:17.523547: train_loss -0.2774 
2025-08-28 08:57:17.532261: val_loss -0.2626 
2025-08-28 08:57:17.536417: Pseudo dice [np.float32(0.4701)] 
2025-08-28 08:57:17.544379: Epoch time: 16.77 s 
2025-08-28 08:57:18.182560:  
2025-08-28 08:57:18.190881: Epoch 201 
2025-08-28 08:57:18.195375: Current learning rate: 0.00817 
2025-08-28 08:57:35.282538: train_loss -0.2657 
2025-08-28 08:57:35.287129: val_loss -0.2613 
2025-08-28 08:57:35.295465: Pseudo dice [np.float32(0.4626)] 
2025-08-28 08:57:35.301723: Epoch time: 17.1 s 
2025-08-28 08:57:35.946239:  
2025-08-28 08:57:35.955270: Epoch 202 
2025-08-28 08:57:35.958647: Current learning rate: 0.00816 
2025-08-28 08:57:53.059332: train_loss -0.2161 
2025-08-28 08:57:53.067430: val_loss -0.3249 
2025-08-28 08:57:53.071809: Pseudo dice [np.float32(0.542)] 
2025-08-28 08:57:53.079826: Epoch time: 17.11 s 
2025-08-28 08:57:53.713860:  
2025-08-28 08:57:53.722249: Epoch 203 
2025-08-28 08:57:53.730551: Current learning rate: 0.00815 
2025-08-28 08:58:10.893605: train_loss -0.2372 
2025-08-28 08:58:10.901966: val_loss -0.3659 
2025-08-28 08:58:10.906152: Pseudo dice [np.float32(0.5982)] 
2025-08-28 08:58:10.912732: Epoch time: 17.18 s 
2025-08-28 08:58:11.565058:  
2025-08-28 08:58:11.573741: Epoch 204 
2025-08-28 08:58:11.577538: Current learning rate: 0.00814 
2025-08-28 08:58:28.748837: train_loss -0.2483 
2025-08-28 08:58:28.756994: val_loss -0.3508 
2025-08-28 08:58:28.761678: Pseudo dice [np.float32(0.5953)] 
2025-08-28 08:58:28.767669: Epoch time: 17.18 s 
2025-08-28 08:58:29.579182:  
2025-08-28 08:58:29.587234: Epoch 205 
2025-08-28 08:58:29.591393: Current learning rate: 0.00813 
2025-08-28 08:58:46.662957: train_loss -0.2584 
2025-08-28 08:58:46.670926: val_loss -0.3325 
2025-08-28 08:58:46.679251: Pseudo dice [np.float32(0.6237)] 
2025-08-28 08:58:46.685481: Epoch time: 17.08 s 
2025-08-28 08:58:47.304879:  
2025-08-28 08:58:47.313237: Epoch 206 
2025-08-28 08:58:47.317819: Current learning rate: 0.00813 
2025-08-28 08:59:04.443221: train_loss -0.235 
2025-08-28 08:59:04.455444: val_loss -0.2873 
2025-08-28 08:59:04.459838: Pseudo dice [np.float32(0.59)] 
2025-08-28 08:59:04.466743: Epoch time: 17.14 s 
2025-08-28 08:59:04.472553: Yayy! New best EMA pseudo Dice: 0.5497999787330627 
2025-08-28 08:59:05.277015:  
2025-08-28 08:59:05.285379: Epoch 207 
2025-08-28 08:59:05.293702: Current learning rate: 0.00812 
2025-08-28 08:59:22.181742: train_loss -0.2505 
2025-08-28 08:59:22.189708: val_loss -0.2296 
2025-08-28 08:59:22.194218: Pseudo dice [np.float32(0.4713)] 
2025-08-28 08:59:22.202042: Epoch time: 16.9 s 
2025-08-28 08:59:22.819506:  
2025-08-28 08:59:22.828330: Epoch 208 
2025-08-28 08:59:22.834125: Current learning rate: 0.00811 
2025-08-28 08:59:39.669653: train_loss -0.2692 
2025-08-28 08:59:39.678060: val_loss -0.2727 
2025-08-28 08:59:39.682224: Pseudo dice [np.float32(0.5471)] 
2025-08-28 08:59:39.689286: Epoch time: 16.85 s 
2025-08-28 08:59:40.303978:  
2025-08-28 08:59:40.311980: Epoch 209 
2025-08-28 08:59:40.316443: Current learning rate: 0.0081 
2025-08-28 08:59:57.291731: train_loss -0.2408 
2025-08-28 08:59:57.303732: val_loss -0.3471 
2025-08-28 08:59:57.308223: Pseudo dice [np.float32(0.5998)] 
2025-08-28 08:59:57.313619: Epoch time: 16.99 s 
2025-08-28 08:59:57.929159:  
2025-08-28 08:59:57.933762: Epoch 210 
2025-08-28 08:59:57.942095: Current learning rate: 0.00809 
2025-08-28 09:00:14.558736: train_loss -0.2651 
2025-08-28 09:00:14.567308: val_loss -0.3011 
2025-08-28 09:00:14.575698: Pseudo dice [np.float32(0.5564)] 
2025-08-28 09:00:14.581639: Epoch time: 16.63 s 
2025-08-28 09:00:15.351220:  
2025-08-28 09:00:15.359834: Epoch 211 
2025-08-28 09:00:15.363654: Current learning rate: 0.00808 
2025-08-28 09:00:32.010029: train_loss -0.2641 
2025-08-28 09:00:32.017797: val_loss -0.328 
2025-08-28 09:00:32.026482: Pseudo dice [np.float32(0.6192)] 
2025-08-28 09:00:32.031085: Epoch time: 16.66 s 
2025-08-28 09:00:32.036506: Yayy! New best EMA pseudo Dice: 0.5559999942779541 
2025-08-28 09:00:32.840765:  
2025-08-28 09:00:32.848036: Epoch 212 
2025-08-28 09:00:32.851975: Current learning rate: 0.00807 
2025-08-28 09:00:48.876578: train_loss -0.25 
2025-08-28 09:00:48.884892: val_loss -0.2208 
2025-08-28 09:00:48.888901: Pseudo dice [np.float32(0.5407)] 
2025-08-28 09:00:48.898122: Epoch time: 16.04 s 
2025-08-28 09:00:49.522772:  
2025-08-28 09:00:49.531126: Epoch 213 
2025-08-28 09:00:49.535511: Current learning rate: 0.00806 
2025-08-28 09:01:05.580459: train_loss -0.2588 
2025-08-28 09:01:05.592992: val_loss -0.2996 
2025-08-28 09:01:05.597476: Pseudo dice [np.float32(0.5219)] 
2025-08-28 09:01:05.603510: Epoch time: 16.06 s 
2025-08-28 09:01:06.231105:  
2025-08-28 09:01:06.239492: Epoch 214 
2025-08-28 09:01:06.243669: Current learning rate: 0.00805 
2025-08-28 09:01:22.663289: train_loss -0.2338 
2025-08-28 09:01:22.668714: val_loss -0.2751 
2025-08-28 09:01:22.677303: Pseudo dice [np.float32(0.5476)] 
2025-08-28 09:01:22.682240: Epoch time: 16.43 s 
2025-08-28 09:01:23.302355:  
2025-08-28 09:01:23.310712: Epoch 215 
2025-08-28 09:01:23.314840: Current learning rate: 0.00804 
2025-08-28 09:01:39.827167: train_loss -0.2544 
2025-08-28 09:01:39.835559: val_loss -0.2755 
2025-08-28 09:01:39.841748: Pseudo dice [np.float32(0.5647)] 
2025-08-28 09:01:39.847927: Epoch time: 16.52 s 
2025-08-28 09:01:40.486137:  
2025-08-28 09:01:40.494495: Epoch 216 
2025-08-28 09:01:40.498688: Current learning rate: 0.00803 
2025-08-28 09:01:57.028077: train_loss -0.2915 
2025-08-28 09:01:57.040302: val_loss -0.2634 
2025-08-28 09:01:57.044410: Pseudo dice [np.float32(0.4144)] 
2025-08-28 09:01:57.052673: Epoch time: 16.55 s 
2025-08-28 09:01:57.686743:  
2025-08-28 09:01:57.695350: Epoch 217 
2025-08-28 09:01:57.699175: Current learning rate: 0.00802 
2025-08-28 09:02:13.815300: train_loss -0.2823 
2025-08-28 09:02:13.823632: val_loss -0.2682 
2025-08-28 09:02:13.828194: Pseudo dice [np.float32(0.5788)] 
2025-08-28 09:02:13.833182: Epoch time: 16.13 s 
2025-08-28 09:02:14.636914:  
2025-08-28 09:02:14.649483: Epoch 218 
2025-08-28 09:02:14.655612: Current learning rate: 0.00801 
2025-08-28 09:02:31.062055: train_loss -0.2739 
2025-08-28 09:02:31.069993: val_loss -0.3317 
2025-08-28 09:02:31.074430: Pseudo dice [np.float32(0.5994)] 
2025-08-28 09:02:31.082325: Epoch time: 16.43 s 
2025-08-28 09:02:31.703973:  
2025-08-28 09:02:31.712331: Epoch 219 
2025-08-28 09:02:31.716514: Current learning rate: 0.00801 
2025-08-28 09:02:47.561472: train_loss -0.2807 
2025-08-28 09:02:47.565694: val_loss -0.3076 
2025-08-28 09:02:47.574044: Pseudo dice [np.float32(0.5888)] 
2025-08-28 09:02:47.580781: Epoch time: 15.86 s 
2025-08-28 09:02:48.207949:  
2025-08-28 09:02:48.212110: Epoch 220 
2025-08-28 09:02:48.216286: Current learning rate: 0.008 
2025-08-28 09:03:03.707262: train_loss -0.2517 
2025-08-28 09:03:03.719295: val_loss -0.2713 
2025-08-28 09:03:03.723789: Pseudo dice [np.float32(0.5018)] 
2025-08-28 09:03:03.730772: Epoch time: 15.5 s 
2025-08-28 09:03:04.349307:  
2025-08-28 09:03:04.357418: Epoch 221 
2025-08-28 09:03:04.365391: Current learning rate: 0.00799 
2025-08-28 09:03:20.085948: train_loss -0.2685 
2025-08-28 09:03:20.094010: val_loss -0.3277 
2025-08-28 09:03:20.098493: Pseudo dice [np.float32(0.6006)] 
2025-08-28 09:03:20.104468: Epoch time: 15.74 s 
2025-08-28 09:03:20.723754:  
2025-08-28 09:03:20.732114: Epoch 222 
2025-08-28 09:03:20.736261: Current learning rate: 0.00798 
2025-08-28 09:03:36.468752: train_loss -0.2918 
2025-08-28 09:03:36.476979: val_loss -0.2913 
2025-08-28 09:03:36.481186: Pseudo dice [np.float32(0.5091)] 
2025-08-28 09:03:36.490411: Epoch time: 15.74 s 
2025-08-28 09:03:37.111317:  
2025-08-28 09:03:37.119306: Epoch 223 
2025-08-28 09:03:37.123476: Current learning rate: 0.00797 
2025-08-28 09:03:54.394922: train_loss -0.2773 
2025-08-28 09:03:54.403233: val_loss -0.3138 
2025-08-28 09:03:54.411568: Pseudo dice [np.float32(0.4846)] 
2025-08-28 09:03:54.415818: Epoch time: 17.28 s 
2025-08-28 09:03:55.037267:  
2025-08-28 09:03:55.045572: Epoch 224 
2025-08-28 09:03:55.049786: Current learning rate: 0.00796 
2025-08-28 09:04:12.229353: train_loss -0.2785 
2025-08-28 09:04:12.237711: val_loss -0.3059 
2025-08-28 09:04:12.242066: Pseudo dice [np.float32(0.5679)] 
2025-08-28 09:04:12.249264: Epoch time: 17.19 s 
2025-08-28 09:04:13.076365:  
2025-08-28 09:04:13.084417: Epoch 225 
2025-08-28 09:04:13.088566: Current learning rate: 0.00795 
2025-08-28 09:04:30.039021: train_loss -0.2589 
2025-08-28 09:04:30.047199: val_loss -0.3463 
2025-08-28 09:04:30.055502: Pseudo dice [np.float32(0.587)] 
2025-08-28 09:04:30.061034: Epoch time: 16.97 s 
2025-08-28 09:04:30.676996:  
2025-08-28 09:04:30.685339: Epoch 226 
2025-08-28 09:04:30.689809: Current learning rate: 0.00794 
2025-08-28 09:04:47.314448: train_loss -0.2586 
2025-08-28 09:04:47.322734: val_loss -0.2976 
2025-08-28 09:04:47.326920: Pseudo dice [np.float32(0.5996)] 
2025-08-28 09:04:47.334110: Epoch time: 16.64 s 
2025-08-28 09:04:47.948631:  
2025-08-28 09:04:47.956772: Epoch 227 
2025-08-28 09:04:47.961170: Current learning rate: 0.00793 
2025-08-28 09:05:04.719585: train_loss -0.2857 
2025-08-28 09:05:04.727628: val_loss -0.2801 
2025-08-28 09:05:04.735787: Pseudo dice [np.float32(0.5464)] 
2025-08-28 09:05:04.741402: Epoch time: 16.77 s 
2025-08-28 09:05:05.365755:  
2025-08-28 09:05:05.374110: Epoch 228 
2025-08-28 09:05:05.378171: Current learning rate: 0.00792 
2025-08-28 09:05:22.378956: train_loss -0.2643 
2025-08-28 09:05:22.391267: val_loss -0.2892 
2025-08-28 09:05:22.395553: Pseudo dice [np.float32(0.5805)] 
2025-08-28 09:05:22.402788: Epoch time: 17.01 s 
2025-08-28 09:05:23.020919:  
2025-08-28 09:05:23.025055: Epoch 229 
2025-08-28 09:05:23.033400: Current learning rate: 0.00791 
2025-08-28 09:05:40.091991: train_loss -0.2495 
2025-08-28 09:05:40.096278: val_loss -0.3324 
2025-08-28 09:05:40.105283: Pseudo dice [np.float32(0.5691)] 
2025-08-28 09:05:40.110342: Epoch time: 17.08 s 
2025-08-28 09:05:40.117057: Yayy! New best EMA pseudo Dice: 0.5570999979972839 
2025-08-28 09:05:40.901282:  
2025-08-28 09:05:40.910042: Epoch 230 
2025-08-28 09:05:40.914022: Current learning rate: 0.0079 
2025-08-28 09:05:57.601197: train_loss -0.2665 
2025-08-28 09:05:57.609584: val_loss -0.3452 
2025-08-28 09:05:57.614133: Pseudo dice [np.float32(0.6363)] 
2025-08-28 09:05:57.621008: Epoch time: 16.7 s 
2025-08-28 09:05:57.627769: Yayy! New best EMA pseudo Dice: 0.5649999976158142 
2025-08-28 09:05:58.502242:  
2025-08-28 09:05:58.510487: Epoch 231 
2025-08-28 09:05:58.514985: Current learning rate: 0.00789 
2025-08-28 09:06:15.593967: train_loss -0.2694 
2025-08-28 09:06:15.598422: val_loss -0.2596 
2025-08-28 09:06:15.607820: Pseudo dice [np.float32(0.4808)] 
2025-08-28 09:06:15.611956: Epoch time: 17.09 s 
2025-08-28 09:06:16.386974:  
2025-08-28 09:06:16.395029: Epoch 232 
2025-08-28 09:06:16.399513: Current learning rate: 0.00789 
2025-08-28 09:06:33.203737: train_loss -0.2928 
2025-08-28 09:06:33.211866: val_loss -0.3574 
2025-08-28 09:06:33.216075: Pseudo dice [np.float32(0.621)] 
2025-08-28 09:06:33.223150: Epoch time: 16.82 s 
2025-08-28 09:06:33.839826:  
2025-08-28 09:06:33.846030: Epoch 233 
2025-08-28 09:06:33.849944: Current learning rate: 0.00788 
2025-08-28 09:06:50.725132: train_loss -0.2605 
2025-08-28 09:06:50.733472: val_loss -0.2742 
2025-08-28 09:06:50.737652: Pseudo dice [np.float32(0.4995)] 
2025-08-28 09:06:50.746069: Epoch time: 16.89 s 
2025-08-28 09:06:51.355201:  
2025-08-28 09:06:51.363348: Epoch 234 
2025-08-28 09:06:51.367775: Current learning rate: 0.00787 
2025-08-28 09:07:08.105699: train_loss -0.2866 
2025-08-28 09:07:08.113358: val_loss -0.347 
2025-08-28 09:07:08.117845: Pseudo dice [np.float32(0.6295)] 
2025-08-28 09:07:08.125921: Epoch time: 16.75 s 
2025-08-28 09:07:08.747311:  
2025-08-28 09:07:08.751466: Epoch 235 
2025-08-28 09:07:08.759850: Current learning rate: 0.00786 
2025-08-28 09:07:25.639137: train_loss -0.2663 
2025-08-28 09:07:25.647516: val_loss -0.2615 
2025-08-28 09:07:25.655860: Pseudo dice [np.float32(0.5475)] 
2025-08-28 09:07:25.662466: Epoch time: 16.9 s 
2025-08-28 09:07:26.331598:  
2025-08-28 09:07:26.338469: Epoch 236 
2025-08-28 09:07:26.347541: Current learning rate: 0.00785 
2025-08-28 09:07:43.106640: train_loss -0.2702 
2025-08-28 09:07:43.115309: val_loss -0.3123 
2025-08-28 09:07:43.119242: Pseudo dice [np.float32(0.5839)] 
2025-08-28 09:07:43.125556: Epoch time: 16.78 s 
2025-08-28 09:07:43.732227:  
2025-08-28 09:07:43.740583: Epoch 237 
2025-08-28 09:07:43.744741: Current learning rate: 0.00784 
2025-08-28 09:08:00.636610: train_loss -0.2733 
2025-08-28 09:08:00.644946: val_loss -0.392 
2025-08-28 09:08:00.649129: Pseudo dice [np.float32(0.6609)] 
2025-08-28 09:08:00.657176: Epoch time: 16.9 s 
2025-08-28 09:08:00.663124: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-08-28 09:08:01.566700:  
2025-08-28 09:08:01.575049: Epoch 238 
2025-08-28 09:08:01.579227: Current learning rate: 0.00783 
2025-08-28 09:08:18.363037: train_loss -0.2735 
2025-08-28 09:08:18.370979: val_loss -0.313 
2025-08-28 09:08:18.375200: Pseudo dice [np.float32(0.6401)] 
2025-08-28 09:08:18.382402: Epoch time: 16.8 s 
2025-08-28 09:08:18.388011: Yayy! New best EMA pseudo Dice: 0.5806999802589417 
2025-08-28 09:08:19.442872:  
2025-08-28 09:08:19.451263: Epoch 239 
2025-08-28 09:08:19.455407: Current learning rate: 0.00782 
2025-08-28 09:08:35.817641: train_loss -0.3014 
2025-08-28 09:08:35.822104: val_loss -0.3576 
2025-08-28 09:08:35.830126: Pseudo dice [np.float32(0.6338)] 
2025-08-28 09:08:35.836544: Epoch time: 16.37 s 
2025-08-28 09:08:35.841942: Yayy! New best EMA pseudo Dice: 0.5860000252723694 
2025-08-28 09:08:36.660110:  
2025-08-28 09:08:36.668782: Epoch 240 
2025-08-28 09:08:36.672893: Current learning rate: 0.00781 
2025-08-28 09:08:52.760512: train_loss -0.2694 
2025-08-28 09:08:52.772066: val_loss -0.366 
2025-08-28 09:08:52.776465: Pseudo dice [np.float32(0.6284)] 
2025-08-28 09:08:52.785380: Epoch time: 16.1 s 
2025-08-28 09:08:52.790248: Yayy! New best EMA pseudo Dice: 0.5903000235557556 
2025-08-28 09:08:53.602093:  
2025-08-28 09:08:53.610426: Epoch 241 
2025-08-28 09:08:53.614553: Current learning rate: 0.0078 
2025-08-28 09:09:10.498708: train_loss -0.2835 
2025-08-28 09:09:10.506683: val_loss -0.3552 
2025-08-28 09:09:10.510568: Pseudo dice [np.float32(0.5861)] 
2025-08-28 09:09:10.518971: Epoch time: 16.9 s 
2025-08-28 09:09:11.144516:  
2025-08-28 09:09:11.148686: Epoch 242 
2025-08-28 09:09:11.157029: Current learning rate: 0.00779 
2025-08-28 09:09:28.332486: train_loss -0.3173 
2025-08-28 09:09:28.342343: val_loss -0.3694 
2025-08-28 09:09:28.345420: Pseudo dice [np.float32(0.6616)] 
2025-08-28 09:09:28.354330: Epoch time: 17.19 s 
2025-08-28 09:09:28.360059: Yayy! New best EMA pseudo Dice: 0.597000002861023 
2025-08-28 09:09:29.170849:  
2025-08-28 09:09:29.179188: Epoch 243 
2025-08-28 09:09:29.183367: Current learning rate: 0.00778 
2025-08-28 09:09:45.908506: train_loss -0.2747 
2025-08-28 09:09:45.916735: val_loss -0.3176 
2025-08-28 09:09:45.920913: Pseudo dice [np.float32(0.5697)] 
2025-08-28 09:09:45.930083: Epoch time: 16.74 s 
2025-08-28 09:09:46.550699:  
2025-08-28 09:09:46.554889: Epoch 244 
2025-08-28 09:09:46.563232: Current learning rate: 0.00777 
2025-08-28 09:10:03.563501: train_loss -0.2788 
2025-08-28 09:10:03.572201: val_loss -0.252 
2025-08-28 09:10:03.580204: Pseudo dice [np.float32(0.4388)] 
2025-08-28 09:10:03.585751: Epoch time: 17.02 s 
2025-08-28 09:10:04.214174:  
2025-08-28 09:10:04.218701: Epoch 245 
2025-08-28 09:10:04.226780: Current learning rate: 0.00777 
2025-08-28 09:10:21.254332: train_loss -0.2731 
2025-08-28 09:10:21.260389: val_loss -0.3134 
2025-08-28 09:10:21.269135: Pseudo dice [np.float32(0.5126)] 
2025-08-28 09:10:21.274256: Epoch time: 17.04 s 
2025-08-28 09:10:22.052843:  
2025-08-28 09:10:22.061159: Epoch 246 
2025-08-28 09:10:22.065289: Current learning rate: 0.00776 
2025-08-28 09:10:39.107664: train_loss -0.2705 
2025-08-28 09:10:39.115717: val_loss -0.264 
2025-08-28 09:10:39.119867: Pseudo dice [np.float32(0.5738)] 
2025-08-28 09:10:39.125991: Epoch time: 17.05 s 
2025-08-28 09:10:39.824748:  
2025-08-28 09:10:39.835611: Epoch 247 
2025-08-28 09:10:39.841775: Current learning rate: 0.00775 
2025-08-28 09:10:56.887625: train_loss -0.2394 
2025-08-28 09:10:56.900146: val_loss -0.3458 
2025-08-28 09:10:56.904526: Pseudo dice [np.float32(0.6021)] 
2025-08-28 09:10:56.913406: Epoch time: 17.06 s 
2025-08-28 09:10:57.534083:  
2025-08-28 09:10:57.538258: Epoch 248 
2025-08-28 09:10:57.546596: Current learning rate: 0.00774 
2025-08-28 09:11:14.813884: train_loss -0.2657 
2025-08-28 09:11:14.822203: val_loss -0.2997 
2025-08-28 09:11:14.826366: Pseudo dice [np.float32(0.5861)] 
2025-08-28 09:11:14.833919: Epoch time: 17.28 s 
2025-08-28 09:11:15.547731:  
2025-08-28 09:11:15.555082: Epoch 249 
2025-08-28 09:11:15.560426: Current learning rate: 0.00773 
2025-08-28 09:11:32.819352: train_loss -0.268 
2025-08-28 09:11:32.827705: val_loss -0.315 
2025-08-28 09:11:32.831869: Pseudo dice [np.float32(0.5485)] 
2025-08-28 09:11:32.841230: Epoch time: 17.27 s 
2025-08-28 09:11:33.641067:  
2025-08-28 09:11:33.649322: Epoch 250 
2025-08-28 09:11:33.653721: Current learning rate: 0.00772 
2025-08-28 09:11:50.842120: train_loss -0.2657 
2025-08-28 09:11:50.849769: val_loss -0.2623 
2025-08-28 09:11:50.853986: Pseudo dice [np.float32(0.5325)] 
2025-08-28 09:11:50.862337: Epoch time: 17.2 s 
2025-08-28 09:11:51.500823:  
2025-08-28 09:11:51.508836: Epoch 251 
2025-08-28 09:11:51.513279: Current learning rate: 0.00771 
2025-08-28 09:12:08.479999: train_loss -0.3014 
2025-08-28 09:12:08.488264: val_loss -0.3262 
2025-08-28 09:12:08.492773: Pseudo dice [np.float32(0.6115)] 
2025-08-28 09:12:08.501563: Epoch time: 16.98 s 
2025-08-28 09:12:09.122579:  
2025-08-28 09:12:09.130851: Epoch 252 
2025-08-28 09:12:09.134793: Current learning rate: 0.0077 
2025-08-28 09:12:25.964103: train_loss -0.2696 
2025-08-28 09:12:25.972445: val_loss -0.3418 
2025-08-28 09:12:25.981025: Pseudo dice [np.float32(0.482)] 
2025-08-28 09:12:25.986114: Epoch time: 16.84 s 
2025-08-28 09:12:26.777386:  
2025-08-28 09:12:26.781774: Epoch 253 
2025-08-28 09:12:26.789872: Current learning rate: 0.00769 
2025-08-28 09:12:43.524124: train_loss -0.276 
2025-08-28 09:12:43.531597: val_loss -0.3161 
2025-08-28 09:12:43.540585: Pseudo dice [np.float32(0.6141)] 
2025-08-28 09:12:43.545476: Epoch time: 16.75 s 
2025-08-28 09:12:44.165799:  
2025-08-28 09:12:44.169815: Epoch 254 
2025-08-28 09:12:44.178155: Current learning rate: 0.00768 
2025-08-28 09:13:00.882556: train_loss -0.2946 
2025-08-28 09:13:00.890698: val_loss -0.3299 
2025-08-28 09:13:00.899299: Pseudo dice [np.float32(0.5659)] 
2025-08-28 09:13:00.904312: Epoch time: 16.72 s 
2025-08-28 09:13:01.528751:  
2025-08-28 09:13:01.532917: Epoch 255 
2025-08-28 09:13:01.541242: Current learning rate: 0.00767 
2025-08-28 09:13:18.403957: train_loss -0.2881 
2025-08-28 09:13:18.412266: val_loss -0.3335 
2025-08-28 09:13:18.416498: Pseudo dice [np.float32(0.5032)] 
2025-08-28 09:13:18.422825: Epoch time: 16.88 s 
2025-08-28 09:13:19.050440:  
2025-08-28 09:13:19.059495: Epoch 256 
2025-08-28 09:13:19.062900: Current learning rate: 0.00766 
2025-08-28 09:13:35.688188: train_loss -0.2856 
2025-08-28 09:13:35.696564: val_loss -0.3583 
2025-08-28 09:13:35.700395: Pseudo dice [np.float32(0.6652)] 
2025-08-28 09:13:35.707545: Epoch time: 16.64 s 
2025-08-28 09:13:36.326009:  
2025-08-28 09:13:36.334329: Epoch 257 
2025-08-28 09:13:36.339101: Current learning rate: 0.00765 
2025-08-28 09:13:53.301493: train_loss -0.2666 
2025-08-28 09:13:53.309634: val_loss -0.3478 
2025-08-28 09:13:53.317962: Pseudo dice [np.float32(0.6392)] 
2025-08-28 09:13:53.324277: Epoch time: 16.98 s 
2025-08-28 09:13:53.956099:  
2025-08-28 09:13:53.964803: Epoch 258 
2025-08-28 09:13:53.968620: Current learning rate: 0.00764 
2025-08-28 09:14:10.777314: train_loss -0.3026 
2025-08-28 09:14:10.785426: val_loss -0.3656 
2025-08-28 09:14:10.789841: Pseudo dice [np.float32(0.6935)] 
2025-08-28 09:14:10.796837: Epoch time: 16.82 s 
2025-08-28 09:14:11.573742:  
2025-08-28 09:14:11.583429: Epoch 259 
2025-08-28 09:14:11.586349: Current learning rate: 0.00764 
2025-08-28 09:14:28.657808: train_loss -0.2746 
2025-08-28 09:14:28.666098: val_loss -0.3147 
2025-08-28 09:14:28.673944: Pseudo dice [np.float32(0.5485)] 
2025-08-28 09:14:28.679153: Epoch time: 17.08 s 
2025-08-28 09:14:29.308079:  
2025-08-28 09:14:29.312215: Epoch 260 
2025-08-28 09:14:29.320606: Current learning rate: 0.00763 
2025-08-28 09:14:46.350393: train_loss -0.2891 
2025-08-28 09:14:46.358472: val_loss -0.3079 
2025-08-28 09:14:46.362615: Pseudo dice [np.float32(0.6162)] 
2025-08-28 09:14:46.370946: Epoch time: 17.05 s 
2025-08-28 09:14:46.996581:  
2025-08-28 09:14:47.004918: Epoch 261 
2025-08-28 09:14:47.009238: Current learning rate: 0.00762 
2025-08-28 09:15:04.005203: train_loss -0.2988 
2025-08-28 09:15:04.017729: val_loss -0.3361 
2025-08-28 09:15:04.021903: Pseudo dice [np.float32(0.579)] 
2025-08-28 09:15:04.030404: Epoch time: 17.01 s 
2025-08-28 09:15:04.660043:  
2025-08-28 09:15:04.668356: Epoch 262 
2025-08-28 09:15:04.672586: Current learning rate: 0.00761 
2025-08-28 09:15:21.389420: train_loss -0.2877 
2025-08-28 09:15:21.397662: val_loss -0.3794 
2025-08-28 09:15:21.405965: Pseudo dice [np.float32(0.6796)] 
2025-08-28 09:15:21.410986: Epoch time: 16.73 s 
2025-08-28 09:15:21.415097: Yayy! New best EMA pseudo Dice: 0.597599983215332 
2025-08-28 09:15:22.219268:  
2025-08-28 09:15:22.223700: Epoch 263 
2025-08-28 09:15:22.232063: Current learning rate: 0.0076 
2025-08-28 09:15:39.286600: train_loss -0.2913 
2025-08-28 09:15:39.294625: val_loss -0.3228 
2025-08-28 09:15:39.298778: Pseudo dice [np.float32(0.5565)] 
2025-08-28 09:15:39.305318: Epoch time: 17.07 s 
2025-08-28 09:15:39.941119:  
2025-08-28 09:15:39.945324: Epoch 264 
2025-08-28 09:15:39.953966: Current learning rate: 0.00759 
2025-08-28 09:15:56.553520: train_loss -0.272 
2025-08-28 09:15:56.561861: val_loss -0.3291 
2025-08-28 09:15:56.570213: Pseudo dice [np.float32(0.6577)] 
2025-08-28 09:15:56.576394: Epoch time: 16.62 s 
2025-08-28 09:15:56.582702: Yayy! New best EMA pseudo Dice: 0.5999000072479248 
2025-08-28 09:15:57.433944:  
2025-08-28 09:15:57.438157: Epoch 265 
2025-08-28 09:15:57.446448: Current learning rate: 0.00758 
2025-08-28 09:16:14.483939: train_loss -0.2648 
2025-08-28 09:16:14.492599: val_loss -0.3393 
2025-08-28 09:16:14.496783: Pseudo dice [np.float32(0.6209)] 
2025-08-28 09:16:14.503587: Epoch time: 17.05 s 
2025-08-28 09:16:14.509451: Yayy! New best EMA pseudo Dice: 0.6019999980926514 
2025-08-28 09:16:15.464272:  
2025-08-28 09:16:15.472637: Epoch 266 
2025-08-28 09:16:15.476582: Current learning rate: 0.00757 
2025-08-28 09:16:32.264225: train_loss -0.256 
2025-08-28 09:16:32.272869: val_loss -0.317 
2025-08-28 09:16:32.281172: Pseudo dice [np.float32(0.5753)] 
2025-08-28 09:16:32.288715: Epoch time: 16.8 s 
2025-08-28 09:16:32.914828:  
2025-08-28 09:16:32.923169: Epoch 267 
2025-08-28 09:16:32.927549: Current learning rate: 0.00756 
2025-08-28 09:16:49.639855: train_loss -0.2834 
2025-08-28 09:16:49.648202: val_loss -0.3463 
2025-08-28 09:16:49.652352: Pseudo dice [np.float32(0.5565)] 
2025-08-28 09:16:49.660571: Epoch time: 16.73 s 
2025-08-28 09:16:50.290836:  
2025-08-28 09:16:50.298833: Epoch 268 
2025-08-28 09:16:50.303015: Current learning rate: 0.00755 
2025-08-28 09:17:07.228251: train_loss -0.2831 
2025-08-28 09:17:07.236619: val_loss -0.3023 
2025-08-28 09:17:07.240759: Pseudo dice [np.float32(0.5991)] 
2025-08-28 09:17:07.249776: Epoch time: 16.94 s 
2025-08-28 09:17:07.875230:  
2025-08-28 09:17:07.883435: Epoch 269 
2025-08-28 09:17:07.887255: Current learning rate: 0.00754 
2025-08-28 09:17:24.478858: train_loss -0.2735 
2025-08-28 09:17:24.487169: val_loss -0.328 
2025-08-28 09:17:24.495523: Pseudo dice [np.float32(0.5211)] 
2025-08-28 09:17:24.500956: Epoch time: 16.6 s 
2025-08-28 09:17:25.129566:  
2025-08-28 09:17:25.137560: Epoch 270 
2025-08-28 09:17:25.141986: Current learning rate: 0.00753 
2025-08-28 09:17:42.100618: train_loss -0.2778 
2025-08-28 09:17:42.109340: val_loss -0.3474 
2025-08-28 09:17:42.113140: Pseudo dice [np.float32(0.6537)] 
2025-08-28 09:17:42.119249: Epoch time: 16.98 s 
2025-08-28 09:17:42.751561:  
2025-08-28 09:17:42.759589: Epoch 271 
2025-08-28 09:17:42.764135: Current learning rate: 0.00752 
2025-08-28 09:17:59.476281: train_loss -0.2798 
2025-08-28 09:17:59.484995: val_loss -0.3698 
2025-08-28 09:17:59.493004: Pseudo dice [np.float32(0.595)] 
2025-08-28 09:17:59.498618: Epoch time: 16.72 s 
2025-08-28 09:18:00.281236:  
2025-08-28 09:18:00.289633: Epoch 272 
2025-08-28 09:18:00.293713: Current learning rate: 0.00751 
2025-08-28 09:18:17.540437: train_loss -0.2876 
2025-08-28 09:18:17.548746: val_loss -0.2917 
2025-08-28 09:18:17.556828: Pseudo dice [np.float32(0.4955)] 
2025-08-28 09:18:17.562217: Epoch time: 17.26 s 
2025-08-28 09:18:18.203338:  
2025-08-28 09:18:18.211546: Epoch 273 
2025-08-28 09:18:18.216338: Current learning rate: 0.00751 
2025-08-28 09:18:34.999819: train_loss -0.2808 
2025-08-28 09:18:35.007805: val_loss -0.3334 
2025-08-28 09:18:35.015977: Pseudo dice [np.float32(0.6066)] 
2025-08-28 09:18:35.020949: Epoch time: 16.8 s 
2025-08-28 09:18:35.649964:  
2025-08-28 09:18:35.658233: Epoch 274 
2025-08-28 09:18:35.662775: Current learning rate: 0.0075 
2025-08-28 09:18:52.491998: train_loss -0.317 
2025-08-28 09:18:52.504479: val_loss -0.2852 
2025-08-28 09:18:52.508754: Pseudo dice [np.float32(0.5397)] 
2025-08-28 09:18:52.515003: Epoch time: 16.84 s 
2025-08-28 09:18:53.146559:  
2025-08-28 09:18:53.154923: Epoch 275 
2025-08-28 09:18:53.159081: Current learning rate: 0.00749 
2025-08-28 09:19:09.830135: train_loss -0.2866 
2025-08-28 09:19:09.838467: val_loss -0.2949 
2025-08-28 09:19:09.844698: Pseudo dice [np.float32(0.5712)] 
2025-08-28 09:19:09.851542: Epoch time: 16.68 s 
2025-08-28 09:19:10.480563:  
2025-08-28 09:19:10.488918: Epoch 276 
2025-08-28 09:19:10.493353: Current learning rate: 0.00748 
2025-08-28 09:19:27.141523: train_loss -0.2785 
2025-08-28 09:19:27.149829: val_loss -0.359 
2025-08-28 09:19:27.155843: Pseudo dice [np.float32(0.5664)] 
2025-08-28 09:19:27.161004: Epoch time: 16.66 s 
2025-08-28 09:19:27.789462:  
2025-08-28 09:19:27.797416: Epoch 277 
2025-08-28 09:19:27.801993: Current learning rate: 0.00747 
2025-08-28 09:19:44.489760: train_loss -0.2581 
2025-08-28 09:19:44.497896: val_loss -0.3924 
2025-08-28 09:19:44.502066: Pseudo dice [np.float32(0.6638)] 
2025-08-28 09:19:44.508484: Epoch time: 16.7 s 
2025-08-28 09:19:45.148836:  
2025-08-28 09:19:45.156800: Epoch 278 
2025-08-28 09:19:45.161309: Current learning rate: 0.00746 
2025-08-28 09:20:02.339078: train_loss -0.3 
2025-08-28 09:20:02.348985: val_loss -0.3146 
2025-08-28 09:20:02.353413: Pseudo dice [np.float32(0.5947)] 
2025-08-28 09:20:02.361596: Epoch time: 17.19 s 
2025-08-28 09:20:03.149819:  
2025-08-28 09:20:03.158181: Epoch 279 
2025-08-28 09:20:03.162355: Current learning rate: 0.00745 
2025-08-28 09:20:20.016679: train_loss -0.2904 
2025-08-28 09:20:20.025205: val_loss -0.2973 
2025-08-28 09:20:20.033330: Pseudo dice [np.float32(0.5811)] 
2025-08-28 09:20:20.039179: Epoch time: 16.87 s 
2025-08-28 09:20:20.671424:  
2025-08-28 09:20:20.679764: Epoch 280 
2025-08-28 09:20:20.683951: Current learning rate: 0.00744 
2025-08-28 09:20:37.550698: train_loss -0.2874 
2025-08-28 09:20:37.555090: val_loss -0.2806 
2025-08-28 09:20:37.563302: Pseudo dice [np.float32(0.5727)] 
2025-08-28 09:20:37.568670: Epoch time: 16.88 s 
2025-08-28 09:20:38.193098:  
2025-08-28 09:20:38.201734: Epoch 281 
2025-08-28 09:20:38.205698: Current learning rate: 0.00743 
2025-08-28 09:20:55.081090: train_loss -0.2932 
2025-08-28 09:20:55.093361: val_loss -0.3181 
2025-08-28 09:20:55.097487: Pseudo dice [np.float32(0.5847)] 
2025-08-28 09:20:55.106812: Epoch time: 16.89 s 
2025-08-28 09:20:55.731460:  
2025-08-28 09:20:55.739786: Epoch 282 
2025-08-28 09:20:55.743940: Current learning rate: 0.00742 
2025-08-28 09:21:12.564925: train_loss -0.3052 
2025-08-28 09:21:12.573252: val_loss -0.3569 
2025-08-28 09:21:12.577671: Pseudo dice [np.float32(0.6013)] 
2025-08-28 09:21:12.583776: Epoch time: 16.83 s 
2025-08-28 09:21:13.244767:  
2025-08-28 09:21:13.253491: Epoch 283 
2025-08-28 09:21:13.257316: Current learning rate: 0.00741 
2025-08-28 09:21:30.124427: train_loss -0.2817 
2025-08-28 09:21:30.132544: val_loss -0.409 
2025-08-28 09:21:30.136675: Pseudo dice [np.float32(0.6845)] 
2025-08-28 09:21:30.144037: Epoch time: 16.88 s 
2025-08-28 09:21:30.770653:  
2025-08-28 09:21:30.779042: Epoch 284 
2025-08-28 09:21:30.783425: Current learning rate: 0.0074 
2025-08-28 09:21:47.796242: train_loss -0.2852 
2025-08-28 09:21:47.804318: val_loss -0.3129 
2025-08-28 09:21:47.812668: Pseudo dice [np.float32(0.4955)] 
2025-08-28 09:21:47.826002: Epoch time: 17.03 s 
2025-08-28 09:21:48.513339:  
2025-08-28 09:21:48.521707: Epoch 285 
2025-08-28 09:21:48.525753: Current learning rate: 0.00739 
2025-08-28 09:22:05.438761: train_loss -0.2746 
2025-08-28 09:22:05.451140: val_loss -0.307 
2025-08-28 09:22:05.455539: Pseudo dice [np.float32(0.6255)] 
2025-08-28 09:22:05.462993: Epoch time: 16.93 s 
2025-08-28 09:22:06.256028:  
2025-08-28 09:22:06.264375: Epoch 286 
2025-08-28 09:22:06.268527: Current learning rate: 0.00738 
2025-08-28 09:22:23.065522: train_loss -0.2664 
2025-08-28 09:22:23.074841: val_loss -0.2835 
2025-08-28 09:22:23.082167: Pseudo dice [np.float32(0.5698)] 
2025-08-28 09:22:23.092687: Epoch time: 16.81 s 
2025-08-28 09:22:23.736063:  
2025-08-28 09:22:23.744736: Epoch 287 
2025-08-28 09:22:23.749021: Current learning rate: 0.00738 
2025-08-28 09:22:40.628153: train_loss -0.3237 
2025-08-28 09:22:40.636506: val_loss -0.3939 
2025-08-28 09:22:40.644532: Pseudo dice [np.float32(0.6312)] 
2025-08-28 09:22:40.649863: Epoch time: 16.89 s 
2025-08-28 09:22:41.282661:  
2025-08-28 09:22:41.291013: Epoch 288 
2025-08-28 09:22:41.295170: Current learning rate: 0.00737 
2025-08-28 09:22:58.175039: train_loss -0.2881 
2025-08-28 09:22:58.187355: val_loss -0.3025 
2025-08-28 09:22:58.191586: Pseudo dice [np.float32(0.5625)] 
2025-08-28 09:22:58.198460: Epoch time: 16.89 s 
2025-08-28 09:22:58.829523:  
2025-08-28 09:22:58.838245: Epoch 289 
2025-08-28 09:22:58.842336: Current learning rate: 0.00736 
2025-08-28 09:23:15.792250: train_loss -0.2921 
2025-08-28 09:23:15.804676: val_loss -0.31 
2025-08-28 09:23:15.808808: Pseudo dice [np.float32(0.6116)] 
2025-08-28 09:23:15.816254: Epoch time: 16.97 s 
2025-08-28 09:23:16.476935:  
2025-08-28 09:23:16.484513: Epoch 290 
2025-08-28 09:23:16.493214: Current learning rate: 0.00735 
2025-08-28 09:23:33.430664: train_loss -0.3073 
2025-08-28 09:23:33.439281: val_loss -0.3851 
2025-08-28 09:23:33.443142: Pseudo dice [np.float32(0.6265)] 
2025-08-28 09:23:33.450203: Epoch time: 16.95 s 
2025-08-28 09:23:34.085428:  
2025-08-28 09:23:34.093728: Epoch 291 
2025-08-28 09:23:34.097921: Current learning rate: 0.00734 
2025-08-28 09:23:51.006101: train_loss -0.3066 
2025-08-28 09:23:51.014911: val_loss -0.3495 
2025-08-28 09:23:51.019055: Pseudo dice [np.float32(0.6274)] 
2025-08-28 09:23:51.027437: Epoch time: 16.92 s 
2025-08-28 09:23:51.665468:  
2025-08-28 09:23:51.673812: Epoch 292 
2025-08-28 09:23:51.677988: Current learning rate: 0.00733 
2025-08-28 09:24:08.849204: train_loss -0.2835 
2025-08-28 09:24:08.853558: val_loss -0.4146 
2025-08-28 09:24:08.861801: Pseudo dice [np.float32(0.5246)] 
2025-08-28 09:24:08.867518: Epoch time: 17.19 s 
2025-08-28 09:24:09.666779:  
2025-08-28 09:24:09.675477: Epoch 293 
2025-08-28 09:24:09.679277: Current learning rate: 0.00732 
2025-08-28 09:24:26.746478: train_loss -0.3187 
2025-08-28 09:24:26.754674: val_loss -0.3456 
2025-08-28 09:24:26.759044: Pseudo dice [np.float32(0.6114)] 
2025-08-28 09:24:26.765440: Epoch time: 17.08 s 
2025-08-28 09:24:27.405414:  
2025-08-28 09:24:27.413768: Epoch 294 
2025-08-28 09:24:27.417942: Current learning rate: 0.00731 
2025-08-28 09:24:44.341684: train_loss -0.2836 
2025-08-28 09:24:44.348133: val_loss -0.3 
2025-08-28 09:24:44.355594: Pseudo dice [np.float32(0.5568)] 
2025-08-28 09:24:44.361219: Epoch time: 16.94 s 
2025-08-28 09:24:45.002095:  
2025-08-28 09:24:45.010613: Epoch 295 
2025-08-28 09:24:45.014896: Current learning rate: 0.0073 
2025-08-28 09:25:01.777132: train_loss -0.2766 
2025-08-28 09:25:01.789669: val_loss -0.3491 
2025-08-28 09:25:01.794111: Pseudo dice [np.float32(0.5366)] 
2025-08-28 09:25:01.801274: Epoch time: 16.78 s 
2025-08-28 09:25:02.436177:  
2025-08-28 09:25:02.444841: Epoch 296 
2025-08-28 09:25:02.448686: Current learning rate: 0.00729 
2025-08-28 09:25:19.387952: train_loss -0.2894 
2025-08-28 09:25:19.394779: val_loss -0.3444 
2025-08-28 09:25:19.403097: Pseudo dice [np.float32(0.6347)] 
2025-08-28 09:25:19.409600: Epoch time: 16.95 s 
2025-08-28 09:25:20.045413:  
2025-08-28 09:25:20.053741: Epoch 297 
2025-08-28 09:25:20.058240: Current learning rate: 0.00728 
2025-08-28 09:25:36.712131: train_loss -0.3086 
2025-08-28 09:25:36.720733: val_loss -0.3602 
2025-08-28 09:25:36.725121: Pseudo dice [np.float32(0.6406)] 
2025-08-28 09:25:36.733788: Epoch time: 16.67 s 
2025-08-28 09:25:37.366850:  
2025-08-28 09:25:37.375208: Epoch 298 
2025-08-28 09:25:37.379347: Current learning rate: 0.00727 
2025-08-28 09:25:54.371333: train_loss -0.2961 
2025-08-28 09:25:54.379676: val_loss -0.3819 
2025-08-28 09:25:54.383841: Pseudo dice [np.float32(0.6279)] 
2025-08-28 09:25:54.392920: Epoch time: 17.0 s 
2025-08-28 09:25:55.026360:  
2025-08-28 09:25:55.034422: Epoch 299 
2025-08-28 09:25:55.039024: Current learning rate: 0.00726 
2025-08-28 09:26:11.934731: train_loss -0.3045 
2025-08-28 09:26:11.943048: val_loss -0.333 
2025-08-28 09:26:11.947468: Pseudo dice [np.float32(0.6145)] 
2025-08-28 09:26:11.954762: Epoch time: 16.91 s 
2025-08-28 09:26:12.931576:  
2025-08-28 09:26:12.939786: Epoch 300 
2025-08-28 09:26:12.944316: Current learning rate: 0.00725 
2025-08-28 09:26:29.251945: train_loss -0.2893 
2025-08-28 09:26:29.260617: val_loss -0.292 
2025-08-28 09:26:29.264826: Pseudo dice [np.float32(0.5589)] 
2025-08-28 09:26:29.271967: Epoch time: 16.32 s 
2025-08-28 09:26:29.919322:  
2025-08-28 09:26:29.928138: Epoch 301 
2025-08-28 09:26:29.931851: Current learning rate: 0.00724 
2025-08-28 09:26:45.931215: train_loss -0.3018 
2025-08-28 09:26:45.939510: val_loss -0.2623 
2025-08-28 09:26:45.943674: Pseudo dice [np.float32(0.5719)] 
2025-08-28 09:26:45.950996: Epoch time: 16.01 s 
2025-08-28 09:26:46.594329:  
2025-08-28 09:26:46.602695: Epoch 302 
2025-08-28 09:26:46.606868: Current learning rate: 0.00724 
2025-08-28 09:27:02.915003: train_loss -0.2962 
2025-08-28 09:27:02.927291: val_loss -0.307 
2025-08-28 09:27:02.935210: Pseudo dice [np.float32(0.5137)] 
2025-08-28 09:27:02.940666: Epoch time: 16.32 s 
2025-08-28 09:27:03.578171:  
2025-08-28 09:27:03.582128: Epoch 303 
2025-08-28 09:27:03.590859: Current learning rate: 0.00723 
2025-08-28 09:27:19.782000: train_loss -0.2891 
2025-08-28 09:27:19.790038: val_loss -0.2826 
2025-08-28 09:27:19.798382: Pseudo dice [np.float32(0.5345)] 
2025-08-28 09:27:19.803764: Epoch time: 16.21 s 
2025-08-28 09:27:20.444798:  
2025-08-28 09:27:20.453187: Epoch 304 
2025-08-28 09:27:20.457553: Current learning rate: 0.00722 
2025-08-28 09:27:36.690166: train_loss -0.3234 
2025-08-28 09:27:36.698599: val_loss -0.3259 
2025-08-28 09:27:36.702948: Pseudo dice [np.float32(0.6033)] 
2025-08-28 09:27:36.711904: Epoch time: 16.25 s 
2025-08-28 09:27:37.353345:  
2025-08-28 09:27:37.361687: Epoch 305 
2025-08-28 09:27:37.366197: Current learning rate: 0.00721 
2025-08-28 09:27:53.498710: train_loss -0.2917 
2025-08-28 09:27:53.507055: val_loss -0.3191 
2025-08-28 09:27:53.511138: Pseudo dice [np.float32(0.5574)] 
2025-08-28 09:27:53.518431: Epoch time: 16.15 s 
2025-08-28 09:27:54.316094:  
2025-08-28 09:27:54.324450: Epoch 306 
2025-08-28 09:27:54.328551: Current learning rate: 0.0072 
2025-08-28 09:28:10.636897: train_loss -0.2976 
2025-08-28 09:28:10.644938: val_loss -0.299 
2025-08-28 09:28:10.653572: Pseudo dice [np.float32(0.5564)] 
2025-08-28 09:28:10.659759: Epoch time: 16.32 s 
2025-08-28 09:28:11.299731:  
2025-08-28 09:28:11.308093: Epoch 307 
2025-08-28 09:28:11.312553: Current learning rate: 0.00719 
2025-08-28 09:28:27.478705: train_loss -0.3259 
2025-08-28 09:28:27.487116: val_loss -0.3554 
2025-08-28 09:28:27.496890: Pseudo dice [np.float32(0.6674)] 
2025-08-28 09:28:27.502308: Epoch time: 16.18 s 
2025-08-28 09:28:28.137390:  
2025-08-28 09:28:28.141560: Epoch 308 
2025-08-28 09:28:28.149935: Current learning rate: 0.00718 
2025-08-28 09:28:44.253460: train_loss -0.3171 
2025-08-28 09:28:44.261866: val_loss -0.357 
2025-08-28 09:28:44.265977: Pseudo dice [np.float32(0.5922)] 
2025-08-28 09:28:44.275133: Epoch time: 16.12 s 
2025-08-28 09:28:44.916627:  
2025-08-28 09:28:44.921449: Epoch 309 
2025-08-28 09:28:44.929163: Current learning rate: 0.00717 
2025-08-28 09:29:01.183220: train_loss -0.2852 
2025-08-28 09:29:01.195635: val_loss -0.2711 
2025-08-28 09:29:01.199955: Pseudo dice [np.float32(0.4785)] 
2025-08-28 09:29:01.206876: Epoch time: 16.27 s 
2025-08-28 09:29:01.842201:  
2025-08-28 09:29:01.846379: Epoch 310 
2025-08-28 09:29:01.854394: Current learning rate: 0.00716 
2025-08-28 09:29:17.846043: train_loss -0.2835 
2025-08-28 09:29:17.853699: val_loss -0.3473 
2025-08-28 09:29:17.858154: Pseudo dice [np.float32(0.6078)] 
2025-08-28 09:29:17.865965: Epoch time: 16.01 s 
2025-08-28 09:29:18.500176:  
2025-08-28 09:29:18.508569: Epoch 311 
2025-08-28 09:29:18.512731: Current learning rate: 0.00715 
2025-08-28 09:29:33.953621: train_loss -0.3065 
2025-08-28 09:29:33.961465: val_loss -0.3643 
2025-08-28 09:29:33.965607: Pseudo dice [np.float32(0.5689)] 
2025-08-28 09:29:33.974488: Epoch time: 15.45 s 
2025-08-28 09:29:34.596472:  
2025-08-28 09:29:34.604832: Epoch 312 
2025-08-28 09:29:34.609039: Current learning rate: 0.00714 
2025-08-28 09:29:49.816082: train_loss -0.3483 
2025-08-28 09:29:49.823684: val_loss -0.3396 
2025-08-28 09:29:49.827929: Pseudo dice [np.float32(0.5496)] 
2025-08-28 09:29:49.835810: Epoch time: 15.22 s 
2025-08-28 09:29:50.737621:  
2025-08-28 09:29:50.745939: Epoch 313 
2025-08-28 09:29:50.750530: Current learning rate: 0.00713 
2025-08-28 09:30:05.905828: train_loss -0.3042 
2025-08-28 09:30:05.914727: val_loss -0.3258 
2025-08-28 09:30:05.918911: Pseudo dice [np.float32(0.6108)] 
2025-08-28 09:30:05.926558: Epoch time: 15.17 s 
2025-08-28 09:30:06.545069:  
2025-08-28 09:30:06.553337: Epoch 314 
2025-08-28 09:30:06.558140: Current learning rate: 0.00712 
2025-08-28 09:30:21.622477: train_loss -0.2352 
2025-08-28 09:30:21.630483: val_loss -0.3972 
2025-08-28 09:30:21.634736: Pseudo dice [np.float32(0.6452)] 
2025-08-28 09:30:21.642398: Epoch time: 15.08 s 
2025-08-28 09:30:22.285982:  
2025-08-28 09:30:22.294909: Epoch 315 
2025-08-28 09:30:22.301348: Current learning rate: 0.00711 
2025-08-28 09:30:37.408844: train_loss -0.3137 
2025-08-28 09:30:37.416883: val_loss -0.327 
2025-08-28 09:30:37.424689: Pseudo dice [np.float32(0.5107)] 
2025-08-28 09:30:37.429557: Epoch time: 15.12 s 
2025-08-28 09:30:38.064054:  
2025-08-28 09:30:38.072388: Epoch 316 
2025-08-28 09:30:38.076552: Current learning rate: 0.0071 
2025-08-28 09:30:52.765653: train_loss -0.309 
2025-08-28 09:30:52.774004: val_loss -0.2533 
2025-08-28 09:30:52.782395: Pseudo dice [np.float32(0.4668)] 
2025-08-28 09:30:52.787579: Epoch time: 14.7 s 
2025-08-28 09:30:53.401620:  
2025-08-28 09:30:53.408861: Epoch 317 
2025-08-28 09:30:53.412748: Current learning rate: 0.0071 
2025-08-28 09:31:07.817656: train_loss -0.2918 
2025-08-28 09:31:07.826021: val_loss -0.3565 
2025-08-28 09:31:07.830185: Pseudo dice [np.float32(0.6211)] 
2025-08-28 09:31:07.838303: Epoch time: 14.42 s 
2025-08-28 09:31:08.469392:  
2025-08-28 09:31:08.477608: Epoch 318 
2025-08-28 09:31:08.481742: Current learning rate: 0.00709 
2025-08-28 09:31:23.729465: train_loss -0.2946 
2025-08-28 09:31:23.737967: val_loss -0.3734 
2025-08-28 09:31:23.741905: Pseudo dice [np.float32(0.6776)] 
2025-08-28 09:31:23.750553: Epoch time: 15.26 s 
2025-08-28 09:31:24.380831:  
2025-08-28 09:31:24.388390: Epoch 319 
2025-08-28 09:31:24.393451: Current learning rate: 0.00708 
2025-08-28 09:31:39.303276: train_loss -0.2695 
2025-08-28 09:31:39.311658: val_loss -0.3347 
2025-08-28 09:31:39.319969: Pseudo dice [np.float32(0.4448)] 
2025-08-28 09:31:39.325237: Epoch time: 14.92 s 
2025-08-28 09:31:40.125706:  
2025-08-28 09:31:40.133268: Epoch 320 
2025-08-28 09:31:40.138313: Current learning rate: 0.00707 
2025-08-28 09:31:55.073238: train_loss -0.2896 
2025-08-28 09:31:55.085701: val_loss -0.3237 
2025-08-28 09:31:55.089862: Pseudo dice [np.float32(0.5662)] 
2025-08-28 09:31:55.097769: Epoch time: 14.95 s 
2025-08-28 09:31:55.720556:  
2025-08-28 09:31:55.729419: Epoch 321 
2025-08-28 09:31:55.736351: Current learning rate: 0.00706 
2025-08-28 09:32:11.009912: train_loss -0.285 
2025-08-28 09:32:11.018275: val_loss -0.317 
2025-08-28 09:32:11.022436: Pseudo dice [np.float32(0.5784)] 
2025-08-28 09:32:11.029840: Epoch time: 15.29 s 
2025-08-28 09:32:11.657303:  
2025-08-28 09:32:11.664675: Epoch 322 
2025-08-28 09:32:11.670062: Current learning rate: 0.00705 
2025-08-28 09:32:26.504568: train_loss -0.2903 
2025-08-28 09:32:26.515148: val_loss -0.3832 
2025-08-28 09:32:26.521250: Pseudo dice [np.float32(0.5733)] 
2025-08-28 09:32:26.527514: Epoch time: 14.85 s 
2025-08-28 09:32:27.160245:  
2025-08-28 09:32:27.167648: Epoch 323 
2025-08-28 09:32:27.172700: Current learning rate: 0.00704 
2025-08-28 09:32:41.332135: train_loss -0.2915 
2025-08-28 09:32:41.340207: val_loss -0.3394 
2025-08-28 09:32:41.344385: Pseudo dice [np.float32(0.6377)] 
2025-08-28 09:32:41.353019: Epoch time: 14.17 s 
2025-08-28 09:32:41.982479:  
2025-08-28 09:32:41.990803: Epoch 324 
2025-08-28 09:32:41.996099: Current learning rate: 0.00703 
2025-08-28 09:32:56.823017: train_loss -0.2794 
2025-08-28 09:32:56.835210: val_loss -0.2568 
2025-08-28 09:32:56.841146: Pseudo dice [np.float32(0.506)] 
2025-08-28 09:32:56.848470: Epoch time: 14.84 s 
2025-08-28 09:32:57.539648:  
2025-08-28 09:32:57.548062: Epoch 325 
2025-08-28 09:32:57.553233: Current learning rate: 0.00702 
2025-08-28 09:33:13.439121: train_loss -0.304 
2025-08-28 09:33:13.447284: val_loss -0.29 
2025-08-28 09:33:13.451353: Pseudo dice [np.float32(0.5096)] 
2025-08-28 09:33:13.460115: Epoch time: 15.9 s 
2025-08-28 09:33:14.232581:  
2025-08-28 09:33:14.239743: Epoch 326 
2025-08-28 09:33:14.244961: Current learning rate: 0.00701 
2025-08-28 09:33:29.380453: train_loss -0.2648 
2025-08-28 09:33:29.388191: val_loss -0.3313 
2025-08-28 09:33:29.396537: Pseudo dice [np.float32(0.5903)] 
2025-08-28 09:33:29.402806: Epoch time: 15.15 s 
2025-08-28 09:33:30.035584:  
2025-08-28 09:33:30.044095: Epoch 327 
2025-08-28 09:33:30.048237: Current learning rate: 0.007 
2025-08-28 09:33:45.980322: train_loss -0.2954 
2025-08-28 09:33:45.988088: val_loss -0.3846 
2025-08-28 09:33:45.996411: Pseudo dice [np.float32(0.6631)] 
2025-08-28 09:33:46.001685: Epoch time: 15.94 s 
2025-08-28 09:33:46.643983:  
2025-08-28 09:33:46.652266: Epoch 328 
2025-08-28 09:33:46.659502: Current learning rate: 0.00699 
2025-08-28 09:34:00.581831: train_loss -0.2923 
2025-08-28 09:34:00.591949: val_loss -0.3013 
2025-08-28 09:34:00.598892: Pseudo dice [np.float32(0.527)] 
2025-08-28 09:34:00.604116: Epoch time: 13.94 s 
2025-08-28 09:34:01.229304:  
2025-08-28 09:34:01.237780: Epoch 329 
2025-08-28 09:34:01.242254: Current learning rate: 0.00698 
2025-08-28 09:34:15.805373: train_loss -0.2842 
2025-08-28 09:34:15.813721: val_loss -0.4017 
2025-08-28 09:34:15.822062: Pseudo dice [np.float32(0.6439)] 
2025-08-28 09:34:15.828853: Epoch time: 14.58 s 
2025-08-28 09:34:16.488240:  
2025-08-28 09:34:16.495599: Epoch 330 
2025-08-28 09:34:16.501731: Current learning rate: 0.00697 
2025-08-28 09:34:30.666107: train_loss -0.2997 
2025-08-28 09:34:30.674383: val_loss -0.3919 
2025-08-28 09:34:30.678544: Pseudo dice [np.float32(0.7168)] 
2025-08-28 09:34:30.685880: Epoch time: 14.18 s 
2025-08-28 09:34:31.324895:  
2025-08-28 09:34:31.333213: Epoch 331 
2025-08-28 09:34:31.340641: Current learning rate: 0.00696 
2025-08-28 09:34:45.126307: train_loss -0.3439 
2025-08-28 09:34:45.134656: val_loss -0.3192 
2025-08-28 09:34:45.142975: Pseudo dice [np.float32(0.5391)] 
2025-08-28 09:34:45.148239: Epoch time: 13.8 s 
2025-08-28 09:34:45.777986:  
2025-08-28 09:34:45.786393: Epoch 332 
2025-08-28 09:34:45.792475: Current learning rate: 0.00696 
2025-08-28 09:34:59.887280: train_loss -0.3065 
2025-08-28 09:34:59.895214: val_loss -0.3117 
2025-08-28 09:34:59.904211: Pseudo dice [np.float32(0.5463)] 
2025-08-28 09:34:59.909825: Epoch time: 14.11 s 
2025-08-28 09:35:00.725098:  
2025-08-28 09:35:00.735577: Epoch 333 
2025-08-28 09:35:00.743080: Current learning rate: 0.00695 
2025-08-28 09:35:14.730781: train_loss -0.2652 
2025-08-28 09:35:14.739237: val_loss -0.3257 
2025-08-28 09:35:14.747568: Pseudo dice [np.float32(0.6434)] 
2025-08-28 09:35:14.752842: Epoch time: 14.01 s 
2025-08-28 09:35:15.383591:  
2025-08-28 09:35:15.390982: Epoch 334 
2025-08-28 09:35:15.398046: Current learning rate: 0.00694 
2025-08-28 09:35:29.337162: train_loss -0.2802 
2025-08-28 09:35:29.341284: val_loss -0.3823 
2025-08-28 09:35:29.349663: Pseudo dice [np.float32(0.613)] 
2025-08-28 09:35:29.356391: Epoch time: 13.95 s 
2025-08-28 09:35:29.994081:  
2025-08-28 09:35:30.002388: Epoch 335 
2025-08-28 09:35:30.008445: Current learning rate: 0.00693 
2025-08-28 09:35:44.072735: train_loss -0.292 
2025-08-28 09:35:44.081036: val_loss -0.2894 
2025-08-28 09:35:44.085127: Pseudo dice [np.float32(0.6172)] 
2025-08-28 09:35:44.094318: Epoch time: 14.08 s 
2025-08-28 09:35:44.742992:  
2025-08-28 09:35:44.749330: Epoch 336 
2025-08-28 09:35:44.755520: Current learning rate: 0.00692 
2025-08-28 09:35:59.951418: train_loss -0.3324 
2025-08-28 09:35:59.963250: val_loss -0.3834 
2025-08-28 09:35:59.967759: Pseudo dice [np.float32(0.6807)] 
2025-08-28 09:35:59.973953: Epoch time: 15.21 s 
2025-08-28 09:35:59.980178: Yayy! New best EMA pseudo Dice: 0.6025999784469604 
2025-08-28 09:36:02.301269:  
2025-08-28 09:36:02.309595: Epoch 337 
2025-08-28 09:36:02.315367: Current learning rate: 0.00691 
2025-08-28 09:36:16.492752: train_loss -0.2885 
2025-08-28 09:36:16.501183: val_loss -0.3341 
2025-08-28 09:36:16.509268: Pseudo dice [np.float32(0.6291)] 
2025-08-28 09:36:16.516012: Epoch time: 14.19 s 
2025-08-28 09:36:16.522037: Yayy! New best EMA pseudo Dice: 0.6053000092506409 
2025-08-28 09:36:17.476729:  
2025-08-28 09:36:17.486350: Epoch 338 
2025-08-28 09:36:17.495278: Current learning rate: 0.0069 
2025-08-28 09:36:31.399018: train_loss -0.3282 
2025-08-28 09:36:31.407461: val_loss -0.3762 
2025-08-28 09:36:31.411577: Pseudo dice [np.float32(0.6626)] 
2025-08-28 09:36:31.419935: Epoch time: 13.92 s 
2025-08-28 09:36:31.422581: Yayy! New best EMA pseudo Dice: 0.6110000014305115 
2025-08-28 09:36:32.690131:  
2025-08-28 09:36:32.699996: Epoch 339 
2025-08-28 09:36:32.709985: Current learning rate: 0.00689 
2025-08-28 09:36:46.706414: train_loss -0.3021 
2025-08-28 09:36:46.714407: val_loss -0.398 
2025-08-28 09:36:46.722720: Pseudo dice [np.float32(0.6442)] 
2025-08-28 09:36:46.726892: Epoch time: 14.02 s 
2025-08-28 09:36:46.732675: Yayy! New best EMA pseudo Dice: 0.614300012588501 
2025-08-28 09:36:47.694363:  
2025-08-28 09:36:47.702711: Epoch 340 
2025-08-28 09:36:47.708114: Current learning rate: 0.00688 
2025-08-28 09:37:01.766926: train_loss -0.2976 
2025-08-28 09:37:01.779730: val_loss -0.3503 
2025-08-28 09:37:01.783543: Pseudo dice [np.float32(0.5624)] 
2025-08-28 09:37:01.792121: Epoch time: 14.07 s 
2025-08-28 09:37:02.430004:  
2025-08-28 09:37:02.439466: Epoch 341 
2025-08-28 09:37:02.446610: Current learning rate: 0.00687 
2025-08-28 09:37:16.318782: train_loss -0.3181 
2025-08-28 09:37:16.327348: val_loss -0.3235 
2025-08-28 09:37:16.331702: Pseudo dice [np.float32(0.6015)] 
2025-08-28 09:37:16.338177: Epoch time: 13.89 s 
2025-08-28 09:37:16.979002:  
2025-08-28 09:37:16.988298: Epoch 342 
2025-08-28 09:37:16.996656: Current learning rate: 0.00686 
2025-08-28 09:37:31.191897: train_loss -0.3076 
2025-08-28 09:37:31.200396: val_loss -0.4129 
2025-08-28 09:37:31.204842: Pseudo dice [np.float32(0.6733)] 
2025-08-28 09:37:31.211910: Epoch time: 14.22 s 
2025-08-28 09:37:31.217575: Yayy! New best EMA pseudo Dice: 0.6148999929428101 
2025-08-28 09:37:32.049223:  
2025-08-28 09:37:32.057562: Epoch 343 
2025-08-28 09:37:32.064873: Current learning rate: 0.00685 
2025-08-28 09:37:46.953692: train_loss -0.3061 
2025-08-28 09:37:46.962318: val_loss -0.2969 
2025-08-28 09:37:46.970354: Pseudo dice [np.float32(0.5793)] 
2025-08-28 09:37:46.975607: Epoch time: 14.91 s 
2025-08-28 09:37:47.625108:  
2025-08-28 09:37:47.633370: Epoch 344 
2025-08-28 09:37:47.641845: Current learning rate: 0.00684 
2025-08-28 09:38:03.320187: train_loss -0.3067 
2025-08-28 09:38:03.328382: val_loss -0.2922 
2025-08-28 09:38:03.332543: Pseudo dice [np.float32(0.6046)] 
2025-08-28 09:38:03.341521: Epoch time: 15.7 s 
2025-08-28 09:38:04.145756:  
2025-08-28 09:38:04.154036: Epoch 345 
2025-08-28 09:38:04.160385: Current learning rate: 0.00683 
2025-08-28 09:38:19.820179: train_loss -0.292 
2025-08-28 09:38:19.828169: val_loss -0.4054 
2025-08-28 09:38:19.836481: Pseudo dice [np.float32(0.6517)] 
2025-08-28 09:38:19.841792: Epoch time: 15.68 s 
2025-08-28 09:38:20.535125:  
2025-08-28 09:38:20.542416: Epoch 346 
2025-08-28 09:38:20.549603: Current learning rate: 0.00682 
2025-08-28 09:38:37.383428: train_loss -0.2902 
2025-08-28 09:38:37.391541: val_loss -0.2438 
2025-08-28 09:38:37.399875: Pseudo dice [np.float32(0.4286)] 
2025-08-28 09:38:37.405158: Epoch time: 16.85 s 
2025-08-28 09:38:38.102678:  
2025-08-28 09:38:38.110155: Epoch 347 
2025-08-28 09:38:38.118383: Current learning rate: 0.00681 
2025-08-28 09:38:54.908586: train_loss -0.2805 
2025-08-28 09:38:54.917440: val_loss -0.2976 
2025-08-28 09:38:54.921549: Pseudo dice [np.float32(0.533)] 
2025-08-28 09:38:54.929655: Epoch time: 16.81 s 
2025-08-28 09:38:55.623272:  
2025-08-28 09:38:55.631639: Epoch 348 
2025-08-28 09:38:55.640023: Current learning rate: 0.0068 
2025-08-28 09:39:12.618943: train_loss -0.3076 
2025-08-28 09:39:12.626725: val_loss -0.2878 
2025-08-28 09:39:12.630881: Pseudo dice [np.float32(0.5213)] 
2025-08-28 09:39:12.640141: Epoch time: 17.0 s 
2025-08-28 09:39:13.349369:  
2025-08-28 09:39:13.358725: Epoch 349 
2025-08-28 09:39:13.367140: Current learning rate: 0.0068 
2025-08-28 09:39:30.036055: train_loss -0.3233 
2025-08-28 09:39:30.044125: val_loss -0.3519 
2025-08-28 09:39:30.048606: Pseudo dice [np.float32(0.6581)] 
2025-08-28 09:39:30.055576: Epoch time: 16.69 s 
2025-08-28 09:39:30.926189:  
2025-08-28 09:39:30.933607: Epoch 350 
2025-08-28 09:39:30.938755: Current learning rate: 0.00679 
2025-08-28 09:39:47.662047: train_loss -0.3059 
2025-08-28 09:39:47.670038: val_loss -0.3689 
2025-08-28 09:39:47.674214: Pseudo dice [np.float32(0.6566)] 
2025-08-28 09:39:47.682670: Epoch time: 16.74 s 
2025-08-28 09:39:48.381085:  
2025-08-28 09:39:48.390452: Epoch 351 
2025-08-28 09:39:48.397804: Current learning rate: 0.00678 
2025-08-28 09:40:05.204214: train_loss -0.3015 
2025-08-28 09:40:05.216806: val_loss -0.34 
2025-08-28 09:40:05.220937: Pseudo dice [np.float32(0.6745)] 
2025-08-28 09:40:05.228902: Epoch time: 16.82 s 
2025-08-28 09:40:06.085355:  
2025-08-28 09:40:06.092574: Epoch 352 
2025-08-28 09:40:06.097816: Current learning rate: 0.00677 
2025-08-28 09:40:22.730360: train_loss -0.307 
2025-08-28 09:40:22.738435: val_loss -0.2798 
2025-08-28 09:40:22.742606: Pseudo dice [np.float32(0.447)] 
2025-08-28 09:40:22.750503: Epoch time: 16.65 s 
2025-08-28 09:40:23.488125:  
2025-08-28 09:40:23.497331: Epoch 353 
2025-08-28 09:40:23.504694: Current learning rate: 0.00676 
2025-08-28 09:40:40.222498: train_loss -0.3099 
2025-08-28 09:40:40.230844: val_loss -0.4179 
2025-08-28 09:40:40.239196: Pseudo dice [np.float32(0.6357)] 
2025-08-28 09:40:40.245428: Epoch time: 16.74 s 
2025-08-28 09:40:40.937736:  
2025-08-28 09:40:40.945060: Epoch 354 
2025-08-28 09:40:40.952276: Current learning rate: 0.00675 
2025-08-28 09:40:58.273854: train_loss -0.3358 
2025-08-28 09:40:58.286378: val_loss -0.3215 
2025-08-28 09:40:58.290835: Pseudo dice [np.float32(0.5956)] 
2025-08-28 09:40:58.298892: Epoch time: 17.34 s 
2025-08-28 09:40:58.993558:  
2025-08-28 09:40:59.002517: Epoch 355 
2025-08-28 09:40:59.007949: Current learning rate: 0.00674 
2025-08-28 09:41:15.699652: train_loss -0.3285 
2025-08-28 09:41:15.707939: val_loss -0.3586 
2025-08-28 09:41:15.716131: Pseudo dice [np.float32(0.4866)] 
2025-08-28 09:41:15.721530: Epoch time: 16.71 s 
2025-08-28 09:41:16.418039:  
2025-08-28 09:41:16.425566: Epoch 356 
2025-08-28 09:41:16.430513: Current learning rate: 0.00673 
2025-08-28 09:41:33.476425: train_loss -0.2966 
2025-08-28 09:41:33.484031: val_loss -0.3479 
2025-08-28 09:41:33.488208: Pseudo dice [np.float32(0.6111)] 
2025-08-28 09:41:33.496531: Epoch time: 17.06 s 
2025-08-28 09:41:34.205474:  
2025-08-28 09:41:34.213886: Epoch 357 
2025-08-28 09:41:34.219212: Current learning rate: 0.00672 
2025-08-28 09:41:51.151733: train_loss -0.3064 
2025-08-28 09:41:51.160059: val_loss -0.3812 
2025-08-28 09:41:51.168407: Pseudo dice [np.float32(0.5862)] 
2025-08-28 09:41:51.174607: Epoch time: 16.95 s 
2025-08-28 09:41:52.021244:  
2025-08-28 09:41:52.030660: Epoch 358 
2025-08-28 09:41:52.035726: Current learning rate: 0.00671 
2025-08-28 09:42:08.581583: train_loss -0.3105 
2025-08-28 09:42:08.589917: val_loss -0.3293 
2025-08-28 09:42:08.594051: Pseudo dice [np.float32(0.5324)] 
2025-08-28 09:42:08.601449: Epoch time: 16.56 s 
2025-08-28 09:42:09.301064:  
2025-08-28 09:42:09.309297: Epoch 359 
2025-08-28 09:42:09.315444: Current learning rate: 0.0067 
2025-08-28 09:42:25.903001: train_loss -0.3055 
2025-08-28 09:42:25.911393: val_loss -0.329 
2025-08-28 09:42:25.915554: Pseudo dice [np.float32(0.6079)] 
2025-08-28 09:42:25.923570: Epoch time: 16.6 s 
2025-08-28 09:42:26.633956:  
2025-08-28 09:42:26.642660: Epoch 360 
2025-08-28 09:42:26.648477: Current learning rate: 0.00669 
2025-08-28 09:42:43.437299: train_loss -0.2883 
2025-08-28 09:42:43.445532: val_loss -0.325 
2025-08-28 09:42:43.453921: Pseudo dice [np.float32(0.5896)] 
2025-08-28 09:42:43.459139: Epoch time: 16.81 s 
2025-08-28 09:42:44.166939:  
2025-08-28 09:42:44.179612: Epoch 361 
2025-08-28 09:42:44.187567: Current learning rate: 0.00668 
2025-08-28 09:43:01.100669: train_loss -0.2923 
2025-08-28 09:43:01.109033: val_loss -0.3564 
2025-08-28 09:43:01.113286: Pseudo dice [np.float32(0.6259)] 
2025-08-28 09:43:01.121278: Epoch time: 16.94 s 
2025-08-28 09:43:01.817973:  
2025-08-28 09:43:01.826572: Epoch 362 
2025-08-28 09:43:01.832615: Current learning rate: 0.00667 
2025-08-28 09:43:18.522609: train_loss -0.3026 
2025-08-28 09:43:18.530589: val_loss -0.3461 
2025-08-28 09:43:18.539310: Pseudo dice [np.float32(0.582)] 
2025-08-28 09:43:18.545158: Epoch time: 16.71 s 
2025-08-28 09:43:19.275000:  
2025-08-28 09:43:19.281210: Epoch 363 
2025-08-28 09:43:19.288678: Current learning rate: 0.00666 
2025-08-28 09:43:36.198217: train_loss -0.3047 
2025-08-28 09:43:36.206548: val_loss -0.3591 
2025-08-28 09:43:36.210706: Pseudo dice [np.float32(0.6467)] 
2025-08-28 09:43:36.219312: Epoch time: 16.93 s 
2025-08-28 09:43:37.069898:  
2025-08-28 09:43:37.076021: Epoch 364 
2025-08-28 09:43:37.082880: Current learning rate: 0.00665 
2025-08-28 09:43:53.695035: train_loss -0.316 
2025-08-28 09:43:53.703517: val_loss -0.3799 
2025-08-28 09:43:53.711594: Pseudo dice [np.float32(0.5383)] 
2025-08-28 09:43:53.716898: Epoch time: 16.63 s 
2025-08-28 09:43:54.411314:  
2025-08-28 09:43:54.420633: Epoch 365 
2025-08-28 09:43:54.426956: Current learning rate: 0.00665 
2025-08-28 09:44:11.341687: train_loss -0.2826 
2025-08-28 09:44:11.349951: val_loss -0.3403 
2025-08-28 09:44:11.354122: Pseudo dice [np.float32(0.5566)] 
2025-08-28 09:44:11.361371: Epoch time: 16.93 s 
2025-08-28 09:44:12.057885:  
2025-08-28 09:44:12.065203: Epoch 366 
2025-08-28 09:44:12.070341: Current learning rate: 0.00664 
2025-08-28 09:44:28.834212: train_loss -0.2835 
2025-08-28 09:44:28.842487: val_loss -0.2999 
2025-08-28 09:44:28.846852: Pseudo dice [np.float32(0.5354)] 
2025-08-28 09:44:28.853868: Epoch time: 16.78 s 
2025-08-28 09:44:29.560821:  
2025-08-28 09:44:29.567999: Epoch 367 
2025-08-28 09:44:29.574437: Current learning rate: 0.00663 
2025-08-28 09:44:46.622386: train_loss -0.3339 
2025-08-28 09:44:46.631375: val_loss -0.3152 
2025-08-28 09:44:46.635918: Pseudo dice [np.float32(0.5811)] 
2025-08-28 09:44:46.643903: Epoch time: 17.06 s 
2025-08-28 09:44:47.378632:  
2025-08-28 09:44:47.385809: Epoch 368 
2025-08-28 09:44:47.393139: Current learning rate: 0.00662 
2025-08-28 09:45:04.118877: train_loss -0.3074 
2025-08-28 09:45:04.127680: val_loss -0.3294 
2025-08-28 09:45:04.135531: Pseudo dice [np.float32(0.6211)] 
2025-08-28 09:45:04.141428: Epoch time: 16.74 s 
2025-08-28 09:45:04.863742:  
2025-08-28 09:45:04.876305: Epoch 369 
2025-08-28 09:45:04.888749: Current learning rate: 0.00661 
2025-08-28 09:45:21.820266: train_loss -0.3192 
2025-08-28 09:45:21.828667: val_loss -0.3209 
2025-08-28 09:45:21.832812: Pseudo dice [np.float32(0.537)] 
2025-08-28 09:45:21.842299: Epoch time: 16.96 s 
2025-08-28 09:45:22.551309:  
2025-08-28 09:45:22.560767: Epoch 370 
2025-08-28 09:45:22.566810: Current learning rate: 0.0066 
2025-08-28 09:45:39.354525: train_loss -0.3148 
2025-08-28 09:45:39.363101: val_loss -0.365 
2025-08-28 09:45:39.366997: Pseudo dice [np.float32(0.6303)] 
2025-08-28 09:45:39.375507: Epoch time: 16.81 s 
2025-08-28 09:45:40.279363:  
2025-08-28 09:45:40.291805: Epoch 371 
2025-08-28 09:45:40.302415: Current learning rate: 0.00659 
2025-08-28 09:45:57.085005: train_loss -0.2967 
2025-08-28 09:45:57.093039: val_loss -0.3345 
2025-08-28 09:45:57.097533: Pseudo dice [np.float32(0.5434)] 
2025-08-28 09:45:57.104493: Epoch time: 16.81 s 
2025-08-28 09:45:57.801497:  
2025-08-28 09:45:57.813727: Epoch 372 
2025-08-28 09:45:57.823035: Current learning rate: 0.00658 
2025-08-28 09:46:14.410625: train_loss -0.3128 
2025-08-28 09:46:14.418683: val_loss -0.3126 
2025-08-28 09:46:14.427027: Pseudo dice [np.float32(0.634)] 
2025-08-28 09:46:14.433680: Epoch time: 16.61 s 
2025-08-28 09:46:15.133975:  
2025-08-28 09:46:15.141325: Epoch 373 
2025-08-28 09:46:15.145458: Current learning rate: 0.00657 
2025-08-28 09:46:31.815519: train_loss -0.3229 
2025-08-28 09:46:31.823602: val_loss -0.2802 
2025-08-28 09:46:31.828091: Pseudo dice [np.float32(0.5956)] 
2025-08-28 09:46:31.835175: Epoch time: 16.68 s 
2025-08-28 09:46:32.539860:  
2025-08-28 09:46:32.548141: Epoch 374 
2025-08-28 09:46:32.553397: Current learning rate: 0.00656 
2025-08-28 09:46:49.265956: train_loss -0.3471 
2025-08-28 09:46:49.274386: val_loss -0.3617 
2025-08-28 09:46:49.278527: Pseudo dice [np.float32(0.6607)] 
2025-08-28 09:46:49.285661: Epoch time: 16.73 s 
2025-08-28 09:46:49.983226:  
2025-08-28 09:46:49.991536: Epoch 375 
2025-08-28 09:46:49.996900: Current learning rate: 0.00655 
2025-08-28 09:47:06.558388: train_loss -0.3252 
2025-08-28 09:47:06.566610: val_loss -0.3487 
2025-08-28 09:47:06.574956: Pseudo dice [np.float32(0.6547)] 
2025-08-28 09:47:06.580223: Epoch time: 16.58 s 
2025-08-28 09:47:07.289257:  
2025-08-28 09:47:07.297562: Epoch 376 
2025-08-28 09:47:07.302645: Current learning rate: 0.00654 
2025-08-28 09:47:24.334308: train_loss -0.3002 
2025-08-28 09:47:24.342665: val_loss -0.3442 
2025-08-28 09:47:24.346829: Pseudo dice [np.float32(0.5468)] 
2025-08-28 09:47:24.354262: Epoch time: 17.05 s 
2025-08-28 09:47:25.247714:  
2025-08-28 09:47:25.254927: Epoch 377 
2025-08-28 09:47:25.266839: Current learning rate: 0.00653 
2025-08-28 09:47:42.082077: train_loss -0.3081 
2025-08-28 09:47:42.089540: val_loss -0.3528 
2025-08-28 09:47:42.094031: Pseudo dice [np.float32(0.5701)] 
2025-08-28 09:47:42.101835: Epoch time: 16.84 s 
2025-08-28 09:47:42.807988:  
2025-08-28 09:47:42.815101: Epoch 378 
2025-08-28 09:47:42.821449: Current learning rate: 0.00652 
2025-08-28 09:47:59.511139: train_loss -0.2948 
2025-08-28 09:47:59.519737: val_loss -0.3071 
2025-08-28 09:47:59.527827: Pseudo dice [np.float32(0.6165)] 
2025-08-28 09:47:59.533105: Epoch time: 16.71 s 
2025-08-28 09:48:00.226312:  
2025-08-28 09:48:00.235773: Epoch 379 
2025-08-28 09:48:00.240833: Current learning rate: 0.00651 
2025-08-28 09:48:16.803349: train_loss -0.2927 
2025-08-28 09:48:16.807853: val_loss -0.2934 
2025-08-28 09:48:16.816150: Pseudo dice [np.float32(0.3862)] 
2025-08-28 09:48:16.823185: Epoch time: 16.58 s 
2025-08-28 09:48:17.534343:  
2025-08-28 09:48:17.543624: Epoch 380 
2025-08-28 09:48:17.554291: Current learning rate: 0.0065 
2025-08-28 09:48:34.612811: train_loss -0.3066 
2025-08-28 09:48:34.621156: val_loss -0.3562 
2025-08-28 09:48:34.630167: Pseudo dice [np.float32(0.5757)] 
2025-08-28 09:48:34.635769: Epoch time: 17.08 s 
2025-08-28 09:48:35.332223:  
2025-08-28 09:48:35.340547: Epoch 381 
2025-08-28 09:48:35.346741: Current learning rate: 0.00649 
2025-08-28 09:48:52.172026: train_loss -0.2899 
2025-08-28 09:48:52.180673: val_loss -0.3313 
2025-08-28 09:48:52.188686: Pseudo dice [np.float32(0.6711)] 
2025-08-28 09:48:52.193905: Epoch time: 16.84 s 
2025-08-28 09:48:52.901761:  
2025-08-28 09:48:52.910115: Epoch 382 
2025-08-28 09:48:52.915568: Current learning rate: 0.00648 
2025-08-28 09:49:09.848026: train_loss -0.3163 
2025-08-28 09:49:09.856321: val_loss -0.2714 
2025-08-28 09:49:09.864688: Pseudo dice [np.float32(0.4307)] 
2025-08-28 09:49:09.869930: Epoch time: 16.95 s 
2025-08-28 09:49:10.751928:  
2025-08-28 09:49:10.768574: Epoch 383 
2025-08-28 09:49:10.786803: Current learning rate: 0.00648 
2025-08-28 09:49:27.761989: train_loss -0.2999 
2025-08-28 09:49:27.770062: val_loss -0.4063 
2025-08-28 09:49:27.776593: Pseudo dice [np.float32(0.712)] 
2025-08-28 09:49:27.782447: Epoch time: 17.01 s 
2025-08-28 09:49:28.472838:  
2025-08-28 09:49:28.481200: Epoch 384 
2025-08-28 09:49:28.486272: Current learning rate: 0.00647 
2025-08-28 09:49:45.387621: train_loss -0.3144 
2025-08-28 09:49:45.396040: val_loss -0.3128 
2025-08-28 09:49:45.400487: Pseudo dice [np.float32(0.6379)] 
2025-08-28 09:49:45.407242: Epoch time: 16.92 s 
2025-08-28 09:49:46.173793:  
2025-08-28 09:49:46.181140: Epoch 385 
2025-08-28 09:49:46.188312: Current learning rate: 0.00646 
2025-08-28 09:50:02.834306: train_loss -0.3376 
2025-08-28 09:50:02.846679: val_loss -0.3475 
2025-08-28 09:50:02.851107: Pseudo dice [np.float32(0.6202)] 
2025-08-28 09:50:02.859513: Epoch time: 16.66 s 
2025-08-28 09:50:03.573610:  
2025-08-28 09:50:03.583039: Epoch 386 
2025-08-28 09:50:03.592216: Current learning rate: 0.00645 
2025-08-28 09:50:20.347489: train_loss -0.2929 
2025-08-28 09:50:20.355895: val_loss -0.3228 
2025-08-28 09:50:20.364542: Pseudo dice [np.float32(0.5254)] 
2025-08-28 09:50:20.369507: Epoch time: 16.78 s 
2025-08-28 09:50:21.069077:  
2025-08-28 09:50:21.079465: Epoch 387 
2025-08-28 09:50:21.086894: Current learning rate: 0.00644 
2025-08-28 09:50:37.539673: train_loss -0.2751 
2025-08-28 09:50:37.548058: val_loss -0.341 
2025-08-28 09:50:37.556400: Pseudo dice [np.float32(0.6666)] 
2025-08-28 09:50:37.561689: Epoch time: 16.47 s 
2025-08-28 09:50:38.270609:  
2025-08-28 09:50:38.278976: Epoch 388 
2025-08-28 09:50:38.285172: Current learning rate: 0.00643 
2025-08-28 09:50:55.207547: train_loss -0.3209 
2025-08-28 09:50:55.219877: val_loss -0.3557 
2025-08-28 09:50:55.224048: Pseudo dice [np.float32(0.5935)] 
2025-08-28 09:50:55.231407: Epoch time: 16.94 s 
2025-08-28 09:50:56.106153:  
2025-08-28 09:50:56.118760: Epoch 389 
2025-08-28 09:50:56.131462: Current learning rate: 0.00642 
2025-08-28 09:51:12.854416: train_loss -0.3353 
2025-08-28 09:51:12.862796: val_loss -0.3347 
2025-08-28 09:51:12.871177: Pseudo dice [np.float32(0.5015)] 
2025-08-28 09:51:12.876101: Epoch time: 16.75 s 
2025-08-28 09:51:13.585093:  
2025-08-28 09:51:13.592227: Epoch 390 
2025-08-28 09:51:13.600758: Current learning rate: 0.00641 
2025-08-28 09:51:30.471796: train_loss -0.3173 
2025-08-28 09:51:30.480131: val_loss -0.3549 
2025-08-28 09:51:30.488659: Pseudo dice [np.float32(0.6266)] 
2025-08-28 09:51:30.495763: Epoch time: 16.89 s 
2025-08-28 09:51:31.217480:  
2025-08-28 09:51:31.230750: Epoch 391 
2025-08-28 09:51:31.238819: Current learning rate: 0.0064 
2025-08-28 09:51:47.931572: train_loss -0.295 
2025-08-28 09:51:47.939475: val_loss -0.2982 
2025-08-28 09:51:47.947520: Pseudo dice [np.float32(0.5786)] 
2025-08-28 09:51:47.953720: Epoch time: 16.72 s 
2025-08-28 09:51:48.661806:  
2025-08-28 09:51:48.670072: Epoch 392 
2025-08-28 09:51:48.675279: Current learning rate: 0.00639 
2025-08-28 09:52:05.502254: train_loss -0.3187 
2025-08-28 09:52:05.510928: val_loss -0.3293 
2025-08-28 09:52:05.518884: Pseudo dice [np.float32(0.6292)] 
2025-08-28 09:52:05.524487: Epoch time: 16.84 s 
2025-08-28 09:52:06.284527:  
2025-08-28 09:52:06.293879: Epoch 393 
2025-08-28 09:52:06.301185: Current learning rate: 0.00638 
2025-08-28 09:52:23.437093: train_loss -0.3057 
2025-08-28 09:52:23.445439: val_loss -0.3254 
2025-08-28 09:52:23.454019: Pseudo dice [np.float32(0.4758)] 
2025-08-28 09:52:23.460056: Epoch time: 17.15 s 
2025-08-28 09:52:24.186080:  
2025-08-28 09:52:24.193062: Epoch 394 
2025-08-28 09:52:24.199284: Current learning rate: 0.00637 
2025-08-28 09:52:40.862868: train_loss -0.2933 
2025-08-28 09:52:40.873222: val_loss -0.279 
2025-08-28 09:52:40.880551: Pseudo dice [np.float32(0.5204)] 
2025-08-28 09:52:40.888919: Epoch time: 16.68 s 
2025-08-28 09:52:41.645856:  
2025-08-28 09:52:41.653139: Epoch 395 
2025-08-28 09:52:41.658311: Current learning rate: 0.00636 
2025-08-28 09:52:58.251001: train_loss -0.2881 
2025-08-28 09:52:58.263572: val_loss -0.292 
2025-08-28 09:52:58.267760: Pseudo dice [np.float32(0.6229)] 
2025-08-28 09:52:58.273972: Epoch time: 16.61 s 
2025-08-28 09:52:59.154035:  
2025-08-28 09:52:59.162280: Epoch 396 
2025-08-28 09:52:59.167432: Current learning rate: 0.00635 
2025-08-28 09:53:15.685514: train_loss -0.325 
2025-08-28 09:53:15.693424: val_loss -0.3738 
2025-08-28 09:53:15.703348: Pseudo dice [np.float32(0.7189)] 
2025-08-28 09:53:15.709275: Epoch time: 16.53 s 
2025-08-28 09:53:16.483787:  
2025-08-28 09:53:16.492169: Epoch 397 
2025-08-28 09:53:16.497252: Current learning rate: 0.00634 
2025-08-28 09:53:33.432495: train_loss -0.3106 
2025-08-28 09:53:33.440341: val_loss -0.3587 
2025-08-28 09:53:33.444789: Pseudo dice [np.float32(0.5833)] 
2025-08-28 09:53:33.452936: Epoch time: 16.95 s 
2025-08-28 09:53:34.145058:  
2025-08-28 09:53:34.154579: Epoch 398 
2025-08-28 09:53:34.160806: Current learning rate: 0.00633 
2025-08-28 09:53:50.724268: train_loss -0.3216 
2025-08-28 09:53:50.732636: val_loss -0.2971 
2025-08-28 09:53:50.736949: Pseudo dice [np.float32(0.626)] 
2025-08-28 09:53:50.745193: Epoch time: 16.58 s 
2025-08-28 09:53:51.467926:  
2025-08-28 09:53:51.476371: Epoch 399 
2025-08-28 09:53:51.481356: Current learning rate: 0.00632 
2025-08-28 09:54:08.742269: train_loss -0.2963 
2025-08-28 09:54:08.750598: val_loss -0.3011 
2025-08-28 09:54:08.754755: Pseudo dice [np.float32(0.5902)] 
2025-08-28 09:54:08.761444: Epoch time: 17.28 s 
2025-08-28 09:54:09.669221:  
2025-08-28 09:54:09.676375: Epoch 400 
2025-08-28 09:54:09.682774: Current learning rate: 0.00631 
2025-08-28 09:54:26.518334: train_loss -0.3092 
2025-08-28 09:54:26.526688: val_loss -0.3268 
2025-08-28 09:54:26.531210: Pseudo dice [np.float32(0.6454)] 
2025-08-28 09:54:26.537774: Epoch time: 16.85 s 
2025-08-28 09:54:27.246786:  
2025-08-28 09:54:27.256531: Epoch 401 
2025-08-28 09:54:27.262100: Current learning rate: 0.0063 
2025-08-28 09:54:43.885691: train_loss -0.2968 
2025-08-28 09:54:43.894052: val_loss -0.3133 
2025-08-28 09:54:43.898458: Pseudo dice [np.float32(0.4949)] 
2025-08-28 09:54:43.906346: Epoch time: 16.64 s 
2025-08-28 09:54:44.757289:  
2025-08-28 09:54:44.765590: Epoch 402 
2025-08-28 09:54:44.776236: Current learning rate: 0.0063 
2025-08-28 09:55:01.682521: train_loss -0.3349 
2025-08-28 09:55:01.690949: val_loss -0.3369 
2025-08-28 09:55:01.699301: Pseudo dice [np.float32(0.6674)] 
2025-08-28 09:55:01.704576: Epoch time: 16.93 s 
2025-08-28 09:55:02.443726:  
2025-08-28 09:55:02.451096: Epoch 403 
2025-08-28 09:55:02.458282: Current learning rate: 0.00629 
2025-08-28 09:55:19.391944: train_loss -0.2857 
2025-08-28 09:55:19.400318: val_loss -0.3344 
2025-08-28 09:55:19.404482: Pseudo dice [np.float32(0.5842)] 
2025-08-28 09:55:19.413456: Epoch time: 16.95 s 
2025-08-28 09:55:20.119718:  
2025-08-28 09:55:20.128065: Epoch 404 
2025-08-28 09:55:20.134274: Current learning rate: 0.00628 
2025-08-28 09:55:37.055624: train_loss -0.3081 
2025-08-28 09:55:37.064098: val_loss -0.3665 
2025-08-28 09:55:37.072441: Pseudo dice [np.float32(0.6791)] 
2025-08-28 09:55:37.077443: Epoch time: 16.94 s 
2025-08-28 09:55:37.793594:  
2025-08-28 09:55:37.803899: Epoch 405 
2025-08-28 09:55:37.811480: Current learning rate: 0.00627 
2025-08-28 09:55:54.694210: train_loss -0.3176 
2025-08-28 09:55:54.702502: val_loss -0.3515 
2025-08-28 09:55:54.706698: Pseudo dice [np.float32(0.5708)] 
2025-08-28 09:55:54.716042: Epoch time: 16.9 s 
2025-08-28 09:55:55.411147:  
2025-08-28 09:55:55.419459: Epoch 406 
2025-08-28 09:55:55.426985: Current learning rate: 0.00626 
2025-08-28 09:56:11.973637: train_loss -0.3269 
2025-08-28 09:56:11.981953: val_loss -0.4013 
2025-08-28 09:56:11.986474: Pseudo dice [np.float32(0.6464)] 
2025-08-28 09:56:11.994247: Epoch time: 16.56 s 
2025-08-28 09:56:12.713886:  
2025-08-28 09:56:12.724262: Epoch 407 
2025-08-28 09:56:12.729646: Current learning rate: 0.00625 
2025-08-28 09:56:29.549618: train_loss -0.2884 
2025-08-28 09:56:29.557846: val_loss -0.359 
2025-08-28 09:56:29.562014: Pseudo dice [np.float32(0.6471)] 
2025-08-28 09:56:29.570453: Epoch time: 16.84 s 
2025-08-28 09:56:30.433560:  
2025-08-28 09:56:30.442220: Epoch 408 
2025-08-28 09:56:30.451442: Current learning rate: 0.00624 
2025-08-28 09:56:46.975223: train_loss -0.3204 
2025-08-28 09:56:46.983570: val_loss -0.3434 
2025-08-28 09:56:46.991931: Pseudo dice [np.float32(0.5864)] 
2025-08-28 09:56:46.997218: Epoch time: 16.54 s 
2025-08-28 09:56:47.724784:  
2025-08-28 09:56:47.731279: Epoch 409 
2025-08-28 09:56:47.735719: Current learning rate: 0.00623 
2025-08-28 09:57:04.342604: train_loss -0.3296 
2025-08-28 09:57:04.350915: val_loss -0.3281 
2025-08-28 09:57:04.359261: Pseudo dice [np.float32(0.6014)] 
2025-08-28 09:57:04.363494: Epoch time: 16.62 s 
2025-08-28 09:57:05.088223:  
2025-08-28 09:57:05.096435: Epoch 410 
2025-08-28 09:57:05.103724: Current learning rate: 0.00622 
2025-08-28 09:57:21.826706: train_loss -0.2943 
2025-08-28 09:57:21.835039: val_loss -0.3232 
2025-08-28 09:57:21.843391: Pseudo dice [np.float32(0.6752)] 
2025-08-28 09:57:21.849666: Epoch time: 16.74 s 
2025-08-28 09:57:22.530438:  
2025-08-28 09:57:22.537800: Epoch 411 
2025-08-28 09:57:22.544611: Current learning rate: 0.00621 
2025-08-28 09:57:39.244409: train_loss -0.3212 
2025-08-28 09:57:39.252522: val_loss -0.3438 
2025-08-28 09:57:39.256882: Pseudo dice [np.float32(0.6164)] 
2025-08-28 09:57:39.263284: Epoch time: 16.71 s 
2025-08-28 09:57:39.942632:  
2025-08-28 09:57:39.949970: Epoch 412 
2025-08-28 09:57:39.956262: Current learning rate: 0.0062 
2025-08-28 09:57:56.828574: train_loss -0.3087 
2025-08-28 09:57:56.840831: val_loss -0.3478 
2025-08-28 09:57:56.847064: Pseudo dice [np.float32(0.6241)] 
2025-08-28 09:57:56.852233: Epoch time: 16.89 s 
2025-08-28 09:57:57.534297:  
2025-08-28 09:57:57.542575: Epoch 413 
2025-08-28 09:57:57.549030: Current learning rate: 0.00619 
2025-08-28 09:58:14.300877: train_loss -0.3111 
2025-08-28 09:58:14.308562: val_loss -0.3316 
2025-08-28 09:58:14.317325: Pseudo dice [np.float32(0.5773)] 
2025-08-28 09:58:14.323343: Epoch time: 16.77 s 
2025-08-28 09:58:15.012966:  
2025-08-28 09:58:15.020445: Epoch 414 
2025-08-28 09:58:15.026710: Current learning rate: 0.00618 
2025-08-28 09:58:31.950909: train_loss -0.3335 
2025-08-28 09:58:31.959459: val_loss -0.3653 
2025-08-28 09:58:31.963372: Pseudo dice [np.float32(0.5719)] 
2025-08-28 09:58:31.972045: Epoch time: 16.94 s 
2025-08-28 09:58:32.823610:  
2025-08-28 09:58:32.831763: Epoch 415 
2025-08-28 09:58:32.836664: Current learning rate: 0.00617 
2025-08-28 09:58:49.343230: train_loss -0.3006 
2025-08-28 09:58:49.351578: val_loss -0.3764 
2025-08-28 09:58:49.356007: Pseudo dice [np.float32(0.6475)] 
2025-08-28 09:58:49.363778: Epoch time: 16.52 s 
2025-08-28 09:58:50.039321:  
2025-08-28 09:58:50.048106: Epoch 416 
2025-08-28 09:58:50.056455: Current learning rate: 0.00616 
2025-08-28 09:59:07.181897: train_loss -0.307 
2025-08-28 09:59:07.190222: val_loss -0.4046 
2025-08-28 09:59:07.198625: Pseudo dice [np.float32(0.6751)] 
2025-08-28 09:59:07.204809: Epoch time: 17.14 s 
2025-08-28 09:59:07.208073: Yayy! New best EMA pseudo Dice: 0.6176000237464905 
2025-08-28 09:59:08.072375:  
2025-08-28 09:59:08.082825: Epoch 417 
2025-08-28 09:59:08.089006: Current learning rate: 0.00615 
2025-08-28 09:59:24.419915: train_loss -0.2679 
2025-08-28 09:59:24.428293: val_loss -0.3473 
2025-08-28 09:59:24.432494: Pseudo dice [np.float32(0.6434)] 
2025-08-28 09:59:24.439898: Epoch time: 16.35 s 
2025-08-28 09:59:24.445487: Yayy! New best EMA pseudo Dice: 0.620199978351593 
2025-08-28 09:59:25.340190:  
2025-08-28 09:59:25.352037: Epoch 418 
2025-08-28 09:59:25.359829: Current learning rate: 0.00614 
2025-08-28 09:59:41.562057: train_loss -0.3204 
2025-08-28 09:59:41.570719: val_loss -0.3389 
2025-08-28 09:59:41.574854: Pseudo dice [np.float32(0.6155)] 
2025-08-28 09:59:41.581783: Epoch time: 16.22 s 
2025-08-28 09:59:42.275209:  
2025-08-28 09:59:42.284622: Epoch 419 
2025-08-28 09:59:42.289793: Current learning rate: 0.00613 
2025-08-28 09:59:57.974448: train_loss -0.3275 
2025-08-28 09:59:57.986809: val_loss -0.4217 
2025-08-28 09:59:57.990974: Pseudo dice [np.float32(0.7111)] 
2025-08-28 09:59:57.999366: Epoch time: 15.7 s 
2025-08-28 09:59:58.003990: Yayy! New best EMA pseudo Dice: 0.6288999915122986 
2025-08-28 09:59:58.884559:  
2025-08-28 09:59:58.892933: Epoch 420 
2025-08-28 09:59:58.899042: Current learning rate: 0.00612 
2025-08-28 10:00:15.721163: train_loss -0.3161 
2025-08-28 10:00:15.729518: val_loss -0.366 
2025-08-28 10:00:15.737850: Pseudo dice [np.float32(0.6496)] 
2025-08-28 10:00:15.744887: Epoch time: 16.84 s 
2025-08-28 10:00:15.750409: Yayy! New best EMA pseudo Dice: 0.6309000253677368 
2025-08-28 10:00:16.761765:  
2025-08-28 10:00:16.769068: Epoch 421 
2025-08-28 10:00:16.775296: Current learning rate: 0.00612 
2025-08-28 10:00:33.330395: train_loss -0.3427 
2025-08-28 10:00:33.338785: val_loss -0.4015 
2025-08-28 10:00:33.342922: Pseudo dice [np.float32(0.6198)] 
2025-08-28 10:00:33.352200: Epoch time: 16.57 s 
2025-08-28 10:00:34.038432:  
2025-08-28 10:00:34.048594: Epoch 422 
2025-08-28 10:00:34.053100: Current learning rate: 0.00611 
2025-08-28 10:00:50.739258: train_loss -0.3071 
2025-08-28 10:00:50.743636: val_loss -0.3324 
2025-08-28 10:00:50.752022: Pseudo dice [np.float32(0.5971)] 
2025-08-28 10:00:50.758994: Epoch time: 16.7 s 
2025-08-28 10:00:51.449509:  
2025-08-28 10:00:51.457974: Epoch 423 
2025-08-28 10:00:51.465039: Current learning rate: 0.0061 
2025-08-28 10:01:07.780516: train_loss -0.3284 
2025-08-28 10:01:07.785601: val_loss -0.3525 
2025-08-28 10:01:07.794003: Pseudo dice [np.float32(0.6169)] 
2025-08-28 10:01:07.800630: Epoch time: 16.33 s 
2025-08-28 10:01:08.491506:  
2025-08-28 10:01:08.498767: Epoch 424 
2025-08-28 10:01:08.504018: Current learning rate: 0.00609 
2025-08-28 10:01:24.852988: train_loss -0.2827 
2025-08-28 10:01:24.861255: val_loss -0.3488 
2025-08-28 10:01:24.869205: Pseudo dice [np.float32(0.6401)] 
2025-08-28 10:01:24.874589: Epoch time: 16.36 s 
2025-08-28 10:01:25.584942:  
2025-08-28 10:01:25.594972: Epoch 425 
2025-08-28 10:01:25.602271: Current learning rate: 0.00608 
2025-08-28 10:01:41.616207: train_loss -0.3519 
2025-08-28 10:01:41.623852: val_loss -0.3695 
2025-08-28 10:01:41.632389: Pseudo dice [np.float32(0.618)] 
2025-08-28 10:01:41.637446: Epoch time: 16.03 s 
2025-08-28 10:01:42.349253:  
2025-08-28 10:01:42.357358: Epoch 426 
2025-08-28 10:01:42.365921: Current learning rate: 0.00607 
2025-08-28 10:01:58.661409: train_loss -0.3207 
2025-08-28 10:01:58.669764: val_loss -0.3086 
2025-08-28 10:01:58.678134: Pseudo dice [np.float32(0.5927)] 
2025-08-28 10:01:58.683400: Epoch time: 16.31 s 
2025-08-28 10:01:59.394470:  
2025-08-28 10:01:59.402660: Epoch 427 
2025-08-28 10:01:59.409322: Current learning rate: 0.00606 
2025-08-28 10:02:15.832709: train_loss -0.3094 
2025-08-28 10:02:15.841071: val_loss -0.3582 
2025-08-28 10:02:15.845588: Pseudo dice [np.float32(0.6573)] 
2025-08-28 10:02:15.852472: Epoch time: 16.44 s 
2025-08-28 10:02:16.722238:  
2025-08-28 10:02:16.730551: Epoch 428 
2025-08-28 10:02:16.735693: Current learning rate: 0.00605 
2025-08-28 10:02:33.062460: train_loss -0.3143 
2025-08-28 10:02:33.070771: val_loss -0.3376 
2025-08-28 10:02:33.074946: Pseudo dice [np.float32(0.6597)] 
2025-08-28 10:02:33.083308: Epoch time: 16.34 s 
2025-08-28 10:02:33.810112:  
2025-08-28 10:02:33.819373: Epoch 429 
2025-08-28 10:02:33.825568: Current learning rate: 0.00604 
2025-08-28 10:02:50.258800: train_loss -0.3151 
2025-08-28 10:02:50.267476: val_loss -0.3683 
2025-08-28 10:02:50.271317: Pseudo dice [np.float32(0.6444)] 
2025-08-28 10:02:50.279592: Epoch time: 16.45 s 
2025-08-28 10:02:50.284491: Yayy! New best EMA pseudo Dice: 0.6310999989509583 
2025-08-28 10:02:51.161497:  
2025-08-28 10:02:51.174256: Epoch 430 
2025-08-28 10:02:51.182111: Current learning rate: 0.00603 
2025-08-28 10:03:07.400876: train_loss -0.3271 
2025-08-28 10:03:07.409106: val_loss -0.3616 
2025-08-28 10:03:07.413550: Pseudo dice [np.float32(0.6347)] 
2025-08-28 10:03:07.419696: Epoch time: 16.24 s 
2025-08-28 10:03:07.423188: Yayy! New best EMA pseudo Dice: 0.6313999891281128 
2025-08-28 10:03:08.327833:  
2025-08-28 10:03:08.336236: Epoch 431 
2025-08-28 10:03:08.345605: Current learning rate: 0.00602 
2025-08-28 10:03:24.822484: train_loss -0.3069 
2025-08-28 10:03:24.830817: val_loss -0.341 
2025-08-28 10:03:24.839123: Pseudo dice [np.float32(0.502)] 
2025-08-28 10:03:24.845927: Epoch time: 16.5 s 
2025-08-28 10:03:25.545010:  
2025-08-28 10:03:25.554923: Epoch 432 
2025-08-28 10:03:25.563452: Current learning rate: 0.00601 
2025-08-28 10:03:41.839384: train_loss -0.3015 
2025-08-28 10:03:41.848136: val_loss -0.419 
2025-08-28 10:03:41.855993: Pseudo dice [np.float32(0.7221)] 
2025-08-28 10:03:41.861400: Epoch time: 16.3 s 
2025-08-28 10:03:42.574515:  
2025-08-28 10:03:42.584886: Epoch 433 
2025-08-28 10:03:42.591206: Current learning rate: 0.006 
2025-08-28 10:03:59.106882: train_loss -0.3102 
2025-08-28 10:03:59.119173: val_loss -0.3502 
2025-08-28 10:03:59.123549: Pseudo dice [np.float32(0.6097)] 
2025-08-28 10:03:59.129648: Epoch time: 16.53 s 
2025-08-28 10:03:59.996098:  
2025-08-28 10:04:00.003265: Epoch 434 
2025-08-28 10:04:00.010635: Current learning rate: 0.00599 
2025-08-28 10:04:16.273789: train_loss -0.3214 
2025-08-28 10:04:16.282160: val_loss -0.3568 
2025-08-28 10:04:16.290720: Pseudo dice [np.float32(0.5826)] 
2025-08-28 10:04:16.296754: Epoch time: 16.28 s 
2025-08-28 10:04:16.999722:  
2025-08-28 10:04:17.008960: Epoch 435 
2025-08-28 10:04:17.016150: Current learning rate: 0.00598 
2025-08-28 10:04:33.178219: train_loss -0.3242 
2025-08-28 10:04:33.186907: val_loss -0.3742 
2025-08-28 10:04:33.190734: Pseudo dice [np.float32(0.6461)] 
2025-08-28 10:04:33.197869: Epoch time: 16.18 s 
2025-08-28 10:04:33.903964:  
2025-08-28 10:04:33.911673: Epoch 436 
2025-08-28 10:04:33.917487: Current learning rate: 0.00597 
2025-08-28 10:04:50.216258: train_loss -0.3088 
2025-08-28 10:04:50.224629: val_loss -0.3465 
2025-08-28 10:04:50.228539: Pseudo dice [np.float32(0.6143)] 
2025-08-28 10:04:50.236728: Epoch time: 16.31 s 
2025-08-28 10:04:50.935493:  
2025-08-28 10:04:50.942928: Epoch 437 
2025-08-28 10:04:50.948324: Current learning rate: 0.00596 
2025-08-28 10:05:06.924368: train_loss -0.3274 
2025-08-28 10:05:06.933086: val_loss -0.3896 
2025-08-28 10:05:06.936909: Pseudo dice [np.float32(0.6517)] 
2025-08-28 10:05:06.944949: Epoch time: 15.99 s 
2025-08-28 10:05:07.652108:  
2025-08-28 10:05:07.660534: Epoch 438 
2025-08-28 10:05:07.666638: Current learning rate: 0.00595 
2025-08-28 10:05:23.874646: train_loss -0.3198 
2025-08-28 10:05:23.883025: val_loss -0.3014 
2025-08-28 10:05:23.887469: Pseudo dice [np.float32(0.5992)] 
2025-08-28 10:05:23.894404: Epoch time: 16.22 s 
2025-08-28 10:05:24.610025:  
2025-08-28 10:05:24.619643: Epoch 439 
2025-08-28 10:05:24.626405: Current learning rate: 0.00594 
2025-08-28 10:05:40.712312: train_loss -0.3 
2025-08-28 10:05:40.721076: val_loss -0.3758 
2025-08-28 10:05:40.729307: Pseudo dice [np.float32(0.6427)] 
2025-08-28 10:05:40.735246: Epoch time: 16.1 s 
2025-08-28 10:05:41.428501:  
2025-08-28 10:05:41.435939: Epoch 440 
2025-08-28 10:05:41.441081: Current learning rate: 0.00593 
2025-08-28 10:05:57.962854: train_loss -0.3109 
2025-08-28 10:05:57.975399: val_loss -0.38 
2025-08-28 10:05:57.979534: Pseudo dice [np.float32(0.6783)] 
2025-08-28 10:05:57.987708: Epoch time: 16.54 s 
2025-08-28 10:05:58.912672:  
2025-08-28 10:05:58.920976: Epoch 441 
2025-08-28 10:05:58.926225: Current learning rate: 0.00592 
2025-08-28 10:06:15.171735: train_loss -0.3385 
2025-08-28 10:06:15.180096: val_loss -0.4274 
2025-08-28 10:06:15.188372: Pseudo dice [np.float32(0.7223)] 
2025-08-28 10:06:15.194634: Epoch time: 16.26 s 
2025-08-28 10:06:15.198789: Yayy! New best EMA pseudo Dice: 0.6401000022888184 
2025-08-28 10:06:16.081596:  
2025-08-28 10:06:16.091577: Epoch 442 
2025-08-28 10:06:16.096678: Current learning rate: 0.00592 
2025-08-28 10:06:32.560140: train_loss -0.3457 
2025-08-28 10:06:32.568263: val_loss -0.3402 
2025-08-28 10:06:32.572452: Pseudo dice [np.float32(0.4646)] 
2025-08-28 10:06:32.579667: Epoch time: 16.48 s 
2025-08-28 10:06:33.274109:  
2025-08-28 10:06:33.281367: Epoch 443 
2025-08-28 10:06:33.286701: Current learning rate: 0.00591 
2025-08-28 10:06:49.743695: train_loss -0.3328 
2025-08-28 10:06:49.752061: val_loss -0.2968 
2025-08-28 10:06:49.756235: Pseudo dice [np.float32(0.5153)] 
2025-08-28 10:06:49.764665: Epoch time: 16.47 s 
2025-08-28 10:06:50.444316:  
2025-08-28 10:06:50.453763: Epoch 444 
2025-08-28 10:06:50.462075: Current learning rate: 0.0059 
2025-08-28 10:07:06.752439: train_loss -0.2981 
2025-08-28 10:07:06.765184: val_loss -0.3025 
2025-08-28 10:07:06.769054: Pseudo dice [np.float32(0.6317)] 
2025-08-28 10:07:06.775794: Epoch time: 16.31 s 
2025-08-28 10:07:07.483282:  
2025-08-28 10:07:07.492009: Epoch 445 
2025-08-28 10:07:07.498888: Current learning rate: 0.00589 
2025-08-28 10:07:23.719852: train_loss -0.3069 
2025-08-28 10:07:23.727632: val_loss -0.3817 
2025-08-28 10:07:23.732148: Pseudo dice [np.float32(0.6117)] 
2025-08-28 10:07:23.741096: Epoch time: 16.24 s 
2025-08-28 10:07:24.447028:  
2025-08-28 10:07:24.456389: Epoch 446 
2025-08-28 10:07:24.464683: Current learning rate: 0.00588 
2025-08-28 10:07:40.773954: train_loss -0.3348 
2025-08-28 10:07:40.782487: val_loss -0.4252 
2025-08-28 10:07:40.786309: Pseudo dice [np.float32(0.6491)] 
2025-08-28 10:07:40.794711: Epoch time: 16.33 s 
2025-08-28 10:07:41.535433:  
2025-08-28 10:07:41.543269: Epoch 447 
2025-08-28 10:07:41.552444: Current learning rate: 0.00587 
2025-08-28 10:07:57.757432: train_loss -0.3186 
2025-08-28 10:07:57.766088: val_loss -0.3232 
2025-08-28 10:07:57.774163: Pseudo dice [np.float32(0.636)] 
2025-08-28 10:07:57.780923: Epoch time: 16.22 s 
2025-08-28 10:07:58.657153:  
2025-08-28 10:07:58.663610: Epoch 448 
2025-08-28 10:07:58.672930: Current learning rate: 0.00586 
2025-08-28 10:08:14.391007: train_loss -0.3168 
2025-08-28 10:08:14.399082: val_loss -0.3012 
2025-08-28 10:08:14.403219: Pseudo dice [np.float32(0.5854)] 
2025-08-28 10:08:14.411293: Epoch time: 15.74 s 
2025-08-28 10:08:15.086149:  
2025-08-28 10:08:15.095465: Epoch 449 
2025-08-28 10:08:15.100921: Current learning rate: 0.00585 
2025-08-28 10:08:31.011651: train_loss -0.3314 
2025-08-28 10:08:31.019854: val_loss -0.333 
2025-08-28 10:08:31.024019: Pseudo dice [np.float32(0.6224)] 
2025-08-28 10:08:31.030567: Epoch time: 15.93 s 
2025-08-28 10:08:31.907102:  
2025-08-28 10:08:31.914411: Epoch 450 
2025-08-28 10:08:31.919584: Current learning rate: 0.00584 
2025-08-28 10:08:48.954415: train_loss -0.3406 
2025-08-28 10:08:48.962736: val_loss -0.3498 
2025-08-28 10:08:48.967204: Pseudo dice [np.float32(0.6226)] 
2025-08-28 10:08:48.975293: Epoch time: 17.05 s 
2025-08-28 10:08:49.677172:  
2025-08-28 10:08:49.688845: Epoch 451 
2025-08-28 10:08:49.695081: Current learning rate: 0.00583 
2025-08-28 10:09:06.530499: train_loss -0.3231 
2025-08-28 10:09:06.542806: val_loss -0.3576 
2025-08-28 10:09:06.546956: Pseudo dice [np.float32(0.6444)] 
2025-08-28 10:09:06.554262: Epoch time: 16.86 s 
2025-08-28 10:09:07.245601:  
2025-08-28 10:09:07.253416: Epoch 452 
2025-08-28 10:09:07.260041: Current learning rate: 0.00582 
2025-08-28 10:09:24.043643: train_loss -0.3154 
2025-08-28 10:09:24.051993: val_loss -0.3811 
2025-08-28 10:09:24.056107: Pseudo dice [np.float32(0.6217)] 
2025-08-28 10:09:24.063649: Epoch time: 16.8 s 
2025-08-28 10:09:24.744133:  
2025-08-28 10:09:24.755236: Epoch 453 
2025-08-28 10:09:24.762969: Current learning rate: 0.00581 
2025-08-28 10:09:41.581957: train_loss -0.3336 
2025-08-28 10:09:41.590627: val_loss -0.3723 
2025-08-28 10:09:41.594777: Pseudo dice [np.float32(0.6417)] 
2025-08-28 10:09:41.602645: Epoch time: 16.84 s 
2025-08-28 10:09:42.266958:  
2025-08-28 10:09:42.276126: Epoch 454 
2025-08-28 10:09:42.283715: Current learning rate: 0.0058 
2025-08-28 10:09:59.291322: train_loss -0.3326 
2025-08-28 10:09:59.299594: val_loss -0.3954 
2025-08-28 10:09:59.303810: Pseudo dice [np.float32(0.67)] 
2025-08-28 10:09:59.310316: Epoch time: 17.03 s 
2025-08-28 10:10:00.133795:  
2025-08-28 10:10:00.145624: Epoch 455 
2025-08-28 10:10:00.152684: Current learning rate: 0.00579 
2025-08-28 10:10:17.280109: train_loss -0.3207 
2025-08-28 10:10:17.288436: val_loss -0.3568 
2025-08-28 10:10:17.296786: Pseudo dice [np.float32(0.5409)] 
2025-08-28 10:10:17.301940: Epoch time: 17.15 s 
2025-08-28 10:10:17.985316:  
2025-08-28 10:10:17.997444: Epoch 456 
2025-08-28 10:10:18.005753: Current learning rate: 0.00578 
2025-08-28 10:10:34.901821: train_loss -0.3346 
2025-08-28 10:10:34.910226: val_loss -0.4175 
2025-08-28 10:10:34.918820: Pseudo dice [np.float32(0.6891)] 
2025-08-28 10:10:34.923950: Epoch time: 16.92 s 
2025-08-28 10:10:35.580020:  
2025-08-28 10:10:35.585960: Epoch 457 
2025-08-28 10:10:35.590365: Current learning rate: 0.00577 
2025-08-28 10:10:52.632232: train_loss -0.2904 
2025-08-28 10:10:52.640632: val_loss -0.4048 
2025-08-28 10:10:52.648430: Pseudo dice [np.float32(0.6589)] 
2025-08-28 10:10:52.654380: Epoch time: 17.05 s 
2025-08-28 10:10:53.318242:  
2025-08-28 10:10:53.325657: Epoch 458 
2025-08-28 10:10:53.330951: Current learning rate: 0.00576 
2025-08-28 10:11:10.349724: train_loss -0.3388 
2025-08-28 10:11:10.361967: val_loss -0.3763 
2025-08-28 10:11:10.366491: Pseudo dice [np.float32(0.6613)] 
2025-08-28 10:11:10.372719: Epoch time: 17.03 s 
2025-08-28 10:11:11.041967:  
2025-08-28 10:11:11.050384: Epoch 459 
2025-08-28 10:11:11.057727: Current learning rate: 0.00575 
2025-08-28 10:11:27.929793: train_loss -0.3566 
2025-08-28 10:11:27.938153: val_loss -0.3818 
2025-08-28 10:11:27.946488: Pseudo dice [np.float32(0.6129)] 
2025-08-28 10:11:27.952725: Epoch time: 16.89 s 
2025-08-28 10:11:28.619078:  
2025-08-28 10:11:28.627781: Epoch 460 
2025-08-28 10:11:28.630840: Current learning rate: 0.00574 
2025-08-28 10:11:45.551764: train_loss -0.3308 
2025-08-28 10:11:45.559967: val_loss -0.3259 
2025-08-28 10:11:45.564152: Pseudo dice [np.float32(0.591)] 
2025-08-28 10:11:45.571291: Epoch time: 16.93 s 
2025-08-28 10:11:46.238385:  
2025-08-28 10:11:46.244470: Epoch 461 
2025-08-28 10:11:46.252914: Current learning rate: 0.00573 
2025-08-28 10:12:03.345262: train_loss -0.3306 
2025-08-28 10:12:03.352720: val_loss -0.3512 
2025-08-28 10:12:03.361266: Pseudo dice [np.float32(0.5894)] 
2025-08-28 10:12:03.369388: Epoch time: 17.11 s 
2025-08-28 10:12:04.185701:  
2025-08-28 10:12:04.194013: Epoch 462 
2025-08-28 10:12:04.202505: Current learning rate: 0.00572 
2025-08-28 10:12:20.757530: train_loss -0.3292 
2025-08-28 10:12:20.765804: val_loss -0.3256 
2025-08-28 10:12:20.770370: Pseudo dice [np.float32(0.4926)] 
2025-08-28 10:12:20.779255: Epoch time: 16.57 s 
2025-08-28 10:12:21.458201:  
2025-08-28 10:12:21.466514: Epoch 463 
2025-08-28 10:12:21.473026: Current learning rate: 0.00571 
2025-08-28 10:12:38.295935: train_loss -0.325 
2025-08-28 10:12:38.304247: val_loss -0.3424 
2025-08-28 10:12:38.312607: Pseudo dice [np.float32(0.5732)] 
2025-08-28 10:12:38.318018: Epoch time: 16.84 s 
2025-08-28 10:12:39.006904:  
2025-08-28 10:12:39.013637: Epoch 464 
2025-08-28 10:12:39.021979: Current learning rate: 0.0057 
2025-08-28 10:12:56.046939: train_loss -0.3247 
2025-08-28 10:12:56.055670: val_loss -0.3266 
2025-08-28 10:12:56.059457: Pseudo dice [np.float32(0.5882)] 
2025-08-28 10:12:56.067737: Epoch time: 17.04 s 
2025-08-28 10:12:56.744044:  
2025-08-28 10:12:56.753056: Epoch 465 
2025-08-28 10:12:56.759212: Current learning rate: 0.0057 
2025-08-28 10:13:13.485197: train_loss -0.3351 
2025-08-28 10:13:13.498892: val_loss -0.3113 
2025-08-28 10:13:13.503021: Pseudo dice [np.float32(0.5711)] 
2025-08-28 10:13:13.510213: Epoch time: 16.74 s 
2025-08-28 10:13:14.197202:  
2025-08-28 10:13:14.206755: Epoch 466 
2025-08-28 10:13:14.230699: Current learning rate: 0.00569 
2025-08-28 10:13:31.340589: train_loss -0.3249 
2025-08-28 10:13:31.348858: val_loss -0.329 
2025-08-28 10:13:31.353011: Pseudo dice [np.float32(0.6061)] 
2025-08-28 10:13:31.361827: Epoch time: 17.15 s 
2025-08-28 10:13:32.047518:  
2025-08-28 10:13:32.054809: Epoch 467 
2025-08-28 10:13:32.059971: Current learning rate: 0.00568 
2025-08-28 10:13:48.857972: train_loss -0.3465 
2025-08-28 10:13:48.866378: val_loss -0.3529 
2025-08-28 10:13:48.870847: Pseudo dice [np.float32(0.6182)] 
2025-08-28 10:13:48.877762: Epoch time: 16.81 s 
2025-08-28 10:13:49.568027:  
2025-08-28 10:13:49.576417: Epoch 468 
2025-08-28 10:13:49.584495: Current learning rate: 0.00567 
2025-08-28 10:14:06.455598: train_loss -0.3054 
2025-08-28 10:14:06.463058: val_loss -0.4001 
2025-08-28 10:14:06.467247: Pseudo dice [np.float32(0.6964)] 
2025-08-28 10:14:06.475626: Epoch time: 16.89 s 
2025-08-28 10:14:07.299473:  
2025-08-28 10:14:07.308629: Epoch 469 
2025-08-28 10:14:07.316988: Current learning rate: 0.00566 
2025-08-28 10:14:23.984751: train_loss -0.3281 
2025-08-28 10:14:23.993067: val_loss -0.3782 
2025-08-28 10:14:23.997503: Pseudo dice [np.float32(0.6157)] 
2025-08-28 10:14:24.005329: Epoch time: 16.69 s 
2025-08-28 10:14:24.681251:  
2025-08-28 10:14:24.689992: Epoch 470 
2025-08-28 10:14:24.696154: Current learning rate: 0.00565 
2025-08-28 10:14:41.781721: train_loss -0.3125 
2025-08-28 10:14:41.790276: val_loss -0.3424 
2025-08-28 10:14:41.798700: Pseudo dice [np.float32(0.6384)] 
2025-08-28 10:14:41.803284: Epoch time: 17.1 s 
2025-08-28 10:14:42.480202:  
2025-08-28 10:14:42.487697: Epoch 471 
2025-08-28 10:14:42.492749: Current learning rate: 0.00564 
2025-08-28 10:14:59.295532: train_loss -0.3239 
2025-08-28 10:14:59.303330: val_loss -0.3475 
2025-08-28 10:14:59.312300: Pseudo dice [np.float32(0.6373)] 
2025-08-28 10:14:59.318015: Epoch time: 16.82 s 
2025-08-28 10:14:59.982100:  
2025-08-28 10:14:59.992994: Epoch 472 
2025-08-28 10:14:59.998475: Current learning rate: 0.00563 
2025-08-28 10:15:16.798612: train_loss -0.3096 
2025-08-28 10:15:16.808310: val_loss -0.3707 
2025-08-28 10:15:16.812480: Pseudo dice [np.float32(0.6119)] 
2025-08-28 10:15:16.819769: Epoch time: 16.82 s 
2025-08-28 10:15:17.503658:  
2025-08-28 10:15:17.512064: Epoch 473 
2025-08-28 10:15:17.517244: Current learning rate: 0.00562 
2025-08-28 10:15:34.117218: train_loss -0.3292 
2025-08-28 10:15:34.125605: val_loss -0.3076 
2025-08-28 10:15:34.129768: Pseudo dice [np.float32(0.6123)] 
2025-08-28 10:15:34.137942: Epoch time: 16.61 s 
2025-08-28 10:15:34.811105:  
2025-08-28 10:15:34.818414: Epoch 474 
2025-08-28 10:15:34.826291: Current learning rate: 0.00561 
2025-08-28 10:15:51.888620: train_loss -0.3545 
2025-08-28 10:15:51.893716: val_loss -0.3868 
2025-08-28 10:15:51.901733: Pseudo dice [np.float32(0.6783)] 
2025-08-28 10:15:51.910451: Epoch time: 17.08 s 
2025-08-28 10:15:52.581387:  
2025-08-28 10:15:52.588772: Epoch 475 
2025-08-28 10:15:52.597354: Current learning rate: 0.0056 
2025-08-28 10:16:09.619397: train_loss -0.3441 
2025-08-28 10:16:09.627775: val_loss -0.3736 
2025-08-28 10:16:09.636395: Pseudo dice [np.float32(0.672)] 
2025-08-28 10:16:09.641496: Epoch time: 17.04 s 
2025-08-28 10:16:10.477489:  
2025-08-28 10:16:10.485723: Epoch 476 
2025-08-28 10:16:10.490968: Current learning rate: 0.00559 
2025-08-28 10:16:27.253636: train_loss -0.3034 
2025-08-28 10:16:27.257821: val_loss -0.3195 
2025-08-28 10:16:27.266536: Pseudo dice [np.float32(0.5512)] 
2025-08-28 10:16:27.272421: Epoch time: 16.78 s 
2025-08-28 10:16:27.943845:  
2025-08-28 10:16:27.952552: Epoch 477 
2025-08-28 10:16:27.958353: Current learning rate: 0.00558 
2025-08-28 10:16:44.775311: train_loss -0.3258 
2025-08-28 10:16:44.783650: val_loss -0.3563 
2025-08-28 10:16:44.788032: Pseudo dice [np.float32(0.6515)] 
2025-08-28 10:16:44.797082: Epoch time: 16.83 s 
2025-08-28 10:16:45.479996:  
2025-08-28 10:16:45.487353: Epoch 478 
2025-08-28 10:16:45.494775: Current learning rate: 0.00557 
2025-08-28 10:17:02.188277: train_loss -0.3218 
2025-08-28 10:17:02.192695: val_loss -0.4169 
2025-08-28 10:17:02.201053: Pseudo dice [np.float32(0.7016)] 
2025-08-28 10:17:02.207206: Epoch time: 16.71 s 
2025-08-28 10:17:02.892265:  
2025-08-28 10:17:02.900645: Epoch 479 
2025-08-28 10:17:02.905749: Current learning rate: 0.00556 
2025-08-28 10:17:19.676803: train_loss -0.3811 
2025-08-28 10:17:19.689347: val_loss -0.3755 
2025-08-28 10:17:19.693713: Pseudo dice [np.float32(0.706)] 
2025-08-28 10:17:19.700660: Epoch time: 16.79 s 
2025-08-28 10:17:20.384790:  
2025-08-28 10:17:20.393035: Epoch 480 
2025-08-28 10:17:20.398357: Current learning rate: 0.00555 
2025-08-28 10:17:37.248506: train_loss -0.3378 
2025-08-28 10:17:37.256869: val_loss -0.3715 
2025-08-28 10:17:37.261260: Pseudo dice [np.float32(0.6549)] 
2025-08-28 10:17:37.268300: Epoch time: 16.86 s 
2025-08-28 10:17:37.953238:  
2025-08-28 10:17:37.960761: Epoch 481 
2025-08-28 10:17:37.967758: Current learning rate: 0.00554 
2025-08-28 10:17:54.970389: train_loss -0.3429 
2025-08-28 10:17:54.979141: val_loss -0.3935 
2025-08-28 10:17:54.983225: Pseudo dice [np.float32(0.6764)] 
2025-08-28 10:17:54.991945: Epoch time: 17.02 s 
2025-08-28 10:17:54.996821: Yayy! New best EMA pseudo Dice: 0.6437000036239624 
2025-08-28 10:17:55.955838:  
2025-08-28 10:17:55.962909: Epoch 482 
2025-08-28 10:17:55.972123: Current learning rate: 0.00553 
2025-08-28 10:18:12.642460: train_loss -0.3192 
2025-08-28 10:18:12.650526: val_loss -0.3572 
2025-08-28 10:18:12.655031: Pseudo dice [np.float32(0.6672)] 
2025-08-28 10:18:12.663842: Epoch time: 16.69 s 
2025-08-28 10:18:12.668662: Yayy! New best EMA pseudo Dice: 0.6460999846458435 
2025-08-28 10:18:13.711996:  
2025-08-28 10:18:13.719350: Epoch 483 
2025-08-28 10:18:13.725514: Current learning rate: 0.00552 
2025-08-28 10:18:30.276859: train_loss -0.3455 
2025-08-28 10:18:30.284822: val_loss -0.3634 
2025-08-28 10:18:30.289003: Pseudo dice [np.float32(0.6418)] 
2025-08-28 10:18:30.296204: Epoch time: 16.57 s 
2025-08-28 10:18:30.992742:  
2025-08-28 10:18:31.001111: Epoch 484 
2025-08-28 10:18:31.009481: Current learning rate: 0.00551 
2025-08-28 10:18:47.118587: train_loss -0.32 
2025-08-28 10:18:47.126643: val_loss -0.3667 
2025-08-28 10:18:47.130791: Pseudo dice [np.float32(0.6286)] 
2025-08-28 10:18:47.140054: Epoch time: 16.13 s 
2025-08-28 10:18:47.842943:  
2025-08-28 10:18:47.852086: Epoch 485 
2025-08-28 10:18:47.862544: Current learning rate: 0.0055 
2025-08-28 10:19:04.398257: train_loss -0.3426 
2025-08-28 10:19:04.406449: val_loss -0.3506 
2025-08-28 10:19:04.410921: Pseudo dice [np.float32(0.6247)] 
2025-08-28 10:19:04.418754: Epoch time: 16.56 s 
2025-08-28 10:19:05.106993:  
2025-08-28 10:19:05.116826: Epoch 486 
2025-08-28 10:19:05.120225: Current learning rate: 0.00549 
2025-08-28 10:19:21.457170: train_loss -0.3307 
2025-08-28 10:19:21.468761: val_loss -0.3379 
2025-08-28 10:19:21.482350: Pseudo dice [np.float32(0.5927)] 
2025-08-28 10:19:21.495278: Epoch time: 16.35 s 
2025-08-28 10:19:22.205362:  
2025-08-28 10:19:22.214711: Epoch 487 
2025-08-28 10:19:22.224245: Current learning rate: 0.00548 
2025-08-28 10:19:37.652537: train_loss -0.3373 
2025-08-28 10:19:37.660556: val_loss -0.3489 
2025-08-28 10:19:37.668763: Pseudo dice [np.float32(0.6812)] 
2025-08-28 10:19:37.675536: Epoch time: 15.45 s 
2025-08-28 10:19:38.303712:  
2025-08-28 10:19:38.312098: Epoch 488 
2025-08-28 10:19:38.319384: Current learning rate: 0.00547 
2025-08-28 10:19:53.225975: train_loss -0.3313 
2025-08-28 10:19:53.234303: val_loss -0.4184 
2025-08-28 10:19:53.238467: Pseudo dice [np.float32(0.6714)] 
2025-08-28 10:19:53.245842: Epoch time: 14.92 s 
2025-08-28 10:19:54.107996:  
2025-08-28 10:19:54.117599: Epoch 489 
2025-08-28 10:19:54.123776: Current learning rate: 0.00546 
2025-08-28 10:20:08.570680: train_loss -0.3122 
2025-08-28 10:20:08.578782: val_loss -0.2915 
2025-08-28 10:20:08.587309: Pseudo dice [np.float32(0.6272)] 
2025-08-28 10:20:08.594418: Epoch time: 14.46 s 
2025-08-28 10:20:09.242947:  
2025-08-28 10:20:09.250146: Epoch 490 
2025-08-28 10:20:09.256457: Current learning rate: 0.00546 
2025-08-28 10:20:23.631301: train_loss -0.3254 
2025-08-28 10:20:23.639665: val_loss -0.2927 
2025-08-28 10:20:23.647993: Pseudo dice [np.float32(0.5811)] 
2025-08-28 10:20:23.653263: Epoch time: 14.39 s 
2025-08-28 10:20:24.294279:  
2025-08-28 10:20:24.301651: Epoch 491 
2025-08-28 10:20:24.310168: Current learning rate: 0.00545 
2025-08-28 10:20:39.490809: train_loss -0.3219 
2025-08-28 10:20:39.499161: val_loss -0.3794 
2025-08-28 10:20:39.503308: Pseudo dice [np.float32(0.6874)] 
2025-08-28 10:20:39.510432: Epoch time: 15.2 s 
2025-08-28 10:20:40.157234:  
2025-08-28 10:20:40.165491: Epoch 492 
2025-08-28 10:20:40.170671: Current learning rate: 0.00544 
2025-08-28 10:20:55.221175: train_loss -0.3176 
2025-08-28 10:20:55.229540: val_loss -0.3635 
2025-08-28 10:20:55.238183: Pseudo dice [np.float32(0.6642)] 
2025-08-28 10:20:55.243941: Epoch time: 15.07 s 
2025-08-28 10:20:55.877122:  
2025-08-28 10:20:55.884207: Epoch 493 
2025-08-28 10:20:55.889538: Current learning rate: 0.00543 
2025-08-28 10:21:10.377780: train_loss -0.3155 
2025-08-28 10:21:10.386375: val_loss -0.3641 
2025-08-28 10:21:10.390499: Pseudo dice [np.float32(0.7026)] 
2025-08-28 10:21:10.397551: Epoch time: 14.5 s 
2025-08-28 10:21:10.403507: Yayy! New best EMA pseudo Dice: 0.6498000025749207 
2025-08-28 10:21:11.235090:  
2025-08-28 10:21:11.245428: Epoch 494 
2025-08-28 10:21:11.250703: Current learning rate: 0.00542 
2025-08-28 10:21:26.786041: train_loss -0.313 
2025-08-28 10:21:26.794364: val_loss -0.3841 
2025-08-28 10:21:26.802731: Pseudo dice [np.float32(0.6879)] 
2025-08-28 10:21:26.807540: Epoch time: 15.55 s 
2025-08-28 10:21:26.811867: Yayy! New best EMA pseudo Dice: 0.6535999774932861 
2025-08-28 10:21:27.625457:  
2025-08-28 10:21:27.632561: Epoch 495 
2025-08-28 10:21:27.637904: Current learning rate: 0.00541 
2025-08-28 10:21:42.034649: train_loss -0.3451 
2025-08-28 10:21:42.042942: val_loss -0.3382 
2025-08-28 10:21:42.047405: Pseudo dice [np.float32(0.6259)] 
2025-08-28 10:21:42.055222: Epoch time: 14.41 s 
2025-08-28 10:21:42.845755:  
2025-08-28 10:21:42.854174: Epoch 496 
2025-08-28 10:21:42.862672: Current learning rate: 0.0054 
2025-08-28 10:21:57.099622: train_loss -0.3323 
2025-08-28 10:21:57.107981: val_loss -0.3941 
2025-08-28 10:21:57.116326: Pseudo dice [np.float32(0.6603)] 
2025-08-28 10:21:57.121680: Epoch time: 14.25 s 
2025-08-28 10:21:57.754399:  
2025-08-28 10:21:57.761711: Epoch 497 
2025-08-28 10:21:57.767974: Current learning rate: 0.00539 
2025-08-28 10:22:12.723571: train_loss -0.3495 
2025-08-28 10:22:12.736080: val_loss -0.4032 
2025-08-28 10:22:12.740220: Pseudo dice [np.float32(0.6697)] 
2025-08-28 10:22:12.747470: Epoch time: 14.97 s 
2025-08-28 10:22:13.383645:  
2025-08-28 10:22:13.393104: Epoch 498 
2025-08-28 10:22:13.399107: Current learning rate: 0.00538 
2025-08-28 10:22:28.038846: train_loss -0.3338 
2025-08-28 10:22:28.047475: val_loss -0.3368 
2025-08-28 10:22:28.051380: Pseudo dice [np.float32(0.5983)] 
2025-08-28 10:22:28.060445: Epoch time: 14.66 s 
2025-08-28 10:22:28.686362:  
2025-08-28 10:22:28.693583: Epoch 499 
2025-08-28 10:22:28.698834: Current learning rate: 0.00537 
2025-08-28 10:22:44.000643: train_loss -0.3141 
2025-08-28 10:22:44.008982: val_loss -0.3388 
2025-08-28 10:22:44.013431: Pseudo dice [np.float32(0.6207)] 
2025-08-28 10:22:44.020407: Epoch time: 15.32 s 
2025-08-28 10:22:44.843033:  
2025-08-28 10:22:44.851337: Epoch 500 
2025-08-28 10:22:44.857683: Current learning rate: 0.00536 
2025-08-28 10:23:00.195977: train_loss -0.3331 
2025-08-28 10:23:00.208466: val_loss -0.3872 
2025-08-28 10:23:00.212650: Pseudo dice [np.float32(0.6412)] 
2025-08-28 10:23:00.219890: Epoch time: 15.35 s 
2025-08-28 10:23:00.858984:  
2025-08-28 10:23:00.866294: Epoch 501 
2025-08-28 10:23:00.871464: Current learning rate: 0.00535 
2025-08-28 10:23:16.053916: train_loss -0.3475 
2025-08-28 10:23:16.061791: val_loss -0.3801 
2025-08-28 10:23:16.070306: Pseudo dice [np.float32(0.701)] 
2025-08-28 10:23:16.076914: Epoch time: 15.2 s 
2025-08-28 10:23:16.714468:  
2025-08-28 10:23:16.721797: Epoch 502 
2025-08-28 10:23:16.726983: Current learning rate: 0.00534 
2025-08-28 10:23:31.514717: train_loss -0.3305 
2025-08-28 10:23:31.523088: val_loss -0.3697 
2025-08-28 10:23:31.532151: Pseudo dice [np.float32(0.6463)] 
2025-08-28 10:23:31.537612: Epoch time: 14.8 s 
2025-08-28 10:23:32.325877:  
2025-08-28 10:23:32.333314: Epoch 503 
2025-08-28 10:23:32.338387: Current learning rate: 0.00533 
2025-08-28 10:23:47.234765: train_loss -0.3488 
2025-08-28 10:23:47.242948: val_loss -0.3572 
2025-08-28 10:23:47.247104: Pseudo dice [np.float32(0.5711)] 
2025-08-28 10:23:47.254160: Epoch time: 14.91 s 
2025-08-28 10:23:47.885090:  
2025-08-28 10:23:47.892513: Epoch 504 
2025-08-28 10:23:47.899757: Current learning rate: 0.00532 
2025-08-28 10:24:02.712535: train_loss -0.3142 
2025-08-28 10:24:02.720901: val_loss -0.3686 
2025-08-28 10:24:02.729228: Pseudo dice [np.float32(0.6732)] 
2025-08-28 10:24:02.735363: Epoch time: 14.83 s 
2025-08-28 10:24:03.369440:  
2025-08-28 10:24:03.377065: Epoch 505 
2025-08-28 10:24:03.382956: Current learning rate: 0.00531 
2025-08-28 10:24:18.094907: train_loss -0.3584 
2025-08-28 10:24:18.102909: val_loss -0.3972 
2025-08-28 10:24:18.107420: Pseudo dice [np.float32(0.6611)] 
2025-08-28 10:24:18.116215: Epoch time: 14.73 s 
2025-08-28 10:24:18.744056:  
2025-08-28 10:24:18.751443: Epoch 506 
2025-08-28 10:24:18.760067: Current learning rate: 0.0053 
2025-08-28 10:24:34.189807: train_loss -0.3367 
2025-08-28 10:24:34.195833: val_loss -0.3972 
2025-08-28 10:24:34.202694: Pseudo dice [np.float32(0.7411)] 
2025-08-28 10:24:34.208544: Epoch time: 15.45 s 
2025-08-28 10:24:34.215270: Yayy! New best EMA pseudo Dice: 0.6563000082969666 
2025-08-28 10:24:35.032165:  
2025-08-28 10:24:35.039562: Epoch 507 
2025-08-28 10:24:35.045863: Current learning rate: 0.00529 
2025-08-28 10:24:50.418700: train_loss -0.3154 
2025-08-28 10:24:50.426856: val_loss -0.3985 
2025-08-28 10:24:50.435195: Pseudo dice [np.float32(0.6483)] 
2025-08-28 10:24:50.440632: Epoch time: 15.39 s 
2025-08-28 10:24:51.070199:  
2025-08-28 10:24:51.077364: Epoch 508 
2025-08-28 10:24:51.082670: Current learning rate: 0.00528 
2025-08-28 10:25:06.922485: train_loss -0.333 
2025-08-28 10:25:06.926903: val_loss -0.4105 
2025-08-28 10:25:06.935063: Pseudo dice [np.float32(0.6536)] 
2025-08-28 10:25:06.940772: Epoch time: 15.85 s 
2025-08-28 10:25:07.570980:  
2025-08-28 10:25:07.579316: Epoch 509 
2025-08-28 10:25:07.584492: Current learning rate: 0.00527 
2025-08-28 10:25:22.517217: train_loss -0.3494 
2025-08-28 10:25:22.525569: val_loss -0.379 
2025-08-28 10:25:22.533910: Pseudo dice [np.float32(0.6178)] 
2025-08-28 10:25:22.539227: Epoch time: 14.95 s 
2025-08-28 10:25:23.336787:  
2025-08-28 10:25:23.344126: Epoch 510 
2025-08-28 10:25:23.349230: Current learning rate: 0.00526 
2025-08-28 10:25:38.620797: train_loss -0.3065 
2025-08-28 10:25:38.629169: val_loss -0.3639 
2025-08-28 10:25:38.633328: Pseudo dice [np.float32(0.6538)] 
2025-08-28 10:25:38.641404: Epoch time: 15.29 s 
2025-08-28 10:25:39.279636:  
2025-08-28 10:25:39.286960: Epoch 511 
2025-08-28 10:25:39.292130: Current learning rate: 0.00525 
2025-08-28 10:25:54.328036: train_loss -0.336 
2025-08-28 10:25:54.336495: val_loss -0.3653 
2025-08-28 10:25:54.340671: Pseudo dice [np.float32(0.6684)] 
2025-08-28 10:25:54.346201: Epoch time: 15.05 s 
2025-08-28 10:25:54.979871:  
2025-08-28 10:25:54.988147: Epoch 512 
2025-08-28 10:25:54.992332: Current learning rate: 0.00524 
2025-08-28 10:26:09.881184: train_loss -0.3326 
2025-08-28 10:26:09.889521: val_loss -0.3296 
2025-08-28 10:26:09.893579: Pseudo dice [np.float32(0.6271)] 
2025-08-28 10:26:09.902827: Epoch time: 14.9 s 
2025-08-28 10:26:10.533835:  
2025-08-28 10:26:10.541181: Epoch 513 
2025-08-28 10:26:10.546347: Current learning rate: 0.00523 
2025-08-28 10:26:25.884867: train_loss -0.3548 
2025-08-28 10:26:25.892994: val_loss -0.3956 
2025-08-28 10:26:25.897217: Pseudo dice [np.float32(0.7251)] 
2025-08-28 10:26:25.907610: Epoch time: 15.35 s 
2025-08-28 10:26:25.913759: Yayy! New best EMA pseudo Dice: 0.6582000255584717 
2025-08-28 10:26:26.738524:  
2025-08-28 10:26:26.746881: Epoch 514 
2025-08-28 10:26:26.753243: Current learning rate: 0.00522 
2025-08-28 10:26:41.721571: train_loss -0.3277 
2025-08-28 10:26:41.733518: val_loss -0.325 
2025-08-28 10:26:41.738147: Pseudo dice [np.float32(0.6136)] 
2025-08-28 10:26:41.744295: Epoch time: 14.99 s 
2025-08-28 10:26:42.379220:  
2025-08-28 10:26:42.388511: Epoch 515 
2025-08-28 10:26:42.394838: Current learning rate: 0.00521 
2025-08-28 10:26:57.541506: train_loss -0.2923 
2025-08-28 10:26:57.549610: val_loss -0.3368 
2025-08-28 10:26:57.553777: Pseudo dice [np.float32(0.6335)] 
2025-08-28 10:26:57.561762: Epoch time: 15.16 s 
2025-08-28 10:26:58.340981:  
2025-08-28 10:26:58.351522: Epoch 516 
2025-08-28 10:26:58.357584: Current learning rate: 0.0052 
2025-08-28 10:27:12.702228: train_loss -0.326 
2025-08-28 10:27:12.710578: val_loss -0.3693 
2025-08-28 10:27:12.714673: Pseudo dice [np.float32(0.6844)] 
2025-08-28 10:27:12.723917: Epoch time: 14.36 s 
2025-08-28 10:27:13.364229:  
2025-08-28 10:27:13.372576: Epoch 517 
2025-08-28 10:27:13.377745: Current learning rate: 0.00519 
2025-08-28 10:27:28.376203: train_loss -0.3301 
2025-08-28 10:27:28.384572: val_loss -0.3926 
2025-08-28 10:27:28.388709: Pseudo dice [np.float32(0.682)] 
2025-08-28 10:27:28.397056: Epoch time: 15.01 s 
2025-08-28 10:27:29.036213:  
2025-08-28 10:27:29.043468: Epoch 518 
2025-08-28 10:27:29.048756: Current learning rate: 0.00518 
2025-08-28 10:27:43.637269: train_loss -0.3302 
2025-08-28 10:27:43.645608: val_loss -0.3955 
2025-08-28 10:27:43.653804: Pseudo dice [np.float32(0.6276)] 
2025-08-28 10:27:43.658957: Epoch time: 14.6 s 
2025-08-28 10:27:44.293140:  
2025-08-28 10:27:44.301466: Epoch 519 
2025-08-28 10:27:44.307654: Current learning rate: 0.00518 
2025-08-28 10:27:59.007213: train_loss -0.3234 
2025-08-28 10:27:59.015171: val_loss -0.3159 
2025-08-28 10:27:59.021534: Pseudo dice [np.float32(0.614)] 
2025-08-28 10:27:59.029025: Epoch time: 14.72 s 
2025-08-28 10:27:59.657423:  
2025-08-28 10:27:59.666814: Epoch 520 
2025-08-28 10:27:59.672963: Current learning rate: 0.00517 
2025-08-28 10:28:15.414919: train_loss -0.3356 
2025-08-28 10:28:15.427364: val_loss -0.3578 
2025-08-28 10:28:15.431557: Pseudo dice [np.float32(0.617)] 
2025-08-28 10:28:15.438587: Epoch time: 15.76 s 
2025-08-28 10:28:16.084213:  
2025-08-28 10:28:16.091579: Epoch 521 
2025-08-28 10:28:16.097024: Current learning rate: 0.00516 
2025-08-28 10:28:31.130556: train_loss -0.3457 
2025-08-28 10:28:31.138905: val_loss -0.3497 
2025-08-28 10:28:31.143308: Pseudo dice [np.float32(0.645)] 
2025-08-28 10:28:31.152159: Epoch time: 15.05 s 
2025-08-28 10:28:31.778141:  
2025-08-28 10:28:31.786445: Epoch 522 
2025-08-28 10:28:31.791532: Current learning rate: 0.00515 
2025-08-28 10:28:46.420815: train_loss -0.3228 
2025-08-28 10:28:46.429188: val_loss -0.3288 
2025-08-28 10:28:46.433325: Pseudo dice [np.float32(0.5713)] 
2025-08-28 10:28:46.439421: Epoch time: 14.64 s 
2025-08-28 10:28:47.238227:  
2025-08-28 10:28:47.245540: Epoch 523 
2025-08-28 10:28:47.250671: Current learning rate: 0.00514 
2025-08-28 10:29:01.965489: train_loss -0.3452 
2025-08-28 10:29:01.973870: val_loss -0.3932 
2025-08-28 10:29:01.978012: Pseudo dice [np.float32(0.6409)] 
2025-08-28 10:29:01.986386: Epoch time: 14.73 s 
2025-08-28 10:29:02.624418:  
2025-08-28 10:29:02.632735: Epoch 524 
2025-08-28 10:29:02.638021: Current learning rate: 0.00513 
2025-08-28 10:29:17.043022: train_loss -0.3453 
2025-08-28 10:29:17.051401: val_loss -0.3769 
2025-08-28 10:29:17.059776: Pseudo dice [np.float32(0.5394)] 
2025-08-28 10:29:17.065363: Epoch time: 14.42 s 
2025-08-28 10:29:17.770884:  
2025-08-28 10:29:17.780982: Epoch 525 
2025-08-28 10:29:17.789640: Current learning rate: 0.00512 
2025-08-28 10:29:33.922393: train_loss -0.339 
2025-08-28 10:29:33.932897: val_loss -0.3604 
2025-08-28 10:29:33.939132: Pseudo dice [np.float32(0.6171)] 
2025-08-28 10:29:33.945461: Epoch time: 16.15 s 
2025-08-28 10:29:34.643955:  
2025-08-28 10:29:34.656041: Epoch 526 
2025-08-28 10:29:34.662496: Current learning rate: 0.00511 
2025-08-28 10:29:50.789204: train_loss -0.3255 
2025-08-28 10:29:50.797596: val_loss -0.3673 
2025-08-28 10:29:50.801752: Pseudo dice [np.float32(0.5987)] 
2025-08-28 10:29:50.808323: Epoch time: 16.15 s 
2025-08-28 10:29:51.492058:  
2025-08-28 10:29:51.500246: Epoch 527 
2025-08-28 10:29:51.508816: Current learning rate: 0.0051 
2025-08-28 10:30:07.793715: train_loss -0.3321 
2025-08-28 10:30:07.806284: val_loss -0.4149 
2025-08-28 10:30:07.810638: Pseudo dice [np.float32(0.6909)] 
2025-08-28 10:30:07.817830: Epoch time: 16.3 s 
2025-08-28 10:30:08.528808:  
2025-08-28 10:30:08.539211: Epoch 528 
2025-08-28 10:30:08.549397: Current learning rate: 0.00509 
2025-08-28 10:30:24.723433: train_loss -0.3473 
2025-08-28 10:30:24.731570: val_loss -0.3919 
2025-08-28 10:30:24.735634: Pseudo dice [np.float32(0.7)] 
2025-08-28 10:30:24.743903: Epoch time: 16.2 s 
2025-08-28 10:30:25.451992:  
2025-08-28 10:30:25.460900: Epoch 529 
2025-08-28 10:30:25.467674: Current learning rate: 0.00508 
2025-08-28 10:30:42.073941: train_loss -0.323 
2025-08-28 10:30:42.082283: val_loss -0.335 
2025-08-28 10:30:42.090482: Pseudo dice [np.float32(0.6556)] 
2025-08-28 10:30:42.096042: Epoch time: 16.62 s 
2025-08-28 10:30:42.962065:  
2025-08-28 10:30:42.970356: Epoch 530 
2025-08-28 10:30:42.981041: Current learning rate: 0.00507 
2025-08-28 10:30:59.215815: train_loss -0.3128 
2025-08-28 10:30:59.224234: val_loss -0.3541 
2025-08-28 10:30:59.232588: Pseudo dice [np.float32(0.6026)] 
2025-08-28 10:30:59.237903: Epoch time: 16.25 s 
2025-08-28 10:30:59.930811:  
2025-08-28 10:30:59.941601: Epoch 531 
2025-08-28 10:30:59.950834: Current learning rate: 0.00506 
2025-08-28 10:31:16.003491: train_loss -0.3508 
2025-08-28 10:31:16.016628: val_loss -0.4138 
2025-08-28 10:31:16.020174: Pseudo dice [np.float32(0.709)] 
2025-08-28 10:31:16.027526: Epoch time: 16.07 s 
2025-08-28 10:31:16.723968:  
2025-08-28 10:31:16.736489: Epoch 532 
2025-08-28 10:31:16.744449: Current learning rate: 0.00505 
2025-08-28 10:31:32.903682: train_loss -0.3552 
2025-08-28 10:31:32.912051: val_loss -0.3828 
2025-08-28 10:31:32.916195: Pseudo dice [np.float32(0.6397)] 
2025-08-28 10:31:32.923519: Epoch time: 16.18 s 
2025-08-28 10:31:33.593978:  
2025-08-28 10:31:33.602278: Epoch 533 
2025-08-28 10:31:33.607500: Current learning rate: 0.00504 
2025-08-28 10:31:49.837264: train_loss -0.3488 
2025-08-28 10:31:49.847837: val_loss -0.338 
2025-08-28 10:31:49.854241: Pseudo dice [np.float32(0.5931)] 
2025-08-28 10:31:49.860459: Epoch time: 16.24 s 
2025-08-28 10:31:50.533699:  
2025-08-28 10:31:50.540964: Epoch 534 
2025-08-28 10:31:50.546213: Current learning rate: 0.00503 
2025-08-28 10:32:06.704366: train_loss -0.348 
2025-08-28 10:32:06.712485: val_loss -0.3811 
2025-08-28 10:32:06.720602: Pseudo dice [np.float32(0.6475)] 
2025-08-28 10:32:06.725909: Epoch time: 16.17 s 
2025-08-28 10:32:07.418395:  
2025-08-28 10:32:07.427675: Epoch 535 
2025-08-28 10:32:07.433673: Current learning rate: 0.00502 
2025-08-28 10:32:23.508352: train_loss -0.3343 
2025-08-28 10:32:23.516765: val_loss -0.3986 
2025-08-28 10:32:23.525510: Pseudo dice [np.float32(0.6355)] 
2025-08-28 10:32:23.530767: Epoch time: 16.09 s 
2025-08-28 10:32:24.235185:  
2025-08-28 10:32:24.243447: Epoch 536 
2025-08-28 10:32:24.250447: Current learning rate: 0.00501 
2025-08-28 10:32:40.646302: train_loss -0.3284 
2025-08-28 10:32:40.654664: val_loss -0.3612 
2025-08-28 10:32:40.659141: Pseudo dice [np.float32(0.5577)] 
2025-08-28 10:32:40.666110: Epoch time: 16.41 s 
2025-08-28 10:32:41.509615:  
2025-08-28 10:32:41.518212: Epoch 537 
2025-08-28 10:32:41.526566: Current learning rate: 0.005 
2025-08-28 10:32:57.726210: train_loss -0.3244 
2025-08-28 10:32:57.734273: val_loss -0.4229 
2025-08-28 10:32:57.738393: Pseudo dice [np.float32(0.6722)] 
2025-08-28 10:32:57.747925: Epoch time: 16.22 s 
2025-08-28 10:32:58.451825:  
2025-08-28 10:32:58.460683: Epoch 538 
2025-08-28 10:32:58.464505: Current learning rate: 0.00499 
2025-08-28 10:33:14.755403: train_loss -0.3513 
2025-08-28 10:33:14.763701: val_loss -0.4165 
2025-08-28 10:33:14.767902: Pseudo dice [np.float32(0.6854)] 
2025-08-28 10:33:14.776994: Epoch time: 16.31 s 
2025-08-28 10:33:15.479052:  
2025-08-28 10:33:15.487335: Epoch 539 
2025-08-28 10:33:15.492451: Current learning rate: 0.00498 
2025-08-28 10:33:31.797421: train_loss -0.3318 
2025-08-28 10:33:31.805730: val_loss -0.3112 
2025-08-28 10:33:31.809916: Pseudo dice [np.float32(0.5941)] 
2025-08-28 10:33:31.817348: Epoch time: 16.32 s 
2025-08-28 10:33:32.515817:  
2025-08-28 10:33:32.524670: Epoch 540 
2025-08-28 10:33:32.532488: Current learning rate: 0.00497 
2025-08-28 10:33:49.035484: train_loss -0.3283 
2025-08-28 10:33:49.043817: val_loss -0.424 
2025-08-28 10:33:49.047948: Pseudo dice [np.float32(0.7183)] 
2025-08-28 10:33:49.056200: Epoch time: 16.52 s 
2025-08-28 10:33:49.761940:  
2025-08-28 10:33:49.770647: Epoch 541 
2025-08-28 10:33:49.778747: Current learning rate: 0.00496 
2025-08-28 10:34:05.910971: train_loss -0.3422 
2025-08-28 10:34:05.918956: val_loss -0.3708 
2025-08-28 10:34:05.923402: Pseudo dice [np.float32(0.6199)] 
2025-08-28 10:34:05.931875: Epoch time: 16.15 s 
2025-08-28 10:34:06.630351:  
2025-08-28 10:34:06.637377: Epoch 542 
2025-08-28 10:34:06.643376: Current learning rate: 0.00495 
2025-08-28 10:34:22.685680: train_loss -0.3254 
2025-08-28 10:34:22.698519: val_loss -0.3769 
2025-08-28 10:34:22.702732: Pseudo dice [np.float32(0.6592)] 
2025-08-28 10:34:22.709712: Epoch time: 16.06 s 
2025-08-28 10:34:23.403606:  
2025-08-28 10:34:23.411322: Epoch 543 
2025-08-28 10:34:23.417393: Current learning rate: 0.00494 
2025-08-28 10:34:39.321428: train_loss -0.3273 
2025-08-28 10:34:39.331362: val_loss -0.3699 
2025-08-28 10:34:39.335861: Pseudo dice [np.float32(0.6303)] 
2025-08-28 10:34:39.345019: Epoch time: 15.92 s 
2025-08-28 10:34:40.234463:  
2025-08-28 10:34:40.241709: Epoch 544 
2025-08-28 10:34:40.246891: Current learning rate: 0.00493 
2025-08-28 10:34:56.290085: train_loss -0.3337 
2025-08-28 10:34:56.298686: val_loss -0.4342 
2025-08-28 10:34:56.302650: Pseudo dice [np.float32(0.6519)] 
2025-08-28 10:34:56.311788: Epoch time: 16.06 s 
2025-08-28 10:34:57.017803:  
2025-08-28 10:34:57.025800: Epoch 545 
2025-08-28 10:34:57.036503: Current learning rate: 0.00492 
2025-08-28 10:35:13.469733: train_loss -0.3111 
2025-08-28 10:35:13.482227: val_loss -0.4149 
2025-08-28 10:35:13.486439: Pseudo dice [np.float32(0.679)] 
2025-08-28 10:35:13.493807: Epoch time: 16.45 s 
2025-08-28 10:35:14.191144:  
2025-08-28 10:35:14.199544: Epoch 546 
2025-08-28 10:35:14.209369: Current learning rate: 0.00491 
2025-08-28 10:35:30.307340: train_loss -0.3254 
2025-08-28 10:35:30.315707: val_loss -0.3405 
2025-08-28 10:35:30.319872: Pseudo dice [np.float32(0.6602)] 
2025-08-28 10:35:30.329221: Epoch time: 16.12 s 
2025-08-28 10:35:31.022617:  
2025-08-28 10:35:31.031008: Epoch 547 
2025-08-28 10:35:31.037095: Current learning rate: 0.0049 
2025-08-28 10:35:47.324567: train_loss -0.3277 
2025-08-28 10:35:47.332702: val_loss -0.3676 
2025-08-28 10:35:47.336908: Pseudo dice [np.float32(0.6649)] 
2025-08-28 10:35:47.344428: Epoch time: 16.3 s 
2025-08-28 10:35:48.038612:  
2025-08-28 10:35:48.045831: Epoch 548 
2025-08-28 10:35:48.054287: Current learning rate: 0.00489 
2025-08-28 10:36:04.391823: train_loss -0.3492 
2025-08-28 10:36:04.399931: val_loss -0.3821 
2025-08-28 10:36:04.404189: Pseudo dice [np.float32(0.6174)] 
2025-08-28 10:36:04.412121: Epoch time: 16.36 s 
2025-08-28 10:36:05.136880:  
2025-08-28 10:36:05.146296: Epoch 549 
2025-08-28 10:36:05.153707: Current learning rate: 0.00488 
2025-08-28 10:36:21.771552: train_loss -0.3316 
2025-08-28 10:36:21.779590: val_loss -0.3486 
2025-08-28 10:36:21.785921: Pseudo dice [np.float32(0.5166)] 
2025-08-28 10:36:21.792190: Epoch time: 16.64 s 
2025-08-28 10:36:22.769194:  
2025-08-28 10:36:22.777485: Epoch 550 
2025-08-28 10:36:22.782647: Current learning rate: 0.00487 
2025-08-28 10:36:38.992610: train_loss -0.3492 
2025-08-28 10:36:39.001345: val_loss -0.3829 
2025-08-28 10:36:39.005505: Pseudo dice [np.float32(0.6323)] 
2025-08-28 10:36:39.011837: Epoch time: 16.22 s 
2025-08-28 10:36:39.868453:  
2025-08-28 10:36:39.876893: Epoch 551 
2025-08-28 10:36:39.885979: Current learning rate: 0.00486 
2025-08-28 10:36:56.205601: train_loss -0.3231 
2025-08-28 10:36:56.209835: val_loss -0.4119 
2025-08-28 10:36:56.218110: Pseudo dice [np.float32(0.6942)] 
2025-08-28 10:36:56.223767: Epoch time: 16.34 s 
2025-08-28 10:36:56.923743:  
2025-08-28 10:36:56.932733: Epoch 552 
2025-08-28 10:36:56.935759: Current learning rate: 0.00485 
2025-08-28 10:37:12.801382: train_loss -0.3525 
2025-08-28 10:37:12.814200: val_loss -0.3785 
2025-08-28 10:37:12.818038: Pseudo dice [np.float32(0.6456)] 
2025-08-28 10:37:12.825366: Epoch time: 15.88 s 
2025-08-28 10:37:13.545638:  
2025-08-28 10:37:13.556240: Epoch 553 
2025-08-28 10:37:13.560688: Current learning rate: 0.00484 
2025-08-28 10:37:29.814167: train_loss -0.3501 
2025-08-28 10:37:29.822524: val_loss -0.3908 
2025-08-28 10:37:29.830803: Pseudo dice [np.float32(0.6471)] 
2025-08-28 10:37:29.834812: Epoch time: 16.27 s 
2025-08-28 10:37:30.552270:  
2025-08-28 10:37:30.557928: Epoch 554 
2025-08-28 10:37:30.566933: Current learning rate: 0.00484 
2025-08-28 10:37:46.743419: train_loss -0.3396 
2025-08-28 10:37:46.747769: val_loss -0.3297 
2025-08-28 10:37:46.756423: Pseudo dice [np.float32(0.6361)] 
2025-08-28 10:37:46.761769: Epoch time: 16.19 s 
2025-08-28 10:37:47.444168:  
2025-08-28 10:37:47.452757: Epoch 555 
2025-08-28 10:37:47.462795: Current learning rate: 0.00483 
2025-08-28 10:38:03.647975: train_loss -0.3359 
2025-08-28 10:38:03.656560: val_loss -0.4 
2025-08-28 10:38:03.660472: Pseudo dice [np.float32(0.674)] 
2025-08-28 10:38:03.668718: Epoch time: 16.21 s 
2025-08-28 10:38:04.362189:  
2025-08-28 10:38:04.370520: Epoch 556 
2025-08-28 10:38:04.378981: Current learning rate: 0.00482 
2025-08-28 10:38:20.736248: train_loss -0.3376 
2025-08-28 10:38:20.748364: val_loss -0.3736 
2025-08-28 10:38:20.752789: Pseudo dice [np.float32(0.6451)] 
2025-08-28 10:38:20.759772: Epoch time: 16.38 s 
2025-08-28 10:38:21.636595:  
2025-08-28 10:38:21.646824: Epoch 557 
2025-08-28 10:38:21.652485: Current learning rate: 0.00481 
2025-08-28 10:38:37.681538: train_loss -0.3227 
2025-08-28 10:38:37.690290: val_loss -0.281 
2025-08-28 10:38:37.694618: Pseudo dice [np.float32(0.6575)] 
2025-08-28 10:38:37.700816: Epoch time: 16.05 s 
2025-08-28 10:38:38.405615:  
2025-08-28 10:38:38.414577: Epoch 558 
2025-08-28 10:38:38.421179: Current learning rate: 0.0048 
2025-08-28 10:38:54.857545: train_loss -0.3668 
2025-08-28 10:38:54.866038: val_loss -0.3842 
2025-08-28 10:38:54.869931: Pseudo dice [np.float32(0.6755)] 
2025-08-28 10:38:54.879214: Epoch time: 16.45 s 
2025-08-28 10:38:55.591390:  
2025-08-28 10:38:55.602134: Epoch 559 
2025-08-28 10:38:55.609180: Current learning rate: 0.00479 
2025-08-28 10:39:11.713007: train_loss -0.3277 
2025-08-28 10:39:11.724256: val_loss -0.4031 
2025-08-28 10:39:11.728426: Pseudo dice [np.float32(0.6445)] 
2025-08-28 10:39:11.736826: Epoch time: 16.12 s 
2025-08-28 10:39:12.436306:  
2025-08-28 10:39:12.444817: Epoch 560 
2025-08-28 10:39:12.449983: Current learning rate: 0.00478 
2025-08-28 10:39:28.661978: train_loss -0.3178 
2025-08-28 10:39:28.670773: val_loss -0.4229 
2025-08-28 10:39:28.678936: Pseudo dice [np.float32(0.7284)] 
2025-08-28 10:39:28.685139: Epoch time: 16.23 s 
2025-08-28 10:39:29.367998:  
2025-08-28 10:39:29.376270: Epoch 561 
2025-08-28 10:39:29.381391: Current learning rate: 0.00477 
2025-08-28 10:39:46.200400: train_loss -0.348 
2025-08-28 10:39:46.208766: val_loss -0.3957 
2025-08-28 10:39:46.212958: Pseudo dice [np.float32(0.6658)] 
2025-08-28 10:39:46.222096: Epoch time: 16.83 s 
2025-08-28 10:39:46.923019:  
2025-08-28 10:39:46.932405: Epoch 562 
2025-08-28 10:39:46.939175: Current learning rate: 0.00476 
2025-08-28 10:40:04.134989: train_loss -0.349 
2025-08-28 10:40:04.143366: val_loss -0.4224 
2025-08-28 10:40:04.152167: Pseudo dice [np.float32(0.6236)] 
2025-08-28 10:40:04.156966: Epoch time: 17.21 s 
2025-08-28 10:40:04.836625:  
2025-08-28 10:40:04.843813: Epoch 563 
2025-08-28 10:40:04.849220: Current learning rate: 0.00475 
2025-08-28 10:40:22.132027: train_loss -0.3275 
2025-08-28 10:40:22.140242: val_loss -0.406 
2025-08-28 10:40:22.144709: Pseudo dice [np.float32(0.6304)] 
2025-08-28 10:40:22.153584: Epoch time: 17.3 s 
2025-08-28 10:40:23.017278:  
2025-08-28 10:40:23.028031: Epoch 564 
2025-08-28 10:40:23.038181: Current learning rate: 0.00474 
2025-08-28 10:40:39.850076: train_loss -0.338 
2025-08-28 10:40:39.858064: val_loss -0.367 
2025-08-28 10:40:39.866425: Pseudo dice [np.float32(0.6069)] 
2025-08-28 10:40:39.875624: Epoch time: 16.83 s 
2025-08-28 10:40:40.571124:  
2025-08-28 10:40:40.579970: Epoch 565 
2025-08-28 10:40:40.589615: Current learning rate: 0.00473 
2025-08-28 10:40:57.484263: train_loss -0.3462 
2025-08-28 10:40:57.492379: val_loss -0.3807 
2025-08-28 10:40:57.496548: Pseudo dice [np.float32(0.6802)] 
2025-08-28 10:40:57.505822: Epoch time: 16.91 s 
2025-08-28 10:40:58.184532:  
2025-08-28 10:40:58.191882: Epoch 566 
2025-08-28 10:40:58.201165: Current learning rate: 0.00472 
2025-08-28 10:41:15.151592: train_loss -0.321 
2025-08-28 10:41:15.160029: val_loss -0.4377 
2025-08-28 10:41:15.164488: Pseudo dice [np.float32(0.697)] 
2025-08-28 10:41:15.170558: Epoch time: 16.97 s 
2025-08-28 10:41:15.865526:  
2025-08-28 10:41:15.874622: Epoch 567 
2025-08-28 10:41:15.877708: Current learning rate: 0.00471 
2025-08-28 10:41:32.773494: train_loss -0.3354 
2025-08-28 10:41:32.781766: val_loss -0.3622 
2025-08-28 10:41:32.785921: Pseudo dice [np.float32(0.6105)] 
2025-08-28 10:41:32.795175: Epoch time: 16.91 s 
2025-08-28 10:41:33.488747:  
2025-08-28 10:41:33.500015: Epoch 568 
2025-08-28 10:41:33.508031: Current learning rate: 0.0047 
2025-08-28 10:41:50.549947: train_loss -0.3349 
2025-08-28 10:41:50.557836: val_loss -0.4012 
2025-08-28 10:41:50.562318: Pseudo dice [np.float32(0.641)] 
2025-08-28 10:41:50.570305: Epoch time: 17.06 s 
2025-08-28 10:41:51.258463:  
2025-08-28 10:41:51.265731: Epoch 569 
2025-08-28 10:41:51.270872: Current learning rate: 0.00469 
2025-08-28 10:42:08.121261: train_loss -0.3331 
2025-08-28 10:42:08.133954: val_loss -0.3391 
2025-08-28 10:42:08.137877: Pseudo dice [np.float32(0.5729)] 
2025-08-28 10:42:08.147055: Epoch time: 16.86 s 
2025-08-28 10:42:08.822165:  
2025-08-28 10:42:08.830221: Epoch 570 
2025-08-28 10:42:08.838601: Current learning rate: 0.00468 
2025-08-28 10:42:26.039339: train_loss -0.3393 
2025-08-28 10:42:26.047455: val_loss -0.4147 
2025-08-28 10:42:26.056295: Pseudo dice [np.float32(0.6476)] 
2025-08-28 10:42:26.061228: Epoch time: 17.22 s 
2025-08-28 10:42:26.888870:  
2025-08-28 10:42:26.897162: Epoch 571 
2025-08-28 10:42:26.904529: Current learning rate: 0.00467 
2025-08-28 10:42:43.811591: train_loss -0.3102 
2025-08-28 10:42:43.819343: val_loss -0.389 
2025-08-28 10:42:43.823499: Pseudo dice [np.float32(0.6927)] 
2025-08-28 10:42:43.831808: Epoch time: 16.92 s 
2025-08-28 10:42:44.534573:  
2025-08-28 10:42:44.546654: Epoch 572 
2025-08-28 10:42:44.554137: Current learning rate: 0.00466 
2025-08-28 10:43:01.282665: train_loss -0.3464 
2025-08-28 10:43:01.291009: val_loss -0.3584 
2025-08-28 10:43:01.299359: Pseudo dice [np.float32(0.6498)] 
2025-08-28 10:43:01.304692: Epoch time: 16.75 s 
2025-08-28 10:43:02.011234:  
2025-08-28 10:43:02.021946: Epoch 573 
2025-08-28 10:43:02.031163: Current learning rate: 0.00465 
2025-08-28 10:43:18.991978: train_loss -0.3316 
2025-08-28 10:43:19.004479: val_loss -0.3593 
2025-08-28 10:43:19.008677: Pseudo dice [np.float32(0.6433)] 
2025-08-28 10:43:19.015165: Epoch time: 16.98 s 
2025-08-28 10:43:19.719709:  
2025-08-28 10:43:19.729245: Epoch 574 
2025-08-28 10:43:19.738580: Current learning rate: 0.00464 
2025-08-28 10:43:36.021502: train_loss -0.3801 
2025-08-28 10:43:36.030121: val_loss -0.4381 
2025-08-28 10:43:36.038169: Pseudo dice [np.float32(0.7012)] 
2025-08-28 10:43:36.043733: Epoch time: 16.3 s 
2025-08-28 10:43:36.727855:  
2025-08-28 10:43:36.736295: Epoch 575 
2025-08-28 10:43:36.742878: Current learning rate: 0.00463 
2025-08-28 10:43:53.822557: train_loss -0.3436 
2025-08-28 10:43:53.831223: val_loss -0.3582 
2025-08-28 10:43:53.835423: Pseudo dice [np.float32(0.6594)] 
2025-08-28 10:43:53.843380: Epoch time: 17.1 s 
2025-08-28 10:43:54.541627:  
2025-08-28 10:43:54.550354: Epoch 576 
2025-08-28 10:43:54.557436: Current learning rate: 0.00462 
2025-08-28 10:44:11.653460: train_loss -0.3359 
2025-08-28 10:44:11.665364: val_loss -0.4367 
2025-08-28 10:44:11.669840: Pseudo dice [np.float32(0.6645)] 
2025-08-28 10:44:11.678691: Epoch time: 17.11 s 
2025-08-28 10:44:12.370147:  
2025-08-28 10:44:12.379319: Epoch 577 
2025-08-28 10:44:12.387996: Current learning rate: 0.00461 
2025-08-28 10:44:29.546003: train_loss -0.2992 
2025-08-28 10:44:29.554344: val_loss -0.3558 
2025-08-28 10:44:29.562453: Pseudo dice [np.float32(0.6054)] 
2025-08-28 10:44:29.567770: Epoch time: 17.18 s 
2025-08-28 10:44:30.420738:  
2025-08-28 10:44:30.429338: Epoch 578 
2025-08-28 10:44:30.434536: Current learning rate: 0.0046 
2025-08-28 10:44:47.376041: train_loss -0.342 
2025-08-28 10:44:47.384353: val_loss -0.4267 
2025-08-28 10:44:47.388837: Pseudo dice [np.float32(0.651)] 
2025-08-28 10:44:47.396902: Epoch time: 16.96 s 
2025-08-28 10:44:48.159986:  
2025-08-28 10:44:48.168457: Epoch 579 
2025-08-28 10:44:48.172554: Current learning rate: 0.00459 
2025-08-28 10:45:05.235503: train_loss -0.3571 
2025-08-28 10:45:05.243876: val_loss -0.3552 
2025-08-28 10:45:05.247952: Pseudo dice [np.float32(0.6562)] 
2025-08-28 10:45:05.257172: Epoch time: 17.08 s 
2025-08-28 10:45:05.961087:  
2025-08-28 10:45:05.969433: Epoch 580 
2025-08-28 10:45:05.977981: Current learning rate: 0.00458 
2025-08-28 10:45:22.719720: train_loss -0.3616 
2025-08-28 10:45:22.728285: val_loss -0.4033 
2025-08-28 10:45:22.736758: Pseudo dice [np.float32(0.7218)] 
2025-08-28 10:45:22.741695: Epoch time: 16.76 s 
2025-08-28 10:45:23.440851:  
2025-08-28 10:45:23.449720: Epoch 581 
2025-08-28 10:45:23.456772: Current learning rate: 0.00457 
2025-08-28 10:45:40.258370: train_loss -0.3399 
2025-08-28 10:45:40.266557: val_loss -0.352 
2025-08-28 10:45:40.274367: Pseudo dice [np.float32(0.5876)] 
2025-08-28 10:45:40.280193: Epoch time: 16.82 s 
2025-08-28 10:45:40.955616:  
2025-08-28 10:45:40.964857: Epoch 582 
2025-08-28 10:45:40.974746: Current learning rate: 0.00456 
2025-08-28 10:45:58.150953: train_loss -0.3308 
2025-08-28 10:45:58.159183: val_loss -0.4219 
2025-08-28 10:45:58.163368: Pseudo dice [np.float32(0.7087)] 
2025-08-28 10:45:58.172447: Epoch time: 17.2 s 
2025-08-28 10:45:58.879278:  
2025-08-28 10:45:58.890162: Epoch 583 
2025-08-28 10:45:58.896301: Current learning rate: 0.00455 
2025-08-28 10:46:15.881067: train_loss -0.3579 
2025-08-28 10:46:15.889710: val_loss -0.3953 
2025-08-28 10:46:15.897730: Pseudo dice [np.float32(0.6486)] 
2025-08-28 10:46:15.903054: Epoch time: 17.0 s 
2025-08-28 10:46:16.603665:  
2025-08-28 10:46:16.612018: Epoch 584 
2025-08-28 10:46:16.620830: Current learning rate: 0.00454 
2025-08-28 10:46:33.448581: train_loss -0.3513 
2025-08-28 10:46:33.457051: val_loss -0.4009 
2025-08-28 10:46:33.461101: Pseudo dice [np.float32(0.6637)] 
2025-08-28 10:46:33.470259: Epoch time: 16.85 s 
2025-08-28 10:46:34.309801:  
2025-08-28 10:46:34.321303: Epoch 585 
2025-08-28 10:46:34.327729: Current learning rate: 0.00453 
2025-08-28 10:46:50.786730: train_loss -0.3414 
2025-08-28 10:46:50.795076: val_loss -0.4052 
2025-08-28 10:46:50.799421: Pseudo dice [np.float32(0.6809)] 
2025-08-28 10:46:50.806432: Epoch time: 16.48 s 
2025-08-28 10:46:50.812099: Yayy! New best EMA pseudo Dice: 0.6588000059127808 
2025-08-28 10:46:51.712467:  
2025-08-28 10:46:51.720968: Epoch 586 
2025-08-28 10:46:51.726334: Current learning rate: 0.00452 
2025-08-28 10:47:07.858531: train_loss -0.3252 
2025-08-28 10:47:07.871033: val_loss -0.3535 
2025-08-28 10:47:07.874938: Pseudo dice [np.float32(0.724)] 
2025-08-28 10:47:07.883878: Epoch time: 16.15 s 
2025-08-28 10:47:07.890713: Yayy! New best EMA pseudo Dice: 0.6653000116348267 
2025-08-28 10:47:08.779758:  
2025-08-28 10:47:08.791068: Epoch 587 
2025-08-28 10:47:08.798894: Current learning rate: 0.00451 
2025-08-28 10:47:24.916623: train_loss -0.3492 
2025-08-28 10:47:24.925005: val_loss -0.3996 
2025-08-28 10:47:24.929171: Pseudo dice [np.float32(0.7194)] 
2025-08-28 10:47:24.936541: Epoch time: 16.14 s 
2025-08-28 10:47:24.942122: Yayy! New best EMA pseudo Dice: 0.6707000136375427 
2025-08-28 10:47:25.853913:  
2025-08-28 10:47:25.862280: Epoch 588 
2025-08-28 10:47:25.867484: Current learning rate: 0.0045 
2025-08-28 10:47:41.996192: train_loss -0.3425 
2025-08-28 10:47:42.008761: val_loss -0.474 
2025-08-28 10:47:42.013143: Pseudo dice [np.float32(0.7113)] 
2025-08-28 10:47:42.020284: Epoch time: 16.14 s 
2025-08-28 10:47:42.026916: Yayy! New best EMA pseudo Dice: 0.6747999787330627 
2025-08-28 10:47:42.979418:  
2025-08-28 10:47:42.986524: Epoch 589 
2025-08-28 10:47:42.995655: Current learning rate: 0.00449 
2025-08-28 10:47:58.954832: train_loss -0.3493 
2025-08-28 10:47:58.963145: val_loss -0.3817 
2025-08-28 10:47:58.971534: Pseudo dice [np.float32(0.6077)] 
2025-08-28 10:47:58.977303: Epoch time: 15.98 s 
2025-08-28 10:47:59.681508:  
2025-08-28 10:47:59.688694: Epoch 590 
2025-08-28 10:47:59.694878: Current learning rate: 0.00448 
2025-08-28 10:48:16.151129: train_loss -0.3594 
2025-08-28 10:48:16.163690: val_loss -0.4364 
2025-08-28 10:48:16.172010: Pseudo dice [np.float32(0.7322)] 
2025-08-28 10:48:16.177550: Epoch time: 16.47 s 
2025-08-28 10:48:17.076556:  
2025-08-28 10:48:17.084275: Epoch 591 
2025-08-28 10:48:17.089475: Current learning rate: 0.00447 
2025-08-28 10:48:32.709314: train_loss -0.3482 
2025-08-28 10:48:32.717713: val_loss -0.3916 
2025-08-28 10:48:32.721854: Pseudo dice [np.float32(0.6637)] 
2025-08-28 10:48:32.729558: Epoch time: 15.63 s 
2025-08-28 10:48:33.430803:  
2025-08-28 10:48:33.440335: Epoch 592 
2025-08-28 10:48:33.448971: Current learning rate: 0.00446 
2025-08-28 10:48:50.247660: train_loss -0.3664 
2025-08-28 10:48:50.256100: val_loss -0.3832 
2025-08-28 10:48:50.260443: Pseudo dice [np.float32(0.67)] 
2025-08-28 10:48:50.268637: Epoch time: 16.82 s 
2025-08-28 10:48:50.988646:  
2025-08-28 10:48:50.996306: Epoch 593 
2025-08-28 10:48:51.005700: Current learning rate: 0.00445 
2025-08-28 10:49:07.619103: train_loss -0.336 
2025-08-28 10:49:07.627435: val_loss -0.3602 
2025-08-28 10:49:07.635871: Pseudo dice [np.float32(0.6509)] 
2025-08-28 10:49:07.642217: Epoch time: 16.63 s 
2025-08-28 10:49:08.342102:  
2025-08-28 10:49:08.351650: Epoch 594 
2025-08-28 10:49:08.359869: Current learning rate: 0.00444 
2025-08-28 10:49:25.253876: train_loss -0.3423 
2025-08-28 10:49:25.261781: val_loss -0.3696 
2025-08-28 10:49:25.265959: Pseudo dice [np.float32(0.6387)] 
2025-08-28 10:49:25.275057: Epoch time: 16.91 s 
2025-08-28 10:49:25.965616:  
2025-08-28 10:49:25.972883: Epoch 595 
2025-08-28 10:49:25.978112: Current learning rate: 0.00443 
2025-08-28 10:49:42.837727: train_loss -0.3158 
2025-08-28 10:49:42.846247: val_loss -0.3488 
2025-08-28 10:49:42.850196: Pseudo dice [np.float32(0.6301)] 
2025-08-28 10:49:42.858748: Epoch time: 16.87 s 
2025-08-28 10:49:43.597858:  
2025-08-28 10:49:43.606857: Epoch 596 
2025-08-28 10:49:43.614286: Current learning rate: 0.00442 
2025-08-28 10:50:00.751806: train_loss -0.3242 
2025-08-28 10:50:00.760115: val_loss -0.3989 
2025-08-28 10:50:00.763876: Pseudo dice [np.float32(0.703)] 
2025-08-28 10:50:00.772313: Epoch time: 17.16 s 
2025-08-28 10:50:01.644202:  
2025-08-28 10:50:01.652330: Epoch 597 
2025-08-28 10:50:01.659486: Current learning rate: 0.00441 
2025-08-28 10:50:18.681797: train_loss -0.3356 
2025-08-28 10:50:18.694372: val_loss -0.4081 
2025-08-28 10:50:18.698487: Pseudo dice [np.float32(0.5838)] 
2025-08-28 10:50:18.707732: Epoch time: 17.04 s 
2025-08-28 10:50:19.419983:  
2025-08-28 10:50:19.429850: Epoch 598 
2025-08-28 10:50:19.437273: Current learning rate: 0.0044 
2025-08-28 10:50:36.241157: train_loss -0.3661 
2025-08-28 10:50:36.249350: val_loss -0.4314 
2025-08-28 10:50:36.253733: Pseudo dice [np.float32(0.6729)] 
2025-08-28 10:50:36.260878: Epoch time: 16.82 s 
2025-08-28 10:50:36.934370:  
2025-08-28 10:50:36.942736: Epoch 599 
2025-08-28 10:50:36.948962: Current learning rate: 0.00439 
2025-08-28 10:50:53.691946: train_loss -0.3603 
2025-08-28 10:50:53.700366: val_loss -0.3872 
2025-08-28 10:50:53.704320: Pseudo dice [np.float32(0.7115)] 
2025-08-28 10:50:53.713509: Epoch time: 16.76 s 
2025-08-28 10:50:54.586476:  
2025-08-28 10:50:54.595308: Epoch 600 
2025-08-28 10:50:54.602032: Current learning rate: 0.00438 
2025-08-28 10:51:10.471004: train_loss -0.3354 
2025-08-28 10:51:10.483530: val_loss -0.3726 
2025-08-28 10:51:10.487730: Pseudo dice [np.float32(0.6536)] 
2025-08-28 10:51:10.496010: Epoch time: 15.89 s 
2025-08-28 10:51:11.165373:  
2025-08-28 10:51:11.172715: Epoch 601 
2025-08-28 10:51:11.177863: Current learning rate: 0.00437 
2025-08-28 10:51:26.011742: train_loss -0.3567 
2025-08-28 10:51:26.019865: val_loss -0.4044 
2025-08-28 10:51:26.028236: Pseudo dice [np.float32(0.697)] 
2025-08-28 10:51:26.033617: Epoch time: 14.85 s 
2025-08-28 10:51:26.694484:  
2025-08-28 10:51:26.702727: Epoch 602 
2025-08-28 10:51:26.709052: Current learning rate: 0.00436 
2025-08-28 10:51:41.598184: train_loss -0.3183 
2025-08-28 10:51:41.606262: val_loss -0.3693 
2025-08-28 10:51:41.614908: Pseudo dice [np.float32(0.6019)] 
2025-08-28 10:51:41.620770: Epoch time: 14.9 s 
2025-08-28 10:51:42.423630:  
2025-08-28 10:51:42.431921: Epoch 603 
2025-08-28 10:51:42.437252: Current learning rate: 0.00435 
2025-08-28 10:51:57.568312: train_loss -0.3279 
2025-08-28 10:51:57.576366: val_loss -0.4005 
2025-08-28 10:51:57.580533: Pseudo dice [np.float32(0.6343)] 
2025-08-28 10:51:57.589608: Epoch time: 15.15 s 
2025-08-28 10:51:58.238362:  
2025-08-28 10:51:58.247895: Epoch 604 
2025-08-28 10:51:58.253052: Current learning rate: 0.00434 
2025-08-28 10:52:13.333814: train_loss -0.3464 
2025-08-28 10:52:13.342117: val_loss -0.3814 
2025-08-28 10:52:13.350504: Pseudo dice [np.float32(0.6752)] 
2025-08-28 10:52:13.355447: Epoch time: 15.1 s 
2025-08-28 10:52:14.004207:  
2025-08-28 10:52:14.013454: Epoch 605 
2025-08-28 10:52:14.020804: Current learning rate: 0.00433 
2025-08-28 10:52:29.349785: train_loss -0.3504 
2025-08-28 10:52:29.358095: val_loss -0.3884 
2025-08-28 10:52:29.362320: Pseudo dice [np.float32(0.6956)] 
2025-08-28 10:52:29.370439: Epoch time: 15.35 s 
2025-08-28 10:52:30.030635:  
2025-08-28 10:52:30.042022: Epoch 606 
2025-08-28 10:52:30.050316: Current learning rate: 0.00432 
2025-08-28 10:52:45.111005: train_loss -0.3851 
2025-08-28 10:52:45.119942: val_loss -0.4323 
2025-08-28 10:52:45.123892: Pseudo dice [np.float32(0.6825)] 
2025-08-28 10:52:45.131980: Epoch time: 15.08 s 
2025-08-28 10:52:45.788014:  
2025-08-28 10:52:45.800493: Epoch 607 
2025-08-28 10:52:45.809799: Current learning rate: 0.00431 
2025-08-28 10:53:01.277354: train_loss -0.3618 
2025-08-28 10:53:01.285807: val_loss -0.4578 
2025-08-28 10:53:01.294154: Pseudo dice [np.float32(0.7455)] 
2025-08-28 10:53:01.300697: Epoch time: 15.49 s 
2025-08-28 10:53:01.943713:  
2025-08-28 10:53:01.952055: Epoch 608 
2025-08-28 10:53:01.957208: Current learning rate: 0.0043 
2025-08-28 10:53:17.168318: train_loss -0.3493 
2025-08-28 10:53:17.180852: val_loss -0.4198 
2025-08-28 10:53:17.184928: Pseudo dice [np.float32(0.6626)] 
2025-08-28 10:53:17.193104: Epoch time: 15.23 s 
2025-08-28 10:53:17.902272:  
2025-08-28 10:53:17.910722: Epoch 609 
2025-08-28 10:53:17.915928: Current learning rate: 0.00429 
2025-08-28 10:53:32.800619: train_loss -0.3755 
2025-08-28 10:53:32.808967: val_loss -0.3755 
2025-08-28 10:53:32.817289: Pseudo dice [np.float32(0.6354)] 
2025-08-28 10:53:32.824478: Epoch time: 14.9 s 
2025-08-28 10:53:33.626337:  
2025-08-28 10:53:33.634633: Epoch 610 
2025-08-28 10:53:33.643102: Current learning rate: 0.00429 
2025-08-28 10:53:49.012676: train_loss -0.3503 
2025-08-28 10:53:49.021269: val_loss -0.3901 
2025-08-28 10:53:49.029333: Pseudo dice [np.float32(0.6556)] 
2025-08-28 10:53:49.035621: Epoch time: 15.39 s 
2025-08-28 10:53:49.687140:  
2025-08-28 10:53:49.695554: Epoch 611 
2025-08-28 10:53:49.702871: Current learning rate: 0.00428 
2025-08-28 10:54:05.324717: train_loss -0.3697 
2025-08-28 10:54:05.333112: val_loss -0.3839 
2025-08-28 10:54:05.337287: Pseudo dice [np.float32(0.6518)] 
2025-08-28 10:54:05.346667: Epoch time: 15.64 s 
2025-08-28 10:54:06.000264:  
2025-08-28 10:54:06.008592: Epoch 612 
2025-08-28 10:54:06.014967: Current learning rate: 0.00427 
2025-08-28 10:54:21.532584: train_loss -0.3594 
2025-08-28 10:54:21.541322: val_loss -0.4291 
2025-08-28 10:54:21.549286: Pseudo dice [np.float32(0.6791)] 
2025-08-28 10:54:21.555516: Epoch time: 15.53 s 
2025-08-28 10:54:22.209359:  
2025-08-28 10:54:22.217628: Epoch 613 
2025-08-28 10:54:22.226430: Current learning rate: 0.00426 
2025-08-28 10:54:37.702907: train_loss -0.3652 
2025-08-28 10:54:37.711258: val_loss -0.4658 
2025-08-28 10:54:37.715307: Pseudo dice [np.float32(0.6923)] 
2025-08-28 10:54:37.723523: Epoch time: 15.49 s 
2025-08-28 10:54:38.443251:  
2025-08-28 10:54:38.451559: Epoch 614 
2025-08-28 10:54:38.457738: Current learning rate: 0.00425 
2025-08-28 10:54:54.298634: train_loss -0.3419 
2025-08-28 10:54:54.307022: val_loss -0.3842 
2025-08-28 10:54:54.315325: Pseudo dice [np.float32(0.645)] 
2025-08-28 10:54:54.320769: Epoch time: 15.86 s 
2025-08-28 10:54:54.981481:  
2025-08-28 10:54:54.989867: Epoch 615 
2025-08-28 10:54:54.996185: Current learning rate: 0.00424 
2025-08-28 10:55:11.566003: train_loss -0.3582 
2025-08-28 10:55:11.574582: val_loss -0.3974 
2025-08-28 10:55:11.582579: Pseudo dice [np.float32(0.6537)] 
2025-08-28 10:55:11.589020: Epoch time: 16.59 s 
2025-08-28 10:55:12.312157:  
2025-08-28 10:55:12.321865: Epoch 616 
2025-08-28 10:55:12.328709: Current learning rate: 0.00423 
2025-08-28 10:55:29.069242: train_loss -0.3587 
2025-08-28 10:55:29.075493: val_loss -0.4326 
2025-08-28 10:55:29.083417: Pseudo dice [np.float32(0.7168)] 
2025-08-28 10:55:29.088696: Epoch time: 16.76 s 
2025-08-28 10:55:29.957042:  
2025-08-28 10:55:29.965232: Epoch 617 
2025-08-28 10:55:29.970934: Current learning rate: 0.00422 
2025-08-28 10:55:46.609514: train_loss -0.3863 
2025-08-28 10:55:46.617560: val_loss -0.4056 
2025-08-28 10:55:46.621986: Pseudo dice [np.float32(0.7116)] 
2025-08-28 10:55:46.631113: Epoch time: 16.65 s 
2025-08-28 10:55:46.637723: Yayy! New best EMA pseudo Dice: 0.6751000285148621 
2025-08-28 10:55:47.567360:  
2025-08-28 10:55:47.574731: Epoch 618 
2025-08-28 10:55:47.582218: Current learning rate: 0.00421 
2025-08-28 10:56:04.114199: train_loss -0.371 
2025-08-28 10:56:04.122702: val_loss -0.361 
2025-08-28 10:56:04.130859: Pseudo dice [np.float32(0.6545)] 
2025-08-28 10:56:04.137067: Epoch time: 16.55 s 
2025-08-28 10:56:04.849416:  
2025-08-28 10:56:04.861697: Epoch 619 
2025-08-28 10:56:04.868621: Current learning rate: 0.0042 
2025-08-28 10:56:21.831880: train_loss -0.3354 
2025-08-28 10:56:21.840230: val_loss -0.4024 
2025-08-28 10:56:21.844401: Pseudo dice [np.float32(0.703)] 
2025-08-28 10:56:21.851789: Epoch time: 16.98 s 
2025-08-28 10:56:21.857261: Yayy! New best EMA pseudo Dice: 0.6759999990463257 
2025-08-28 10:56:22.763863:  
2025-08-28 10:56:22.773360: Epoch 620 
2025-08-28 10:56:22.780356: Current learning rate: 0.00419 
2025-08-28 10:56:39.637450: train_loss -0.3463 
2025-08-28 10:56:39.645534: val_loss -0.3814 
2025-08-28 10:56:39.653853: Pseudo dice [np.float32(0.702)] 
2025-08-28 10:56:39.658791: Epoch time: 16.88 s 
2025-08-28 10:56:39.664088: Yayy! New best EMA pseudo Dice: 0.678600013256073 
2025-08-28 10:56:40.570265:  
2025-08-28 10:56:40.582414: Epoch 621 
2025-08-28 10:56:40.593168: Current learning rate: 0.00418 
2025-08-28 10:56:57.696892: train_loss -0.3707 
2025-08-28 10:56:57.705266: val_loss -0.3875 
2025-08-28 10:56:57.709445: Pseudo dice [np.float32(0.6844)] 
2025-08-28 10:56:57.718927: Epoch time: 17.13 s 
2025-08-28 10:56:57.722748: Yayy! New best EMA pseudo Dice: 0.6791999936103821 
2025-08-28 10:56:58.769239:  
2025-08-28 10:56:58.780303: Epoch 622 
2025-08-28 10:56:58.786506: Current learning rate: 0.00417 
2025-08-28 10:57:15.376757: train_loss -0.361 
2025-08-28 10:57:15.385735: val_loss -0.4125 
2025-08-28 10:57:15.393804: Pseudo dice [np.float32(0.6906)] 
2025-08-28 10:57:15.399120: Epoch time: 16.61 s 
2025-08-28 10:57:15.402855: Yayy! New best EMA pseudo Dice: 0.6802999973297119 
2025-08-28 10:57:16.310011:  
2025-08-28 10:57:16.321662: Epoch 623 
2025-08-28 10:57:16.328386: Current learning rate: 0.00416 
2025-08-28 10:57:33.728657: train_loss -0.3572 
2025-08-28 10:57:33.737022: val_loss -0.4138 
2025-08-28 10:57:33.741163: Pseudo dice [np.float32(0.7448)] 
2025-08-28 10:57:33.750406: Epoch time: 17.42 s 
2025-08-28 10:57:33.755331: Yayy! New best EMA pseudo Dice: 0.6868000030517578 
2025-08-28 10:57:34.660891:  
2025-08-28 10:57:34.671664: Epoch 624 
2025-08-28 10:57:34.680614: Current learning rate: 0.00415 
2025-08-28 10:57:50.904359: train_loss -0.3646 
2025-08-28 10:57:50.912589: val_loss -0.3471 
2025-08-28 10:57:50.916698: Pseudo dice [np.float32(0.6171)] 
2025-08-28 10:57:50.925949: Epoch time: 16.25 s 
2025-08-28 10:57:51.652467:  
2025-08-28 10:57:51.659532: Epoch 625 
2025-08-28 10:57:51.666265: Current learning rate: 0.00414 
2025-08-28 10:58:07.950648: train_loss -0.3314 
2025-08-28 10:58:07.962858: val_loss -0.4084 
2025-08-28 10:58:07.967280: Pseudo dice [np.float32(0.7071)] 
2025-08-28 10:58:07.973418: Epoch time: 16.3 s 
2025-08-28 10:58:08.707630:  
2025-08-28 10:58:08.717822: Epoch 626 
2025-08-28 10:58:08.726028: Current learning rate: 0.00413 
2025-08-28 10:58:25.113760: train_loss -0.3277 
2025-08-28 10:58:25.121612: val_loss -0.3598 
2025-08-28 10:58:25.125776: Pseudo dice [np.float32(0.644)] 
2025-08-28 10:58:25.132165: Epoch time: 16.41 s 
2025-08-28 10:58:25.847378:  
2025-08-28 10:58:25.857788: Epoch 627 
2025-08-28 10:58:25.864796: Current learning rate: 0.00412 
2025-08-28 10:58:42.243431: train_loss -0.346 
2025-08-28 10:58:42.251249: val_loss -0.3949 
2025-08-28 10:58:42.255643: Pseudo dice [np.float32(0.6015)] 
2025-08-28 10:58:42.263745: Epoch time: 16.4 s 
2025-08-28 10:58:42.964726:  
2025-08-28 10:58:42.973847: Epoch 628 
2025-08-28 10:58:42.981848: Current learning rate: 0.00411 
2025-08-28 10:58:59.360107: train_loss -0.3479 
2025-08-28 10:58:59.372508: val_loss -0.3892 
2025-08-28 10:58:59.376601: Pseudo dice [np.float32(0.6444)] 
2025-08-28 10:58:59.382959: Epoch time: 16.4 s 
2025-08-28 10:59:00.250414:  
2025-08-28 10:59:00.258188: Epoch 629 
2025-08-28 10:59:00.264948: Current learning rate: 0.0041 
2025-08-28 10:59:15.893649: train_loss -0.3299 
2025-08-28 10:59:15.905699: val_loss -0.3815 
2025-08-28 10:59:15.910059: Pseudo dice [np.float32(0.6897)] 
2025-08-28 10:59:15.918581: Epoch time: 15.65 s 
2025-08-28 10:59:16.636331:  
2025-08-28 10:59:16.645508: Epoch 630 
2025-08-28 10:59:16.652694: Current learning rate: 0.00409 
2025-08-28 10:59:32.322257: train_loss -0.3442 
2025-08-28 10:59:32.330461: val_loss -0.4124 
2025-08-28 10:59:32.340255: Pseudo dice [np.float32(0.6286)] 
2025-08-28 10:59:32.345064: Epoch time: 15.69 s 
2025-08-28 10:59:33.043490:  
2025-08-28 10:59:33.054000: Epoch 631 
2025-08-28 10:59:33.060263: Current learning rate: 0.00408 
2025-08-28 10:59:48.809459: train_loss -0.3327 
2025-08-28 10:59:48.817727: val_loss -0.3756 
2025-08-28 10:59:48.826074: Pseudo dice [np.float32(0.6286)] 
2025-08-28 10:59:48.831114: Epoch time: 15.77 s 
2025-08-28 10:59:49.540288:  
2025-08-28 10:59:49.547496: Epoch 632 
2025-08-28 10:59:49.555907: Current learning rate: 0.00407 
2025-08-28 11:00:05.876706: train_loss -0.3613 
2025-08-28 11:00:05.884977: val_loss -0.4098 
2025-08-28 11:00:05.893769: Pseudo dice [np.float32(0.7009)] 
2025-08-28 11:00:05.898642: Epoch time: 16.34 s 
2025-08-28 11:00:06.607295:  
2025-08-28 11:00:06.614598: Epoch 633 
2025-08-28 11:00:06.621829: Current learning rate: 0.00406 
2025-08-28 11:00:22.192978: train_loss -0.3443 
2025-08-28 11:00:22.201095: val_loss -0.4009 
2025-08-28 11:00:22.209702: Pseudo dice [np.float32(0.6712)] 
2025-08-28 11:00:22.214741: Epoch time: 15.59 s 
2025-08-28 11:00:22.935036:  
2025-08-28 11:00:22.943347: Epoch 634 
2025-08-28 11:00:22.950824: Current learning rate: 0.00405 
2025-08-28 11:00:38.771908: train_loss -0.3425 
2025-08-28 11:00:38.780107: val_loss -0.4031 
2025-08-28 11:00:38.784275: Pseudo dice [np.float32(0.6666)] 
2025-08-28 11:00:38.791809: Epoch time: 15.84 s 
2025-08-28 11:00:39.694634:  
2025-08-28 11:00:39.702875: Epoch 635 
2025-08-28 11:00:39.708052: Current learning rate: 0.00404 
2025-08-28 11:00:55.121384: train_loss -0.3557 
2025-08-28 11:00:55.129837: val_loss -0.376 
2025-08-28 11:00:55.138169: Pseudo dice [np.float32(0.6712)] 
2025-08-28 11:00:55.143581: Epoch time: 15.43 s 
2025-08-28 11:00:55.860756:  
2025-08-28 11:00:55.868438: Epoch 636 
2025-08-28 11:00:55.877389: Current learning rate: 0.00403 
2025-08-28 11:01:11.596416: train_loss -0.3699 
2025-08-28 11:01:11.604540: val_loss -0.4272 
2025-08-28 11:01:11.613505: Pseudo dice [np.float32(0.6322)] 
2025-08-28 11:01:11.619228: Epoch time: 15.74 s 
2025-08-28 11:01:12.364773:  
2025-08-28 11:01:12.371892: Epoch 637 
2025-08-28 11:01:12.380191: Current learning rate: 0.00402 
2025-08-28 11:01:27.946024: train_loss -0.3679 
2025-08-28 11:01:27.954458: val_loss -0.3986 
2025-08-28 11:01:27.962762: Pseudo dice [np.float32(0.6375)] 
2025-08-28 11:01:27.968132: Epoch time: 15.58 s 
2025-08-28 11:01:28.756108:  
2025-08-28 11:01:28.764177: Epoch 638 
2025-08-28 11:01:28.775799: Current learning rate: 0.00401 
2025-08-28 11:01:44.320557: train_loss -0.3227 
2025-08-28 11:01:44.328880: val_loss -0.3874 
2025-08-28 11:01:44.333031: Pseudo dice [np.float32(0.6559)] 
2025-08-28 11:01:44.341382: Epoch time: 15.57 s 
2025-08-28 11:01:45.058648:  
2025-08-28 11:01:45.068776: Epoch 639 
2025-08-28 11:01:45.075929: Current learning rate: 0.004 
2025-08-28 11:02:00.862350: train_loss -0.3317 
2025-08-28 11:02:00.870778: val_loss -0.3446 
2025-08-28 11:02:00.874493: Pseudo dice [np.float32(0.4769)] 
2025-08-28 11:02:00.882986: Epoch time: 15.8 s 
2025-08-28 11:02:01.595581:  
2025-08-28 11:02:01.603525: Epoch 640 
2025-08-28 11:02:01.609558: Current learning rate: 0.00399 
2025-08-28 11:02:17.420519: train_loss -0.349 
2025-08-28 11:02:17.428628: val_loss -0.395 
2025-08-28 11:02:17.436967: Pseudo dice [np.float32(0.7096)] 
2025-08-28 11:02:17.443379: Epoch time: 15.83 s 
2025-08-28 11:02:18.290012:  
2025-08-28 11:02:18.300360: Epoch 641 
2025-08-28 11:02:18.306913: Current learning rate: 0.00398 
2025-08-28 11:02:33.949517: train_loss -0.3506 
2025-08-28 11:02:33.957537: val_loss -0.356 
2025-08-28 11:02:33.961947: Pseudo dice [np.float32(0.642)] 
2025-08-28 11:02:33.968014: Epoch time: 15.66 s 
2025-08-28 11:02:34.679882:  
2025-08-28 11:02:34.689888: Epoch 642 
2025-08-28 11:02:34.696012: Current learning rate: 0.00397 
2025-08-28 11:02:50.232202: train_loss -0.3552 
2025-08-28 11:02:50.240551: val_loss -0.3185 
2025-08-28 11:02:50.249192: Pseudo dice [np.float32(0.5622)] 
2025-08-28 11:02:50.255138: Epoch time: 15.55 s 
2025-08-28 11:02:50.972016:  
2025-08-28 11:02:50.978595: Epoch 643 
2025-08-28 11:02:50.983979: Current learning rate: 0.00396 
2025-08-28 11:03:06.507064: train_loss -0.3859 
2025-08-28 11:03:06.515136: val_loss -0.3464 
2025-08-28 11:03:06.519179: Pseudo dice [np.float32(0.6375)] 
2025-08-28 11:03:06.526894: Epoch time: 15.54 s 
2025-08-28 11:03:07.249003:  
2025-08-28 11:03:07.257357: Epoch 644 
2025-08-28 11:03:07.263821: Current learning rate: 0.00395 
2025-08-28 11:03:22.819534: train_loss -0.3279 
2025-08-28 11:03:22.827247: val_loss -0.3833 
2025-08-28 11:03:22.835913: Pseudo dice [np.float32(0.6422)] 
2025-08-28 11:03:22.841058: Epoch time: 15.57 s 
2025-08-28 11:03:23.613544:  
2025-08-28 11:03:23.621764: Epoch 645 
2025-08-28 11:03:23.628357: Current learning rate: 0.00394 
2025-08-28 11:03:39.147738: train_loss -0.3499 
2025-08-28 11:03:39.155987: val_loss -0.3847 
2025-08-28 11:03:39.164437: Pseudo dice [np.float32(0.7118)] 
2025-08-28 11:03:39.169997: Epoch time: 15.54 s 
2025-08-28 11:03:39.875459:  
2025-08-28 11:03:39.884160: Epoch 646 
2025-08-28 11:03:39.890093: Current learning rate: 0.00393 
2025-08-28 11:03:55.409765: train_loss -0.3325 
2025-08-28 11:03:55.418103: val_loss -0.3951 
2025-08-28 11:03:55.426440: Pseudo dice [np.float32(0.6978)] 
2025-08-28 11:03:55.432901: Epoch time: 15.54 s 
2025-08-28 11:03:56.134411:  
2025-08-28 11:03:56.143659: Epoch 647 
2025-08-28 11:03:56.152100: Current learning rate: 0.00392 
2025-08-28 11:04:11.889040: train_loss -0.3577 
2025-08-28 11:04:11.901242: val_loss -0.3863 
2025-08-28 11:04:11.905384: Pseudo dice [np.float32(0.6152)] 
2025-08-28 11:04:11.912801: Epoch time: 15.76 s 
2025-08-28 11:04:12.765607:  
2025-08-28 11:04:12.777122: Epoch 648 
2025-08-28 11:04:12.785983: Current learning rate: 0.00391 
2025-08-28 11:04:28.346725: train_loss -0.3809 
2025-08-28 11:04:28.355201: val_loss -0.3965 
2025-08-28 11:04:28.359352: Pseudo dice [np.float32(0.6538)] 
2025-08-28 11:04:28.365566: Epoch time: 15.58 s 
2025-08-28 11:04:29.077538:  
2025-08-28 11:04:29.085514: Epoch 649 
2025-08-28 11:04:29.095482: Current learning rate: 0.0039 
2025-08-28 11:04:44.796788: train_loss -0.3406 
2025-08-28 11:04:44.804892: val_loss -0.3989 
2025-08-28 11:04:44.809086: Pseudo dice [np.float32(0.6007)] 
2025-08-28 11:04:44.817563: Epoch time: 15.72 s 
2025-08-28 11:04:45.731924:  
2025-08-28 11:04:45.739040: Epoch 650 
2025-08-28 11:04:45.743603: Current learning rate: 0.00389 
2025-08-28 11:05:02.449908: train_loss -0.3774 
2025-08-28 11:05:02.464217: val_loss -0.4016 
2025-08-28 11:05:02.472551: Pseudo dice [np.float32(0.6709)] 
2025-08-28 11:05:02.478847: Epoch time: 16.72 s 
2025-08-28 11:05:03.202309:  
2025-08-28 11:05:03.211543: Epoch 651 
2025-08-28 11:05:03.221938: Current learning rate: 0.00388 
2025-08-28 11:05:20.073415: train_loss -0.3757 
2025-08-28 11:05:20.081836: val_loss -0.4352 
2025-08-28 11:05:20.090168: Pseudo dice [np.float32(0.7109)] 
2025-08-28 11:05:20.095659: Epoch time: 16.87 s 
2025-08-28 11:05:20.794923:  
2025-08-28 11:05:20.803211: Epoch 652 
2025-08-28 11:05:20.811597: Current learning rate: 0.00387 
2025-08-28 11:05:37.353246: train_loss -0.35 
2025-08-28 11:05:37.361586: val_loss -0.3702 
2025-08-28 11:05:37.365745: Pseudo dice [np.float32(0.6687)] 
2025-08-28 11:05:37.375020: Epoch time: 16.56 s 
2025-08-28 11:05:38.083627:  
2025-08-28 11:05:38.091432: Epoch 653 
2025-08-28 11:05:38.098867: Current learning rate: 0.00386 
2025-08-28 11:05:55.066745: train_loss -0.3431 
2025-08-28 11:05:55.075111: val_loss -0.4142 
2025-08-28 11:05:55.079239: Pseudo dice [np.float32(0.6219)] 
2025-08-28 11:05:55.087428: Epoch time: 16.98 s 
2025-08-28 11:05:55.969075:  
2025-08-28 11:05:55.979934: Epoch 654 
2025-08-28 11:05:55.984614: Current learning rate: 0.00385 
2025-08-28 11:06:12.905392: train_loss -0.3386 
2025-08-28 11:06:12.913755: val_loss -0.4087 
2025-08-28 11:06:12.922016: Pseudo dice [np.float32(0.6002)] 
2025-08-28 11:06:12.927478: Epoch time: 16.94 s 
2025-08-28 11:06:13.635204:  
2025-08-28 11:06:13.645629: Epoch 655 
2025-08-28 11:06:13.653124: Current learning rate: 0.00384 
2025-08-28 11:06:30.710998: train_loss -0.3684 
2025-08-28 11:06:30.718974: val_loss -0.4146 
2025-08-28 11:06:30.727371: Pseudo dice [np.float32(0.6879)] 
2025-08-28 11:06:30.733645: Epoch time: 17.08 s 
2025-08-28 11:06:31.437910:  
2025-08-28 11:06:31.446097: Epoch 656 
2025-08-28 11:06:31.451012: Current learning rate: 0.00383 
2025-08-28 11:06:48.482539: train_loss -0.3546 
2025-08-28 11:06:48.490900: val_loss -0.3876 
2025-08-28 11:06:48.497136: Pseudo dice [np.float32(0.6411)] 
2025-08-28 11:06:48.504871: Epoch time: 17.05 s 
2025-08-28 11:06:49.196827:  
2025-08-28 11:06:49.205108: Epoch 657 
2025-08-28 11:06:49.210270: Current learning rate: 0.00382 
2025-08-28 11:07:06.396665: train_loss -0.3836 
2025-08-28 11:07:06.404654: val_loss -0.3856 
2025-08-28 11:07:06.408808: Pseudo dice [np.float32(0.7045)] 
2025-08-28 11:07:06.416066: Epoch time: 17.2 s 
2025-08-28 11:07:07.130212:  
2025-08-28 11:07:07.140813: Epoch 658 
2025-08-28 11:07:07.150267: Current learning rate: 0.00381 
2025-08-28 11:07:24.126585: train_loss -0.351 
2025-08-28 11:07:24.134815: val_loss -0.4164 
2025-08-28 11:07:24.143196: Pseudo dice [np.float32(0.7037)] 
2025-08-28 11:07:24.149410: Epoch time: 17.0 s 
2025-08-28 11:07:24.881225:  
2025-08-28 11:07:24.890814: Epoch 659 
2025-08-28 11:07:24.896920: Current learning rate: 0.0038 
2025-08-28 11:07:41.944231: train_loss -0.341 
2025-08-28 11:07:41.952638: val_loss -0.3394 
2025-08-28 11:07:41.956838: Pseudo dice [np.float32(0.4892)] 
2025-08-28 11:07:41.965368: Epoch time: 17.06 s 
2025-08-28 11:07:42.672087:  
2025-08-28 11:07:42.683031: Epoch 660 
2025-08-28 11:07:42.692318: Current learning rate: 0.00379 
2025-08-28 11:07:59.353221: train_loss -0.3572 
2025-08-28 11:07:59.361663: val_loss -0.3903 
2025-08-28 11:07:59.365804: Pseudo dice [np.float32(0.6771)] 
2025-08-28 11:07:59.374898: Epoch time: 16.68 s 
2025-08-28 11:08:00.236419:  
2025-08-28 11:08:00.245973: Epoch 661 
2025-08-28 11:08:00.253021: Current learning rate: 0.00378 
2025-08-28 11:08:17.091869: train_loss -0.3804 
2025-08-28 11:08:17.100064: val_loss -0.4153 
2025-08-28 11:08:17.108519: Pseudo dice [np.float32(0.7056)] 
2025-08-28 11:08:17.114821: Epoch time: 16.86 s 
2025-08-28 11:08:17.855010:  
2025-08-28 11:08:17.863372: Epoch 662 
2025-08-28 11:08:17.871770: Current learning rate: 0.00377 
2025-08-28 11:08:34.459202: train_loss -0.3808 
2025-08-28 11:08:34.467558: val_loss -0.4171 
2025-08-28 11:08:34.471736: Pseudo dice [np.float32(0.7066)] 
2025-08-28 11:08:34.479018: Epoch time: 16.61 s 
2025-08-28 11:08:35.170576:  
2025-08-28 11:08:35.179585: Epoch 663 
2025-08-28 11:08:35.185976: Current learning rate: 0.00376 
2025-08-28 11:08:51.730930: train_loss -0.3545 
2025-08-28 11:08:51.739292: val_loss -0.3854 
2025-08-28 11:08:51.743121: Pseudo dice [np.float32(0.6666)] 
2025-08-28 11:08:51.751498: Epoch time: 16.56 s 
2025-08-28 11:08:52.471814:  
2025-08-28 11:08:52.479321: Epoch 664 
2025-08-28 11:08:52.486072: Current learning rate: 0.00375 
2025-08-28 11:09:09.536461: train_loss -0.3549 
2025-08-28 11:09:09.548441: val_loss -0.4109 
2025-08-28 11:09:09.552572: Pseudo dice [np.float32(0.723)] 
2025-08-28 11:09:09.560788: Epoch time: 17.07 s 
2025-08-28 11:09:10.261450:  
2025-08-28 11:09:10.271012: Epoch 665 
2025-08-28 11:09:10.278775: Current learning rate: 0.00374 
2025-08-28 11:09:26.819777: train_loss -0.3825 
2025-08-28 11:09:26.828147: val_loss -0.3804 
2025-08-28 11:09:26.832278: Pseudo dice [np.float32(0.6392)] 
2025-08-28 11:09:26.840500: Epoch time: 16.56 s 
2025-08-28 11:09:27.569510:  
2025-08-28 11:09:27.578512: Epoch 666 
2025-08-28 11:09:27.585456: Current learning rate: 0.00373 
2025-08-28 11:09:44.581676: train_loss -0.3839 
2025-08-28 11:09:44.587528: val_loss -0.4707 
2025-08-28 11:09:44.595927: Pseudo dice [np.float32(0.7361)] 
2025-08-28 11:09:44.602137: Epoch time: 17.01 s 
2025-08-28 11:09:45.443635:  
2025-08-28 11:09:45.452577: Epoch 667 
2025-08-28 11:09:45.459306: Current learning rate: 0.00372 
2025-08-28 11:10:02.038326: train_loss -0.3657 
2025-08-28 11:10:02.046641: val_loss -0.4299 
2025-08-28 11:10:02.055027: Pseudo dice [np.float32(0.7141)] 
2025-08-28 11:10:02.061251: Epoch time: 16.6 s 
2025-08-28 11:10:02.768173:  
2025-08-28 11:10:02.776544: Epoch 668 
2025-08-28 11:10:02.784861: Current learning rate: 0.00371 
2025-08-28 11:10:19.655892: train_loss -0.3484 
2025-08-28 11:10:19.668599: val_loss -0.3826 
2025-08-28 11:10:19.672321: Pseudo dice [np.float32(0.5768)] 
2025-08-28 11:10:19.681084: Epoch time: 16.89 s 
2025-08-28 11:10:20.405109:  
2025-08-28 11:10:20.411892: Epoch 669 
2025-08-28 11:10:20.419186: Current learning rate: 0.0037 
2025-08-28 11:10:37.048242: train_loss -0.364 
2025-08-28 11:10:37.056634: val_loss -0.3457 
2025-08-28 11:10:37.061095: Pseudo dice [np.float32(0.6941)] 
2025-08-28 11:10:37.067318: Epoch time: 16.64 s 
2025-08-28 11:10:37.770394:  
2025-08-28 11:10:37.780549: Epoch 670 
2025-08-28 11:10:37.786347: Current learning rate: 0.00369 
2025-08-28 11:10:54.861930: train_loss -0.3354 
2025-08-28 11:10:54.870502: val_loss -0.4293 
2025-08-28 11:10:54.874416: Pseudo dice [np.float32(0.6688)] 
2025-08-28 11:10:54.883319: Epoch time: 17.09 s 
2025-08-28 11:10:55.608851:  
2025-08-28 11:10:55.612874: Epoch 671 
2025-08-28 11:10:55.621190: Current learning rate: 0.00368 
2025-08-28 11:11:12.580054: train_loss -0.3337 
2025-08-28 11:11:12.588210: val_loss -0.4513 
2025-08-28 11:11:12.596982: Pseudo dice [np.float32(0.7441)] 
2025-08-28 11:11:12.602089: Epoch time: 16.97 s 
2025-08-28 11:11:13.337507:  
2025-08-28 11:11:13.347682: Epoch 672 
2025-08-28 11:11:13.355717: Current learning rate: 0.00367 
2025-08-28 11:11:30.347369: train_loss -0.296 
2025-08-28 11:11:30.355644: val_loss -0.442 
2025-08-28 11:11:30.364631: Pseudo dice [np.float32(0.6517)] 
2025-08-28 11:11:30.369735: Epoch time: 17.01 s 
2025-08-28 11:11:31.087637:  
2025-08-28 11:11:31.097142: Epoch 673 
2025-08-28 11:11:31.103942: Current learning rate: 0.00366 
2025-08-28 11:11:48.056892: train_loss -0.3663 
2025-08-28 11:11:48.065325: val_loss -0.4606 
2025-08-28 11:11:48.073345: Pseudo dice [np.float32(0.7717)] 
2025-08-28 11:11:48.079893: Epoch time: 16.97 s 
2025-08-28 11:11:48.950278:  
2025-08-28 11:11:48.959604: Epoch 674 
2025-08-28 11:11:48.964798: Current learning rate: 0.00365 
2025-08-28 11:12:05.911960: train_loss -0.3428 
2025-08-28 11:12:05.920321: val_loss -0.3999 
2025-08-28 11:12:05.928653: Pseudo dice [np.float32(0.6242)] 
2025-08-28 11:12:05.934140: Epoch time: 16.96 s 
2025-08-28 11:12:06.656051:  
2025-08-28 11:12:06.666930: Epoch 675 
2025-08-28 11:12:06.671716: Current learning rate: 0.00364 
2025-08-28 11:12:23.187910: train_loss -0.3487 
2025-08-28 11:12:23.200077: val_loss -0.442 
2025-08-28 11:12:23.204474: Pseudo dice [np.float32(0.6759)] 
2025-08-28 11:12:23.212658: Epoch time: 16.53 s 
2025-08-28 11:12:23.956692:  
2025-08-28 11:12:23.962491: Epoch 676 
2025-08-28 11:12:23.968999: Current learning rate: 0.00363 
2025-08-28 11:12:40.767766: train_loss -0.371 
2025-08-28 11:12:40.776295: val_loss -0.4008 
2025-08-28 11:12:40.784622: Pseudo dice [np.float32(0.6722)] 
2025-08-28 11:12:40.790496: Epoch time: 16.82 s 
2025-08-28 11:12:41.522472:  
2025-08-28 11:12:41.529817: Epoch 677 
2025-08-28 11:12:41.535177: Current learning rate: 0.00362 
2025-08-28 11:12:58.097399: train_loss -0.35 
2025-08-28 11:12:58.109939: val_loss -0.4206 
2025-08-28 11:12:58.114105: Pseudo dice [np.float32(0.6598)] 
2025-08-28 11:12:58.120513: Epoch time: 16.58 s 
2025-08-28 11:12:58.862783:  
2025-08-28 11:12:58.872140: Epoch 678 
2025-08-28 11:12:58.877223: Current learning rate: 0.00361 
2025-08-28 11:13:15.435931: train_loss -0.3428 
2025-08-28 11:13:15.448149: val_loss -0.4181 
2025-08-28 11:13:15.452507: Pseudo dice [np.float32(0.6881)] 
2025-08-28 11:13:15.459636: Epoch time: 16.58 s 
2025-08-28 11:13:16.194522:  
2025-08-28 11:13:16.204059: Epoch 679 
2025-08-28 11:13:16.212062: Current learning rate: 0.0036 
2025-08-28 11:13:33.011336: train_loss -0.3755 
2025-08-28 11:13:33.015613: val_loss -0.3627 
2025-08-28 11:13:33.024383: Pseudo dice [np.float32(0.6568)] 
2025-08-28 11:13:33.029488: Epoch time: 16.82 s 
2025-08-28 11:13:33.905725:  
2025-08-28 11:13:33.913434: Epoch 680 
2025-08-28 11:13:33.920681: Current learning rate: 0.00359 
2025-08-28 11:13:50.516448: train_loss -0.3455 
2025-08-28 11:13:50.524764: val_loss -0.3962 
2025-08-28 11:13:50.533105: Pseudo dice [np.float32(0.6646)] 
2025-08-28 11:13:50.539535: Epoch time: 16.61 s 
2025-08-28 11:13:51.280025:  
2025-08-28 11:13:51.286896: Epoch 681 
2025-08-28 11:13:51.292525: Current learning rate: 0.00358 
2025-08-28 11:14:08.229953: train_loss -0.3494 
2025-08-28 11:14:08.242500: val_loss -0.4448 
2025-08-28 11:14:08.246906: Pseudo dice [np.float32(0.6758)] 
2025-08-28 11:14:08.254136: Epoch time: 16.95 s 
2025-08-28 11:14:08.974602:  
2025-08-28 11:14:08.985004: Epoch 682 
2025-08-28 11:14:08.992321: Current learning rate: 0.00357 
2025-08-28 11:14:25.568113: train_loss -0.3726 
2025-08-28 11:14:25.576440: val_loss -0.3683 
2025-08-28 11:14:25.585373: Pseudo dice [np.float32(0.6581)] 
2025-08-28 11:14:25.590495: Epoch time: 16.59 s 
2025-08-28 11:14:26.311108:  
2025-08-28 11:14:26.319590: Epoch 683 
2025-08-28 11:14:26.324460: Current learning rate: 0.00356 
2025-08-28 11:14:43.156792: train_loss -0.3748 
2025-08-28 11:14:43.164829: val_loss -0.4254 
2025-08-28 11:14:43.169031: Pseudo dice [np.float32(0.7335)] 
2025-08-28 11:14:43.178108: Epoch time: 16.85 s 
2025-08-28 11:14:43.897318:  
2025-08-28 11:14:43.905114: Epoch 684 
2025-08-28 11:14:43.911226: Current learning rate: 0.00355 
2025-08-28 11:15:00.757430: train_loss -0.3738 
2025-08-28 11:15:00.766046: val_loss -0.4356 
2025-08-28 11:15:00.774085: Pseudo dice [np.float32(0.7359)] 
2025-08-28 11:15:00.781621: Epoch time: 16.86 s 
2025-08-28 11:15:01.516476:  
2025-08-28 11:15:01.525138: Epoch 685 
2025-08-28 11:15:01.531070: Current learning rate: 0.00354 
2025-08-28 11:15:18.404221: train_loss -0.373 
2025-08-28 11:15:18.416705: val_loss -0.4332 
2025-08-28 11:15:18.420868: Pseudo dice [np.float32(0.7065)] 
2025-08-28 11:15:18.428686: Epoch time: 16.89 s 
2025-08-28 11:15:19.308537:  
2025-08-28 11:15:19.319564: Epoch 686 
2025-08-28 11:15:19.327518: Current learning rate: 0.00353 
2025-08-28 11:15:35.955075: train_loss -0.3451 
2025-08-28 11:15:35.963415: val_loss -0.4111 
2025-08-28 11:15:35.967887: Pseudo dice [np.float32(0.6678)] 
2025-08-28 11:15:35.975495: Epoch time: 16.65 s 
2025-08-28 11:15:36.707959:  
2025-08-28 11:15:36.716503: Epoch 687 
2025-08-28 11:15:36.722312: Current learning rate: 0.00352 
2025-08-28 11:15:53.668557: train_loss -0.3559 
2025-08-28 11:15:53.681082: val_loss -0.3903 
2025-08-28 11:15:53.685238: Pseudo dice [np.float32(0.6544)] 
2025-08-28 11:15:53.692775: Epoch time: 16.96 s 
2025-08-28 11:15:54.399435:  
2025-08-28 11:15:54.409905: Epoch 688 
2025-08-28 11:15:54.417238: Current learning rate: 0.00351 
2025-08-28 11:16:10.985840: train_loss -0.3696 
2025-08-28 11:16:10.998552: val_loss -0.3699 
2025-08-28 11:16:11.002531: Pseudo dice [np.float32(0.5606)] 
2025-08-28 11:16:11.009855: Epoch time: 16.59 s 
2025-08-28 11:16:11.740618:  
2025-08-28 11:16:11.748984: Epoch 689 
2025-08-28 11:16:11.754307: Current learning rate: 0.0035 
2025-08-28 11:16:28.712214: train_loss -0.3649 
2025-08-28 11:16:28.720571: val_loss -0.344 
2025-08-28 11:16:28.724780: Pseudo dice [np.float32(0.5845)] 
2025-08-28 11:16:28.733582: Epoch time: 16.97 s 
2025-08-28 11:16:29.454651:  
2025-08-28 11:16:29.464195: Epoch 690 
2025-08-28 11:16:29.469519: Current learning rate: 0.00349 
2025-08-28 11:16:46.492113: train_loss -0.3754 
2025-08-28 11:16:46.500490: val_loss -0.3833 
2025-08-28 11:16:46.508848: Pseudo dice [np.float32(0.6385)] 
2025-08-28 11:16:46.515033: Epoch time: 17.04 s 
2025-08-28 11:16:47.227126:  
2025-08-28 11:16:47.235833: Epoch 691 
2025-08-28 11:16:47.239410: Current learning rate: 0.00348 
2025-08-28 11:17:03.985020: train_loss -0.3473 
2025-08-28 11:17:03.992934: val_loss -0.4171 
2025-08-28 11:17:03.997137: Pseudo dice [np.float32(0.6974)] 
2025-08-28 11:17:04.005229: Epoch time: 16.76 s 
2025-08-28 11:17:04.882120:  
2025-08-28 11:17:04.890640: Epoch 692 
2025-08-28 11:17:04.896898: Current learning rate: 0.00346 
2025-08-28 11:17:21.460379: train_loss -0.3591 
2025-08-28 11:17:21.469022: val_loss -0.3273 
2025-08-28 11:17:21.477046: Pseudo dice [np.float32(0.5462)] 
2025-08-28 11:17:21.483504: Epoch time: 16.58 s 
2025-08-28 11:17:22.205781:  
2025-08-28 11:17:22.216191: Epoch 693 
2025-08-28 11:17:22.223480: Current learning rate: 0.00345 
2025-08-28 11:17:38.760962: train_loss -0.3769 
2025-08-28 11:17:38.769339: val_loss -0.4259 
2025-08-28 11:17:38.773524: Pseudo dice [np.float32(0.7016)] 
2025-08-28 11:17:38.781811: Epoch time: 16.56 s 
2025-08-28 11:17:39.521080:  
2025-08-28 11:17:39.529964: Epoch 694 
2025-08-28 11:17:39.537533: Current learning rate: 0.00344 
2025-08-28 11:17:56.566518: train_loss -0.3828 
2025-08-28 11:17:56.574627: val_loss -0.3902 
2025-08-28 11:17:56.578756: Pseudo dice [np.float32(0.6742)] 
2025-08-28 11:17:56.587838: Epoch time: 17.05 s 
2025-08-28 11:17:57.300623:  
2025-08-28 11:17:57.309658: Epoch 695 
2025-08-28 11:17:57.316659: Current learning rate: 0.00343 
2025-08-28 11:18:13.954469: train_loss -0.3406 
2025-08-28 11:18:13.966994: val_loss -0.3863 
2025-08-28 11:18:13.971484: Pseudo dice [np.float32(0.683)] 
2025-08-28 11:18:13.980356: Epoch time: 16.65 s 
2025-08-28 11:18:14.730021:  
2025-08-28 11:18:14.738432: Epoch 696 
2025-08-28 11:18:14.744840: Current learning rate: 0.00342 
2025-08-28 11:18:31.751412: train_loss -0.3751 
2025-08-28 11:18:31.759742: val_loss -0.4462 
2025-08-28 11:18:31.763896: Pseudo dice [np.float32(0.7314)] 
2025-08-28 11:18:31.773656: Epoch time: 17.02 s 
2025-08-28 11:18:32.495872:  
2025-08-28 11:18:32.506250: Epoch 697 
2025-08-28 11:18:32.510905: Current learning rate: 0.00341 
2025-08-28 11:18:49.060329: train_loss -0.3645 
2025-08-28 11:18:49.068759: val_loss -0.3466 
2025-08-28 11:18:49.073140: Pseudo dice [np.float32(0.6136)] 
2025-08-28 11:18:49.080337: Epoch time: 16.57 s 
2025-08-28 11:18:49.952831:  
2025-08-28 11:18:49.961450: Epoch 698 
2025-08-28 11:18:49.967767: Current learning rate: 0.0034 
2025-08-28 11:19:06.649177: train_loss -0.3527 
2025-08-28 11:19:06.657065: val_loss -0.465 
2025-08-28 11:19:06.661283: Pseudo dice [np.float32(0.7637)] 
2025-08-28 11:19:06.670388: Epoch time: 16.7 s 
2025-08-28 11:19:07.403583:  
2025-08-28 11:19:07.414335: Epoch 699 
2025-08-28 11:19:07.421518: Current learning rate: 0.00339 
2025-08-28 11:19:23.845115: train_loss -0.3645 
2025-08-28 11:19:23.857651: val_loss -0.3866 
2025-08-28 11:19:23.862175: Pseudo dice [np.float32(0.6737)] 
2025-08-28 11:19:23.869026: Epoch time: 16.44 s 
2025-08-28 11:19:24.760572:  
2025-08-28 11:19:24.770993: Epoch 700 
2025-08-28 11:19:24.777779: Current learning rate: 0.00338 
2025-08-28 11:19:41.587907: train_loss -0.3446 
2025-08-28 11:19:41.596490: val_loss -0.4614 
2025-08-28 11:19:41.600541: Pseudo dice [np.float32(0.7233)] 
2025-08-28 11:19:41.609633: Epoch time: 16.83 s 
2025-08-28 11:19:42.336977:  
2025-08-28 11:19:42.343373: Epoch 701 
2025-08-28 11:19:42.351039: Current learning rate: 0.00337 
2025-08-28 11:19:59.096926: train_loss -0.3555 
2025-08-28 11:19:59.105284: val_loss -0.4047 
2025-08-28 11:19:59.109372: Pseudo dice [np.float32(0.6967)] 
2025-08-28 11:19:59.117763: Epoch time: 16.76 s 
2025-08-28 11:19:59.831446:  
2025-08-28 11:19:59.840034: Epoch 702 
2025-08-28 11:19:59.847710: Current learning rate: 0.00336 
2025-08-28 11:20:16.948093: train_loss -0.3891 
2025-08-28 11:20:16.956478: val_loss -0.4034 
2025-08-28 11:20:16.965485: Pseudo dice [np.float32(0.6964)] 
2025-08-28 11:20:16.971236: Epoch time: 17.12 s 
2025-08-28 11:20:17.682188:  
2025-08-28 11:20:17.693949: Epoch 703 
2025-08-28 11:20:17.699207: Current learning rate: 0.00335 
2025-08-28 11:20:34.620240: train_loss -0.3674 
2025-08-28 11:20:34.632417: val_loss -0.4529 
2025-08-28 11:20:34.636822: Pseudo dice [np.float32(0.7857)] 
2025-08-28 11:20:34.643905: Epoch time: 16.94 s 
2025-08-28 11:20:34.649610: Yayy! New best EMA pseudo Dice: 0.6915000081062317 
2025-08-28 11:20:35.689053:  
2025-08-28 11:20:35.696332: Epoch 704 
2025-08-28 11:20:35.702847: Current learning rate: 0.00334 
2025-08-28 11:20:52.688229: train_loss -0.3675 
2025-08-28 11:20:52.696322: val_loss -0.406 
2025-08-28 11:20:52.704972: Pseudo dice [np.float32(0.6887)] 
2025-08-28 11:20:52.710792: Epoch time: 17.0 s 
2025-08-28 11:20:53.406431:  
2025-08-28 11:20:53.416724: Epoch 705 
2025-08-28 11:20:53.423020: Current learning rate: 0.00333 
2025-08-28 11:21:10.422528: train_loss -0.3803 
2025-08-28 11:21:10.430662: val_loss -0.3418 
2025-08-28 11:21:10.439069: Pseudo dice [np.float32(0.6199)] 
2025-08-28 11:21:10.444440: Epoch time: 17.02 s 
2025-08-28 11:21:11.166514:  
2025-08-28 11:21:11.175373: Epoch 706 
2025-08-28 11:21:11.181413: Current learning rate: 0.00332 
2025-08-28 11:21:28.144377: train_loss -0.3661 
2025-08-28 11:21:28.152516: val_loss -0.2944 
2025-08-28 11:21:28.156642: Pseudo dice [np.float32(0.649)] 
2025-08-28 11:21:28.164259: Epoch time: 16.98 s 
2025-08-28 11:21:28.867770:  
2025-08-28 11:21:28.877148: Epoch 707 
2025-08-28 11:21:28.884186: Current learning rate: 0.00331 
2025-08-28 11:21:45.882723: train_loss -0.3675 
2025-08-28 11:21:45.891067: val_loss -0.3519 
2025-08-28 11:21:45.895444: Pseudo dice [np.float32(0.6386)] 
2025-08-28 11:21:45.904691: Epoch time: 17.02 s 
2025-08-28 11:21:46.616517:  
2025-08-28 11:21:46.626697: Epoch 708 
2025-08-28 11:21:46.633427: Current learning rate: 0.0033 
2025-08-28 11:22:03.542031: train_loss -0.3704 
2025-08-28 11:22:03.550689: val_loss -0.377 
2025-08-28 11:22:03.554572: Pseudo dice [np.float32(0.6763)] 
2025-08-28 11:22:03.562809: Epoch time: 16.93 s 
2025-08-28 11:22:04.298152:  
2025-08-28 11:22:04.308269: Epoch 709 
2025-08-28 11:22:04.313258: Current learning rate: 0.00329 
2025-08-28 11:22:21.101220: train_loss -0.3944 
2025-08-28 11:22:21.109859: val_loss -0.4103 
2025-08-28 11:22:21.117904: Pseudo dice [np.float32(0.7074)] 
2025-08-28 11:22:21.123448: Epoch time: 16.81 s 
2025-08-28 11:22:21.994800:  
2025-08-28 11:22:22.002440: Epoch 710 
2025-08-28 11:22:22.008944: Current learning rate: 0.00328 
2025-08-28 11:22:38.602106: train_loss -0.3557 
2025-08-28 11:22:38.610364: val_loss -0.4498 
2025-08-28 11:22:38.619378: Pseudo dice [np.float32(0.6804)] 
2025-08-28 11:22:38.624149: Epoch time: 16.61 s 
2025-08-28 11:22:39.325581:  
2025-08-28 11:22:39.334954: Epoch 711 
2025-08-28 11:22:39.341272: Current learning rate: 0.00327 
2025-08-28 11:22:56.044684: train_loss -0.379 
2025-08-28 11:22:56.052782: val_loss -0.3848 
2025-08-28 11:22:56.061131: Pseudo dice [np.float32(0.6985)] 
2025-08-28 11:22:56.066534: Epoch time: 16.72 s 
2025-08-28 11:22:56.804888:  
2025-08-28 11:22:56.811779: Epoch 712 
2025-08-28 11:22:56.819078: Current learning rate: 0.00326 
2025-08-28 11:23:13.274157: train_loss -0.3556 
2025-08-28 11:23:13.286941: val_loss -0.4255 
2025-08-28 11:23:13.295383: Pseudo dice [np.float32(0.613)] 
2025-08-28 11:23:13.305713: Epoch time: 16.47 s 
2025-08-28 11:23:14.075849:  
2025-08-28 11:23:14.087378: Epoch 713 
2025-08-28 11:23:14.094673: Current learning rate: 0.00325 
2025-08-28 11:23:30.927149: train_loss -0.3305 
2025-08-28 11:23:30.933447: val_loss -0.3872 
2025-08-28 11:23:30.942125: Pseudo dice [np.float32(0.6993)] 
2025-08-28 11:23:30.948091: Epoch time: 16.85 s 
2025-08-28 11:23:31.676922:  
2025-08-28 11:23:31.686004: Epoch 714 
2025-08-28 11:23:31.694999: Current learning rate: 0.00324 
2025-08-28 11:23:48.400894: train_loss -0.3617 
2025-08-28 11:23:48.409211: val_loss -0.455 
2025-08-28 11:23:48.417617: Pseudo dice [np.float32(0.676)] 
2025-08-28 11:23:48.423739: Epoch time: 16.73 s 
2025-08-28 11:23:49.154551:  
2025-08-28 11:23:49.164093: Epoch 715 
2025-08-28 11:23:49.168692: Current learning rate: 0.00323 
2025-08-28 11:24:06.214490: train_loss -0.3726 
2025-08-28 11:24:06.218715: val_loss -0.383 
2025-08-28 11:24:06.227014: Pseudo dice [np.float32(0.6641)] 
2025-08-28 11:24:06.232431: Epoch time: 17.06 s 
2025-08-28 11:24:06.940173:  
2025-08-28 11:24:06.948446: Epoch 716 
2025-08-28 11:24:06.953375: Current learning rate: 0.00322 
2025-08-28 11:24:24.024090: train_loss -0.3669 
2025-08-28 11:24:24.032789: val_loss -0.4046 
2025-08-28 11:24:24.041236: Pseudo dice [np.float32(0.6387)] 
2025-08-28 11:24:24.050035: Epoch time: 17.09 s 
2025-08-28 11:24:24.921965:  
2025-08-28 11:24:24.931478: Epoch 717 
2025-08-28 11:24:24.938348: Current learning rate: 0.00321 
2025-08-28 11:24:41.689672: train_loss -0.3797 
2025-08-28 11:24:41.695765: val_loss -0.3912 
2025-08-28 11:24:41.704137: Pseudo dice [np.float32(0.7073)] 
2025-08-28 11:24:41.710454: Epoch time: 16.77 s 
2025-08-28 11:24:42.426656:  
2025-08-28 11:24:42.434244: Epoch 718 
2025-08-28 11:24:42.440670: Current learning rate: 0.0032 
2025-08-28 11:24:59.154757: train_loss -0.3794 
2025-08-28 11:24:59.163246: val_loss -0.3687 
2025-08-28 11:24:59.167409: Pseudo dice [np.float32(0.6454)] 
2025-08-28 11:24:59.175589: Epoch time: 16.73 s 
2025-08-28 11:24:59.884759:  
2025-08-28 11:24:59.893059: Epoch 719 
2025-08-28 11:24:59.900386: Current learning rate: 0.00319 
2025-08-28 11:25:16.973048: train_loss -0.3433 
2025-08-28 11:25:16.985138: val_loss -0.4468 
2025-08-28 11:25:16.989321: Pseudo dice [np.float32(0.736)] 
2025-08-28 11:25:16.999121: Epoch time: 17.09 s 
2025-08-28 11:25:17.698254:  
2025-08-28 11:25:17.708704: Epoch 720 
2025-08-28 11:25:17.714471: Current learning rate: 0.00318 
2025-08-28 11:25:34.540232: train_loss -0.3633 
2025-08-28 11:25:34.548613: val_loss -0.4425 
2025-08-28 11:25:34.552980: Pseudo dice [np.float32(0.7045)] 
2025-08-28 11:25:34.560325: Epoch time: 16.84 s 
2025-08-28 11:25:35.319601:  
2025-08-28 11:25:35.327332: Epoch 721 
2025-08-28 11:25:35.333705: Current learning rate: 0.00317 
2025-08-28 11:25:52.401685: train_loss -0.3826 
2025-08-28 11:25:52.408039: val_loss -0.4049 
2025-08-28 11:25:52.416700: Pseudo dice [np.float32(0.6961)] 
2025-08-28 11:25:52.422015: Epoch time: 17.08 s 
2025-08-28 11:25:53.134004:  
2025-08-28 11:25:53.144156: Epoch 722 
2025-08-28 11:25:53.151559: Current learning rate: 0.00316 
2025-08-28 11:26:10.171595: train_loss -0.3707 
2025-08-28 11:26:10.180328: val_loss -0.402 
2025-08-28 11:26:10.188592: Pseudo dice [np.float32(0.6747)] 
2025-08-28 11:26:10.194905: Epoch time: 17.04 s 
2025-08-28 11:26:10.930707:  
2025-08-28 11:26:10.940043: Epoch 723 
2025-08-28 11:26:10.947400: Current learning rate: 0.00315 
2025-08-28 11:26:27.342936: train_loss -0.3701 
2025-08-28 11:26:27.351259: val_loss -0.4387 
2025-08-28 11:26:27.355435: Pseudo dice [np.float32(0.6829)] 
2025-08-28 11:26:27.361943: Epoch time: 16.41 s 
2025-08-28 11:26:28.107348:  
2025-08-28 11:26:28.114388: Epoch 724 
2025-08-28 11:26:28.123918: Current learning rate: 0.00314 
2025-08-28 11:26:45.052596: train_loss -0.3787 
2025-08-28 11:26:45.064787: val_loss -0.3517 
2025-08-28 11:26:45.068920: Pseudo dice [np.float32(0.6406)] 
2025-08-28 11:26:45.076280: Epoch time: 16.95 s 
2025-08-28 11:26:45.819696:  
2025-08-28 11:26:45.827990: Epoch 725 
2025-08-28 11:26:45.833289: Current learning rate: 0.00313 
2025-08-28 11:27:02.315983: train_loss -0.3889 
2025-08-28 11:27:02.323720: val_loss -0.3977 
2025-08-28 11:27:02.327884: Pseudo dice [np.float32(0.6393)] 
2025-08-28 11:27:02.336191: Epoch time: 16.5 s 
2025-08-28 11:27:03.044098:  
2025-08-28 11:27:03.054412: Epoch 726 
2025-08-28 11:27:03.062167: Current learning rate: 0.00312 
2025-08-28 11:27:19.578401: train_loss -0.341 
2025-08-28 11:27:19.587407: val_loss -0.4722 
2025-08-28 11:27:19.595098: Pseudo dice [np.float32(0.7627)] 
2025-08-28 11:27:19.602546: Epoch time: 16.54 s 
2025-08-28 11:27:20.283199:  
2025-08-28 11:27:20.290463: Epoch 727 
2025-08-28 11:27:20.295747: Current learning rate: 0.00311 
2025-08-28 11:27:34.280640: train_loss -0.3715 
2025-08-28 11:27:34.288976: val_loss -0.3725 
2025-08-28 11:27:34.293103: Pseudo dice [np.float32(0.6328)] 
2025-08-28 11:27:34.300251: Epoch time: 14.0 s 
2025-08-28 11:27:35.114659:  
2025-08-28 11:27:35.123254: Epoch 728 
2025-08-28 11:27:35.131968: Current learning rate: 0.0031 
2025-08-28 11:27:49.104438: train_loss -0.3642 
2025-08-28 11:27:49.112053: val_loss -0.3727 
2025-08-28 11:27:49.116208: Pseudo dice [np.float32(0.6429)] 
2025-08-28 11:27:49.125783: Epoch time: 13.99 s 
2025-08-28 11:27:49.799064:  
2025-08-28 11:27:49.809546: Epoch 729 
2025-08-28 11:27:49.815270: Current learning rate: 0.00309 
2025-08-28 11:28:04.577511: train_loss -0.3694 
2025-08-28 11:28:04.585838: val_loss -0.43 
2025-08-28 11:28:04.590016: Pseudo dice [np.float32(0.6834)] 
2025-08-28 11:28:04.598109: Epoch time: 14.78 s 
2025-08-28 11:28:05.260352:  
2025-08-28 11:28:05.268715: Epoch 730 
2025-08-28 11:28:05.278141: Current learning rate: 0.00308 
2025-08-28 11:28:20.631028: train_loss -0.378 
2025-08-28 11:28:20.639399: val_loss -0.3861 
2025-08-28 11:28:20.647722: Pseudo dice [np.float32(0.6866)] 
2025-08-28 11:28:20.654758: Epoch time: 15.37 s 
2025-08-28 11:28:21.327404:  
2025-08-28 11:28:21.336952: Epoch 731 
2025-08-28 11:28:21.347688: Current learning rate: 0.00307 
2025-08-28 11:28:36.647482: train_loss -0.3969 
2025-08-28 11:28:36.655640: val_loss -0.4295 
2025-08-28 11:28:36.663682: Pseudo dice [np.float32(0.7401)] 
2025-08-28 11:28:36.670932: Epoch time: 15.32 s 
2025-08-28 11:28:37.344606:  
2025-08-28 11:28:37.351711: Epoch 732 
2025-08-28 11:28:37.357062: Current learning rate: 0.00306 
2025-08-28 11:28:52.083251: train_loss -0.3878 
2025-08-28 11:28:52.091608: val_loss -0.4229 
2025-08-28 11:28:52.099941: Pseudo dice [np.float32(0.6992)] 
2025-08-28 11:28:52.107074: Epoch time: 14.74 s 
2025-08-28 11:28:52.782828:  
2025-08-28 11:28:52.791240: Epoch 733 
2025-08-28 11:28:52.797499: Current learning rate: 0.00305 
2025-08-28 11:29:07.644624: train_loss -0.3856 
2025-08-28 11:29:07.652987: val_loss -0.4381 
2025-08-28 11:29:07.657002: Pseudo dice [np.float32(0.7282)] 
2025-08-28 11:29:07.666252: Epoch time: 14.86 s 
2025-08-28 11:29:08.332721:  
2025-08-28 11:29:08.341005: Epoch 734 
2025-08-28 11:29:08.346433: Current learning rate: 0.00304 
2025-08-28 11:29:23.677299: train_loss -0.3904 
2025-08-28 11:29:23.685707: val_loss -0.4252 
2025-08-28 11:29:23.694514: Pseudo dice [np.float32(0.6296)] 
2025-08-28 11:29:23.699284: Epoch time: 15.35 s 
2025-08-28 11:29:24.534403:  
2025-08-28 11:29:24.542770: Epoch 735 
2025-08-28 11:29:24.547911: Current learning rate: 0.00303 
2025-08-28 11:29:39.693296: train_loss -0.3607 
2025-08-28 11:29:39.701632: val_loss -0.4249 
2025-08-28 11:29:39.709817: Pseudo dice [np.float32(0.7415)] 
2025-08-28 11:29:39.716358: Epoch time: 15.16 s 
2025-08-28 11:29:40.376170:  
2025-08-28 11:29:40.385626: Epoch 736 
2025-08-28 11:29:40.390851: Current learning rate: 0.00302 
2025-08-28 11:29:55.213192: train_loss -0.3841 
2025-08-28 11:29:55.221328: val_loss -0.4295 
2025-08-28 11:29:55.229638: Pseudo dice [np.float32(0.7563)] 
2025-08-28 11:29:55.235070: Epoch time: 14.84 s 
2025-08-28 11:29:55.238798: Yayy! New best EMA pseudo Dice: 0.6955000162124634 
2025-08-28 11:29:56.080467:  
2025-08-28 11:29:56.091013: Epoch 737 
2025-08-28 11:29:56.097006: Current learning rate: 0.00301 
2025-08-28 11:30:11.345898: train_loss -0.3803 
2025-08-28 11:30:11.358256: val_loss -0.4346 
2025-08-28 11:30:11.364535: Pseudo dice [np.float32(0.6431)] 
2025-08-28 11:30:11.371861: Epoch time: 15.27 s 
2025-08-28 11:30:12.036992:  
2025-08-28 11:30:12.046391: Epoch 738 
2025-08-28 11:30:12.056534: Current learning rate: 0.003 
2025-08-28 11:30:27.399460: train_loss -0.3728 
2025-08-28 11:30:27.407601: val_loss -0.4166 
2025-08-28 11:30:27.411777: Pseudo dice [np.float32(0.7045)] 
2025-08-28 11:30:27.421098: Epoch time: 15.36 s 
2025-08-28 11:30:28.109391:  
2025-08-28 11:30:28.119650: Epoch 739 
2025-08-28 11:30:28.127158: Current learning rate: 0.00299 
2025-08-28 11:30:43.240111: train_loss -0.4005 
2025-08-28 11:30:43.248425: val_loss -0.3947 
2025-08-28 11:30:43.256769: Pseudo dice [np.float32(0.6883)] 
2025-08-28 11:30:43.262904: Epoch time: 15.13 s 
2025-08-28 11:30:43.931287:  
2025-08-28 11:30:43.941793: Epoch 740 
2025-08-28 11:30:43.950564: Current learning rate: 0.00297 
2025-08-28 11:30:58.759720: train_loss -0.3404 
2025-08-28 11:30:58.768066: val_loss -0.3802 
2025-08-28 11:30:58.776402: Pseudo dice [np.float32(0.6877)] 
2025-08-28 11:30:58.781361: Epoch time: 14.83 s 
2025-08-28 11:30:59.601119:  
2025-08-28 11:30:59.611757: Epoch 741 
2025-08-28 11:30:59.621016: Current learning rate: 0.00296 
2025-08-28 11:31:14.550865: train_loss -0.3702 
2025-08-28 11:31:14.558843: val_loss -0.491 
2025-08-28 11:31:14.567198: Pseudo dice [np.float32(0.7084)] 
2025-08-28 11:31:14.574417: Epoch time: 14.95 s 
2025-08-28 11:31:15.240714:  
2025-08-28 11:31:15.251124: Epoch 742 
2025-08-28 11:31:15.259360: Current learning rate: 0.00295 
2025-08-28 11:31:32.026287: train_loss -0.3863 
2025-08-28 11:31:32.034637: val_loss -0.4113 
2025-08-28 11:31:32.043309: Pseudo dice [np.float32(0.7341)] 
2025-08-28 11:31:32.050249: Epoch time: 16.79 s 
2025-08-28 11:31:32.057098: Yayy! New best EMA pseudo Dice: 0.6969000101089478 
2025-08-28 11:31:32.999118:  
2025-08-28 11:31:33.006721: Epoch 743 
2025-08-28 11:31:33.015879: Current learning rate: 0.00294 
2025-08-28 11:31:50.132305: train_loss -0.349 
2025-08-28 11:31:50.144405: val_loss -0.3664 
2025-08-28 11:31:50.148589: Pseudo dice [np.float32(0.6414)] 
2025-08-28 11:31:50.155961: Epoch time: 17.14 s 
2025-08-28 11:31:50.937376:  
2025-08-28 11:31:50.945453: Epoch 744 
2025-08-28 11:31:50.953845: Current learning rate: 0.00293 
2025-08-28 11:32:09.026102: train_loss -0.3549 
2025-08-28 11:32:09.034469: val_loss -0.4223 
2025-08-28 11:32:09.043011: Pseudo dice [np.float32(0.6997)] 
2025-08-28 11:32:09.047952: Epoch time: 18.09 s 
2025-08-28 11:32:09.793110:  
2025-08-28 11:32:09.801877: Epoch 745 
2025-08-28 11:32:09.809857: Current learning rate: 0.00292 
2025-08-28 11:32:28.060989: train_loss -0.3672 
2025-08-28 11:32:28.069748: val_loss -0.4189 
2025-08-28 11:32:28.074132: Pseudo dice [np.float32(0.7225)] 
2025-08-28 11:32:28.083133: Epoch time: 18.27 s 
2025-08-28 11:32:28.972296:  
2025-08-28 11:32:28.982701: Epoch 746 
2025-08-28 11:32:28.990544: Current learning rate: 0.00291 
2025-08-28 11:32:47.480882: train_loss -0.3818 
2025-08-28 11:32:47.489373: val_loss -0.4337 
2025-08-28 11:32:47.495793: Pseudo dice [np.float32(0.7242)] 
2025-08-28 11:32:47.501189: Epoch time: 18.51 s 
2025-08-28 11:32:47.508406: Yayy! New best EMA pseudo Dice: 0.6980999708175659 
2025-08-28 11:32:48.762917:  
2025-08-28 11:32:48.770612: Epoch 747 
2025-08-28 11:32:48.778231: Current learning rate: 0.0029 
2025-08-28 11:33:07.258851: train_loss -0.3684 
2025-08-28 11:33:07.267479: val_loss -0.404 
2025-08-28 11:33:07.275889: Pseudo dice [np.float32(0.6505)] 
2025-08-28 11:33:07.282079: Epoch time: 18.5 s 
2025-08-28 11:33:08.137373:  
2025-08-28 11:33:08.147104: Epoch 748 
2025-08-28 11:33:08.155501: Current learning rate: 0.00289 
2025-08-28 11:33:26.377936: train_loss -0.3988 
2025-08-28 11:33:26.386307: val_loss -0.387 
2025-08-28 11:33:26.390460: Pseudo dice [np.float32(0.6642)] 
2025-08-28 11:33:26.397842: Epoch time: 18.24 s 
2025-08-28 11:33:27.122399:  
2025-08-28 11:33:27.129735: Epoch 749 
2025-08-28 11:33:27.135972: Current learning rate: 0.00288 
2025-08-28 11:33:43.904105: train_loss -0.359 
2025-08-28 11:33:43.912158: val_loss -0.4512 
2025-08-28 11:33:43.920244: Pseudo dice [np.float32(0.768)] 
2025-08-28 11:33:43.925434: Epoch time: 16.78 s 
2025-08-28 11:33:44.137686: Yayy! New best EMA pseudo Dice: 0.698199987411499 
2025-08-28 11:33:45.061111:  
2025-08-28 11:33:45.068972: Epoch 750 
2025-08-28 11:33:45.075681: Current learning rate: 0.00287 
2025-08-28 11:34:01.192152: train_loss -0.3901 
2025-08-28 11:34:01.204376: val_loss -0.368 
2025-08-28 11:34:01.212740: Pseudo dice [np.float32(0.6482)] 
2025-08-28 11:34:01.221982: Epoch time: 16.13 s 
2025-08-28 11:34:01.942504:  
2025-08-28 11:34:01.951827: Epoch 751 
2025-08-28 11:34:01.958963: Current learning rate: 0.00286 
2025-08-28 11:34:18.217357: train_loss -0.3817 
2025-08-28 11:34:18.225549: val_loss -0.4503 
2025-08-28 11:34:18.229731: Pseudo dice [np.float32(0.691)] 
2025-08-28 11:34:18.237124: Epoch time: 16.28 s 
2025-08-28 11:34:19.131022:  
2025-08-28 11:34:19.137879: Epoch 752 
2025-08-28 11:34:19.143504: Current learning rate: 0.00285 
2025-08-28 11:34:35.262969: train_loss -0.3865 
2025-08-28 11:34:35.271761: val_loss -0.3458 
2025-08-28 11:34:35.275850: Pseudo dice [np.float32(0.6309)] 
2025-08-28 11:34:35.284444: Epoch time: 16.13 s 
2025-08-28 11:34:36.022446:  
2025-08-28 11:34:36.030131: Epoch 753 
2025-08-28 11:34:36.037376: Current learning rate: 0.00284 
2025-08-28 11:34:51.700746: train_loss -0.3773 
2025-08-28 11:34:51.709005: val_loss -0.3994 
2025-08-28 11:34:51.713165: Pseudo dice [np.float32(0.6781)] 
2025-08-28 11:34:51.722310: Epoch time: 15.68 s 
2025-08-28 11:34:52.451679:  
2025-08-28 11:34:52.459745: Epoch 754 
2025-08-28 11:34:52.464830: Current learning rate: 0.00283 
2025-08-28 11:35:08.354964: train_loss -0.3842 
2025-08-28 11:35:08.367614: val_loss -0.4019 
2025-08-28 11:35:08.372076: Pseudo dice [np.float32(0.7031)] 
2025-08-28 11:35:08.381014: Epoch time: 15.91 s 
2025-08-28 11:35:09.117563:  
2025-08-28 11:35:09.126330: Epoch 755 
2025-08-28 11:35:09.133183: Current learning rate: 0.00282 
2025-08-28 11:35:24.933944: train_loss -0.3673 
2025-08-28 11:35:24.942176: val_loss -0.4186 
2025-08-28 11:35:24.950583: Pseudo dice [np.float32(0.6759)] 
2025-08-28 11:35:24.956847: Epoch time: 15.82 s 
2025-08-28 11:35:25.677254:  
2025-08-28 11:35:25.685330: Epoch 756 
2025-08-28 11:35:25.695371: Current learning rate: 0.00281 
2025-08-28 11:35:41.467026: train_loss -0.3795 
2025-08-28 11:35:41.475348: val_loss -0.4322 
2025-08-28 11:35:41.483892: Pseudo dice [np.float32(0.6961)] 
2025-08-28 11:35:41.489943: Epoch time: 15.79 s 
2025-08-28 11:35:42.198942:  
2025-08-28 11:35:42.205479: Epoch 757 
2025-08-28 11:35:42.214928: Current learning rate: 0.0028 
2025-08-28 11:35:58.000291: train_loss -0.393 
2025-08-28 11:35:58.008534: val_loss -0.46 
2025-08-28 11:35:58.012598: Pseudo dice [np.float32(0.7026)] 
2025-08-28 11:35:58.022306: Epoch time: 15.8 s 
2025-08-28 11:35:58.738309:  
2025-08-28 11:35:58.747857: Epoch 758 
2025-08-28 11:35:58.756208: Current learning rate: 0.00279 
2025-08-28 11:36:14.595904: train_loss -0.3858 
2025-08-28 11:36:14.604264: val_loss -0.439 
2025-08-28 11:36:14.608583: Pseudo dice [np.float32(0.6875)] 
2025-08-28 11:36:14.616645: Epoch time: 15.86 s 
2025-08-28 11:36:15.522256:  
2025-08-28 11:36:15.531249: Epoch 759 
2025-08-28 11:36:15.536419: Current learning rate: 0.00278 
2025-08-28 11:36:31.112711: train_loss -0.4081 
2025-08-28 11:36:31.120746: val_loss -0.409 
2025-08-28 11:36:31.124910: Pseudo dice [np.float32(0.704)] 
2025-08-28 11:36:31.133103: Epoch time: 15.59 s 
2025-08-28 11:36:31.856418:  
2025-08-28 11:36:31.863422: Epoch 760 
2025-08-28 11:36:31.871593: Current learning rate: 0.00277 
2025-08-28 11:36:47.557998: train_loss -0.3736 
2025-08-28 11:36:47.566592: val_loss -0.4184 
2025-08-28 11:36:47.570513: Pseudo dice [np.float32(0.7304)] 
2025-08-28 11:36:47.577712: Epoch time: 15.7 s 
2025-08-28 11:36:48.309494:  
2025-08-28 11:36:48.318489: Epoch 761 
2025-08-28 11:36:48.324303: Current learning rate: 0.00276 
2025-08-28 11:37:04.024609: train_loss -0.3728 
2025-08-28 11:37:04.032650: val_loss -0.4313 
2025-08-28 11:37:04.041741: Pseudo dice [np.float32(0.7348)] 
2025-08-28 11:37:04.047372: Epoch time: 15.72 s 
2025-08-28 11:37:04.053499: Yayy! New best EMA pseudo Dice: 0.6984000205993652 
2025-08-28 11:37:05.009103:  
2025-08-28 11:37:05.017083: Epoch 762 
2025-08-28 11:37:05.022225: Current learning rate: 0.00275 
2025-08-28 11:37:21.070604: train_loss -0.3915 
2025-08-28 11:37:21.083131: val_loss -0.3988 
2025-08-28 11:37:21.087274: Pseudo dice [np.float32(0.6271)] 
2025-08-28 11:37:21.096469: Epoch time: 16.06 s 
2025-08-28 11:37:21.827966:  
2025-08-28 11:37:21.837577: Epoch 763 
2025-08-28 11:37:21.844256: Current learning rate: 0.00274 
2025-08-28 11:37:38.192123: train_loss -0.3829 
2025-08-28 11:37:38.200447: val_loss -0.4421 
2025-08-28 11:37:38.208576: Pseudo dice [np.float32(0.6171)] 
2025-08-28 11:37:38.214799: Epoch time: 16.37 s 
2025-08-28 11:37:38.940476:  
2025-08-28 11:37:38.949882: Epoch 764 
2025-08-28 11:37:38.958140: Current learning rate: 0.00273 
2025-08-28 11:37:54.896217: train_loss -0.3804 
2025-08-28 11:37:54.908567: val_loss -0.4071 
2025-08-28 11:37:54.912742: Pseudo dice [np.float32(0.7082)] 
2025-08-28 11:37:54.919967: Epoch time: 15.96 s 
2025-08-28 11:37:55.788571:  
2025-08-28 11:37:55.796848: Epoch 765 
2025-08-28 11:37:55.803151: Current learning rate: 0.00272 
2025-08-28 11:38:12.001624: train_loss -0.3672 
2025-08-28 11:38:12.013374: val_loss -0.4007 
2025-08-28 11:38:12.017565: Pseudo dice [np.float32(0.6596)] 
2025-08-28 11:38:12.024733: Epoch time: 16.21 s 
2025-08-28 11:38:12.738772:  
2025-08-28 11:38:12.748188: Epoch 766 
2025-08-28 11:38:12.753448: Current learning rate: 0.00271 
2025-08-28 11:38:29.230296: train_loss -0.365 
2025-08-28 11:38:29.238762: val_loss -0.4209 
2025-08-28 11:38:29.242815: Pseudo dice [np.float32(0.7046)] 
2025-08-28 11:38:29.251870: Epoch time: 16.49 s 
2025-08-28 11:38:29.989449:  
2025-08-28 11:38:29.996457: Epoch 767 
2025-08-28 11:38:30.002006: Current learning rate: 0.0027 
2025-08-28 11:38:46.350008: train_loss -0.3745 
2025-08-28 11:38:46.359921: val_loss -0.4241 
2025-08-28 11:38:46.364136: Pseudo dice [np.float32(0.664)] 
2025-08-28 11:38:46.372432: Epoch time: 16.36 s 
2025-08-28 11:38:47.096406:  
2025-08-28 11:38:47.102807: Epoch 768 
2025-08-28 11:38:47.112612: Current learning rate: 0.00268 
2025-08-28 11:39:03.372778: train_loss -0.3692 
2025-08-28 11:39:03.381136: val_loss -0.3329 
2025-08-28 11:39:03.385560: Pseudo dice [np.float32(0.6234)] 
2025-08-28 11:39:03.392554: Epoch time: 16.28 s 
2025-08-28 11:39:04.117275:  
2025-08-28 11:39:04.126548: Epoch 769 
2025-08-28 11:39:04.132911: Current learning rate: 0.00267 
2025-08-28 11:39:20.393902: train_loss -0.3811 
2025-08-28 11:39:20.402602: val_loss -0.4025 
2025-08-28 11:39:20.410833: Pseudo dice [np.float32(0.6597)] 
2025-08-28 11:39:20.418028: Epoch time: 16.28 s 
2025-08-28 11:39:21.160186:  
2025-08-28 11:39:21.168516: Epoch 770 
2025-08-28 11:39:21.178851: Current learning rate: 0.00266 
2025-08-28 11:39:37.565242: train_loss -0.367 
2025-08-28 11:39:37.573545: val_loss -0.4321 
2025-08-28 11:39:37.581946: Pseudo dice [np.float32(0.689)] 
2025-08-28 11:39:37.587353: Epoch time: 16.41 s 
2025-08-28 11:39:38.463277:  
2025-08-28 11:39:38.473266: Epoch 771 
2025-08-28 11:39:38.479164: Current learning rate: 0.00265 
2025-08-28 11:39:54.980517: train_loss -0.3993 
2025-08-28 11:39:54.986785: val_loss -0.469 
2025-08-28 11:39:54.995486: Pseudo dice [np.float32(0.7107)] 
2025-08-28 11:39:55.001679: Epoch time: 16.52 s 
2025-08-28 11:39:55.737353:  
2025-08-28 11:39:55.746885: Epoch 772 
2025-08-28 11:39:55.756532: Current learning rate: 0.00264 
2025-08-28 11:40:11.745300: train_loss -0.391 
2025-08-28 11:40:11.758063: val_loss -0.4158 
2025-08-28 11:40:11.762209: Pseudo dice [np.float32(0.644)] 
2025-08-28 11:40:11.771283: Epoch time: 16.01 s 
2025-08-28 11:40:12.504158:  
2025-08-28 11:40:12.515758: Epoch 773 
2025-08-28 11:40:12.521600: Current learning rate: 0.00263 
2025-08-28 11:40:28.820590: train_loss -0.3894 
2025-08-28 11:40:28.828949: val_loss -0.4246 
2025-08-28 11:40:28.837265: Pseudo dice [np.float32(0.6637)] 
2025-08-28 11:40:28.845539: Epoch time: 16.32 s 
2025-08-28 11:40:29.583833:  
2025-08-28 11:40:29.593167: Epoch 774 
2025-08-28 11:40:29.596481: Current learning rate: 0.00262 
2025-08-28 11:40:45.716599: train_loss -0.3756 
2025-08-28 11:40:45.724961: val_loss -0.3799 
2025-08-28 11:40:45.729139: Pseudo dice [np.float32(0.69)] 
2025-08-28 11:40:45.737311: Epoch time: 16.13 s 
2025-08-28 11:40:46.476203:  
2025-08-28 11:40:46.482969: Epoch 775 
2025-08-28 11:40:46.488208: Current learning rate: 0.00261 
2025-08-28 11:41:02.875401: train_loss -0.3618 
2025-08-28 11:41:02.883748: val_loss -0.4141 
2025-08-28 11:41:02.888595: Pseudo dice [np.float32(0.7333)] 
2025-08-28 11:41:02.897143: Epoch time: 16.4 s 
2025-08-28 11:41:03.621888:  
2025-08-28 11:41:03.630267: Epoch 776 
2025-08-28 11:41:03.637532: Current learning rate: 0.0026 
2025-08-28 11:41:19.842372: train_loss -0.3858 
2025-08-28 11:41:19.850720: val_loss -0.4178 
2025-08-28 11:41:19.859338: Pseudo dice [np.float32(0.7439)] 
2025-08-28 11:41:19.863974: Epoch time: 16.22 s 
2025-08-28 11:41:20.591954:  
2025-08-28 11:41:20.600263: Epoch 777 
2025-08-28 11:41:20.608576: Current learning rate: 0.00259 
2025-08-28 11:41:37.017816: train_loss -0.3829 
2025-08-28 11:41:37.026182: val_loss -0.4069 
2025-08-28 11:41:37.030348: Pseudo dice [np.float32(0.6983)] 
2025-08-28 11:41:37.038686: Epoch time: 16.43 s 
2025-08-28 11:41:37.773788:  
2025-08-28 11:41:37.784089: Epoch 778 
2025-08-28 11:41:37.790450: Current learning rate: 0.00258 
2025-08-28 11:41:53.914275: train_loss -0.4032 
2025-08-28 11:41:53.922190: val_loss -0.3997 
2025-08-28 11:41:53.931458: Pseudo dice [np.float32(0.7055)] 
2025-08-28 11:41:53.937177: Epoch time: 16.14 s 
2025-08-28 11:41:54.666036:  
2025-08-28 11:41:54.673048: Epoch 779 
2025-08-28 11:41:54.682394: Current learning rate: 0.00257 
2025-08-28 11:42:10.885402: train_loss -0.3951 
2025-08-28 11:42:10.897475: val_loss -0.3929 
2025-08-28 11:42:10.901972: Pseudo dice [np.float32(0.6064)] 
2025-08-28 11:42:10.910296: Epoch time: 16.22 s 
2025-08-28 11:42:11.659621:  
2025-08-28 11:42:11.667972: Epoch 780 
2025-08-28 11:42:11.675349: Current learning rate: 0.00256 
2025-08-28 11:42:27.751734: train_loss -0.3559 
2025-08-28 11:42:27.764325: val_loss -0.419 
2025-08-28 11:42:27.772927: Pseudo dice [np.float32(0.7309)] 
2025-08-28 11:42:27.780953: Epoch time: 16.09 s 
2025-08-28 11:42:28.541102:  
2025-08-28 11:42:28.550589: Epoch 781 
2025-08-28 11:42:28.556726: Current learning rate: 0.00255 
2025-08-28 11:42:44.076492: train_loss -0.3523 
2025-08-28 11:42:44.084793: val_loss -0.3775 
2025-08-28 11:42:44.088958: Pseudo dice [np.float32(0.7601)] 
2025-08-28 11:42:44.098158: Epoch time: 15.54 s 
2025-08-28 11:42:44.834249:  
2025-08-28 11:42:44.843863: Epoch 782 
2025-08-28 11:42:44.851224: Current learning rate: 0.00254 
2025-08-28 11:43:00.484595: train_loss -0.3954 
2025-08-28 11:43:00.497034: val_loss -0.4303 
2025-08-28 11:43:00.501167: Pseudo dice [np.float32(0.7079)] 
2025-08-28 11:43:00.508507: Epoch time: 15.65 s 
2025-08-28 11:43:01.386767:  
2025-08-28 11:43:01.394734: Epoch 783 
2025-08-28 11:43:01.401934: Current learning rate: 0.00253 
2025-08-28 11:43:17.055233: train_loss -0.3774 
2025-08-28 11:43:17.067771: val_loss -0.4055 
2025-08-28 11:43:17.072620: Pseudo dice [np.float32(0.664)] 
2025-08-28 11:43:17.082601: Epoch time: 15.67 s 
2025-08-28 11:43:17.756183:  
2025-08-28 11:43:17.764606: Epoch 784 
2025-08-28 11:43:17.774616: Current learning rate: 0.00252 
2025-08-28 11:43:31.661472: train_loss -0.3569 
2025-08-28 11:43:31.669947: val_loss -0.4143 
2025-08-28 11:43:31.674520: Pseudo dice [np.float32(0.6504)] 
2025-08-28 11:43:31.682971: Epoch time: 13.91 s 
2025-08-28 11:43:32.354908:  
2025-08-28 11:43:32.363267: Epoch 785 
2025-08-28 11:43:32.372396: Current learning rate: 0.00251 
2025-08-28 11:43:46.301286: train_loss -0.3728 
2025-08-28 11:43:46.309682: val_loss -0.406 
2025-08-28 11:43:46.313579: Pseudo dice [np.float32(0.7322)] 
2025-08-28 11:43:46.321248: Epoch time: 13.95 s 
2025-08-28 11:43:46.995429:  
2025-08-28 11:43:47.002875: Epoch 786 
2025-08-28 11:43:47.008977: Current learning rate: 0.0025 
2025-08-28 11:44:01.120307: train_loss -0.3863 
2025-08-28 11:44:01.128401: val_loss -0.4078 
2025-08-28 11:44:01.132566: Pseudo dice [np.float32(0.7304)] 
2025-08-28 11:44:01.139650: Epoch time: 14.13 s 
2025-08-28 11:44:01.809303:  
2025-08-28 11:44:01.817610: Epoch 787 
2025-08-28 11:44:01.826527: Current learning rate: 0.00249 
2025-08-28 11:44:15.889112: train_loss -0.3817 
2025-08-28 11:44:15.897279: val_loss -0.4202 
2025-08-28 11:44:15.905638: Pseudo dice [np.float32(0.7321)] 
2025-08-28 11:44:15.911017: Epoch time: 14.08 s 
2025-08-28 11:44:15.917857: Yayy! New best EMA pseudo Dice: 0.7002999782562256 
2025-08-28 11:44:16.767923:  
2025-08-28 11:44:16.777348: Epoch 788 
2025-08-28 11:44:16.783529: Current learning rate: 0.00248 
2025-08-28 11:44:30.661494: train_loss -0.3861 
2025-08-28 11:44:30.666223: val_loss -0.3672 
2025-08-28 11:44:30.674913: Pseudo dice [np.float32(0.619)] 
2025-08-28 11:44:30.681744: Epoch time: 13.9 s 
2025-08-28 11:44:31.350072:  
2025-08-28 11:44:31.358462: Epoch 789 
2025-08-28 11:44:31.363770: Current learning rate: 0.00247 
2025-08-28 11:44:45.597887: train_loss -0.3849 
2025-08-28 11:44:45.606099: val_loss -0.416 
2025-08-28 11:44:45.610286: Pseudo dice [np.float32(0.7242)] 
2025-08-28 11:44:45.619394: Epoch time: 14.25 s 
2025-08-28 11:44:46.453870:  
2025-08-28 11:44:46.463212: Epoch 790 
2025-08-28 11:44:46.468322: Current learning rate: 0.00245 
2025-08-28 11:45:00.316149: train_loss -0.3617 
2025-08-28 11:45:00.324553: val_loss -0.4314 
2025-08-28 11:45:00.329138: Pseudo dice [np.float32(0.6969)] 
2025-08-28 11:45:00.336348: Epoch time: 13.86 s 
2025-08-28 11:45:01.015343:  
2025-08-28 11:45:01.025682: Epoch 791 
2025-08-28 11:45:01.031385: Current learning rate: 0.00244 
2025-08-28 11:45:14.818568: train_loss -0.3721 
2025-08-28 11:45:14.826961: val_loss -0.3738 
2025-08-28 11:45:14.836859: Pseudo dice [np.float32(0.6436)] 
2025-08-28 11:45:14.841517: Epoch time: 13.8 s 
2025-08-28 11:45:15.519142:  
2025-08-28 11:45:15.527484: Epoch 792 
2025-08-28 11:45:15.539073: Current learning rate: 0.00243 
2025-08-28 11:45:30.042188: train_loss -0.3761 
2025-08-28 11:45:30.050499: val_loss -0.4248 
2025-08-28 11:45:30.058851: Pseudo dice [np.float32(0.7011)] 
2025-08-28 11:45:30.063748: Epoch time: 14.52 s 
2025-08-28 11:45:30.735764:  
2025-08-28 11:45:30.746310: Epoch 793 
2025-08-28 11:45:30.751537: Current learning rate: 0.00242 
2025-08-28 11:45:45.449184: train_loss -0.3768 
2025-08-28 11:45:45.457545: val_loss -0.4141 
2025-08-28 11:45:45.461711: Pseudo dice [np.float32(0.6971)] 
2025-08-28 11:45:45.469170: Epoch time: 14.71 s 
2025-08-28 11:45:46.159264:  
2025-08-28 11:45:46.166507: Epoch 794 
2025-08-28 11:45:46.172777: Current learning rate: 0.00241 
2025-08-28 11:46:01.156553: train_loss -0.3813 
2025-08-28 11:46:01.165134: val_loss -0.4091 
2025-08-28 11:46:01.169131: Pseudo dice [np.float32(0.6723)] 
2025-08-28 11:46:01.178144: Epoch time: 15.0 s 
2025-08-28 11:46:01.861265:  
2025-08-28 11:46:01.870976: Epoch 795 
2025-08-28 11:46:01.876006: Current learning rate: 0.0024 
2025-08-28 11:46:16.563910: train_loss -0.3806 
2025-08-28 11:46:16.571928: val_loss -0.3744 
2025-08-28 11:46:16.580298: Pseudo dice [np.float32(0.5872)] 
2025-08-28 11:46:16.586425: Epoch time: 14.7 s 
2025-08-28 11:46:17.416461:  
2025-08-28 11:46:17.424791: Epoch 796 
2025-08-28 11:46:17.430010: Current learning rate: 0.00239 
2025-08-28 11:46:32.787764: train_loss -0.397 
2025-08-28 11:46:32.796479: val_loss -0.4334 
2025-08-28 11:46:32.804834: Pseudo dice [np.float32(0.7204)] 
2025-08-28 11:46:32.810938: Epoch time: 15.37 s 
2025-08-28 11:46:33.481496:  
2025-08-28 11:46:33.491909: Epoch 797 
2025-08-28 11:46:33.498265: Current learning rate: 0.00238 
2025-08-28 11:46:48.712686: train_loss -0.3896 
2025-08-28 11:46:48.716851: val_loss -0.4384 
2025-08-28 11:46:48.725305: Pseudo dice [np.float32(0.678)] 
2025-08-28 11:46:48.735067: Epoch time: 15.23 s 
2025-08-28 11:46:49.428618:  
2025-08-28 11:46:49.437966: Epoch 798 
2025-08-28 11:46:49.444283: Current learning rate: 0.00237 
2025-08-28 11:47:04.890993: train_loss -0.4139 
2025-08-28 11:47:04.903588: val_loss -0.4043 
2025-08-28 11:47:04.907731: Pseudo dice [np.float32(0.7185)] 
2025-08-28 11:47:04.914787: Epoch time: 15.46 s 
2025-08-28 11:47:05.590611:  
2025-08-28 11:47:05.599982: Epoch 799 
2025-08-28 11:47:05.604529: Current learning rate: 0.00236 
2025-08-28 11:47:20.902734: train_loss -0.3686 
2025-08-28 11:47:20.915345: val_loss -0.3898 
2025-08-28 11:47:20.919526: Pseudo dice [np.float32(0.6342)] 
2025-08-28 11:47:20.926775: Epoch time: 15.31 s 
2025-08-28 11:47:21.878822:  
2025-08-28 11:47:21.887575: Epoch 800 
2025-08-28 11:47:21.891613: Current learning rate: 0.00235 
2025-08-28 11:47:38.728985: train_loss -0.3663 
2025-08-28 11:47:38.737309: val_loss -0.4348 
2025-08-28 11:47:38.741468: Pseudo dice [np.float32(0.7419)] 
2025-08-28 11:47:38.750558: Epoch time: 16.85 s 
2025-08-28 11:47:39.474452:  
2025-08-28 11:47:39.482824: Epoch 801 
2025-08-28 11:47:39.487884: Current learning rate: 0.00234 
2025-08-28 11:47:56.463531: train_loss -0.3694 
2025-08-28 11:47:56.471973: val_loss -0.3629 
2025-08-28 11:47:56.480026: Pseudo dice [np.float32(0.6331)] 
2025-08-28 11:47:56.486203: Epoch time: 16.99 s 
2025-08-28 11:47:57.228780:  
2025-08-28 11:47:57.237415: Epoch 802 
2025-08-28 11:47:57.245457: Current learning rate: 0.00233 
2025-08-28 11:48:14.043429: train_loss -0.3843 
2025-08-28 11:48:14.052116: val_loss -0.4218 
2025-08-28 11:48:14.056359: Pseudo dice [np.float32(0.6285)] 
2025-08-28 11:48:14.064270: Epoch time: 16.82 s 
2025-08-28 11:48:14.832684:  
2025-08-28 11:48:14.839950: Epoch 803 
2025-08-28 11:48:14.846285: Current learning rate: 0.00232 
2025-08-28 11:48:31.531686: train_loss -0.3876 
2025-08-28 11:48:31.540027: val_loss -0.44 
2025-08-28 11:48:31.548539: Pseudo dice [np.float32(0.6632)] 
2025-08-28 11:48:31.555984: Epoch time: 16.7 s 
2025-08-28 11:48:32.286547:  
2025-08-28 11:48:32.292229: Epoch 804 
2025-08-28 11:48:32.301911: Current learning rate: 0.00231 
2025-08-28 11:48:48.849098: train_loss -0.3733 
2025-08-28 11:48:48.861221: val_loss -0.4436 
2025-08-28 11:48:48.865699: Pseudo dice [np.float32(0.7026)] 
2025-08-28 11:48:48.871854: Epoch time: 16.56 s 
2025-08-28 11:48:49.657276:  
2025-08-28 11:48:49.665344: Epoch 805 
2025-08-28 11:48:49.671762: Current learning rate: 0.0023 
2025-08-28 11:49:06.712072: train_loss -0.3794 
2025-08-28 11:49:06.721309: val_loss -0.3908 
2025-08-28 11:49:06.725213: Pseudo dice [np.float32(0.6529)] 
2025-08-28 11:49:06.732511: Epoch time: 17.06 s 
2025-08-28 11:49:07.476701:  
2025-08-28 11:49:07.487847: Epoch 806 
2025-08-28 11:49:07.492848: Current learning rate: 0.00229 
2025-08-28 11:49:24.159257: train_loss -0.3943 
2025-08-28 11:49:24.171802: val_loss -0.3719 
2025-08-28 11:49:24.175912: Pseudo dice [np.float32(0.6821)] 
2025-08-28 11:49:24.184168: Epoch time: 16.68 s 
2025-08-28 11:49:25.157081:  
2025-08-28 11:49:25.165509: Epoch 807 
2025-08-28 11:49:25.171699: Current learning rate: 0.00228 
2025-08-28 11:49:42.335743: train_loss -0.3637 
2025-08-28 11:49:42.344048: val_loss -0.4201 
2025-08-28 11:49:42.352996: Pseudo dice [np.float32(0.7233)] 
2025-08-28 11:49:42.358020: Epoch time: 17.18 s 
2025-08-28 11:49:43.111511:  
2025-08-28 11:49:43.120237: Epoch 808 
2025-08-28 11:49:43.128143: Current learning rate: 0.00226 
2025-08-28 11:49:59.907736: train_loss -0.3818 
2025-08-28 11:49:59.915862: val_loss -0.4306 
2025-08-28 11:49:59.924130: Pseudo dice [np.float32(0.6641)] 
2025-08-28 11:49:59.930416: Epoch time: 16.8 s 
2025-08-28 11:50:00.654008:  
2025-08-28 11:50:00.662374: Epoch 809 
2025-08-28 11:50:00.666538: Current learning rate: 0.00225 
2025-08-28 11:50:17.846267: train_loss -0.3612 
2025-08-28 11:50:17.854865: val_loss -0.4581 
2025-08-28 11:50:17.862892: Pseudo dice [np.float32(0.7048)] 
2025-08-28 11:50:17.868366: Epoch time: 17.2 s 
2025-08-28 11:50:18.607377:  
2025-08-28 11:50:18.614714: Epoch 810 
2025-08-28 11:50:18.620402: Current learning rate: 0.00224 
2025-08-28 11:50:35.793470: train_loss -0.3748 
2025-08-28 11:50:35.801645: val_loss -0.4368 
2025-08-28 11:50:35.809973: Pseudo dice [np.float32(0.6791)] 
2025-08-28 11:50:35.816384: Epoch time: 17.19 s 
2025-08-28 11:50:36.540896:  
2025-08-28 11:50:36.549222: Epoch 811 
2025-08-28 11:50:36.557725: Current learning rate: 0.00223 
2025-08-28 11:50:53.766059: train_loss -0.3766 
2025-08-28 11:50:53.774098: val_loss -0.3993 
2025-08-28 11:50:53.778235: Pseudo dice [np.float32(0.637)] 
2025-08-28 11:50:53.786053: Epoch time: 17.23 s 
2025-08-28 11:50:54.508915:  
2025-08-28 11:50:54.517142: Epoch 812 
2025-08-28 11:50:54.524471: Current learning rate: 0.00222 
2025-08-28 11:51:11.333107: train_loss -0.4185 
2025-08-28 11:51:11.341331: val_loss -0.455 
2025-08-28 11:51:11.345480: Pseudo dice [np.float32(0.7215)] 
2025-08-28 11:51:11.352843: Epoch time: 16.83 s 
2025-08-28 11:51:12.079346:  
2025-08-28 11:51:12.087696: Epoch 813 
2025-08-28 11:51:12.097339: Current learning rate: 0.00221 
2025-08-28 11:51:29.157446: train_loss -0.3828 
2025-08-28 11:51:29.163216: val_loss -0.4035 
2025-08-28 11:51:29.171594: Pseudo dice [np.float32(0.6567)] 
2025-08-28 11:51:29.177906: Epoch time: 17.08 s 
2025-08-28 11:51:30.073495:  
2025-08-28 11:51:30.081804: Epoch 814 
2025-08-28 11:51:30.092215: Current learning rate: 0.0022 
2025-08-28 11:51:46.568099: train_loss -0.367 
2025-08-28 11:51:46.576483: val_loss -0.3576 
2025-08-28 11:51:46.580645: Pseudo dice [np.float32(0.6443)] 
2025-08-28 11:51:46.589062: Epoch time: 16.5 s 
2025-08-28 11:51:47.328223:  
2025-08-28 11:51:47.337662: Epoch 815 
2025-08-28 11:51:47.348177: Current learning rate: 0.00219 
2025-08-28 11:52:04.229820: train_loss -0.3906 
2025-08-28 11:52:04.235998: val_loss -0.3474 
2025-08-28 11:52:04.244104: Pseudo dice [np.float32(0.6953)] 
2025-08-28 11:52:04.251574: Epoch time: 16.9 s 
2025-08-28 11:52:05.006507:  
2025-08-28 11:52:05.013524: Epoch 816 
2025-08-28 11:52:05.019705: Current learning rate: 0.00218 
2025-08-28 11:52:21.861664: train_loss -0.4174 
2025-08-28 11:52:21.874187: val_loss -0.3956 
2025-08-28 11:52:21.878320: Pseudo dice [np.float32(0.6582)] 
2025-08-28 11:52:21.887509: Epoch time: 16.86 s 
2025-08-28 11:52:22.636177:  
2025-08-28 11:52:22.645223: Epoch 817 
2025-08-28 11:52:22.652058: Current learning rate: 0.00217 
2025-08-28 11:52:39.116495: train_loss -0.429 
2025-08-28 11:52:39.124781: val_loss -0.4231 
2025-08-28 11:52:39.133384: Pseudo dice [np.float32(0.7303)] 
2025-08-28 11:52:39.139604: Epoch time: 16.48 s 
2025-08-28 11:52:39.881684:  
2025-08-28 11:52:39.890111: Epoch 818 
2025-08-28 11:52:39.895179: Current learning rate: 0.00216 
2025-08-28 11:52:56.830217: train_loss -0.3963 
2025-08-28 11:52:56.838274: val_loss -0.4543 
2025-08-28 11:52:56.842444: Pseudo dice [np.float32(0.7171)] 
2025-08-28 11:52:56.851518: Epoch time: 16.95 s 
2025-08-28 11:52:57.579539:  
2025-08-28 11:52:57.587867: Epoch 819 
2025-08-28 11:52:57.593025: Current learning rate: 0.00215 
2025-08-28 11:53:14.309886: train_loss -0.4059 
2025-08-28 11:53:14.322425: val_loss -0.432 
2025-08-28 11:53:14.326591: Pseudo dice [np.float32(0.7249)] 
2025-08-28 11:53:14.335916: Epoch time: 16.73 s 
2025-08-28 11:53:15.213122:  
2025-08-28 11:53:15.219945: Epoch 820 
2025-08-28 11:53:15.223803: Current learning rate: 0.00214 
2025-08-28 11:53:32.169708: train_loss -0.3916 
2025-08-28 11:53:32.181946: val_loss -0.404 
2025-08-28 11:53:32.186376: Pseudo dice [np.float32(0.6804)] 
2025-08-28 11:53:32.194103: Epoch time: 16.96 s 
2025-08-28 11:53:32.955544:  
2025-08-28 11:53:32.963949: Epoch 821 
2025-08-28 11:53:32.971223: Current learning rate: 0.00213 
2025-08-28 11:53:49.945575: train_loss -0.3957 
2025-08-28 11:53:49.953523: val_loss -0.4233 
2025-08-28 11:53:49.964375: Pseudo dice [np.float32(0.6429)] 
2025-08-28 11:53:49.970425: Epoch time: 16.99 s 
2025-08-28 11:53:50.695070:  
2025-08-28 11:53:50.700762: Epoch 822 
2025-08-28 11:53:50.710806: Current learning rate: 0.00212 
2025-08-28 11:54:07.350387: train_loss -0.3943 
2025-08-28 11:54:07.358901: val_loss -0.4178 
2025-08-28 11:54:07.362862: Pseudo dice [np.float32(0.6229)] 
2025-08-28 11:54:07.372117: Epoch time: 16.66 s 
2025-08-28 11:54:08.098720:  
2025-08-28 11:54:08.106997: Epoch 823 
2025-08-28 11:54:08.113603: Current learning rate: 0.0021 
2025-08-28 11:54:24.934573: train_loss -0.3983 
2025-08-28 11:54:24.942915: val_loss -0.3982 
2025-08-28 11:54:24.951254: Pseudo dice [np.float32(0.6848)] 
2025-08-28 11:54:24.957649: Epoch time: 16.84 s 
2025-08-28 11:54:25.667532:  
2025-08-28 11:54:25.676998: Epoch 824 
2025-08-28 11:54:25.684646: Current learning rate: 0.00209 
2025-08-28 11:54:42.347831: train_loss -0.3909 
2025-08-28 11:54:42.356096: val_loss -0.441 
2025-08-28 11:54:42.364953: Pseudo dice [np.float32(0.699)] 
2025-08-28 11:54:42.369902: Epoch time: 16.68 s 
2025-08-28 11:54:43.086893:  
2025-08-28 11:54:43.097450: Epoch 825 
2025-08-28 11:54:43.104825: Current learning rate: 0.00208 
2025-08-28 11:54:59.632169: train_loss -0.3741 
2025-08-28 11:54:59.640107: val_loss -0.4519 
2025-08-28 11:54:59.644240: Pseudo dice [np.float32(0.7137)] 
2025-08-28 11:54:59.653423: Epoch time: 16.55 s 
2025-08-28 11:55:00.507443:  
2025-08-28 11:55:00.515879: Epoch 826 
2025-08-28 11:55:00.521139: Current learning rate: 0.00207 
2025-08-28 11:55:17.407854: train_loss -0.3916 
2025-08-28 11:55:17.420072: val_loss -0.4214 
2025-08-28 11:55:17.424565: Pseudo dice [np.float32(0.7396)] 
2025-08-28 11:55:17.431783: Epoch time: 16.9 s 
2025-08-28 11:55:18.163340:  
2025-08-28 11:55:18.170928: Epoch 827 
2025-08-28 11:55:18.177248: Current learning rate: 0.00206 
2025-08-28 11:55:34.825234: train_loss -0.4009 
2025-08-28 11:55:34.833559: val_loss -0.4337 
2025-08-28 11:55:34.837686: Pseudo dice [np.float32(0.7104)] 
2025-08-28 11:55:34.843890: Epoch time: 16.67 s 
2025-08-28 11:55:35.551442:  
2025-08-28 11:55:35.560282: Epoch 828 
2025-08-28 11:55:35.563748: Current learning rate: 0.00205 
2025-08-28 11:55:52.355205: train_loss -0.382 
2025-08-28 11:55:52.363874: val_loss -0.4149 
2025-08-28 11:55:52.371924: Pseudo dice [np.float32(0.7356)] 
2025-08-28 11:55:52.377393: Epoch time: 16.81 s 
2025-08-28 11:55:53.090357:  
2025-08-28 11:55:53.100429: Epoch 829 
2025-08-28 11:55:53.109457: Current learning rate: 0.00204 
2025-08-28 11:56:10.147977: train_loss -0.3661 
2025-08-28 11:56:10.159003: val_loss -0.4188 
2025-08-28 11:56:10.165232: Pseudo dice [np.float32(0.6984)] 
2025-08-28 11:56:10.170920: Epoch time: 17.06 s 
2025-08-28 11:56:10.896626:  
2025-08-28 11:56:10.907602: Epoch 830 
2025-08-28 11:56:10.915357: Current learning rate: 0.00203 
2025-08-28 11:56:27.769724: train_loss -0.3697 
2025-08-28 11:56:27.778323: val_loss -0.4617 
2025-08-28 11:56:27.786418: Pseudo dice [np.float32(0.7313)] 
2025-08-28 11:56:27.792633: Epoch time: 16.88 s 
2025-08-28 11:56:28.488136:  
2025-08-28 11:56:28.495628: Epoch 831 
2025-08-28 11:56:28.505836: Current learning rate: 0.00202 
2025-08-28 11:56:45.321184: train_loss -0.4194 
2025-08-28 11:56:45.328938: val_loss -0.425 
2025-08-28 11:56:45.337267: Pseudo dice [np.float32(0.741)] 
2025-08-28 11:56:45.342764: Epoch time: 16.83 s 
2025-08-28 11:56:45.349727: Yayy! New best EMA pseudo Dice: 0.7035999894142151 
2025-08-28 11:56:46.353617:  
2025-08-28 11:56:46.363176: Epoch 832 
2025-08-28 11:56:46.367857: Current learning rate: 0.00201 
2025-08-28 11:57:03.435178: train_loss -0.4069 
2025-08-28 11:57:03.442879: val_loss -0.4315 
2025-08-28 11:57:03.451527: Pseudo dice [np.float32(0.7158)] 
2025-08-28 11:57:03.457530: Epoch time: 17.08 s 
2025-08-28 11:57:03.464155: Yayy! New best EMA pseudo Dice: 0.7049000263214111 
2025-08-28 11:57:04.528116:  
2025-08-28 11:57:04.535493: Epoch 833 
2025-08-28 11:57:04.540082: Current learning rate: 0.002 
2025-08-28 11:57:20.906144: train_loss -0.3955 
2025-08-28 11:57:20.914450: val_loss -0.4803 
2025-08-28 11:57:20.922813: Pseudo dice [np.float32(0.7574)] 
2025-08-28 11:57:20.928276: Epoch time: 16.38 s 
2025-08-28 11:57:20.932059: Yayy! New best EMA pseudo Dice: 0.710099995136261 
2025-08-28 11:57:21.834103:  
2025-08-28 11:57:21.842427: Epoch 834 
2025-08-28 11:57:21.849731: Current learning rate: 0.00199 
2025-08-28 11:57:38.519949: train_loss -0.3853 
2025-08-28 11:57:38.527889: val_loss -0.418 
2025-08-28 11:57:38.532362: Pseudo dice [np.float32(0.7419)] 
2025-08-28 11:57:38.540786: Epoch time: 16.69 s 
2025-08-28 11:57:38.547084: Yayy! New best EMA pseudo Dice: 0.7132999897003174 
2025-08-28 11:57:39.443355:  
2025-08-28 11:57:39.451641: Epoch 835 
2025-08-28 11:57:39.456792: Current learning rate: 0.00198 
2025-08-28 11:57:55.241468: train_loss -0.3908 
2025-08-28 11:57:55.249033: val_loss -0.4472 
2025-08-28 11:57:55.257084: Pseudo dice [np.float32(0.734)] 
2025-08-28 11:57:55.262438: Epoch time: 15.8 s 
2025-08-28 11:57:55.269560: Yayy! New best EMA pseudo Dice: 0.715399980545044 
2025-08-28 11:57:56.174645:  
2025-08-28 11:57:56.182738: Epoch 836 
2025-08-28 11:57:56.187718: Current learning rate: 0.00196 
2025-08-28 11:58:12.970805: train_loss -0.3784 
2025-08-28 11:58:12.983421: val_loss -0.3815 
2025-08-28 11:58:12.987292: Pseudo dice [np.float32(0.6964)] 
2025-08-28 11:58:12.994552: Epoch time: 16.8 s 
2025-08-28 11:58:13.701439:  
2025-08-28 11:58:13.709141: Epoch 837 
2025-08-28 11:58:13.718063: Current learning rate: 0.00195 
2025-08-28 11:58:30.183809: train_loss -0.3861 
2025-08-28 11:58:30.191974: val_loss -0.4695 
2025-08-28 11:58:30.196148: Pseudo dice [np.float32(0.7369)] 
2025-08-28 11:58:30.204114: Epoch time: 16.48 s 
2025-08-28 11:58:30.210984: Yayy! New best EMA pseudo Dice: 0.7157999873161316 
2025-08-28 11:58:31.287755:  
2025-08-28 11:58:31.296112: Epoch 838 
2025-08-28 11:58:31.302020: Current learning rate: 0.00194 
2025-08-28 11:58:47.930494: train_loss -0.4031 
2025-08-28 11:58:47.939191: val_loss -0.4573 
2025-08-28 11:58:47.943285: Pseudo dice [np.float32(0.7574)] 
2025-08-28 11:58:47.950422: Epoch time: 16.64 s 
2025-08-28 11:58:47.957063: Yayy! New best EMA pseudo Dice: 0.7200000286102295 
2025-08-28 11:58:48.877251:  
2025-08-28 11:58:48.883550: Epoch 839 
2025-08-28 11:58:48.890162: Current learning rate: 0.00193 
2025-08-28 11:59:05.218562: train_loss -0.4059 
2025-08-28 11:59:05.226945: val_loss -0.3993 
2025-08-28 11:59:05.231138: Pseudo dice [np.float32(0.6498)] 
2025-08-28 11:59:05.239693: Epoch time: 16.34 s 
2025-08-28 11:59:05.950501:  
2025-08-28 11:59:05.960060: Epoch 840 
2025-08-28 11:59:05.965502: Current learning rate: 0.00192 
2025-08-28 11:59:22.331807: train_loss -0.3878 
2025-08-28 11:59:22.344069: val_loss -0.4386 
2025-08-28 11:59:22.348446: Pseudo dice [np.float32(0.7099)] 
2025-08-28 11:59:22.356532: Epoch time: 16.38 s 
2025-08-28 11:59:23.078065:  
2025-08-28 11:59:23.085392: Epoch 841 
2025-08-28 11:59:23.090501: Current learning rate: 0.00191 
2025-08-28 11:59:39.035713: train_loss -0.4027 
2025-08-28 11:59:39.044046: val_loss -0.4231 
2025-08-28 11:59:39.052785: Pseudo dice [np.float32(0.7047)] 
2025-08-28 11:59:39.058749: Epoch time: 15.96 s 
2025-08-28 11:59:39.786439:  
2025-08-28 11:59:39.791164: Epoch 842 
2025-08-28 11:59:39.801773: Current learning rate: 0.0019 
2025-08-28 11:59:55.673162: train_loss -0.3914 
2025-08-28 11:59:55.681519: val_loss -0.3868 
2025-08-28 11:59:55.690406: Pseudo dice [np.float32(0.6496)] 
2025-08-28 11:59:55.696197: Epoch time: 15.89 s 
2025-08-28 11:59:56.415470:  
2025-08-28 11:59:56.424936: Epoch 843 
2025-08-28 11:59:56.431093: Current learning rate: 0.00189 
2025-08-28 12:00:12.560893: train_loss -0.4131 
2025-08-28 12:00:12.573385: val_loss -0.4941 
2025-08-28 12:00:12.577543: Pseudo dice [np.float32(0.7605)] 
2025-08-28 12:00:12.585001: Epoch time: 16.15 s 
2025-08-28 12:00:13.279259:  
2025-08-28 12:00:13.287602: Epoch 844 
2025-08-28 12:00:13.293801: Current learning rate: 0.00188 
2025-08-28 12:00:29.411268: train_loss -0.3794 
2025-08-28 12:00:29.419356: val_loss -0.4713 
2025-08-28 12:00:29.423740: Pseudo dice [np.float32(0.7029)] 
2025-08-28 12:00:29.431902: Epoch time: 16.13 s 
2025-08-28 12:00:30.303842:  
2025-08-28 12:00:30.310766: Epoch 845 
2025-08-28 12:00:30.316276: Current learning rate: 0.00187 
2025-08-28 12:00:46.542533: train_loss -0.3731 
2025-08-28 12:00:46.553158: val_loss -0.3967 
2025-08-28 12:00:46.557320: Pseudo dice [np.float32(0.7233)] 
2025-08-28 12:00:46.564598: Epoch time: 16.24 s 
2025-08-28 12:00:47.277063:  
2025-08-28 12:00:47.283637: Epoch 846 
2025-08-28 12:00:47.292395: Current learning rate: 0.00186 
2025-08-28 12:01:03.407693: train_loss -0.3993 
2025-08-28 12:01:03.420009: val_loss -0.4005 
2025-08-28 12:01:03.424171: Pseudo dice [np.float32(0.698)] 
2025-08-28 12:01:03.433312: Epoch time: 16.13 s 
2025-08-28 12:01:04.145713:  
2025-08-28 12:01:04.153843: Epoch 847 
2025-08-28 12:01:04.160181: Current learning rate: 0.00185 
2025-08-28 12:01:20.574657: train_loss -0.3721 
2025-08-28 12:01:20.583230: val_loss -0.4668 
2025-08-28 12:01:20.587028: Pseudo dice [np.float32(0.7654)] 
2025-08-28 12:01:20.595351: Epoch time: 16.43 s 
2025-08-28 12:01:21.313877:  
2025-08-28 12:01:21.324022: Epoch 848 
2025-08-28 12:01:21.330559: Current learning rate: 0.00184 
2025-08-28 12:01:37.574961: train_loss -0.3724 
2025-08-28 12:01:37.583250: val_loss -0.4543 
2025-08-28 12:01:37.591601: Pseudo dice [np.float32(0.6995)] 
2025-08-28 12:01:37.597195: Epoch time: 16.26 s 
2025-08-28 12:01:38.313248:  
2025-08-28 12:01:38.322645: Epoch 849 
2025-08-28 12:01:38.328714: Current learning rate: 0.00182 
2025-08-28 12:01:54.525065: train_loss -0.4181 
2025-08-28 12:01:54.533541: val_loss -0.4274 
2025-08-28 12:01:54.537702: Pseudo dice [np.float32(0.7462)] 
2025-08-28 12:01:54.543460: Epoch time: 16.21 s 
2025-08-28 12:01:55.472944:  
2025-08-28 12:01:55.482353: Epoch 850 
2025-08-28 12:01:55.488436: Current learning rate: 0.00181 
2025-08-28 12:02:11.417291: train_loss -0.3799 
2025-08-28 12:02:11.425380: val_loss -0.431 
2025-08-28 12:02:11.433743: Pseudo dice [np.float32(0.6891)] 
2025-08-28 12:02:11.439815: Epoch time: 15.95 s 
2025-08-28 12:02:12.297310:  
2025-08-28 12:02:12.307878: Epoch 851 
2025-08-28 12:02:12.316030: Current learning rate: 0.0018 
2025-08-28 12:02:28.112839: train_loss -0.3911 
2025-08-28 12:02:28.121235: val_loss -0.4032 
2025-08-28 12:02:28.129562: Pseudo dice [np.float32(0.7095)] 
2025-08-28 12:02:28.135088: Epoch time: 15.82 s 
2025-08-28 12:02:28.851468:  
2025-08-28 12:02:28.859404: Epoch 852 
2025-08-28 12:02:28.863985: Current learning rate: 0.00179 
2025-08-28 12:02:45.122025: train_loss -0.3793 
2025-08-28 12:02:45.130178: val_loss -0.4142 
2025-08-28 12:02:45.138247: Pseudo dice [np.float32(0.7009)] 
2025-08-28 12:02:45.145607: Epoch time: 16.27 s 
2025-08-28 12:02:45.837838:  
2025-08-28 12:02:45.845172: Epoch 853 
2025-08-28 12:02:45.850331: Current learning rate: 0.00178 
2025-08-28 12:03:01.867398: train_loss -0.4132 
2025-08-28 12:03:01.876037: val_loss -0.4084 
2025-08-28 12:03:01.884167: Pseudo dice [np.float32(0.7729)] 
2025-08-28 12:03:01.890395: Epoch time: 16.03 s 
2025-08-28 12:03:02.586876:  
2025-08-28 12:03:02.595256: Epoch 854 
2025-08-28 12:03:02.600413: Current learning rate: 0.00177 
2025-08-28 12:03:19.105458: train_loss -0.4214 
2025-08-28 12:03:19.118353: val_loss -0.4809 
2025-08-28 12:03:19.122167: Pseudo dice [np.float32(0.7255)] 
2025-08-28 12:03:19.129492: Epoch time: 16.52 s 
2025-08-28 12:03:19.854159:  
2025-08-28 12:03:19.861474: Epoch 855 
2025-08-28 12:03:19.866634: Current learning rate: 0.00176 
2025-08-28 12:03:36.018520: train_loss -0.4182 
2025-08-28 12:03:36.026543: val_loss -0.3881 
2025-08-28 12:03:36.030999: Pseudo dice [np.float32(0.6982)] 
2025-08-28 12:03:36.039800: Epoch time: 16.17 s 
2025-08-28 12:03:36.772974:  
2025-08-28 12:03:36.782608: Epoch 856 
2025-08-28 12:03:36.787642: Current learning rate: 0.00175 
2025-08-28 12:03:53.243753: train_loss -0.384 
2025-08-28 12:03:53.255190: val_loss -0.4301 
2025-08-28 12:03:53.260420: Pseudo dice [np.float32(0.7131)] 
2025-08-28 12:03:53.266898: Epoch time: 16.47 s 
2025-08-28 12:03:54.002639:  
2025-08-28 12:03:54.011075: Epoch 857 
2025-08-28 12:03:54.017349: Current learning rate: 0.00174 
2025-08-28 12:04:10.535958: train_loss -0.405 
2025-08-28 12:04:10.548500: val_loss -0.4016 
2025-08-28 12:04:10.556566: Pseudo dice [np.float32(0.6824)] 
2025-08-28 12:04:10.562254: Epoch time: 16.54 s 
2025-08-28 12:04:11.412964:  
2025-08-28 12:04:11.422309: Epoch 858 
2025-08-28 12:04:11.429617: Current learning rate: 0.00173 
2025-08-28 12:04:27.940932: train_loss -0.4019 
2025-08-28 12:04:27.949211: val_loss -0.4183 
2025-08-28 12:04:27.957576: Pseudo dice [np.float32(0.6804)] 
2025-08-28 12:04:27.962930: Epoch time: 16.53 s 
2025-08-28 12:04:28.668605:  
2025-08-28 12:04:28.677019: Epoch 859 
2025-08-28 12:04:28.683107: Current learning rate: 0.00172 
2025-08-28 12:04:45.266158: train_loss -0.4204 
2025-08-28 12:04:45.274915: val_loss -0.4404 
2025-08-28 12:04:45.279218: Pseudo dice [np.float32(0.7234)] 
2025-08-28 12:04:45.286301: Epoch time: 16.6 s 
2025-08-28 12:04:46.004560:  
2025-08-28 12:04:46.014437: Epoch 860 
2025-08-28 12:04:46.024088: Current learning rate: 0.0017 
2025-08-28 12:05:02.738119: train_loss -0.4015 
2025-08-28 12:05:02.746467: val_loss -0.3922 
2025-08-28 12:05:02.754823: Pseudo dice [np.float32(0.6838)] 
2025-08-28 12:05:02.761083: Epoch time: 16.74 s 
2025-08-28 12:05:03.457517:  
2025-08-28 12:05:03.466940: Epoch 861 
2025-08-28 12:05:03.472119: Current learning rate: 0.00169 
2025-08-28 12:05:20.043027: train_loss -0.4304 
2025-08-28 12:05:20.051274: val_loss -0.4352 
2025-08-28 12:05:20.055416: Pseudo dice [np.float32(0.6663)] 
2025-08-28 12:05:20.061950: Epoch time: 16.59 s 
2025-08-28 12:05:20.764396:  
2025-08-28 12:05:20.774809: Epoch 862 
2025-08-28 12:05:20.780070: Current learning rate: 0.00168 
2025-08-28 12:05:37.585409: train_loss -0.3985 
2025-08-28 12:05:37.593776: val_loss -0.4417 
2025-08-28 12:05:37.602113: Pseudo dice [np.float32(0.672)] 
2025-08-28 12:05:37.608577: Epoch time: 16.82 s 
2025-08-28 12:05:38.314230:  
2025-08-28 12:05:38.323689: Epoch 863 
2025-08-28 12:05:38.331215: Current learning rate: 0.00167 
2025-08-28 12:05:55.174201: train_loss -0.4062 
2025-08-28 12:05:55.182208: val_loss -0.4319 
2025-08-28 12:05:55.190518: Pseudo dice [np.float32(0.734)] 
2025-08-28 12:05:55.195957: Epoch time: 16.86 s 
2025-08-28 12:05:55.910736:  
2025-08-28 12:05:55.916595: Epoch 864 
2025-08-28 12:05:55.924888: Current learning rate: 0.00166 
2025-08-28 12:06:12.733000: train_loss -0.3994 
2025-08-28 12:06:12.745873: val_loss -0.4143 
2025-08-28 12:06:12.749994: Pseudo dice [np.float32(0.6422)] 
2025-08-28 12:06:12.757109: Epoch time: 16.82 s 
2025-08-28 12:06:13.632210:  
2025-08-28 12:06:13.638418: Epoch 865 
2025-08-28 12:06:13.648671: Current learning rate: 0.00165 
2025-08-28 12:06:30.288029: train_loss -0.4344 
2025-08-28 12:06:30.296436: val_loss -0.4438 
2025-08-28 12:06:30.304756: Pseudo dice [np.float32(0.7396)] 
2025-08-28 12:06:30.309619: Epoch time: 16.66 s 
2025-08-28 12:06:31.029406:  
2025-08-28 12:06:31.037506: Epoch 866 
2025-08-28 12:06:31.043993: Current learning rate: 0.00164 
2025-08-28 12:06:47.555285: train_loss -0.3963 
2025-08-28 12:06:47.563958: val_loss -0.4457 
2025-08-28 12:06:47.567811: Pseudo dice [np.float32(0.6976)] 
2025-08-28 12:06:47.574042: Epoch time: 16.53 s 
2025-08-28 12:06:48.285174:  
2025-08-28 12:06:48.293698: Epoch 867 
2025-08-28 12:06:48.299732: Current learning rate: 0.00163 
2025-08-28 12:07:05.093702: train_loss -0.3963 
2025-08-28 12:07:05.102029: val_loss -0.4381 
2025-08-28 12:07:05.110354: Pseudo dice [np.float32(0.7478)] 
2025-08-28 12:07:05.115796: Epoch time: 16.81 s 
2025-08-28 12:07:05.822177:  
2025-08-28 12:07:05.829590: Epoch 868 
2025-08-28 12:07:05.837636: Current learning rate: 0.00162 
2025-08-28 12:07:22.135687: train_loss -0.4102 
2025-08-28 12:07:22.143993: val_loss -0.4514 
2025-08-28 12:07:22.152344: Pseudo dice [np.float32(0.7738)] 
2025-08-28 12:07:22.158756: Epoch time: 16.32 s 
2025-08-28 12:07:22.870774:  
2025-08-28 12:07:22.879280: Epoch 869 
2025-08-28 12:07:22.885283: Current learning rate: 0.00161 
2025-08-28 12:07:39.774125: train_loss -0.4233 
2025-08-28 12:07:39.782434: val_loss -0.427 
2025-08-28 12:07:39.786538: Pseudo dice [np.float32(0.6515)] 
2025-08-28 12:07:39.793807: Epoch time: 16.91 s 
2025-08-28 12:07:40.560280:  
2025-08-28 12:07:40.568619: Epoch 870 
2025-08-28 12:07:40.573819: Current learning rate: 0.00159 
2025-08-28 12:07:57.387561: train_loss -0.3699 
2025-08-28 12:07:57.400261: val_loss -0.4248 
2025-08-28 12:07:57.404212: Pseudo dice [np.float32(0.6696)] 
2025-08-28 12:07:57.410598: Epoch time: 16.83 s 
2025-08-28 12:07:58.124679:  
2025-08-28 12:07:58.129971: Epoch 871 
2025-08-28 12:07:58.139306: Current learning rate: 0.00158 
2025-08-28 12:08:15.017622: train_loss -0.4214 
2025-08-28 12:08:15.030486: val_loss -0.4934 
2025-08-28 12:08:15.034577: Pseudo dice [np.float32(0.7802)] 
2025-08-28 12:08:15.043150: Epoch time: 16.89 s 
2025-08-28 12:08:15.886213:  
2025-08-28 12:08:15.894564: Epoch 872 
2025-08-28 12:08:15.900695: Current learning rate: 0.00157 
2025-08-28 12:08:32.981792: train_loss -0.4276 
2025-08-28 12:08:32.989761: val_loss -0.4497 
2025-08-28 12:08:32.993897: Pseudo dice [np.float32(0.7561)] 
2025-08-28 12:08:33.003115: Epoch time: 17.1 s 
2025-08-28 12:08:33.719509:  
2025-08-28 12:08:33.729522: Epoch 873 
2025-08-28 12:08:33.738441: Current learning rate: 0.00156 
2025-08-28 12:08:50.511473: train_loss -0.4021 
2025-08-28 12:08:50.519784: val_loss -0.4573 
2025-08-28 12:08:50.528771: Pseudo dice [np.float32(0.7369)] 
2025-08-28 12:08:50.534484: Epoch time: 16.79 s 
2025-08-28 12:08:51.255800:  
2025-08-28 12:08:51.265183: Epoch 874 
2025-08-28 12:08:51.271624: Current learning rate: 0.00155 
2025-08-28 12:09:07.803657: train_loss -0.3988 
2025-08-28 12:09:07.814399: val_loss -0.4002 
2025-08-28 12:09:07.820703: Pseudo dice [np.float32(0.6998)] 
2025-08-28 12:09:07.825501: Epoch time: 16.55 s 
2025-08-28 12:09:08.538766:  
2025-08-28 12:09:08.548530: Epoch 875 
2025-08-28 12:09:08.554405: Current learning rate: 0.00154 
2025-08-28 12:09:25.300344: train_loss -0.4018 
2025-08-28 12:09:25.308661: val_loss -0.3853 
2025-08-28 12:09:25.316986: Pseudo dice [np.float32(0.6442)] 
2025-08-28 12:09:25.322491: Epoch time: 16.76 s 
2025-08-28 12:09:26.028052:  
2025-08-28 12:09:26.037493: Epoch 876 
2025-08-28 12:09:26.043853: Current learning rate: 0.00153 
2025-08-28 12:09:42.872523: train_loss -0.3857 
2025-08-28 12:09:42.880665: val_loss -0.4577 
2025-08-28 12:09:42.888717: Pseudo dice [np.float32(0.707)] 
2025-08-28 12:09:42.894978: Epoch time: 16.85 s 
2025-08-28 12:09:43.591491:  
2025-08-28 12:09:43.599764: Epoch 877 
2025-08-28 12:09:43.606005: Current learning rate: 0.00152 
2025-08-28 12:10:00.256074: train_loss -0.3886 
2025-08-28 12:10:00.264385: val_loss -0.4467 
2025-08-28 12:10:00.272749: Pseudo dice [np.float32(0.713)] 
2025-08-28 12:10:00.278045: Epoch time: 16.67 s 
2025-08-28 12:10:01.006652:  
2025-08-28 12:10:01.015092: Epoch 878 
2025-08-28 12:10:01.021346: Current learning rate: 0.00151 
2025-08-28 12:10:17.786113: train_loss -0.3886 
2025-08-28 12:10:17.794823: val_loss -0.4544 
2025-08-28 12:10:17.802763: Pseudo dice [np.float32(0.7037)] 
2025-08-28 12:10:17.809313: Epoch time: 16.78 s 
2025-08-28 12:10:18.675428:  
2025-08-28 12:10:18.682679: Epoch 879 
2025-08-28 12:10:18.689045: Current learning rate: 0.00149 
2025-08-28 12:10:35.215943: train_loss -0.4 
2025-08-28 12:10:35.224299: val_loss -0.423 
2025-08-28 12:10:35.228468: Pseudo dice [np.float32(0.7667)] 
2025-08-28 12:10:35.238049: Epoch time: 16.54 s 
2025-08-28 12:10:35.957016:  
2025-08-28 12:10:35.965586: Epoch 880 
2025-08-28 12:10:35.972991: Current learning rate: 0.00148 
2025-08-28 12:10:52.679458: train_loss -0.4134 
2025-08-28 12:10:52.687592: val_loss -0.4687 
2025-08-28 12:10:52.696616: Pseudo dice [np.float32(0.7881)] 
2025-08-28 12:10:52.701633: Epoch time: 16.72 s 
2025-08-28 12:10:52.709290: Yayy! New best EMA pseudo Dice: 0.7217000126838684 
2025-08-28 12:10:53.614570:  
2025-08-28 12:10:53.623867: Epoch 881 
2025-08-28 12:10:53.629099: Current learning rate: 0.00147 
2025-08-28 12:11:10.371880: train_loss -0.3944 
2025-08-28 12:11:10.380247: val_loss -0.4448 
2025-08-28 12:11:10.384681: Pseudo dice [np.float32(0.6919)] 
2025-08-28 12:11:10.393642: Epoch time: 16.76 s 
2025-08-28 12:11:11.105234:  
2025-08-28 12:11:11.114239: Epoch 882 
2025-08-28 12:11:11.119584: Current learning rate: 0.00146 
2025-08-28 12:11:27.826691: train_loss -0.402 
2025-08-28 12:11:27.835509: val_loss -0.442 
2025-08-28 12:11:27.844377: Pseudo dice [np.float32(0.7131)] 
2025-08-28 12:11:27.850063: Epoch time: 16.72 s 
2025-08-28 12:11:28.543144:  
2025-08-28 12:11:28.550487: Epoch 883 
2025-08-28 12:11:28.555576: Current learning rate: 0.00145 
2025-08-28 12:11:45.457210: train_loss -0.3819 
2025-08-28 12:11:45.465810: val_loss -0.4296 
2025-08-28 12:11:45.469457: Pseudo dice [np.float32(0.6771)] 
2025-08-28 12:11:45.478667: Epoch time: 16.92 s 
2025-08-28 12:11:46.206750:  
2025-08-28 12:11:46.213875: Epoch 884 
2025-08-28 12:11:46.220344: Current learning rate: 0.00144 
2025-08-28 12:12:03.366483: train_loss -0.4201 
2025-08-28 12:12:03.375148: val_loss -0.4744 
2025-08-28 12:12:03.383168: Pseudo dice [np.float32(0.7191)] 
2025-08-28 12:12:03.390620: Epoch time: 17.16 s 
2025-08-28 12:12:04.072416:  
2025-08-28 12:12:04.080719: Epoch 885 
2025-08-28 12:12:04.088022: Current learning rate: 0.00143 
2025-08-28 12:12:20.859499: train_loss -0.405 
2025-08-28 12:12:20.867286: val_loss -0.4693 
2025-08-28 12:12:20.875998: Pseudo dice [np.float32(0.7454)] 
2025-08-28 12:12:20.880589: Epoch time: 16.79 s 
2025-08-28 12:12:21.718063:  
2025-08-28 12:12:21.725319: Epoch 886 
2025-08-28 12:12:21.731656: Current learning rate: 0.00142 
2025-08-28 12:12:38.680913: train_loss -0.384 
2025-08-28 12:12:38.689273: val_loss -0.4867 
2025-08-28 12:12:38.697582: Pseudo dice [np.float32(0.734)] 
2025-08-28 12:12:38.703279: Epoch time: 16.96 s 
2025-08-28 12:12:39.411868:  
2025-08-28 12:12:39.419906: Epoch 887 
2025-08-28 12:12:39.425590: Current learning rate: 0.00141 
2025-08-28 12:12:55.835538: train_loss -0.4047 
2025-08-28 12:12:55.844201: val_loss -0.3734 
2025-08-28 12:12:55.852262: Pseudo dice [np.float32(0.6833)] 
2025-08-28 12:12:55.859645: Epoch time: 16.43 s 
2025-08-28 12:12:56.561337:  
2025-08-28 12:12:56.570682: Epoch 888 
2025-08-28 12:12:56.574751: Current learning rate: 0.00139 
2025-08-28 12:13:13.320007: train_loss -0.401 
2025-08-28 12:13:13.331186: val_loss -0.4113 
2025-08-28 12:13:13.336376: Pseudo dice [np.float32(0.6317)] 
2025-08-28 12:13:13.343561: Epoch time: 16.76 s 
2025-08-28 12:13:14.036940:  
2025-08-28 12:13:14.045317: Epoch 889 
2025-08-28 12:13:14.049419: Current learning rate: 0.00138 
2025-08-28 12:13:30.549419: train_loss -0.4115 
2025-08-28 12:13:30.561876: val_loss -0.4038 
2025-08-28 12:13:30.565967: Pseudo dice [np.float32(0.7029)] 
2025-08-28 12:13:30.573274: Epoch time: 16.51 s 
2025-08-28 12:13:31.259523:  
2025-08-28 12:13:31.267858: Epoch 890 
2025-08-28 12:13:31.273039: Current learning rate: 0.00137 
2025-08-28 12:13:47.950084: train_loss -0.3935 
2025-08-28 12:13:47.958421: val_loss -0.4562 
2025-08-28 12:13:47.962635: Pseudo dice [np.float32(0.7504)] 
2025-08-28 12:13:47.971786: Epoch time: 16.69 s 
2025-08-28 12:13:48.699735:  
2025-08-28 12:13:48.708093: Epoch 891 
2025-08-28 12:13:48.719611: Current learning rate: 0.00136 
2025-08-28 12:14:05.375813: train_loss -0.4029 
2025-08-28 12:14:05.384438: val_loss -0.4509 
2025-08-28 12:14:05.391607: Pseudo dice [np.float32(0.7278)] 
2025-08-28 12:14:05.396739: Epoch time: 16.68 s 
2025-08-28 12:14:06.202659:  
2025-08-28 12:14:06.211973: Epoch 892 
2025-08-28 12:14:06.219460: Current learning rate: 0.00135 
2025-08-28 12:14:23.001763: train_loss -0.4125 
2025-08-28 12:14:23.010087: val_loss -0.4221 
2025-08-28 12:14:23.018435: Pseudo dice [np.float32(0.729)] 
2025-08-28 12:14:23.027035: Epoch time: 16.8 s 
2025-08-28 12:14:23.886971:  
2025-08-28 12:14:23.895322: Epoch 893 
2025-08-28 12:14:23.902441: Current learning rate: 0.00134 
2025-08-28 12:14:40.540073: train_loss -0.4071 
2025-08-28 12:14:40.548435: val_loss -0.4299 
2025-08-28 12:14:40.552634: Pseudo dice [np.float32(0.6881)] 
2025-08-28 12:14:40.558804: Epoch time: 16.65 s 
2025-08-28 12:14:41.267560:  
2025-08-28 12:14:41.275213: Epoch 894 
2025-08-28 12:14:41.281317: Current learning rate: 0.00133 
2025-08-28 12:14:57.965867: train_loss -0.4156 
2025-08-28 12:14:57.974162: val_loss -0.4203 
2025-08-28 12:14:57.978337: Pseudo dice [np.float32(0.6963)] 
2025-08-28 12:14:57.986661: Epoch time: 16.7 s 
2025-08-28 12:14:58.699800:  
2025-08-28 12:14:58.707062: Epoch 895 
2025-08-28 12:14:58.712285: Current learning rate: 0.00132 
2025-08-28 12:15:15.704607: train_loss -0.4183 
2025-08-28 12:15:15.717215: val_loss -0.4564 
2025-08-28 12:15:15.725230: Pseudo dice [np.float32(0.7414)] 
2025-08-28 12:15:15.731704: Epoch time: 17.01 s 
2025-08-28 12:15:16.422856:  
2025-08-28 12:15:16.431169: Epoch 896 
2025-08-28 12:15:16.439546: Current learning rate: 0.0013 
2025-08-28 12:15:33.017517: train_loss -0.4063 
2025-08-28 12:15:33.026147: val_loss -0.452 
2025-08-28 12:15:33.034521: Pseudo dice [np.float32(0.7239)] 
2025-08-28 12:15:33.039118: Epoch time: 16.6 s 
2025-08-28 12:15:33.742052:  
2025-08-28 12:15:33.750485: Epoch 897 
2025-08-28 12:15:33.755597: Current learning rate: 0.00129 
2025-08-28 12:15:50.548212: train_loss -0.4311 
2025-08-28 12:15:50.556155: val_loss -0.4669 
2025-08-28 12:15:50.560250: Pseudo dice [np.float32(0.6944)] 
2025-08-28 12:15:50.569128: Epoch time: 16.81 s 
2025-08-28 12:15:51.274355:  
2025-08-28 12:15:51.283504: Epoch 898 
2025-08-28 12:15:51.288884: Current learning rate: 0.00128 
2025-08-28 12:16:07.743853: train_loss -0.4047 
2025-08-28 12:16:07.756368: val_loss -0.496 
2025-08-28 12:16:07.760529: Pseudo dice [np.float32(0.7965)] 
2025-08-28 12:16:07.769754: Epoch time: 16.47 s 
2025-08-28 12:16:08.470672:  
2025-08-28 12:16:08.480943: Epoch 899 
2025-08-28 12:16:08.488031: Current learning rate: 0.00127 
2025-08-28 12:16:25.278062: train_loss -0.4125 
2025-08-28 12:16:25.286356: val_loss -0.4524 
2025-08-28 12:16:25.290853: Pseudo dice [np.float32(0.7404)] 
2025-08-28 12:16:25.299698: Epoch time: 16.81 s 
2025-08-28 12:16:25.661721: Yayy! New best EMA pseudo Dice: 0.7228000164031982 
2025-08-28 12:16:26.584251:  
2025-08-28 12:16:26.592911: Epoch 900 
2025-08-28 12:16:26.601264: Current learning rate: 0.00126 
2025-08-28 12:16:43.033266: train_loss -0.4037 
2025-08-28 12:16:43.041891: val_loss -0.4972 
2025-08-28 12:16:43.046023: Pseudo dice [np.float32(0.7708)] 
2025-08-28 12:16:43.054997: Epoch time: 16.45 s 
2025-08-28 12:16:43.059223: Yayy! New best EMA pseudo Dice: 0.7275999784469604 
2025-08-28 12:16:43.949693:  
2025-08-28 12:16:43.958033: Epoch 901 
2025-08-28 12:16:43.963208: Current learning rate: 0.00125 
2025-08-28 12:17:00.859628: train_loss -0.407 
2025-08-28 12:17:00.872200: val_loss -0.4312 
2025-08-28 12:17:00.876059: Pseudo dice [np.float32(0.7463)] 
2025-08-28 12:17:00.884498: Epoch time: 16.91 s 
2025-08-28 12:17:00.890082: Yayy! New best EMA pseudo Dice: 0.7294999957084656 
2025-08-28 12:17:01.803997:  
2025-08-28 12:17:01.812455: Epoch 902 
2025-08-28 12:17:01.820730: Current learning rate: 0.00124 
2025-08-28 12:17:17.859721: train_loss -0.4228 
2025-08-28 12:17:17.872597: val_loss -0.4457 
2025-08-28 12:17:17.876380: Pseudo dice [np.float32(0.7513)] 
2025-08-28 12:17:17.884583: Epoch time: 16.06 s 
2025-08-28 12:17:17.890398: Yayy! New best EMA pseudo Dice: 0.7317000031471252 
2025-08-28 12:17:18.774179:  
2025-08-28 12:17:18.782521: Epoch 903 
2025-08-28 12:17:18.788698: Current learning rate: 0.00122 
2025-08-28 12:17:35.631628: train_loss -0.4187 
2025-08-28 12:17:35.640140: val_loss -0.4613 
2025-08-28 12:17:35.644463: Pseudo dice [np.float32(0.7239)] 
2025-08-28 12:17:35.652669: Epoch time: 16.86 s 
2025-08-28 12:17:36.361326:  
2025-08-28 12:17:36.369681: Epoch 904 
2025-08-28 12:17:36.375031: Current learning rate: 0.00121 
2025-08-28 12:17:53.170184: train_loss -0.4139 
2025-08-28 12:17:53.178333: val_loss -0.431 
2025-08-28 12:17:53.182654: Pseudo dice [np.float32(0.6805)] 
2025-08-28 12:17:53.190751: Epoch time: 16.81 s 
2025-08-28 12:17:54.151095:  
2025-08-28 12:17:54.161343: Epoch 905 
2025-08-28 12:17:54.169677: Current learning rate: 0.0012 
2025-08-28 12:18:10.942185: train_loss -0.3797 
2025-08-28 12:18:10.954355: val_loss -0.4058 
2025-08-28 12:18:10.963061: Pseudo dice [np.float32(0.7218)] 
2025-08-28 12:18:10.968226: Epoch time: 16.79 s 
2025-08-28 12:18:11.669616:  
2025-08-28 12:18:11.678041: Epoch 906 
2025-08-28 12:18:11.683191: Current learning rate: 0.00119 
2025-08-28 12:18:28.538637: train_loss -0.3828 
2025-08-28 12:18:28.546974: val_loss -0.4894 
2025-08-28 12:18:28.551190: Pseudo dice [np.float32(0.7883)] 
2025-08-28 12:18:28.559532: Epoch time: 16.87 s 
2025-08-28 12:18:28.566123: Yayy! New best EMA pseudo Dice: 0.7317000031471252 
2025-08-28 12:18:29.471719:  
2025-08-28 12:18:29.479806: Epoch 907 
2025-08-28 12:18:29.486846: Current learning rate: 0.00118 
2025-08-28 12:18:46.026896: train_loss -0.3928 
2025-08-28 12:18:46.035234: val_loss -0.4938 
2025-08-28 12:18:46.039418: Pseudo dice [np.float32(0.7354)] 
2025-08-28 12:18:46.047725: Epoch time: 16.56 s 
2025-08-28 12:18:46.053312: Yayy! New best EMA pseudo Dice: 0.7321000099182129 
2025-08-28 12:18:46.972469:  
2025-08-28 12:18:46.982498: Epoch 908 
2025-08-28 12:18:46.989087: Current learning rate: 0.00117 
2025-08-28 12:19:03.060580: train_loss -0.3558 
2025-08-28 12:19:03.068922: val_loss -0.4639 
2025-08-28 12:19:03.073040: Pseudo dice [np.float32(0.7307)] 
2025-08-28 12:19:03.082273: Epoch time: 16.09 s 
2025-08-28 12:19:03.793676:  
2025-08-28 12:19:03.804302: Epoch 909 
2025-08-28 12:19:03.810661: Current learning rate: 0.00116 
2025-08-28 12:19:19.798351: train_loss -0.3978 
2025-08-28 12:19:19.806801: val_loss -0.4469 
2025-08-28 12:19:19.814829: Pseudo dice [np.float32(0.7205)] 
2025-08-28 12:19:19.820276: Epoch time: 16.01 s 
2025-08-28 12:19:20.530021:  
2025-08-28 12:19:20.538470: Epoch 910 
2025-08-28 12:19:20.544723: Current learning rate: 0.00115 
2025-08-28 12:19:36.715027: train_loss -0.3805 
2025-08-28 12:19:36.723379: val_loss -0.4986 
2025-08-28 12:19:36.727813: Pseudo dice [np.float32(0.7474)] 
2025-08-28 12:19:36.735776: Epoch time: 16.19 s 
2025-08-28 12:19:36.741698: Yayy! New best EMA pseudo Dice: 0.7325000166893005 
2025-08-28 12:19:37.650371:  
2025-08-28 12:19:37.659671: Epoch 911 
2025-08-28 12:19:37.665924: Current learning rate: 0.00113 
2025-08-28 12:19:54.499455: train_loss -0.4191 
2025-08-28 12:19:54.507780: val_loss -0.4235 
2025-08-28 12:19:54.515538: Pseudo dice [np.float32(0.6929)] 
2025-08-28 12:19:54.521074: Epoch time: 16.85 s 
2025-08-28 12:19:55.380487:  
2025-08-28 12:19:55.387666: Epoch 912 
2025-08-28 12:19:55.394045: Current learning rate: 0.00112 
2025-08-28 12:20:12.162885: train_loss -0.4348 
2025-08-28 12:20:12.175722: val_loss -0.4398 
2025-08-28 12:20:12.179562: Pseudo dice [np.float32(0.7433)] 
2025-08-28 12:20:12.186845: Epoch time: 16.78 s 
2025-08-28 12:20:12.902179:  
2025-08-28 12:20:12.910493: Epoch 913 
2025-08-28 12:20:12.915663: Current learning rate: 0.00111 
2025-08-28 12:20:29.885079: train_loss -0.3999 
2025-08-28 12:20:29.893161: val_loss -0.4241 
2025-08-28 12:20:29.901467: Pseudo dice [np.float32(0.7353)] 
2025-08-28 12:20:29.906891: Epoch time: 16.98 s 
2025-08-28 12:20:30.611524:  
2025-08-28 12:20:30.619871: Epoch 914 
2025-08-28 12:20:30.626082: Current learning rate: 0.0011 
2025-08-28 12:20:47.631694: train_loss -0.4199 
2025-08-28 12:20:47.640207: val_loss -0.52 
2025-08-28 12:20:47.644420: Pseudo dice [np.float32(0.7692)] 
2025-08-28 12:20:47.652585: Epoch time: 17.02 s 
2025-08-28 12:20:47.658932: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-08-28 12:20:48.581926:  
2025-08-28 12:20:48.591480: Epoch 915 
2025-08-28 12:20:48.596970: Current learning rate: 0.00109 
2025-08-28 12:21:05.492853: train_loss -0.4143 
2025-08-28 12:21:05.499548: val_loss -0.4889 
2025-08-28 12:21:05.508183: Pseudo dice [np.float32(0.6934)] 
2025-08-28 12:21:05.514119: Epoch time: 16.91 s 
2025-08-28 12:21:06.217501:  
2025-08-28 12:21:06.225235: Epoch 916 
2025-08-28 12:21:06.231427: Current learning rate: 0.00108 
2025-08-28 12:21:23.467495: train_loss -0.4082 
2025-08-28 12:21:23.475862: val_loss -0.4634 
2025-08-28 12:21:23.480268: Pseudo dice [np.float32(0.7359)] 
2025-08-28 12:21:23.487404: Epoch time: 17.25 s 
2025-08-28 12:21:24.198483:  
2025-08-28 12:21:24.209354: Epoch 917 
2025-08-28 12:21:24.214459: Current learning rate: 0.00106 
2025-08-28 12:21:41.431484: train_loss -0.4064 
2025-08-28 12:21:41.439556: val_loss -0.4502 
2025-08-28 12:21:41.448194: Pseudo dice [np.float32(0.7372)] 
2025-08-28 12:21:41.455178: Epoch time: 17.23 s 
2025-08-28 12:21:42.326914:  
2025-08-28 12:21:42.335208: Epoch 918 
2025-08-28 12:21:42.341504: Current learning rate: 0.00105 
2025-08-28 12:21:59.282107: train_loss -0.4446 
2025-08-28 12:21:59.290719: val_loss -0.4817 
2025-08-28 12:21:59.294903: Pseudo dice [np.float32(0.744)] 
2025-08-28 12:21:59.302382: Epoch time: 16.96 s 
2025-08-28 12:22:00.003794:  
2025-08-28 12:22:00.012408: Epoch 919 
2025-08-28 12:22:00.020968: Current learning rate: 0.00104 
2025-08-28 12:22:16.654145: train_loss -0.4097 
2025-08-28 12:22:16.666419: val_loss -0.4742 
2025-08-28 12:22:16.674484: Pseudo dice [np.float32(0.7546)] 
2025-08-28 12:22:16.678945: Epoch time: 16.65 s 
2025-08-28 12:22:16.683904: Yayy! New best EMA pseudo Dice: 0.7348999977111816 
2025-08-28 12:22:17.581873:  
2025-08-28 12:22:17.589200: Epoch 920 
2025-08-28 12:22:17.594313: Current learning rate: 0.00103 
2025-08-28 12:22:34.709754: train_loss -0.3783 
2025-08-28 12:22:34.717749: val_loss -0.4331 
2025-08-28 12:22:34.721914: Pseudo dice [np.float32(0.7666)] 
2025-08-28 12:22:34.731544: Epoch time: 17.13 s 
2025-08-28 12:22:34.735292: Yayy! New best EMA pseudo Dice: 0.738099992275238 
2025-08-28 12:22:35.638515:  
2025-08-28 12:22:35.644802: Epoch 921 
2025-08-28 12:22:35.648114: Current learning rate: 0.00102 
2025-08-28 12:22:52.314590: train_loss -0.3915 
2025-08-28 12:22:52.322810: val_loss -0.4577 
2025-08-28 12:22:52.331175: Pseudo dice [np.float32(0.7004)] 
2025-08-28 12:22:52.336763: Epoch time: 16.68 s 
2025-08-28 12:22:53.060619:  
2025-08-28 12:22:53.068345: Epoch 922 
2025-08-28 12:22:53.076791: Current learning rate: 0.00101 
2025-08-28 12:23:09.840326: train_loss -0.4273 
2025-08-28 12:23:09.852834: val_loss -0.4835 
2025-08-28 12:23:09.857018: Pseudo dice [np.float32(0.737)] 
2025-08-28 12:23:09.866325: Epoch time: 16.78 s 
2025-08-28 12:23:10.586747:  
2025-08-28 12:23:10.595924: Epoch 923 
2025-08-28 12:23:10.604256: Current learning rate: 0.001 
2025-08-28 12:23:27.432934: train_loss -0.4003 
2025-08-28 12:23:27.441245: val_loss -0.4409 
2025-08-28 12:23:27.445407: Pseudo dice [np.float32(0.6721)] 
2025-08-28 12:23:27.453734: Epoch time: 16.85 s 
2025-08-28 12:23:28.171020:  
2025-08-28 12:23:28.179386: Epoch 924 
2025-08-28 12:23:28.186671: Current learning rate: 0.00098 
2025-08-28 12:23:45.338258: train_loss -0.4293 
2025-08-28 12:23:45.346698: val_loss -0.4412 
2025-08-28 12:23:45.350825: Pseudo dice [np.float32(0.7595)] 
2025-08-28 12:23:45.358856: Epoch time: 17.17 s 
2025-08-28 12:23:46.212232:  
2025-08-28 12:23:46.220426: Epoch 925 
2025-08-28 12:23:46.226509: Current learning rate: 0.00097 
2025-08-28 12:24:02.834777: train_loss -0.4057 
2025-08-28 12:24:02.843267: val_loss -0.43 
2025-08-28 12:24:02.851582: Pseudo dice [np.float32(0.6489)] 
2025-08-28 12:24:02.857940: Epoch time: 16.63 s 
2025-08-28 12:24:03.553486:  
2025-08-28 12:24:03.563147: Epoch 926 
2025-08-28 12:24:03.569364: Current learning rate: 0.00096 
2025-08-28 12:24:20.156680: train_loss -0.4345 
2025-08-28 12:24:20.168892: val_loss -0.4838 
2025-08-28 12:24:20.173383: Pseudo dice [np.float32(0.726)] 
2025-08-28 12:24:20.179342: Epoch time: 16.61 s 
2025-08-28 12:24:20.886224:  
2025-08-28 12:24:20.896402: Epoch 927 
2025-08-28 12:24:20.904320: Current learning rate: 0.00095 
2025-08-28 12:24:37.711547: train_loss -0.4107 
2025-08-28 12:24:37.719957: val_loss -0.4344 
2025-08-28 12:24:37.724118: Pseudo dice [np.float32(0.6833)] 
2025-08-28 12:24:37.733163: Epoch time: 16.83 s 
2025-08-28 12:24:38.427039:  
2025-08-28 12:24:38.433410: Epoch 928 
2025-08-28 12:24:38.441312: Current learning rate: 0.00094 
2025-08-28 12:24:55.500565: train_loss -0.4215 
2025-08-28 12:24:55.510534: val_loss -0.4937 
2025-08-28 12:24:55.516700: Pseudo dice [np.float32(0.7622)] 
2025-08-28 12:24:55.524119: Epoch time: 17.07 s 
2025-08-28 12:24:56.238072:  
2025-08-28 12:24:56.246499: Epoch 929 
2025-08-28 12:24:56.251765: Current learning rate: 0.00092 
2025-08-28 12:25:12.896516: train_loss -0.4197 
2025-08-28 12:25:12.909062: val_loss -0.4614 
2025-08-28 12:25:12.913484: Pseudo dice [np.float32(0.7616)] 
2025-08-28 12:25:12.922312: Epoch time: 16.66 s 
2025-08-28 12:25:13.622200:  
2025-08-28 12:25:13.631343: Epoch 930 
2025-08-28 12:25:13.637820: Current learning rate: 0.00091 
2025-08-28 12:25:30.301410: train_loss -0.425 
2025-08-28 12:25:30.309744: val_loss -0.4234 
2025-08-28 12:25:30.318086: Pseudo dice [np.float32(0.7255)] 
2025-08-28 12:25:30.324431: Epoch time: 16.68 s 
2025-08-28 12:25:31.162789:  
2025-08-28 12:25:31.171947: Epoch 931 
2025-08-28 12:25:31.178299: Current learning rate: 0.0009 
2025-08-28 12:25:47.827551: train_loss -0.3911 
2025-08-28 12:25:47.835834: val_loss -0.3945 
2025-08-28 12:25:47.843971: Pseudo dice [np.float32(0.7073)] 
2025-08-28 12:25:47.850183: Epoch time: 16.67 s 
2025-08-28 12:25:48.570669:  
2025-08-28 12:25:48.580041: Epoch 932 
2025-08-28 12:25:48.586720: Current learning rate: 0.00089 
2025-08-28 12:26:05.232111: train_loss -0.4308 
2025-08-28 12:26:05.244633: val_loss -0.4833 
2025-08-28 12:26:05.248829: Pseudo dice [np.float32(0.7678)] 
2025-08-28 12:26:05.258074: Epoch time: 16.66 s 
2025-08-28 12:26:05.949455:  
2025-08-28 12:26:05.957793: Epoch 933 
2025-08-28 12:26:05.964045: Current learning rate: 0.00088 
2025-08-28 12:26:22.804213: train_loss -0.4262 
2025-08-28 12:26:22.812182: val_loss -0.4202 
2025-08-28 12:26:22.820225: Pseudo dice [np.float32(0.7579)] 
2025-08-28 12:26:22.825471: Epoch time: 16.86 s 
2025-08-28 12:26:23.519174:  
2025-08-28 12:26:23.527418: Epoch 934 
2025-08-28 12:26:23.533720: Current learning rate: 0.00087 
2025-08-28 12:26:40.396965: train_loss -0.393 
2025-08-28 12:26:40.404757: val_loss -0.4234 
2025-08-28 12:26:40.413113: Pseudo dice [np.float32(0.7136)] 
2025-08-28 12:26:40.418487: Epoch time: 16.88 s 
2025-08-28 12:26:41.116842:  
2025-08-28 12:26:41.125140: Epoch 935 
2025-08-28 12:26:41.130334: Current learning rate: 0.00085 
2025-08-28 12:26:57.863847: train_loss -0.4125 
2025-08-28 12:26:57.872202: val_loss -0.4301 
2025-08-28 12:26:57.880552: Pseudo dice [np.float32(0.6572)] 
2025-08-28 12:26:57.886853: Epoch time: 16.75 s 
2025-08-28 12:26:58.586421:  
2025-08-28 12:26:58.595891: Epoch 936 
2025-08-28 12:26:58.602029: Current learning rate: 0.00084 
2025-08-28 12:27:15.398050: train_loss -0.4307 
2025-08-28 12:27:15.410533: val_loss -0.459 
2025-08-28 12:27:15.414752: Pseudo dice [np.float32(0.7154)] 
2025-08-28 12:27:15.422199: Epoch time: 16.81 s 
2025-08-28 12:27:16.118456:  
2025-08-28 12:27:16.127774: Epoch 937 
2025-08-28 12:27:16.135155: Current learning rate: 0.00083 
2025-08-28 12:27:33.599870: train_loss -0.4268 
2025-08-28 12:27:33.608088: val_loss -0.4339 
2025-08-28 12:27:33.612326: Pseudo dice [np.float32(0.7688)] 
2025-08-28 12:27:33.620710: Epoch time: 17.48 s 
2025-08-28 12:27:34.333460:  
2025-08-28 12:27:34.346095: Epoch 938 
2025-08-28 12:27:34.351537: Current learning rate: 0.00082 
2025-08-28 12:27:51.584083: train_loss -0.4285 
2025-08-28 12:27:51.592940: val_loss -0.4476 
2025-08-28 12:27:51.596733: Pseudo dice [np.float32(0.6627)] 
2025-08-28 12:27:51.605000: Epoch time: 17.25 s 
2025-08-28 12:27:52.313872:  
2025-08-28 12:27:52.322595: Epoch 939 
2025-08-28 12:27:52.329101: Current learning rate: 0.00081 
2025-08-28 12:28:09.239289: train_loss -0.4219 
2025-08-28 12:28:09.251800: val_loss -0.4254 
2025-08-28 12:28:09.260145: Pseudo dice [np.float32(0.6929)] 
2025-08-28 12:28:09.266323: Epoch time: 16.93 s 
2025-08-28 12:28:09.962874:  
2025-08-28 12:28:09.971197: Epoch 940 
2025-08-28 12:28:09.978618: Current learning rate: 0.00079 
2025-08-28 12:28:26.994590: train_loss -0.4067 
2025-08-28 12:28:27.003174: val_loss -0.4683 
2025-08-28 12:28:27.007287: Pseudo dice [np.float32(0.7172)] 
2025-08-28 12:28:27.015226: Epoch time: 17.03 s 
2025-08-28 12:28:27.726538:  
2025-08-28 12:28:27.736011: Epoch 941 
2025-08-28 12:28:27.740967: Current learning rate: 0.00078 
2025-08-28 12:28:44.674976: train_loss -0.4167 
2025-08-28 12:28:44.687193: val_loss -0.402 
2025-08-28 12:28:44.691668: Pseudo dice [np.float32(0.7118)] 
2025-08-28 12:28:44.699901: Epoch time: 16.95 s 
2025-08-28 12:28:45.407647:  
2025-08-28 12:28:45.415977: Epoch 942 
2025-08-28 12:28:45.422358: Current learning rate: 0.00077 
2025-08-28 12:29:02.242480: train_loss -0.4262 
2025-08-28 12:29:02.250881: val_loss -0.4872 
2025-08-28 12:29:02.258641: Pseudo dice [np.float32(0.7223)] 
2025-08-28 12:29:02.264346: Epoch time: 16.84 s 
2025-08-28 12:29:02.959408:  
2025-08-28 12:29:02.968196: Epoch 943 
2025-08-28 12:29:02.974199: Current learning rate: 0.00076 
2025-08-28 12:29:19.984952: train_loss -0.4001 
2025-08-28 12:29:19.997494: val_loss -0.4556 
2025-08-28 12:29:20.001879: Pseudo dice [np.float32(0.7287)] 
2025-08-28 12:29:20.011167: Epoch time: 17.03 s 
2025-08-28 12:29:20.695024:  
2025-08-28 12:29:20.704308: Epoch 944 
2025-08-28 12:29:20.710603: Current learning rate: 0.00075 
2025-08-28 12:29:37.473252: train_loss -0.3905 
2025-08-28 12:29:37.481634: val_loss -0.474 
2025-08-28 12:29:37.485769: Pseudo dice [np.float32(0.7231)] 
2025-08-28 12:29:37.494890: Epoch time: 16.78 s 
2025-08-28 12:29:38.331351:  
2025-08-28 12:29:38.338662: Epoch 945 
2025-08-28 12:29:38.344974: Current learning rate: 0.00074 
2025-08-28 12:29:54.807203: train_loss -0.4416 
2025-08-28 12:29:54.815551: val_loss -0.4346 
2025-08-28 12:29:54.819729: Pseudo dice [np.float32(0.7428)] 
2025-08-28 12:29:54.829010: Epoch time: 16.48 s 
2025-08-28 12:29:55.526605:  
2025-08-28 12:29:55.532914: Epoch 946 
2025-08-28 12:29:55.541135: Current learning rate: 0.00072 
2025-08-28 12:30:12.362137: train_loss -0.432 
2025-08-28 12:30:12.370583: val_loss -0.4776 
2025-08-28 12:30:12.378909: Pseudo dice [np.float32(0.7371)] 
2025-08-28 12:30:12.384446: Epoch time: 16.84 s 
2025-08-28 12:30:13.084158:  
2025-08-28 12:30:13.092134: Epoch 947 
2025-08-28 12:30:13.099320: Current learning rate: 0.00071 
2025-08-28 12:30:29.817587: train_loss -0.4237 
2025-08-28 12:30:29.825518: val_loss -0.4812 
2025-08-28 12:30:29.830022: Pseudo dice [np.float32(0.7719)] 
2025-08-28 12:30:29.837867: Epoch time: 16.73 s 
2025-08-28 12:30:30.540785:  
2025-08-28 12:30:30.548977: Epoch 948 
2025-08-28 12:30:30.556414: Current learning rate: 0.0007 
2025-08-28 12:30:47.513999: train_loss -0.4274 
2025-08-28 12:30:47.522630: val_loss -0.5122 
2025-08-28 12:30:47.531939: Pseudo dice [np.float32(0.7586)] 
2025-08-28 12:30:47.536983: Epoch time: 16.97 s 
2025-08-28 12:30:48.234383:  
2025-08-28 12:30:48.241742: Epoch 949 
2025-08-28 12:30:48.246953: Current learning rate: 0.00069 
2025-08-28 12:31:04.881721: train_loss -0.4136 
2025-08-28 12:31:04.889685: val_loss -0.465 
2025-08-28 12:31:04.894118: Pseudo dice [np.float32(0.7327)] 
2025-08-28 12:31:04.902375: Epoch time: 16.65 s 
2025-08-28 12:31:05.802019:  
2025-08-28 12:31:05.811450: Epoch 950 
2025-08-28 12:31:05.818673: Current learning rate: 0.00067 
2025-08-28 12:31:22.761686: train_loss -0.4138 
2025-08-28 12:31:22.770047: val_loss -0.4883 
2025-08-28 12:31:22.778405: Pseudo dice [np.float32(0.7239)] 
2025-08-28 12:31:22.784816: Epoch time: 16.96 s 
2025-08-28 12:31:23.492614:  
2025-08-28 12:31:23.500958: Epoch 951 
2025-08-28 12:31:23.509318: Current learning rate: 0.00066 
2025-08-28 12:31:40.008082: train_loss -0.4238 
2025-08-28 12:31:40.016437: val_loss -0.4874 
2025-08-28 12:31:40.024790: Pseudo dice [np.float32(0.7735)] 
2025-08-28 12:31:40.030273: Epoch time: 16.52 s 
2025-08-28 12:31:40.867522:  
2025-08-28 12:31:40.876437: Epoch 952 
2025-08-28 12:31:40.880339: Current learning rate: 0.00065 
2025-08-28 12:31:57.760081: train_loss -0.4457 
2025-08-28 12:31:57.767839: val_loss -0.3856 
2025-08-28 12:31:57.771967: Pseudo dice [np.float32(0.7202)] 
2025-08-28 12:31:57.780867: Epoch time: 16.89 s 
2025-08-28 12:31:58.477540:  
2025-08-28 12:31:58.484891: Epoch 953 
2025-08-28 12:31:58.492023: Current learning rate: 0.00064 
2025-08-28 12:32:15.368425: train_loss -0.4147 
2025-08-28 12:32:15.380939: val_loss -0.4305 
2025-08-28 12:32:15.385120: Pseudo dice [np.float32(0.7184)] 
2025-08-28 12:32:15.392159: Epoch time: 16.89 s 
2025-08-28 12:32:16.083658:  
2025-08-28 12:32:16.091064: Epoch 954 
2025-08-28 12:32:16.096177: Current learning rate: 0.00063 
2025-08-28 12:32:33.003074: train_loss -0.4161 
2025-08-28 12:32:33.011035: val_loss -0.3793 
2025-08-28 12:32:33.019392: Pseudo dice [np.float32(0.7168)] 
2025-08-28 12:32:33.026886: Epoch time: 16.92 s 
2025-08-28 12:32:33.736130:  
2025-08-28 12:32:33.743212: Epoch 955 
2025-08-28 12:32:33.753381: Current learning rate: 0.00061 
2025-08-28 12:32:50.379073: train_loss -0.4432 
2025-08-28 12:32:50.386704: val_loss -0.4186 
2025-08-28 12:32:50.395076: Pseudo dice [np.float32(0.6466)] 
2025-08-28 12:32:50.400473: Epoch time: 16.64 s 
2025-08-28 12:32:51.122891:  
2025-08-28 12:32:51.129451: Epoch 956 
2025-08-28 12:32:51.138491: Current learning rate: 0.0006 
2025-08-28 12:33:07.641560: train_loss -0.4235 
2025-08-28 12:33:07.649781: val_loss -0.4749 
2025-08-28 12:33:07.658116: Pseudo dice [np.float32(0.7712)] 
2025-08-28 12:33:07.665431: Epoch time: 16.52 s 
2025-08-28 12:33:08.392143:  
2025-08-28 12:33:08.400464: Epoch 957 
2025-08-28 12:33:08.406758: Current learning rate: 0.00059 
2025-08-28 12:33:25.154790: train_loss -0.4323 
2025-08-28 12:33:25.163154: val_loss -0.4718 
2025-08-28 12:33:25.171131: Pseudo dice [np.float32(0.7042)] 
2025-08-28 12:33:25.176344: Epoch time: 16.76 s 
2025-08-28 12:33:26.031626:  
2025-08-28 12:33:26.038911: Epoch 958 
2025-08-28 12:33:26.044141: Current learning rate: 0.00058 
2025-08-28 12:33:42.764042: train_loss -0.4138 
2025-08-28 12:33:42.772633: val_loss -0.4371 
2025-08-28 12:33:42.781045: Pseudo dice [np.float32(0.71)] 
2025-08-28 12:33:42.786181: Epoch time: 16.73 s 
2025-08-28 12:33:43.491695:  
2025-08-28 12:33:43.500918: Epoch 959 
2025-08-28 12:33:43.508180: Current learning rate: 0.00056 
2025-08-28 12:34:00.165090: train_loss -0.4197 
2025-08-28 12:34:00.173063: val_loss -0.4651 
2025-08-28 12:34:00.177219: Pseudo dice [np.float32(0.6808)] 
2025-08-28 12:34:00.187216: Epoch time: 16.68 s 
2025-08-28 12:34:00.893536:  
2025-08-28 12:34:00.902918: Epoch 960 
2025-08-28 12:34:00.909220: Current learning rate: 0.00055 
2025-08-28 12:34:17.594620: train_loss -0.4302 
2025-08-28 12:34:17.605814: val_loss -0.4308 
2025-08-28 12:34:17.611352: Pseudo dice [np.float32(0.7139)] 
2025-08-28 12:34:17.618684: Epoch time: 16.7 s 
2025-08-28 12:34:18.338065:  
2025-08-28 12:34:18.349497: Epoch 961 
2025-08-28 12:34:18.354016: Current learning rate: 0.00054 
2025-08-28 12:34:35.262435: train_loss -0.4235 
2025-08-28 12:34:35.270598: val_loss -0.4555 
2025-08-28 12:34:35.274765: Pseudo dice [np.float32(0.7148)] 
2025-08-28 12:34:35.283201: Epoch time: 16.93 s 
2025-08-28 12:34:36.009312:  
2025-08-28 12:34:36.020771: Epoch 962 
2025-08-28 12:34:36.026567: Current learning rate: 0.00053 
2025-08-28 12:34:52.817336: train_loss -0.4298 
2025-08-28 12:34:52.825649: val_loss -0.3865 
2025-08-28 12:34:52.834267: Pseudo dice [np.float32(0.7057)] 
2025-08-28 12:34:52.839470: Epoch time: 16.81 s 
2025-08-28 12:34:53.554533:  
2025-08-28 12:34:53.562036: Epoch 963 
2025-08-28 12:34:53.569060: Current learning rate: 0.00051 
2025-08-28 12:35:10.839489: train_loss -0.4368 
2025-08-28 12:35:10.851697: val_loss -0.4909 
2025-08-28 12:35:10.856385: Pseudo dice [np.float32(0.7807)] 
2025-08-28 12:35:10.867212: Epoch time: 17.29 s 
2025-08-28 12:35:11.616225:  
2025-08-28 12:35:11.625162: Epoch 964 
2025-08-28 12:35:11.633373: Current learning rate: 0.0005 
2025-08-28 12:35:28.302725: train_loss -0.449 
2025-08-28 12:35:28.311081: val_loss -0.4823 
2025-08-28 12:35:28.319762: Pseudo dice [np.float32(0.7718)] 
2025-08-28 12:35:28.325672: Epoch time: 16.69 s 
2025-08-28 12:35:29.207316:  
2025-08-28 12:35:29.214056: Epoch 965 
2025-08-28 12:35:29.216979: Current learning rate: 0.00049 
2025-08-28 12:35:46.236958: train_loss -0.4163 
2025-08-28 12:35:46.245687: val_loss -0.4725 
2025-08-28 12:35:46.250100: Pseudo dice [np.float32(0.7643)] 
2025-08-28 12:35:46.258129: Epoch time: 17.03 s 
2025-08-28 12:35:46.943184:  
2025-08-28 12:35:46.953571: Epoch 966 
2025-08-28 12:35:46.960935: Current learning rate: 0.00048 
2025-08-28 12:36:03.558766: train_loss -0.4314 
2025-08-28 12:36:03.567095: val_loss -0.426 
2025-08-28 12:36:03.575785: Pseudo dice [np.float32(0.7507)] 
2025-08-28 12:36:03.580959: Epoch time: 16.62 s 
2025-08-28 12:36:04.292663:  
2025-08-28 12:36:04.301013: Epoch 967 
2025-08-28 12:36:04.306406: Current learning rate: 0.00046 
2025-08-28 12:36:20.913642: train_loss -0.4453 
2025-08-28 12:36:20.921925: val_loss -0.4565 
2025-08-28 12:36:20.930163: Pseudo dice [np.float32(0.7384)] 
2025-08-28 12:36:20.937717: Epoch time: 16.62 s 
2025-08-28 12:36:21.657663:  
2025-08-28 12:36:21.665420: Epoch 968 
2025-08-28 12:36:21.672677: Current learning rate: 0.00045 
2025-08-28 12:36:38.181371: train_loss -0.4478 
2025-08-28 12:36:38.189517: val_loss -0.4207 
2025-08-28 12:36:38.193324: Pseudo dice [np.float32(0.7283)] 
2025-08-28 12:36:38.201617: Epoch time: 16.52 s 
2025-08-28 12:36:38.904500:  
2025-08-28 12:36:38.913805: Epoch 969 
2025-08-28 12:36:38.918883: Current learning rate: 0.00044 
2025-08-28 12:36:55.748833: train_loss -0.435 
2025-08-28 12:36:55.756711: val_loss -0.4522 
2025-08-28 12:36:55.760889: Pseudo dice [np.float32(0.7089)] 
2025-08-28 12:36:55.769575: Epoch time: 16.85 s 
2025-08-28 12:36:56.487641:  
2025-08-28 12:36:56.494814: Epoch 970 
2025-08-28 12:36:56.501133: Current learning rate: 0.00043 
2025-08-28 12:37:13.416595: train_loss -0.4331 
2025-08-28 12:37:13.428542: val_loss -0.4604 
2025-08-28 12:37:13.432712: Pseudo dice [np.float32(0.7523)] 
2025-08-28 12:37:13.441003: Epoch time: 16.93 s 
2025-08-28 12:37:14.292328:  
2025-08-28 12:37:14.300258: Epoch 971 
2025-08-28 12:37:14.305318: Current learning rate: 0.00041 
2025-08-28 12:37:31.358993: train_loss -0.4346 
2025-08-28 12:37:31.367241: val_loss -0.4304 
2025-08-28 12:37:31.371487: Pseudo dice [np.float32(0.6507)] 
2025-08-28 12:37:31.380102: Epoch time: 17.07 s 
2025-08-28 12:37:32.083540:  
2025-08-28 12:37:32.091847: Epoch 972 
2025-08-28 12:37:32.097062: Current learning rate: 0.0004 
2025-08-28 12:37:48.926465: train_loss -0.4125 
2025-08-28 12:37:48.934839: val_loss -0.4438 
2025-08-28 12:37:48.939002: Pseudo dice [np.float32(0.7553)] 
2025-08-28 12:37:48.948246: Epoch time: 16.84 s 
2025-08-28 12:37:49.642945:  
2025-08-28 12:37:49.650723: Epoch 973 
2025-08-28 12:37:49.656992: Current learning rate: 0.00039 
2025-08-28 12:38:06.619798: train_loss -0.4381 
2025-08-28 12:38:06.627515: val_loss -0.4761 
2025-08-28 12:38:06.636182: Pseudo dice [np.float32(0.7545)] 
2025-08-28 12:38:06.642049: Epoch time: 16.98 s 
2025-08-28 12:38:07.348969:  
2025-08-28 12:38:07.359411: Epoch 974 
2025-08-28 12:38:07.367398: Current learning rate: 0.00037 
2025-08-28 12:38:24.103293: train_loss -0.456 
2025-08-28 12:38:24.115776: val_loss -0.403 
2025-08-28 12:38:24.119956: Pseudo dice [np.float32(0.6839)] 
2025-08-28 12:38:24.128181: Epoch time: 16.76 s 
2025-08-28 12:38:24.858191:  
2025-08-28 12:38:24.866559: Epoch 975 
2025-08-28 12:38:24.883248: Current learning rate: 0.00036 
2025-08-28 12:38:41.658194: train_loss -0.4477 
2025-08-28 12:38:41.666652: val_loss -0.4262 
2025-08-28 12:38:41.670806: Pseudo dice [np.float32(0.7439)] 
2025-08-28 12:38:41.679026: Epoch time: 16.8 s 
2025-08-28 12:38:42.523670:  
2025-08-28 12:38:42.533676: Epoch 976 
2025-08-28 12:38:42.539135: Current learning rate: 0.00035 
2025-08-28 12:38:59.330194: train_loss -0.4201 
2025-08-28 12:38:59.342641: val_loss -0.4554 
2025-08-28 12:38:59.346808: Pseudo dice [np.float32(0.7175)] 
2025-08-28 12:38:59.354550: Epoch time: 16.81 s 
2025-08-28 12:39:00.081859:  
2025-08-28 12:39:00.089078: Epoch 977 
2025-08-28 12:39:00.095374: Current learning rate: 0.00034 
2025-08-28 12:39:16.726469: train_loss -0.4626 
2025-08-28 12:39:16.735001: val_loss -0.4875 
2025-08-28 12:39:16.743343: Pseudo dice [np.float32(0.8083)] 
2025-08-28 12:39:16.748710: Epoch time: 16.65 s 
2025-08-28 12:39:17.624067:  
2025-08-28 12:39:17.634774: Epoch 978 
2025-08-28 12:39:17.641822: Current learning rate: 0.00032 
2025-08-28 12:39:34.377228: train_loss -0.4126 
2025-08-28 12:39:34.385982: val_loss -0.4896 
2025-08-28 12:39:34.390431: Pseudo dice [np.float32(0.7457)] 
2025-08-28 12:39:34.398380: Epoch time: 16.75 s 
2025-08-28 12:39:35.096096:  
2025-08-28 12:39:35.103174: Epoch 979 
2025-08-28 12:39:35.108521: Current learning rate: 0.00031 
2025-08-28 12:39:51.652982: train_loss -0.4321 
2025-08-28 12:39:51.661561: val_loss -0.4448 
2025-08-28 12:39:51.665750: Pseudo dice [np.float32(0.7521)] 
2025-08-28 12:39:51.674230: Epoch time: 16.56 s 
2025-08-28 12:39:52.400088:  
2025-08-28 12:39:52.409125: Epoch 980 
2025-08-28 12:39:52.417311: Current learning rate: 0.0003 
2025-08-28 12:40:08.812021: train_loss -0.4276 
2025-08-28 12:40:08.824540: val_loss -0.3924 
2025-08-28 12:40:08.828604: Pseudo dice [np.float32(0.7509)] 
2025-08-28 12:40:08.837768: Epoch time: 16.41 s 
2025-08-28 12:40:08.842026: Yayy! New best EMA pseudo Dice: 0.7389000058174133 
2025-08-28 12:40:09.788211:  
2025-08-28 12:40:09.797255: Epoch 981 
2025-08-28 12:40:09.804655: Current learning rate: 0.00028 
2025-08-28 12:40:26.352862: train_loss -0.4385 
2025-08-28 12:40:26.362863: val_loss -0.4771 
2025-08-28 12:40:26.367028: Pseudo dice [np.float32(0.7537)] 
2025-08-28 12:40:26.375376: Epoch time: 16.57 s 
2025-08-28 12:40:26.381101: Yayy! New best EMA pseudo Dice: 0.7404000163078308 
2025-08-28 12:40:27.309919:  
2025-08-28 12:40:27.318056: Epoch 982 
2025-08-28 12:40:27.324170: Current learning rate: 0.00027 
2025-08-28 12:40:44.243274: train_loss -0.4086 
2025-08-28 12:40:44.251873: val_loss -0.4568 
2025-08-28 12:40:44.255999: Pseudo dice [np.float32(0.773)] 
2025-08-28 12:40:44.263898: Epoch time: 16.94 s 
2025-08-28 12:40:44.269810: Yayy! New best EMA pseudo Dice: 0.7436000108718872 
2025-08-28 12:40:45.181773:  
2025-08-28 12:40:45.190434: Epoch 983 
2025-08-28 12:40:45.196190: Current learning rate: 0.00026 
2025-08-28 12:41:01.435598: train_loss -0.4609 
2025-08-28 12:41:01.443751: val_loss -0.4034 
2025-08-28 12:41:01.447901: Pseudo dice [np.float32(0.692)] 
2025-08-28 12:41:01.455247: Epoch time: 16.26 s 
2025-08-28 12:41:02.354240:  
2025-08-28 12:41:02.361581: Epoch 984 
2025-08-28 12:41:02.367696: Current learning rate: 0.00024 
2025-08-28 12:41:18.610865: train_loss -0.4544 
2025-08-28 12:41:18.619472: val_loss -0.46 
2025-08-28 12:41:18.627534: Pseudo dice [np.float32(0.7729)] 
2025-08-28 12:41:18.634096: Epoch time: 16.26 s 
2025-08-28 12:41:19.365728:  
2025-08-28 12:41:19.374027: Epoch 985 
2025-08-28 12:41:19.379395: Current learning rate: 0.00023 
2025-08-28 12:41:35.264992: train_loss -0.4532 
2025-08-28 12:41:35.273323: val_loss -0.5092 
2025-08-28 12:41:35.277681: Pseudo dice [np.float32(0.7419)] 
2025-08-28 12:41:35.287141: Epoch time: 15.9 s 
2025-08-28 12:41:36.019952:  
2025-08-28 12:41:36.027084: Epoch 986 
2025-08-28 12:41:36.032299: Current learning rate: 0.00021 
2025-08-28 12:41:52.123507: train_loss -0.4367 
2025-08-28 12:41:52.131850: val_loss -0.4836 
2025-08-28 12:41:52.136043: Pseudo dice [np.float32(0.76)] 
2025-08-28 12:41:52.145201: Epoch time: 16.11 s 
2025-08-28 12:41:52.150922: Yayy! New best EMA pseudo Dice: 0.7437000274658203 
2025-08-28 12:41:53.068163:  
2025-08-28 12:41:53.076513: Epoch 987 
2025-08-28 12:41:53.082673: Current learning rate: 0.0002 
2025-08-28 12:42:09.441462: train_loss -0.4518 
2025-08-28 12:42:09.453352: val_loss -0.454 
2025-08-28 12:42:09.457806: Pseudo dice [np.float32(0.7149)] 
2025-08-28 12:42:09.463836: Epoch time: 16.38 s 
2025-08-28 12:42:10.195337:  
2025-08-28 12:42:10.204049: Epoch 988 
2025-08-28 12:42:10.209329: Current learning rate: 0.00019 
2025-08-28 12:42:26.528694: train_loss -0.4603 
2025-08-28 12:42:26.537015: val_loss -0.5006 
2025-08-28 12:42:26.545415: Pseudo dice [np.float32(0.7831)] 
2025-08-28 12:42:26.551747: Epoch time: 16.34 s 
2025-08-28 12:42:26.557845: Yayy! New best EMA pseudo Dice: 0.7451000213623047 
2025-08-28 12:42:27.474324:  
2025-08-28 12:42:27.484186: Epoch 989 
2025-08-28 12:42:27.489555: Current learning rate: 0.00017 
2025-08-28 12:42:43.437428: train_loss -0.4337 
2025-08-28 12:42:43.445577: val_loss -0.5083 
2025-08-28 12:42:43.453959: Pseudo dice [np.float32(0.7222)] 
2025-08-28 12:42:43.459376: Epoch time: 15.96 s 
2025-08-28 12:42:44.315580:  
2025-08-28 12:42:44.323180: Epoch 990 
2025-08-28 12:42:44.331514: Current learning rate: 0.00016 
2025-08-28 12:43:00.199414: train_loss -0.4393 
2025-08-28 12:43:00.208164: val_loss -0.4692 
2025-08-28 12:43:00.212332: Pseudo dice [np.float32(0.7338)] 
2025-08-28 12:43:00.218649: Epoch time: 15.89 s 
2025-08-28 12:43:00.935903:  
2025-08-28 12:43:00.945321: Epoch 991 
2025-08-28 12:43:00.952641: Current learning rate: 0.00014 
2025-08-28 12:43:17.108397: train_loss -0.4764 
2025-08-28 12:43:17.120871: val_loss -0.4456 
2025-08-28 12:43:17.125349: Pseudo dice [np.float32(0.7118)] 
2025-08-28 12:43:17.132380: Epoch time: 16.17 s 
2025-08-28 12:43:17.867806:  
2025-08-28 12:43:17.876926: Epoch 992 
2025-08-28 12:43:17.885371: Current learning rate: 0.00013 
2025-08-28 12:43:33.695924: train_loss -0.4622 
2025-08-28 12:43:33.704103: val_loss -0.403 
2025-08-28 12:43:33.708262: Pseudo dice [np.float32(0.7339)] 
2025-08-28 12:43:33.718015: Epoch time: 15.83 s 
2025-08-28 12:43:34.428719:  
2025-08-28 12:43:34.436015: Epoch 993 
2025-08-28 12:43:34.441156: Current learning rate: 0.00011 
2025-08-28 12:43:50.721128: train_loss -0.4549 
2025-08-28 12:43:50.729445: val_loss -0.485 
2025-08-28 12:43:50.733602: Pseudo dice [np.float32(0.7807)] 
2025-08-28 12:43:50.742669: Epoch time: 16.29 s 
2025-08-28 12:43:51.452696:  
2025-08-28 12:43:51.461304: Epoch 994 
2025-08-28 12:43:51.468103: Current learning rate: 0.0001 
2025-08-28 12:44:07.567085: train_loss -0.4394 
2025-08-28 12:44:07.575427: val_loss -0.4002 
2025-08-28 12:44:07.584026: Pseudo dice [np.float32(0.7185)] 
2025-08-28 12:44:07.589255: Epoch time: 16.12 s 
2025-08-28 12:44:08.311028:  
2025-08-28 12:44:08.321881: Epoch 995 
2025-08-28 12:44:08.327837: Current learning rate: 8e-05 
2025-08-28 12:44:24.821816: train_loss -0.4425 
2025-08-28 12:44:24.830164: val_loss -0.4417 
2025-08-28 12:44:24.834332: Pseudo dice [np.float32(0.7211)] 
2025-08-28 12:44:24.840695: Epoch time: 16.51 s 
2025-08-28 12:44:25.563171:  
2025-08-28 12:44:25.571440: Epoch 996 
2025-08-28 12:44:25.577753: Current learning rate: 7e-05 
2025-08-28 12:44:41.822113: train_loss -0.4407 
2025-08-28 12:44:41.834872: val_loss -0.4502 
2025-08-28 12:44:41.840091: Pseudo dice [np.float32(0.7473)] 
2025-08-28 12:44:41.847127: Epoch time: 16.26 s 
2025-08-28 12:44:42.734339:  
2025-08-28 12:44:42.743348: Epoch 997 
2025-08-28 12:44:42.750088: Current learning rate: 5e-05 
2025-08-28 12:44:58.855789: train_loss -0.4523 
2025-08-28 12:44:58.864145: val_loss -0.4858 
2025-08-28 12:44:58.868325: Pseudo dice [np.float32(0.7775)] 
2025-08-28 12:44:58.876621: Epoch time: 16.12 s 
2025-08-28 12:44:59.581496:  
2025-08-28 12:44:59.590216: Epoch 998 
2025-08-28 12:44:59.594327: Current learning rate: 4e-05 
2025-08-28 12:45:15.547642: train_loss -0.4535 
2025-08-28 12:45:15.560056: val_loss -0.4766 
2025-08-28 12:45:15.564415: Pseudo dice [np.float32(0.7297)] 
2025-08-28 12:45:15.572590: Epoch time: 15.97 s 
2025-08-28 12:45:16.272087:  
2025-08-28 12:45:16.280348: Epoch 999 
2025-08-28 12:45:16.285519: Current learning rate: 2e-05 
2025-08-28 12:45:32.356110: train_loss -0.4357 
2025-08-28 12:45:32.364290: val_loss -0.4482 
2025-08-28 12:45:32.372611: Pseudo dice [np.float32(0.6821)] 
2025-08-28 12:45:32.378950: Epoch time: 16.09 s 
2025-08-28 12:45:33.367326: Training done. 
2025-08-28 12:45:33.621581: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 12:45:33.646042: The split file contains 5 splits. 
2025-08-28 12:45:33.658211: Desired fold for training: 2 
2025-08-28 12:45:33.669955: This split has 524 training and 131 validation cases. 
2025-08-28 12:45:33.683009: predicting sub-r001s013 
2025-08-28 12:45:33.970072: sub-r001s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:45:43.801021: predicting sub-r001s017 
2025-08-28 12:45:44.030079: sub-r001s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:45:54.573803: predicting sub-r001s018 
2025-08-28 12:45:54.823899: sub-r001s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:05.130311: predicting sub-r001s020 
2025-08-28 12:46:05.338886: sub-r001s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:15.982752: predicting sub-r001s031 
2025-08-28 12:46:16.237267: sub-r001s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:26.126337: predicting sub-r001s032 
2025-08-28 12:46:26.330645: sub-r001s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:36.870330: predicting sub-r002s001 
2025-08-28 12:46:37.091408: sub-r002s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:47.038821: predicting sub-r002s004 
2025-08-28 12:46:47.303862: sub-r002s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:46:59.167593: predicting sub-r003s001 
2025-08-28 12:46:59.413683: sub-r003s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:47:11.066971: predicting sub-r003s002 
2025-08-28 12:47:11.375542: sub-r003s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:47:22.248871: predicting sub-r003s011 
2025-08-28 12:47:22.549293: sub-r003s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:47:31.783480: predicting sub-r003s015 
2025-08-28 12:47:32.046264: sub-r003s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:47:41.388904: predicting sub-r004s007 
2025-08-28 12:47:41.660028: sub-r004s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:47:50.956814: predicting sub-r004s009 
2025-08-28 12:47:51.227976: sub-r004s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:01.271270: predicting sub-r004s024 
2025-08-28 12:48:01.534046: sub-r004s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:11.844326: predicting sub-r005s015 
2025-08-28 12:48:12.094882: sub-r005s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:21.941915: predicting sub-r005s026 
2025-08-28 12:48:22.204728: sub-r005s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:32.790268: predicting sub-r005s070 
2025-08-28 12:48:33.086403: sub-r005s070, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:42.462353: predicting sub-r009s009 
2025-08-28 12:48:42.746264: sub-r009s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:48:52.902177: predicting sub-r009s013 
2025-08-28 12:48:53.189769: sub-r009s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:02.336404: predicting sub-r009s018 
2025-08-28 12:49:02.615873: sub-r009s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:12.567462: predicting sub-r009s036 
2025-08-28 12:49:12.855252: sub-r009s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:22.026790: predicting sub-r009s041 
2025-08-28 12:49:22.323039: sub-r009s041, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:32.495713: predicting sub-r009s045 
2025-08-28 12:49:32.804338: sub-r009s045, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:42.013561: predicting sub-r009s046 
2025-08-28 12:49:42.288815: sub-r009s046, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:49:52.282103: predicting sub-r009s055 
2025-08-28 12:49:52.553240: sub-r009s055, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:01.883695: predicting sub-r009s072 
2025-08-28 12:50:02.150321: sub-r009s072, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:12.627469: predicting sub-r009s086 
2025-08-28 12:50:12.902751: sub-r009s086, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:22.149456: predicting sub-r009s093 
2025-08-28 12:50:22.420280: sub-r009s093, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:31.963394: predicting sub-r009s096 
2025-08-28 12:50:32.213741: sub-r009s096, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:41.581352: predicting sub-r009s097 
2025-08-28 12:50:41.860811: sub-r009s097, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:50:51.716473: predicting sub-r009s099 
2025-08-28 12:50:51.995960: sub-r009s099, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:01.509579: predicting sub-r009s105 
2025-08-28 12:51:01.784904: sub-r009s105, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:12.307882: predicting sub-r009s109 
2025-08-28 12:51:12.570624: sub-r009s109, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:22.059407: predicting sub-r009s111 
2025-08-28 12:51:22.330368: sub-r009s111, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:31.548169: predicting sub-r009s114 
2025-08-28 12:51:31.827350: sub-r009s114, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:41.537129: predicting sub-r009s125 
2025-08-28 12:51:41.812380: sub-r009s125, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:51:51.551212: predicting sub-r009s126 
2025-08-28 12:51:51.830666: sub-r009s126, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:01.744736: predicting sub-r010s004 
2025-08-28 12:52:02.028350: sub-r010s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:12.113437: predicting sub-r010s007 
2025-08-28 12:52:12.392847: sub-r010s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:21.656269: predicting sub-r010s018 
2025-08-28 12:52:21.923205: sub-r010s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:31.962401: predicting sub-r010s019 
2025-08-28 12:52:32.246205: sub-r010s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:41.597016: predicting sub-r010s023 
2025-08-28 12:52:41.872538: sub-r010s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:52:52.228567: predicting sub-r010s026 
2025-08-28 12:52:52.491239: sub-r010s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:02.167556: predicting sub-r011s008 
2025-08-28 12:53:02.426164: sub-r011s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:12.390258: predicting sub-r011s021 
2025-08-28 12:53:12.657228: sub-r011s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:22.145999: predicting sub-r011s023 
2025-08-28 12:53:22.417240: sub-r011s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:31.609470: predicting sub-r011s025 
2025-08-28 12:53:31.893097: sub-r011s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:41.410953: predicting sub-r011s027 
2025-08-28 12:53:41.694533: sub-r011s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:53:51.170647: predicting sub-r011s031 
2025-08-28 12:53:51.437616: sub-r011s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:00.834463: predicting sub-r015s006 
2025-08-28 12:54:01.113923: sub-r015s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:11.161438: predicting sub-r015s010 
2025-08-28 12:54:11.428412: sub-r015s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:20.846095: predicting sub-r015s019 
2025-08-28 12:54:21.133922: sub-r015s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:30.685117: predicting sub-r017s106 
2025-08-28 12:54:30.956227: sub-r017s106, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:40.382272: predicting sub-r017s110 
2025-08-28 12:54:40.657596: sub-r017s110, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:54:50.821034: predicting sub-r019s007 
2025-08-28 12:54:51.105497: sub-r019s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:00.606632: predicting sub-r019s012 
2025-08-28 12:55:00.877770: sub-r019s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:10.020414: predicting sub-r023s007 
2025-08-28 12:55:10.278809: sub-r023s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:19.917624: predicting sub-r023s017 
2025-08-28 12:55:20.188781: sub-r023s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:29.981813: predicting sub-r024s013 
2025-08-28 12:55:30.257101: sub-r024s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:39.783434: predicting sub-r024s014 
2025-08-28 12:55:40.041865: sub-r024s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:49.864192: predicting sub-r024s021 
2025-08-28 12:55:50.139442: sub-r024s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:55:59.774051: predicting sub-r027s013 
2025-08-28 12:56:00.036883: sub-r027s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:09.880383: predicting sub-r027s015 
2025-08-28 12:56:10.138598: sub-r027s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:20.010945: predicting sub-r027s017 
2025-08-28 12:56:20.273450: sub-r027s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:30.187753: predicting sub-r027s023 
2025-08-28 12:56:30.454706: sub-r027s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:39.814038: predicting sub-r027s047 
2025-08-28 12:56:40.081004: sub-r027s047, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:49.882462: predicting sub-r027s052 
2025-08-28 12:56:50.182728: sub-r027s052, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:56:59.625543: predicting sub-r028s005 
2025-08-28 12:56:59.892470: sub-r028s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:09.881558: predicting sub-r028s007 
2025-08-28 12:57:10.144343: sub-r028s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:19.566654: predicting sub-r028s008 
2025-08-28 12:57:19.883682: sub-r028s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:29.075869: predicting sub-r028s011 
2025-08-28 12:57:29.367717: sub-r028s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:38.860497: predicting sub-r028s014 
2025-08-28 12:57:39.139793: sub-r028s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:48.887254: predicting sub-r028s020 
2025-08-28 12:57:49.158618: sub-r028s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:57:58.417403: predicting sub-r029s003 
2025-08-28 12:57:58.688718: sub-r029s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:07.718778: predicting sub-r031s009 
2025-08-28 12:58:07.977136: sub-r031s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:17.641227: predicting sub-r031s014 
2025-08-28 12:58:17.920630: sub-r031s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:27.646921: predicting sub-r031s023 
2025-08-28 12:58:27.926167: sub-r031s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:37.285811: predicting sub-r031s025 
2025-08-28 12:58:37.535812: sub-r031s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:47.537501: predicting sub-r031s028 
2025-08-28 12:58:47.804752: sub-r031s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:58:57.268189: predicting sub-r034s003 
2025-08-28 12:58:57.534909: sub-r034s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:07.594970: predicting sub-r034s012 
2025-08-28 12:59:07.882742: sub-r034s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:17.588247: predicting sub-r034s022 
2025-08-28 12:59:17.871873: sub-r034s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:28.007042: predicting sub-r034s026 
2025-08-28 12:59:28.282275: sub-r034s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:38.146527: predicting sub-r034s033 
2025-08-28 12:59:38.442421: sub-r034s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:48.456578: predicting sub-r034s040 
2025-08-28 12:59:48.715420: sub-r034s040, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 12:59:58.366484: predicting sub-r034s047 
2025-08-28 12:59:58.637629: sub-r034s047, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:08.639262: predicting sub-r038s006 
2025-08-28 13:00:08.910349: sub-r038s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:19.183383: predicting sub-r038s016 
2025-08-28 13:00:19.445868: sub-r038s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:28.901386: predicting sub-r038s017 
2025-08-28 13:00:29.197250: sub-r038s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:38.919483: predicting sub-r038s018 
2025-08-28 13:00:39.186424: sub-r038s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:48.399797: predicting sub-r038s028 
2025-08-28 13:00:48.666698: sub-r038s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:00:57.938657: predicting sub-r038s033 
2025-08-28 13:00:58.201219: sub-r038s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:07.585593: predicting sub-r038s041 
2025-08-28 13:01:07.844180: sub-r038s041, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:17.554086: predicting sub-r038s043 
2025-08-28 13:01:17.824713: sub-r038s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:26.921567: predicting sub-r038s048 
2025-08-28 13:01:27.192718: sub-r038s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:37.707246: predicting sub-r038s056 
2025-08-28 13:01:37.970151: sub-r038s056, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:47.934197: predicting sub-r038s064 
2025-08-28 13:01:48.196985: sub-r038s064, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:01:58.035954: predicting sub-r038s068 
2025-08-28 13:01:58.319599: sub-r038s068, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:07.557972: predicting sub-r038s084 
2025-08-28 13:02:07.808230: sub-r038s084, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:17.346941: predicting sub-r039s003 
2025-08-28 13:02:17.638897: sub-r039s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:27.636379: predicting sub-r040s011 
2025-08-28 13:02:27.916055: sub-r040s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:37.266768: predicting sub-r040s015 
2025-08-28 13:02:37.537942: sub-r040s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:46.642853: predicting sub-r040s028 
2025-08-28 13:02:46.893141: sub-r040s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:02:56.436183: predicting sub-r040s030 
2025-08-28 13:02:56.702898: sub-r040s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:06.054153: predicting sub-r040s032 
2025-08-28 13:03:06.325015: sub-r040s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:16.108090: predicting sub-r040s069 
2025-08-28 13:03:16.364205: sub-r040s069, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:26.174283: predicting sub-r040s071 
2025-08-28 13:03:26.440916: sub-r040s071, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:35.992149: predicting sub-r040s076 
2025-08-28 13:03:36.250704: sub-r040s076, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:45.768555: predicting sub-r042s015 
2025-08-28 13:03:46.031309: sub-r042s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:03:55.320007: predicting sub-r045s003 
2025-08-28 13:03:55.586691: sub-r045s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:05.580227: predicting sub-r046s001 
2025-08-28 13:04:05.843175: sub-r046s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:16.290693: predicting sub-r047s015 
2025-08-28 13:04:16.565985: sub-r047s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:25.562450: predicting sub-r047s017 
2025-08-28 13:04:25.825279: sub-r047s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:35.580793: predicting sub-r047s026 
2025-08-28 13:04:35.831052: sub-r047s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:44.823262: predicting sub-r047s037 
2025-08-28 13:04:45.090286: sub-r047s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:04:54.945962: predicting sub-r048s002 
2025-08-28 13:04:55.200458: sub-r048s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:04.435135: predicting sub-r048s008 
2025-08-28 13:05:04.705706: sub-r048s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:15.078554: predicting sub-r048s012 
2025-08-28 13:05:15.349692: sub-r048s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:24.387840: predicting sub-r048s035 
2025-08-28 13:05:24.654860: sub-r048s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:34.810804: predicting sub-r048s036 
2025-08-28 13:05:35.065181: sub-r048s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:44.236834: predicting sub-r048s038 
2025-08-28 13:05:44.499858: sub-r048s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:05:54.276031: predicting sub-r049s011 
2025-08-28 13:05:54.538851: sub-r049s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:03.889827: predicting sub-r049s012 
2025-08-28 13:06:04.148564: sub-r049s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:14.250159: predicting sub-r049s016 
2025-08-28 13:06:14.521306: sub-r049s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:23.388676: predicting sub-r049s025 
2025-08-28 13:06:23.667966: sub-r049s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:33.978190: predicting sub-r052s010 
2025-08-28 13:06:34.228493: sub-r052s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:44.184197: predicting sub-r052s011 
2025-08-28 13:06:44.455333: sub-r052s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:06:54.640484: predicting sub-r052s015 
2025-08-28 13:06:54.920302: sub-r052s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:07:04.145809: predicting sub-r052s021 
2025-08-28 13:07:04.421122: sub-r052s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:07:13.747064: predicting sub-r052s026 
2025-08-28 13:07:14.022353: sub-r052s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 13:07:32.232504: Validation complete 
2025-08-28 13:07:32.240546: Mean Validation Dice:  0.5053295619686535 
