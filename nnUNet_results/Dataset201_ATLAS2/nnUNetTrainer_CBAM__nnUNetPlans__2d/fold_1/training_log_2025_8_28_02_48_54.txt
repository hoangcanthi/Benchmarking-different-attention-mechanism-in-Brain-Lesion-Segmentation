
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-28 02:48:54.903422: do_dummy_2d_data_aug: False 
2025-08-28 02:48:54.907444: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 02:48:54.918074: The split file contains 5 splits. 
2025-08-28 02:48:54.922715: Desired fold for training: 1 
2025-08-28 02:48:54.928361: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-28 02:49:01.658726: Unable to plot network architecture: 
2025-08-28 02:49:01.667356: No module named 'hiddenlayer' 
2025-08-28 02:49:01.714593:  
2025-08-28 02:49:01.722380: Epoch 0 
2025-08-28 02:49:01.727056: Current learning rate: 0.01 
2025-08-28 02:49:17.075199: train_loss 0.0549 
2025-08-28 02:49:17.081347: val_loss 0.0041 
2025-08-28 02:49:17.088668: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:49:17.094922: Epoch time: 15.36 s 
2025-08-28 02:49:17.097986: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-28 02:49:17.742485:  
2025-08-28 02:49:17.748640: Epoch 1 
2025-08-28 02:49:17.755010: Current learning rate: 0.00999 
2025-08-28 02:49:31.531252: train_loss 0.0101 
2025-08-28 02:49:31.539606: val_loss -0.0006 
2025-08-28 02:49:31.547972: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:49:31.553881: Epoch time: 13.79 s 
2025-08-28 02:49:32.228893:  
2025-08-28 02:49:32.237240: Epoch 2 
2025-08-28 02:49:32.241525: Current learning rate: 0.00998 
2025-08-28 02:49:46.083466: train_loss 0.0136 
2025-08-28 02:49:46.091654: val_loss 0.0355 
2025-08-28 02:49:46.099964: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:49:46.104760: Epoch time: 13.85 s 
2025-08-28 02:49:46.714191:  
2025-08-28 02:49:46.721407: Epoch 3 
2025-08-28 02:49:46.726728: Current learning rate: 0.00997 
2025-08-28 02:50:01.744914: train_loss 0.0155 
2025-08-28 02:50:01.753177: val_loss 0.0004 
2025-08-28 02:50:01.761433: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:50:01.766339: Epoch time: 15.03 s 
2025-08-28 02:50:02.358962:  
2025-08-28 02:50:02.367265: Epoch 4 
2025-08-28 02:50:02.371419: Current learning rate: 0.00996 
2025-08-28 02:50:18.927962: train_loss 0.0007 
2025-08-28 02:50:18.933131: val_loss 0.0319 
2025-08-28 02:50:18.941237: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:50:18.946654: Epoch time: 16.57 s 
2025-08-28 02:50:19.587620:  
2025-08-28 02:50:19.592852: Epoch 5 
2025-08-28 02:50:19.600373: Current learning rate: 0.00995 
2025-08-28 02:50:34.709263: train_loss -0.0006 
2025-08-28 02:50:34.719191: val_loss -0.0318 
2025-08-28 02:50:34.723599: Pseudo dice [np.float32(0.0)] 
2025-08-28 02:50:34.730284: Epoch time: 15.12 s 
2025-08-28 02:50:35.308511:  
2025-08-28 02:50:35.316850: Epoch 6 
2025-08-28 02:50:35.320947: Current learning rate: 0.00995 
2025-08-28 02:50:50.101367: train_loss -0.0265 
2025-08-28 02:50:50.109729: val_loss -0.069 
2025-08-28 02:50:50.118063: Pseudo dice [np.float32(0.2386)] 
2025-08-28 02:50:50.123769: Epoch time: 14.79 s 
2025-08-28 02:50:50.128388: Yayy! New best EMA pseudo Dice: 0.023900000378489494 
2025-08-28 02:50:50.890775:  
2025-08-28 02:50:50.898006: Epoch 7 
2025-08-28 02:50:50.903257: Current learning rate: 0.00994 
2025-08-28 02:51:06.184405: train_loss -0.031 
2025-08-28 02:51:06.192423: val_loss -0.0851 
2025-08-28 02:51:06.196595: Pseudo dice [np.float32(0.2822)] 
2025-08-28 02:51:06.205608: Epoch time: 15.3 s 
2025-08-28 02:51:06.208444: Yayy! New best EMA pseudo Dice: 0.04969999939203262 
2025-08-28 02:51:06.972374:  
2025-08-28 02:51:06.977638: Epoch 8 
2025-08-28 02:51:06.981795: Current learning rate: 0.00993 
2025-08-28 02:51:22.112435: train_loss -0.0258 
2025-08-28 02:51:22.120828: val_loss -0.0327 
2025-08-28 02:51:22.124996: Pseudo dice [np.float32(0.1259)] 
2025-08-28 02:51:22.133356: Epoch time: 15.14 s 
2025-08-28 02:51:22.137865: Yayy! New best EMA pseudo Dice: 0.05730000138282776 
2025-08-28 02:51:22.906024:  
2025-08-28 02:51:22.914377: Epoch 9 
2025-08-28 02:51:22.918543: Current learning rate: 0.00992 
2025-08-28 02:51:37.941427: train_loss -0.0292 
2025-08-28 02:51:37.949152: val_loss -0.1042 
2025-08-28 02:51:37.953199: Pseudo dice [np.float32(0.3745)] 
2025-08-28 02:51:37.962001: Epoch time: 15.04 s 
2025-08-28 02:51:37.966221: Yayy! New best EMA pseudo Dice: 0.08900000154972076 
2025-08-28 02:51:38.717685:  
2025-08-28 02:51:38.725998: Epoch 10 
2025-08-28 02:51:38.730111: Current learning rate: 0.00991 
2025-08-28 02:51:53.573315: train_loss -0.0395 
2025-08-28 02:51:53.586408: val_loss -0.1249 
2025-08-28 02:51:53.593819: Pseudo dice [np.float32(0.2737)] 
2025-08-28 02:51:53.601482: Epoch time: 14.86 s 
2025-08-28 02:51:53.606769: Yayy! New best EMA pseudo Dice: 0.10750000178813934 
2025-08-28 02:51:54.362458:  
2025-08-28 02:51:54.370778: Epoch 11 
2025-08-28 02:51:54.374951: Current learning rate: 0.0099 
2025-08-28 02:52:09.231093: train_loss -0.0108 
2025-08-28 02:52:09.239057: val_loss -0.0223 
2025-08-28 02:52:09.243151: Pseudo dice [np.float32(0.1582)] 
2025-08-28 02:52:09.252511: Epoch time: 14.87 s 
2025-08-28 02:52:09.255784: Yayy! New best EMA pseudo Dice: 0.11259999871253967 
2025-08-28 02:52:10.028074:  
2025-08-28 02:52:10.032235: Epoch 12 
2025-08-28 02:52:10.039492: Current learning rate: 0.00989 
2025-08-28 02:52:24.808964: train_loss -0.0037 
2025-08-28 02:52:24.816745: val_loss -0.0427 
2025-08-28 02:52:24.821181: Pseudo dice [np.float32(0.1272)] 
2025-08-28 02:52:24.830470: Epoch time: 14.78 s 
2025-08-28 02:52:24.836127: Yayy! New best EMA pseudo Dice: 0.11400000005960464 
2025-08-28 02:52:25.593631:  
2025-08-28 02:52:25.601957: Epoch 13 
2025-08-28 02:52:25.606056: Current learning rate: 0.00988 
2025-08-28 02:52:40.445207: train_loss -0.0241 
2025-08-28 02:52:40.453191: val_loss -0.0183 
2025-08-28 02:52:40.457364: Pseudo dice [np.float32(0.0741)] 
2025-08-28 02:52:40.465091: Epoch time: 14.85 s 
2025-08-28 02:52:41.213320:  
2025-08-28 02:52:41.217531: Epoch 14 
2025-08-28 02:52:41.224736: Current learning rate: 0.00987 
2025-08-28 02:52:56.598478: train_loss -0.0068 
2025-08-28 02:52:56.606836: val_loss -0.0144 
2025-08-28 02:52:56.615156: Pseudo dice [np.float32(0.076)] 
2025-08-28 02:52:56.620838: Epoch time: 15.39 s 
2025-08-28 02:52:57.237709:  
2025-08-28 02:52:57.244967: Epoch 15 
2025-08-28 02:52:57.249149: Current learning rate: 0.00986 
2025-08-28 02:53:12.305842: train_loss -0.0158 
2025-08-28 02:53:12.314178: val_loss -0.0486 
2025-08-28 02:53:12.318351: Pseudo dice [np.float32(0.1166)] 
2025-08-28 02:53:12.326222: Epoch time: 15.07 s 
2025-08-28 02:53:12.932569:  
2025-08-28 02:53:12.940882: Epoch 16 
2025-08-28 02:53:12.945120: Current learning rate: 0.00986 
2025-08-28 02:53:28.292646: train_loss -0.0163 
2025-08-28 02:53:28.300952: val_loss -0.0193 
2025-08-28 02:53:28.305131: Pseudo dice [np.float32(0.0808)] 
2025-08-28 02:53:28.311862: Epoch time: 15.36 s 
2025-08-28 02:53:28.923510:  
2025-08-28 02:53:28.931860: Epoch 17 
2025-08-28 02:53:28.935988: Current learning rate: 0.00985 
2025-08-28 02:53:44.316951: train_loss -0.0176 
2025-08-28 02:53:44.325294: val_loss -0.0369 
2025-08-28 02:53:44.333657: Pseudo dice [np.float32(0.106)] 
2025-08-28 02:53:44.339634: Epoch time: 15.39 s 
2025-08-28 02:53:44.989538:  
2025-08-28 02:53:45.000991: Epoch 18 
2025-08-28 02:53:45.005161: Current learning rate: 0.00984 
2025-08-28 02:54:00.161932: train_loss -0.0212 
2025-08-28 02:54:00.172220: val_loss -0.0156 
2025-08-28 02:54:00.174638: Pseudo dice [np.float32(0.0594)] 
2025-08-28 02:54:00.184320: Epoch time: 15.17 s 
2025-08-28 02:54:00.813699:  
2025-08-28 02:54:00.822035: Epoch 19 
2025-08-28 02:54:00.826156: Current learning rate: 0.00983 
2025-08-28 02:54:15.819506: train_loss -0.0118 
2025-08-28 02:54:15.827530: val_loss -0.0298 
2025-08-28 02:54:15.831922: Pseudo dice [np.float32(0.1245)] 
2025-08-28 02:54:15.842089: Epoch time: 15.01 s 
2025-08-28 02:54:16.608626:  
2025-08-28 02:54:16.615877: Epoch 20 
2025-08-28 02:54:16.621157: Current learning rate: 0.00982 
2025-08-28 02:54:33.253636: train_loss -0.0185 
2025-08-28 02:54:33.261960: val_loss -0.04 
2025-08-28 02:54:33.266090: Pseudo dice [np.float32(0.1049)] 
2025-08-28 02:54:33.273085: Epoch time: 16.65 s 
2025-08-28 02:54:33.921678:  
2025-08-28 02:54:33.929007: Epoch 21 
2025-08-28 02:54:33.933175: Current learning rate: 0.00981 
2025-08-28 02:54:50.729131: train_loss -0.0255 
2025-08-28 02:54:50.741623: val_loss -0.0369 
2025-08-28 02:54:50.745791: Pseudo dice [np.float32(0.1098)] 
2025-08-28 02:54:50.752641: Epoch time: 16.81 s 
2025-08-28 02:54:51.379754:  
2025-08-28 02:54:51.385016: Epoch 22 
2025-08-28 02:54:51.392284: Current learning rate: 0.0098 
2025-08-28 02:55:07.721121: train_loss -0.0238 
2025-08-28 02:55:07.729401: val_loss -0.0524 
2025-08-28 02:55:07.733575: Pseudo dice [np.float32(0.112)] 
2025-08-28 02:55:07.740764: Epoch time: 16.34 s 
2025-08-28 02:55:08.368611:  
2025-08-28 02:55:08.376987: Epoch 23 
2025-08-28 02:55:08.381127: Current learning rate: 0.00979 
2025-08-28 02:55:24.905208: train_loss -0.034 
2025-08-28 02:55:24.913552: val_loss -0.0324 
2025-08-28 02:55:24.921443: Pseudo dice [np.float32(0.1013)] 
2025-08-28 02:55:24.926427: Epoch time: 16.54 s 
2025-08-28 02:55:25.544080:  
2025-08-28 02:55:25.552490: Epoch 24 
2025-08-28 02:55:25.556635: Current learning rate: 0.00978 
2025-08-28 02:55:41.817698: train_loss -0.0253 
2025-08-28 02:55:41.826043: val_loss -0.054 
2025-08-28 02:55:41.830219: Pseudo dice [np.float32(0.1025)] 
2025-08-28 02:55:41.838847: Epoch time: 16.27 s 
2025-08-28 02:55:42.606963:  
2025-08-28 02:55:42.614260: Epoch 25 
2025-08-28 02:55:42.619513: Current learning rate: 0.00977 
2025-08-28 02:55:59.426865: train_loss -0.0168 
2025-08-28 02:55:59.439361: val_loss -0.0314 
2025-08-28 02:55:59.443832: Pseudo dice [np.float32(0.0846)] 
2025-08-28 02:55:59.451924: Epoch time: 16.82 s 
2025-08-28 02:56:00.081698:  
2025-08-28 02:56:00.086974: Epoch 26 
2025-08-28 02:56:00.094224: Current learning rate: 0.00977 
2025-08-28 02:56:16.869363: train_loss -0.0157 
2025-08-28 02:56:16.877619: val_loss -0.0341 
2025-08-28 02:56:16.882099: Pseudo dice [np.float32(0.1191)] 
2025-08-28 02:56:16.889178: Epoch time: 16.79 s 
2025-08-28 02:56:17.670066:  
2025-08-28 02:56:17.675324: Epoch 27 
2025-08-28 02:56:17.682596: Current learning rate: 0.00976 
2025-08-28 02:56:34.491594: train_loss -0.0313 
2025-08-28 02:56:34.499377: val_loss -0.0501 
2025-08-28 02:56:34.507751: Pseudo dice [np.float32(0.0921)] 
2025-08-28 02:56:34.512422: Epoch time: 16.82 s 
2025-08-28 02:56:35.163578:  
2025-08-28 02:56:35.167835: Epoch 28 
2025-08-28 02:56:35.175064: Current learning rate: 0.00975 
2025-08-28 02:56:51.975153: train_loss -0.0303 
2025-08-28 02:56:51.983529: val_loss -0.0277 
2025-08-28 02:56:51.992617: Pseudo dice [np.float32(0.0786)] 
2025-08-28 02:56:51.996606: Epoch time: 16.82 s 
2025-08-28 02:56:52.627605:  
2025-08-28 02:56:52.635251: Epoch 29 
2025-08-28 02:56:52.639412: Current learning rate: 0.00974 
2025-08-28 02:57:09.409235: train_loss -0.0238 
2025-08-28 02:57:09.417841: val_loss -0.0305 
2025-08-28 02:57:09.422024: Pseudo dice [np.float32(0.0775)] 
2025-08-28 02:57:09.427369: Epoch time: 16.78 s 
2025-08-28 02:57:10.069626:  
2025-08-28 02:57:10.077650: Epoch 30 
2025-08-28 02:57:10.081892: Current learning rate: 0.00973 
2025-08-28 02:57:26.121794: train_loss -0.0206 
2025-08-28 02:57:26.130124: val_loss -0.0445 
2025-08-28 02:57:26.138442: Pseudo dice [np.float32(0.0876)] 
2025-08-28 02:57:26.144202: Epoch time: 16.05 s 
2025-08-28 02:57:26.777670:  
2025-08-28 02:57:26.786001: Epoch 31 
2025-08-28 02:57:26.790174: Current learning rate: 0.00972 
2025-08-28 02:57:42.835509: train_loss -0.0287 
2025-08-28 02:57:42.844073: val_loss -0.0252 
2025-08-28 02:57:42.849304: Pseudo dice [np.float32(0.0776)] 
2025-08-28 02:57:42.855545: Epoch time: 16.06 s 
2025-08-28 02:57:43.503402:  
2025-08-28 02:57:43.511032: Epoch 32 
2025-08-28 02:57:43.515195: Current learning rate: 0.00971 
2025-08-28 02:57:59.588794: train_loss -0.0171 
2025-08-28 02:57:59.601354: val_loss -0.0487 
2025-08-28 02:57:59.605492: Pseudo dice [np.float32(0.1137)] 
2025-08-28 02:57:59.611943: Epoch time: 16.09 s 
2025-08-28 02:58:00.407120:  
2025-08-28 02:58:00.414331: Epoch 33 
2025-08-28 02:58:00.418494: Current learning rate: 0.0097 
2025-08-28 02:58:17.259673: train_loss -0.02 
2025-08-28 02:58:17.264471: val_loss -0.0241 
2025-08-28 02:58:17.272821: Pseudo dice [np.float32(0.0857)] 
2025-08-28 02:58:17.277497: Epoch time: 16.86 s 
2025-08-28 02:58:17.928755:  
2025-08-28 02:58:17.935989: Epoch 34 
2025-08-28 02:58:17.941243: Current learning rate: 0.00969 
2025-08-28 02:58:34.089757: train_loss -0.0211 
2025-08-28 02:58:34.097953: val_loss -0.0064 
2025-08-28 02:58:34.106349: Pseudo dice [np.float32(0.0503)] 
2025-08-28 02:58:34.111958: Epoch time: 16.17 s 
2025-08-28 02:58:34.778969:  
2025-08-28 02:58:34.787310: Epoch 35 
2025-08-28 02:58:34.794689: Current learning rate: 0.00968 
2025-08-28 02:58:50.864802: train_loss -0.0273 
2025-08-28 02:58:50.877598: val_loss -0.0197 
2025-08-28 02:58:50.881405: Pseudo dice [np.float32(0.082)] 
2025-08-28 02:58:50.888574: Epoch time: 16.09 s 
2025-08-28 02:58:51.537299:  
2025-08-28 02:58:51.544566: Epoch 36 
2025-08-28 02:58:51.548710: Current learning rate: 0.00968 
2025-08-28 02:59:07.894545: train_loss -0.0341 
2025-08-28 02:59:07.902531: val_loss -0.0519 
2025-08-28 02:59:07.906940: Pseudo dice [np.float32(0.1018)] 
2025-08-28 02:59:07.915557: Epoch time: 16.36 s 
2025-08-28 02:59:08.570989:  
2025-08-28 02:59:08.579337: Epoch 37 
2025-08-28 02:59:08.583467: Current learning rate: 0.00967 
2025-08-28 02:59:24.627633: train_loss -0.0201 
2025-08-28 02:59:24.635922: val_loss -0.0598 
2025-08-28 02:59:24.640475: Pseudo dice [np.float32(0.115)] 
2025-08-28 02:59:24.648415: Epoch time: 16.06 s 
2025-08-28 02:59:25.309217:  
2025-08-28 02:59:25.316843: Epoch 38 
2025-08-28 02:59:25.321065: Current learning rate: 0.00966 
2025-08-28 02:59:41.707516: train_loss -0.0336 
2025-08-28 02:59:41.715487: val_loss -0.0293 
2025-08-28 02:59:41.719986: Pseudo dice [np.float32(0.0917)] 
2025-08-28 02:59:41.726760: Epoch time: 16.4 s 
2025-08-28 02:59:42.558991:  
2025-08-28 02:59:42.567400: Epoch 39 
2025-08-28 02:59:42.575755: Current learning rate: 0.00965 
2025-08-28 02:59:58.845407: train_loss -0.0299 
2025-08-28 02:59:58.857608: val_loss -0.053 
2025-08-28 02:59:58.861783: Pseudo dice [np.float32(0.1123)] 
2025-08-28 02:59:58.870108: Epoch time: 16.29 s 
2025-08-28 02:59:59.533244:  
2025-08-28 02:59:59.538558: Epoch 40 
2025-08-28 02:59:59.542687: Current learning rate: 0.00964 
2025-08-28 03:00:15.471449: train_loss -0.0278 
2025-08-28 03:00:15.478377: val_loss -0.0286 
2025-08-28 03:00:15.482889: Pseudo dice [np.float32(0.0684)] 
2025-08-28 03:00:15.490884: Epoch time: 15.94 s 
2025-08-28 03:00:16.162342:  
2025-08-28 03:00:16.167646: Epoch 41 
2025-08-28 03:00:16.174873: Current learning rate: 0.00963 
2025-08-28 03:00:32.153676: train_loss -0.0197 
2025-08-28 03:00:32.161690: val_loss -0.0575 
2025-08-28 03:00:32.170032: Pseudo dice [np.float32(0.1187)] 
2025-08-28 03:00:32.174724: Epoch time: 15.99 s 
2025-08-28 03:00:32.817565:  
2025-08-28 03:00:32.825909: Epoch 42 
2025-08-28 03:00:32.830036: Current learning rate: 0.00962 
2025-08-28 03:00:49.007630: train_loss -0.0273 
2025-08-28 03:00:49.016302: val_loss -0.0395 
2025-08-28 03:00:49.024636: Pseudo dice [np.float32(0.0952)] 
2025-08-28 03:00:49.031196: Epoch time: 16.19 s 
2025-08-28 03:00:49.668455:  
2025-08-28 03:00:49.676070: Epoch 43 
2025-08-28 03:00:49.680264: Current learning rate: 0.00961 
2025-08-28 03:01:05.982952: train_loss -0.0206 
2025-08-28 03:01:05.991359: val_loss -0.0293 
2025-08-28 03:01:05.995526: Pseudo dice [np.float32(0.0851)] 
2025-08-28 03:01:06.004287: Epoch time: 16.32 s 
2025-08-28 03:01:06.652208:  
2025-08-28 03:01:06.658644: Epoch 44 
2025-08-28 03:01:06.663862: Current learning rate: 0.0096 
2025-08-28 03:01:23.012413: train_loss -0.0268 
2025-08-28 03:01:23.024963: val_loss -0.0345 
2025-08-28 03:01:23.029135: Pseudo dice [np.float32(0.0961)] 
2025-08-28 03:01:23.035873: Epoch time: 16.36 s 
2025-08-28 03:01:23.681579:  
2025-08-28 03:01:23.689203: Epoch 45 
2025-08-28 03:01:23.693399: Current learning rate: 0.00959 
2025-08-28 03:01:40.212938: train_loss -0.0312 
2025-08-28 03:01:40.221369: val_loss -0.0568 
2025-08-28 03:01:40.225471: Pseudo dice [np.float32(0.1179)] 
2025-08-28 03:01:40.233141: Epoch time: 16.53 s 
2025-08-28 03:01:41.026277:  
2025-08-28 03:01:41.031589: Epoch 46 
2025-08-28 03:01:41.038920: Current learning rate: 0.00959 
2025-08-28 03:01:57.209524: train_loss -0.0363 
2025-08-28 03:01:57.217418: val_loss -0.0185 
2025-08-28 03:01:57.226125: Pseudo dice [np.float32(0.0548)] 
2025-08-28 03:01:57.232652: Epoch time: 16.19 s 
2025-08-28 03:01:57.877529:  
2025-08-28 03:01:57.886311: Epoch 47 
2025-08-28 03:01:57.889987: Current learning rate: 0.00958 
2025-08-28 03:02:14.430702: train_loss -0.0283 
2025-08-28 03:02:14.438785: val_loss -0.0479 
2025-08-28 03:02:14.447370: Pseudo dice [np.float32(0.1053)] 
2025-08-28 03:02:14.451820: Epoch time: 16.55 s 
2025-08-28 03:02:15.069697:  
2025-08-28 03:02:15.076955: Epoch 48 
2025-08-28 03:02:15.082186: Current learning rate: 0.00957 
2025-08-28 03:02:31.681005: train_loss -0.0281 
2025-08-28 03:02:31.693526: val_loss -0.0426 
2025-08-28 03:02:31.697699: Pseudo dice [np.float32(0.0788)] 
2025-08-28 03:02:31.704952: Epoch time: 16.61 s 
2025-08-28 03:02:32.337779:  
2025-08-28 03:02:32.345297: Epoch 49 
2025-08-28 03:02:32.349772: Current learning rate: 0.00956 
2025-08-28 03:02:49.127901: train_loss -0.0148 
2025-08-28 03:02:49.136279: val_loss -0.0347 
2025-08-28 03:02:49.144315: Pseudo dice [np.float32(0.0879)] 
2025-08-28 03:02:49.150010: Epoch time: 16.79 s 
2025-08-28 03:02:49.955458:  
2025-08-28 03:02:49.965792: Epoch 50 
2025-08-28 03:02:49.978789: Current learning rate: 0.00955 
2025-08-28 03:03:06.349219: train_loss -0.0306 
2025-08-28 03:03:06.357202: val_loss -0.0527 
2025-08-28 03:03:06.361688: Pseudo dice [np.float32(0.1007)] 
2025-08-28 03:03:06.369808: Epoch time: 16.4 s 
2025-08-28 03:03:06.996508:  
2025-08-28 03:03:07.004879: Epoch 51 
2025-08-28 03:03:07.009022: Current learning rate: 0.00954 
2025-08-28 03:03:23.970686: train_loss -0.0303 
2025-08-28 03:03:23.979355: val_loss -0.0482 
2025-08-28 03:03:23.983190: Pseudo dice [np.float32(0.0942)] 
2025-08-28 03:03:23.991498: Epoch time: 16.97 s 
2025-08-28 03:03:24.617207:  
2025-08-28 03:03:24.622484: Epoch 52 
2025-08-28 03:03:24.629729: Current learning rate: 0.00953 
2025-08-28 03:03:40.879498: train_loss -0.026 
2025-08-28 03:03:40.887834: val_loss -0.0349 
2025-08-28 03:03:40.895952: Pseudo dice [np.float32(0.0945)] 
2025-08-28 03:03:40.901699: Epoch time: 16.27 s 
2025-08-28 03:03:41.688383:  
2025-08-28 03:03:41.693643: Epoch 53 
2025-08-28 03:03:41.700948: Current learning rate: 0.00952 
2025-08-28 03:03:58.065362: train_loss -0.0273 
2025-08-28 03:03:58.075558: val_loss -0.0549 
2025-08-28 03:03:58.079980: Pseudo dice [np.float32(0.1065)] 
2025-08-28 03:03:58.088094: Epoch time: 16.38 s 
2025-08-28 03:03:58.744048:  
2025-08-28 03:03:58.752384: Epoch 54 
2025-08-28 03:03:58.756549: Current learning rate: 0.00951 
2025-08-28 03:04:15.430256: train_loss -0.0162 
2025-08-28 03:04:15.438627: val_loss -0.0426 
2025-08-28 03:04:15.443022: Pseudo dice [np.float32(0.0973)] 
2025-08-28 03:04:15.449673: Epoch time: 16.69 s 
2025-08-28 03:04:16.082157:  
2025-08-28 03:04:16.089386: Epoch 55 
2025-08-28 03:04:16.094650: Current learning rate: 0.0095 
2025-08-28 03:04:32.459933: train_loss -0.0231 
2025-08-28 03:04:32.468621: val_loss -0.0336 
2025-08-28 03:04:32.472717: Pseudo dice [np.float32(0.0992)] 
2025-08-28 03:04:32.481206: Epoch time: 16.38 s 
2025-08-28 03:04:33.107524:  
2025-08-28 03:04:33.115857: Epoch 56 
2025-08-28 03:04:33.120010: Current learning rate: 0.00949 
2025-08-28 03:04:49.823050: train_loss -0.0241 
2025-08-28 03:04:49.836790: val_loss -0.0504 
2025-08-28 03:04:49.842296: Pseudo dice [np.float32(0.1144)] 
2025-08-28 03:04:49.848069: Epoch time: 16.72 s 
2025-08-28 03:04:50.479705:  
2025-08-28 03:04:50.487350: Epoch 57 
2025-08-28 03:04:50.491529: Current learning rate: 0.00949 
2025-08-28 03:05:06.842695: train_loss -0.021 
2025-08-28 03:05:06.848774: val_loss -0.044 
2025-08-28 03:05:06.857147: Pseudo dice [np.float32(0.0901)] 
2025-08-28 03:05:06.862469: Epoch time: 16.36 s 
2025-08-28 03:05:07.503244:  
2025-08-28 03:05:07.511600: Epoch 58 
2025-08-28 03:05:07.516871: Current learning rate: 0.00948 
2025-08-28 03:05:24.478647: train_loss -0.0342 
2025-08-28 03:05:24.486889: val_loss -0.0817 
2025-08-28 03:05:24.491046: Pseudo dice [np.float32(0.1991)] 
2025-08-28 03:05:24.497824: Epoch time: 16.98 s 
2025-08-28 03:05:25.297097:  
2025-08-28 03:05:25.304358: Epoch 59 
2025-08-28 03:05:25.308561: Current learning rate: 0.00947 
2025-08-28 03:05:41.832256: train_loss -0.0753 
2025-08-28 03:05:41.843349: val_loss -0.0661 
2025-08-28 03:05:41.849677: Pseudo dice [np.float32(0.2223)] 
2025-08-28 03:05:41.854734: Epoch time: 16.54 s 
2025-08-28 03:05:41.857435: Yayy! New best EMA pseudo Dice: 0.11819999665021896 
2025-08-28 03:05:42.651933:  
2025-08-28 03:05:42.660300: Epoch 60 
2025-08-28 03:05:42.664455: Current learning rate: 0.00946 
2025-08-28 03:05:59.546875: train_loss -0.0782 
2025-08-28 03:05:59.555196: val_loss -0.0589 
2025-08-28 03:05:59.563571: Pseudo dice [np.float32(0.1757)] 
2025-08-28 03:05:59.568155: Epoch time: 16.89 s 
2025-08-28 03:05:59.574322: Yayy! New best EMA pseudo Dice: 0.12399999797344208 
2025-08-28 03:06:00.382096:  
2025-08-28 03:06:00.390432: Epoch 61 
2025-08-28 03:06:00.394673: Current learning rate: 0.00945 
2025-08-28 03:06:15.817948: train_loss -0.0672 
2025-08-28 03:06:15.825634: val_loss -0.069 
2025-08-28 03:06:15.832348: Pseudo dice [np.float32(0.1354)] 
2025-08-28 03:06:15.838489: Epoch time: 15.44 s 
2025-08-28 03:06:15.842767: Yayy! New best EMA pseudo Dice: 0.1251000016927719 
2025-08-28 03:06:16.630618:  
2025-08-28 03:06:16.635879: Epoch 62 
2025-08-28 03:06:16.643129: Current learning rate: 0.00944 
2025-08-28 03:06:33.434887: train_loss -0.0603 
2025-08-28 03:06:33.447454: val_loss -0.028 
2025-08-28 03:06:33.451598: Pseudo dice [np.float32(0.0898)] 
2025-08-28 03:06:33.458317: Epoch time: 16.81 s 
2025-08-28 03:06:34.107470:  
2025-08-28 03:06:34.114755: Epoch 63 
2025-08-28 03:06:34.120007: Current learning rate: 0.00943 
2025-08-28 03:06:50.352103: train_loss -0.0718 
2025-08-28 03:06:50.364543: val_loss -0.1203 
2025-08-28 03:06:50.368685: Pseudo dice [np.float32(0.2751)] 
2025-08-28 03:06:50.376776: Epoch time: 16.25 s 
2025-08-28 03:06:50.381431: Yayy! New best EMA pseudo Dice: 0.13689999282360077 
2025-08-28 03:06:51.191166:  
2025-08-28 03:06:51.199516: Epoch 64 
2025-08-28 03:06:51.203648: Current learning rate: 0.00942 
2025-08-28 03:07:07.736110: train_loss -0.0646 
2025-08-28 03:07:07.744151: val_loss -0.1012 
2025-08-28 03:07:07.752494: Pseudo dice [np.float32(0.2374)] 
2025-08-28 03:07:07.758307: Epoch time: 16.54 s 
2025-08-28 03:07:07.763965: Yayy! New best EMA pseudo Dice: 0.1469999998807907 
2025-08-28 03:07:08.725366:  
2025-08-28 03:07:08.732642: Epoch 65 
2025-08-28 03:07:08.737901: Current learning rate: 0.00941 
2025-08-28 03:07:24.838900: train_loss -0.0763 
2025-08-28 03:07:24.849216: val_loss -0.1535 
2025-08-28 03:07:24.853188: Pseudo dice [np.float32(0.3347)] 
2025-08-28 03:07:24.861568: Epoch time: 16.11 s 
2025-08-28 03:07:24.865750: Yayy! New best EMA pseudo Dice: 0.16580000519752502 
2025-08-28 03:07:25.667259:  
2025-08-28 03:07:25.675588: Epoch 66 
2025-08-28 03:07:25.682842: Current learning rate: 0.0094 
2025-08-28 03:07:42.070953: train_loss -0.0846 
2025-08-28 03:07:42.078756: val_loss -0.1233 
2025-08-28 03:07:42.082569: Pseudo dice [np.float32(0.2619)] 
2025-08-28 03:07:42.091338: Epoch time: 16.4 s 
2025-08-28 03:07:42.097539: Yayy! New best EMA pseudo Dice: 0.1754000037908554 
2025-08-28 03:07:42.904209:  
2025-08-28 03:07:42.909519: Epoch 67 
2025-08-28 03:07:42.916730: Current learning rate: 0.00939 
2025-08-28 03:07:59.825348: train_loss -0.0731 
2025-08-28 03:07:59.837739: val_loss -0.1125 
2025-08-28 03:07:59.843528: Pseudo dice [np.float32(0.2731)] 
2025-08-28 03:07:59.847811: Epoch time: 16.92 s 
2025-08-28 03:07:59.853286: Yayy! New best EMA pseudo Dice: 0.1851000040769577 
2025-08-28 03:08:00.656382:  
2025-08-28 03:08:00.663664: Epoch 68 
2025-08-28 03:08:00.669038: Current learning rate: 0.00939 
2025-08-28 03:08:17.230052: train_loss -0.1008 
2025-08-28 03:08:17.238497: val_loss -0.1346 
2025-08-28 03:08:17.242907: Pseudo dice [np.float32(0.3241)] 
2025-08-28 03:08:17.251358: Epoch time: 16.58 s 
2025-08-28 03:08:17.254250: Yayy! New best EMA pseudo Dice: 0.19900000095367432 
2025-08-28 03:08:18.076822:  
2025-08-28 03:08:18.082084: Epoch 69 
2025-08-28 03:08:18.090499: Current learning rate: 0.00938 
2025-08-28 03:08:34.134510: train_loss -0.1066 
2025-08-28 03:08:34.142867: val_loss -0.1319 
2025-08-28 03:08:34.147315: Pseudo dice [np.float32(0.2885)] 
2025-08-28 03:08:34.154316: Epoch time: 16.06 s 
2025-08-28 03:08:34.160757: Yayy! New best EMA pseudo Dice: 0.20800000429153442 
2025-08-28 03:08:34.986502:  
2025-08-28 03:08:34.995050: Epoch 70 
2025-08-28 03:08:35.003063: Current learning rate: 0.00937 
2025-08-28 03:08:51.101788: train_loss -0.1074 
2025-08-28 03:08:51.110076: val_loss -0.1258 
2025-08-28 03:08:51.118197: Pseudo dice [np.float32(0.2607)] 
2025-08-28 03:08:51.123884: Epoch time: 16.12 s 
2025-08-28 03:08:51.129375: Yayy! New best EMA pseudo Dice: 0.21320000290870667 
2025-08-28 03:08:51.970717:  
2025-08-28 03:08:51.978471: Epoch 71 
2025-08-28 03:08:51.982563: Current learning rate: 0.00936 
2025-08-28 03:09:08.106392: train_loss -0.1026 
2025-08-28 03:09:08.114285: val_loss -0.1066 
2025-08-28 03:09:08.118866: Pseudo dice [np.float32(0.2781)] 
2025-08-28 03:09:08.126682: Epoch time: 16.14 s 
2025-08-28 03:09:08.132199: Yayy! New best EMA pseudo Dice: 0.21969999372959137 
2025-08-28 03:09:08.944291:  
2025-08-28 03:09:08.949538: Epoch 72 
2025-08-28 03:09:08.957943: Current learning rate: 0.00935 
2025-08-28 03:09:25.715943: train_loss -0.0994 
2025-08-28 03:09:25.723534: val_loss -0.1152 
2025-08-28 03:09:25.731616: Pseudo dice [np.float32(0.2833)] 
2025-08-28 03:09:25.736413: Epoch time: 16.77 s 
2025-08-28 03:09:25.739243: Yayy! New best EMA pseudo Dice: 0.22609999775886536 
2025-08-28 03:09:26.596910:  
2025-08-28 03:09:26.604708: Epoch 73 
2025-08-28 03:09:26.614069: Current learning rate: 0.00934 
2025-08-28 03:09:42.615698: train_loss -0.101 
2025-08-28 03:09:42.623748: val_loss -0.1335 
2025-08-28 03:09:42.632080: Pseudo dice [np.float32(0.3045)] 
2025-08-28 03:09:42.637789: Epoch time: 16.02 s 
2025-08-28 03:09:42.643751: Yayy! New best EMA pseudo Dice: 0.23389999568462372 
2025-08-28 03:09:43.459602:  
2025-08-28 03:09:43.467343: Epoch 74 
2025-08-28 03:09:43.474631: Current learning rate: 0.00933 
2025-08-28 03:09:59.415449: train_loss -0.1108 
2025-08-28 03:09:59.423859: val_loss -0.0629 
2025-08-28 03:09:59.432229: Pseudo dice [np.float32(0.1319)] 
2025-08-28 03:09:59.438911: Epoch time: 15.96 s 
2025-08-28 03:10:00.105515:  
2025-08-28 03:10:00.113263: Epoch 75 
2025-08-28 03:10:00.120416: Current learning rate: 0.00932 
2025-08-28 03:10:16.507644: train_loss -0.0757 
2025-08-28 03:10:16.515924: val_loss -0.1188 
2025-08-28 03:10:16.520127: Pseudo dice [np.float32(0.2098)] 
2025-08-28 03:10:16.528438: Epoch time: 16.4 s 
2025-08-28 03:10:17.188882:  
2025-08-28 03:10:17.197009: Epoch 76 
2025-08-28 03:10:17.201057: Current learning rate: 0.00931 
2025-08-28 03:10:33.582084: train_loss -0.1013 
2025-08-28 03:10:33.587140: val_loss -0.134 
2025-08-28 03:10:33.595870: Pseudo dice [np.float32(0.2929)] 
2025-08-28 03:10:33.601286: Epoch time: 16.39 s 
2025-08-28 03:10:34.255927:  
2025-08-28 03:10:34.262843: Epoch 77 
2025-08-28 03:10:34.268097: Current learning rate: 0.0093 
2025-08-28 03:10:51.071632: train_loss -0.1198 
2025-08-28 03:10:51.084057: val_loss -0.1887 
2025-08-28 03:10:51.087924: Pseudo dice [np.float32(0.4367)] 
2025-08-28 03:10:51.095257: Epoch time: 16.82 s 
2025-08-28 03:10:51.100875: Yayy! New best EMA pseudo Dice: 0.2500999867916107 
2025-08-28 03:10:52.113963:  
2025-08-28 03:10:52.119225: Epoch 78 
2025-08-28 03:10:52.126480: Current learning rate: 0.0093 
2025-08-28 03:11:08.267869: train_loss -0.1023 
2025-08-28 03:11:08.275954: val_loss -0.0904 
2025-08-28 03:11:08.284370: Pseudo dice [np.float32(0.2607)] 
2025-08-28 03:11:08.290018: Epoch time: 16.16 s 
2025-08-28 03:11:08.295983: Yayy! New best EMA pseudo Dice: 0.25119999051094055 
2025-08-28 03:11:09.099025:  
2025-08-28 03:11:09.106098: Epoch 79 
2025-08-28 03:11:09.111222: Current learning rate: 0.00929 
2025-08-28 03:11:25.832514: train_loss -0.1078 
2025-08-28 03:11:25.840788: val_loss -0.124 
2025-08-28 03:11:25.847955: Pseudo dice [np.float32(0.2991)] 
2025-08-28 03:11:25.852377: Epoch time: 16.73 s 
2025-08-28 03:11:25.855403: Yayy! New best EMA pseudo Dice: 0.25600001215934753 
2025-08-28 03:11:26.675302:  
2025-08-28 03:11:26.682930: Epoch 80 
2025-08-28 03:11:26.687760: Current learning rate: 0.00928 
2025-08-28 03:11:42.197637: train_loss -0.1092 
2025-08-28 03:11:42.208809: val_loss -0.2047 
2025-08-28 03:11:42.214236: Pseudo dice [np.float32(0.3592)] 
2025-08-28 03:11:42.220694: Epoch time: 15.52 s 
2025-08-28 03:11:42.226465: Yayy! New best EMA pseudo Dice: 0.2662999927997589 
2025-08-28 03:11:43.037107:  
2025-08-28 03:11:43.045070: Epoch 81 
2025-08-28 03:11:43.049252: Current learning rate: 0.00927 
2025-08-28 03:11:59.590502: train_loss -0.1214 
2025-08-28 03:11:59.602501: val_loss -0.2199 
2025-08-28 03:11:59.606660: Pseudo dice [np.float32(0.451)] 
2025-08-28 03:11:59.613814: Epoch time: 16.55 s 
2025-08-28 03:11:59.619265: Yayy! New best EMA pseudo Dice: 0.2847999930381775 
2025-08-28 03:12:00.433267:  
2025-08-28 03:12:00.441586: Epoch 82 
2025-08-28 03:12:00.445795: Current learning rate: 0.00926 
2025-08-28 03:12:17.066535: train_loss -0.1274 
2025-08-28 03:12:17.073784: val_loss -0.2197 
2025-08-28 03:12:17.082164: Pseudo dice [np.float32(0.481)] 
2025-08-28 03:12:17.087952: Epoch time: 16.63 s 
2025-08-28 03:12:17.091949: Yayy! New best EMA pseudo Dice: 0.3043999969959259 
2025-08-28 03:12:17.882969:  
2025-08-28 03:12:17.888181: Epoch 83 
2025-08-28 03:12:17.895455: Current learning rate: 0.00925 
2025-08-28 03:12:34.783530: train_loss -0.1133 
2025-08-28 03:12:34.791522: val_loss -0.147 
2025-08-28 03:12:34.795755: Pseudo dice [np.float32(0.3571)] 
2025-08-28 03:12:34.802816: Epoch time: 16.9 s 
2025-08-28 03:12:34.809465: Yayy! New best EMA pseudo Dice: 0.30970001220703125 
2025-08-28 03:12:35.768590:  
2025-08-28 03:12:35.776891: Epoch 84 
2025-08-28 03:12:35.781052: Current learning rate: 0.00924 
2025-08-28 03:12:52.401297: train_loss -0.1488 
2025-08-28 03:12:52.413232: val_loss -0.1324 
2025-08-28 03:12:52.417637: Pseudo dice [np.float32(0.297)] 
2025-08-28 03:12:52.423050: Epoch time: 16.63 s 
2025-08-28 03:12:53.067947:  
2025-08-28 03:12:53.073321: Epoch 85 
2025-08-28 03:12:53.080617: Current learning rate: 0.00923 
2025-08-28 03:13:09.522007: train_loss -0.1377 
2025-08-28 03:13:09.530323: val_loss -0.2142 
2025-08-28 03:13:09.534488: Pseudo dice [np.float32(0.3941)] 
2025-08-28 03:13:09.541350: Epoch time: 16.46 s 
2025-08-28 03:13:09.547412: Yayy! New best EMA pseudo Dice: 0.31700000166893005 
2025-08-28 03:13:10.347646:  
2025-08-28 03:13:10.355149: Epoch 86 
2025-08-28 03:13:10.360312: Current learning rate: 0.00922 
2025-08-28 03:13:27.085526: train_loss -0.1383 
2025-08-28 03:13:27.093931: val_loss -0.1432 
2025-08-28 03:13:27.097870: Pseudo dice [np.float32(0.3162)] 
2025-08-28 03:13:27.107300: Epoch time: 16.74 s 
2025-08-28 03:13:27.777584:  
2025-08-28 03:13:27.787614: Epoch 87 
2025-08-28 03:13:27.795408: Current learning rate: 0.00921 
2025-08-28 03:13:44.160737: train_loss -0.1356 
2025-08-28 03:13:44.169300: val_loss -0.1972 
2025-08-28 03:13:44.173265: Pseudo dice [np.float32(0.4163)] 
2025-08-28 03:13:44.180567: Epoch time: 16.39 s 
2025-08-28 03:13:44.186203: Yayy! New best EMA pseudo Dice: 0.32679998874664307 
2025-08-28 03:13:44.988548:  
2025-08-28 03:13:44.995988: Epoch 88 
2025-08-28 03:13:45.000715: Current learning rate: 0.0092 
2025-08-28 03:14:01.102797: train_loss -0.1166 
2025-08-28 03:14:01.115201: val_loss -0.1828 
2025-08-28 03:14:01.119640: Pseudo dice [np.float32(0.3661)] 
2025-08-28 03:14:01.126665: Epoch time: 16.12 s 
2025-08-28 03:14:01.132215: Yayy! New best EMA pseudo Dice: 0.33070001006126404 
2025-08-28 03:14:01.928495:  
2025-08-28 03:14:01.933745: Epoch 89 
2025-08-28 03:14:01.941021: Current learning rate: 0.0092 
2025-08-28 03:14:18.419942: train_loss -0.1277 
2025-08-28 03:14:18.428276: val_loss -0.2167 
2025-08-28 03:14:18.436616: Pseudo dice [np.float32(0.4776)] 
2025-08-28 03:14:18.442392: Epoch time: 16.49 s 
2025-08-28 03:14:18.447432: Yayy! New best EMA pseudo Dice: 0.34540000557899475 
2025-08-28 03:14:19.409486:  
2025-08-28 03:14:19.417917: Epoch 90 
2025-08-28 03:14:19.422678: Current learning rate: 0.00919 
2025-08-28 03:14:35.912460: train_loss -0.1509 
2025-08-28 03:14:35.921078: val_loss -0.2158 
2025-08-28 03:14:35.929323: Pseudo dice [np.float32(0.4601)] 
2025-08-28 03:14:35.934828: Epoch time: 16.5 s 
2025-08-28 03:14:35.940008: Yayy! New best EMA pseudo Dice: 0.35690000653266907 
2025-08-28 03:14:36.726831:  
2025-08-28 03:14:36.731026: Epoch 91 
2025-08-28 03:14:36.738268: Current learning rate: 0.00918 
2025-08-28 03:14:52.991988: train_loss -0.1355 
2025-08-28 03:14:53.000339: val_loss -0.2236 
2025-08-28 03:14:53.009385: Pseudo dice [np.float32(0.4534)] 
2025-08-28 03:14:53.014406: Epoch time: 16.27 s 
2025-08-28 03:14:53.020254: Yayy! New best EMA pseudo Dice: 0.36649999022483826 
2025-08-28 03:14:53.818854:  
2025-08-28 03:14:53.826147: Epoch 92 
2025-08-28 03:14:53.831687: Current learning rate: 0.00917 
2025-08-28 03:15:09.306212: train_loss -0.1748 
2025-08-28 03:15:09.312511: val_loss -0.2399 
2025-08-28 03:15:09.320786: Pseudo dice [np.float32(0.4455)] 
2025-08-28 03:15:09.326459: Epoch time: 15.49 s 
2025-08-28 03:15:09.331533: Yayy! New best EMA pseudo Dice: 0.37439998984336853 
2025-08-28 03:15:10.121553:  
2025-08-28 03:15:10.126850: Epoch 93 
2025-08-28 03:15:10.130940: Current learning rate: 0.00916 
2025-08-28 03:15:25.578691: train_loss -0.1735 
2025-08-28 03:15:25.587431: val_loss -0.2607 
2025-08-28 03:15:25.591204: Pseudo dice [np.float32(0.536)] 
2025-08-28 03:15:25.597903: Epoch time: 15.46 s 
2025-08-28 03:15:25.604109: Yayy! New best EMA pseudo Dice: 0.3905999958515167 
2025-08-28 03:15:26.405716:  
2025-08-28 03:15:26.414752: Epoch 94 
2025-08-28 03:15:26.422957: Current learning rate: 0.00915 
2025-08-28 03:15:43.033906: train_loss -0.1575 
2025-08-28 03:15:43.041945: val_loss -0.1992 
2025-08-28 03:15:43.050305: Pseudo dice [np.float32(0.4041)] 
2025-08-28 03:15:43.055907: Epoch time: 16.63 s 
2025-08-28 03:15:43.060923: Yayy! New best EMA pseudo Dice: 0.3919999897480011 
2025-08-28 03:15:43.836526:  
2025-08-28 03:15:43.843747: Epoch 95 
2025-08-28 03:15:43.848962: Current learning rate: 0.00914 
2025-08-28 03:16:00.576260: train_loss -0.1743 
2025-08-28 03:16:00.588444: val_loss -0.2239 
2025-08-28 03:16:00.593030: Pseudo dice [np.float32(0.4291)] 
2025-08-28 03:16:00.598520: Epoch time: 16.74 s 
2025-08-28 03:16:00.603646: Yayy! New best EMA pseudo Dice: 0.39570000767707825 
2025-08-28 03:16:01.397789:  
2025-08-28 03:16:01.403020: Epoch 96 
2025-08-28 03:16:01.407178: Current learning rate: 0.00913 
2025-08-28 03:16:18.389762: train_loss -0.1426 
2025-08-28 03:16:18.398057: val_loss -0.2404 
2025-08-28 03:16:18.402221: Pseudo dice [np.float32(0.4783)] 
2025-08-28 03:16:18.410582: Epoch time: 17.0 s 
2025-08-28 03:16:18.415168: Yayy! New best EMA pseudo Dice: 0.40389999747276306 
2025-08-28 03:16:19.370955:  
2025-08-28 03:16:19.379307: Epoch 97 
2025-08-28 03:16:19.383490: Current learning rate: 0.00912 
2025-08-28 03:16:35.152282: train_loss -0.1407 
2025-08-28 03:16:35.160622: val_loss -0.1841 
2025-08-28 03:16:35.164805: Pseudo dice [np.float32(0.3898)] 
2025-08-28 03:16:35.171479: Epoch time: 15.78 s 
2025-08-28 03:16:35.795703:  
2025-08-28 03:16:35.804069: Epoch 98 
2025-08-28 03:16:35.808554: Current learning rate: 0.00911 
2025-08-28 03:16:52.135952: train_loss -0.1586 
2025-08-28 03:16:52.144288: val_loss -0.1935 
2025-08-28 03:16:52.148435: Pseudo dice [np.float32(0.3072)] 
2025-08-28 03:16:52.156990: Epoch time: 16.34 s 
2025-08-28 03:16:52.796410:  
2025-08-28 03:16:52.804498: Epoch 99 
2025-08-28 03:16:52.808516: Current learning rate: 0.0091 
2025-08-28 03:17:09.107042: train_loss -0.1922 
2025-08-28 03:17:09.115679: val_loss -0.2713 
2025-08-28 03:17:09.123752: Pseudo dice [np.float32(0.5236)] 
2025-08-28 03:17:09.129519: Epoch time: 16.31 s 
2025-08-28 03:17:09.303763: Yayy! New best EMA pseudo Dice: 0.40610000491142273 
2025-08-28 03:17:10.079914:  
2025-08-28 03:17:10.088763: Epoch 100 
2025-08-28 03:17:10.092417: Current learning rate: 0.0091 
2025-08-28 03:17:26.737482: train_loss -0.1793 
2025-08-28 03:17:26.745470: val_loss -0.2151 
2025-08-28 03:17:26.749643: Pseudo dice [np.float32(0.4172)] 
2025-08-28 03:17:26.758321: Epoch time: 16.66 s 
2025-08-28 03:17:26.761589: Yayy! New best EMA pseudo Dice: 0.40720000863075256 
2025-08-28 03:17:27.548085:  
2025-08-28 03:17:27.555737: Epoch 101 
2025-08-28 03:17:27.559852: Current learning rate: 0.00909 
2025-08-28 03:17:44.154511: train_loss -0.1403 
2025-08-28 03:17:44.163170: val_loss -0.2512 
2025-08-28 03:17:44.167434: Pseudo dice [np.float32(0.5073)] 
2025-08-28 03:17:44.173836: Epoch time: 16.61 s 
2025-08-28 03:17:44.179966: Yayy! New best EMA pseudo Dice: 0.4171999990940094 
2025-08-28 03:17:44.997018:  
2025-08-28 03:17:45.002311: Epoch 102 
2025-08-28 03:17:45.009543: Current learning rate: 0.00908 
2025-08-28 03:18:01.576073: train_loss -0.1932 
2025-08-28 03:18:01.584418: val_loss -0.2297 
2025-08-28 03:18:01.592768: Pseudo dice [np.float32(0.4675)] 
2025-08-28 03:18:01.598513: Epoch time: 16.58 s 
2025-08-28 03:18:01.603676: Yayy! New best EMA pseudo Dice: 0.4221999943256378 
2025-08-28 03:18:02.415657:  
2025-08-28 03:18:02.423872: Epoch 103 
2025-08-28 03:18:02.428356: Current learning rate: 0.00907 
2025-08-28 03:18:19.337605: train_loss -0.1809 
2025-08-28 03:18:19.346324: val_loss -0.199 
2025-08-28 03:18:19.348307: Pseudo dice [np.float32(0.3957)] 
2025-08-28 03:18:19.356952: Epoch time: 16.92 s 
2025-08-28 03:18:20.145729:  
2025-08-28 03:18:20.154083: Epoch 104 
2025-08-28 03:18:20.158216: Current learning rate: 0.00906 
2025-08-28 03:18:36.640765: train_loss -0.1842 
2025-08-28 03:18:36.648915: val_loss -0.1866 
2025-08-28 03:18:36.657259: Pseudo dice [np.float32(0.3998)] 
2025-08-28 03:18:36.661806: Epoch time: 16.5 s 
2025-08-28 03:18:37.299238:  
2025-08-28 03:18:37.304518: Epoch 105 
2025-08-28 03:18:37.311769: Current learning rate: 0.00905 
2025-08-28 03:18:54.091091: train_loss -0.2059 
2025-08-28 03:18:54.103529: val_loss -0.2172 
2025-08-28 03:18:54.107705: Pseudo dice [np.float32(0.5143)] 
2025-08-28 03:18:54.114512: Epoch time: 16.79 s 
2025-08-28 03:18:54.120161: Yayy! New best EMA pseudo Dice: 0.42730000615119934 
2025-08-28 03:18:54.929389:  
2025-08-28 03:18:54.937700: Epoch 106 
2025-08-28 03:18:54.942955: Current learning rate: 0.00904 
2025-08-28 03:19:11.366616: train_loss -0.1614 
2025-08-28 03:19:11.374930: val_loss -0.173 
2025-08-28 03:19:11.379455: Pseudo dice [np.float32(0.3121)] 
2025-08-28 03:19:11.386256: Epoch time: 16.44 s 
2025-08-28 03:19:12.022658:  
2025-08-28 03:19:12.030856: Epoch 107 
2025-08-28 03:19:12.035350: Current learning rate: 0.00903 
2025-08-28 03:19:28.567192: train_loss -0.1953 
2025-08-28 03:19:28.575438: val_loss -0.2828 
2025-08-28 03:19:28.579960: Pseudo dice [np.float32(0.5435)] 
2025-08-28 03:19:28.588934: Epoch time: 16.54 s 
2025-08-28 03:19:28.592629: Yayy! New best EMA pseudo Dice: 0.4284999966621399 
2025-08-28 03:19:29.403139:  
2025-08-28 03:19:29.411542: Epoch 108 
2025-08-28 03:19:29.419782: Current learning rate: 0.00902 
2025-08-28 03:19:46.122140: train_loss -0.1528 
2025-08-28 03:19:46.130701: val_loss -0.2655 
2025-08-28 03:19:46.138857: Pseudo dice [np.float32(0.4796)] 
2025-08-28 03:19:46.143531: Epoch time: 16.72 s 
2025-08-28 03:19:46.149732: Yayy! New best EMA pseudo Dice: 0.4336000084877014 
2025-08-28 03:19:46.964676:  
2025-08-28 03:19:46.974075: Epoch 109 
2025-08-28 03:19:46.982465: Current learning rate: 0.00901 
2025-08-28 03:20:03.481104: train_loss -0.1903 
2025-08-28 03:20:03.489846: val_loss -0.2787 
2025-08-28 03:20:03.497814: Pseudo dice [np.float32(0.6003)] 
2025-08-28 03:20:03.503686: Epoch time: 16.52 s 
2025-08-28 03:20:03.506693: Yayy! New best EMA pseudo Dice: 0.450300008058548 
2025-08-28 03:20:04.461296:  
2025-08-28 03:20:04.466561: Epoch 110 
2025-08-28 03:20:04.473788: Current learning rate: 0.009 
2025-08-28 03:20:20.986305: train_loss -0.2147 
2025-08-28 03:20:20.994786: val_loss -0.2672 
2025-08-28 03:20:21.003119: Pseudo dice [np.float32(0.4599)] 
2025-08-28 03:20:21.008596: Epoch time: 16.53 s 
2025-08-28 03:20:21.015689: Yayy! New best EMA pseudo Dice: 0.4512999951839447 
2025-08-28 03:20:21.811852:  
2025-08-28 03:20:21.817197: Epoch 111 
2025-08-28 03:20:21.821281: Current learning rate: 0.009 
2025-08-28 03:20:38.428393: train_loss -0.2236 
2025-08-28 03:20:38.432681: val_loss -0.2359 
2025-08-28 03:20:38.441381: Pseudo dice [np.float32(0.42)] 
2025-08-28 03:20:38.446798: Epoch time: 16.62 s 
2025-08-28 03:20:39.083364:  
2025-08-28 03:20:39.088650: Epoch 112 
2025-08-28 03:20:39.095864: Current learning rate: 0.00899 
2025-08-28 03:20:55.663128: train_loss -0.2187 
2025-08-28 03:20:55.670738: val_loss -0.2794 
2025-08-28 03:20:55.679265: Pseudo dice [np.float32(0.5089)] 
2025-08-28 03:20:55.684707: Epoch time: 16.58 s 
2025-08-28 03:20:55.689873: Yayy! New best EMA pseudo Dice: 0.45419999957084656 
2025-08-28 03:20:56.506215:  
2025-08-28 03:20:56.513279: Epoch 113 
2025-08-28 03:20:56.519243: Current learning rate: 0.00898 
2025-08-28 03:21:12.491717: train_loss -0.2265 
2025-08-28 03:21:12.500034: val_loss -0.2494 
2025-08-28 03:21:12.508386: Pseudo dice [np.float32(0.4937)] 
2025-08-28 03:21:12.513028: Epoch time: 15.99 s 
2025-08-28 03:21:12.519108: Yayy! New best EMA pseudo Dice: 0.45820000767707825 
2025-08-28 03:21:13.344554:  
2025-08-28 03:21:13.352335: Epoch 114 
2025-08-28 03:21:13.357426: Current learning rate: 0.00897 
2025-08-28 03:21:29.300168: train_loss -0.1716 
2025-08-28 03:21:29.308485: val_loss -0.3233 
2025-08-28 03:21:29.312880: Pseudo dice [np.float32(0.5359)] 
2025-08-28 03:21:29.321596: Epoch time: 15.96 s 
2025-08-28 03:21:29.324237: Yayy! New best EMA pseudo Dice: 0.4659000039100647 
2025-08-28 03:21:30.147886:  
2025-08-28 03:21:30.156297: Epoch 115 
2025-08-28 03:21:30.160431: Current learning rate: 0.00896 
2025-08-28 03:21:46.017416: train_loss -0.1917 
2025-08-28 03:21:46.025182: val_loss -0.3008 
2025-08-28 03:21:46.029323: Pseudo dice [np.float32(0.4785)] 
2025-08-28 03:21:46.038239: Epoch time: 15.87 s 
2025-08-28 03:21:46.040958: Yayy! New best EMA pseudo Dice: 0.46720001101493835 
2025-08-28 03:21:46.902413:  
2025-08-28 03:21:46.910484: Epoch 116 
2025-08-28 03:21:46.917742: Current learning rate: 0.00895 
2025-08-28 03:22:02.812751: train_loss -0.1749 
2025-08-28 03:22:02.821137: val_loss -0.2348 
2025-08-28 03:22:02.829664: Pseudo dice [np.float32(0.4659)] 
2025-08-28 03:22:02.835347: Epoch time: 15.91 s 
2025-08-28 03:22:03.660563:  
2025-08-28 03:22:03.667839: Epoch 117 
2025-08-28 03:22:03.673136: Current learning rate: 0.00894 
2025-08-28 03:22:19.813500: train_loss -0.187 
2025-08-28 03:22:19.821426: val_loss -0.2241 
2025-08-28 03:22:19.825565: Pseudo dice [np.float32(0.4463)] 
2025-08-28 03:22:19.833191: Epoch time: 16.15 s 
2025-08-28 03:22:20.493989:  
2025-08-28 03:22:20.502409: Epoch 118 
2025-08-28 03:22:20.507135: Current learning rate: 0.00893 
2025-08-28 03:22:36.730352: train_loss -0.2028 
2025-08-28 03:22:36.738325: val_loss -0.2499 
2025-08-28 03:22:36.747044: Pseudo dice [np.float32(0.5219)] 
2025-08-28 03:22:36.752458: Epoch time: 16.24 s 
2025-08-28 03:22:36.759143: Yayy! New best EMA pseudo Dice: 0.4706999957561493 
2025-08-28 03:22:37.581919:  
2025-08-28 03:22:37.590251: Epoch 119 
2025-08-28 03:22:37.597493: Current learning rate: 0.00892 
2025-08-28 03:22:53.330175: train_loss -0.2212 
2025-08-28 03:22:53.340548: val_loss -0.2812 
2025-08-28 03:22:53.346498: Pseudo dice [np.float32(0.5013)] 
2025-08-28 03:22:53.351234: Epoch time: 15.75 s 
2025-08-28 03:22:53.353904: Yayy! New best EMA pseudo Dice: 0.47369998693466187 
2025-08-28 03:22:54.151526:  
2025-08-28 03:22:54.156826: Epoch 120 
2025-08-28 03:22:54.164048: Current learning rate: 0.00891 
2025-08-28 03:23:10.664204: train_loss -0.224 
2025-08-28 03:23:10.672476: val_loss -0.2789 
2025-08-28 03:23:10.676636: Pseudo dice [np.float32(0.5619)] 
2025-08-28 03:23:10.684778: Epoch time: 16.52 s 
2025-08-28 03:23:10.689312: Yayy! New best EMA pseudo Dice: 0.48260000348091125 
2025-08-28 03:23:11.491099:  
2025-08-28 03:23:11.499139: Epoch 121 
2025-08-28 03:23:11.503309: Current learning rate: 0.0089 
2025-08-28 03:23:27.654519: train_loss -0.2102 
2025-08-28 03:23:27.660324: val_loss -0.1426 
2025-08-28 03:23:27.668384: Pseudo dice [np.float32(0.3198)] 
2025-08-28 03:23:27.675103: Epoch time: 16.16 s 
2025-08-28 03:23:28.328607:  
2025-08-28 03:23:28.336706: Epoch 122 
2025-08-28 03:23:28.342376: Current learning rate: 0.00889 
2025-08-28 03:23:44.322773: train_loss -0.1903 
2025-08-28 03:23:44.330803: val_loss -0.284 
2025-08-28 03:23:44.339092: Pseudo dice [np.float32(0.5223)] 
2025-08-28 03:23:44.344623: Epoch time: 16.0 s 
2025-08-28 03:23:45.166040:  
2025-08-28 03:23:45.173327: Epoch 123 
2025-08-28 03:23:45.178563: Current learning rate: 0.00889 
2025-08-28 03:24:01.114221: train_loss -0.232 
2025-08-28 03:24:01.122872: val_loss -0.2345 
2025-08-28 03:24:01.127000: Pseudo dice [np.float32(0.5109)] 
2025-08-28 03:24:01.135091: Epoch time: 15.95 s 
2025-08-28 03:24:01.791775:  
2025-08-28 03:24:01.799329: Epoch 124 
2025-08-28 03:24:01.803506: Current learning rate: 0.00888 
2025-08-28 03:24:17.760334: train_loss -0.249 
2025-08-28 03:24:17.772605: val_loss -0.2705 
2025-08-28 03:24:17.777035: Pseudo dice [np.float32(0.5027)] 
2025-08-28 03:24:17.785039: Epoch time: 15.97 s 
2025-08-28 03:24:18.453461:  
2025-08-28 03:24:18.460715: Epoch 125 
2025-08-28 03:24:18.465962: Current learning rate: 0.00887 
2025-08-28 03:24:34.585413: train_loss -0.2367 
2025-08-28 03:24:34.593544: val_loss -0.3059 
2025-08-28 03:24:34.601881: Pseudo dice [np.float32(0.5438)] 
2025-08-28 03:24:34.607602: Epoch time: 16.14 s 
2025-08-28 03:24:34.612805: Yayy! New best EMA pseudo Dice: 0.48500001430511475 
2025-08-28 03:24:35.416277:  
2025-08-28 03:24:35.425003: Epoch 126 
2025-08-28 03:24:35.430216: Current learning rate: 0.00886 
2025-08-28 03:24:51.310480: train_loss -0.2053 
2025-08-28 03:24:51.323015: val_loss -0.2482 
2025-08-28 03:24:51.327127: Pseudo dice [np.float32(0.4988)] 
2025-08-28 03:24:51.335634: Epoch time: 15.9 s 
2025-08-28 03:24:51.339783: Yayy! New best EMA pseudo Dice: 0.4864000082015991 
2025-08-28 03:24:52.161024:  
2025-08-28 03:24:52.166364: Epoch 127 
2025-08-28 03:24:52.173552: Current learning rate: 0.00885 
2025-08-28 03:25:08.306347: train_loss -0.2365 
2025-08-28 03:25:08.314968: val_loss -0.3213 
2025-08-28 03:25:08.319182: Pseudo dice [np.float32(0.5874)] 
2025-08-28 03:25:08.326100: Epoch time: 16.15 s 
2025-08-28 03:25:08.331665: Yayy! New best EMA pseudo Dice: 0.4964999854564667 
2025-08-28 03:25:09.140460:  
2025-08-28 03:25:09.145725: Epoch 128 
2025-08-28 03:25:09.152987: Current learning rate: 0.00884 
2025-08-28 03:25:25.828907: train_loss -0.2229 
2025-08-28 03:25:25.837604: val_loss -0.1621 
2025-08-28 03:25:25.844073: Pseudo dice [np.float32(0.412)] 
2025-08-28 03:25:25.849473: Epoch time: 16.69 s 
2025-08-28 03:25:26.642384:  
2025-08-28 03:25:26.650700: Epoch 129 
2025-08-28 03:25:26.654918: Current learning rate: 0.00883 
2025-08-28 03:25:43.316120: train_loss -0.217 
2025-08-28 03:25:43.320738: val_loss -0.2028 
2025-08-28 03:25:43.328868: Pseudo dice [np.float32(0.4215)] 
2025-08-28 03:25:43.334187: Epoch time: 16.67 s 
2025-08-28 03:25:43.971419:  
2025-08-28 03:25:43.979828: Epoch 130 
2025-08-28 03:25:43.983591: Current learning rate: 0.00882 
2025-08-28 03:26:00.301957: train_loss -0.2518 
2025-08-28 03:26:00.308203: val_loss -0.2973 
2025-08-28 03:26:00.316561: Pseudo dice [np.float32(0.5402)] 
2025-08-28 03:26:00.322910: Epoch time: 16.33 s 
2025-08-28 03:26:00.956228:  
2025-08-28 03:26:00.963196: Epoch 131 
2025-08-28 03:26:00.971684: Current learning rate: 0.00881 
2025-08-28 03:26:17.601149: train_loss -0.2512 
2025-08-28 03:26:17.608912: val_loss -0.2661 
2025-08-28 03:26:17.617541: Pseudo dice [np.float32(0.4738)] 
2025-08-28 03:26:17.622559: Epoch time: 16.64 s 
2025-08-28 03:26:18.264028:  
2025-08-28 03:26:18.272033: Epoch 132 
2025-08-28 03:26:18.276165: Current learning rate: 0.0088 
2025-08-28 03:26:34.707396: train_loss -0.2232 
2025-08-28 03:26:34.713419: val_loss -0.3365 
2025-08-28 03:26:34.721733: Pseudo dice [np.float32(0.6178)] 
2025-08-28 03:26:34.727756: Epoch time: 16.44 s 
2025-08-28 03:26:34.731065: Yayy! New best EMA pseudo Dice: 0.499099999666214 
2025-08-28 03:26:35.535428:  
2025-08-28 03:26:35.543442: Epoch 133 
2025-08-28 03:26:35.547604: Current learning rate: 0.00879 
2025-08-28 03:26:52.285419: train_loss -0.2329 
2025-08-28 03:26:52.297629: val_loss -0.2973 
2025-08-28 03:26:52.301795: Pseudo dice [np.float32(0.5428)] 
2025-08-28 03:26:52.310011: Epoch time: 16.75 s 
2025-08-28 03:26:52.315758: Yayy! New best EMA pseudo Dice: 0.5034999847412109 
2025-08-28 03:26:53.123304:  
2025-08-28 03:26:53.128405: Epoch 134 
2025-08-28 03:26:53.135958: Current learning rate: 0.00879 
2025-08-28 03:27:09.301851: train_loss -0.2123 
2025-08-28 03:27:09.310450: val_loss -0.3322 
2025-08-28 03:27:09.314624: Pseudo dice [np.float32(0.6291)] 
2025-08-28 03:27:09.322264: Epoch time: 16.18 s 
2025-08-28 03:27:09.328651: Yayy! New best EMA pseudo Dice: 0.515999972820282 
2025-08-28 03:27:10.324292:  
2025-08-28 03:27:10.332459: Epoch 135 
2025-08-28 03:27:10.338035: Current learning rate: 0.00878 
2025-08-28 03:27:26.850362: train_loss -0.2697 
2025-08-28 03:27:26.857150: val_loss -0.3367 
2025-08-28 03:27:26.861293: Pseudo dice [np.float32(0.5949)] 
2025-08-28 03:27:26.870470: Epoch time: 16.53 s 
2025-08-28 03:27:26.877930: Yayy! New best EMA pseudo Dice: 0.5238999724388123 
2025-08-28 03:27:27.690937:  
2025-08-28 03:27:27.699428: Epoch 136 
2025-08-28 03:27:27.704388: Current learning rate: 0.00877 
2025-08-28 03:27:43.690793: train_loss -0.2487 
2025-08-28 03:27:43.699225: val_loss -0.2986 
2025-08-28 03:27:43.707285: Pseudo dice [np.float32(0.465)] 
2025-08-28 03:27:43.713659: Epoch time: 16.0 s 
2025-08-28 03:27:44.366309:  
2025-08-28 03:27:44.374635: Epoch 137 
2025-08-28 03:27:44.379131: Current learning rate: 0.00876 
2025-08-28 03:28:01.041267: train_loss -0.2538 
2025-08-28 03:28:01.049623: val_loss -0.3382 
2025-08-28 03:28:01.057944: Pseudo dice [np.float32(0.6016)] 
2025-08-28 03:28:01.064242: Epoch time: 16.67 s 
2025-08-28 03:28:01.067129: Yayy! New best EMA pseudo Dice: 0.5264000296592712 
2025-08-28 03:28:01.884142:  
2025-08-28 03:28:01.892434: Epoch 138 
2025-08-28 03:28:01.900467: Current learning rate: 0.00875 
2025-08-28 03:28:17.995677: train_loss -0.2489 
2025-08-28 03:28:18.004038: val_loss -0.1516 
2025-08-28 03:28:18.008467: Pseudo dice [np.float32(0.1657)] 
2025-08-28 03:28:18.014512: Epoch time: 16.11 s 
2025-08-28 03:28:18.667186:  
2025-08-28 03:28:18.675556: Epoch 139 
2025-08-28 03:28:18.679980: Current learning rate: 0.00874 
2025-08-28 03:28:34.541460: train_loss -0.2124 
2025-08-28 03:28:34.550774: val_loss -0.312 
2025-08-28 03:28:34.555894: Pseudo dice [np.float32(0.5677)] 
2025-08-28 03:28:34.563215: Epoch time: 15.88 s 
2025-08-28 03:28:35.212870:  
2025-08-28 03:28:35.221226: Epoch 140 
2025-08-28 03:28:35.229571: Current learning rate: 0.00873 
2025-08-28 03:28:51.133151: train_loss -0.2617 
2025-08-28 03:28:51.145011: val_loss -0.317 
2025-08-28 03:28:51.150100: Pseudo dice [np.float32(0.5688)] 
2025-08-28 03:28:51.155723: Epoch time: 15.92 s 
2025-08-28 03:28:51.821144:  
2025-08-28 03:28:51.829486: Epoch 141 
2025-08-28 03:28:51.834848: Current learning rate: 0.00872 
2025-08-28 03:29:07.732801: train_loss -0.2717 
2025-08-28 03:29:07.741210: val_loss -0.3182 
2025-08-28 03:29:07.750101: Pseudo dice [np.float32(0.6204)] 
2025-08-28 03:29:07.755044: Epoch time: 15.92 s 
2025-08-28 03:29:08.404349:  
2025-08-28 03:29:08.412712: Epoch 142 
2025-08-28 03:29:08.416856: Current learning rate: 0.00871 
2025-08-28 03:29:24.675095: train_loss -0.2759 
2025-08-28 03:29:24.683112: val_loss -0.2166 
2025-08-28 03:29:24.692133: Pseudo dice [np.float32(0.4351)] 
2025-08-28 03:29:24.696830: Epoch time: 16.27 s 
2025-08-28 03:29:25.350725:  
2025-08-28 03:29:25.358820: Epoch 143 
2025-08-28 03:29:25.363193: Current learning rate: 0.0087 
2025-08-28 03:29:40.737139: train_loss -0.3038 
2025-08-28 03:29:40.745331: val_loss -0.3378 
2025-08-28 03:29:40.749156: Pseudo dice [np.float32(0.6409)] 
2025-08-28 03:29:40.757744: Epoch time: 15.39 s 
2025-08-28 03:29:41.408503:  
2025-08-28 03:29:41.412316: Epoch 144 
2025-08-28 03:29:41.420662: Current learning rate: 0.00869 
2025-08-28 03:29:56.953530: train_loss -0.3278 
2025-08-28 03:29:56.965365: val_loss -0.2975 
2025-08-28 03:29:56.969534: Pseudo dice [np.float32(0.5591)] 
2025-08-28 03:29:56.976968: Epoch time: 15.55 s 
2025-08-28 03:29:57.628852:  
2025-08-28 03:29:57.637150: Epoch 145 
2025-08-28 03:29:57.641029: Current learning rate: 0.00868 
2025-08-28 03:30:13.080927: train_loss -0.2521 
2025-08-28 03:30:13.085606: val_loss -0.368 
2025-08-28 03:30:13.093967: Pseudo dice [np.float32(0.6782)] 
2025-08-28 03:30:13.100292: Epoch time: 15.45 s 
2025-08-28 03:30:13.106459: Yayy! New best EMA pseudo Dice: 0.5407000184059143 
2025-08-28 03:30:13.894743:  
2025-08-28 03:30:13.898927: Epoch 146 
2025-08-28 03:30:13.907615: Current learning rate: 0.00868 
2025-08-28 03:30:30.615888: train_loss -0.2173 
2025-08-28 03:30:30.624351: val_loss -0.2026 
2025-08-28 03:30:30.632216: Pseudo dice [np.float32(0.4037)] 
2025-08-28 03:30:30.637564: Epoch time: 16.72 s 
2025-08-28 03:30:31.287181:  
2025-08-28 03:30:31.295497: Epoch 147 
2025-08-28 03:30:31.299729: Current learning rate: 0.00867 
2025-08-28 03:30:47.999532: train_loss -0.2331 
2025-08-28 03:30:48.008038: val_loss -0.3055 
2025-08-28 03:30:48.012215: Pseudo dice [np.float32(0.5638)] 
2025-08-28 03:30:48.020759: Epoch time: 16.71 s 
2025-08-28 03:30:48.804696:  
2025-08-28 03:30:48.813008: Epoch 148 
2025-08-28 03:30:48.817452: Current learning rate: 0.00866 
2025-08-28 03:31:05.679624: train_loss -0.2242 
2025-08-28 03:31:05.688325: val_loss -0.3631 
2025-08-28 03:31:05.694930: Pseudo dice [np.float32(0.6282)] 
2025-08-28 03:31:05.701630: Epoch time: 16.87 s 
2025-08-28 03:31:06.344296:  
2025-08-28 03:31:06.351297: Epoch 149 
2025-08-28 03:31:06.355475: Current learning rate: 0.00865 
2025-08-28 03:31:23.235297: train_loss -0.2408 
2025-08-28 03:31:23.243160: val_loss -0.3317 
2025-08-28 03:31:23.251544: Pseudo dice [np.float32(0.5499)] 
2025-08-28 03:31:23.257190: Epoch time: 16.89 s 
2025-08-28 03:31:23.422767: Yayy! New best EMA pseudo Dice: 0.5414000153541565 
2025-08-28 03:31:24.223319:  
2025-08-28 03:31:24.231657: Epoch 150 
2025-08-28 03:31:24.236032: Current learning rate: 0.00864 
2025-08-28 03:31:40.898774: train_loss -0.2527 
2025-08-28 03:31:40.906989: val_loss -0.3723 
2025-08-28 03:31:40.913171: Pseudo dice [np.float32(0.617)] 
2025-08-28 03:31:40.920147: Epoch time: 16.68 s 
2025-08-28 03:31:40.924352: Yayy! New best EMA pseudo Dice: 0.5490000247955322 
2025-08-28 03:31:41.741155:  
2025-08-28 03:31:41.749716: Epoch 151 
2025-08-28 03:31:41.753671: Current learning rate: 0.00863 
2025-08-28 03:31:57.707061: train_loss -0.2534 
2025-08-28 03:31:57.715150: val_loss -0.3216 
2025-08-28 03:31:57.723405: Pseudo dice [np.float32(0.5486)] 
2025-08-28 03:31:57.729185: Epoch time: 15.97 s 
2025-08-28 03:31:58.369901:  
2025-08-28 03:31:58.378705: Epoch 152 
2025-08-28 03:31:58.382334: Current learning rate: 0.00862 
2025-08-28 03:32:14.427578: train_loss -0.3163 
2025-08-28 03:32:14.436197: val_loss -0.3591 
2025-08-28 03:32:14.440106: Pseudo dice [np.float32(0.6204)] 
2025-08-28 03:32:14.448514: Epoch time: 16.06 s 
2025-08-28 03:32:14.453526: Yayy! New best EMA pseudo Dice: 0.5561000108718872 
2025-08-28 03:32:15.278515:  
2025-08-28 03:32:15.286844: Epoch 153 
2025-08-28 03:32:15.291262: Current learning rate: 0.00861 
2025-08-28 03:32:31.294809: train_loss -0.2656 
2025-08-28 03:32:31.303009: val_loss -0.2097 
2025-08-28 03:32:31.307255: Pseudo dice [np.float32(0.4838)] 
2025-08-28 03:32:31.316556: Epoch time: 16.02 s 
2025-08-28 03:32:32.128630:  
2025-08-28 03:32:32.137239: Epoch 154 
2025-08-28 03:32:32.141104: Current learning rate: 0.0086 
2025-08-28 03:32:47.969526: train_loss -0.2832 
2025-08-28 03:32:47.982027: val_loss -0.3137 
2025-08-28 03:32:47.986211: Pseudo dice [np.float32(0.5962)] 
2025-08-28 03:32:47.991601: Epoch time: 15.84 s 
2025-08-28 03:32:48.649271:  
2025-08-28 03:32:48.653836: Epoch 155 
2025-08-28 03:32:48.657612: Current learning rate: 0.00859 
2025-08-28 03:33:04.782065: train_loss -0.2554 
2025-08-28 03:33:04.790440: val_loss -0.3089 
2025-08-28 03:33:04.794879: Pseudo dice [np.float32(0.5488)] 
2025-08-28 03:33:04.802986: Epoch time: 16.14 s 
2025-08-28 03:33:05.449361:  
2025-08-28 03:33:05.458080: Epoch 156 
2025-08-28 03:33:05.462133: Current learning rate: 0.00858 
2025-08-28 03:33:21.281957: train_loss -0.2698 
2025-08-28 03:33:21.290255: val_loss -0.3609 
2025-08-28 03:33:21.294378: Pseudo dice [np.float32(0.6199)] 
2025-08-28 03:33:21.303556: Epoch time: 15.83 s 
2025-08-28 03:33:21.308315: Yayy! New best EMA pseudo Dice: 0.5598000288009644 
2025-08-28 03:33:22.128553:  
2025-08-28 03:33:22.136912: Epoch 157 
2025-08-28 03:33:22.141046: Current learning rate: 0.00858 
2025-08-28 03:33:38.991137: train_loss -0.2697 
2025-08-28 03:33:39.003999: val_loss -0.3823 
2025-08-28 03:33:39.009405: Pseudo dice [np.float32(0.6509)] 
2025-08-28 03:33:39.017474: Epoch time: 16.86 s 
2025-08-28 03:33:39.021376: Yayy! New best EMA pseudo Dice: 0.5688999891281128 
2025-08-28 03:33:39.829563:  
2025-08-28 03:33:39.840161: Epoch 158 
2025-08-28 03:33:39.845356: Current learning rate: 0.00857 
2025-08-28 03:33:56.596267: train_loss -0.2426 
2025-08-28 03:33:56.608831: val_loss -0.3534 
2025-08-28 03:33:56.612991: Pseudo dice [np.float32(0.6029)] 
2025-08-28 03:33:56.620311: Epoch time: 16.77 s 
2025-08-28 03:33:56.625962: Yayy! New best EMA pseudo Dice: 0.5723000168800354 
2025-08-28 03:33:57.434614:  
2025-08-28 03:33:57.443221: Epoch 159 
2025-08-28 03:33:57.447155: Current learning rate: 0.00856 
2025-08-28 03:34:14.155607: train_loss -0.2798 
2025-08-28 03:34:14.163850: val_loss -0.261 
2025-08-28 03:34:14.172443: Pseudo dice [np.float32(0.5453)] 
2025-08-28 03:34:14.178761: Epoch time: 16.72 s 
2025-08-28 03:34:14.985739:  
2025-08-28 03:34:14.993809: Epoch 160 
2025-08-28 03:34:14.998031: Current learning rate: 0.00855 
2025-08-28 03:34:31.272898: train_loss -0.326 
2025-08-28 03:34:31.280901: val_loss -0.3867 
2025-08-28 03:34:31.285476: Pseudo dice [np.float32(0.6403)] 
2025-08-28 03:34:31.292507: Epoch time: 16.29 s 
2025-08-28 03:34:31.298017: Yayy! New best EMA pseudo Dice: 0.57669997215271 
2025-08-28 03:34:32.110630:  
2025-08-28 03:34:32.115113: Epoch 161 
2025-08-28 03:34:32.123130: Current learning rate: 0.00854 
2025-08-28 03:34:48.940536: train_loss -0.3036 
2025-08-28 03:34:48.952728: val_loss -0.2876 
2025-08-28 03:34:48.956923: Pseudo dice [np.float32(0.505)] 
2025-08-28 03:34:48.963276: Epoch time: 16.83 s 
2025-08-28 03:34:49.616202:  
2025-08-28 03:34:49.624254: Epoch 162 
2025-08-28 03:34:49.629025: Current learning rate: 0.00853 
2025-08-28 03:35:05.582083: train_loss -0.2861 
2025-08-28 03:35:05.590506: val_loss -0.3847 
2025-08-28 03:35:05.594631: Pseudo dice [np.float32(0.6639)] 
2025-08-28 03:35:05.600941: Epoch time: 15.97 s 
2025-08-28 03:35:05.607574: Yayy! New best EMA pseudo Dice: 0.5788999795913696 
2025-08-28 03:35:06.420173:  
2025-08-28 03:35:06.428533: Epoch 163 
2025-08-28 03:35:06.436966: Current learning rate: 0.00852 
2025-08-28 03:35:23.199421: train_loss -0.3305 
2025-08-28 03:35:23.207762: val_loss -0.2665 
2025-08-28 03:35:23.216106: Pseudo dice [np.float32(0.5535)] 
2025-08-28 03:35:23.222169: Epoch time: 16.78 s 
2025-08-28 03:35:23.879009:  
2025-08-28 03:35:23.883460: Epoch 164 
2025-08-28 03:35:23.891556: Current learning rate: 0.00851 
2025-08-28 03:35:40.358183: train_loss -0.2883 
2025-08-28 03:35:40.366563: val_loss -0.3216 
2025-08-28 03:35:40.370759: Pseudo dice [np.float32(0.4808)] 
2025-08-28 03:35:40.377965: Epoch time: 16.48 s 
2025-08-28 03:35:41.021409:  
2025-08-28 03:35:41.029755: Epoch 165 
2025-08-28 03:35:41.033867: Current learning rate: 0.0085 
2025-08-28 03:35:57.312674: train_loss -0.291 
2025-08-28 03:35:57.325269: val_loss -0.347 
2025-08-28 03:35:57.331379: Pseudo dice [np.float32(0.6366)] 
2025-08-28 03:35:57.337402: Epoch time: 16.29 s 
2025-08-28 03:35:58.134316:  
2025-08-28 03:35:58.138495: Epoch 166 
2025-08-28 03:35:58.146843: Current learning rate: 0.00849 
2025-08-28 03:36:13.717253: train_loss -0.2845 
2025-08-28 03:36:13.725169: val_loss -0.3 
2025-08-28 03:36:13.733186: Pseudo dice [np.float32(0.5035)] 
2025-08-28 03:36:13.738832: Epoch time: 15.59 s 
2025-08-28 03:36:14.388058:  
2025-08-28 03:36:14.396695: Epoch 167 
2025-08-28 03:36:14.400992: Current learning rate: 0.00848 
2025-08-28 03:36:29.924954: train_loss -0.2774 
2025-08-28 03:36:29.932959: val_loss -0.4437 
2025-08-28 03:36:29.941051: Pseudo dice [np.float32(0.6865)] 
2025-08-28 03:36:29.946965: Epoch time: 15.54 s 
2025-08-28 03:36:30.591699:  
2025-08-28 03:36:30.599770: Epoch 168 
2025-08-28 03:36:30.604318: Current learning rate: 0.00847 
2025-08-28 03:36:46.524390: train_loss -0.2863 
2025-08-28 03:36:46.532705: val_loss -0.3757 
2025-08-28 03:36:46.536793: Pseudo dice [np.float32(0.5443)] 
2025-08-28 03:36:46.545357: Epoch time: 15.94 s 
2025-08-28 03:36:47.195797:  
2025-08-28 03:36:47.204135: Epoch 169 
2025-08-28 03:36:47.208288: Current learning rate: 0.00847 
2025-08-28 03:37:02.899092: train_loss -0.2717 
2025-08-28 03:37:02.907305: val_loss -0.333 
2025-08-28 03:37:02.916280: Pseudo dice [np.float32(0.6132)] 
2025-08-28 03:37:02.921795: Epoch time: 15.7 s 
2025-08-28 03:37:02.928100: Yayy! New best EMA pseudo Dice: 0.5791000127792358 
2025-08-28 03:37:03.754286:  
2025-08-28 03:37:03.762703: Epoch 170 
2025-08-28 03:37:03.768857: Current learning rate: 0.00846 
2025-08-28 03:37:20.016278: train_loss -0.3179 
2025-08-28 03:37:20.027113: val_loss -0.3967 
2025-08-28 03:37:20.032817: Pseudo dice [np.float32(0.5476)] 
2025-08-28 03:37:20.039108: Epoch time: 16.27 s 
2025-08-28 03:37:20.700073:  
2025-08-28 03:37:20.708410: Epoch 171 
2025-08-28 03:37:20.712812: Current learning rate: 0.00845 
2025-08-28 03:37:36.390731: train_loss -0.3218 
2025-08-28 03:37:36.399098: val_loss -0.3955 
2025-08-28 03:37:36.403228: Pseudo dice [np.float32(0.6542)] 
2025-08-28 03:37:36.412377: Epoch time: 15.69 s 
2025-08-28 03:37:36.416611: Yayy! New best EMA pseudo Dice: 0.5838000178337097 
2025-08-28 03:37:37.441819:  
2025-08-28 03:37:37.450158: Epoch 172 
2025-08-28 03:37:37.454290: Current learning rate: 0.00844 
2025-08-28 03:37:53.503639: train_loss -0.3647 
2025-08-28 03:37:53.516550: val_loss -0.3764 
2025-08-28 03:37:53.520334: Pseudo dice [np.float32(0.6775)] 
2025-08-28 03:37:53.529553: Epoch time: 16.07 s 
2025-08-28 03:37:53.534426: Yayy! New best EMA pseudo Dice: 0.5932000279426575 
2025-08-28 03:37:54.358700:  
2025-08-28 03:37:54.367025: Epoch 173 
2025-08-28 03:37:54.371193: Current learning rate: 0.00843 
2025-08-28 03:38:10.370569: train_loss -0.2909 
2025-08-28 03:38:10.378830: val_loss -0.3865 
2025-08-28 03:38:10.387231: Pseudo dice [np.float32(0.5903)] 
2025-08-28 03:38:10.393413: Epoch time: 16.02 s 
2025-08-28 03:38:11.046161:  
2025-08-28 03:38:11.050333: Epoch 174 
2025-08-28 03:38:11.054488: Current learning rate: 0.00842 
2025-08-28 03:38:27.183107: train_loss -0.3291 
2025-08-28 03:38:27.191779: val_loss -0.3998 
2025-08-28 03:38:27.195925: Pseudo dice [np.float32(0.6589)] 
2025-08-28 03:38:27.204004: Epoch time: 16.14 s 
2025-08-28 03:38:27.209679: Yayy! New best EMA pseudo Dice: 0.5995000004768372 
2025-08-28 03:38:28.025831:  
2025-08-28 03:38:28.033978: Epoch 175 
2025-08-28 03:38:28.038141: Current learning rate: 0.00841 
2025-08-28 03:38:44.129240: train_loss -0.3012 
2025-08-28 03:38:44.137548: val_loss -0.3408 
2025-08-28 03:38:44.141723: Pseudo dice [np.float32(0.5987)] 
2025-08-28 03:38:44.149906: Epoch time: 16.1 s 
2025-08-28 03:38:44.813192:  
2025-08-28 03:38:44.821752: Epoch 176 
2025-08-28 03:38:44.825716: Current learning rate: 0.0084 
2025-08-28 03:39:00.937854: train_loss -0.2541 
2025-08-28 03:39:00.946102: val_loss -0.348 
2025-08-28 03:39:00.950462: Pseudo dice [np.float32(0.5504)] 
2025-08-28 03:39:00.958288: Epoch time: 16.12 s 
2025-08-28 03:39:01.613317:  
2025-08-28 03:39:01.621666: Epoch 177 
2025-08-28 03:39:01.625810: Current learning rate: 0.00839 
2025-08-28 03:39:18.401968: train_loss -0.2953 
2025-08-28 03:39:18.409251: val_loss -0.3675 
2025-08-28 03:39:18.417582: Pseudo dice [np.float32(0.6078)] 
2025-08-28 03:39:18.422535: Epoch time: 16.79 s 
2025-08-28 03:39:19.081369:  
2025-08-28 03:39:19.084946: Epoch 178 
2025-08-28 03:39:19.093618: Current learning rate: 0.00838 
2025-08-28 03:39:35.760133: train_loss -0.2942 
2025-08-28 03:39:35.768716: val_loss -0.3112 
2025-08-28 03:39:35.776644: Pseudo dice [np.float32(0.5183)] 
2025-08-28 03:39:35.782218: Epoch time: 16.68 s 
2025-08-28 03:39:36.585751:  
2025-08-28 03:39:36.594095: Epoch 179 
2025-08-28 03:39:36.598615: Current learning rate: 0.00837 
2025-08-28 03:39:53.073289: train_loss -0.2894 
2025-08-28 03:39:53.081366: val_loss -0.4328 
2025-08-28 03:39:53.085529: Pseudo dice [np.float32(0.6525)] 
2025-08-28 03:39:53.094850: Epoch time: 16.49 s 
2025-08-28 03:39:53.744585:  
2025-08-28 03:39:53.752566: Epoch 180 
2025-08-28 03:39:53.757394: Current learning rate: 0.00836 
2025-08-28 03:40:09.573528: train_loss -0.3217 
2025-08-28 03:40:09.581499: val_loss -0.4064 
2025-08-28 03:40:09.585367: Pseudo dice [np.float32(0.6575)] 
2025-08-28 03:40:09.593729: Epoch time: 15.83 s 
2025-08-28 03:40:09.598847: Yayy! New best EMA pseudo Dice: 0.6007999777793884 
2025-08-28 03:40:10.415766:  
2025-08-28 03:40:10.423688: Epoch 181 
2025-08-28 03:40:10.428203: Current learning rate: 0.00836 
2025-08-28 03:40:26.574737: train_loss -0.2947 
2025-08-28 03:40:26.581503: val_loss -0.363 
2025-08-28 03:40:26.589792: Pseudo dice [np.float32(0.6533)] 
2025-08-28 03:40:26.595352: Epoch time: 16.16 s 
2025-08-28 03:40:26.598957: Yayy! New best EMA pseudo Dice: 0.6061000227928162 
2025-08-28 03:40:27.411541:  
2025-08-28 03:40:27.420221: Epoch 182 
2025-08-28 03:40:27.424383: Current learning rate: 0.00835 
2025-08-28 03:40:43.265165: train_loss -0.3371 
2025-08-28 03:40:43.273167: val_loss -0.3781 
2025-08-28 03:40:43.281519: Pseudo dice [np.float32(0.6571)] 
2025-08-28 03:40:43.286586: Epoch time: 15.85 s 
2025-08-28 03:40:43.290710: Yayy! New best EMA pseudo Dice: 0.6111999750137329 
2025-08-28 03:40:44.103216:  
2025-08-28 03:40:44.111574: Epoch 183 
2025-08-28 03:40:44.115674: Current learning rate: 0.00834 
2025-08-28 03:41:00.390348: train_loss -0.3112 
2025-08-28 03:41:00.398608: val_loss -0.2499 
2025-08-28 03:41:00.402741: Pseudo dice [np.float32(0.4339)] 
2025-08-28 03:41:00.410892: Epoch time: 16.29 s 
2025-08-28 03:41:01.066273:  
2025-08-28 03:41:01.074347: Epoch 184 
2025-08-28 03:41:01.078446: Current learning rate: 0.00833 
2025-08-28 03:41:17.228179: train_loss -0.261 
2025-08-28 03:41:17.236270: val_loss -0.4271 
2025-08-28 03:41:17.245228: Pseudo dice [np.float32(0.6859)] 
2025-08-28 03:41:17.249671: Epoch time: 16.16 s 
2025-08-28 03:41:18.053702:  
2025-08-28 03:41:18.062102: Epoch 185 
2025-08-28 03:41:18.066238: Current learning rate: 0.00832 
2025-08-28 03:41:34.291229: train_loss -0.3341 
2025-08-28 03:41:34.299447: val_loss -0.3499 
2025-08-28 03:41:34.303610: Pseudo dice [np.float32(0.6685)] 
2025-08-28 03:41:34.311525: Epoch time: 16.24 s 
2025-08-28 03:41:34.954018:  
2025-08-28 03:41:34.962649: Epoch 186 
2025-08-28 03:41:34.966520: Current learning rate: 0.00831 
2025-08-28 03:41:51.554174: train_loss -0.2819 
2025-08-28 03:41:51.562249: val_loss -0.3621 
2025-08-28 03:41:51.566403: Pseudo dice [np.float32(0.7093)] 
2025-08-28 03:41:51.574720: Epoch time: 16.6 s 
2025-08-28 03:41:51.579718: Yayy! New best EMA pseudo Dice: 0.6193000078201294 
2025-08-28 03:41:52.394125:  
2025-08-28 03:41:52.400523: Epoch 187 
2025-08-28 03:41:52.404923: Current learning rate: 0.0083 
2025-08-28 03:42:08.762781: train_loss -0.3316 
2025-08-28 03:42:08.775119: val_loss -0.2793 
2025-08-28 03:42:08.779356: Pseudo dice [np.float32(0.4733)] 
2025-08-28 03:42:08.785899: Epoch time: 16.37 s 
2025-08-28 03:42:09.430007:  
2025-08-28 03:42:09.438364: Epoch 188 
2025-08-28 03:42:09.442806: Current learning rate: 0.00829 
2025-08-28 03:42:25.733788: train_loss -0.3004 
2025-08-28 03:42:25.742172: val_loss -0.3679 
2025-08-28 03:42:25.751133: Pseudo dice [np.float32(0.5985)] 
2025-08-28 03:42:25.756273: Epoch time: 16.3 s 
2025-08-28 03:42:26.417803:  
2025-08-28 03:42:26.422015: Epoch 189 
2025-08-28 03:42:26.430676: Current learning rate: 0.00828 
2025-08-28 03:42:43.084858: train_loss -0.2889 
2025-08-28 03:42:43.092899: val_loss -0.4133 
2025-08-28 03:42:43.101190: Pseudo dice [np.float32(0.7109)] 
2025-08-28 03:42:43.106533: Epoch time: 16.67 s 
2025-08-28 03:42:43.751789:  
2025-08-28 03:42:43.756225: Epoch 190 
2025-08-28 03:42:43.764322: Current learning rate: 0.00827 
2025-08-28 03:43:00.276609: train_loss -0.3391 
2025-08-28 03:43:00.285599: val_loss -0.4127 
2025-08-28 03:43:00.289117: Pseudo dice [np.float32(0.6139)] 
2025-08-28 03:43:00.297503: Epoch time: 16.52 s 
2025-08-28 03:43:01.098309:  
2025-08-28 03:43:01.102534: Epoch 191 
2025-08-28 03:43:01.110788: Current learning rate: 0.00826 
2025-08-28 03:43:17.644336: train_loss -0.3079 
2025-08-28 03:43:17.652362: val_loss -0.3959 
2025-08-28 03:43:17.656863: Pseudo dice [np.float32(0.6153)] 
2025-08-28 03:43:17.662759: Epoch time: 16.55 s 
2025-08-28 03:43:18.319625:  
2025-08-28 03:43:18.327968: Epoch 192 
2025-08-28 03:43:18.334152: Current learning rate: 0.00825 
2025-08-28 03:43:35.061880: train_loss -0.2829 
2025-08-28 03:43:35.069685: val_loss -0.3596 
2025-08-28 03:43:35.073823: Pseudo dice [np.float32(0.665)] 
2025-08-28 03:43:35.083139: Epoch time: 16.74 s 
2025-08-28 03:43:35.090260: Yayy! New best EMA pseudo Dice: 0.619700014591217 
2025-08-28 03:43:35.916367:  
2025-08-28 03:43:35.925092: Epoch 193 
2025-08-28 03:43:35.933519: Current learning rate: 0.00824 
2025-08-28 03:43:52.653893: train_loss -0.3349 
2025-08-28 03:43:52.666424: val_loss -0.3378 
2025-08-28 03:43:52.670590: Pseudo dice [np.float32(0.5279)] 
2025-08-28 03:43:52.678734: Epoch time: 16.74 s 
2025-08-28 03:43:53.333749:  
2025-08-28 03:43:53.341355: Epoch 194 
2025-08-28 03:43:53.346529: Current learning rate: 0.00824 
2025-08-28 03:44:10.146358: train_loss -0.322 
2025-08-28 03:44:10.154729: val_loss -0.4232 
2025-08-28 03:44:10.158881: Pseudo dice [np.float32(0.6733)] 
2025-08-28 03:44:10.165149: Epoch time: 16.82 s 
2025-08-28 03:44:10.822044:  
2025-08-28 03:44:10.830424: Epoch 195 
2025-08-28 03:44:10.837281: Current learning rate: 0.00823 
2025-08-28 03:44:27.071607: train_loss -0.3176 
2025-08-28 03:44:27.079952: val_loss -0.3487 
2025-08-28 03:44:27.088648: Pseudo dice [np.float32(0.5183)] 
2025-08-28 03:44:27.095136: Epoch time: 16.25 s 
2025-08-28 03:44:27.764039:  
2025-08-28 03:44:27.772414: Epoch 196 
2025-08-28 03:44:27.780326: Current learning rate: 0.00822 
2025-08-28 03:44:44.564389: train_loss -0.3021 
2025-08-28 03:44:44.572414: val_loss -0.3717 
2025-08-28 03:44:44.576871: Pseudo dice [np.float32(0.6922)] 
2025-08-28 03:44:44.583956: Epoch time: 16.8 s 
2025-08-28 03:44:45.385706:  
2025-08-28 03:44:45.394076: Epoch 197 
2025-08-28 03:44:45.398511: Current learning rate: 0.00821 
2025-08-28 03:45:01.239049: train_loss -0.3294 
2025-08-28 03:45:01.251613: val_loss -0.3035 
2025-08-28 03:45:01.256117: Pseudo dice [np.float32(0.6382)] 
2025-08-28 03:45:01.262087: Epoch time: 15.85 s 
2025-08-28 03:45:02.002378:  
2025-08-28 03:45:02.006500: Epoch 198 
2025-08-28 03:45:02.010775: Current learning rate: 0.0082 
2025-08-28 03:45:18.410366: train_loss -0.3834 
2025-08-28 03:45:18.418725: val_loss -0.3757 
2025-08-28 03:45:18.422871: Pseudo dice [np.float32(0.6653)] 
2025-08-28 03:45:18.432554: Epoch time: 16.41 s 
2025-08-28 03:45:18.436276: Yayy! New best EMA pseudo Dice: 0.6225000023841858 
2025-08-28 03:45:19.261205:  
2025-08-28 03:45:19.269843: Epoch 199 
2025-08-28 03:45:19.273767: Current learning rate: 0.00819 
2025-08-28 03:45:35.256361: train_loss -0.3254 
2025-08-28 03:45:35.264721: val_loss -0.3353 
2025-08-28 03:45:35.268919: Pseudo dice [np.float32(0.6181)] 
2025-08-28 03:45:35.276324: Epoch time: 16.0 s 
2025-08-28 03:45:36.124306:  
2025-08-28 03:45:36.132270: Epoch 200 
2025-08-28 03:45:36.136686: Current learning rate: 0.00818 
2025-08-28 03:45:52.298522: train_loss -0.3415 
2025-08-28 03:45:52.310942: val_loss -0.4036 
2025-08-28 03:45:52.315371: Pseudo dice [np.float32(0.7065)] 
2025-08-28 03:45:52.322372: Epoch time: 16.17 s 
2025-08-28 03:45:52.328075: Yayy! New best EMA pseudo Dice: 0.6305000185966492 
2025-08-28 03:45:53.190941:  
2025-08-28 03:45:53.199305: Epoch 201 
2025-08-28 03:45:53.203891: Current learning rate: 0.00817 
2025-08-28 03:46:09.357831: train_loss -0.3495 
2025-08-28 03:46:09.365691: val_loss -0.3937 
2025-08-28 03:46:09.374304: Pseudo dice [np.float32(0.6749)] 
2025-08-28 03:46:09.378679: Epoch time: 16.17 s 
2025-08-28 03:46:09.385024: Yayy! New best EMA pseudo Dice: 0.6349999904632568 
2025-08-28 03:46:10.208279:  
2025-08-28 03:46:10.218179: Epoch 202 
2025-08-28 03:46:10.220440: Current learning rate: 0.00816 
2025-08-28 03:46:26.834964: train_loss -0.3072 
2025-08-28 03:46:26.843558: val_loss -0.4072 
2025-08-28 03:46:26.849585: Pseudo dice [np.float32(0.6926)] 
2025-08-28 03:46:26.855080: Epoch time: 16.63 s 
2025-08-28 03:46:26.858706: Yayy! New best EMA pseudo Dice: 0.6406999826431274 
2025-08-28 03:46:27.850471:  
2025-08-28 03:46:27.858932: Epoch 203 
2025-08-28 03:46:27.863302: Current learning rate: 0.00815 
2025-08-28 03:46:43.758078: train_loss -0.3301 
2025-08-28 03:46:43.766460: val_loss -0.3523 
2025-08-28 03:46:43.770504: Pseudo dice [np.float32(0.5339)] 
2025-08-28 03:46:43.777914: Epoch time: 15.91 s 
2025-08-28 03:46:44.437913:  
2025-08-28 03:46:44.442132: Epoch 204 
2025-08-28 03:46:44.446303: Current learning rate: 0.00814 
2025-08-28 03:47:00.378834: train_loss -0.3159 
2025-08-28 03:47:00.387195: val_loss -0.3848 
2025-08-28 03:47:00.395614: Pseudo dice [np.float32(0.6895)] 
2025-08-28 03:47:00.400971: Epoch time: 15.94 s 
2025-08-28 03:47:01.062853:  
2025-08-28 03:47:01.067037: Epoch 205 
2025-08-28 03:47:01.075411: Current learning rate: 0.00813 
2025-08-28 03:47:17.195628: train_loss -0.3392 
2025-08-28 03:47:17.203976: val_loss -0.3823 
2025-08-28 03:47:17.212278: Pseudo dice [np.float32(0.6724)] 
2025-08-28 03:47:17.218669: Epoch time: 16.14 s 
2025-08-28 03:47:17.850773:  
2025-08-28 03:47:17.858907: Epoch 206 
2025-08-28 03:47:17.863167: Current learning rate: 0.00813 
2025-08-28 03:47:34.000090: train_loss -0.3023 
2025-08-28 03:47:34.008260: val_loss -0.3885 
2025-08-28 03:47:34.012426: Pseudo dice [np.float32(0.7471)] 
2025-08-28 03:47:34.020507: Epoch time: 16.15 s 
2025-08-28 03:47:34.026264: Yayy! New best EMA pseudo Dice: 0.6503999829292297 
2025-08-28 03:47:34.817459:  
2025-08-28 03:47:34.825809: Epoch 207 
2025-08-28 03:47:34.829943: Current learning rate: 0.00812 
2025-08-28 03:47:51.626401: train_loss -0.3231 
2025-08-28 03:47:51.634212: val_loss -0.3591 
2025-08-28 03:47:51.642882: Pseudo dice [np.float32(0.6164)] 
2025-08-28 03:47:51.648912: Epoch time: 16.81 s 
2025-08-28 03:47:52.280822:  
2025-08-28 03:47:52.289047: Epoch 208 
2025-08-28 03:47:52.293192: Current learning rate: 0.00811 
2025-08-28 03:48:08.438609: train_loss -0.3362 
2025-08-28 03:48:08.447143: val_loss -0.4024 
2025-08-28 03:48:08.451281: Pseudo dice [np.float32(0.6787)] 
2025-08-28 03:48:08.458151: Epoch time: 16.16 s 
2025-08-28 03:48:09.101614:  
2025-08-28 03:48:09.110184: Epoch 209 
2025-08-28 03:48:09.114176: Current learning rate: 0.0081 
2025-08-28 03:48:25.259778: train_loss -0.3209 
2025-08-28 03:48:25.267801: val_loss -0.366 
2025-08-28 03:48:25.271929: Pseudo dice [np.float32(0.619)] 
2025-08-28 03:48:25.279241: Epoch time: 16.16 s 
2025-08-28 03:48:26.081491:  
2025-08-28 03:48:26.089463: Epoch 210 
2025-08-28 03:48:26.093599: Current learning rate: 0.00809 
2025-08-28 03:48:42.113958: train_loss -0.363 
2025-08-28 03:48:42.122116: val_loss -0.3796 
2025-08-28 03:48:42.129333: Pseudo dice [np.float32(0.6713)] 
2025-08-28 03:48:42.134668: Epoch time: 16.03 s 
2025-08-28 03:48:42.773015:  
2025-08-28 03:48:42.780573: Epoch 211 
2025-08-28 03:48:42.785303: Current learning rate: 0.00808 
2025-08-28 03:48:58.753720: train_loss -0.3364 
2025-08-28 03:48:58.764067: val_loss -0.3626 
2025-08-28 03:48:58.768272: Pseudo dice [np.float32(0.6557)] 
2025-08-28 03:48:58.774775: Epoch time: 15.99 s 
2025-08-28 03:48:59.418541:  
2025-08-28 03:48:59.427274: Epoch 212 
2025-08-28 03:48:59.431052: Current learning rate: 0.00807 
2025-08-28 03:49:15.209582: train_loss -0.3559 
2025-08-28 03:49:15.217673: val_loss -0.3573 
2025-08-28 03:49:15.226332: Pseudo dice [np.float32(0.5992)] 
2025-08-28 03:49:15.231429: Epoch time: 15.79 s 
2025-08-28 03:49:15.872459:  
2025-08-28 03:49:15.876624: Epoch 213 
2025-08-28 03:49:15.885010: Current learning rate: 0.00806 
2025-08-28 03:49:31.784065: train_loss -0.3437 
2025-08-28 03:49:31.792294: val_loss -0.3645 
2025-08-28 03:49:31.796820: Pseudo dice [np.float32(0.6551)] 
2025-08-28 03:49:31.803017: Epoch time: 15.92 s 
2025-08-28 03:49:32.443256:  
2025-08-28 03:49:32.447370: Epoch 214 
2025-08-28 03:49:32.451522: Current learning rate: 0.00805 
2025-08-28 03:49:48.229749: train_loss -0.3192 
2025-08-28 03:49:48.238208: val_loss -0.4809 
2025-08-28 03:49:48.242265: Pseudo dice [np.float32(0.718)] 
2025-08-28 03:49:48.249561: Epoch time: 15.79 s 
2025-08-28 03:49:48.255136: Yayy! New best EMA pseudo Dice: 0.6531999707221985 
2025-08-28 03:49:49.061769:  
2025-08-28 03:49:49.071140: Epoch 215 
2025-08-28 03:49:49.077460: Current learning rate: 0.00804 
2025-08-28 03:50:05.847792: train_loss -0.3545 
2025-08-28 03:50:05.855703: val_loss -0.3903 
2025-08-28 03:50:05.859883: Pseudo dice [np.float32(0.6725)] 
2025-08-28 03:50:05.868063: Epoch time: 16.79 s 
2025-08-28 03:50:05.872833: Yayy! New best EMA pseudo Dice: 0.6550999879837036 
2025-08-28 03:50:06.823339:  
2025-08-28 03:50:06.831703: Epoch 216 
2025-08-28 03:50:06.835884: Current learning rate: 0.00803 
2025-08-28 03:50:23.231414: train_loss -0.374 
2025-08-28 03:50:23.239758: val_loss -0.3833 
2025-08-28 03:50:23.248643: Pseudo dice [np.float32(0.627)] 
2025-08-28 03:50:23.253671: Epoch time: 16.41 s 
2025-08-28 03:50:23.890357:  
2025-08-28 03:50:23.898734: Epoch 217 
2025-08-28 03:50:23.903200: Current learning rate: 0.00802 
2025-08-28 03:50:40.402783: train_loss -0.3411 
2025-08-28 03:50:40.411052: val_loss -0.4859 
2025-08-28 03:50:40.415210: Pseudo dice [np.float32(0.7699)] 
2025-08-28 03:50:40.423401: Epoch time: 16.52 s 
2025-08-28 03:50:40.429291: Yayy! New best EMA pseudo Dice: 0.6640999913215637 
2025-08-28 03:50:41.245201:  
2025-08-28 03:50:41.253547: Epoch 218 
2025-08-28 03:50:41.257751: Current learning rate: 0.00801 
2025-08-28 03:50:57.594551: train_loss -0.4092 
2025-08-28 03:50:57.603212: val_loss -0.3889 
2025-08-28 03:50:57.607372: Pseudo dice [np.float32(0.6552)] 
2025-08-28 03:50:57.615767: Epoch time: 16.35 s 
2025-08-28 03:50:58.253879:  
2025-08-28 03:50:58.262274: Epoch 219 
2025-08-28 03:50:58.266679: Current learning rate: 0.00801 
2025-08-28 03:51:14.524567: train_loss -0.3758 
2025-08-28 03:51:14.532585: val_loss -0.4449 
2025-08-28 03:51:14.537115: Pseudo dice [np.float32(0.7127)] 
2025-08-28 03:51:14.544326: Epoch time: 16.27 s 
2025-08-28 03:51:14.549800: Yayy! New best EMA pseudo Dice: 0.6680999994277954 
2025-08-28 03:51:15.346222:  
2025-08-28 03:51:15.354629: Epoch 220 
2025-08-28 03:51:15.358744: Current learning rate: 0.008 
2025-08-28 03:51:31.850421: train_loss -0.2925 
2025-08-28 03:51:31.858501: val_loss -0.3545 
2025-08-28 03:51:31.862388: Pseudo dice [np.float32(0.5862)] 
2025-08-28 03:51:31.871507: Epoch time: 16.5 s 
2025-08-28 03:51:32.508878:  
2025-08-28 03:51:32.513084: Epoch 221 
2025-08-28 03:51:32.521426: Current learning rate: 0.00799 
2025-08-28 03:51:48.808596: train_loss -0.3651 
2025-08-28 03:51:48.817100: val_loss -0.3724 
2025-08-28 03:51:48.824855: Pseudo dice [np.float32(0.5741)] 
2025-08-28 03:51:48.830014: Epoch time: 16.3 s 
2025-08-28 03:51:49.496713:  
2025-08-28 03:51:49.505037: Epoch 222 
2025-08-28 03:51:49.509199: Current learning rate: 0.00798 
2025-08-28 03:52:06.104928: train_loss -0.3427 
2025-08-28 03:52:06.113281: val_loss -0.4137 
2025-08-28 03:52:06.121620: Pseudo dice [np.float32(0.7005)] 
2025-08-28 03:52:06.127210: Epoch time: 16.61 s 
2025-08-28 03:52:06.922639:  
2025-08-28 03:52:06.930793: Epoch 223 
2025-08-28 03:52:06.934999: Current learning rate: 0.00797 
2025-08-28 03:52:23.447559: train_loss -0.3386 
2025-08-28 03:52:23.455656: val_loss -0.376 
2025-08-28 03:52:23.460068: Pseudo dice [np.float32(0.7014)] 
2025-08-28 03:52:23.467446: Epoch time: 16.52 s 
2025-08-28 03:52:24.102130:  
2025-08-28 03:52:24.110684: Epoch 224 
2025-08-28 03:52:24.114652: Current learning rate: 0.00796 
2025-08-28 03:52:40.985591: train_loss -0.3996 
2025-08-28 03:52:40.993935: val_loss -0.4164 
2025-08-28 03:52:40.998085: Pseudo dice [np.float32(0.6729)] 
2025-08-28 03:52:41.007417: Epoch time: 16.88 s 
2025-08-28 03:52:41.690454:  
2025-08-28 03:52:41.698823: Epoch 225 
2025-08-28 03:52:41.707163: Current learning rate: 0.00795 
2025-08-28 03:52:58.277956: train_loss -0.3324 
2025-08-28 03:52:58.290367: val_loss -0.4353 
2025-08-28 03:52:58.294899: Pseudo dice [np.float32(0.7198)] 
2025-08-28 03:52:58.302851: Epoch time: 16.59 s 
2025-08-28 03:52:58.929189:  
2025-08-28 03:52:58.936919: Epoch 226 
2025-08-28 03:52:58.941086: Current learning rate: 0.00794 
2025-08-28 03:53:15.524228: train_loss -0.3271 
2025-08-28 03:53:15.532891: val_loss -0.4659 
2025-08-28 03:53:15.540859: Pseudo dice [np.float32(0.7508)] 
2025-08-28 03:53:15.546249: Epoch time: 16.6 s 
2025-08-28 03:53:15.550160: Yayy! New best EMA pseudo Dice: 0.6761000156402588 
2025-08-28 03:53:16.366762:  
2025-08-28 03:53:16.375075: Epoch 227 
2025-08-28 03:53:16.379590: Current learning rate: 0.00793 
2025-08-28 03:53:32.512428: train_loss -0.3532 
2025-08-28 03:53:32.520389: val_loss -0.3723 
2025-08-28 03:53:32.529047: Pseudo dice [np.float32(0.6397)] 
2025-08-28 03:53:32.535412: Epoch time: 16.15 s 
2025-08-28 03:53:33.162693:  
2025-08-28 03:53:33.171303: Epoch 228 
2025-08-28 03:53:33.175774: Current learning rate: 0.00792 
2025-08-28 03:53:49.366345: train_loss -0.3747 
2025-08-28 03:53:49.374704: val_loss -0.3908 
2025-08-28 03:53:49.383109: Pseudo dice [np.float32(0.6794)] 
2025-08-28 03:53:49.388490: Epoch time: 16.2 s 
2025-08-28 03:53:50.083755:  
2025-08-28 03:53:50.092076: Epoch 229 
2025-08-28 03:53:50.096579: Current learning rate: 0.00791 
2025-08-28 03:54:05.590955: train_loss -0.3405 
2025-08-28 03:54:05.599330: val_loss -0.3372 
2025-08-28 03:54:05.607603: Pseudo dice [np.float32(0.6734)] 
2025-08-28 03:54:05.613981: Epoch time: 15.51 s 
2025-08-28 03:54:06.404201:  
2025-08-28 03:54:06.408389: Epoch 230 
2025-08-28 03:54:06.416555: Current learning rate: 0.0079 
2025-08-28 03:54:22.286726: train_loss -0.3395 
2025-08-28 03:54:22.295471: val_loss -0.39 
2025-08-28 03:54:22.303416: Pseudo dice [np.float32(0.6407)] 
2025-08-28 03:54:22.309783: Epoch time: 15.89 s 
2025-08-28 03:54:22.941544:  
2025-08-28 03:54:22.946189: Epoch 231 
2025-08-28 03:54:22.954070: Current learning rate: 0.00789 
2025-08-28 03:54:39.174440: train_loss -0.3304 
2025-08-28 03:54:39.183057: val_loss -0.4139 
2025-08-28 03:54:39.187308: Pseudo dice [np.float32(0.6694)] 
2025-08-28 03:54:39.194627: Epoch time: 16.24 s 
2025-08-28 03:54:39.829228:  
2025-08-28 03:54:39.840368: Epoch 232 
2025-08-28 03:54:39.846577: Current learning rate: 0.00789 
2025-08-28 03:54:55.778434: train_loss -0.3426 
2025-08-28 03:54:55.787161: val_loss -0.4382 
2025-08-28 03:54:55.795227: Pseudo dice [np.float32(0.6762)] 
2025-08-28 03:54:55.801627: Epoch time: 15.95 s 
2025-08-28 03:54:56.437487:  
2025-08-28 03:54:56.445872: Epoch 233 
2025-08-28 03:54:56.450440: Current learning rate: 0.00788 
2025-08-28 03:55:12.591311: train_loss -0.3544 
2025-08-28 03:55:12.603673: val_loss -0.3069 
2025-08-28 03:55:12.608122: Pseudo dice [np.float32(0.5505)] 
2025-08-28 03:55:12.615270: Epoch time: 16.16 s 
2025-08-28 03:55:13.254587:  
2025-08-28 03:55:13.262951: Epoch 234 
2025-08-28 03:55:13.267128: Current learning rate: 0.00787 
2025-08-28 03:55:29.367209: train_loss -0.347 
2025-08-28 03:55:29.374552: val_loss -0.4339 
2025-08-28 03:55:29.378716: Pseudo dice [np.float32(0.6966)] 
2025-08-28 03:55:29.388279: Epoch time: 16.11 s 
2025-08-28 03:55:30.021093:  
2025-08-28 03:55:30.029664: Epoch 235 
2025-08-28 03:55:30.033554: Current learning rate: 0.00786 
2025-08-28 03:55:46.746413: train_loss -0.3565 
2025-08-28 03:55:46.754418: val_loss -0.4761 
2025-08-28 03:55:46.762760: Pseudo dice [np.float32(0.7091)] 
2025-08-28 03:55:46.768828: Epoch time: 16.73 s 
2025-08-28 03:55:47.538619:  
2025-08-28 03:55:47.546899: Epoch 236 
2025-08-28 03:55:47.551341: Current learning rate: 0.00785 
2025-08-28 03:56:04.075852: train_loss -0.3855 
2025-08-28 03:56:04.088380: val_loss -0.4809 
2025-08-28 03:56:04.092546: Pseudo dice [np.float32(0.6781)] 
2025-08-28 03:56:04.099825: Epoch time: 16.54 s 
2025-08-28 03:56:04.726499:  
2025-08-28 03:56:04.734903: Epoch 237 
2025-08-28 03:56:04.739042: Current learning rate: 0.00784 
2025-08-28 03:56:21.210757: train_loss -0.3852 
2025-08-28 03:56:21.218003: val_loss -0.4298 
2025-08-28 03:56:21.226327: Pseudo dice [np.float32(0.6733)] 
2025-08-28 03:56:21.231655: Epoch time: 16.48 s 
2025-08-28 03:56:21.860292:  
2025-08-28 03:56:21.868649: Epoch 238 
2025-08-28 03:56:21.872843: Current learning rate: 0.00783 
2025-08-28 03:56:38.097814: train_loss -0.3453 
2025-08-28 03:56:38.105675: val_loss -0.3373 
2025-08-28 03:56:38.109866: Pseudo dice [np.float32(0.7252)] 
2025-08-28 03:56:38.118059: Epoch time: 16.24 s 
2025-08-28 03:56:38.743796:  
2025-08-28 03:56:38.747995: Epoch 239 
2025-08-28 03:56:38.752135: Current learning rate: 0.00782 
2025-08-28 03:56:55.131426: train_loss -0.3342 
2025-08-28 03:56:55.139365: val_loss -0.3972 
2025-08-28 03:56:55.147793: Pseudo dice [np.float32(0.7153)] 
2025-08-28 03:56:55.153107: Epoch time: 16.39 s 
2025-08-28 03:56:55.156986: Yayy! New best EMA pseudo Dice: 0.6783999800682068 
2025-08-28 03:56:55.960996:  
2025-08-28 03:56:55.965451: Epoch 240 
2025-08-28 03:56:55.973887: Current learning rate: 0.00781 
2025-08-28 03:57:12.515246: train_loss -0.3613 
2025-08-28 03:57:12.523394: val_loss -0.3922 
2025-08-28 03:57:12.527554: Pseudo dice [np.float32(0.6485)] 
2025-08-28 03:57:12.535797: Epoch time: 16.56 s 
2025-08-28 03:57:13.191048:  
2025-08-28 03:57:13.199399: Epoch 241 
2025-08-28 03:57:13.203265: Current learning rate: 0.0078 
2025-08-28 03:57:29.970481: train_loss -0.3155 
2025-08-28 03:57:29.978653: val_loss -0.3908 
2025-08-28 03:57:29.982509: Pseudo dice [np.float32(0.6847)] 
2025-08-28 03:57:29.990666: Epoch time: 16.78 s 
2025-08-28 03:57:30.641464:  
2025-08-28 03:57:30.649825: Epoch 242 
2025-08-28 03:57:30.654248: Current learning rate: 0.00779 
2025-08-28 03:57:47.458338: train_loss -0.3141 
2025-08-28 03:57:47.466944: val_loss -0.3569 
2025-08-28 03:57:47.471081: Pseudo dice [np.float32(0.625)] 
2025-08-28 03:57:47.477009: Epoch time: 16.82 s 
2025-08-28 03:57:48.275730:  
2025-08-28 03:57:48.284079: Epoch 243 
2025-08-28 03:57:48.288242: Current learning rate: 0.00778 
2025-08-28 03:58:04.775982: train_loss -0.3425 
2025-08-28 03:58:04.788073: val_loss -0.4207 
2025-08-28 03:58:04.792395: Pseudo dice [np.float32(0.7122)] 
2025-08-28 03:58:04.801471: Epoch time: 16.5 s 
2025-08-28 03:58:05.434560:  
2025-08-28 03:58:05.439042: Epoch 244 
2025-08-28 03:58:05.447065: Current learning rate: 0.00777 
2025-08-28 03:58:22.184585: train_loss -0.3605 
2025-08-28 03:58:22.193346: val_loss -0.4725 
2025-08-28 03:58:22.201572: Pseudo dice [np.float32(0.6974)] 
2025-08-28 03:58:22.206902: Epoch time: 16.75 s 
2025-08-28 03:58:22.847678:  
2025-08-28 03:58:22.852227: Epoch 245 
2025-08-28 03:58:22.860278: Current learning rate: 0.00777 
2025-08-28 03:58:38.192382: train_loss -0.3779 
2025-08-28 03:58:38.200875: val_loss -0.3612 
2025-08-28 03:58:38.209181: Pseudo dice [np.float32(0.6388)] 
2025-08-28 03:58:38.214470: Epoch time: 15.35 s 
2025-08-28 03:58:38.855726:  
2025-08-28 03:58:38.859570: Epoch 246 
2025-08-28 03:58:38.867955: Current learning rate: 0.00776 
2025-08-28 03:58:54.258973: train_loss -0.3606 
2025-08-28 03:58:54.270816: val_loss -0.4304 
2025-08-28 03:58:54.275401: Pseudo dice [np.float32(0.7039)] 
2025-08-28 03:58:54.281310: Epoch time: 15.41 s 
2025-08-28 03:58:54.913171:  
2025-08-28 03:58:54.921778: Epoch 247 
2025-08-28 03:58:54.925833: Current learning rate: 0.00775 
2025-08-28 03:59:10.245083: train_loss -0.3799 
2025-08-28 03:59:10.253748: val_loss -0.4278 
2025-08-28 03:59:10.261841: Pseudo dice [np.float32(0.6521)] 
2025-08-28 03:59:10.268118: Epoch time: 15.33 s 
2025-08-28 03:59:10.908571:  
2025-08-28 03:59:10.916601: Epoch 248 
2025-08-28 03:59:10.920796: Current learning rate: 0.00774 
2025-08-28 03:59:27.762590: train_loss -0.3855 
2025-08-28 03:59:27.766741: val_loss -0.4781 
2025-08-28 03:59:27.775101: Pseudo dice [np.float32(0.7795)] 
2025-08-28 03:59:27.780468: Epoch time: 16.85 s 
2025-08-28 03:59:27.784264: Yayy! New best EMA pseudo Dice: 0.6847000122070312 
2025-08-28 03:59:28.592636:  
2025-08-28 03:59:28.601199: Epoch 249 
2025-08-28 03:59:28.609364: Current learning rate: 0.00773 
2025-08-28 03:59:45.267595: train_loss -0.3759 
2025-08-28 03:59:45.275900: val_loss -0.3686 
2025-08-28 03:59:45.280060: Pseudo dice [np.float32(0.6726)] 
2025-08-28 03:59:45.287297: Epoch time: 16.67 s 
2025-08-28 03:59:46.281126:  
2025-08-28 03:59:46.289724: Epoch 250 
2025-08-28 03:59:46.293590: Current learning rate: 0.00772 
2025-08-28 04:00:03.165310: train_loss -0.3495 
2025-08-28 04:00:03.177119: val_loss -0.4055 
2025-08-28 04:00:03.181626: Pseudo dice [np.float32(0.7302)] 
2025-08-28 04:00:03.187551: Epoch time: 16.88 s 
2025-08-28 04:00:03.190573: Yayy! New best EMA pseudo Dice: 0.6881999969482422 
2025-08-28 04:00:03.990406:  
2025-08-28 04:00:03.998747: Epoch 251 
2025-08-28 04:00:04.002928: Current learning rate: 0.00771 
2025-08-28 04:00:20.594496: train_loss -0.3756 
2025-08-28 04:00:20.603876: val_loss -0.3551 
2025-08-28 04:00:20.611465: Pseudo dice [np.float32(0.6154)] 
2025-08-28 04:00:20.616741: Epoch time: 16.6 s 
2025-08-28 04:00:21.253558:  
2025-08-28 04:00:21.261833: Epoch 252 
2025-08-28 04:00:21.265988: Current learning rate: 0.0077 
2025-08-28 04:00:37.899483: train_loss -0.3532 
2025-08-28 04:00:37.907996: val_loss -0.2951 
2025-08-28 04:00:37.912132: Pseudo dice [np.float32(0.556)] 
2025-08-28 04:00:37.920093: Epoch time: 16.65 s 
2025-08-28 04:00:38.587435:  
2025-08-28 04:00:38.595800: Epoch 253 
2025-08-28 04:00:38.599945: Current learning rate: 0.00769 
2025-08-28 04:00:55.349935: train_loss -0.3375 
2025-08-28 04:00:55.358742: val_loss -0.4377 
2025-08-28 04:00:55.362789: Pseudo dice [np.float32(0.713)] 
2025-08-28 04:00:55.370654: Epoch time: 16.76 s 
2025-08-28 04:00:56.005186:  
2025-08-28 04:00:56.013268: Epoch 254 
2025-08-28 04:00:56.017656: Current learning rate: 0.00768 
2025-08-28 04:01:12.467113: train_loss -0.347 
2025-08-28 04:01:12.475695: val_loss -0.4405 
2025-08-28 04:01:12.483752: Pseudo dice [np.float32(0.6325)] 
2025-08-28 04:01:12.489257: Epoch time: 16.46 s 
2025-08-28 04:01:13.126201:  
2025-08-28 04:01:13.134532: Epoch 255 
2025-08-28 04:01:13.138660: Current learning rate: 0.00767 
2025-08-28 04:01:29.846189: train_loss -0.3837 
2025-08-28 04:01:29.851452: val_loss -0.373 
2025-08-28 04:01:29.859509: Pseudo dice [np.float32(0.6952)] 
2025-08-28 04:01:29.864325: Epoch time: 16.72 s 
2025-08-28 04:01:30.505970:  
2025-08-28 04:01:30.514343: Epoch 256 
2025-08-28 04:01:30.518487: Current learning rate: 0.00766 
2025-08-28 04:01:47.031041: train_loss -0.3572 
2025-08-28 04:01:47.039162: val_loss -0.4694 
2025-08-28 04:01:47.043300: Pseudo dice [np.float32(0.7249)] 
2025-08-28 04:01:47.051629: Epoch time: 16.53 s 
2025-08-28 04:01:47.845592:  
2025-08-28 04:01:47.852463: Epoch 257 
2025-08-28 04:01:47.856655: Current learning rate: 0.00765 
2025-08-28 04:02:03.676679: train_loss -0.3602 
2025-08-28 04:02:03.684926: val_loss -0.4552 
2025-08-28 04:02:03.693578: Pseudo dice [np.float32(0.6982)] 
2025-08-28 04:02:03.698807: Epoch time: 15.83 s 
2025-08-28 04:02:04.327236:  
2025-08-28 04:02:04.337989: Epoch 258 
2025-08-28 04:02:04.343857: Current learning rate: 0.00764 
2025-08-28 04:02:20.197563: train_loss -0.3516 
2025-08-28 04:02:20.205590: val_loss -0.3894 
2025-08-28 04:02:20.210057: Pseudo dice [np.float32(0.7199)] 
2025-08-28 04:02:20.218951: Epoch time: 15.87 s 
2025-08-28 04:02:20.856217:  
2025-08-28 04:02:20.864614: Epoch 259 
2025-08-28 04:02:20.868744: Current learning rate: 0.00764 
2025-08-28 04:02:37.080802: train_loss -0.3929 
2025-08-28 04:02:37.089534: val_loss -0.3692 
2025-08-28 04:02:37.097445: Pseudo dice [np.float32(0.6868)] 
2025-08-28 04:02:37.102961: Epoch time: 16.22 s 
2025-08-28 04:02:37.743924:  
2025-08-28 04:02:37.752279: Epoch 260 
2025-08-28 04:02:37.756447: Current learning rate: 0.00763 
2025-08-28 04:02:54.665237: train_loss -0.3366 
2025-08-28 04:02:54.673343: val_loss -0.4414 
2025-08-28 04:02:54.677531: Pseudo dice [np.float32(0.7295)] 
2025-08-28 04:02:54.685903: Epoch time: 16.92 s 
2025-08-28 04:02:55.319818:  
2025-08-28 04:02:55.328474: Epoch 261 
2025-08-28 04:02:55.336507: Current learning rate: 0.00762 
2025-08-28 04:03:12.503871: train_loss -0.3897 
2025-08-28 04:03:12.511981: val_loss -0.4178 
2025-08-28 04:03:12.520320: Pseudo dice [np.float32(0.6361)] 
2025-08-28 04:03:12.526846: Epoch time: 17.18 s 
2025-08-28 04:03:13.171006:  
2025-08-28 04:03:13.179319: Epoch 262 
2025-08-28 04:03:13.183573: Current learning rate: 0.00761 
2025-08-28 04:03:30.104544: train_loss -0.3784 
2025-08-28 04:03:30.112900: val_loss -0.4003 
2025-08-28 04:03:30.117397: Pseudo dice [np.float32(0.6875)] 
2025-08-28 04:03:30.124209: Epoch time: 16.93 s 
2025-08-28 04:03:30.763930:  
2025-08-28 04:03:30.771935: Epoch 263 
2025-08-28 04:03:30.780241: Current learning rate: 0.0076 
2025-08-28 04:03:47.667910: train_loss -0.3773 
2025-08-28 04:03:47.676321: val_loss -0.4437 
2025-08-28 04:03:47.680715: Pseudo dice [np.float32(0.6956)] 
2025-08-28 04:03:47.686835: Epoch time: 16.9 s 
2025-08-28 04:03:48.489595:  
2025-08-28 04:03:48.498295: Epoch 264 
2025-08-28 04:03:48.502225: Current learning rate: 0.00759 
2025-08-28 04:04:05.102000: train_loss -0.3571 
2025-08-28 04:04:05.110309: val_loss -0.4512 
2025-08-28 04:04:05.114800: Pseudo dice [np.float32(0.6974)] 
2025-08-28 04:04:05.122837: Epoch time: 16.61 s 
2025-08-28 04:04:05.752643:  
2025-08-28 04:04:05.761257: Epoch 265 
2025-08-28 04:04:05.765238: Current learning rate: 0.00758 
2025-08-28 04:04:22.486063: train_loss -0.3936 
2025-08-28 04:04:22.494410: val_loss -0.4051 
2025-08-28 04:04:22.498591: Pseudo dice [np.float32(0.6973)] 
2025-08-28 04:04:22.506674: Epoch time: 16.73 s 
2025-08-28 04:04:23.144989:  
2025-08-28 04:04:23.153338: Epoch 266 
2025-08-28 04:04:23.157493: Current learning rate: 0.00757 
2025-08-28 04:04:39.782631: train_loss -0.3626 
2025-08-28 04:04:39.790775: val_loss -0.4623 
2025-08-28 04:04:39.795202: Pseudo dice [np.float32(0.7027)] 
2025-08-28 04:04:39.804202: Epoch time: 16.64 s 
2025-08-28 04:04:39.809847: Yayy! New best EMA pseudo Dice: 0.6884999871253967 
2025-08-28 04:04:40.608377:  
2025-08-28 04:04:40.616623: Epoch 267 
2025-08-28 04:04:40.624846: Current learning rate: 0.00756 
2025-08-28 04:04:57.095854: train_loss -0.3619 
2025-08-28 04:04:57.103921: val_loss -0.3885 
2025-08-28 04:04:57.112522: Pseudo dice [np.float32(0.6682)] 
2025-08-28 04:04:57.117635: Epoch time: 16.49 s 
2025-08-28 04:04:57.779593:  
2025-08-28 04:04:57.787923: Epoch 268 
2025-08-28 04:04:57.792105: Current learning rate: 0.00755 
2025-08-28 04:05:14.413320: train_loss -0.3562 
2025-08-28 04:05:14.421547: val_loss -0.4454 
2025-08-28 04:05:14.425358: Pseudo dice [np.float32(0.7513)] 
2025-08-28 04:05:14.434518: Epoch time: 16.63 s 
2025-08-28 04:05:14.438796: Yayy! New best EMA pseudo Dice: 0.6930000185966492 
2025-08-28 04:05:15.234508:  
2025-08-28 04:05:15.242955: Epoch 269 
2025-08-28 04:05:15.247048: Current learning rate: 0.00754 
2025-08-28 04:05:31.642558: train_loss -0.4006 
2025-08-28 04:05:31.650897: val_loss -0.4458 
2025-08-28 04:05:31.655052: Pseudo dice [np.float32(0.7099)] 
2025-08-28 04:05:31.664334: Epoch time: 16.41 s 
2025-08-28 04:05:31.668392: Yayy! New best EMA pseudo Dice: 0.6947000026702881 
2025-08-28 04:05:32.631066:  
2025-08-28 04:05:32.639395: Epoch 270 
2025-08-28 04:05:32.643564: Current learning rate: 0.00753 
2025-08-28 04:05:49.126760: train_loss -0.3824 
2025-08-28 04:05:49.135044: val_loss -0.4388 
2025-08-28 04:05:49.143439: Pseudo dice [np.float32(0.666)] 
2025-08-28 04:05:49.147623: Epoch time: 16.5 s 
2025-08-28 04:05:49.786175:  
2025-08-28 04:05:49.794031: Epoch 271 
2025-08-28 04:05:49.798162: Current learning rate: 0.00752 
2025-08-28 04:06:05.560127: train_loss -0.3967 
2025-08-28 04:06:05.568428: val_loss -0.508 
2025-08-28 04:06:05.576186: Pseudo dice [np.float32(0.7868)] 
2025-08-28 04:06:05.581463: Epoch time: 15.77 s 
2025-08-28 04:06:05.585752: Yayy! New best EMA pseudo Dice: 0.7013000249862671 
2025-08-28 04:06:06.418974:  
2025-08-28 04:06:06.423142: Epoch 272 
2025-08-28 04:06:06.427319: Current learning rate: 0.00751 
2025-08-28 04:06:21.976190: train_loss -0.3893 
2025-08-28 04:06:21.984499: val_loss -0.4333 
2025-08-28 04:06:21.988666: Pseudo dice [np.float32(0.7351)] 
2025-08-28 04:06:21.997815: Epoch time: 15.56 s 
2025-08-28 04:06:22.002523: Yayy! New best EMA pseudo Dice: 0.7046999931335449 
2025-08-28 04:06:22.823005:  
2025-08-28 04:06:22.831545: Epoch 273 
2025-08-28 04:06:22.839489: Current learning rate: 0.00751 
2025-08-28 04:06:40.027502: train_loss -0.3934 
2025-08-28 04:06:40.035858: val_loss -0.4098 
2025-08-28 04:06:40.044207: Pseudo dice [np.float32(0.6579)] 
2025-08-28 04:06:40.049861: Epoch time: 17.2 s 
2025-08-28 04:06:40.962122:  
2025-08-28 04:06:40.970128: Epoch 274 
2025-08-28 04:06:40.974337: Current learning rate: 0.0075 
2025-08-28 04:06:59.918544: train_loss -0.3758 
2025-08-28 04:06:59.926829: val_loss -0.4813 
2025-08-28 04:06:59.934875: Pseudo dice [np.float32(0.7829)] 
2025-08-28 04:06:59.941537: Epoch time: 18.96 s 
2025-08-28 04:06:59.944184: Yayy! New best EMA pseudo Dice: 0.708299994468689 
2025-08-28 04:07:00.848716:  
2025-08-28 04:07:00.856936: Epoch 275 
2025-08-28 04:07:00.864998: Current learning rate: 0.00749 
2025-08-28 04:07:18.887428: train_loss -0.396 
2025-08-28 04:07:18.895816: val_loss -0.4771 
2025-08-28 04:07:18.899643: Pseudo dice [np.float32(0.7248)] 
2025-08-28 04:07:18.905893: Epoch time: 18.04 s 
2025-08-28 04:07:18.912686: Yayy! New best EMA pseudo Dice: 0.7099000215530396 
2025-08-28 04:07:19.888958:  
2025-08-28 04:07:19.896878: Epoch 276 
2025-08-28 04:07:19.904835: Current learning rate: 0.00748 
2025-08-28 04:07:36.012811: train_loss -0.3843 
2025-08-28 04:07:36.020916: val_loss -0.4963 
2025-08-28 04:07:36.029076: Pseudo dice [np.float32(0.6901)] 
2025-08-28 04:07:36.034393: Epoch time: 16.12 s 
2025-08-28 04:07:36.676085:  
2025-08-28 04:07:36.684063: Epoch 277 
2025-08-28 04:07:36.688646: Current learning rate: 0.00747 
2025-08-28 04:07:52.891671: train_loss -0.3744 
2025-08-28 04:07:52.904405: val_loss -0.3551 
2025-08-28 04:07:52.908875: Pseudo dice [np.float32(0.6975)] 
2025-08-28 04:07:52.916346: Epoch time: 16.22 s 
2025-08-28 04:07:53.626286:  
2025-08-28 04:07:53.634434: Epoch 278 
2025-08-28 04:07:53.638590: Current learning rate: 0.00746 
2025-08-28 04:08:12.098665: train_loss -0.3541 
2025-08-28 04:08:12.106945: val_loss -0.3296 
2025-08-28 04:08:12.111171: Pseudo dice [np.float32(0.6308)] 
2025-08-28 04:08:12.119303: Epoch time: 18.47 s 
2025-08-28 04:08:12.770416:  
2025-08-28 04:08:12.774562: Epoch 279 
2025-08-28 04:08:12.782953: Current learning rate: 0.00745 
2025-08-28 04:08:29.457602: train_loss -0.368 
2025-08-28 04:08:29.468302: val_loss -0.4196 
2025-08-28 04:08:29.474282: Pseudo dice [np.float32(0.6771)] 
2025-08-28 04:08:29.480341: Epoch time: 16.69 s 
2025-08-28 04:08:30.129142:  
2025-08-28 04:08:30.137461: Epoch 280 
2025-08-28 04:08:30.141661: Current learning rate: 0.00744 
2025-08-28 04:08:46.925372: train_loss -0.3388 
2025-08-28 04:08:46.933447: val_loss -0.4673 
2025-08-28 04:08:46.938182: Pseudo dice [np.float32(0.7243)] 
2025-08-28 04:08:46.943990: Epoch time: 16.8 s 
2025-08-28 04:08:47.588211:  
2025-08-28 04:08:47.596937: Epoch 281 
2025-08-28 04:08:47.600747: Current learning rate: 0.00743 
2025-08-28 04:09:04.509680: train_loss -0.3702 
2025-08-28 04:09:04.521863: val_loss -0.425 
2025-08-28 04:09:04.526252: Pseudo dice [np.float32(0.6853)] 
2025-08-28 04:09:04.533304: Epoch time: 16.93 s 
2025-08-28 04:09:05.180813:  
2025-08-28 04:09:05.184942: Epoch 282 
2025-08-28 04:09:05.194055: Current learning rate: 0.00742 
2025-08-28 04:09:22.218606: train_loss -0.3885 
2025-08-28 04:09:22.226961: val_loss -0.4962 
2025-08-28 04:09:22.231119: Pseudo dice [np.float32(0.707)] 
2025-08-28 04:09:22.239507: Epoch time: 17.04 s 
2025-08-28 04:09:23.052810:  
2025-08-28 04:09:23.056990: Epoch 283 
2025-08-28 04:09:23.065328: Current learning rate: 0.00741 
2025-08-28 04:09:39.923814: train_loss -0.4192 
2025-08-28 04:09:39.932143: val_loss -0.4408 
2025-08-28 04:09:39.941068: Pseudo dice [np.float32(0.7544)] 
2025-08-28 04:09:39.946146: Epoch time: 16.88 s 
2025-08-28 04:09:40.716282:  
2025-08-28 04:09:40.724630: Epoch 284 
2025-08-28 04:09:40.729138: Current learning rate: 0.0074 
2025-08-28 04:09:57.766630: train_loss -0.3584 
2025-08-28 04:09:57.774957: val_loss -0.3942 
2025-08-28 04:09:57.783967: Pseudo dice [np.float32(0.6891)] 
2025-08-28 04:09:57.789591: Epoch time: 17.05 s 
2025-08-28 04:09:58.434329:  
2025-08-28 04:09:58.442598: Epoch 285 
2025-08-28 04:09:58.446608: Current learning rate: 0.00739 
2025-08-28 04:10:15.246616: train_loss -0.3946 
2025-08-28 04:10:15.254948: val_loss -0.5166 
2025-08-28 04:10:15.259089: Pseudo dice [np.float32(0.7301)] 
2025-08-28 04:10:15.266451: Epoch time: 16.81 s 
2025-08-28 04:10:15.909735:  
2025-08-28 04:10:15.918079: Epoch 286 
2025-08-28 04:10:15.922234: Current learning rate: 0.00738 
2025-08-28 04:10:32.605557: train_loss -0.4074 
2025-08-28 04:10:32.613898: val_loss -0.4779 
2025-08-28 04:10:32.618083: Pseudo dice [np.float32(0.7394)] 
2025-08-28 04:10:32.626512: Epoch time: 16.7 s 
2025-08-28 04:10:33.277126:  
2025-08-28 04:10:33.281229: Epoch 287 
2025-08-28 04:10:33.289953: Current learning rate: 0.00738 
2025-08-28 04:10:49.918998: train_loss -0.4097 
2025-08-28 04:10:49.927019: val_loss -0.4502 
2025-08-28 04:10:49.935669: Pseudo dice [np.float32(0.6501)] 
2025-08-28 04:10:49.940927: Epoch time: 16.65 s 
2025-08-28 04:10:50.590183:  
2025-08-28 04:10:50.598527: Epoch 288 
2025-08-28 04:10:50.602735: Current learning rate: 0.00737 
2025-08-28 04:11:07.302778: train_loss -0.4176 
2025-08-28 04:11:07.311047: val_loss -0.4044 
2025-08-28 04:11:07.319429: Pseudo dice [np.float32(0.6569)] 
2025-08-28 04:11:07.324872: Epoch time: 16.71 s 
2025-08-28 04:11:07.978414:  
2025-08-28 04:11:07.982627: Epoch 289 
2025-08-28 04:11:07.990569: Current learning rate: 0.00736 
2025-08-28 04:11:24.503216: train_loss -0.4062 
2025-08-28 04:11:24.511593: val_loss -0.4792 
2025-08-28 04:11:24.519895: Pseudo dice [np.float32(0.6967)] 
2025-08-28 04:11:24.525684: Epoch time: 16.53 s 
2025-08-28 04:11:25.325054:  
2025-08-28 04:11:25.333210: Epoch 290 
2025-08-28 04:11:25.339975: Current learning rate: 0.00735 
2025-08-28 04:11:41.962391: train_loss -0.3636 
2025-08-28 04:11:41.970706: val_loss -0.5006 
2025-08-28 04:11:41.974913: Pseudo dice [np.float32(0.7512)] 
2025-08-28 04:11:41.984062: Epoch time: 16.64 s 
2025-08-28 04:11:42.629703:  
2025-08-28 04:11:42.638337: Epoch 291 
2025-08-28 04:11:42.642446: Current learning rate: 0.00734 
2025-08-28 04:11:59.459736: train_loss -0.3914 
2025-08-28 04:11:59.471839: val_loss -0.4385 
2025-08-28 04:11:59.475675: Pseudo dice [np.float32(0.7319)] 
2025-08-28 04:11:59.482914: Epoch time: 16.83 s 
2025-08-28 04:12:00.147453:  
2025-08-28 04:12:00.155711: Epoch 292 
2025-08-28 04:12:00.159650: Current learning rate: 0.00733 
2025-08-28 04:12:16.755723: train_loss -0.3595 
2025-08-28 04:12:16.763759: val_loss -0.459 
2025-08-28 04:12:16.768355: Pseudo dice [np.float32(0.6702)] 
2025-08-28 04:12:16.777014: Epoch time: 16.61 s 
2025-08-28 04:12:17.431094:  
2025-08-28 04:12:17.439447: Epoch 293 
2025-08-28 04:12:17.444122: Current learning rate: 0.00732 
2025-08-28 04:12:35.632062: train_loss -0.3788 
2025-08-28 04:12:35.636998: val_loss -0.4319 
2025-08-28 04:12:35.645149: Pseudo dice [np.float32(0.63)] 
2025-08-28 04:12:35.651579: Epoch time: 18.2 s 
2025-08-28 04:12:36.396049:  
2025-08-28 04:12:36.404198: Epoch 294 
2025-08-28 04:12:36.408326: Current learning rate: 0.00731 
2025-08-28 04:12:53.609910: train_loss -0.3923 
2025-08-28 04:12:53.621740: val_loss -0.4298 
2025-08-28 04:12:53.625831: Pseudo dice [np.float32(0.667)] 
2025-08-28 04:12:53.633211: Epoch time: 17.22 s 
2025-08-28 04:12:54.292871:  
2025-08-28 04:12:54.297085: Epoch 295 
2025-08-28 04:12:54.305452: Current learning rate: 0.0073 
2025-08-28 04:13:11.155602: train_loss -0.4047 
2025-08-28 04:13:11.163887: val_loss -0.3707 
2025-08-28 04:13:11.167976: Pseudo dice [np.float32(0.7301)] 
2025-08-28 04:13:11.177242: Epoch time: 16.87 s 
2025-08-28 04:13:11.973370:  
2025-08-28 04:13:11.981642: Epoch 296 
2025-08-28 04:13:11.985867: Current learning rate: 0.00729 
2025-08-28 04:13:28.748589: train_loss -0.3938 
2025-08-28 04:13:28.756787: val_loss -0.4565 
2025-08-28 04:13:28.760853: Pseudo dice [np.float32(0.7289)] 
2025-08-28 04:13:28.768751: Epoch time: 16.78 s 
2025-08-28 04:13:29.423823:  
2025-08-28 04:13:29.427995: Epoch 297 
2025-08-28 04:13:29.436293: Current learning rate: 0.00728 
2025-08-28 04:13:46.514758: train_loss -0.396 
2025-08-28 04:13:46.524019: val_loss -0.426 
2025-08-28 04:13:46.528470: Pseudo dice [np.float32(0.678)] 
2025-08-28 04:13:46.535855: Epoch time: 17.09 s 
2025-08-28 04:13:47.220721:  
2025-08-28 04:13:47.229051: Epoch 298 
2025-08-28 04:13:47.233230: Current learning rate: 0.00727 
2025-08-28 04:14:04.625811: train_loss -0.3651 
2025-08-28 04:14:04.634031: val_loss -0.3887 
2025-08-28 04:14:04.638191: Pseudo dice [np.float32(0.622)] 
2025-08-28 04:14:04.647243: Epoch time: 17.41 s 
2025-08-28 04:14:05.292986:  
2025-08-28 04:14:05.301330: Epoch 299 
2025-08-28 04:14:05.305490: Current learning rate: 0.00726 
2025-08-28 04:14:22.105803: train_loss -0.4078 
2025-08-28 04:14:22.113904: val_loss -0.3887 
2025-08-28 04:14:22.122272: Pseudo dice [np.float32(0.7372)] 
2025-08-28 04:14:22.127273: Epoch time: 16.81 s 
2025-08-28 04:14:23.069042:  
2025-08-28 04:14:23.073168: Epoch 300 
2025-08-28 04:14:23.081515: Current learning rate: 0.00725 
2025-08-28 04:14:39.735921: train_loss -0.3729 
2025-08-28 04:14:39.744048: val_loss -0.4082 
2025-08-28 04:14:39.752108: Pseudo dice [np.float32(0.6348)] 
2025-08-28 04:14:39.757282: Epoch time: 16.67 s 
2025-08-28 04:14:40.407180:  
2025-08-28 04:14:40.415534: Epoch 301 
2025-08-28 04:14:40.419660: Current learning rate: 0.00724 
2025-08-28 04:14:57.457781: train_loss -0.3908 
2025-08-28 04:14:57.465954: val_loss -0.4492 
2025-08-28 04:14:57.474481: Pseudo dice [np.float32(0.6906)] 
2025-08-28 04:14:57.479743: Epoch time: 17.05 s 
2025-08-28 04:14:58.287784:  
2025-08-28 04:14:58.295858: Epoch 302 
2025-08-28 04:14:58.300352: Current learning rate: 0.00724 
2025-08-28 04:15:14.862512: train_loss -0.3389 
2025-08-28 04:15:14.870747: val_loss -0.442 
2025-08-28 04:15:14.879102: Pseudo dice [np.float32(0.6163)] 
2025-08-28 04:15:14.884151: Epoch time: 16.57 s 
2025-08-28 04:15:15.538437:  
2025-08-28 04:15:15.546490: Epoch 303 
2025-08-28 04:15:15.550954: Current learning rate: 0.00723 
2025-08-28 04:15:32.592688: train_loss -0.4035 
2025-08-28 04:15:32.600920: val_loss -0.4255 
2025-08-28 04:15:32.605318: Pseudo dice [np.float32(0.6936)] 
2025-08-28 04:15:32.612888: Epoch time: 17.05 s 
2025-08-28 04:15:33.260006:  
2025-08-28 04:15:33.268331: Epoch 304 
2025-08-28 04:15:33.272474: Current learning rate: 0.00722 
2025-08-28 04:15:50.202227: train_loss -0.3785 
2025-08-28 04:15:50.214429: val_loss -0.4832 
2025-08-28 04:15:50.218863: Pseudo dice [np.float32(0.7215)] 
2025-08-28 04:15:50.224841: Epoch time: 16.94 s 
2025-08-28 04:15:50.873385:  
2025-08-28 04:15:50.877524: Epoch 305 
2025-08-28 04:15:50.881681: Current learning rate: 0.00721 
2025-08-28 04:16:07.978504: train_loss -0.4014 
2025-08-28 04:16:07.986602: val_loss -0.5174 
2025-08-28 04:16:07.994628: Pseudo dice [np.float32(0.7684)] 
2025-08-28 04:16:08.000134: Epoch time: 17.11 s 
2025-08-28 04:16:08.654042:  
2025-08-28 04:16:08.661995: Epoch 306 
2025-08-28 04:16:08.666122: Current learning rate: 0.0072 
2025-08-28 04:16:25.236816: train_loss -0.3913 
2025-08-28 04:16:25.245179: val_loss -0.4238 
2025-08-28 04:16:25.253554: Pseudo dice [np.float32(0.7329)] 
2025-08-28 04:16:25.258873: Epoch time: 16.59 s 
2025-08-28 04:16:25.916670:  
2025-08-28 04:16:25.925057: Epoch 307 
2025-08-28 04:16:25.929191: Current learning rate: 0.00719 
2025-08-28 04:16:42.963904: train_loss -0.3755 
2025-08-28 04:16:42.971576: val_loss -0.3975 
2025-08-28 04:16:42.979598: Pseudo dice [np.float32(0.6739)] 
2025-08-28 04:16:42.985031: Epoch time: 17.05 s 
2025-08-28 04:16:43.638583:  
2025-08-28 04:16:43.642749: Epoch 308 
2025-08-28 04:16:43.651101: Current learning rate: 0.00718 
2025-08-28 04:17:00.630868: train_loss -0.3993 
2025-08-28 04:17:00.643361: val_loss -0.4334 
2025-08-28 04:17:00.647178: Pseudo dice [np.float32(0.7716)] 
2025-08-28 04:17:00.654393: Epoch time: 17.0 s 
2025-08-28 04:17:01.468873:  
2025-08-28 04:17:01.477189: Epoch 309 
2025-08-28 04:17:01.481356: Current learning rate: 0.00717 
2025-08-28 04:17:18.206399: train_loss -0.4163 
2025-08-28 04:17:18.214731: val_loss -0.4425 
2025-08-28 04:17:18.218944: Pseudo dice [np.float32(0.6458)] 
2025-08-28 04:17:18.226196: Epoch time: 16.74 s 
2025-08-28 04:17:18.890414:  
2025-08-28 04:17:18.898779: Epoch 310 
2025-08-28 04:17:18.902942: Current learning rate: 0.00716 
2025-08-28 04:17:34.531133: train_loss -0.3781 
2025-08-28 04:17:34.539380: val_loss -0.4408 
2025-08-28 04:17:34.543825: Pseudo dice [np.float32(0.7114)] 
2025-08-28 04:17:34.551641: Epoch time: 15.64 s 
2025-08-28 04:17:35.206693:  
2025-08-28 04:17:35.210870: Epoch 311 
2025-08-28 04:17:35.219255: Current learning rate: 0.00715 
2025-08-28 04:17:51.160587: train_loss -0.3943 
2025-08-28 04:17:51.172960: val_loss -0.4323 
2025-08-28 04:17:51.180876: Pseudo dice [np.float32(0.626)] 
2025-08-28 04:17:51.186493: Epoch time: 15.96 s 
2025-08-28 04:17:51.919243:  
2025-08-28 04:17:51.927827: Epoch 312 
2025-08-28 04:17:51.931764: Current learning rate: 0.00714 
2025-08-28 04:18:09.641076: train_loss -0.4204 
2025-08-28 04:18:09.649414: val_loss -0.476 
2025-08-28 04:18:09.657794: Pseudo dice [np.float32(0.7432)] 
2025-08-28 04:18:09.663162: Epoch time: 17.72 s 
2025-08-28 04:18:10.400163:  
2025-08-28 04:18:10.404356: Epoch 313 
2025-08-28 04:18:10.413044: Current learning rate: 0.00713 
2025-08-28 04:18:27.340405: train_loss -0.4147 
2025-08-28 04:18:27.346586: val_loss -0.4293 
2025-08-28 04:18:27.354872: Pseudo dice [np.float32(0.7104)] 
2025-08-28 04:18:27.361763: Epoch time: 16.94 s 
2025-08-28 04:18:28.026114:  
2025-08-28 04:18:28.034958: Epoch 314 
2025-08-28 04:18:28.038625: Current learning rate: 0.00712 
2025-08-28 04:18:44.259097: train_loss -0.4254 
2025-08-28 04:18:44.267592: val_loss -0.4972 
2025-08-28 04:18:44.271589: Pseudo dice [np.float32(0.737)] 
2025-08-28 04:18:44.279810: Epoch time: 16.23 s 
2025-08-28 04:18:44.951423:  
2025-08-28 04:18:44.959678: Epoch 315 
2025-08-28 04:18:44.964061: Current learning rate: 0.00711 
2025-08-28 04:19:01.301333: train_loss -0.4092 
2025-08-28 04:19:01.309334: val_loss -0.4483 
2025-08-28 04:19:01.317681: Pseudo dice [np.float32(0.7209)] 
2025-08-28 04:19:01.324356: Epoch time: 16.35 s 
2025-08-28 04:19:02.151837:  
2025-08-28 04:19:02.160196: Epoch 316 
2025-08-28 04:19:02.164813: Current learning rate: 0.0071 
2025-08-28 04:19:19.691004: train_loss -0.4036 
2025-08-28 04:19:19.698546: val_loss -0.4692 
2025-08-28 04:19:19.702716: Pseudo dice [np.float32(0.7418)] 
2025-08-28 04:19:19.711394: Epoch time: 17.54 s 
2025-08-28 04:19:20.378416:  
2025-08-28 04:19:20.386758: Epoch 317 
2025-08-28 04:19:20.391195: Current learning rate: 0.0071 
2025-08-28 04:19:36.594587: train_loss -0.3382 
2025-08-28 04:19:36.602973: val_loss -0.3671 
2025-08-28 04:19:36.608341: Pseudo dice [np.float32(0.6599)] 
2025-08-28 04:19:36.613511: Epoch time: 16.22 s 
2025-08-28 04:19:37.282756:  
2025-08-28 04:19:37.291443: Epoch 318 
2025-08-28 04:19:37.295528: Current learning rate: 0.00709 
2025-08-28 04:19:53.699483: train_loss -0.3815 
2025-08-28 04:19:53.707549: val_loss -0.4508 
2025-08-28 04:19:53.715873: Pseudo dice [np.float32(0.708)] 
2025-08-28 04:19:53.721231: Epoch time: 16.42 s 
2025-08-28 04:19:54.383165:  
2025-08-28 04:19:54.387331: Epoch 319 
2025-08-28 04:19:54.395716: Current learning rate: 0.00708 
2025-08-28 04:20:10.970884: train_loss -0.3487 
2025-08-28 04:20:10.983387: val_loss -0.5273 
2025-08-28 04:20:10.987461: Pseudo dice [np.float32(0.7348)] 
2025-08-28 04:20:10.996629: Epoch time: 16.59 s 
2025-08-28 04:20:11.721322:  
2025-08-28 04:20:11.729759: Epoch 320 
2025-08-28 04:20:11.733882: Current learning rate: 0.00707 
2025-08-28 04:20:28.409172: train_loss -0.4287 
2025-08-28 04:20:28.417167: val_loss -0.3872 
2025-08-28 04:20:28.425536: Pseudo dice [np.float32(0.7012)] 
2025-08-28 04:20:28.431062: Epoch time: 16.69 s 
2025-08-28 04:20:29.092819:  
2025-08-28 04:20:29.101215: Epoch 321 
2025-08-28 04:20:29.105348: Current learning rate: 0.00706 
2025-08-28 04:20:45.934694: train_loss -0.3374 
2025-08-28 04:20:45.943116: val_loss -0.3964 
2025-08-28 04:20:45.947211: Pseudo dice [np.float32(0.6325)] 
2025-08-28 04:20:45.953859: Epoch time: 16.84 s 
2025-08-28 04:20:46.752225:  
2025-08-28 04:20:46.760517: Epoch 322 
2025-08-28 04:20:46.764943: Current learning rate: 0.00705 
2025-08-28 04:21:03.784617: train_loss -0.4134 
2025-08-28 04:21:03.795154: val_loss -0.4268 
2025-08-28 04:21:03.801342: Pseudo dice [np.float32(0.6945)] 
2025-08-28 04:21:03.806707: Epoch time: 17.03 s 
2025-08-28 04:21:04.732951:  
2025-08-28 04:21:04.741004: Epoch 323 
2025-08-28 04:21:04.745075: Current learning rate: 0.00704 
2025-08-28 04:21:21.682836: train_loss -0.4416 
2025-08-28 04:21:21.687348: val_loss -0.4309 
2025-08-28 04:21:21.695392: Pseudo dice [np.float32(0.7021)] 
2025-08-28 04:21:21.701065: Epoch time: 16.95 s 
2025-08-28 04:21:22.366842:  
2025-08-28 04:21:22.375604: Epoch 324 
2025-08-28 04:21:22.379688: Current learning rate: 0.00703 
2025-08-28 04:21:38.628937: train_loss -0.4421 
2025-08-28 04:21:38.633099: val_loss -0.4016 
2025-08-28 04:21:38.641459: Pseudo dice [np.float32(0.582)] 
2025-08-28 04:21:38.646907: Epoch time: 16.26 s 
2025-08-28 04:21:39.300439:  
2025-08-28 04:21:39.309200: Epoch 325 
2025-08-28 04:21:39.313344: Current learning rate: 0.00702 
2025-08-28 04:21:55.675167: train_loss -0.3806 
2025-08-28 04:21:55.683468: val_loss -0.3959 
2025-08-28 04:21:55.691850: Pseudo dice [np.float32(0.6862)] 
2025-08-28 04:21:55.699230: Epoch time: 16.37 s 
2025-08-28 04:21:56.413342:  
2025-08-28 04:21:56.417531: Epoch 326 
2025-08-28 04:21:56.425883: Current learning rate: 0.00701 
2025-08-28 04:22:13.718132: train_loss -0.3564 
2025-08-28 04:22:13.726645: val_loss -0.4417 
2025-08-28 04:22:13.730648: Pseudo dice [np.float32(0.6795)] 
2025-08-28 04:22:13.737968: Epoch time: 17.31 s 
2025-08-28 04:22:14.402135:  
2025-08-28 04:22:14.410499: Epoch 327 
2025-08-28 04:22:14.414845: Current learning rate: 0.007 
2025-08-28 04:22:30.305794: train_loss -0.3882 
2025-08-28 04:22:30.313895: val_loss -0.4243 
2025-08-28 04:22:30.318035: Pseudo dice [np.float32(0.6791)] 
2025-08-28 04:22:30.325739: Epoch time: 15.91 s 
2025-08-28 04:22:30.977034:  
2025-08-28 04:22:30.985403: Epoch 328 
2025-08-28 04:22:30.989772: Current learning rate: 0.00699 
2025-08-28 04:22:46.722239: train_loss -0.4247 
2025-08-28 04:22:46.730280: val_loss -0.4931 
2025-08-28 04:22:46.738978: Pseudo dice [np.float32(0.7373)] 
2025-08-28 04:22:46.743713: Epoch time: 15.75 s 
2025-08-28 04:22:47.643703:  
2025-08-28 04:22:47.652022: Epoch 329 
2025-08-28 04:22:47.656627: Current learning rate: 0.00698 
2025-08-28 04:23:04.345218: train_loss -0.4142 
2025-08-28 04:23:04.355999: val_loss -0.5044 
2025-08-28 04:23:04.360478: Pseudo dice [np.float32(0.7663)] 
2025-08-28 04:23:04.366697: Epoch time: 16.71 s 
2025-08-28 04:23:05.023546:  
2025-08-28 04:23:05.031874: Epoch 330 
2025-08-28 04:23:05.036068: Current learning rate: 0.00697 
2025-08-28 04:23:21.581724: train_loss -0.398 
2025-08-28 04:23:21.590147: val_loss -0.3927 
2025-08-28 04:23:21.594444: Pseudo dice [np.float32(0.6034)] 
2025-08-28 04:23:21.602551: Epoch time: 16.56 s 
2025-08-28 04:23:22.257759:  
2025-08-28 04:23:22.265733: Epoch 331 
2025-08-28 04:23:22.269950: Current learning rate: 0.00696 
2025-08-28 04:23:39.178962: train_loss -0.4165 
2025-08-28 04:23:39.187056: val_loss -0.4889 
2025-08-28 04:23:39.195773: Pseudo dice [np.float32(0.7127)] 
2025-08-28 04:23:39.200891: Epoch time: 16.92 s 
2025-08-28 04:23:39.854105:  
2025-08-28 04:23:39.862521: Epoch 332 
2025-08-28 04:23:39.866875: Current learning rate: 0.00696 
2025-08-28 04:23:57.363644: train_loss -0.4001 
2025-08-28 04:23:57.371705: val_loss -0.4579 
2025-08-28 04:23:57.380474: Pseudo dice [np.float32(0.7142)] 
2025-08-28 04:23:57.384756: Epoch time: 17.51 s 
2025-08-28 04:23:58.030646:  
2025-08-28 04:23:58.038999: Epoch 333 
2025-08-28 04:23:58.043128: Current learning rate: 0.00695 
2025-08-28 04:24:15.081089: train_loss -0.4226 
2025-08-28 04:24:15.089607: val_loss -0.4149 
2025-08-28 04:24:15.097450: Pseudo dice [np.float32(0.7195)] 
2025-08-28 04:24:15.103112: Epoch time: 17.05 s 
2025-08-28 04:24:15.756679:  
2025-08-28 04:24:15.765047: Epoch 334 
2025-08-28 04:24:15.769203: Current learning rate: 0.00694 
2025-08-28 04:24:32.377769: train_loss -0.4023 
2025-08-28 04:24:32.386064: val_loss -0.4316 
2025-08-28 04:24:32.389989: Pseudo dice [np.float32(0.6434)] 
2025-08-28 04:24:32.398088: Epoch time: 16.63 s 
2025-08-28 04:24:33.065655:  
2025-08-28 04:24:33.070033: Epoch 335 
2025-08-28 04:24:33.077825: Current learning rate: 0.00693 
2025-08-28 04:24:51.046073: train_loss -0.4138 
2025-08-28 04:24:51.054411: val_loss -0.3363 
2025-08-28 04:24:51.058554: Pseudo dice [np.float32(0.6927)] 
2025-08-28 04:24:51.066917: Epoch time: 17.98 s 
2025-08-28 04:24:51.917754:  
2025-08-28 04:24:51.926094: Epoch 336 
2025-08-28 04:24:51.930247: Current learning rate: 0.00692 
2025-08-28 04:25:08.697021: train_loss -0.4009 
2025-08-28 04:25:08.705358: val_loss -0.4403 
2025-08-28 04:25:08.713707: Pseudo dice [np.float32(0.7119)] 
2025-08-28 04:25:08.720121: Epoch time: 16.78 s 
2025-08-28 04:25:09.381028:  
2025-08-28 04:25:09.389415: Epoch 337 
2025-08-28 04:25:09.393731: Current learning rate: 0.00691 
2025-08-28 04:25:26.577890: train_loss -0.3814 
2025-08-28 04:25:26.585773: val_loss -0.395 
2025-08-28 04:25:26.589891: Pseudo dice [np.float32(0.6547)] 
2025-08-28 04:25:26.599073: Epoch time: 17.2 s 
2025-08-28 04:25:27.261387:  
2025-08-28 04:25:27.269730: Epoch 338 
2025-08-28 04:25:27.274116: Current learning rate: 0.0069 
2025-08-28 04:25:44.662119: train_loss -0.4064 
2025-08-28 04:25:44.670475: val_loss -0.4414 
2025-08-28 04:25:44.674859: Pseudo dice [np.float32(0.7237)] 
2025-08-28 04:25:44.683035: Epoch time: 17.4 s 
2025-08-28 04:25:45.387851:  
2025-08-28 04:25:45.396260: Epoch 339 
2025-08-28 04:25:45.400419: Current learning rate: 0.00689 
2025-08-28 04:26:02.425916: train_loss -0.4221 
2025-08-28 04:26:02.438253: val_loss -0.471 
2025-08-28 04:26:02.442654: Pseudo dice [np.float32(0.7068)] 
2025-08-28 04:26:02.449702: Epoch time: 17.04 s 
2025-08-28 04:26:03.109665:  
2025-08-28 04:26:03.118061: Epoch 340 
2025-08-28 04:26:03.122230: Current learning rate: 0.00688 
2025-08-28 04:26:19.734865: train_loss -0.4121 
2025-08-28 04:26:19.742936: val_loss -0.4419 
2025-08-28 04:26:19.751538: Pseudo dice [np.float32(0.6843)] 
2025-08-28 04:26:19.759094: Epoch time: 16.63 s 
2025-08-28 04:26:20.414757:  
2025-08-28 04:26:20.422836: Epoch 341 
2025-08-28 04:26:20.427006: Current learning rate: 0.00687 
2025-08-28 04:26:37.994494: train_loss -0.4123 
2025-08-28 04:26:38.002860: val_loss -0.4638 
2025-08-28 04:26:38.007363: Pseudo dice [np.float32(0.7277)] 
2025-08-28 04:26:38.013386: Epoch time: 17.58 s 
2025-08-28 04:26:38.678521:  
2025-08-28 04:26:38.686907: Epoch 342 
2025-08-28 04:26:38.691037: Current learning rate: 0.00686 
2025-08-28 04:26:55.645878: train_loss -0.4158 
2025-08-28 04:26:55.657957: val_loss -0.4334 
2025-08-28 04:26:55.662132: Pseudo dice [np.float32(0.6926)] 
2025-08-28 04:26:55.669439: Epoch time: 16.97 s 
2025-08-28 04:26:56.484096:  
2025-08-28 04:26:56.492672: Epoch 343 
2025-08-28 04:26:56.496598: Current learning rate: 0.00685 
2025-08-28 04:27:13.146302: train_loss -0.4158 
2025-08-28 04:27:13.154935: val_loss -0.4192 
2025-08-28 04:27:13.163332: Pseudo dice [np.float32(0.6962)] 
2025-08-28 04:27:13.168374: Epoch time: 16.66 s 
2025-08-28 04:27:13.826191:  
2025-08-28 04:27:13.834206: Epoch 344 
2025-08-28 04:27:13.839058: Current learning rate: 0.00684 
2025-08-28 04:27:31.235193: train_loss -0.4041 
2025-08-28 04:27:31.243860: val_loss -0.5019 
2025-08-28 04:27:31.247668: Pseudo dice [np.float32(0.7583)] 
2025-08-28 04:27:31.256138: Epoch time: 17.41 s 
2025-08-28 04:27:31.998444:  
2025-08-28 04:27:32.002615: Epoch 345 
2025-08-28 04:27:32.011237: Current learning rate: 0.00683 
2025-08-28 04:27:49.195055: train_loss -0.4375 
2025-08-28 04:27:49.203186: val_loss -0.4846 
2025-08-28 04:27:49.211485: Pseudo dice [np.float32(0.6891)] 
2025-08-28 04:27:49.217899: Epoch time: 17.2 s 
2025-08-28 04:27:49.870467:  
2025-08-28 04:27:49.879129: Epoch 346 
2025-08-28 04:27:49.887172: Current learning rate: 0.00682 
2025-08-28 04:28:06.671157: train_loss -0.3848 
2025-08-28 04:28:06.678903: val_loss -0.4417 
2025-08-28 04:28:06.687588: Pseudo dice [np.float32(0.7395)] 
2025-08-28 04:28:06.692725: Epoch time: 16.8 s 
2025-08-28 04:28:07.354362:  
2025-08-28 04:28:07.358815: Epoch 347 
2025-08-28 04:28:07.366799: Current learning rate: 0.00681 
2025-08-28 04:28:24.033808: train_loss -0.3937 
2025-08-28 04:28:24.042475: val_loss -0.3765 
2025-08-28 04:28:24.046242: Pseudo dice [np.float32(0.6359)] 
2025-08-28 04:28:24.053391: Epoch time: 16.68 s 
2025-08-28 04:28:24.730282:  
2025-08-28 04:28:24.738966: Epoch 348 
2025-08-28 04:28:24.743077: Current learning rate: 0.0068 
2025-08-28 04:28:41.484804: train_loss -0.3871 
2025-08-28 04:28:41.492934: val_loss -0.4572 
2025-08-28 04:28:41.497365: Pseudo dice [np.float32(0.7152)] 
2025-08-28 04:28:41.504992: Epoch time: 16.75 s 
2025-08-28 04:28:42.318682:  
2025-08-28 04:28:42.327003: Epoch 349 
2025-08-28 04:28:42.331187: Current learning rate: 0.0068 
2025-08-28 04:28:59.381540: train_loss -0.4142 
2025-08-28 04:28:59.390208: val_loss -0.5125 
2025-08-28 04:28:59.398566: Pseudo dice [np.float32(0.7584)] 
2025-08-28 04:28:59.403206: Epoch time: 17.06 s 
2025-08-28 04:29:00.299095:  
2025-08-28 04:29:00.303298: Epoch 350 
2025-08-28 04:29:00.311629: Current learning rate: 0.00679 
2025-08-28 04:29:17.361958: train_loss -0.388 
2025-08-28 04:29:17.370416: val_loss -0.4322 
2025-08-28 04:29:17.377949: Pseudo dice [np.float32(0.6851)] 
2025-08-28 04:29:17.383743: Epoch time: 17.07 s 
2025-08-28 04:29:18.050477:  
2025-08-28 04:29:18.058507: Epoch 351 
2025-08-28 04:29:18.062679: Current learning rate: 0.00678 
2025-08-28 04:29:34.404351: train_loss -0.4164 
2025-08-28 04:29:34.412654: val_loss -0.4357 
2025-08-28 04:29:34.416519: Pseudo dice [np.float32(0.7407)] 
2025-08-28 04:29:34.425702: Epoch time: 16.35 s 
2025-08-28 04:29:35.092172:  
2025-08-28 04:29:35.100513: Epoch 352 
2025-08-28 04:29:35.104665: Current learning rate: 0.00677 
2025-08-28 04:29:51.767589: train_loss -0.4383 
2025-08-28 04:29:51.779673: val_loss -0.4564 
2025-08-28 04:29:51.783843: Pseudo dice [np.float32(0.6972)] 
2025-08-28 04:29:51.792476: Epoch time: 16.68 s 
2025-08-28 04:29:52.570992:  
2025-08-28 04:29:52.579312: Epoch 353 
2025-08-28 04:29:52.586664: Current learning rate: 0.00676 
2025-08-28 04:30:09.018106: train_loss -0.438 
2025-08-28 04:30:09.026331: val_loss -0.4425 
2025-08-28 04:30:09.030290: Pseudo dice [np.float32(0.6835)] 
2025-08-28 04:30:09.038595: Epoch time: 16.45 s 
2025-08-28 04:30:09.701751:  
2025-08-28 04:30:09.710409: Epoch 354 
2025-08-28 04:30:09.714262: Current learning rate: 0.00675 
2025-08-28 04:30:25.655876: train_loss -0.3697 
2025-08-28 04:30:25.663524: val_loss -0.412 
2025-08-28 04:30:25.667691: Pseudo dice [np.float32(0.6576)] 
2025-08-28 04:30:25.676054: Epoch time: 15.95 s 
2025-08-28 04:30:26.489411:  
2025-08-28 04:30:26.497708: Epoch 355 
2025-08-28 04:30:26.505321: Current learning rate: 0.00674 
2025-08-28 04:30:41.954299: train_loss -0.4013 
2025-08-28 04:30:41.958985: val_loss -0.4378 
2025-08-28 04:30:41.967366: Pseudo dice [np.float32(0.6462)] 
2025-08-28 04:30:41.973691: Epoch time: 15.46 s 
2025-08-28 04:30:42.634963:  
2025-08-28 04:30:42.642997: Epoch 356 
2025-08-28 04:30:42.647427: Current learning rate: 0.00673 
2025-08-28 04:30:59.318094: train_loss -0.4339 
2025-08-28 04:30:59.326308: val_loss -0.4989 
2025-08-28 04:30:59.335837: Pseudo dice [np.float32(0.7426)] 
2025-08-28 04:30:59.352906: Epoch time: 16.69 s 
2025-08-28 04:31:00.152458:  
2025-08-28 04:31:00.160469: Epoch 357 
2025-08-28 04:31:00.168820: Current learning rate: 0.00672 
2025-08-28 04:31:15.909518: train_loss -0.3748 
2025-08-28 04:31:15.917877: val_loss -0.4451 
2025-08-28 04:31:15.922046: Pseudo dice [np.float32(0.7356)] 
2025-08-28 04:31:15.928299: Epoch time: 15.76 s 
2025-08-28 04:31:16.589845:  
2025-08-28 04:31:16.597733: Epoch 358 
2025-08-28 04:31:16.602216: Current learning rate: 0.00671 
2025-08-28 04:31:32.255004: train_loss -0.4112 
2025-08-28 04:31:32.263119: val_loss -0.4106 
2025-08-28 04:31:32.267691: Pseudo dice [np.float32(0.6461)] 
2025-08-28 04:31:32.274775: Epoch time: 15.67 s 
2025-08-28 04:31:32.943293:  
2025-08-28 04:31:32.951554: Epoch 359 
2025-08-28 04:31:32.955746: Current learning rate: 0.0067 
2025-08-28 04:31:49.325194: train_loss -0.4058 
2025-08-28 04:31:49.335799: val_loss -0.4335 
2025-08-28 04:31:49.341702: Pseudo dice [np.float32(0.6929)] 
2025-08-28 04:31:49.348104: Epoch time: 16.39 s 
2025-08-28 04:31:50.131209:  
2025-08-28 04:31:50.139355: Epoch 360 
2025-08-28 04:31:50.144064: Current learning rate: 0.00669 
2025-08-28 04:32:07.240006: train_loss -0.3937 
2025-08-28 04:32:07.248613: val_loss -0.4294 
2025-08-28 04:32:07.252730: Pseudo dice [np.float32(0.7157)] 
2025-08-28 04:32:07.261843: Epoch time: 17.11 s 
2025-08-28 04:32:07.928341:  
2025-08-28 04:32:07.936888: Epoch 361 
2025-08-28 04:32:07.940678: Current learning rate: 0.00668 
2025-08-28 04:32:24.098112: train_loss -0.4311 
2025-08-28 04:32:24.106795: val_loss -0.4518 
2025-08-28 04:32:24.110960: Pseudo dice [np.float32(0.7444)] 
2025-08-28 04:32:24.117242: Epoch time: 16.17 s 
2025-08-28 04:32:24.936831:  
2025-08-28 04:32:24.944845: Epoch 362 
2025-08-28 04:32:24.949414: Current learning rate: 0.00667 
2025-08-28 04:32:41.278090: train_loss -0.4209 
2025-08-28 04:32:41.286429: val_loss -0.4414 
2025-08-28 04:32:41.290543: Pseudo dice [np.float32(0.7232)] 
2025-08-28 04:32:41.299712: Epoch time: 16.35 s 
2025-08-28 04:32:41.966266:  
2025-08-28 04:32:41.970453: Epoch 363 
2025-08-28 04:32:41.978803: Current learning rate: 0.00666 
2025-08-28 04:32:59.054430: train_loss -0.4293 
2025-08-28 04:32:59.062510: val_loss -0.4271 
2025-08-28 04:32:59.070871: Pseudo dice [np.float32(0.7117)] 
2025-08-28 04:32:59.076500: Epoch time: 17.09 s 
2025-08-28 04:32:59.746514:  
2025-08-28 04:32:59.750739: Epoch 364 
2025-08-28 04:32:59.759166: Current learning rate: 0.00665 
2025-08-28 04:33:16.146289: train_loss -0.4125 
2025-08-28 04:33:16.154586: val_loss -0.477 
2025-08-28 04:33:16.158780: Pseudo dice [np.float32(0.7367)] 
2025-08-28 04:33:16.167432: Epoch time: 16.4 s 
2025-08-28 04:33:16.844617:  
2025-08-28 04:33:16.851414: Epoch 365 
2025-08-28 04:33:16.855372: Current learning rate: 0.00665 
2025-08-28 04:33:33.075720: train_loss -0.4132 
2025-08-28 04:33:33.084351: val_loss -0.3934 
2025-08-28 04:33:33.088489: Pseudo dice [np.float32(0.6306)] 
2025-08-28 04:33:33.097912: Epoch time: 16.23 s 
2025-08-28 04:33:33.763850:  
2025-08-28 04:33:33.772522: Epoch 366 
2025-08-28 04:33:33.776727: Current learning rate: 0.00664 
2025-08-28 04:33:50.935170: train_loss -0.4116 
2025-08-28 04:33:50.947662: val_loss -0.4446 
2025-08-28 04:33:50.952025: Pseudo dice [np.float32(0.7365)] 
2025-08-28 04:33:50.960176: Epoch time: 17.18 s 
2025-08-28 04:33:51.631683:  
2025-08-28 04:33:51.640019: Epoch 367 
2025-08-28 04:33:51.644202: Current learning rate: 0.00663 
2025-08-28 04:34:07.881612: train_loss -0.4238 
2025-08-28 04:34:07.889546: val_loss -0.4991 
2025-08-28 04:34:07.898587: Pseudo dice [np.float32(0.785)] 
2025-08-28 04:34:07.903410: Epoch time: 16.25 s 
2025-08-28 04:34:07.909091: Yayy! New best EMA pseudo Dice: 0.7125999927520752 
2025-08-28 04:34:08.878053:  
2025-08-28 04:34:08.886401: Epoch 368 
2025-08-28 04:34:08.894780: Current learning rate: 0.00662 
2025-08-28 04:34:25.569732: train_loss -0.4049 
2025-08-28 04:34:25.578097: val_loss -0.4657 
2025-08-28 04:34:25.586949: Pseudo dice [np.float32(0.7307)] 
2025-08-28 04:34:25.592652: Epoch time: 16.69 s 
2025-08-28 04:34:25.597658: Yayy! New best EMA pseudo Dice: 0.7143999934196472 
2025-08-28 04:34:26.445886:  
2025-08-28 04:34:26.454214: Epoch 369 
2025-08-28 04:34:26.458431: Current learning rate: 0.00661 
2025-08-28 04:34:43.642121: train_loss -0.4339 
2025-08-28 04:34:43.650296: val_loss -0.4538 
2025-08-28 04:34:43.654457: Pseudo dice [np.float32(0.7327)] 
2025-08-28 04:34:43.661848: Epoch time: 17.2 s 
2025-08-28 04:34:43.667512: Yayy! New best EMA pseudo Dice: 0.7161999940872192 
2025-08-28 04:34:44.647110:  
2025-08-28 04:34:44.655466: Epoch 370 
2025-08-28 04:34:44.663546: Current learning rate: 0.0066 
2025-08-28 04:35:01.080704: train_loss -0.4322 
2025-08-28 04:35:01.093025: val_loss -0.4642 
2025-08-28 04:35:01.097155: Pseudo dice [np.float32(0.7288)] 
2025-08-28 04:35:01.104207: Epoch time: 16.44 s 
2025-08-28 04:35:01.109806: Yayy! New best EMA pseudo Dice: 0.7174999713897705 
2025-08-28 04:35:01.951893:  
2025-08-28 04:35:01.960248: Epoch 371 
2025-08-28 04:35:01.964687: Current learning rate: 0.00659 
2025-08-28 04:35:18.264201: train_loss -0.4032 
2025-08-28 04:35:18.272347: val_loss -0.4071 
2025-08-28 04:35:18.276775: Pseudo dice [np.float32(0.6741)] 
2025-08-28 04:35:18.284603: Epoch time: 16.31 s 
2025-08-28 04:35:18.964720:  
2025-08-28 04:35:18.973158: Epoch 372 
2025-08-28 04:35:18.977314: Current learning rate: 0.00658 
2025-08-28 04:35:36.157245: train_loss -0.3931 
2025-08-28 04:35:36.165493: val_loss -0.4549 
2025-08-28 04:35:36.169401: Pseudo dice [np.float32(0.7272)] 
2025-08-28 04:35:36.178810: Epoch time: 17.19 s 
2025-08-28 04:35:36.949635:  
2025-08-28 04:35:36.957692: Epoch 373 
2025-08-28 04:35:36.962111: Current learning rate: 0.00657 
2025-08-28 04:35:53.307020: train_loss -0.3809 
2025-08-28 04:35:53.315697: val_loss -0.513 
2025-08-28 04:35:53.319856: Pseudo dice [np.float32(0.7706)] 
2025-08-28 04:35:53.329126: Epoch time: 16.36 s 
2025-08-28 04:35:53.335257: Yayy! New best EMA pseudo Dice: 0.7200999855995178 
2025-08-28 04:35:54.325019:  
2025-08-28 04:35:54.335465: Epoch 374 
2025-08-28 04:35:54.343051: Current learning rate: 0.00656 
2025-08-28 04:36:11.750956: train_loss -0.4028 
2025-08-28 04:36:11.759099: val_loss -0.3778 
2025-08-28 04:36:11.767441: Pseudo dice [np.float32(0.6181)] 
2025-08-28 04:36:11.773009: Epoch time: 17.43 s 
2025-08-28 04:36:12.443222:  
2025-08-28 04:36:12.451433: Epoch 375 
2025-08-28 04:36:12.455720: Current learning rate: 0.00655 
2025-08-28 04:36:28.972116: train_loss -0.4201 
2025-08-28 04:36:28.980336: val_loss -0.4782 
2025-08-28 04:36:28.984855: Pseudo dice [np.float32(0.7643)] 
2025-08-28 04:36:28.991874: Epoch time: 16.53 s 
2025-08-28 04:36:29.651965:  
2025-08-28 04:36:29.660599: Epoch 376 
2025-08-28 04:36:29.664512: Current learning rate: 0.00654 
2025-08-28 04:36:45.934908: train_loss -0.4441 
2025-08-28 04:36:45.943506: val_loss -0.4074 
2025-08-28 04:36:45.947689: Pseudo dice [np.float32(0.6939)] 
2025-08-28 04:36:45.955289: Epoch time: 16.28 s 
2025-08-28 04:36:46.623065:  
2025-08-28 04:36:46.631461: Epoch 377 
2025-08-28 04:36:46.635588: Current learning rate: 0.00653 
2025-08-28 04:37:03.632027: train_loss -0.4174 
2025-08-28 04:37:03.640377: val_loss -0.4681 
2025-08-28 04:37:03.648782: Pseudo dice [np.float32(0.742)] 
2025-08-28 04:37:03.655244: Epoch time: 17.01 s 
2025-08-28 04:37:04.545206:  
2025-08-28 04:37:04.558137: Epoch 378 
2025-08-28 04:37:04.566404: Current learning rate: 0.00652 
2025-08-28 04:37:20.861428: train_loss -0.3877 
2025-08-28 04:37:20.869779: val_loss -0.4281 
2025-08-28 04:37:20.878113: Pseudo dice [np.float32(0.6314)] 
2025-08-28 04:37:20.883645: Epoch time: 16.32 s 
2025-08-28 04:37:21.553878:  
2025-08-28 04:37:21.562130: Epoch 379 
2025-08-28 04:37:21.566611: Current learning rate: 0.00651 
2025-08-28 04:37:38.228882: train_loss -0.409 
2025-08-28 04:37:38.237115: val_loss -0.4809 
2025-08-28 04:37:38.241505: Pseudo dice [np.float32(0.7982)] 
2025-08-28 04:37:38.250438: Epoch time: 16.68 s 
2025-08-28 04:37:39.059082:  
2025-08-28 04:37:39.067113: Epoch 380 
2025-08-28 04:37:39.071288: Current learning rate: 0.0065 
2025-08-28 04:37:55.191624: train_loss -0.4296 
2025-08-28 04:37:55.204401: val_loss -0.4754 
2025-08-28 04:37:55.208526: Pseudo dice [np.float32(0.7558)] 
2025-08-28 04:37:55.217670: Epoch time: 16.13 s 
2025-08-28 04:37:55.221691: Yayy! New best EMA pseudo Dice: 0.7206000089645386 
2025-08-28 04:37:56.142783:  
2025-08-28 04:37:56.150823: Epoch 381 
2025-08-28 04:37:56.155339: Current learning rate: 0.00649 
2025-08-28 04:38:13.322127: train_loss -0.4193 
2025-08-28 04:38:13.330479: val_loss -0.5322 
2025-08-28 04:38:13.336842: Pseudo dice [np.float32(0.7934)] 
2025-08-28 04:38:13.343844: Epoch time: 17.18 s 
2025-08-28 04:38:13.349730: Yayy! New best EMA pseudo Dice: 0.7279000282287598 
2025-08-28 04:38:14.193923:  
2025-08-28 04:38:14.201940: Epoch 382 
2025-08-28 04:38:14.206516: Current learning rate: 0.00648 
2025-08-28 04:38:30.251557: train_loss -0.4448 
2025-08-28 04:38:30.259890: val_loss -0.4071 
2025-08-28 04:38:30.268247: Pseudo dice [np.float32(0.7196)] 
2025-08-28 04:38:30.274557: Epoch time: 16.06 s 
2025-08-28 04:38:30.948135:  
2025-08-28 04:38:30.956422: Epoch 383 
2025-08-28 04:38:30.960876: Current learning rate: 0.00648 
2025-08-28 04:38:47.264322: train_loss -0.4045 
2025-08-28 04:38:47.272718: val_loss -0.4402 
2025-08-28 04:38:47.277103: Pseudo dice [np.float32(0.6979)] 
2025-08-28 04:38:47.286039: Epoch time: 16.32 s 
2025-08-28 04:38:48.044318:  
2025-08-28 04:38:48.052665: Epoch 384 
2025-08-28 04:38:48.057160: Current learning rate: 0.00647 
2025-08-28 04:39:05.311548: train_loss -0.4628 
2025-08-28 04:39:05.320306: val_loss -0.474 
2025-08-28 04:39:05.328247: Pseudo dice [np.float32(0.78)] 
2025-08-28 04:39:05.333678: Epoch time: 17.27 s 
2025-08-28 04:39:05.340051: Yayy! New best EMA pseudo Dice: 0.7297000288963318 
2025-08-28 04:39:06.316956:  
2025-08-28 04:39:06.325103: Epoch 385 
2025-08-28 04:39:06.329256: Current learning rate: 0.00646 
2025-08-28 04:39:22.395306: train_loss -0.432 
2025-08-28 04:39:22.404792: val_loss -0.4645 
2025-08-28 04:39:22.412296: Pseudo dice [np.float32(0.7017)] 
2025-08-28 04:39:22.417370: Epoch time: 16.08 s 
2025-08-28 04:39:23.267030:  
2025-08-28 04:39:23.275345: Epoch 386 
2025-08-28 04:39:23.279707: Current learning rate: 0.00645 
2025-08-28 04:39:40.238167: train_loss -0.4133 
2025-08-28 04:39:40.246495: val_loss -0.5604 
2025-08-28 04:39:40.250686: Pseudo dice [np.float32(0.7583)] 
2025-08-28 04:39:40.258853: Epoch time: 16.97 s 
2025-08-28 04:39:40.264677: Yayy! New best EMA pseudo Dice: 0.7300999760627747 
2025-08-28 04:39:41.101784:  
2025-08-28 04:39:41.105618: Epoch 387 
2025-08-28 04:39:41.113989: Current learning rate: 0.00644 
2025-08-28 04:39:58.739906: train_loss -0.4413 
2025-08-28 04:39:58.748274: val_loss -0.4141 
2025-08-28 04:39:58.752434: Pseudo dice [np.float32(0.6989)] 
2025-08-28 04:39:58.759757: Epoch time: 17.64 s 
2025-08-28 04:39:59.428095:  
2025-08-28 04:39:59.436440: Epoch 388 
2025-08-28 04:39:59.444821: Current learning rate: 0.00643 
2025-08-28 04:40:16.290832: train_loss -0.4148 
2025-08-28 04:40:16.299158: val_loss -0.4804 
2025-08-28 04:40:16.307705: Pseudo dice [np.float32(0.6833)] 
2025-08-28 04:40:16.312896: Epoch time: 16.86 s 
2025-08-28 04:40:16.994189:  
2025-08-28 04:40:16.999825: Epoch 389 
2025-08-28 04:40:17.003987: Current learning rate: 0.00642 
2025-08-28 04:40:32.678560: train_loss -0.425 
2025-08-28 04:40:32.686481: val_loss -0.5003 
2025-08-28 04:40:32.694652: Pseudo dice [np.float32(0.7814)] 
2025-08-28 04:40:32.699572: Epoch time: 15.69 s 
2025-08-28 04:40:33.378654:  
2025-08-28 04:40:33.382834: Epoch 390 
2025-08-28 04:40:33.391260: Current learning rate: 0.00641 
2025-08-28 04:40:50.058163: train_loss -0.4306 
2025-08-28 04:40:50.066333: val_loss -0.5006 
2025-08-28 04:40:50.074594: Pseudo dice [np.float32(0.7531)] 
2025-08-28 04:40:50.079984: Epoch time: 16.68 s 
2025-08-28 04:40:50.083804: Yayy! New best EMA pseudo Dice: 0.73089998960495 
2025-08-28 04:40:50.925375:  
2025-08-28 04:40:50.933693: Epoch 391 
2025-08-28 04:40:50.937939: Current learning rate: 0.0064 
2025-08-28 04:41:06.515912: train_loss -0.3868 
2025-08-28 04:41:06.524272: val_loss -0.474 
2025-08-28 04:41:06.532703: Pseudo dice [np.float32(0.6916)] 
2025-08-28 04:41:06.538269: Epoch time: 15.59 s 
2025-08-28 04:41:07.358656:  
2025-08-28 04:41:07.367075: Epoch 392 
2025-08-28 04:41:07.370935: Current learning rate: 0.00639 
2025-08-28 04:41:23.257735: train_loss -0.4072 
2025-08-28 04:41:23.266003: val_loss -0.5871 
2025-08-28 04:41:23.270221: Pseudo dice [np.float32(0.7733)] 
2025-08-28 04:41:23.278451: Epoch time: 15.9 s 
2025-08-28 04:41:23.284013: Yayy! New best EMA pseudo Dice: 0.7315999865531921 
2025-08-28 04:41:24.250320:  
2025-08-28 04:41:24.258663: Epoch 393 
2025-08-28 04:41:24.262821: Current learning rate: 0.00638 
2025-08-28 04:41:40.120402: train_loss -0.4615 
2025-08-28 04:41:40.128670: val_loss -0.4112 
2025-08-28 04:41:40.132915: Pseudo dice [np.float32(0.6458)] 
2025-08-28 04:41:40.141456: Epoch time: 15.87 s 
2025-08-28 04:41:40.816854:  
2025-08-28 04:41:40.825537: Epoch 394 
2025-08-28 04:41:40.829374: Current learning rate: 0.00637 
2025-08-28 04:41:56.612517: train_loss -0.4104 
2025-08-28 04:41:56.624307: val_loss -0.4277 
2025-08-28 04:41:56.628455: Pseudo dice [np.float32(0.7209)] 
2025-08-28 04:41:56.635694: Epoch time: 15.8 s 
2025-08-28 04:41:57.316675:  
2025-08-28 04:41:57.325369: Epoch 395 
2025-08-28 04:41:57.329190: Current learning rate: 0.00636 
2025-08-28 04:42:13.166600: train_loss -0.4263 
2025-08-28 04:42:13.174448: val_loss -0.4762 
2025-08-28 04:42:13.182235: Pseudo dice [np.float32(0.7367)] 
2025-08-28 04:42:13.187515: Epoch time: 15.85 s 
2025-08-28 04:42:13.874863:  
2025-08-28 04:42:13.879049: Epoch 396 
2025-08-28 04:42:13.887403: Current learning rate: 0.00635 
2025-08-28 04:42:30.516473: train_loss -0.4432 
2025-08-28 04:42:30.524807: val_loss -0.4098 
2025-08-28 04:42:30.528962: Pseudo dice [np.float32(0.6946)] 
2025-08-28 04:42:30.538198: Epoch time: 16.65 s 
2025-08-28 04:42:31.221435:  
2025-08-28 04:42:31.229877: Epoch 397 
2025-08-28 04:42:31.234050: Current learning rate: 0.00634 
2025-08-28 04:42:46.854335: train_loss -0.4105 
2025-08-28 04:42:46.862365: val_loss -0.3917 
2025-08-28 04:42:46.870369: Pseudo dice [np.float32(0.7134)] 
2025-08-28 04:42:46.875678: Epoch time: 15.63 s 
2025-08-28 04:42:47.700671:  
2025-08-28 04:42:47.708955: Epoch 398 
2025-08-28 04:42:47.712916: Current learning rate: 0.00633 
2025-08-28 04:43:03.478531: train_loss -0.3894 
2025-08-28 04:43:03.486920: val_loss -0.52 
2025-08-28 04:43:03.495269: Pseudo dice [np.float32(0.7426)] 
2025-08-28 04:43:03.500261: Epoch time: 15.78 s 
2025-08-28 04:43:04.179635:  
2025-08-28 04:43:04.187634: Epoch 399 
2025-08-28 04:43:04.192157: Current learning rate: 0.00632 
2025-08-28 04:43:19.870538: train_loss -0.4296 
2025-08-28 04:43:19.882933: val_loss -0.4409 
2025-08-28 04:43:19.893160: Pseudo dice [np.float32(0.7365)] 
2025-08-28 04:43:19.899063: Epoch time: 15.69 s 
2025-08-28 04:43:20.779552:  
2025-08-28 04:43:20.787541: Epoch 400 
2025-08-28 04:43:20.791762: Current learning rate: 0.00631 
2025-08-28 04:43:37.128848: train_loss -0.4344 
2025-08-28 04:43:37.137407: val_loss -0.5269 
2025-08-28 04:43:37.145333: Pseudo dice [np.float32(0.7875)] 
2025-08-28 04:43:37.151192: Epoch time: 16.35 s 
2025-08-28 04:43:37.829531:  
2025-08-28 04:43:37.836491: Epoch 401 
2025-08-28 04:43:37.845556: Current learning rate: 0.0063 
2025-08-28 04:43:54.934102: train_loss -0.394 
2025-08-28 04:43:54.942787: val_loss -0.5175 
2025-08-28 04:43:54.946937: Pseudo dice [np.float32(0.8219)] 
2025-08-28 04:43:54.954946: Epoch time: 17.1 s 
2025-08-28 04:43:54.960109: Yayy! New best EMA pseudo Dice: 0.7396000027656555 
2025-08-28 04:43:55.885086:  
2025-08-28 04:43:55.893409: Epoch 402 
2025-08-28 04:43:55.897895: Current learning rate: 0.0063 
2025-08-28 04:44:12.238866: train_loss -0.4238 
2025-08-28 04:44:12.247215: val_loss -0.4202 
2025-08-28 04:44:12.251456: Pseudo dice [np.float32(0.6857)] 
2025-08-28 04:44:12.259746: Epoch time: 16.35 s 
2025-08-28 04:44:12.927139:  
2025-08-28 04:44:12.935485: Epoch 403 
2025-08-28 04:44:12.939567: Current learning rate: 0.00629 
2025-08-28 04:44:28.509633: train_loss -0.41 
2025-08-28 04:44:28.517638: val_loss -0.4474 
2025-08-28 04:44:28.522110: Pseudo dice [np.float32(0.6824)] 
2025-08-28 04:44:28.530876: Epoch time: 15.58 s 
2025-08-28 04:44:29.342045:  
2025-08-28 04:44:29.352087: Epoch 404 
2025-08-28 04:44:29.359723: Current learning rate: 0.00628 
2025-08-28 04:44:45.755553: train_loss -0.4043 
2025-08-28 04:44:45.763959: val_loss -0.4453 
2025-08-28 04:44:45.768508: Pseudo dice [np.float32(0.7461)] 
2025-08-28 04:44:45.776480: Epoch time: 16.41 s 
2025-08-28 04:44:46.460564:  
2025-08-28 04:44:46.469253: Epoch 405 
2025-08-28 04:44:46.477275: Current learning rate: 0.00627 
2025-08-28 04:45:02.080680: train_loss -0.4324 
2025-08-28 04:45:02.092501: val_loss -0.4952 
2025-08-28 04:45:02.097288: Pseudo dice [np.float32(0.7483)] 
2025-08-28 04:45:02.103514: Epoch time: 15.62 s 
2025-08-28 04:45:02.772663:  
2025-08-28 04:45:02.781035: Epoch 406 
2025-08-28 04:45:02.785177: Current learning rate: 0.00626 
2025-08-28 04:45:18.304842: train_loss -0.4285 
2025-08-28 04:45:18.313216: val_loss -0.509 
2025-08-28 04:45:18.317373: Pseudo dice [np.float32(0.7185)] 
2025-08-28 04:45:18.323711: Epoch time: 15.54 s 
2025-08-28 04:45:18.993109:  
2025-08-28 04:45:19.001414: Epoch 407 
2025-08-28 04:45:19.005585: Current learning rate: 0.00625 
2025-08-28 04:45:35.430341: train_loss -0.4408 
2025-08-28 04:45:35.438644: val_loss -0.4804 
2025-08-28 04:45:35.446806: Pseudo dice [np.float32(0.7354)] 
2025-08-28 04:45:35.452104: Epoch time: 16.44 s 
2025-08-28 04:45:36.197716:  
2025-08-28 04:45:36.206068: Epoch 408 
2025-08-28 04:45:36.210217: Current learning rate: 0.00624 
2025-08-28 04:45:51.980365: train_loss -0.4277 
2025-08-28 04:45:51.992676: val_loss -0.5026 
2025-08-28 04:45:52.001426: Pseudo dice [np.float32(0.7322)] 
2025-08-28 04:45:52.006427: Epoch time: 15.79 s 
2025-08-28 04:45:52.672587:  
2025-08-28 04:45:52.680917: Epoch 409 
2025-08-28 04:45:52.685015: Current learning rate: 0.00623 
2025-08-28 04:46:08.288529: train_loss -0.4365 
2025-08-28 04:46:08.296504: val_loss -0.4706 
2025-08-28 04:46:08.304873: Pseudo dice [np.float32(0.731)] 
2025-08-28 04:46:08.309791: Epoch time: 15.62 s 
2025-08-28 04:46:09.122292:  
2025-08-28 04:46:09.130905: Epoch 410 
2025-08-28 04:46:09.135030: Current learning rate: 0.00622 
2025-08-28 04:46:24.683963: train_loss -0.4313 
2025-08-28 04:46:24.691964: val_loss -0.4352 
2025-08-28 04:46:24.696402: Pseudo dice [np.float32(0.66)] 
2025-08-28 04:46:24.704291: Epoch time: 15.56 s 
2025-08-28 04:46:25.380475:  
2025-08-28 04:46:25.388507: Epoch 411 
2025-08-28 04:46:25.392667: Current learning rate: 0.00621 
2025-08-28 04:46:41.880694: train_loss -0.423 
2025-08-28 04:46:41.888354: val_loss -0.4422 
2025-08-28 04:46:41.896673: Pseudo dice [np.float32(0.7667)] 
2025-08-28 04:46:41.902039: Epoch time: 16.5 s 
2025-08-28 04:46:42.530597:  
2025-08-28 04:46:42.539063: Epoch 412 
2025-08-28 04:46:42.543129: Current learning rate: 0.0062 
2025-08-28 04:46:58.112891: train_loss -0.4219 
2025-08-28 04:46:58.125365: val_loss -0.4413 
2025-08-28 04:46:58.129676: Pseudo dice [np.float32(0.7211)] 
2025-08-28 04:46:58.136791: Epoch time: 15.58 s 
2025-08-28 04:46:58.776030:  
2025-08-28 04:46:58.780543: Epoch 413 
2025-08-28 04:46:58.788625: Current learning rate: 0.00619 
2025-08-28 04:47:14.433450: train_loss -0.4495 
2025-08-28 04:47:14.441707: val_loss -0.4616 
2025-08-28 04:47:14.450361: Pseudo dice [np.float32(0.7068)] 
2025-08-28 04:47:14.455506: Epoch time: 15.66 s 
2025-08-28 04:47:15.096479:  
2025-08-28 04:47:15.104841: Epoch 414 
2025-08-28 04:47:15.109287: Current learning rate: 0.00618 
2025-08-28 04:47:31.754771: train_loss -0.3964 
2025-08-28 04:47:31.763134: val_loss -0.5306 
2025-08-28 04:47:31.771149: Pseudo dice [np.float32(0.7604)] 
2025-08-28 04:47:31.776720: Epoch time: 16.66 s 
2025-08-28 04:47:32.488886:  
2025-08-28 04:47:32.497528: Epoch 415 
2025-08-28 04:47:32.501622: Current learning rate: 0.00617 
2025-08-28 04:47:48.262931: train_loss -0.4422 
2025-08-28 04:47:48.271272: val_loss -0.4465 
2025-08-28 04:47:48.275417: Pseudo dice [np.float32(0.7444)] 
2025-08-28 04:47:48.283908: Epoch time: 15.77 s 
2025-08-28 04:47:48.942743:  
2025-08-28 04:47:48.951132: Epoch 416 
2025-08-28 04:47:48.959479: Current learning rate: 0.00616 
2025-08-28 04:48:04.462831: train_loss -0.4686 
2025-08-28 04:48:04.470794: val_loss -0.4618 
2025-08-28 04:48:04.474963: Pseudo dice [np.float32(0.7585)] 
2025-08-28 04:48:04.483049: Epoch time: 15.52 s 
2025-08-28 04:48:05.279892:  
2025-08-28 04:48:05.288264: Epoch 417 
2025-08-28 04:48:05.292310: Current learning rate: 0.00615 
2025-08-28 04:48:21.416731: train_loss -0.4518 
2025-08-28 04:48:21.425504: val_loss -0.5179 
2025-08-28 04:48:21.433645: Pseudo dice [np.float32(0.7533)] 
2025-08-28 04:48:21.439247: Epoch time: 16.14 s 
2025-08-28 04:48:22.201025:  
2025-08-28 04:48:22.205137: Epoch 418 
2025-08-28 04:48:22.213566: Current learning rate: 0.00614 
2025-08-28 04:48:38.471548: train_loss -0.4051 
2025-08-28 04:48:38.479719: val_loss -0.4494 
2025-08-28 04:48:38.483932: Pseudo dice [np.float32(0.7209)] 
2025-08-28 04:48:38.492205: Epoch time: 16.27 s 
2025-08-28 04:48:39.134589:  
2025-08-28 04:48:39.138979: Epoch 419 
2025-08-28 04:48:39.147072: Current learning rate: 0.00613 
2025-08-28 04:48:54.762659: train_loss -0.3909 
2025-08-28 04:48:54.775256: val_loss -0.452 
2025-08-28 04:48:54.779710: Pseudo dice [np.float32(0.7456)] 
2025-08-28 04:48:54.785968: Epoch time: 15.63 s 
2025-08-28 04:48:55.425832:  
2025-08-28 04:48:55.434151: Epoch 420 
2025-08-28 04:48:55.438354: Current learning rate: 0.00612 
2025-08-28 04:49:11.049777: train_loss -0.4541 
2025-08-28 04:49:11.058117: val_loss -0.4081 
2025-08-28 04:49:11.066407: Pseudo dice [np.float32(0.6974)] 
2025-08-28 04:49:11.071876: Epoch time: 15.63 s 
2025-08-28 04:49:11.717077:  
2025-08-28 04:49:11.725617: Epoch 421 
2025-08-28 04:49:11.729583: Current learning rate: 0.00612 
2025-08-28 04:49:28.463129: train_loss -0.3895 
2025-08-28 04:49:28.471301: val_loss -0.482 
2025-08-28 04:49:28.475478: Pseudo dice [np.float32(0.7633)] 
2025-08-28 04:49:28.483843: Epoch time: 16.75 s 
2025-08-28 04:49:29.146959:  
2025-08-28 04:49:29.151189: Epoch 422 
2025-08-28 04:49:29.159510: Current learning rate: 0.00611 
2025-08-28 04:49:44.899549: train_loss -0.4159 
2025-08-28 04:49:44.904397: val_loss -0.4865 
2025-08-28 04:49:44.912750: Pseudo dice [np.float32(0.7299)] 
2025-08-28 04:49:44.919056: Epoch time: 15.76 s 
2025-08-28 04:49:45.567804:  
2025-08-28 04:49:45.576200: Epoch 423 
2025-08-28 04:49:45.580042: Current learning rate: 0.0061 
2025-08-28 04:50:01.713131: train_loss -0.4509 
2025-08-28 04:50:01.721213: val_loss -0.4859 
2025-08-28 04:50:01.729548: Pseudo dice [np.float32(0.7527)] 
2025-08-28 04:50:01.737851: Epoch time: 16.15 s 
2025-08-28 04:50:02.484412:  
2025-08-28 04:50:02.492776: Epoch 424 
2025-08-28 04:50:02.496932: Current learning rate: 0.00609 
2025-08-28 04:50:18.613143: train_loss -0.4056 
2025-08-28 04:50:18.621360: val_loss -0.4275 
2025-08-28 04:50:18.630076: Pseudo dice [np.float32(0.6539)] 
2025-08-28 04:50:18.634809: Epoch time: 16.13 s 
2025-08-28 04:50:19.284553:  
2025-08-28 04:50:19.292905: Epoch 425 
2025-08-28 04:50:19.297061: Current learning rate: 0.00608 
2025-08-28 04:50:35.055026: train_loss -0.4472 
2025-08-28 04:50:35.062809: val_loss -0.4804 
2025-08-28 04:50:35.071010: Pseudo dice [np.float32(0.7045)] 
2025-08-28 04:50:35.076250: Epoch time: 15.77 s 
2025-08-28 04:50:35.722029:  
2025-08-28 04:50:35.730210: Epoch 426 
2025-08-28 04:50:35.734298: Current learning rate: 0.00607 
2025-08-28 04:50:52.293126: train_loss -0.4183 
2025-08-28 04:50:52.300873: val_loss -0.3973 
2025-08-28 04:50:52.309540: Pseudo dice [np.float32(0.6644)] 
2025-08-28 04:50:52.314764: Epoch time: 16.57 s 
2025-08-28 04:50:53.039021:  
2025-08-28 04:50:53.047429: Epoch 427 
2025-08-28 04:50:53.051482: Current learning rate: 0.00606 
2025-08-28 04:51:09.226357: train_loss -0.4347 
2025-08-28 04:51:09.234693: val_loss -0.4558 
2025-08-28 04:51:09.242775: Pseudo dice [np.float32(0.749)] 
2025-08-28 04:51:09.248184: Epoch time: 16.19 s 
2025-08-28 04:51:09.885047:  
2025-08-28 04:51:09.893615: Epoch 428 
2025-08-28 04:51:09.897566: Current learning rate: 0.00605 
2025-08-28 04:51:25.680470: train_loss -0.384 
2025-08-28 04:51:25.688344: val_loss -0.4199 
2025-08-28 04:51:25.696707: Pseudo dice [np.float32(0.6186)] 
2025-08-28 04:51:25.701657: Epoch time: 15.8 s 
2025-08-28 04:51:26.351476:  
2025-08-28 04:51:26.355696: Epoch 429 
2025-08-28 04:51:26.364005: Current learning rate: 0.00604 
2025-08-28 04:51:41.988011: train_loss -0.4413 
2025-08-28 04:51:41.996607: val_loss -0.4615 
2025-08-28 04:51:42.000464: Pseudo dice [np.float32(0.6544)] 
2025-08-28 04:51:42.009566: Epoch time: 15.64 s 
2025-08-28 04:51:42.805432:  
2025-08-28 04:51:42.813776: Epoch 430 
2025-08-28 04:51:42.818279: Current learning rate: 0.00603 
2025-08-28 04:51:59.518069: train_loss -0.4052 
2025-08-28 04:51:59.530539: val_loss -0.5169 
2025-08-28 04:51:59.534924: Pseudo dice [np.float32(0.7457)] 
2025-08-28 04:51:59.542260: Epoch time: 16.71 s 
2025-08-28 04:52:00.264554:  
2025-08-28 04:52:00.272880: Epoch 431 
2025-08-28 04:52:00.277044: Current learning rate: 0.00602 
2025-08-28 04:52:15.813477: train_loss -0.4354 
2025-08-28 04:52:15.821766: val_loss -0.4481 
2025-08-28 04:52:15.825846: Pseudo dice [np.float32(0.6896)] 
2025-08-28 04:52:15.834254: Epoch time: 15.55 s 
2025-08-28 04:52:16.484953:  
2025-08-28 04:52:16.489426: Epoch 432 
2025-08-28 04:52:16.497785: Current learning rate: 0.00601 
2025-08-28 04:52:33.356690: train_loss -0.4149 
2025-08-28 04:52:33.364566: val_loss -0.3637 
2025-08-28 04:52:33.372935: Pseudo dice [np.float32(0.6465)] 
2025-08-28 04:52:33.378067: Epoch time: 16.88 s 
2025-08-28 04:52:34.027421:  
2025-08-28 04:52:34.031610: Epoch 433 
2025-08-28 04:52:34.039937: Current learning rate: 0.006 
2025-08-28 04:52:51.378254: train_loss -0.4365 
2025-08-28 04:52:51.390690: val_loss -0.4427 
2025-08-28 04:52:51.394825: Pseudo dice [np.float32(0.7022)] 
2025-08-28 04:52:51.402127: Epoch time: 17.36 s 
2025-08-28 04:52:52.149692:  
2025-08-28 04:52:52.153854: Epoch 434 
2025-08-28 04:52:52.162182: Current learning rate: 0.00599 
2025-08-28 04:53:09.671323: train_loss -0.4092 
2025-08-28 04:53:09.679677: val_loss -0.5048 
2025-08-28 04:53:09.688008: Pseudo dice [np.float32(0.778)] 
2025-08-28 04:53:09.694255: Epoch time: 17.53 s 
2025-08-28 04:53:10.347322:  
2025-08-28 04:53:10.355644: Epoch 435 
2025-08-28 04:53:10.359604: Current learning rate: 0.00598 
2025-08-28 04:53:27.151613: train_loss -0.4375 
2025-08-28 04:53:27.161872: val_loss -0.5329 
2025-08-28 04:53:27.167974: Pseudo dice [np.float32(0.7778)] 
2025-08-28 04:53:27.173550: Epoch time: 16.8 s 
2025-08-28 04:53:27.826958:  
2025-08-28 04:53:27.836603: Epoch 436 
2025-08-28 04:53:27.842803: Current learning rate: 0.00597 
2025-08-28 04:53:45.623938: train_loss -0.46 
2025-08-28 04:53:45.636251: val_loss -0.4631 
2025-08-28 04:53:45.640861: Pseudo dice [np.float32(0.7234)] 
2025-08-28 04:53:45.647842: Epoch time: 17.8 s 
2025-08-28 04:53:46.570693:  
2025-08-28 04:53:46.579026: Epoch 437 
2025-08-28 04:53:46.583178: Current learning rate: 0.00596 
2025-08-28 04:54:03.587689: train_loss -0.4317 
2025-08-28 04:54:03.600197: val_loss -0.4783 
2025-08-28 04:54:03.604651: Pseudo dice [np.float32(0.7293)] 
2025-08-28 04:54:03.611589: Epoch time: 17.02 s 
2025-08-28 04:54:04.250832:  
2025-08-28 04:54:04.254994: Epoch 438 
2025-08-28 04:54:04.263743: Current learning rate: 0.00595 
2025-08-28 04:54:21.301203: train_loss -0.4121 
2025-08-28 04:54:21.309530: val_loss -0.3675 
2025-08-28 04:54:21.314066: Pseudo dice [np.float32(0.681)] 
2025-08-28 04:54:21.319942: Epoch time: 17.05 s 
2025-08-28 04:54:21.964386:  
2025-08-28 04:54:21.972729: Epoch 439 
2025-08-28 04:54:21.976897: Current learning rate: 0.00594 
2025-08-28 04:54:38.764469: train_loss -0.4428 
2025-08-28 04:54:38.772807: val_loss -0.502 
2025-08-28 04:54:38.776990: Pseudo dice [np.float32(0.7112)] 
2025-08-28 04:54:38.786270: Epoch time: 16.8 s 
2025-08-28 04:54:39.528062:  
2025-08-28 04:54:39.536072: Epoch 440 
2025-08-28 04:54:39.540515: Current learning rate: 0.00593 
2025-08-28 04:54:57.020425: train_loss -0.4246 
2025-08-28 04:54:57.028524: val_loss -0.4861 
2025-08-28 04:54:57.036910: Pseudo dice [np.float32(0.7266)] 
2025-08-28 04:54:57.042630: Epoch time: 17.49 s 
2025-08-28 04:54:57.683383:  
2025-08-28 04:54:57.692008: Epoch 441 
2025-08-28 04:54:57.695864: Current learning rate: 0.00592 
2025-08-28 04:55:14.254147: train_loss -0.3942 
2025-08-28 04:55:14.262455: val_loss -0.5233 
2025-08-28 04:55:14.270457: Pseudo dice [np.float32(0.7306)] 
2025-08-28 04:55:14.275822: Epoch time: 16.57 s 
2025-08-28 04:55:14.921401:  
2025-08-28 04:55:14.929761: Epoch 442 
2025-08-28 04:55:14.933904: Current learning rate: 0.00592 
2025-08-28 04:55:32.435041: train_loss -0.4506 
2025-08-28 04:55:32.443351: val_loss -0.5261 
2025-08-28 04:55:32.451786: Pseudo dice [np.float32(0.7079)] 
2025-08-28 04:55:32.459327: Epoch time: 17.52 s 
2025-08-28 04:55:33.198087:  
2025-08-28 04:55:33.206547: Epoch 443 
2025-08-28 04:55:33.213399: Current learning rate: 0.00591 
2025-08-28 04:55:50.590346: train_loss -0.423 
2025-08-28 04:55:50.598681: val_loss -0.526 
2025-08-28 04:55:50.607050: Pseudo dice [np.float32(0.7571)] 
2025-08-28 04:55:50.612426: Epoch time: 17.39 s 
2025-08-28 04:55:51.411999:  
2025-08-28 04:55:51.420702: Epoch 444 
2025-08-28 04:55:51.424523: Current learning rate: 0.0059 
2025-08-28 04:56:08.366745: train_loss -0.4426 
2025-08-28 04:56:08.375024: val_loss -0.4339 
2025-08-28 04:56:08.383154: Pseudo dice [np.float32(0.6861)] 
2025-08-28 04:56:08.387975: Epoch time: 16.95 s 
2025-08-28 04:56:09.012915:  
2025-08-28 04:56:09.021588: Epoch 445 
2025-08-28 04:56:09.025434: Current learning rate: 0.00589 
2025-08-28 04:56:25.787939: train_loss -0.4053 
2025-08-28 04:56:25.796671: val_loss -0.5264 
2025-08-28 04:56:25.804667: Pseudo dice [np.float32(0.7886)] 
2025-08-28 04:56:25.811416: Epoch time: 16.78 s 
2025-08-28 04:56:26.472103:  
2025-08-28 04:56:26.480393: Epoch 446 
2025-08-28 04:56:26.484934: Current learning rate: 0.00588 
2025-08-28 04:56:44.160496: train_loss -0.4065 
2025-08-28 04:56:44.168846: val_loss -0.4974 
2025-08-28 04:56:44.173410: Pseudo dice [np.float32(0.7963)] 
2025-08-28 04:56:44.180212: Epoch time: 17.69 s 
2025-08-28 04:56:44.815317:  
2025-08-28 04:56:44.823687: Epoch 447 
2025-08-28 04:56:44.827813: Current learning rate: 0.00587 
2025-08-28 04:57:01.732330: train_loss -0.4281 
2025-08-28 04:57:01.744773: val_loss -0.5468 
2025-08-28 04:57:01.749364: Pseudo dice [np.float32(0.8041)] 
2025-08-28 04:57:01.756052: Epoch time: 16.92 s 
2025-08-28 04:57:02.395416:  
2025-08-28 04:57:02.399585: Epoch 448 
2025-08-28 04:57:02.408241: Current learning rate: 0.00586 
2025-08-28 04:57:19.200060: train_loss -0.4513 
2025-08-28 04:57:19.208325: val_loss -0.4993 
2025-08-28 04:57:19.212520: Pseudo dice [np.float32(0.7604)] 
2025-08-28 04:57:19.220830: Epoch time: 16.81 s 
2025-08-28 04:57:19.227313: Yayy! New best EMA pseudo Dice: 0.7407000064849854 
2025-08-28 04:57:20.117233:  
2025-08-28 04:57:20.125594: Epoch 449 
2025-08-28 04:57:20.133915: Current learning rate: 0.00585 
2025-08-28 04:57:37.864137: train_loss -0.4654 
2025-08-28 04:57:37.872478: val_loss -0.4672 
2025-08-28 04:57:37.876938: Pseudo dice [np.float32(0.7234)] 
2025-08-28 04:57:37.884048: Epoch time: 17.75 s 
2025-08-28 04:57:38.773410:  
2025-08-28 04:57:38.777563: Epoch 450 
2025-08-28 04:57:38.785890: Current learning rate: 0.00584 
2025-08-28 04:57:55.999462: train_loss -0.4645 
2025-08-28 04:57:56.011767: val_loss -0.5262 
2025-08-28 04:57:56.015900: Pseudo dice [np.float32(0.7716)] 
2025-08-28 04:57:56.022717: Epoch time: 17.23 s 
2025-08-28 04:57:56.028557: Yayy! New best EMA pseudo Dice: 0.7422000169754028 
2025-08-28 04:57:56.991833:  
2025-08-28 04:57:57.000260: Epoch 451 
2025-08-28 04:57:57.004092: Current learning rate: 0.00583 
2025-08-28 04:58:13.228686: train_loss -0.4434 
2025-08-28 04:58:13.236995: val_loss -0.4408 
2025-08-28 04:58:13.241618: Pseudo dice [np.float32(0.6697)] 
2025-08-28 04:58:13.249468: Epoch time: 16.24 s 
2025-08-28 04:58:13.879602:  
2025-08-28 04:58:13.887646: Epoch 452 
2025-08-28 04:58:13.891783: Current learning rate: 0.00582 
2025-08-28 04:58:30.170794: train_loss -0.4428 
2025-08-28 04:58:30.179195: val_loss -0.4907 
2025-08-28 04:58:30.183322: Pseudo dice [np.float32(0.7844)] 
2025-08-28 04:58:30.192828: Epoch time: 16.29 s 
2025-08-28 04:58:30.825336:  
2025-08-28 04:58:30.835126: Epoch 453 
2025-08-28 04:58:30.840406: Current learning rate: 0.00581 
2025-08-28 04:58:47.446377: train_loss -0.4391 
2025-08-28 04:58:47.454879: val_loss -0.4487 
2025-08-28 04:58:47.458969: Pseudo dice [np.float32(0.6856)] 
2025-08-28 04:58:47.466026: Epoch time: 16.62 s 
2025-08-28 04:58:48.105098:  
2025-08-28 04:58:48.113695: Epoch 454 
2025-08-28 04:58:48.117932: Current learning rate: 0.0058 
2025-08-28 04:59:05.017858: train_loss -0.4423 
2025-08-28 04:59:05.030539: val_loss -0.4939 
2025-08-28 04:59:05.034530: Pseudo dice [np.float32(0.7623)] 
2025-08-28 04:59:05.041113: Epoch time: 16.92 s 
2025-08-28 04:59:05.772740:  
2025-08-28 04:59:05.781139: Epoch 455 
2025-08-28 04:59:05.785274: Current learning rate: 0.00579 
2025-08-28 04:59:22.055688: train_loss -0.4293 
2025-08-28 04:59:22.064013: val_loss -0.4747 
2025-08-28 04:59:22.068200: Pseudo dice [np.float32(0.7702)] 
2025-08-28 04:59:22.076417: Epoch time: 16.29 s 
2025-08-28 04:59:22.735515:  
2025-08-28 04:59:22.739974: Epoch 456 
2025-08-28 04:59:22.748429: Current learning rate: 0.00578 
2025-08-28 04:59:38.889346: train_loss -0.4315 
2025-08-28 04:59:38.897542: val_loss -0.5507 
2025-08-28 04:59:38.905894: Pseudo dice [np.float32(0.7606)] 
2025-08-28 04:59:38.911288: Epoch time: 16.16 s 
2025-08-28 04:59:38.914984: Yayy! New best EMA pseudo Dice: 0.7426000237464905 
2025-08-28 04:59:39.990240:  
2025-08-28 04:59:39.998611: Epoch 457 
2025-08-28 04:59:40.002780: Current learning rate: 0.00577 
2025-08-28 04:59:57.416110: train_loss -0.4403 
2025-08-28 04:59:57.424335: val_loss -0.4726 
2025-08-28 04:59:57.432992: Pseudo dice [np.float32(0.6778)] 
2025-08-28 04:59:57.438212: Epoch time: 17.43 s 
2025-08-28 04:59:58.120863:  
2025-08-28 04:59:58.129234: Epoch 458 
2025-08-28 04:59:58.133311: Current learning rate: 0.00576 
2025-08-28 05:00:14.896040: train_loss -0.4502 
2025-08-28 05:00:14.904276: val_loss -0.5043 
2025-08-28 05:00:14.912569: Pseudo dice [np.float32(0.748)] 
2025-08-28 05:00:14.919827: Epoch time: 16.78 s 
2025-08-28 05:00:15.559183:  
2025-08-28 05:00:15.567230: Epoch 459 
2025-08-28 05:00:15.572036: Current learning rate: 0.00575 
2025-08-28 05:00:31.897288: train_loss -0.4355 
2025-08-28 05:00:31.904598: val_loss -0.5553 
2025-08-28 05:00:31.912925: Pseudo dice [np.float32(0.8359)] 
2025-08-28 05:00:31.921248: Epoch time: 16.34 s 
2025-08-28 05:00:31.927012: Yayy! New best EMA pseudo Dice: 0.7470999956130981 
2025-08-28 05:00:32.730402:  
2025-08-28 05:00:32.734585: Epoch 460 
2025-08-28 05:00:32.742924: Current learning rate: 0.00574 
2025-08-28 05:00:49.647768: train_loss -0.4273 
2025-08-28 05:00:49.655646: val_loss -0.4723 
2025-08-28 05:00:49.663998: Pseudo dice [np.float32(0.6954)] 
2025-08-28 05:00:49.670571: Epoch time: 16.92 s 
2025-08-28 05:00:50.381401:  
2025-08-28 05:00:50.390040: Epoch 461 
2025-08-28 05:00:50.393904: Current learning rate: 0.00573 
2025-08-28 05:01:08.257566: train_loss -0.4157 
2025-08-28 05:01:08.265908: val_loss -0.4408 
2025-08-28 05:01:08.274416: Pseudo dice [np.float32(0.7068)] 
2025-08-28 05:01:08.279876: Epoch time: 17.88 s 
2025-08-28 05:01:08.912379:  
2025-08-28 05:01:08.920715: Epoch 462 
2025-08-28 05:01:08.924926: Current learning rate: 0.00572 
2025-08-28 05:01:25.679118: train_loss -0.4566 
2025-08-28 05:01:25.691594: val_loss -0.443 
2025-08-28 05:01:25.695842: Pseudo dice [np.float32(0.6794)] 
2025-08-28 05:01:25.701740: Epoch time: 16.77 s 
2025-08-28 05:01:26.346874:  
2025-08-28 05:01:26.350920: Epoch 463 
2025-08-28 05:01:26.359487: Current learning rate: 0.00571 
2025-08-28 05:01:43.209133: train_loss -0.4394 
2025-08-28 05:01:43.217494: val_loss -0.5696 
2025-08-28 05:01:43.226145: Pseudo dice [np.float32(0.8265)] 
2025-08-28 05:01:43.232950: Epoch time: 16.86 s 
2025-08-28 05:01:44.043346:  
2025-08-28 05:01:44.047547: Epoch 464 
2025-08-28 05:01:44.055525: Current learning rate: 0.0057 
2025-08-28 05:02:01.957056: train_loss -0.4429 
2025-08-28 05:02:01.965444: val_loss -0.3842 
2025-08-28 05:02:01.973734: Pseudo dice [np.float32(0.6565)] 
2025-08-28 05:02:01.979138: Epoch time: 17.92 s 
2025-08-28 05:02:02.611835:  
2025-08-28 05:02:02.620215: Epoch 465 
2025-08-28 05:02:02.624348: Current learning rate: 0.0057 
2025-08-28 05:02:19.357830: train_loss -0.4701 
2025-08-28 05:02:19.366133: val_loss -0.5092 
2025-08-28 05:02:19.370551: Pseudo dice [np.float32(0.7964)] 
2025-08-28 05:02:19.377607: Epoch time: 16.75 s 
2025-08-28 05:02:20.050075:  
2025-08-28 05:02:20.054250: Epoch 466 
2025-08-28 05:02:20.062604: Current learning rate: 0.00569 
2025-08-28 05:02:36.687812: train_loss -0.4457 
2025-08-28 05:02:36.696153: val_loss -0.5062 
2025-08-28 05:02:36.703983: Pseudo dice [np.float32(0.7704)] 
2025-08-28 05:02:36.709211: Epoch time: 16.64 s 
2025-08-28 05:02:37.413248:  
2025-08-28 05:02:37.421605: Epoch 467 
2025-08-28 05:02:37.425979: Current learning rate: 0.00568 
2025-08-28 05:02:55.168512: train_loss -0.4367 
2025-08-28 05:02:55.180748: val_loss -0.5063 
2025-08-28 05:02:55.187200: Pseudo dice [np.float32(0.6794)] 
2025-08-28 05:02:55.193490: Epoch time: 17.76 s 
2025-08-28 05:02:55.894197:  
2025-08-28 05:02:55.902632: Epoch 468 
2025-08-28 05:02:55.906790: Current learning rate: 0.00567 
2025-08-28 05:03:12.469141: train_loss -0.466 
2025-08-28 05:03:12.477872: val_loss -0.4588 
2025-08-28 05:03:12.485826: Pseudo dice [np.float32(0.6688)] 
2025-08-28 05:03:12.490829: Epoch time: 16.57 s 
2025-08-28 05:03:13.132255:  
2025-08-28 05:03:13.140928: Epoch 469 
2025-08-28 05:03:13.144794: Current learning rate: 0.00566 
2025-08-28 05:03:30.261863: train_loss -0.4221 
2025-08-28 05:03:30.274404: val_loss -0.4594 
2025-08-28 05:03:30.279067: Pseudo dice [np.float32(0.7054)] 
2025-08-28 05:03:30.287865: Epoch time: 17.13 s 
2025-08-28 05:03:31.029288:  
2025-08-28 05:03:31.037628: Epoch 470 
2025-08-28 05:03:31.042140: Current learning rate: 0.00565 
2025-08-28 05:03:48.530111: train_loss -0.4477 
2025-08-28 05:03:48.538455: val_loss -0.453 
2025-08-28 05:03:48.542617: Pseudo dice [np.float32(0.7149)] 
2025-08-28 05:03:48.549783: Epoch time: 17.5 s 
2025-08-28 05:03:49.189096:  
2025-08-28 05:03:49.197468: Epoch 471 
2025-08-28 05:03:49.205437: Current learning rate: 0.00564 
2025-08-28 05:04:06.176536: train_loss -0.4319 
2025-08-28 05:04:06.185003: val_loss -0.417 
2025-08-28 05:04:06.189389: Pseudo dice [np.float32(0.691)] 
2025-08-28 05:04:06.197271: Epoch time: 16.99 s 
2025-08-28 05:04:06.831763:  
2025-08-28 05:04:06.840561: Epoch 472 
2025-08-28 05:04:06.845765: Current learning rate: 0.00563 
2025-08-28 05:04:23.569518: train_loss -0.4485 
2025-08-28 05:04:23.577642: val_loss -0.4122 
2025-08-28 05:04:23.586221: Pseudo dice [np.float32(0.607)] 
2025-08-28 05:04:23.591124: Epoch time: 16.74 s 
2025-08-28 05:04:24.224126:  
2025-08-28 05:04:24.232434: Epoch 473 
2025-08-28 05:04:24.236588: Current learning rate: 0.00562 
2025-08-28 05:04:42.054345: train_loss -0.4484 
2025-08-28 05:04:42.063160: val_loss -0.5309 
2025-08-28 05:04:42.067050: Pseudo dice [np.float32(0.7396)] 
2025-08-28 05:04:42.074076: Epoch time: 17.83 s 
2025-08-28 05:04:42.788499:  
2025-08-28 05:04:42.797049: Epoch 474 
2025-08-28 05:04:42.801222: Current learning rate: 0.00561 
2025-08-28 05:04:59.667852: train_loss -0.4505 
2025-08-28 05:04:59.680367: val_loss -0.4879 
2025-08-28 05:04:59.684755: Pseudo dice [np.float32(0.7119)] 
2025-08-28 05:04:59.691715: Epoch time: 16.88 s 
2025-08-28 05:05:00.364316:  
2025-08-28 05:05:00.372674: Epoch 475 
2025-08-28 05:05:00.376842: Current learning rate: 0.0056 
2025-08-28 05:05:16.952028: train_loss -0.4453 
2025-08-28 05:05:16.960377: val_loss -0.4566 
2025-08-28 05:05:16.964241: Pseudo dice [np.float32(0.6865)] 
2025-08-28 05:05:16.971798: Epoch time: 16.59 s 
2025-08-28 05:05:17.602594:  
2025-08-28 05:05:17.606568: Epoch 476 
2025-08-28 05:05:17.610723: Current learning rate: 0.00559 
2025-08-28 05:05:34.702796: train_loss -0.4723 
2025-08-28 05:05:34.711111: val_loss -0.5037 
2025-08-28 05:05:34.715636: Pseudo dice [np.float32(0.7881)] 
2025-08-28 05:05:34.724575: Epoch time: 17.1 s 
2025-08-28 05:05:35.361758:  
2025-08-28 05:05:35.365941: Epoch 477 
2025-08-28 05:05:35.374277: Current learning rate: 0.00558 
2025-08-28 05:05:53.021098: train_loss -0.4272 
2025-08-28 05:05:53.033590: val_loss -0.4459 
2025-08-28 05:05:53.042033: Pseudo dice [np.float32(0.7112)] 
2025-08-28 05:05:53.047707: Epoch time: 17.66 s 
2025-08-28 05:05:53.839973:  
2025-08-28 05:05:53.847242: Epoch 478 
2025-08-28 05:05:53.851180: Current learning rate: 0.00557 
2025-08-28 05:06:10.672038: train_loss -0.4842 
2025-08-28 05:06:10.680362: val_loss -0.4583 
2025-08-28 05:06:10.688756: Pseudo dice [np.float32(0.7044)] 
2025-08-28 05:06:10.693606: Epoch time: 16.83 s 
2025-08-28 05:06:11.339307:  
2025-08-28 05:06:11.346918: Epoch 479 
2025-08-28 05:06:11.351859: Current learning rate: 0.00556 
2025-08-28 05:06:28.227110: train_loss -0.4262 
2025-08-28 05:06:28.235658: val_loss -0.4812 
2025-08-28 05:06:28.243739: Pseudo dice [np.float32(0.7567)] 
2025-08-28 05:06:28.249963: Epoch time: 16.89 s 
2025-08-28 05:06:28.965327:  
2025-08-28 05:06:28.973631: Epoch 480 
2025-08-28 05:06:28.978122: Current learning rate: 0.00555 
2025-08-28 05:06:47.012489: train_loss -0.4386 
2025-08-28 05:06:47.021164: val_loss -0.5159 
2025-08-28 05:06:47.025171: Pseudo dice [np.float32(0.7128)] 
2025-08-28 05:06:47.034218: Epoch time: 18.05 s 
2025-08-28 05:06:47.667287:  
2025-08-28 05:06:47.675638: Epoch 481 
2025-08-28 05:06:47.682570: Current learning rate: 0.00554 
2025-08-28 05:07:04.271527: train_loss -0.4434 
2025-08-28 05:07:04.283963: val_loss -0.492 
2025-08-28 05:07:04.288357: Pseudo dice [np.float32(0.735)] 
2025-08-28 05:07:04.295269: Epoch time: 16.6 s 
2025-08-28 05:07:04.938721:  
2025-08-28 05:07:04.947092: Epoch 482 
2025-08-28 05:07:04.951235: Current learning rate: 0.00553 
2025-08-28 05:07:21.639194: train_loss -0.4602 
2025-08-28 05:07:21.647072: val_loss -0.5716 
2025-08-28 05:07:21.651228: Pseudo dice [np.float32(0.8132)] 
2025-08-28 05:07:21.658331: Epoch time: 16.7 s 
2025-08-28 05:07:22.301917:  
2025-08-28 05:07:22.306398: Epoch 483 
2025-08-28 05:07:22.310234: Current learning rate: 0.00552 
2025-08-28 05:07:40.107182: train_loss -0.4812 
2025-08-28 05:07:40.115511: val_loss -0.534 
2025-08-28 05:07:40.119711: Pseudo dice [np.float32(0.747)] 
2025-08-28 05:07:40.127821: Epoch time: 17.81 s 
2025-08-28 05:07:40.774770:  
2025-08-28 05:07:40.782905: Epoch 484 
2025-08-28 05:07:40.787005: Current learning rate: 0.00551 
2025-08-28 05:07:57.783565: train_loss -0.4552 
2025-08-28 05:07:57.791717: val_loss -0.5227 
2025-08-28 05:07:57.799843: Pseudo dice [np.float32(0.803)] 
2025-08-28 05:07:57.806123: Epoch time: 17.01 s 
2025-08-28 05:07:58.609006:  
2025-08-28 05:07:58.617346: Epoch 485 
2025-08-28 05:07:58.621813: Current learning rate: 0.0055 
2025-08-28 05:08:15.542831: train_loss -0.4629 
2025-08-28 05:08:15.550890: val_loss -0.5226 
2025-08-28 05:08:15.559243: Pseudo dice [np.float32(0.7777)] 
2025-08-28 05:08:15.565429: Epoch time: 16.93 s 
2025-08-28 05:08:16.234943:  
2025-08-28 05:08:16.239105: Epoch 486 
2025-08-28 05:08:16.247720: Current learning rate: 0.00549 
2025-08-28 05:08:34.432388: train_loss -0.4702 
2025-08-28 05:08:34.440895: val_loss -0.5742 
2025-08-28 05:08:34.445073: Pseudo dice [np.float32(0.8312)] 
2025-08-28 05:08:34.450986: Epoch time: 18.2 s 
2025-08-28 05:08:34.454019: Yayy! New best EMA pseudo Dice: 0.7519000172615051 
2025-08-28 05:08:35.395979:  
2025-08-28 05:08:35.404157: Epoch 487 
2025-08-28 05:08:35.408601: Current learning rate: 0.00548 
2025-08-28 05:08:52.396087: train_loss -0.4574 
2025-08-28 05:08:52.408822: val_loss -0.5165 
2025-08-28 05:08:52.412779: Pseudo dice [np.float32(0.7824)] 
2025-08-28 05:08:52.421938: Epoch time: 17.0 s 
2025-08-28 05:08:52.426101: Yayy! New best EMA pseudo Dice: 0.7548999786376953 
2025-08-28 05:08:53.230178:  
2025-08-28 05:08:53.238510: Epoch 488 
2025-08-28 05:08:53.242687: Current learning rate: 0.00547 
2025-08-28 05:09:10.213799: train_loss -0.4443 
2025-08-28 05:09:10.222510: val_loss -0.4733 
2025-08-28 05:09:10.230810: Pseudo dice [np.float32(0.7577)] 
2025-08-28 05:09:10.237213: Epoch time: 16.98 s 
2025-08-28 05:09:10.243415: Yayy! New best EMA pseudo Dice: 0.7552000284194946 
2025-08-28 05:09:11.064646:  
2025-08-28 05:09:11.073254: Epoch 489 
2025-08-28 05:09:11.081872: Current learning rate: 0.00546 
2025-08-28 05:09:28.244217: train_loss -0.4504 
2025-08-28 05:09:28.252935: val_loss -0.4812 
2025-08-28 05:09:28.256915: Pseudo dice [np.float32(0.7212)] 
2025-08-28 05:09:28.264387: Epoch time: 17.18 s 
2025-08-28 05:09:28.995088:  
2025-08-28 05:09:28.999232: Epoch 490 
2025-08-28 05:09:29.007573: Current learning rate: 0.00546 
2025-08-28 05:09:45.674290: train_loss -0.466 
2025-08-28 05:09:45.682556: val_loss -0.5175 
2025-08-28 05:09:45.691264: Pseudo dice [np.float32(0.7225)] 
2025-08-28 05:09:45.696395: Epoch time: 16.68 s 
2025-08-28 05:09:46.350089:  
2025-08-28 05:09:46.358301: Epoch 491 
2025-08-28 05:09:46.362404: Current learning rate: 0.00545 
2025-08-28 05:10:03.567551: train_loss -0.4598 
2025-08-28 05:10:03.579593: val_loss -0.4994 
2025-08-28 05:10:03.583779: Pseudo dice [np.float32(0.7563)] 
2025-08-28 05:10:03.590264: Epoch time: 17.22 s 
2025-08-28 05:10:04.384919:  
2025-08-28 05:10:04.392922: Epoch 492 
2025-08-28 05:10:04.397480: Current learning rate: 0.00544 
2025-08-28 05:10:21.681184: train_loss -0.4168 
2025-08-28 05:10:21.689698: val_loss -0.4867 
2025-08-28 05:10:21.697722: Pseudo dice [np.float32(0.7551)] 
2025-08-28 05:10:21.703929: Epoch time: 17.3 s 
2025-08-28 05:10:22.481892:  
2025-08-28 05:10:22.486043: Epoch 493 
2025-08-28 05:10:22.494337: Current learning rate: 0.00543 
2025-08-28 05:10:39.824112: train_loss -0.4423 
2025-08-28 05:10:39.832487: val_loss -0.4351 
2025-08-28 05:10:39.838268: Pseudo dice [np.float32(0.7159)] 
2025-08-28 05:10:39.845078: Epoch time: 17.35 s 
2025-08-28 05:10:40.491467:  
2025-08-28 05:10:40.495907: Epoch 494 
2025-08-28 05:10:40.503971: Current learning rate: 0.00542 
2025-08-28 05:10:57.334519: train_loss -0.4724 
2025-08-28 05:10:57.345710: val_loss -0.5218 
2025-08-28 05:10:57.350250: Pseudo dice [np.float32(0.7928)] 
2025-08-28 05:10:57.357250: Epoch time: 16.85 s 
2025-08-28 05:10:58.000619:  
2025-08-28 05:10:58.004776: Epoch 495 
2025-08-28 05:10:58.013117: Current learning rate: 0.00541 
2025-08-28 05:11:15.055569: train_loss -0.4728 
2025-08-28 05:11:15.063550: val_loss -0.412 
2025-08-28 05:11:15.072237: Pseudo dice [np.float32(0.7353)] 
2025-08-28 05:11:15.078021: Epoch time: 17.06 s 
2025-08-28 05:11:15.722461:  
2025-08-28 05:11:15.730844: Epoch 496 
2025-08-28 05:11:15.735262: Current learning rate: 0.0054 
2025-08-28 05:11:33.744965: train_loss -0.4398 
2025-08-28 05:11:33.752998: val_loss -0.4767 
2025-08-28 05:11:33.761349: Pseudo dice [np.float32(0.8246)] 
2025-08-28 05:11:33.766377: Epoch time: 18.02 s 
2025-08-28 05:11:33.772571: Yayy! New best EMA pseudo Dice: 0.7572000026702881 
2025-08-28 05:11:34.591342:  
2025-08-28 05:11:34.600008: Epoch 497 
2025-08-28 05:11:34.603842: Current learning rate: 0.00539 
2025-08-28 05:11:51.708415: train_loss -0.4796 
2025-08-28 05:11:51.722591: val_loss -0.4888 
2025-08-28 05:11:51.729242: Pseudo dice [np.float32(0.7076)] 
2025-08-28 05:11:51.734981: Epoch time: 17.12 s 
2025-08-28 05:11:52.384104:  
2025-08-28 05:11:52.392801: Epoch 498 
2025-08-28 05:11:52.396619: Current learning rate: 0.00538 
2025-08-28 05:12:09.000726: train_loss -0.4279 
2025-08-28 05:12:09.009284: val_loss -0.4873 
2025-08-28 05:12:09.017601: Pseudo dice [np.float32(0.7332)] 
2025-08-28 05:12:09.023813: Epoch time: 16.62 s 
2025-08-28 05:12:09.826470:  
2025-08-28 05:12:09.834865: Epoch 499 
2025-08-28 05:12:09.841391: Current learning rate: 0.00537 
2025-08-28 05:12:27.169168: train_loss -0.4354 
2025-08-28 05:12:27.177140: val_loss -0.5346 
2025-08-28 05:12:27.186063: Pseudo dice [np.float32(0.7777)] 
2025-08-28 05:12:27.191128: Epoch time: 17.34 s 
2025-08-28 05:12:28.057192:  
2025-08-28 05:12:28.065533: Epoch 500 
2025-08-28 05:12:28.069699: Current learning rate: 0.00536 
2025-08-28 05:12:44.690722: train_loss -0.4465 
2025-08-28 05:12:44.698816: val_loss -0.529 
2025-08-28 05:12:44.702989: Pseudo dice [np.float32(0.7484)] 
2025-08-28 05:12:44.712159: Epoch time: 16.64 s 
2025-08-28 05:12:45.361977:  
2025-08-28 05:12:45.370316: Epoch 501 
2025-08-28 05:12:45.374489: Current learning rate: 0.00535 
2025-08-28 05:13:02.283316: train_loss -0.4855 
2025-08-28 05:13:02.295610: val_loss -0.5043 
2025-08-28 05:13:02.299726: Pseudo dice [np.float32(0.7565)] 
2025-08-28 05:13:02.308830: Epoch time: 16.92 s 
2025-08-28 05:13:02.950372:  
2025-08-28 05:13:02.958717: Epoch 502 
2025-08-28 05:13:02.962824: Current learning rate: 0.00534 
2025-08-28 05:13:19.784247: train_loss -0.4387 
2025-08-28 05:13:19.792499: val_loss -0.506 
2025-08-28 05:13:19.796350: Pseudo dice [np.float32(0.7502)] 
2025-08-28 05:13:19.805578: Epoch time: 16.83 s 
2025-08-28 05:13:20.651401:  
2025-08-28 05:13:20.660119: Epoch 503 
2025-08-28 05:13:20.668075: Current learning rate: 0.00533 
2025-08-28 05:13:38.490441: train_loss -0.4501 
2025-08-28 05:13:38.498399: val_loss -0.4859 
2025-08-28 05:13:38.502531: Pseudo dice [np.float32(0.7583)] 
2025-08-28 05:13:38.511701: Epoch time: 17.84 s 
2025-08-28 05:13:39.161542:  
2025-08-28 05:13:39.170237: Epoch 504 
2025-08-28 05:13:39.174048: Current learning rate: 0.00532 
2025-08-28 05:13:55.878435: train_loss -0.4603 
2025-08-28 05:13:55.890962: val_loss -0.5674 
2025-08-28 05:13:55.895170: Pseudo dice [np.float32(0.7711)] 
2025-08-28 05:13:55.903965: Epoch time: 16.72 s 
2025-08-28 05:13:56.608118:  
2025-08-28 05:13:56.616462: Epoch 505 
2025-08-28 05:13:56.620648: Current learning rate: 0.00531 
2025-08-28 05:14:13.462414: train_loss -0.4676 
2025-08-28 05:14:13.470796: val_loss -0.4379 
2025-08-28 05:14:13.479121: Pseudo dice [np.float32(0.6932)] 
2025-08-28 05:14:13.485428: Epoch time: 16.85 s 
2025-08-28 05:14:14.296324:  
2025-08-28 05:14:14.305277: Epoch 506 
2025-08-28 05:14:14.309122: Current learning rate: 0.0053 
2025-08-28 05:14:32.252028: train_loss -0.426 
2025-08-28 05:14:32.260422: val_loss -0.5127 
2025-08-28 05:14:32.264530: Pseudo dice [np.float32(0.7636)] 
2025-08-28 05:14:32.273829: Epoch time: 17.96 s 
2025-08-28 05:14:32.911020:  
2025-08-28 05:14:32.919483: Epoch 507 
2025-08-28 05:14:32.923552: Current learning rate: 0.00529 
2025-08-28 05:14:49.752860: train_loss -0.4345 
2025-08-28 05:14:49.765359: val_loss -0.4637 
2025-08-28 05:14:49.769536: Pseudo dice [np.float32(0.6835)] 
2025-08-28 05:14:49.777776: Epoch time: 16.85 s 
2025-08-28 05:14:50.437287:  
2025-08-28 05:14:50.445207: Epoch 508 
2025-08-28 05:14:50.449770: Current learning rate: 0.00528 
2025-08-28 05:15:07.074347: train_loss -0.4433 
2025-08-28 05:15:07.082940: val_loss -0.4613 
2025-08-28 05:15:07.091066: Pseudo dice [np.float32(0.7935)] 
2025-08-28 05:15:07.096646: Epoch time: 16.64 s 
2025-08-28 05:15:07.729123:  
2025-08-28 05:15:07.737467: Epoch 509 
2025-08-28 05:15:07.741651: Current learning rate: 0.00527 
2025-08-28 05:15:25.292589: train_loss -0.4745 
2025-08-28 05:15:25.300875: val_loss -0.5552 
2025-08-28 05:15:25.309571: Pseudo dice [np.float32(0.7479)] 
2025-08-28 05:15:25.314653: Epoch time: 17.56 s 
2025-08-28 05:15:26.089194:  
2025-08-28 05:15:26.097336: Epoch 510 
2025-08-28 05:15:26.101772: Current learning rate: 0.00526 
2025-08-28 05:15:43.281290: train_loss -0.4233 
2025-08-28 05:15:43.290021: val_loss -0.5361 
2025-08-28 05:15:43.294199: Pseudo dice [np.float32(0.782)] 
2025-08-28 05:15:43.302906: Epoch time: 17.2 s 
2025-08-28 05:15:43.948695:  
2025-08-28 05:15:43.957039: Epoch 511 
2025-08-28 05:15:43.961167: Current learning rate: 0.00525 
2025-08-28 05:16:00.853209: train_loss -0.4682 
2025-08-28 05:16:00.865581: val_loss -0.4767 
2025-08-28 05:16:00.869747: Pseudo dice [np.float32(0.754)] 
2025-08-28 05:16:00.878572: Epoch time: 16.9 s 
2025-08-28 05:16:01.524544:  
2025-08-28 05:16:01.532899: Epoch 512 
2025-08-28 05:16:01.537117: Current learning rate: 0.00524 
2025-08-28 05:16:19.671835: train_loss -0.4269 
2025-08-28 05:16:19.680147: val_loss -0.4714 
2025-08-28 05:16:19.684326: Pseudo dice [np.float32(0.7292)] 
2025-08-28 05:16:19.693087: Epoch time: 18.15 s 
2025-08-28 05:16:20.576903:  
2025-08-28 05:16:20.581397: Epoch 513 
2025-08-28 05:16:20.589390: Current learning rate: 0.00523 
2025-08-28 05:16:37.690149: train_loss -0.4381 
2025-08-28 05:16:37.698176: val_loss -0.4626 
2025-08-28 05:16:37.702348: Pseudo dice [np.float32(0.7843)] 
2025-08-28 05:16:37.711543: Epoch time: 17.12 s 
2025-08-28 05:16:38.357472:  
2025-08-28 05:16:38.365473: Epoch 514 
2025-08-28 05:16:38.369675: Current learning rate: 0.00522 
2025-08-28 05:16:55.461747: train_loss -0.4688 
2025-08-28 05:16:55.474241: val_loss -0.4009 
2025-08-28 05:16:55.478404: Pseudo dice [np.float32(0.7114)] 
2025-08-28 05:16:55.487235: Epoch time: 17.1 s 
2025-08-28 05:16:56.216665:  
2025-08-28 05:16:56.221145: Epoch 515 
2025-08-28 05:16:56.229139: Current learning rate: 0.00521 
2025-08-28 05:17:13.421291: train_loss -0.4669 
2025-08-28 05:17:13.429657: val_loss -0.5519 
2025-08-28 05:17:13.433817: Pseudo dice [np.float32(0.7996)] 
2025-08-28 05:17:13.440937: Epoch time: 17.21 s 
2025-08-28 05:17:14.084826:  
2025-08-28 05:17:14.093175: Epoch 516 
2025-08-28 05:17:14.097487: Current learning rate: 0.0052 
2025-08-28 05:17:30.725931: train_loss -0.4941 
2025-08-28 05:17:30.734563: val_loss -0.4969 
2025-08-28 05:17:30.738941: Pseudo dice [np.float32(0.7396)] 
2025-08-28 05:17:30.745327: Epoch time: 16.64 s 
2025-08-28 05:17:31.397586:  
2025-08-28 05:17:31.405936: Epoch 517 
2025-08-28 05:17:31.410094: Current learning rate: 0.00519 
2025-08-28 05:17:48.289226: train_loss -0.4276 
2025-08-28 05:17:48.297820: val_loss -0.465 
2025-08-28 05:17:48.301992: Pseudo dice [np.float32(0.7799)] 
2025-08-28 05:17:48.309476: Epoch time: 16.89 s 
2025-08-28 05:17:49.023593:  
2025-08-28 05:17:49.032151: Epoch 518 
2025-08-28 05:17:49.039896: Current learning rate: 0.00518 
2025-08-28 05:18:06.853803: train_loss -0.4428 
2025-08-28 05:18:06.862470: val_loss -0.4757 
2025-08-28 05:18:06.870522: Pseudo dice [np.float32(0.7273)] 
2025-08-28 05:18:06.876658: Epoch time: 17.83 s 
2025-08-28 05:18:07.537865:  
2025-08-28 05:18:07.546215: Epoch 519 
2025-08-28 05:18:07.550380: Current learning rate: 0.00518 
2025-08-28 05:18:24.755979: train_loss -0.4375 
2025-08-28 05:18:24.763715: val_loss -0.5223 
2025-08-28 05:18:24.771605: Pseudo dice [np.float32(0.7885)] 
2025-08-28 05:18:24.777793: Epoch time: 17.22 s 
2025-08-28 05:18:25.576689:  
2025-08-28 05:18:25.585037: Epoch 520 
2025-08-28 05:18:25.593391: Current learning rate: 0.00517 
2025-08-28 05:18:42.598186: train_loss -0.4267 
2025-08-28 05:18:42.606231: val_loss -0.5198 
2025-08-28 05:18:42.614990: Pseudo dice [np.float32(0.7322)] 
2025-08-28 05:18:42.620275: Epoch time: 17.02 s 
2025-08-28 05:18:43.265193:  
2025-08-28 05:18:43.273563: Epoch 521 
2025-08-28 05:18:43.278008: Current learning rate: 0.00516 
2025-08-28 05:19:00.678726: train_loss -0.461 
2025-08-28 05:19:00.691006: val_loss -0.5126 
2025-08-28 05:19:00.695749: Pseudo dice [np.float32(0.7405)] 
2025-08-28 05:19:00.703530: Epoch time: 17.41 s 
2025-08-28 05:19:01.429171:  
2025-08-28 05:19:01.437351: Epoch 522 
2025-08-28 05:19:01.441738: Current learning rate: 0.00515 
2025-08-28 05:19:18.083327: train_loss -0.4756 
2025-08-28 05:19:18.091704: val_loss -0.5488 
2025-08-28 05:19:18.099745: Pseudo dice [np.float32(0.774)] 
2025-08-28 05:19:18.104154: Epoch time: 16.66 s 
2025-08-28 05:19:18.759253:  
2025-08-28 05:19:18.767347: Epoch 523 
2025-08-28 05:19:18.771484: Current learning rate: 0.00514 
2025-08-28 05:19:35.063468: train_loss -0.5066 
2025-08-28 05:19:35.071211: val_loss -0.4966 
2025-08-28 05:19:35.079725: Pseudo dice [np.float32(0.7947)] 
2025-08-28 05:19:35.084969: Epoch time: 16.3 s 
2025-08-28 05:19:35.088712: Yayy! New best EMA pseudo Dice: 0.7585999965667725 
2025-08-28 05:19:35.909693:  
2025-08-28 05:19:35.917484: Epoch 524 
2025-08-28 05:19:35.921953: Current learning rate: 0.00513 
2025-08-28 05:19:52.851350: train_loss -0.4465 
2025-08-28 05:19:52.863803: val_loss -0.436 
2025-08-28 05:19:52.868047: Pseudo dice [np.float32(0.6408)] 
2025-08-28 05:19:52.874431: Epoch time: 16.95 s 
2025-08-28 05:19:53.602103:  
2025-08-28 05:19:53.610524: Epoch 525 
2025-08-28 05:19:53.614778: Current learning rate: 0.00512 
2025-08-28 05:20:10.502343: train_loss -0.4677 
2025-08-28 05:20:10.510766: val_loss -0.4874 
2025-08-28 05:20:10.514838: Pseudo dice [np.float32(0.7271)] 
2025-08-28 05:20:10.523078: Epoch time: 16.9 s 
2025-08-28 05:20:11.328135:  
2025-08-28 05:20:11.336740: Epoch 526 
2025-08-28 05:20:11.343110: Current learning rate: 0.00511 
2025-08-28 05:20:27.932242: train_loss -0.4424 
2025-08-28 05:20:27.944708: val_loss -0.4728 
2025-08-28 05:20:27.949092: Pseudo dice [np.float32(0.7413)] 
2025-08-28 05:20:27.958189: Epoch time: 16.6 s 
2025-08-28 05:20:28.620385:  
2025-08-28 05:20:28.629111: Epoch 527 
2025-08-28 05:20:28.632920: Current learning rate: 0.0051 
2025-08-28 05:20:45.567433: train_loss -0.4645 
2025-08-28 05:20:45.574908: val_loss -0.4521 
2025-08-28 05:20:45.582899: Pseudo dice [np.float32(0.7389)] 
2025-08-28 05:20:45.588279: Epoch time: 16.95 s 
2025-08-28 05:20:46.305071:  
2025-08-28 05:20:46.313071: Epoch 528 
2025-08-28 05:20:46.321443: Current learning rate: 0.00509 
2025-08-28 05:21:03.376269: train_loss -0.4835 
2025-08-28 05:21:03.388790: val_loss -0.4835 
2025-08-28 05:21:03.392629: Pseudo dice [np.float32(0.7213)] 
2025-08-28 05:21:03.399822: Epoch time: 17.07 s 
2025-08-28 05:21:04.109987:  
2025-08-28 05:21:04.114204: Epoch 529 
2025-08-28 05:21:04.122406: Current learning rate: 0.00508 
2025-08-28 05:21:20.605820: train_loss -0.4552 
2025-08-28 05:21:20.613977: val_loss -0.4766 
2025-08-28 05:21:20.618152: Pseudo dice [np.float32(0.7236)] 
2025-08-28 05:21:20.627485: Epoch time: 16.5 s 
2025-08-28 05:21:21.273171:  
2025-08-28 05:21:21.281338: Epoch 530 
2025-08-28 05:21:21.285682: Current learning rate: 0.00507 
2025-08-28 05:21:37.710232: train_loss -0.4336 
2025-08-28 05:21:37.718801: val_loss -0.4505 
2025-08-28 05:21:37.722726: Pseudo dice [np.float32(0.7137)] 
2025-08-28 05:21:37.732300: Epoch time: 16.44 s 
2025-08-28 05:21:38.490228:  
2025-08-28 05:21:38.498583: Epoch 531 
2025-08-28 05:21:38.502756: Current learning rate: 0.00506 
2025-08-28 05:21:55.757381: train_loss -0.467 
2025-08-28 05:21:55.765735: val_loss -0.5406 
2025-08-28 05:21:55.774105: Pseudo dice [np.float32(0.7987)] 
2025-08-28 05:21:55.780389: Epoch time: 17.27 s 
2025-08-28 05:21:56.441426:  
2025-08-28 05:21:56.449807: Epoch 532 
2025-08-28 05:21:56.454142: Current learning rate: 0.00505 
2025-08-28 05:22:13.341597: train_loss -0.4573 
2025-08-28 05:22:13.350698: val_loss -0.4901 
2025-08-28 05:22:13.356130: Pseudo dice [np.float32(0.7177)] 
2025-08-28 05:22:13.361311: Epoch time: 16.9 s 
2025-08-28 05:22:14.175792:  
2025-08-28 05:22:14.184467: Epoch 533 
2025-08-28 05:22:14.192523: Current learning rate: 0.00504 
2025-08-28 05:22:31.105270: train_loss -0.478 
2025-08-28 05:22:31.113827: val_loss -0.4581 
2025-08-28 05:22:31.118053: Pseudo dice [np.float32(0.6911)] 
2025-08-28 05:22:31.126239: Epoch time: 16.93 s 
2025-08-28 05:22:31.914379:  
2025-08-28 05:22:31.918532: Epoch 534 
2025-08-28 05:22:31.927185: Current learning rate: 0.00503 
2025-08-28 05:22:49.423513: train_loss -0.4576 
2025-08-28 05:22:49.436013: val_loss -0.429 
2025-08-28 05:22:49.440177: Pseudo dice [np.float32(0.7272)] 
2025-08-28 05:22:49.449346: Epoch time: 17.51 s 
2025-08-28 05:22:50.103400:  
2025-08-28 05:22:50.107519: Epoch 535 
2025-08-28 05:22:50.115894: Current learning rate: 0.00502 
2025-08-28 05:23:06.854232: train_loss -0.4702 
2025-08-28 05:23:06.861746: val_loss -0.4183 
2025-08-28 05:23:06.865910: Pseudo dice [np.float32(0.6934)] 
2025-08-28 05:23:06.875555: Epoch time: 16.75 s 
2025-08-28 05:23:07.658396:  
2025-08-28 05:23:07.666847: Epoch 536 
2025-08-28 05:23:07.674803: Current learning rate: 0.00501 
2025-08-28 05:23:24.379210: train_loss -0.4565 
2025-08-28 05:23:24.387569: val_loss -0.419 
2025-08-28 05:23:24.391751: Pseudo dice [np.float32(0.7954)] 
2025-08-28 05:23:24.400892: Epoch time: 16.72 s 
2025-08-28 05:23:25.046567:  
2025-08-28 05:23:25.055263: Epoch 537 
2025-08-28 05:23:25.059078: Current learning rate: 0.005 
2025-08-28 05:23:42.860197: train_loss -0.4889 
2025-08-28 05:23:42.868828: val_loss -0.44 
2025-08-28 05:23:42.872948: Pseudo dice [np.float32(0.7088)] 
2025-08-28 05:23:42.879897: Epoch time: 17.81 s 
2025-08-28 05:23:43.640119:  
2025-08-28 05:23:43.648479: Epoch 538 
2025-08-28 05:23:43.652677: Current learning rate: 0.00499 
2025-08-28 05:24:00.081740: train_loss -0.4596 
2025-08-28 05:24:00.094443: val_loss -0.53 
2025-08-28 05:24:00.098266: Pseudo dice [np.float32(0.7789)] 
2025-08-28 05:24:00.106549: Epoch time: 16.44 s 
2025-08-28 05:24:00.761393:  
2025-08-28 05:24:00.769831: Epoch 539 
2025-08-28 05:24:00.773933: Current learning rate: 0.00498 
2025-08-28 05:24:16.881650: train_loss -0.4745 
2025-08-28 05:24:16.890399: val_loss -0.4872 
2025-08-28 05:24:16.894448: Pseudo dice [np.float32(0.7406)] 
2025-08-28 05:24:16.901634: Epoch time: 16.12 s 
2025-08-28 05:24:17.709612:  
2025-08-28 05:24:17.715812: Epoch 540 
2025-08-28 05:24:17.720348: Current learning rate: 0.00497 
2025-08-28 05:24:34.491026: train_loss -0.4454 
2025-08-28 05:24:34.499236: val_loss -0.5294 
2025-08-28 05:24:34.507593: Pseudo dice [np.float32(0.788)] 
2025-08-28 05:24:34.513120: Epoch time: 16.78 s 
2025-08-28 05:24:35.266674:  
2025-08-28 05:24:35.275057: Epoch 541 
2025-08-28 05:24:35.279201: Current learning rate: 0.00496 
2025-08-28 05:24:51.970863: train_loss -0.449 
2025-08-28 05:24:51.979200: val_loss -0.4248 
2025-08-28 05:24:51.987546: Pseudo dice [np.float32(0.6825)] 
2025-08-28 05:24:51.992398: Epoch time: 16.71 s 
2025-08-28 05:24:52.721927:  
2025-08-28 05:24:52.729950: Epoch 542 
2025-08-28 05:24:52.738377: Current learning rate: 0.00495 
2025-08-28 05:25:09.096610: train_loss -0.4735 
2025-08-28 05:25:09.104628: val_loss -0.5323 
2025-08-28 05:25:09.112980: Pseudo dice [np.float32(0.711)] 
2025-08-28 05:25:09.118366: Epoch time: 16.37 s 
2025-08-28 05:25:09.767875:  
2025-08-28 05:25:09.776262: Epoch 543 
2025-08-28 05:25:09.784733: Current learning rate: 0.00494 
2025-08-28 05:25:26.125903: train_loss -0.4369 
2025-08-28 05:25:26.134532: val_loss -0.4253 
2025-08-28 05:25:26.138307: Pseudo dice [np.float32(0.7734)] 
2025-08-28 05:25:26.145977: Epoch time: 16.36 s 
2025-08-28 05:25:26.793113:  
2025-08-28 05:25:26.801493: Epoch 544 
2025-08-28 05:25:26.805675: Current learning rate: 0.00493 
2025-08-28 05:25:44.252206: train_loss -0.4568 
2025-08-28 05:25:44.260612: val_loss -0.5144 
2025-08-28 05:25:44.265044: Pseudo dice [np.float32(0.7973)] 
2025-08-28 05:25:44.273912: Epoch time: 17.46 s 
2025-08-28 05:25:44.919807:  
2025-08-28 05:25:44.927912: Epoch 545 
2025-08-28 05:25:44.932272: Current learning rate: 0.00492 
2025-08-28 05:26:01.444417: train_loss -0.429 
2025-08-28 05:26:01.457095: val_loss -0.4999 
2025-08-28 05:26:01.461114: Pseudo dice [np.float32(0.8145)] 
2025-08-28 05:26:01.468492: Epoch time: 16.52 s 
2025-08-28 05:26:02.266118:  
2025-08-28 05:26:02.274435: Epoch 546 
2025-08-28 05:26:02.278843: Current learning rate: 0.00491 
2025-08-28 05:26:18.490365: train_loss -0.4663 
2025-08-28 05:26:18.499001: val_loss -0.4427 
2025-08-28 05:26:18.503090: Pseudo dice [np.float32(0.7488)] 
2025-08-28 05:26:18.511429: Epoch time: 16.22 s 
2025-08-28 05:26:19.166266:  
2025-08-28 05:26:19.174644: Epoch 547 
2025-08-28 05:26:19.179163: Current learning rate: 0.0049 
2025-08-28 05:26:36.291701: train_loss -0.4739 
2025-08-28 05:26:36.300070: val_loss -0.474 
2025-08-28 05:26:36.304456: Pseudo dice [np.float32(0.7419)] 
2025-08-28 05:26:36.313447: Epoch time: 17.13 s 
2025-08-28 05:26:37.111949:  
2025-08-28 05:26:37.117857: Epoch 548 
2025-08-28 05:26:37.121634: Current learning rate: 0.00489 
2025-08-28 05:26:53.159633: train_loss -0.4577 
2025-08-28 05:26:53.171054: val_loss -0.4556 
2025-08-28 05:26:53.179409: Pseudo dice [np.float32(0.7486)] 
2025-08-28 05:26:53.184909: Epoch time: 16.05 s 
2025-08-28 05:26:53.830237:  
2025-08-28 05:26:53.836332: Epoch 549 
2025-08-28 05:26:53.844075: Current learning rate: 0.00488 
2025-08-28 05:27:09.416739: train_loss -0.4737 
2025-08-28 05:27:09.424781: val_loss -0.4899 
2025-08-28 05:27:09.433112: Pseudo dice [np.float32(0.766)] 
2025-08-28 05:27:09.438606: Epoch time: 15.59 s 
2025-08-28 05:27:10.259160:  
2025-08-28 05:27:10.267326: Epoch 550 
2025-08-28 05:27:10.271842: Current learning rate: 0.00487 
2025-08-28 05:27:26.425368: train_loss -0.4768 
2025-08-28 05:27:26.433477: val_loss -0.5326 
2025-08-28 05:27:26.442168: Pseudo dice [np.float32(0.7625)] 
2025-08-28 05:27:26.447232: Epoch time: 16.17 s 
2025-08-28 05:27:27.109085:  
2025-08-28 05:27:27.117435: Epoch 551 
2025-08-28 05:27:27.126143: Current learning rate: 0.00486 
2025-08-28 05:27:44.689251: train_loss -0.477 
2025-08-28 05:27:44.697502: val_loss -0.4441 
2025-08-28 05:27:44.701869: Pseudo dice [np.float32(0.692)] 
2025-08-28 05:27:44.710035: Epoch time: 17.58 s 
2025-08-28 05:27:45.364825:  
2025-08-28 05:27:45.373354: Epoch 552 
2025-08-28 05:27:45.377347: Current learning rate: 0.00485 
2025-08-28 05:28:01.639390: train_loss -0.4656 
2025-08-28 05:28:01.651958: val_loss -0.4348 
2025-08-28 05:28:01.656101: Pseudo dice [np.float32(0.7407)] 
2025-08-28 05:28:01.664296: Epoch time: 16.27 s 
2025-08-28 05:28:02.481995:  
2025-08-28 05:28:02.490348: Epoch 553 
2025-08-28 05:28:02.494852: Current learning rate: 0.00484 
2025-08-28 05:28:18.845895: train_loss -0.464 
2025-08-28 05:28:18.852700: val_loss -0.4814 
2025-08-28 05:28:18.856648: Pseudo dice [np.float32(0.732)] 
2025-08-28 05:28:18.864976: Epoch time: 16.36 s 
2025-08-28 05:28:19.519756:  
2025-08-28 05:28:19.528111: Epoch 554 
2025-08-28 05:28:19.532282: Current learning rate: 0.00484 
2025-08-28 05:28:36.541806: train_loss -0.4463 
2025-08-28 05:28:36.549467: val_loss -0.4985 
2025-08-28 05:28:36.557905: Pseudo dice [np.float32(0.7664)] 
2025-08-28 05:28:36.563359: Epoch time: 17.02 s 
2025-08-28 05:28:37.358665:  
2025-08-28 05:28:37.366955: Epoch 555 
2025-08-28 05:28:37.371246: Current learning rate: 0.00483 
2025-08-28 05:28:53.695352: train_loss -0.4702 
2025-08-28 05:28:53.703938: val_loss -0.5594 
2025-08-28 05:28:53.708192: Pseudo dice [np.float32(0.7869)] 
2025-08-28 05:28:53.717298: Epoch time: 16.34 s 
2025-08-28 05:28:54.371203:  
2025-08-28 05:28:54.375396: Epoch 556 
2025-08-28 05:28:54.383763: Current learning rate: 0.00482 
2025-08-28 05:29:11.012851: train_loss -0.4681 
2025-08-28 05:29:11.021181: val_loss -0.4828 
2025-08-28 05:29:11.025373: Pseudo dice [np.float32(0.7593)] 
2025-08-28 05:29:11.034545: Epoch time: 16.65 s 
2025-08-28 05:29:11.680179:  
2025-08-28 05:29:11.688568: Epoch 557 
2025-08-28 05:29:11.692704: Current learning rate: 0.00481 
2025-08-28 05:29:28.759778: train_loss -0.4587 
2025-08-28 05:29:28.768103: val_loss -0.5337 
2025-08-28 05:29:28.772259: Pseudo dice [np.float32(0.7719)] 
2025-08-28 05:29:28.780750: Epoch time: 17.08 s 
2025-08-28 05:29:29.523043:  
2025-08-28 05:29:29.531449: Epoch 558 
2025-08-28 05:29:29.535794: Current learning rate: 0.0048 
2025-08-28 05:29:45.935213: train_loss -0.4702 
2025-08-28 05:29:45.943780: val_loss -0.4882 
2025-08-28 05:29:45.947814: Pseudo dice [np.float32(0.7311)] 
2025-08-28 05:29:45.956891: Epoch time: 16.42 s 
2025-08-28 05:29:46.615052:  
2025-08-28 05:29:46.619226: Epoch 559 
2025-08-28 05:29:46.627627: Current learning rate: 0.00479 
2025-08-28 05:30:02.852110: train_loss -0.4411 
2025-08-28 05:30:02.864623: val_loss -0.513 
2025-08-28 05:30:02.868800: Pseudo dice [np.float32(0.7357)] 
2025-08-28 05:30:02.876186: Epoch time: 16.24 s 
2025-08-28 05:30:03.682147:  
2025-08-28 05:30:03.690486: Epoch 560 
2025-08-28 05:30:03.694634: Current learning rate: 0.00478 
2025-08-28 05:30:20.835738: train_loss -0.4725 
2025-08-28 05:30:20.845459: val_loss -0.4621 
2025-08-28 05:30:20.849501: Pseudo dice [np.float32(0.7498)] 
2025-08-28 05:30:20.857503: Epoch time: 17.16 s 
2025-08-28 05:30:21.504369:  
2025-08-28 05:30:21.512451: Epoch 561 
2025-08-28 05:30:21.516917: Current learning rate: 0.00477 
2025-08-28 05:30:38.033057: train_loss -0.4718 
2025-08-28 05:30:38.041825: val_loss -0.4838 
2025-08-28 05:30:38.049778: Pseudo dice [np.float32(0.8106)] 
2025-08-28 05:30:38.054809: Epoch time: 16.53 s 
2025-08-28 05:30:38.704576:  
2025-08-28 05:30:38.708758: Epoch 562 
2025-08-28 05:30:38.717424: Current learning rate: 0.00476 
2025-08-28 05:30:55.246088: train_loss -0.4389 
2025-08-28 05:30:55.258629: val_loss -0.4408 
2025-08-28 05:30:55.263091: Pseudo dice [np.float32(0.6854)] 
2025-08-28 05:30:55.270132: Epoch time: 16.55 s 
2025-08-28 05:30:55.917660:  
2025-08-28 05:30:55.926020: Epoch 563 
2025-08-28 05:30:55.934321: Current learning rate: 0.00475 
2025-08-28 05:31:13.218264: train_loss -0.4898 
2025-08-28 05:31:13.230471: val_loss -0.4434 
2025-08-28 05:31:13.234990: Pseudo dice [np.float32(0.6865)] 
2025-08-28 05:31:13.242198: Epoch time: 17.3 s 
2025-08-28 05:31:13.885535:  
2025-08-28 05:31:13.890094: Epoch 564 
2025-08-28 05:31:13.898082: Current learning rate: 0.00474 
2025-08-28 05:31:30.673134: train_loss -0.4286 
2025-08-28 05:31:30.681520: val_loss -0.5238 
2025-08-28 05:31:30.686045: Pseudo dice [np.float32(0.7532)] 
2025-08-28 05:31:30.692904: Epoch time: 16.79 s 
2025-08-28 05:31:31.352962:  
2025-08-28 05:31:31.357190: Epoch 565 
2025-08-28 05:31:31.365876: Current learning rate: 0.00473 
2025-08-28 05:31:47.741642: train_loss -0.4407 
2025-08-28 05:31:47.748834: val_loss -0.5246 
2025-08-28 05:31:47.756858: Pseudo dice [np.float32(0.778)] 
2025-08-28 05:31:47.763314: Epoch time: 16.39 s 
2025-08-28 05:31:48.495082:  
2025-08-28 05:31:48.499277: Epoch 566 
2025-08-28 05:31:48.508120: Current learning rate: 0.00472 
2025-08-28 05:32:05.875125: train_loss -0.456 
2025-08-28 05:32:05.883650: val_loss -0.4569 
2025-08-28 05:32:05.891615: Pseudo dice [np.float32(0.7376)] 
2025-08-28 05:32:05.897346: Epoch time: 17.38 s 
2025-08-28 05:32:06.700753:  
2025-08-28 05:32:06.709147: Epoch 567 
2025-08-28 05:32:06.713682: Current learning rate: 0.00471 
2025-08-28 05:32:22.712563: train_loss -0.4461 
2025-08-28 05:32:22.720935: val_loss -0.4465 
2025-08-28 05:32:22.725607: Pseudo dice [np.float32(0.7139)] 
2025-08-28 05:32:22.733646: Epoch time: 16.01 s 
2025-08-28 05:32:23.404949:  
2025-08-28 05:32:23.413327: Epoch 568 
2025-08-28 05:32:23.417871: Current learning rate: 0.0047 
2025-08-28 05:32:39.479597: train_loss -0.5046 
2025-08-28 05:32:39.492183: val_loss -0.4478 
2025-08-28 05:32:39.499255: Pseudo dice [np.float32(0.6815)] 
2025-08-28 05:32:39.505539: Epoch time: 16.07 s 
2025-08-28 05:32:40.205578:  
2025-08-28 05:32:40.213705: Epoch 569 
2025-08-28 05:32:40.217874: Current learning rate: 0.00469 
2025-08-28 05:32:57.576554: train_loss -0.4821 
2025-08-28 05:32:57.584894: val_loss -0.4909 
2025-08-28 05:32:57.593276: Pseudo dice [np.float32(0.7198)] 
2025-08-28 05:32:57.599409: Epoch time: 17.37 s 
2025-08-28 05:32:58.273313:  
2025-08-28 05:32:58.277309: Epoch 570 
2025-08-28 05:32:58.286011: Current learning rate: 0.00468 
2025-08-28 05:33:14.539660: train_loss -0.5 
2025-08-28 05:33:14.547937: val_loss -0.4873 
2025-08-28 05:33:14.557622: Pseudo dice [np.float32(0.7863)] 
2025-08-28 05:33:14.562250: Epoch time: 16.27 s 
2025-08-28 05:33:15.206650:  
2025-08-28 05:33:15.215092: Epoch 571 
2025-08-28 05:33:15.219198: Current learning rate: 0.00467 
2025-08-28 05:33:31.915458: train_loss -0.4689 
2025-08-28 05:33:31.923380: val_loss -0.5085 
2025-08-28 05:33:31.927543: Pseudo dice [np.float32(0.7582)] 
2025-08-28 05:33:31.936591: Epoch time: 16.71 s 
2025-08-28 05:33:32.582385:  
2025-08-28 05:33:32.590689: Epoch 572 
2025-08-28 05:33:32.594861: Current learning rate: 0.00466 
2025-08-28 05:33:49.779505: train_loss -0.4558 
2025-08-28 05:33:49.791399: val_loss -0.5288 
2025-08-28 05:33:49.799306: Pseudo dice [np.float32(0.7545)] 
2025-08-28 05:33:49.805086: Epoch time: 17.2 s 
2025-08-28 05:33:50.525275:  
2025-08-28 05:33:50.533660: Epoch 573 
2025-08-28 05:33:50.541973: Current learning rate: 0.00465 
2025-08-28 05:34:06.775143: train_loss -0.4383 
2025-08-28 05:34:06.783415: val_loss -0.4984 
2025-08-28 05:34:06.787336: Pseudo dice [np.float32(0.7159)] 
2025-08-28 05:34:06.796530: Epoch time: 16.25 s 
2025-08-28 05:34:07.608974:  
2025-08-28 05:34:07.619606: Epoch 574 
2025-08-28 05:34:07.626467: Current learning rate: 0.00464 
2025-08-28 05:34:23.730026: train_loss -0.4887 
2025-08-28 05:34:23.737917: val_loss -0.5328 
2025-08-28 05:34:23.742076: Pseudo dice [np.float32(0.7689)] 
2025-08-28 05:34:23.751013: Epoch time: 16.12 s 
2025-08-28 05:34:24.400788:  
2025-08-28 05:34:24.413271: Epoch 575 
2025-08-28 05:34:24.417426: Current learning rate: 0.00463 
2025-08-28 05:34:41.647616: train_loss -0.4564 
2025-08-28 05:34:41.655810: val_loss -0.5826 
2025-08-28 05:34:41.660025: Pseudo dice [np.float32(0.7909)] 
2025-08-28 05:34:41.669007: Epoch time: 17.25 s 
2025-08-28 05:34:42.447944:  
2025-08-28 05:34:42.456284: Epoch 576 
2025-08-28 05:34:42.460453: Current learning rate: 0.00462 
2025-08-28 05:34:59.607260: train_loss -0.4953 
2025-08-28 05:34:59.619671: val_loss -0.5332 
2025-08-28 05:34:59.627995: Pseudo dice [np.float32(0.7747)] 
2025-08-28 05:34:59.633358: Epoch time: 17.16 s 
2025-08-28 05:35:00.290737:  
2025-08-28 05:35:00.299081: Epoch 577 
2025-08-28 05:35:00.303270: Current learning rate: 0.00461 
2025-08-28 05:35:17.165998: train_loss -0.4619 
2025-08-28 05:35:17.174296: val_loss -0.5028 
2025-08-28 05:35:17.182672: Pseudo dice [np.float32(0.7622)] 
2025-08-28 05:35:17.188165: Epoch time: 16.88 s 
2025-08-28 05:35:17.858522:  
2025-08-28 05:35:17.866956: Epoch 578 
2025-08-28 05:35:17.870828: Current learning rate: 0.0046 
2025-08-28 05:35:34.929831: train_loss -0.4874 
2025-08-28 05:35:34.938199: val_loss -0.477 
2025-08-28 05:35:34.942130: Pseudo dice [np.float32(0.7154)] 
2025-08-28 05:35:34.951794: Epoch time: 17.08 s 
2025-08-28 05:35:35.659422:  
2025-08-28 05:35:35.667757: Epoch 579 
2025-08-28 05:35:35.676100: Current learning rate: 0.00459 
2025-08-28 05:35:52.664213: train_loss -0.4771 
2025-08-28 05:35:52.676726: val_loss -0.4655 
2025-08-28 05:35:52.680911: Pseudo dice [np.float32(0.6978)] 
2025-08-28 05:35:52.687810: Epoch time: 17.0 s 
2025-08-28 05:35:53.506697:  
2025-08-28 05:35:53.514811: Epoch 580 
2025-08-28 05:35:53.519003: Current learning rate: 0.00458 
2025-08-28 05:36:10.306836: train_loss -0.4697 
2025-08-28 05:36:10.315202: val_loss -0.4818 
2025-08-28 05:36:10.319021: Pseudo dice [np.float32(0.7144)] 
2025-08-28 05:36:10.327263: Epoch time: 16.8 s 
2025-08-28 05:36:10.990546:  
2025-08-28 05:36:10.998860: Epoch 581 
2025-08-28 05:36:11.003021: Current learning rate: 0.00457 
2025-08-28 05:36:28.508015: train_loss -0.492 
2025-08-28 05:36:28.520543: val_loss -0.5639 
2025-08-28 05:36:28.524697: Pseudo dice [np.float32(0.7721)] 
2025-08-28 05:36:28.531445: Epoch time: 17.52 s 
2025-08-28 05:36:29.179546:  
2025-08-28 05:36:29.187966: Epoch 582 
2025-08-28 05:36:29.192038: Current learning rate: 0.00456 
2025-08-28 05:36:46.150958: train_loss -0.4938 
2025-08-28 05:36:46.163245: val_loss -0.4358 
2025-08-28 05:36:46.171723: Pseudo dice [np.float32(0.7204)] 
2025-08-28 05:36:46.180836: Epoch time: 16.97 s 
2025-08-28 05:36:46.868029:  
2025-08-28 05:36:46.876699: Epoch 583 
2025-08-28 05:36:46.880559: Current learning rate: 0.00455 
2025-08-28 05:37:03.780810: train_loss -0.4435 
2025-08-28 05:37:03.789113: val_loss -0.4964 
2025-08-28 05:37:03.797419: Pseudo dice [np.float32(0.7316)] 
2025-08-28 05:37:03.803645: Epoch time: 16.91 s 
2025-08-28 05:37:04.452249:  
2025-08-28 05:37:04.460647: Epoch 584 
2025-08-28 05:37:04.464825: Current learning rate: 0.00454 
2025-08-28 05:37:22.362155: train_loss -0.4624 
2025-08-28 05:37:22.370476: val_loss -0.4916 
2025-08-28 05:37:22.374728: Pseudo dice [np.float32(0.7548)] 
2025-08-28 05:37:22.382890: Epoch time: 17.91 s 
2025-08-28 05:37:23.041618:  
2025-08-28 05:37:23.049980: Epoch 585 
2025-08-28 05:37:23.054189: Current learning rate: 0.00453 
2025-08-28 05:37:39.687626: train_loss -0.429 
2025-08-28 05:37:39.695767: val_loss -0.4455 
2025-08-28 05:37:39.700276: Pseudo dice [np.float32(0.7148)] 
2025-08-28 05:37:39.708309: Epoch time: 16.65 s 
2025-08-28 05:37:40.371444:  
2025-08-28 05:37:40.379797: Epoch 586 
2025-08-28 05:37:40.383952: Current learning rate: 0.00452 
2025-08-28 05:37:57.050659: train_loss -0.4512 
2025-08-28 05:37:57.071717: val_loss -0.5377 
2025-08-28 05:37:57.075727: Pseudo dice [np.float32(0.7471)] 
2025-08-28 05:37:57.083990: Epoch time: 16.68 s 
2025-08-28 05:37:57.918113:  
2025-08-28 05:37:57.926507: Epoch 587 
2025-08-28 05:37:57.930634: Current learning rate: 0.00451 
2025-08-28 05:38:15.244098: train_loss -0.4717 
2025-08-28 05:38:15.252391: val_loss -0.524 
2025-08-28 05:38:15.256275: Pseudo dice [np.float32(0.7219)] 
2025-08-28 05:38:15.265738: Epoch time: 17.33 s 
2025-08-28 05:38:16.011181:  
2025-08-28 05:38:16.019722: Epoch 588 
2025-08-28 05:38:16.023792: Current learning rate: 0.0045 
2025-08-28 05:38:33.265925: train_loss -0.4877 
2025-08-28 05:38:33.274252: val_loss -0.4387 
2025-08-28 05:38:33.282984: Pseudo dice [np.float32(0.7458)] 
2025-08-28 05:38:33.287483: Epoch time: 17.25 s 
2025-08-28 05:38:33.945807:  
2025-08-28 05:38:33.954142: Epoch 589 
2025-08-28 05:38:33.958277: Current learning rate: 0.00449 
2025-08-28 05:38:50.975263: train_loss -0.463 
2025-08-28 05:38:50.987825: val_loss -0.4904 
2025-08-28 05:38:50.991961: Pseudo dice [np.float32(0.767)] 
2025-08-28 05:38:51.000274: Epoch time: 17.03 s 
2025-08-28 05:38:51.675964:  
2025-08-28 05:38:51.684333: Epoch 590 
2025-08-28 05:38:51.688487: Current learning rate: 0.00448 
2025-08-28 05:39:08.755533: train_loss -0.4755 
2025-08-28 05:39:08.763866: val_loss -0.4872 
2025-08-28 05:39:08.768044: Pseudo dice [np.float32(0.7424)] 
2025-08-28 05:39:08.777341: Epoch time: 17.08 s 
2025-08-28 05:39:09.494116:  
2025-08-28 05:39:09.502135: Epoch 591 
2025-08-28 05:39:09.506603: Current learning rate: 0.00447 
2025-08-28 05:39:26.865771: train_loss -0.4827 
2025-08-28 05:39:26.874162: val_loss -0.5079 
2025-08-28 05:39:26.882004: Pseudo dice [np.float32(0.7108)] 
2025-08-28 05:39:26.887525: Epoch time: 17.37 s 
2025-08-28 05:39:27.549286:  
2025-08-28 05:39:27.557693: Epoch 592 
2025-08-28 05:39:27.561873: Current learning rate: 0.00446 
2025-08-28 05:39:44.629318: train_loss -0.4656 
2025-08-28 05:39:44.641366: val_loss -0.4971 
2025-08-28 05:39:44.645560: Pseudo dice [np.float32(0.7431)] 
2025-08-28 05:39:44.651757: Epoch time: 17.08 s 
2025-08-28 05:39:45.454825:  
2025-08-28 05:39:45.463049: Epoch 593 
2025-08-28 05:39:45.467544: Current learning rate: 0.00445 
2025-08-28 05:40:02.467801: train_loss -0.4835 
2025-08-28 05:40:02.480029: val_loss -0.4653 
2025-08-28 05:40:02.484186: Pseudo dice [np.float32(0.7993)] 
2025-08-28 05:40:02.491616: Epoch time: 17.02 s 
2025-08-28 05:40:03.272458:  
2025-08-28 05:40:03.281132: Epoch 594 
2025-08-28 05:40:03.284961: Current learning rate: 0.00444 
2025-08-28 05:40:20.681553: train_loss -0.4677 
2025-08-28 05:40:20.689864: val_loss -0.5078 
2025-08-28 05:40:20.698747: Pseudo dice [np.float32(0.7908)] 
2025-08-28 05:40:20.703990: Epoch time: 17.41 s 
2025-08-28 05:40:21.357191:  
2025-08-28 05:40:21.365540: Epoch 595 
2025-08-28 05:40:21.370036: Current learning rate: 0.00443 
2025-08-28 05:40:37.895506: train_loss -0.4858 
2025-08-28 05:40:37.902876: val_loss -0.5456 
2025-08-28 05:40:37.907044: Pseudo dice [np.float32(0.8314)] 
2025-08-28 05:40:37.916709: Epoch time: 16.54 s 
2025-08-28 05:40:38.566056:  
2025-08-28 05:40:38.574476: Epoch 596 
2025-08-28 05:40:38.578669: Current learning rate: 0.00442 
2025-08-28 05:40:55.416403: train_loss -0.477 
2025-08-28 05:40:55.424531: val_loss -0.5365 
2025-08-28 05:40:55.432887: Pseudo dice [np.float32(0.7919)] 
2025-08-28 05:40:55.439412: Epoch time: 16.85 s 
2025-08-28 05:40:55.445812: Yayy! New best EMA pseudo Dice: 0.7612000107765198 
2025-08-28 05:40:56.267135:  
2025-08-28 05:40:56.275508: Epoch 597 
2025-08-28 05:40:56.279650: Current learning rate: 0.00441 
2025-08-28 05:41:13.605168: train_loss -0.461 
2025-08-28 05:41:13.613548: val_loss -0.5315 
2025-08-28 05:41:13.617711: Pseudo dice [np.float32(0.7634)] 
2025-08-28 05:41:13.625340: Epoch time: 17.34 s 
2025-08-28 05:41:13.632597: Yayy! New best EMA pseudo Dice: 0.7615000009536743 
2025-08-28 05:41:14.589425:  
2025-08-28 05:41:14.593685: Epoch 598 
2025-08-28 05:41:14.602031: Current learning rate: 0.0044 
2025-08-28 05:41:31.056264: train_loss -0.4719 
2025-08-28 05:41:31.064624: val_loss -0.4358 
2025-08-28 05:41:31.068941: Pseudo dice [np.float32(0.6451)] 
2025-08-28 05:41:31.076937: Epoch time: 16.47 s 
2025-08-28 05:41:31.729945:  
2025-08-28 05:41:31.735805: Epoch 599 
2025-08-28 05:41:31.739914: Current learning rate: 0.00439 
2025-08-28 05:41:47.985625: train_loss -0.4614 
2025-08-28 05:41:47.993912: val_loss -0.5136 
2025-08-28 05:41:48.002038: Pseudo dice [np.float32(0.7213)] 
2025-08-28 05:41:48.008158: Epoch time: 16.26 s 
2025-08-28 05:41:48.978011:  
2025-08-28 05:41:48.982564: Epoch 600 
2025-08-28 05:41:48.990602: Current learning rate: 0.00438 
2025-08-28 05:42:05.515421: train_loss -0.4428 
2025-08-28 05:42:05.524055: val_loss -0.5836 
2025-08-28 05:42:05.532056: Pseudo dice [np.float32(0.7943)] 
2025-08-28 05:42:05.538530: Epoch time: 16.54 s 
2025-08-28 05:42:06.328671:  
2025-08-28 05:42:06.337011: Epoch 601 
2025-08-28 05:42:06.342695: Current learning rate: 0.00437 
2025-08-28 05:42:22.378281: train_loss -0.5 
2025-08-28 05:42:22.390853: val_loss -0.4966 
2025-08-28 05:42:22.394719: Pseudo dice [np.float32(0.7533)] 
2025-08-28 05:42:22.403805: Epoch time: 16.05 s 
2025-08-28 05:42:23.049530:  
2025-08-28 05:42:23.057905: Epoch 602 
2025-08-28 05:42:23.062043: Current learning rate: 0.00436 
2025-08-28 05:42:38.790243: train_loss -0.4808 
2025-08-28 05:42:38.798601: val_loss -0.4953 
2025-08-28 05:42:38.802738: Pseudo dice [np.float32(0.7972)] 
2025-08-28 05:42:38.811862: Epoch time: 15.74 s 
2025-08-28 05:42:39.465970:  
2025-08-28 05:42:39.474302: Epoch 603 
2025-08-28 05:42:39.478773: Current learning rate: 0.00435 
2025-08-28 05:42:55.094027: train_loss -0.4487 
2025-08-28 05:42:55.102681: val_loss -0.4826 
2025-08-28 05:42:55.108943: Pseudo dice [np.float32(0.7463)] 
2025-08-28 05:42:55.114753: Epoch time: 15.63 s 
2025-08-28 05:42:55.769698:  
2025-08-28 05:42:55.773816: Epoch 604 
2025-08-28 05:42:55.782636: Current learning rate: 0.00434 
2025-08-28 05:43:11.243544: train_loss -0.4954 
2025-08-28 05:43:11.254755: val_loss -0.509 
2025-08-28 05:43:11.260180: Pseudo dice [np.float32(0.7658)] 
2025-08-28 05:43:11.266495: Epoch time: 15.48 s 
2025-08-28 05:43:11.936110:  
2025-08-28 05:43:11.943950: Epoch 605 
2025-08-28 05:43:11.948749: Current learning rate: 0.00433 
2025-08-28 05:43:27.447500: train_loss -0.4833 
2025-08-28 05:43:27.455827: val_loss -0.5279 
2025-08-28 05:43:27.462108: Pseudo dice [np.float32(0.7725)] 
2025-08-28 05:43:27.468665: Epoch time: 15.52 s 
2025-08-28 05:43:28.143709:  
2025-08-28 05:43:28.152059: Epoch 606 
2025-08-28 05:43:28.156196: Current learning rate: 0.00432 
2025-08-28 05:43:44.623671: train_loss -0.4831 
2025-08-28 05:43:44.631008: val_loss -0.5021 
2025-08-28 05:43:44.639559: Pseudo dice [np.float32(0.7592)] 
2025-08-28 05:43:44.645861: Epoch time: 16.48 s 
2025-08-28 05:43:45.465183:  
2025-08-28 05:43:45.473490: Epoch 607 
2025-08-28 05:43:45.478082: Current learning rate: 0.00431 
2025-08-28 05:44:01.022726: train_loss -0.5009 
2025-08-28 05:44:01.030702: val_loss -0.467 
2025-08-28 05:44:01.039362: Pseudo dice [np.float32(0.7334)] 
2025-08-28 05:44:01.045302: Epoch time: 15.56 s 
2025-08-28 05:44:01.698102:  
2025-08-28 05:44:01.702494: Epoch 608 
2025-08-28 05:44:01.710550: Current learning rate: 0.0043 
2025-08-28 05:44:17.380719: train_loss -0.4962 
2025-08-28 05:44:17.389010: val_loss -0.5873 
2025-08-28 05:44:17.393255: Pseudo dice [np.float32(0.7706)] 
2025-08-28 05:44:17.399212: Epoch time: 15.69 s 
2025-08-28 05:44:18.106072:  
2025-08-28 05:44:18.114547: Epoch 609 
2025-08-28 05:44:18.118914: Current learning rate: 0.00429 
2025-08-28 05:44:34.831241: train_loss -0.4915 
2025-08-28 05:44:34.841893: val_loss -0.4741 
2025-08-28 05:44:34.848326: Pseudo dice [np.float32(0.6918)] 
2025-08-28 05:44:34.854006: Epoch time: 16.73 s 
2025-08-28 05:44:35.503894:  
2025-08-28 05:44:35.511247: Epoch 610 
2025-08-28 05:44:35.515338: Current learning rate: 0.00429 
2025-08-28 05:44:51.277214: train_loss -0.5064 
2025-08-28 05:44:51.289222: val_loss -0.5449 
2025-08-28 05:44:51.293387: Pseudo dice [np.float32(0.75)] 
2025-08-28 05:44:51.301637: Epoch time: 15.77 s 
2025-08-28 05:44:51.964900:  
2025-08-28 05:44:51.973259: Epoch 611 
2025-08-28 05:44:51.977427: Current learning rate: 0.00428 
2025-08-28 05:45:07.651583: train_loss -0.4742 
2025-08-28 05:45:07.659750: val_loss -0.5279 
2025-08-28 05:45:07.663906: Pseudo dice [np.float32(0.7557)] 
2025-08-28 05:45:07.672227: Epoch time: 15.69 s 
2025-08-28 05:45:08.327431:  
2025-08-28 05:45:08.337533: Epoch 612 
2025-08-28 05:45:08.343712: Current learning rate: 0.00427 
2025-08-28 05:45:24.689377: train_loss -0.5245 
2025-08-28 05:45:24.697886: val_loss -0.5072 
2025-08-28 05:45:24.701774: Pseudo dice [np.float32(0.7298)] 
2025-08-28 05:45:24.709103: Epoch time: 16.36 s 
2025-08-28 05:45:25.644365:  
2025-08-28 05:45:25.652733: Epoch 613 
2025-08-28 05:45:25.661064: Current learning rate: 0.00426 
2025-08-28 05:45:41.702064: train_loss -0.5095 
2025-08-28 05:45:41.714953: val_loss -0.5509 
2025-08-28 05:45:41.719245: Pseudo dice [np.float32(0.8014)] 
2025-08-28 05:45:41.727121: Epoch time: 16.06 s 
2025-08-28 05:45:42.390239:  
2025-08-28 05:45:42.398595: Epoch 614 
2025-08-28 05:45:42.402737: Current learning rate: 0.00425 
2025-08-28 05:45:57.889414: train_loss -0.4847 
2025-08-28 05:45:57.901566: val_loss -0.3502 
2025-08-28 05:45:57.905989: Pseudo dice [np.float32(0.6422)] 
2025-08-28 05:45:57.914923: Epoch time: 15.5 s 
2025-08-28 05:45:58.623134:  
2025-08-28 05:45:58.631492: Epoch 615 
2025-08-28 05:45:58.635628: Current learning rate: 0.00424 
2025-08-28 05:46:14.368339: train_loss -0.5083 
2025-08-28 05:46:14.376392: val_loss -0.5205 
2025-08-28 05:46:14.384700: Pseudo dice [np.float32(0.7388)] 
2025-08-28 05:46:14.390930: Epoch time: 15.75 s 
2025-08-28 05:46:15.062306:  
2025-08-28 05:46:15.066682: Epoch 616 
2025-08-28 05:46:15.073184: Current learning rate: 0.00423 
2025-08-28 05:46:31.601871: train_loss -0.4841 
2025-08-28 05:46:31.610230: val_loss -0.52 
2025-08-28 05:46:31.619253: Pseudo dice [np.float32(0.7218)] 
2025-08-28 05:46:31.624959: Epoch time: 16.54 s 
2025-08-28 05:46:32.369412:  
2025-08-28 05:46:32.377739: Epoch 617 
2025-08-28 05:46:32.381909: Current learning rate: 0.00422 
2025-08-28 05:46:48.310379: train_loss -0.5032 
2025-08-28 05:46:48.318584: val_loss -0.4701 
2025-08-28 05:46:48.326932: Pseudo dice [np.float32(0.6797)] 
2025-08-28 05:46:48.331935: Epoch time: 15.94 s 
2025-08-28 05:46:48.994304:  
2025-08-28 05:46:49.002976: Epoch 618 
2025-08-28 05:46:49.006738: Current learning rate: 0.00421 
2025-08-28 05:47:05.371780: train_loss -0.4692 
2025-08-28 05:47:05.381849: val_loss -0.4837 
2025-08-28 05:47:05.385951: Pseudo dice [np.float32(0.7412)] 
2025-08-28 05:47:05.394977: Epoch time: 16.38 s 
2025-08-28 05:47:06.181986:  
2025-08-28 05:47:06.186613: Epoch 619 
2025-08-28 05:47:06.194834: Current learning rate: 0.0042 
2025-08-28 05:47:22.163202: train_loss -0.4764 
2025-08-28 05:47:22.169058: val_loss -0.4914 
2025-08-28 05:47:22.177402: Pseudo dice [np.float32(0.6938)] 
2025-08-28 05:47:22.182962: Epoch time: 15.99 s 
2025-08-28 05:47:23.007381:  
2025-08-28 05:47:23.015730: Epoch 620 
2025-08-28 05:47:23.019929: Current learning rate: 0.00419 
2025-08-28 05:47:38.631332: train_loss -0.498 
2025-08-28 05:47:38.639668: val_loss -0.5334 
2025-08-28 05:47:38.643821: Pseudo dice [np.float32(0.7853)] 
2025-08-28 05:47:38.652972: Epoch time: 15.62 s 
2025-08-28 05:47:39.319794:  
2025-08-28 05:47:39.327867: Epoch 621 
2025-08-28 05:47:39.332274: Current learning rate: 0.00418 
2025-08-28 05:47:55.281611: train_loss -0.5066 
2025-08-28 05:47:55.289618: val_loss -0.5783 
2025-08-28 05:47:55.298272: Pseudo dice [np.float32(0.7818)] 
2025-08-28 05:47:55.304492: Epoch time: 15.97 s 
2025-08-28 05:47:55.965296:  
2025-08-28 05:47:55.973662: Epoch 622 
2025-08-28 05:47:55.981981: Current learning rate: 0.00417 
2025-08-28 05:48:11.393238: train_loss -0.4979 
2025-08-28 05:48:11.401544: val_loss -0.5431 
2025-08-28 05:48:11.405720: Pseudo dice [np.float32(0.8056)] 
2025-08-28 05:48:11.412850: Epoch time: 15.43 s 
2025-08-28 05:48:12.068847:  
2025-08-28 05:48:12.077229: Epoch 623 
2025-08-28 05:48:12.081406: Current learning rate: 0.00416 
2025-08-28 05:48:28.318407: train_loss -0.5128 
2025-08-28 05:48:28.330946: val_loss -0.5942 
2025-08-28 05:48:28.336677: Pseudo dice [np.float32(0.7969)] 
2025-08-28 05:48:28.342171: Epoch time: 16.25 s 
2025-08-28 05:48:29.173434:  
2025-08-28 05:48:29.185965: Epoch 624 
2025-08-28 05:48:29.190346: Current learning rate: 0.00415 
2025-08-28 05:48:46.240702: train_loss -0.5525 
2025-08-28 05:48:46.249174: val_loss -0.5269 
2025-08-28 05:48:46.253012: Pseudo dice [np.float32(0.743)] 
2025-08-28 05:48:46.261558: Epoch time: 17.07 s 
2025-08-28 05:48:46.924212:  
2025-08-28 05:48:46.928702: Epoch 625 
2025-08-28 05:48:46.932913: Current learning rate: 0.00414 
2025-08-28 05:49:02.631843: train_loss -0.5207 
2025-08-28 05:49:02.640279: val_loss -0.4655 
2025-08-28 05:49:02.644382: Pseudo dice [np.float32(0.7621)] 
2025-08-28 05:49:02.652645: Epoch time: 15.71 s 
2025-08-28 05:49:03.462190:  
2025-08-28 05:49:03.470222: Epoch 626 
2025-08-28 05:49:03.474667: Current learning rate: 0.00413 
2025-08-28 05:49:19.211289: train_loss -0.5319 
2025-08-28 05:49:19.219568: val_loss -0.5636 
2025-08-28 05:49:19.228259: Pseudo dice [np.float32(0.7941)] 
2025-08-28 05:49:19.233927: Epoch time: 15.75 s 
2025-08-28 05:49:19.894998:  
2025-08-28 05:49:19.903276: Epoch 627 
2025-08-28 05:49:19.907526: Current learning rate: 0.00412 
2025-08-28 05:49:35.765205: train_loss -0.4818 
2025-08-28 05:49:35.777847: val_loss -0.459 
2025-08-28 05:49:35.781943: Pseudo dice [np.float32(0.6897)] 
2025-08-28 05:49:35.788383: Epoch time: 15.87 s 
2025-08-28 05:49:36.457623:  
2025-08-28 05:49:36.469865: Epoch 628 
2025-08-28 05:49:36.474331: Current learning rate: 0.00411 
2025-08-28 05:49:52.202373: train_loss -0.458 
2025-08-28 05:49:52.210537: val_loss -0.5574 
2025-08-28 05:49:52.218889: Pseudo dice [np.float32(0.768)] 
2025-08-28 05:49:52.225127: Epoch time: 15.74 s 
2025-08-28 05:49:52.890373:  
2025-08-28 05:49:52.898718: Epoch 629 
2025-08-28 05:49:52.907398: Current learning rate: 0.0041 
2025-08-28 05:50:08.547900: train_loss -0.4639 
2025-08-28 05:50:08.556042: val_loss -0.4439 
2025-08-28 05:50:08.560544: Pseudo dice [np.float32(0.7352)] 
2025-08-28 05:50:08.568338: Epoch time: 15.66 s 
2025-08-28 05:50:09.219163:  
2025-08-28 05:50:09.227552: Epoch 630 
2025-08-28 05:50:09.231720: Current learning rate: 0.00409 
2025-08-28 05:50:26.165264: train_loss -0.5038 
2025-08-28 05:50:26.177775: val_loss -0.5264 
2025-08-28 05:50:26.182267: Pseudo dice [np.float32(0.7839)] 
2025-08-28 05:50:26.189180: Epoch time: 16.95 s 
2025-08-28 05:50:26.870152:  
2025-08-28 05:50:26.878513: Epoch 631 
2025-08-28 05:50:26.882675: Current learning rate: 0.00408 
2025-08-28 05:50:43.278243: train_loss -0.4929 
2025-08-28 05:50:43.286530: val_loss -0.5841 
2025-08-28 05:50:43.290696: Pseudo dice [np.float32(0.8181)] 
2025-08-28 05:50:43.299841: Epoch time: 16.41 s 
2025-08-28 05:50:43.962196:  
2025-08-28 05:50:43.970543: Epoch 632 
2025-08-28 05:50:43.978908: Current learning rate: 0.00407 
2025-08-28 05:51:00.883306: train_loss -0.5248 
2025-08-28 05:51:00.891601: val_loss -0.5365 
2025-08-28 05:51:00.900259: Pseudo dice [np.float32(0.7814)] 
2025-08-28 05:51:00.906106: Epoch time: 16.92 s 
2025-08-28 05:51:00.912246: Yayy! New best EMA pseudo Dice: 0.7620999813079834 
2025-08-28 05:51:02.021901:  
2025-08-28 05:51:02.030240: Epoch 633 
2025-08-28 05:51:02.034785: Current learning rate: 0.00406 
2025-08-28 05:51:18.384054: train_loss -0.4913 
2025-08-28 05:51:18.392455: val_loss -0.5251 
2025-08-28 05:51:18.396607: Pseudo dice [np.float32(0.7986)] 
2025-08-28 05:51:18.405683: Epoch time: 16.37 s 
2025-08-28 05:51:18.409923: Yayy! New best EMA pseudo Dice: 0.7656999826431274 
2025-08-28 05:51:19.251647:  
2025-08-28 05:51:19.263714: Epoch 634 
2025-08-28 05:51:19.268622: Current learning rate: 0.00405 
2025-08-28 05:51:35.751734: train_loss -0.5035 
2025-08-28 05:51:35.759831: val_loss -0.5444 
2025-08-28 05:51:35.764294: Pseudo dice [np.float32(0.6857)] 
2025-08-28 05:51:35.773161: Epoch time: 16.5 s 
2025-08-28 05:51:36.427094:  
2025-08-28 05:51:36.435436: Epoch 635 
2025-08-28 05:51:36.439877: Current learning rate: 0.00404 
2025-08-28 05:51:52.739336: train_loss -0.4884 
2025-08-28 05:51:52.751718: val_loss -0.5022 
2025-08-28 05:51:52.756288: Pseudo dice [np.float32(0.6957)] 
2025-08-28 05:51:52.765240: Epoch time: 16.31 s 
2025-08-28 05:51:53.423265:  
2025-08-28 05:51:53.431566: Epoch 636 
2025-08-28 05:51:53.435772: Current learning rate: 0.00403 
2025-08-28 05:52:10.027203: train_loss -0.484 
2025-08-28 05:52:10.035645: val_loss -0.5771 
2025-08-28 05:52:10.044003: Pseudo dice [np.float32(0.7852)] 
2025-08-28 05:52:10.049631: Epoch time: 16.6 s 
2025-08-28 05:52:10.707177:  
2025-08-28 05:52:10.711553: Epoch 637 
2025-08-28 05:52:10.719687: Current learning rate: 0.00402 
2025-08-28 05:52:27.073799: train_loss -0.5363 
2025-08-28 05:52:27.082104: val_loss -0.486 
2025-08-28 05:52:27.086098: Pseudo dice [np.float32(0.7666)] 
2025-08-28 05:52:27.094241: Epoch time: 16.37 s 
2025-08-28 05:52:27.766243:  
2025-08-28 05:52:27.774199: Epoch 638 
2025-08-28 05:52:27.783013: Current learning rate: 0.00401 
2025-08-28 05:52:44.186683: train_loss -0.4893 
2025-08-28 05:52:44.194872: val_loss -0.5615 
2025-08-28 05:52:44.199330: Pseudo dice [np.float32(0.7756)] 
2025-08-28 05:52:44.208727: Epoch time: 16.42 s 
2025-08-28 05:52:45.028982:  
2025-08-28 05:52:45.033348: Epoch 639 
2025-08-28 05:52:45.041614: Current learning rate: 0.004 
2025-08-28 05:53:01.220442: train_loss -0.4709 
2025-08-28 05:53:01.228439: val_loss -0.5677 
2025-08-28 05:53:01.237158: Pseudo dice [np.float32(0.7503)] 
2025-08-28 05:53:01.243043: Epoch time: 16.2 s 
2025-08-28 05:53:01.904387:  
2025-08-28 05:53:01.912505: Epoch 640 
2025-08-28 05:53:01.916633: Current learning rate: 0.00399 
2025-08-28 05:53:18.621171: train_loss -0.5054 
2025-08-28 05:53:18.629142: val_loss -0.4936 
2025-08-28 05:53:18.637502: Pseudo dice [np.float32(0.7448)] 
2025-08-28 05:53:18.643272: Epoch time: 16.72 s 
2025-08-28 05:53:19.359387:  
2025-08-28 05:53:19.367635: Epoch 641 
2025-08-28 05:53:19.372008: Current learning rate: 0.00398 
2025-08-28 05:53:36.201008: train_loss -0.4733 
2025-08-28 05:53:36.209215: val_loss -0.466 
2025-08-28 05:53:36.217584: Pseudo dice [np.float32(0.7824)] 
2025-08-28 05:53:36.222960: Epoch time: 16.84 s 
2025-08-28 05:53:36.884922:  
2025-08-28 05:53:36.892972: Epoch 642 
2025-08-28 05:53:36.897391: Current learning rate: 0.00397 
2025-08-28 05:53:53.727005: train_loss -0.5275 
2025-08-28 05:53:53.735307: val_loss -0.5372 
2025-08-28 05:53:53.743714: Pseudo dice [np.float32(0.8296)] 
2025-08-28 05:53:53.750679: Epoch time: 16.85 s 
2025-08-28 05:53:53.756362: Yayy! New best EMA pseudo Dice: 0.7657999992370605 
2025-08-28 05:53:54.582145:  
2025-08-28 05:53:54.590171: Epoch 643 
2025-08-28 05:53:54.594347: Current learning rate: 0.00396 
2025-08-28 05:54:11.782506: train_loss -0.4863 
2025-08-28 05:54:11.790592: val_loss -0.5061 
2025-08-28 05:54:11.795033: Pseudo dice [np.float32(0.786)] 
2025-08-28 05:54:11.803928: Epoch time: 17.2 s 
2025-08-28 05:54:11.809775: Yayy! New best EMA pseudo Dice: 0.767799973487854 
2025-08-28 05:54:12.741494:  
2025-08-28 05:54:12.750210: Epoch 644 
2025-08-28 05:54:12.754008: Current learning rate: 0.00395 
2025-08-28 05:54:29.462409: train_loss -0.5009 
2025-08-28 05:54:29.470850: val_loss -0.5089 
2025-08-28 05:54:29.474913: Pseudo dice [np.float32(0.7816)] 
2025-08-28 05:54:29.484290: Epoch time: 16.73 s 
2025-08-28 05:54:29.490116: Yayy! New best EMA pseudo Dice: 0.7692000269889832 
2025-08-28 05:54:30.459575:  
2025-08-28 05:54:30.463590: Epoch 645 
2025-08-28 05:54:30.471706: Current learning rate: 0.00394 
2025-08-28 05:54:47.338532: train_loss -0.5184 
2025-08-28 05:54:47.347187: val_loss -0.5226 
2025-08-28 05:54:47.351386: Pseudo dice [np.float32(0.7417)] 
2025-08-28 05:54:47.359448: Epoch time: 16.88 s 
2025-08-28 05:54:48.185214:  
2025-08-28 05:54:48.193599: Epoch 646 
2025-08-28 05:54:48.197780: Current learning rate: 0.00393 
2025-08-28 05:55:04.117857: train_loss -0.5098 
2025-08-28 05:55:04.130350: val_loss -0.4933 
2025-08-28 05:55:04.134511: Pseudo dice [np.float32(0.7147)] 
2025-08-28 05:55:04.141819: Epoch time: 15.93 s 
2025-08-28 05:55:04.801872:  
2025-08-28 05:55:04.810477: Epoch 647 
2025-08-28 05:55:04.814638: Current learning rate: 0.00392 
2025-08-28 05:55:20.521772: train_loss -0.467 
2025-08-28 05:55:20.530377: val_loss -0.5064 
2025-08-28 05:55:20.534219: Pseudo dice [np.float32(0.7301)] 
2025-08-28 05:55:20.542372: Epoch time: 15.72 s 
2025-08-28 05:55:21.201640:  
2025-08-28 05:55:21.209928: Epoch 648 
2025-08-28 05:55:21.214363: Current learning rate: 0.00391 
2025-08-28 05:55:36.763676: train_loss -0.4753 
2025-08-28 05:55:36.771255: val_loss -0.4567 
2025-08-28 05:55:36.779919: Pseudo dice [np.float32(0.763)] 
2025-08-28 05:55:36.785104: Epoch time: 15.56 s 
2025-08-28 05:55:37.551202:  
2025-08-28 05:55:37.559540: Epoch 649 
2025-08-28 05:55:37.563660: Current learning rate: 0.0039 
2025-08-28 05:55:53.305291: train_loss -0.4758 
2025-08-28 05:55:53.316922: val_loss -0.5142 
2025-08-28 05:55:53.321377: Pseudo dice [np.float32(0.7064)] 
2025-08-28 05:55:53.330320: Epoch time: 15.76 s 
2025-08-28 05:55:54.146997:  
2025-08-28 05:55:54.155272: Epoch 650 
2025-08-28 05:55:54.159438: Current learning rate: 0.00389 
2025-08-28 05:56:10.488626: train_loss -0.4588 
2025-08-28 05:56:10.496917: val_loss -0.5567 
2025-08-28 05:56:10.504826: Pseudo dice [np.float32(0.7871)] 
2025-08-28 05:56:10.511190: Epoch time: 16.34 s 
2025-08-28 05:56:11.184780:  
2025-08-28 05:56:11.193203: Epoch 651 
2025-08-28 05:56:11.197277: Current learning rate: 0.00388 
2025-08-28 05:56:27.776857: train_loss -0.4569 
2025-08-28 05:56:27.784702: val_loss -0.554 
2025-08-28 05:56:27.793036: Pseudo dice [np.float32(0.7971)] 
2025-08-28 05:56:27.798399: Epoch time: 16.59 s 
2025-08-28 05:56:28.614772:  
2025-08-28 05:56:28.623299: Epoch 652 
2025-08-28 05:56:28.631436: Current learning rate: 0.00387 
2025-08-28 05:56:44.976880: train_loss -0.5149 
2025-08-28 05:56:44.985571: val_loss -0.4886 
2025-08-28 05:56:44.989686: Pseudo dice [np.float32(0.8023)] 
2025-08-28 05:56:44.996632: Epoch time: 16.36 s 
2025-08-28 05:56:45.660838:  
2025-08-28 05:56:45.669219: Epoch 653 
2025-08-28 05:56:45.673379: Current learning rate: 0.00386 
2025-08-28 05:57:02.065183: train_loss -0.473 
2025-08-28 05:57:02.073088: val_loss -0.5927 
2025-08-28 05:57:02.081784: Pseudo dice [np.float32(0.832)] 
2025-08-28 05:57:02.088015: Epoch time: 16.4 s 
2025-08-28 05:57:02.093906: Yayy! New best EMA pseudo Dice: 0.7717000246047974 
2025-08-28 05:57:02.923931:  
2025-08-28 05:57:02.932268: Epoch 654 
2025-08-28 05:57:02.941139: Current learning rate: 0.00385 
2025-08-28 05:57:19.236166: train_loss -0.516 
2025-08-28 05:57:19.244463: val_loss -0.5765 
2025-08-28 05:57:19.248648: Pseudo dice [np.float32(0.821)] 
2025-08-28 05:57:19.257036: Epoch time: 16.31 s 
2025-08-28 05:57:19.262925: Yayy! New best EMA pseudo Dice: 0.7766000032424927 
2025-08-28 05:57:20.132703:  
2025-08-28 05:57:20.137311: Epoch 655 
2025-08-28 05:57:20.145382: Current learning rate: 0.00384 
2025-08-28 05:57:36.653438: train_loss -0.5274 
2025-08-28 05:57:36.662206: val_loss -0.6075 
2025-08-28 05:57:36.670148: Pseudo dice [np.float32(0.812)] 
2025-08-28 05:57:36.676470: Epoch time: 16.52 s 
2025-08-28 05:57:36.682506: Yayy! New best EMA pseudo Dice: 0.7800999879837036 
2025-08-28 05:57:37.512650:  
2025-08-28 05:57:37.521200: Epoch 656 
2025-08-28 05:57:37.525090: Current learning rate: 0.00383 
2025-08-28 05:57:53.811116: train_loss -0.5371 
2025-08-28 05:57:53.820981: val_loss -0.5296 
2025-08-28 05:57:53.825052: Pseudo dice [np.float32(0.7593)] 
2025-08-28 05:57:53.834127: Epoch time: 16.3 s 
2025-08-28 05:57:54.500539:  
2025-08-28 05:57:54.509196: Epoch 657 
2025-08-28 05:57:54.512948: Current learning rate: 0.00382 
2025-08-28 05:58:10.775103: train_loss -0.5323 
2025-08-28 05:58:10.783476: val_loss -0.6165 
2025-08-28 05:58:10.787866: Pseudo dice [np.float32(0.806)] 
2025-08-28 05:58:10.796937: Epoch time: 16.27 s 
2025-08-28 05:58:10.801011: Yayy! New best EMA pseudo Dice: 0.7807999849319458 
2025-08-28 05:58:11.725976:  
2025-08-28 05:58:11.734361: Epoch 658 
2025-08-28 05:58:11.738801: Current learning rate: 0.00381 
2025-08-28 05:58:27.929960: train_loss -0.5326 
2025-08-28 05:58:27.938018: val_loss -0.5866 
2025-08-28 05:58:27.946335: Pseudo dice [np.float32(0.801)] 
2025-08-28 05:58:27.951691: Epoch time: 16.2 s 
2025-08-28 05:58:27.955704: Yayy! New best EMA pseudo Dice: 0.7828999757766724 
2025-08-28 05:58:29.034907:  
2025-08-28 05:58:29.043272: Epoch 659 
2025-08-28 05:58:29.047437: Current learning rate: 0.0038 
2025-08-28 05:58:44.517176: train_loss -0.5234 
2025-08-28 05:58:44.525710: val_loss -0.5229 
2025-08-28 05:58:44.529847: Pseudo dice [np.float32(0.7575)] 
2025-08-28 05:58:44.539132: Epoch time: 15.48 s 
2025-08-28 05:58:45.192951:  
2025-08-28 05:58:45.201122: Epoch 660 
2025-08-28 05:58:45.205561: Current learning rate: 0.00379 
2025-08-28 05:59:00.733266: train_loss -0.5074 
2025-08-28 05:59:00.742532: val_loss -0.5812 
2025-08-28 05:59:00.752207: Pseudo dice [np.float32(0.7956)] 
2025-08-28 05:59:00.759110: Epoch time: 15.54 s 
2025-08-28 05:59:01.433930:  
2025-08-28 05:59:01.442323: Epoch 661 
2025-08-28 05:59:01.446494: Current learning rate: 0.00378 
2025-08-28 05:59:16.961701: train_loss -0.5172 
2025-08-28 05:59:16.970280: val_loss -0.4976 
2025-08-28 05:59:16.974463: Pseudo dice [np.float32(0.7244)] 
2025-08-28 05:59:16.981951: Epoch time: 15.53 s 
2025-08-28 05:59:17.637650:  
2025-08-28 05:59:17.642150: Epoch 662 
2025-08-28 05:59:17.650520: Current learning rate: 0.00377 
2025-08-28 05:59:33.378657: train_loss -0.5519 
2025-08-28 05:59:33.387040: val_loss -0.6387 
2025-08-28 05:59:33.395034: Pseudo dice [np.float32(0.7761)] 
2025-08-28 05:59:33.401444: Epoch time: 15.75 s 
2025-08-28 05:59:34.058177:  
2025-08-28 05:59:34.062355: Epoch 663 
2025-08-28 05:59:34.070721: Current learning rate: 0.00376 
2025-08-28 05:59:49.644742: train_loss -0.5109 
2025-08-28 05:59:49.657116: val_loss -0.608 
2025-08-28 05:59:49.661540: Pseudo dice [np.float32(0.7726)] 
2025-08-28 05:59:49.670427: Epoch time: 15.59 s 
2025-08-28 05:59:50.338466:  
2025-08-28 05:59:50.345654: Epoch 664 
2025-08-28 05:59:50.349442: Current learning rate: 0.00375 
2025-08-28 06:00:05.994550: train_loss -0.526 
2025-08-28 06:00:06.002611: val_loss -0.5493 
2025-08-28 06:00:06.006998: Pseudo dice [np.float32(0.7899)] 
2025-08-28 06:00:06.016367: Epoch time: 15.66 s 
2025-08-28 06:00:06.824230:  
2025-08-28 06:00:06.832608: Epoch 665 
2025-08-28 06:00:06.838295: Current learning rate: 0.00374 
2025-08-28 06:00:22.365160: train_loss -0.5325 
2025-08-28 06:00:22.373118: val_loss -0.5708 
2025-08-28 06:00:22.377662: Pseudo dice [np.float32(0.8068)] 
2025-08-28 06:00:22.385699: Epoch time: 15.54 s 
2025-08-28 06:00:23.040730:  
2025-08-28 06:00:23.048790: Epoch 666 
2025-08-28 06:00:23.055114: Current learning rate: 0.00373 
2025-08-28 06:00:38.752016: train_loss -0.5234 
2025-08-28 06:00:38.760307: val_loss -0.4773 
2025-08-28 06:00:38.768637: Pseudo dice [np.float32(0.7014)] 
2025-08-28 06:00:38.774071: Epoch time: 15.71 s 
2025-08-28 06:00:39.431815:  
2025-08-28 06:00:39.440521: Epoch 667 
2025-08-28 06:00:39.448516: Current learning rate: 0.00372 
2025-08-28 06:00:55.101856: train_loss -0.5344 
2025-08-28 06:00:55.109990: val_loss -0.4836 
2025-08-28 06:00:55.118326: Pseudo dice [np.float32(0.7429)] 
2025-08-28 06:00:55.123725: Epoch time: 15.67 s 
2025-08-28 06:00:55.785624:  
2025-08-28 06:00:55.793978: Epoch 668 
2025-08-28 06:00:55.798136: Current learning rate: 0.00371 
2025-08-28 06:01:11.409698: train_loss -0.5222 
2025-08-28 06:01:11.417933: val_loss -0.5212 
2025-08-28 06:01:11.422376: Pseudo dice [np.float32(0.8061)] 
2025-08-28 06:01:11.431243: Epoch time: 15.62 s 
2025-08-28 06:01:12.106109:  
2025-08-28 06:01:12.114431: Epoch 669 
2025-08-28 06:01:12.118600: Current learning rate: 0.0037 
2025-08-28 06:01:27.734435: train_loss -0.5472 
2025-08-28 06:01:27.742621: val_loss -0.5859 
2025-08-28 06:01:27.750957: Pseudo dice [np.float32(0.8161)] 
2025-08-28 06:01:27.756484: Epoch time: 15.63 s 
2025-08-28 06:01:28.426630:  
2025-08-28 06:01:28.434984: Epoch 670 
2025-08-28 06:01:28.439264: Current learning rate: 0.00369 
2025-08-28 06:01:45.397969: train_loss -0.5212 
2025-08-28 06:01:45.410259: val_loss -0.5276 
2025-08-28 06:01:45.414644: Pseudo dice [np.float32(0.7901)] 
2025-08-28 06:01:45.423661: Epoch time: 16.97 s 
2025-08-28 06:01:46.090053:  
2025-08-28 06:01:46.098416: Epoch 671 
2025-08-28 06:01:46.102581: Current learning rate: 0.00368 
2025-08-28 06:02:02.594244: train_loss -0.5196 
2025-08-28 06:02:02.606106: val_loss -0.6034 
2025-08-28 06:02:02.610698: Pseudo dice [np.float32(0.7926)] 
2025-08-28 06:02:02.617030: Epoch time: 16.51 s 
2025-08-28 06:02:03.440715:  
2025-08-28 06:02:03.449020: Epoch 672 
2025-08-28 06:02:03.453526: Current learning rate: 0.00367 
2025-08-28 06:02:20.236936: train_loss -0.5057 
2025-08-28 06:02:20.245047: val_loss -0.6825 
2025-08-28 06:02:20.253300: Pseudo dice [np.float32(0.8255)] 
2025-08-28 06:02:20.258693: Epoch time: 16.8 s 
2025-08-28 06:02:20.265786: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-08-28 06:02:21.108331:  
2025-08-28 06:02:21.116991: Epoch 673 
2025-08-28 06:02:21.125050: Current learning rate: 0.00366 
2025-08-28 06:02:37.346911: train_loss -0.5184 
2025-08-28 06:02:37.353818: val_loss -0.5321 
2025-08-28 06:02:37.362086: Pseudo dice [np.float32(0.7855)] 
2025-08-28 06:02:37.367584: Epoch time: 16.24 s 
2025-08-28 06:02:37.374552: Yayy! New best EMA pseudo Dice: 0.784600019454956 
2025-08-28 06:02:38.212893:  
2025-08-28 06:02:38.221596: Epoch 674 
2025-08-28 06:02:38.229665: Current learning rate: 0.00365 
2025-08-28 06:02:54.925418: train_loss -0.4971 
2025-08-28 06:02:54.938228: val_loss -0.5601 
2025-08-28 06:02:54.942218: Pseudo dice [np.float32(0.8059)] 
2025-08-28 06:02:54.951367: Epoch time: 16.71 s 
2025-08-28 06:02:54.957143: Yayy! New best EMA pseudo Dice: 0.7868000268936157 
2025-08-28 06:02:55.809672:  
2025-08-28 06:02:55.818007: Epoch 675 
2025-08-28 06:02:55.822493: Current learning rate: 0.00364 
2025-08-28 06:03:12.517993: train_loss -0.5152 
2025-08-28 06:03:12.526330: val_loss -0.5734 
2025-08-28 06:03:12.530514: Pseudo dice [np.float32(0.8266)] 
2025-08-28 06:03:12.538747: Epoch time: 16.71 s 
2025-08-28 06:03:12.545349: Yayy! New best EMA pseudo Dice: 0.7907999753952026 
2025-08-28 06:03:13.485624:  
2025-08-28 06:03:13.493937: Epoch 676 
2025-08-28 06:03:13.498082: Current learning rate: 0.00363 
2025-08-28 06:03:30.270889: train_loss -0.5341 
2025-08-28 06:03:30.277431: val_loss -0.5469 
2025-08-28 06:03:30.285765: Pseudo dice [np.float32(0.7894)] 
2025-08-28 06:03:30.290693: Epoch time: 16.79 s 
2025-08-28 06:03:31.094951:  
2025-08-28 06:03:31.103504: Epoch 677 
2025-08-28 06:03:31.111230: Current learning rate: 0.00362 
2025-08-28 06:03:47.953417: train_loss -0.5062 
2025-08-28 06:03:47.962033: val_loss -0.5715 
2025-08-28 06:03:47.966176: Pseudo dice [np.float32(0.7668)] 
2025-08-28 06:03:47.974242: Epoch time: 16.86 s 
2025-08-28 06:03:48.645993:  
2025-08-28 06:03:48.654413: Epoch 678 
2025-08-28 06:03:48.658280: Current learning rate: 0.00361 
2025-08-28 06:04:05.441826: train_loss -0.5063 
2025-08-28 06:04:05.454205: val_loss -0.5389 
2025-08-28 06:04:05.458354: Pseudo dice [np.float32(0.7725)] 
2025-08-28 06:04:05.465651: Epoch time: 16.8 s 
2025-08-28 06:04:06.134044:  
2025-08-28 06:04:06.142364: Epoch 679 
2025-08-28 06:04:06.150434: Current learning rate: 0.0036 
2025-08-28 06:04:23.280341: train_loss -0.4921 
2025-08-28 06:04:23.288671: val_loss -0.6131 
2025-08-28 06:04:23.297395: Pseudo dice [np.float32(0.7749)] 
2025-08-28 06:04:23.306800: Epoch time: 17.15 s 
2025-08-28 06:04:23.976934:  
2025-08-28 06:04:23.985165: Epoch 680 
2025-08-28 06:04:23.989360: Current learning rate: 0.00359 
2025-08-28 06:04:40.877340: train_loss -0.5373 
2025-08-28 06:04:40.885458: val_loss -0.5795 
2025-08-28 06:04:40.893844: Pseudo dice [np.float32(0.7822)] 
2025-08-28 06:04:40.900022: Epoch time: 16.9 s 
2025-08-28 06:04:41.565249:  
2025-08-28 06:04:41.573594: Epoch 681 
2025-08-28 06:04:41.578068: Current learning rate: 0.00358 
2025-08-28 06:04:58.587041: train_loss -0.5361 
2025-08-28 06:04:58.599185: val_loss -0.4714 
2025-08-28 06:04:58.609782: Pseudo dice [np.float32(0.7717)] 
2025-08-28 06:04:58.620781: Epoch time: 17.02 s 
2025-08-28 06:04:59.328825:  
2025-08-28 06:04:59.337575: Epoch 682 
2025-08-28 06:04:59.343693: Current learning rate: 0.00357 
2025-08-28 06:05:16.387445: train_loss -0.5024 
2025-08-28 06:05:16.395944: val_loss -0.5721 
2025-08-28 06:05:16.400396: Pseudo dice [np.float32(0.8222)] 
2025-08-28 06:05:16.407223: Epoch time: 17.06 s 
2025-08-28 06:05:17.075699:  
2025-08-28 06:05:17.079880: Epoch 683 
2025-08-28 06:05:17.088226: Current learning rate: 0.00356 
2025-08-28 06:05:34.194891: train_loss -0.522 
2025-08-28 06:05:34.201540: val_loss -0.5619 
2025-08-28 06:05:34.209517: Pseudo dice [np.float32(0.8129)] 
2025-08-28 06:05:34.216035: Epoch time: 17.12 s 
2025-08-28 06:05:35.064508:  
2025-08-28 06:05:35.072863: Epoch 684 
2025-08-28 06:05:35.077437: Current learning rate: 0.00355 
2025-08-28 06:05:51.864599: train_loss -0.5266 
2025-08-28 06:05:51.873066: val_loss -0.5722 
2025-08-28 06:05:51.877125: Pseudo dice [np.float32(0.766)] 
2025-08-28 06:05:51.885424: Epoch time: 16.8 s 
2025-08-28 06:05:52.544452:  
2025-08-28 06:05:52.552802: Epoch 685 
2025-08-28 06:05:52.561173: Current learning rate: 0.00354 
2025-08-28 06:06:09.537501: train_loss -0.5442 
2025-08-28 06:06:09.551448: val_loss -0.5228 
2025-08-28 06:06:09.557358: Pseudo dice [np.float32(0.7612)] 
2025-08-28 06:06:09.563473: Epoch time: 16.99 s 
2025-08-28 06:06:10.228800:  
2025-08-28 06:06:10.237128: Epoch 686 
2025-08-28 06:06:10.245510: Current learning rate: 0.00353 
2025-08-28 06:06:27.558996: train_loss -0.5186 
2025-08-28 06:06:27.567206: val_loss -0.5847 
2025-08-28 06:06:27.571473: Pseudo dice [np.float32(0.748)] 
2025-08-28 06:06:27.578567: Epoch time: 17.33 s 
2025-08-28 06:06:28.242633:  
2025-08-28 06:06:28.250938: Epoch 687 
2025-08-28 06:06:28.255109: Current learning rate: 0.00352 
2025-08-28 06:06:45.272420: train_loss -0.5289 
2025-08-28 06:06:45.280546: val_loss -0.515 
2025-08-28 06:06:45.284602: Pseudo dice [np.float32(0.7851)] 
2025-08-28 06:06:45.293806: Epoch time: 17.03 s 
2025-08-28 06:06:45.964504:  
2025-08-28 06:06:45.968626: Epoch 688 
2025-08-28 06:06:45.976949: Current learning rate: 0.00351 
2025-08-28 06:07:02.814522: train_loss -0.5299 
2025-08-28 06:07:02.823009: val_loss -0.5512 
2025-08-28 06:07:02.831917: Pseudo dice [np.float32(0.7844)] 
2025-08-28 06:07:02.836720: Epoch time: 16.85 s 
2025-08-28 06:07:03.506987:  
2025-08-28 06:07:03.515359: Epoch 689 
2025-08-28 06:07:03.519485: Current learning rate: 0.0035 
2025-08-28 06:07:20.036104: train_loss -0.5525 
2025-08-28 06:07:20.044426: val_loss -0.5173 
2025-08-28 06:07:20.052746: Pseudo dice [np.float32(0.7481)] 
2025-08-28 06:07:20.058970: Epoch time: 16.53 s 
2025-08-28 06:07:20.736700:  
2025-08-28 06:07:20.745067: Epoch 690 
2025-08-28 06:07:20.749239: Current learning rate: 0.00349 
2025-08-28 06:07:37.724963: train_loss -0.5016 
2025-08-28 06:07:37.732828: val_loss -0.5072 
2025-08-28 06:07:37.741200: Pseudo dice [np.float32(0.7511)] 
2025-08-28 06:07:37.746732: Epoch time: 16.99 s 
2025-08-28 06:07:38.583690:  
2025-08-28 06:07:38.592004: Epoch 691 
2025-08-28 06:07:38.596175: Current learning rate: 0.00348 
2025-08-28 06:07:55.450736: train_loss -0.5139 
2025-08-28 06:07:55.463032: val_loss -0.5417 
2025-08-28 06:07:55.467239: Pseudo dice [np.float32(0.7663)] 
2025-08-28 06:07:55.476436: Epoch time: 16.87 s 
2025-08-28 06:07:56.155453:  
2025-08-28 06:07:56.163733: Epoch 692 
2025-08-28 06:07:56.168247: Current learning rate: 0.00346 
2025-08-28 06:08:13.035083: train_loss -0.5324 
2025-08-28 06:08:13.043092: val_loss -0.608 
2025-08-28 06:08:13.051650: Pseudo dice [np.float32(0.8202)] 
2025-08-28 06:08:13.056923: Epoch time: 16.88 s 
2025-08-28 06:08:13.727090:  
2025-08-28 06:08:13.735445: Epoch 693 
2025-08-28 06:08:13.739616: Current learning rate: 0.00345 
2025-08-28 06:08:29.205045: train_loss -0.5392 
2025-08-28 06:08:29.213399: val_loss -0.5933 
2025-08-28 06:08:29.221744: Pseudo dice [np.float32(0.784)] 
2025-08-28 06:08:29.226671: Epoch time: 15.48 s 
2025-08-28 06:08:29.897467:  
2025-08-28 06:08:29.905833: Epoch 694 
2025-08-28 06:08:29.910231: Current learning rate: 0.00344 
2025-08-28 06:08:45.492842: train_loss -0.5392 
2025-08-28 06:08:45.504609: val_loss -0.5634 
2025-08-28 06:08:45.509102: Pseudo dice [np.float32(0.7799)] 
2025-08-28 06:08:45.516258: Epoch time: 15.6 s 
2025-08-28 06:08:46.176166:  
2025-08-28 06:08:46.184812: Epoch 695 
2025-08-28 06:08:46.188950: Current learning rate: 0.00343 
2025-08-28 06:09:01.599942: train_loss -0.5011 
2025-08-28 06:09:01.608254: val_loss -0.5742 
2025-08-28 06:09:01.616619: Pseudo dice [np.float32(0.8031)] 
2025-08-28 06:09:01.623869: Epoch time: 15.42 s 
2025-08-28 06:09:02.296464:  
2025-08-28 06:09:02.300894: Epoch 696 
2025-08-28 06:09:02.308989: Current learning rate: 0.00342 
2025-08-28 06:09:17.991600: train_loss -0.5396 
2025-08-28 06:09:17.999704: val_loss -0.5205 
2025-08-28 06:09:18.004131: Pseudo dice [np.float32(0.7336)] 
2025-08-28 06:09:18.012057: Epoch time: 15.7 s 
2025-08-28 06:09:18.835951:  
2025-08-28 06:09:18.844657: Epoch 697 
2025-08-28 06:09:18.850502: Current learning rate: 0.00341 
2025-08-28 06:09:34.395588: train_loss -0.5111 
2025-08-28 06:09:34.403570: val_loss -0.477 
2025-08-28 06:09:34.411561: Pseudo dice [np.float32(0.7358)] 
2025-08-28 06:09:34.416887: Epoch time: 15.56 s 
2025-08-28 06:09:35.087524:  
2025-08-28 06:09:35.091691: Epoch 698 
2025-08-28 06:09:35.100064: Current learning rate: 0.0034 
2025-08-28 06:09:50.824144: train_loss -0.5039 
2025-08-28 06:09:50.837437: val_loss -0.5708 
2025-08-28 06:09:50.844120: Pseudo dice [np.float32(0.7218)] 
2025-08-28 06:09:50.849876: Epoch time: 15.74 s 
2025-08-28 06:09:51.516436:  
2025-08-28 06:09:51.525130: Epoch 699 
2025-08-28 06:09:51.529258: Current learning rate: 0.00339 
2025-08-28 06:10:07.319132: train_loss -0.5261 
2025-08-28 06:10:07.324234: val_loss -0.5501 
2025-08-28 06:10:07.333438: Pseudo dice [np.float32(0.746)] 
2025-08-28 06:10:07.340859: Epoch time: 15.81 s 
2025-08-28 06:10:08.178968:  
2025-08-28 06:10:08.187543: Epoch 700 
2025-08-28 06:10:08.191526: Current learning rate: 0.00338 
2025-08-28 06:10:24.887257: train_loss -0.5046 
2025-08-28 06:10:24.895889: val_loss -0.5416 
2025-08-28 06:10:24.903942: Pseudo dice [np.float32(0.7558)] 
2025-08-28 06:10:24.909577: Epoch time: 16.71 s 
2025-08-28 06:10:25.575441:  
2025-08-28 06:10:25.583768: Epoch 701 
2025-08-28 06:10:25.588178: Current learning rate: 0.00337 
2025-08-28 06:10:42.180061: train_loss -0.5086 
2025-08-28 06:10:42.187837: val_loss -0.5801 
2025-08-28 06:10:42.196217: Pseudo dice [np.float32(0.7995)] 
2025-08-28 06:10:42.201682: Epoch time: 16.61 s 
2025-08-28 06:10:42.863573:  
2025-08-28 06:10:42.867816: Epoch 702 
2025-08-28 06:10:42.876338: Current learning rate: 0.00336 
2025-08-28 06:10:59.893325: train_loss -0.5285 
2025-08-28 06:10:59.901405: val_loss -0.5613 
2025-08-28 06:10:59.910071: Pseudo dice [np.float32(0.7816)] 
2025-08-28 06:10:59.915989: Epoch time: 17.03 s 
2025-08-28 06:11:00.781240:  
2025-08-28 06:11:00.788625: Epoch 703 
2025-08-28 06:11:00.794930: Current learning rate: 0.00335 
2025-08-28 06:11:17.297961: train_loss -0.5295 
2025-08-28 06:11:17.306253: val_loss -0.5822 
2025-08-28 06:11:17.310708: Pseudo dice [np.float32(0.8079)] 
2025-08-28 06:11:17.316737: Epoch time: 16.52 s 
2025-08-28 06:11:17.981911:  
2025-08-28 06:11:17.990562: Epoch 704 
2025-08-28 06:11:17.994434: Current learning rate: 0.00334 
2025-08-28 06:11:34.277395: train_loss -0.5099 
2025-08-28 06:11:34.286052: val_loss -0.6378 
2025-08-28 06:11:34.289846: Pseudo dice [np.float32(0.7635)] 
2025-08-28 06:11:34.299057: Epoch time: 16.3 s 
2025-08-28 06:11:34.965636:  
2025-08-28 06:11:34.973924: Epoch 705 
2025-08-28 06:11:34.978426: Current learning rate: 0.00333 
2025-08-28 06:11:51.915799: train_loss -0.5506 
2025-08-28 06:11:51.924161: val_loss -0.5196 
2025-08-28 06:11:51.932502: Pseudo dice [np.float32(0.7753)] 
2025-08-28 06:11:51.937797: Epoch time: 16.95 s 
2025-08-28 06:11:52.604352:  
2025-08-28 06:11:52.612603: Epoch 706 
2025-08-28 06:11:52.616560: Current learning rate: 0.00332 
2025-08-28 06:12:09.336210: train_loss -0.5041 
2025-08-28 06:12:09.346270: val_loss -0.4594 
2025-08-28 06:12:09.350268: Pseudo dice [np.float32(0.7257)] 
2025-08-28 06:12:09.358975: Epoch time: 16.73 s 
2025-08-28 06:12:10.029714:  
2025-08-28 06:12:10.038125: Epoch 707 
2025-08-28 06:12:10.042580: Current learning rate: 0.00331 
2025-08-28 06:12:26.975801: train_loss -0.4889 
2025-08-28 06:12:26.984476: val_loss -0.5003 
2025-08-28 06:12:26.992580: Pseudo dice [np.float32(0.7394)] 
2025-08-28 06:12:26.997999: Epoch time: 16.95 s 
2025-08-28 06:12:27.689091:  
2025-08-28 06:12:27.697703: Epoch 708 
2025-08-28 06:12:27.706508: Current learning rate: 0.0033 
2025-08-28 06:12:44.306086: train_loss -0.5278 
2025-08-28 06:12:44.314292: val_loss -0.5001 
2025-08-28 06:12:44.322832: Pseudo dice [np.float32(0.7788)] 
2025-08-28 06:12:44.327781: Epoch time: 16.62 s 
2025-08-28 06:12:45.002182:  
2025-08-28 06:12:45.010822: Epoch 709 
2025-08-28 06:12:45.015074: Current learning rate: 0.00329 
2025-08-28 06:13:02.215190: train_loss -0.5486 
2025-08-28 06:13:02.223851: val_loss -0.517 
2025-08-28 06:13:02.231860: Pseudo dice [np.float32(0.781)] 
2025-08-28 06:13:02.238531: Epoch time: 17.22 s 
2025-08-28 06:13:03.078551:  
2025-08-28 06:13:03.086881: Epoch 710 
2025-08-28 06:13:03.094937: Current learning rate: 0.00328 
2025-08-28 06:13:19.757720: train_loss -0.4999 
2025-08-28 06:13:19.766038: val_loss -0.5703 
2025-08-28 06:13:19.770206: Pseudo dice [np.float32(0.7732)] 
2025-08-28 06:13:19.779422: Epoch time: 16.68 s 
2025-08-28 06:13:20.450066:  
2025-08-28 06:13:20.458403: Epoch 711 
2025-08-28 06:13:20.462560: Current learning rate: 0.00327 
2025-08-28 06:13:37.358677: train_loss -0.5202 
2025-08-28 06:13:37.367004: val_loss -0.5479 
2025-08-28 06:13:37.371201: Pseudo dice [np.float32(0.7462)] 
2025-08-28 06:13:37.380249: Epoch time: 16.91 s 
2025-08-28 06:13:38.063544:  
2025-08-28 06:13:38.072103: Epoch 712 
2025-08-28 06:13:38.076277: Current learning rate: 0.00326 
2025-08-28 06:13:54.746817: train_loss -0.5103 
2025-08-28 06:13:54.759322: val_loss -0.5961 
2025-08-28 06:13:54.763819: Pseudo dice [np.float32(0.7447)] 
2025-08-28 06:13:54.770806: Epoch time: 16.68 s 
2025-08-28 06:13:55.443319:  
2025-08-28 06:13:55.451679: Epoch 713 
2025-08-28 06:13:55.455844: Current learning rate: 0.00325 
2025-08-28 06:14:12.410346: train_loss -0.5132 
2025-08-28 06:14:12.422795: val_loss -0.5941 
2025-08-28 06:14:12.426978: Pseudo dice [np.float32(0.8286)] 
2025-08-28 06:14:12.436107: Epoch time: 16.97 s 
2025-08-28 06:14:13.115177:  
2025-08-28 06:14:13.123545: Epoch 714 
2025-08-28 06:14:13.127965: Current learning rate: 0.00324 
2025-08-28 06:14:29.853034: train_loss -0.5784 
2025-08-28 06:14:29.865206: val_loss -0.5966 
2025-08-28 06:14:29.869650: Pseudo dice [np.float32(0.7984)] 
2025-08-28 06:14:29.876950: Epoch time: 16.74 s 
2025-08-28 06:14:30.545048:  
2025-08-28 06:14:30.553434: Epoch 715 
2025-08-28 06:14:30.557595: Current learning rate: 0.00323 
2025-08-28 06:14:47.420236: train_loss -0.5459 
2025-08-28 06:14:47.428578: val_loss -0.5243 
2025-08-28 06:14:47.436953: Pseudo dice [np.float32(0.7266)] 
2025-08-28 06:14:47.442388: Epoch time: 16.88 s 
2025-08-28 06:14:48.125529:  
2025-08-28 06:14:48.133777: Epoch 716 
2025-08-28 06:14:48.137982: Current learning rate: 0.00322 
2025-08-28 06:15:04.779503: train_loss -0.5567 
2025-08-28 06:15:04.791822: val_loss -0.4998 
2025-08-28 06:15:04.796242: Pseudo dice [np.float32(0.7685)] 
2025-08-28 06:15:04.805176: Epoch time: 16.65 s 
2025-08-28 06:15:05.646781:  
2025-08-28 06:15:05.655106: Epoch 717 
2025-08-28 06:15:05.659273: Current learning rate: 0.00321 
2025-08-28 06:15:22.447163: train_loss -0.5133 
2025-08-28 06:15:22.455224: val_loss -0.5723 
2025-08-28 06:15:22.459381: Pseudo dice [np.float32(0.7684)] 
2025-08-28 06:15:22.468607: Epoch time: 16.8 s 
2025-08-28 06:15:23.135050:  
2025-08-28 06:15:23.139657: Epoch 718 
2025-08-28 06:15:23.147521: Current learning rate: 0.0032 
2025-08-28 06:15:39.756121: train_loss -0.5169 
2025-08-28 06:15:39.764184: val_loss -0.534 
2025-08-28 06:15:39.772571: Pseudo dice [np.float32(0.7823)] 
2025-08-28 06:15:39.778052: Epoch time: 16.63 s 
2025-08-28 06:15:40.448210:  
2025-08-28 06:15:40.456892: Epoch 719 
2025-08-28 06:15:40.460698: Current learning rate: 0.00319 
2025-08-28 06:15:56.897944: train_loss -0.5259 
2025-08-28 06:15:56.906279: val_loss -0.4482 
2025-08-28 06:15:56.914653: Pseudo dice [np.float32(0.6641)] 
2025-08-28 06:15:56.921077: Epoch time: 16.45 s 
2025-08-28 06:15:57.590289:  
2025-08-28 06:15:57.599005: Epoch 720 
2025-08-28 06:15:57.606993: Current learning rate: 0.00318 
2025-08-28 06:16:14.582256: train_loss -0.5207 
2025-08-28 06:16:14.590621: val_loss -0.549 
2025-08-28 06:16:14.594789: Pseudo dice [np.float32(0.7742)] 
2025-08-28 06:16:14.603001: Epoch time: 16.99 s 
2025-08-28 06:16:15.270725:  
2025-08-28 06:16:15.278610: Epoch 721 
2025-08-28 06:16:15.283032: Current learning rate: 0.00317 
2025-08-28 06:16:31.803619: train_loss -0.5211 
2025-08-28 06:16:31.811971: val_loss -0.6018 
2025-08-28 06:16:31.816292: Pseudo dice [np.float32(0.8066)] 
2025-08-28 06:16:31.825752: Epoch time: 16.54 s 
2025-08-28 06:16:32.500159:  
2025-08-28 06:16:32.508574: Epoch 722 
2025-08-28 06:16:32.512720: Current learning rate: 0.00316 
2025-08-28 06:16:49.155383: train_loss -0.5239 
2025-08-28 06:16:49.162676: val_loss -0.553 
2025-08-28 06:16:49.167160: Pseudo dice [np.float32(0.7416)] 
2025-08-28 06:16:49.175213: Epoch time: 16.66 s 
2025-08-28 06:16:49.988823:  
2025-08-28 06:16:50.000989: Epoch 723 
2025-08-28 06:16:50.005913: Current learning rate: 0.00315 
2025-08-28 06:17:06.709772: train_loss -0.5465 
2025-08-28 06:17:06.717723: val_loss -0.5314 
2025-08-28 06:17:06.726761: Pseudo dice [np.float32(0.7601)] 
2025-08-28 06:17:06.732183: Epoch time: 16.72 s 
2025-08-28 06:17:07.405849:  
2025-08-28 06:17:07.414190: Epoch 724 
2025-08-28 06:17:07.418352: Current learning rate: 0.00314 
2025-08-28 06:17:24.422885: train_loss -0.5255 
2025-08-28 06:17:24.431178: val_loss -0.5309 
2025-08-28 06:17:24.435364: Pseudo dice [np.float32(0.7568)] 
2025-08-28 06:17:24.444005: Epoch time: 17.02 s 
2025-08-28 06:17:25.115196:  
2025-08-28 06:17:25.123536: Epoch 725 
2025-08-28 06:17:25.127770: Current learning rate: 0.00313 
2025-08-28 06:17:41.832166: train_loss -0.5794 
2025-08-28 06:17:41.840672: val_loss -0.6249 
2025-08-28 06:17:41.848084: Pseudo dice [np.float32(0.8347)] 
2025-08-28 06:17:41.853718: Epoch time: 16.72 s 
2025-08-28 06:17:42.524545:  
2025-08-28 06:17:42.532623: Epoch 726 
2025-08-28 06:17:42.536762: Current learning rate: 0.00312 
2025-08-28 06:17:59.729258: train_loss -0.5361 
2025-08-28 06:17:59.741485: val_loss -0.5901 
2025-08-28 06:17:59.745615: Pseudo dice [np.float32(0.8012)] 
2025-08-28 06:17:59.751883: Epoch time: 17.2 s 
2025-08-28 06:18:00.421309:  
2025-08-28 06:18:00.429630: Epoch 727 
2025-08-28 06:18:00.438007: Current learning rate: 0.00311 
2025-08-28 06:18:17.263101: train_loss -0.508 
2025-08-28 06:18:17.271451: val_loss -0.5787 
2025-08-28 06:18:17.275615: Pseudo dice [np.float32(0.8119)] 
2025-08-28 06:18:17.284841: Epoch time: 16.84 s 
2025-08-28 06:18:17.963815:  
2025-08-28 06:18:17.972481: Epoch 728 
2025-08-28 06:18:17.976604: Current learning rate: 0.0031 
2025-08-28 06:18:34.567883: train_loss -0.5332 
2025-08-28 06:18:34.576225: val_loss -0.5269 
2025-08-28 06:18:34.584573: Pseudo dice [np.float32(0.7668)] 
2025-08-28 06:18:34.591891: Epoch time: 16.6 s 
2025-08-28 06:18:35.281079:  
2025-08-28 06:18:35.285453: Epoch 729 
2025-08-28 06:18:35.293620: Current learning rate: 0.00309 
2025-08-28 06:18:51.764715: train_loss -0.5469 
2025-08-28 06:18:51.776739: val_loss -0.5225 
2025-08-28 06:18:51.780899: Pseudo dice [np.float32(0.7831)] 
2025-08-28 06:18:51.789300: Epoch time: 16.49 s 
2025-08-28 06:18:52.619209:  
2025-08-28 06:18:52.623716: Epoch 730 
2025-08-28 06:18:52.631824: Current learning rate: 0.00308 
2025-08-28 06:19:09.319797: train_loss -0.5468 
2025-08-28 06:19:09.327839: val_loss -0.5618 
2025-08-28 06:19:09.335948: Pseudo dice [np.float32(0.7524)] 
2025-08-28 06:19:09.341931: Epoch time: 16.7 s 
2025-08-28 06:19:10.015805:  
2025-08-28 06:19:10.024123: Epoch 731 
2025-08-28 06:19:10.028327: Current learning rate: 0.00307 
2025-08-28 06:19:26.828452: train_loss -0.5283 
2025-08-28 06:19:26.842373: val_loss -0.5557 
2025-08-28 06:19:26.853446: Pseudo dice [np.float32(0.8083)] 
2025-08-28 06:19:26.864383: Epoch time: 16.81 s 
2025-08-28 06:19:27.575018:  
2025-08-28 06:19:27.583228: Epoch 732 
2025-08-28 06:19:27.587506: Current learning rate: 0.00306 
2025-08-28 06:19:44.112899: train_loss -0.5382 
2025-08-28 06:19:44.125085: val_loss -0.5361 
2025-08-28 06:19:44.129281: Pseudo dice [np.float32(0.8086)] 
2025-08-28 06:19:44.137269: Epoch time: 16.54 s 
2025-08-28 06:19:44.817210:  
2025-08-28 06:19:44.825585: Epoch 733 
2025-08-28 06:19:44.829738: Current learning rate: 0.00305 
2025-08-28 06:20:01.692383: train_loss -0.5337 
2025-08-28 06:20:01.700727: val_loss -0.6357 
2025-08-28 06:20:01.709810: Pseudo dice [np.float32(0.7917)] 
2025-08-28 06:20:01.714212: Epoch time: 16.88 s 
2025-08-28 06:20:02.451147:  
2025-08-28 06:20:02.459650: Epoch 734 
2025-08-28 06:20:02.464084: Current learning rate: 0.00304 
2025-08-28 06:20:19.410138: train_loss -0.5213 
2025-08-28 06:20:19.418427: val_loss -0.5668 
2025-08-28 06:20:19.422586: Pseudo dice [np.float32(0.7868)] 
2025-08-28 06:20:19.431699: Epoch time: 16.96 s 
2025-08-28 06:20:20.115324:  
2025-08-28 06:20:20.123480: Epoch 735 
2025-08-28 06:20:20.131724: Current learning rate: 0.00303 
2025-08-28 06:20:37.075839: train_loss -0.5412 
2025-08-28 06:20:37.086055: val_loss -0.6024 
2025-08-28 06:20:37.090527: Pseudo dice [np.float32(0.8288)] 
2025-08-28 06:20:37.099513: Epoch time: 16.96 s 
2025-08-28 06:20:37.912123:  
2025-08-28 06:20:37.920227: Epoch 736 
2025-08-28 06:20:37.924392: Current learning rate: 0.00302 
2025-08-28 06:20:54.292063: train_loss -0.5733 
2025-08-28 06:20:54.303264: val_loss -0.5797 
2025-08-28 06:20:54.307408: Pseudo dice [np.float32(0.8273)] 
2025-08-28 06:20:54.316613: Epoch time: 16.38 s 
2025-08-28 06:20:54.322376: Yayy! New best EMA pseudo Dice: 0.7907999753952026 
2025-08-28 06:20:55.166615:  
2025-08-28 06:20:55.174989: Epoch 737 
2025-08-28 06:20:55.179117: Current learning rate: 0.00301 
2025-08-28 06:21:11.870778: train_loss -0.5543 
2025-08-28 06:21:11.879203: val_loss -0.4987 
2025-08-28 06:21:11.887573: Pseudo dice [np.float32(0.7221)] 
2025-08-28 06:21:11.894739: Epoch time: 16.7 s 
2025-08-28 06:21:12.567317:  
2025-08-28 06:21:12.571685: Epoch 738 
2025-08-28 06:21:12.580540: Current learning rate: 0.003 
2025-08-28 06:21:28.912800: train_loss -0.5169 
2025-08-28 06:21:28.921504: val_loss -0.5694 
2025-08-28 06:21:28.925322: Pseudo dice [np.float32(0.7937)] 
2025-08-28 06:21:28.932408: Epoch time: 16.35 s 
2025-08-28 06:21:29.601151:  
2025-08-28 06:21:29.609908: Epoch 739 
2025-08-28 06:21:29.618006: Current learning rate: 0.00299 
2025-08-28 06:21:46.313656: train_loss -0.5684 
2025-08-28 06:21:46.321881: val_loss -0.6155 
2025-08-28 06:21:46.330571: Pseudo dice [np.float32(0.81)] 
2025-08-28 06:21:46.336954: Epoch time: 16.71 s 
2025-08-28 06:21:47.010037:  
2025-08-28 06:21:47.019958: Epoch 740 
2025-08-28 06:21:47.022538: Current learning rate: 0.00297 
2025-08-28 06:22:03.635425: train_loss -0.5221 
2025-08-28 06:22:03.647546: val_loss -0.6007 
2025-08-28 06:22:03.651956: Pseudo dice [np.float32(0.7849)] 
2025-08-28 06:22:03.658973: Epoch time: 16.63 s 
2025-08-28 06:22:04.338453:  
2025-08-28 06:22:04.348121: Epoch 741 
2025-08-28 06:22:04.352757: Current learning rate: 0.00296 
2025-08-28 06:22:21.307574: train_loss -0.5302 
2025-08-28 06:22:21.315136: val_loss -0.556 
2025-08-28 06:22:21.319611: Pseudo dice [np.float32(0.7855)] 
2025-08-28 06:22:21.328992: Epoch time: 16.97 s 
2025-08-28 06:22:22.170138:  
2025-08-28 06:22:22.174552: Epoch 742 
2025-08-28 06:22:22.183156: Current learning rate: 0.00295 
2025-08-28 06:22:38.870202: train_loss -0.5433 
2025-08-28 06:22:38.878515: val_loss -0.6334 
2025-08-28 06:22:38.882686: Pseudo dice [np.float32(0.7949)] 
2025-08-28 06:22:38.891736: Epoch time: 16.7 s 
2025-08-28 06:22:39.575061:  
2025-08-28 06:22:39.583701: Epoch 743 
2025-08-28 06:22:39.592018: Current learning rate: 0.00294 
2025-08-28 06:22:56.688482: train_loss -0.5425 
2025-08-28 06:22:56.700480: val_loss -0.6216 
2025-08-28 06:22:56.704649: Pseudo dice [np.float32(0.8192)] 
2025-08-28 06:22:56.713837: Epoch time: 17.11 s 
2025-08-28 06:22:56.720494: Yayy! New best EMA pseudo Dice: 0.7910000085830688 
2025-08-28 06:22:57.572417:  
2025-08-28 06:22:57.581189: Epoch 744 
2025-08-28 06:22:57.584699: Current learning rate: 0.00293 
2025-08-28 06:23:13.817844: train_loss -0.5466 
2025-08-28 06:23:13.825919: val_loss -0.5524 
2025-08-28 06:23:13.834235: Pseudo dice [np.float32(0.7736)] 
2025-08-28 06:23:13.841442: Epoch time: 16.25 s 
2025-08-28 06:23:14.518249:  
2025-08-28 06:23:14.526674: Epoch 745 
2025-08-28 06:23:14.530786: Current learning rate: 0.00292 
2025-08-28 06:23:30.859888: train_loss -0.5621 
2025-08-28 06:23:30.867987: val_loss -0.6064 
2025-08-28 06:23:30.876033: Pseudo dice [np.float32(0.8072)] 
2025-08-28 06:23:30.881235: Epoch time: 16.35 s 
2025-08-28 06:23:30.885559: Yayy! New best EMA pseudo Dice: 0.7910000085830688 
2025-08-28 06:23:31.884485:  
2025-08-28 06:23:31.890065: Epoch 746 
2025-08-28 06:23:31.898214: Current learning rate: 0.00291 
2025-08-28 06:23:48.101827: train_loss -0.5396 
2025-08-28 06:23:48.110139: val_loss -0.612 
2025-08-28 06:23:48.114325: Pseudo dice [np.float32(0.8042)] 
2025-08-28 06:23:48.122485: Epoch time: 16.22 s 
2025-08-28 06:23:48.128359: Yayy! New best EMA pseudo Dice: 0.7922999858856201 
2025-08-28 06:23:49.111141:  
2025-08-28 06:23:49.119812: Epoch 747 
2025-08-28 06:23:49.127854: Current learning rate: 0.0029 
2025-08-28 06:24:05.110449: train_loss -0.5404 
2025-08-28 06:24:05.123211: val_loss -0.5853 
2025-08-28 06:24:05.131316: Pseudo dice [np.float32(0.7718)] 
2025-08-28 06:24:05.137548: Epoch time: 16.0 s 
2025-08-28 06:24:05.965465:  
2025-08-28 06:24:05.973819: Epoch 748 
2025-08-28 06:24:05.982163: Current learning rate: 0.00289 
2025-08-28 06:24:22.069079: train_loss -0.5323 
2025-08-28 06:24:22.077395: val_loss -0.5442 
2025-08-28 06:24:22.085747: Pseudo dice [np.float32(0.7811)] 
2025-08-28 06:24:22.092085: Epoch time: 16.1 s 
2025-08-28 06:24:22.778107:  
2025-08-28 06:24:22.786447: Epoch 749 
2025-08-28 06:24:22.790621: Current learning rate: 0.00288 
2025-08-28 06:24:39.182267: train_loss -0.5428 
2025-08-28 06:24:39.190686: val_loss -0.5753 
2025-08-28 06:24:39.194761: Pseudo dice [np.float32(0.8161)] 
2025-08-28 06:24:39.203721: Epoch time: 16.41 s 
2025-08-28 06:24:40.057826:  
2025-08-28 06:24:40.066231: Epoch 750 
2025-08-28 06:24:40.070354: Current learning rate: 0.00287 
2025-08-28 06:24:56.094759: train_loss -0.5412 
2025-08-28 06:24:56.107484: val_loss -0.6003 
2025-08-28 06:24:56.115621: Pseudo dice [np.float32(0.7893)] 
2025-08-28 06:24:56.121798: Epoch time: 16.04 s 
2025-08-28 06:24:56.799576:  
2025-08-28 06:24:56.807926: Epoch 751 
2025-08-28 06:24:56.816271: Current learning rate: 0.00286 
2025-08-28 06:25:12.956831: train_loss -0.5523 
2025-08-28 06:25:12.965725: val_loss -0.5951 
2025-08-28 06:25:12.969905: Pseudo dice [np.float32(0.8066)] 
2025-08-28 06:25:12.977283: Epoch time: 16.16 s 
2025-08-28 06:25:12.983243: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-08-28 06:25:13.838761:  
2025-08-28 06:25:13.846100: Epoch 752 
2025-08-28 06:25:13.850256: Current learning rate: 0.00285 
2025-08-28 06:25:30.141600: train_loss -0.5698 
2025-08-28 06:25:30.153728: val_loss -0.6093 
2025-08-28 06:25:30.158226: Pseudo dice [np.float32(0.7872)] 
2025-08-28 06:25:30.167098: Epoch time: 16.3 s 
2025-08-28 06:25:30.838228:  
2025-08-28 06:25:30.846486: Epoch 753 
2025-08-28 06:25:30.850563: Current learning rate: 0.00284 
2025-08-28 06:25:46.566285: train_loss -0.5078 
2025-08-28 06:25:46.574331: val_loss -0.5216 
2025-08-28 06:25:46.582690: Pseudo dice [np.float32(0.7015)] 
2025-08-28 06:25:46.589967: Epoch time: 15.73 s 
2025-08-28 06:25:47.412880:  
2025-08-28 06:25:47.420958: Epoch 754 
2025-08-28 06:25:47.429398: Current learning rate: 0.00283 
2025-08-28 06:26:03.270127: train_loss -0.5351 
2025-08-28 06:26:03.282653: val_loss -0.5719 
2025-08-28 06:26:03.287126: Pseudo dice [np.float32(0.8373)] 
2025-08-28 06:26:03.295948: Epoch time: 15.86 s 
2025-08-28 06:26:03.979151:  
2025-08-28 06:26:03.987586: Epoch 755 
2025-08-28 06:26:03.991737: Current learning rate: 0.00282 
2025-08-28 06:26:20.049767: train_loss -0.5586 
2025-08-28 06:26:20.057757: val_loss -0.555 
2025-08-28 06:26:20.062286: Pseudo dice [np.float32(0.7747)] 
2025-08-28 06:26:20.070094: Epoch time: 16.07 s 
2025-08-28 06:26:20.745905:  
2025-08-28 06:26:20.754247: Epoch 756 
2025-08-28 06:26:20.758426: Current learning rate: 0.00281 
2025-08-28 06:26:36.991766: train_loss -0.5444 
2025-08-28 06:26:36.999948: val_loss -0.6402 
2025-08-28 06:26:37.008625: Pseudo dice [np.float32(0.819)] 
2025-08-28 06:26:37.013582: Epoch time: 16.25 s 
2025-08-28 06:26:37.687823:  
2025-08-28 06:26:37.696167: Epoch 757 
2025-08-28 06:26:37.700370: Current learning rate: 0.0028 
2025-08-28 06:26:53.900237: train_loss -0.5239 
2025-08-28 06:26:53.912378: val_loss -0.5694 
2025-08-28 06:26:53.916528: Pseudo dice [np.float32(0.78)] 
2025-08-28 06:26:53.924671: Epoch time: 16.21 s 
2025-08-28 06:26:54.596377:  
2025-08-28 06:26:54.604750: Epoch 758 
2025-08-28 06:26:54.608981: Current learning rate: 0.00279 
2025-08-28 06:27:10.666647: train_loss -0.5129 
2025-08-28 06:27:10.678148: val_loss -0.6183 
2025-08-28 06:27:10.684204: Pseudo dice [np.float32(0.7942)] 
2025-08-28 06:27:10.689569: Epoch time: 16.07 s 
2025-08-28 06:27:11.363150:  
2025-08-28 06:27:11.371464: Epoch 759 
2025-08-28 06:27:11.380247: Current learning rate: 0.00278 
2025-08-28 06:27:27.637772: train_loss -0.5381 
2025-08-28 06:27:27.646043: val_loss -0.5361 
2025-08-28 06:27:27.654996: Pseudo dice [np.float32(0.7672)] 
2025-08-28 06:27:27.660708: Epoch time: 16.27 s 
2025-08-28 06:27:28.334251:  
2025-08-28 06:27:28.344141: Epoch 760 
2025-08-28 06:27:28.347082: Current learning rate: 0.00277 
2025-08-28 06:27:44.429483: train_loss -0.5324 
2025-08-28 06:27:44.438559: val_loss -0.5747 
2025-08-28 06:27:44.446190: Pseudo dice [np.float32(0.764)] 
2025-08-28 06:27:44.452554: Epoch time: 16.1 s 
2025-08-28 06:27:45.280391:  
2025-08-28 06:27:45.288771: Epoch 761 
2025-08-28 06:27:45.293147: Current learning rate: 0.00276 
2025-08-28 06:28:01.033601: train_loss -0.5498 
2025-08-28 06:28:01.046296: val_loss -0.6315 
2025-08-28 06:28:01.050310: Pseudo dice [np.float32(0.8355)] 
2025-08-28 06:28:01.058675: Epoch time: 15.76 s 
2025-08-28 06:28:01.734247:  
2025-08-28 06:28:01.742593: Epoch 762 
2025-08-28 06:28:01.750960: Current learning rate: 0.00275 
2025-08-28 06:28:17.612602: train_loss -0.552 
2025-08-28 06:28:17.620982: val_loss -0.5891 
2025-08-28 06:28:17.631094: Pseudo dice [np.float32(0.7728)] 
2025-08-28 06:28:17.637591: Epoch time: 15.88 s 
2025-08-28 06:28:18.325820:  
2025-08-28 06:28:18.336260: Epoch 763 
2025-08-28 06:28:18.342817: Current learning rate: 0.00274 
2025-08-28 06:28:34.363373: train_loss -0.5261 
2025-08-28 06:28:34.375246: val_loss -0.5918 
2025-08-28 06:28:34.379422: Pseudo dice [np.float32(0.7978)] 
2025-08-28 06:28:34.387699: Epoch time: 16.04 s 
2025-08-28 06:28:35.080055:  
2025-08-28 06:28:35.088396: Epoch 764 
2025-08-28 06:28:35.096762: Current learning rate: 0.00273 
2025-08-28 06:28:50.996401: train_loss -0.5381 
2025-08-28 06:28:51.008446: val_loss -0.5626 
2025-08-28 06:28:51.012985: Pseudo dice [np.float32(0.7945)] 
2025-08-28 06:28:51.021809: Epoch time: 15.92 s 
2025-08-28 06:28:51.705217:  
2025-08-28 06:28:51.713697: Epoch 765 
2025-08-28 06:28:51.717509: Current learning rate: 0.00272 
2025-08-28 06:29:08.108945: train_loss -0.537 
2025-08-28 06:29:08.117491: val_loss -0.5714 
2025-08-28 06:29:08.121693: Pseudo dice [np.float32(0.7993)] 
2025-08-28 06:29:08.130651: Epoch time: 16.4 s 
2025-08-28 06:29:08.822069:  
2025-08-28 06:29:08.830452: Epoch 766 
2025-08-28 06:29:08.835889: Current learning rate: 0.00271 
2025-08-28 06:29:24.705197: train_loss -0.5207 
2025-08-28 06:29:24.717160: val_loss -0.6074 
2025-08-28 06:29:24.721642: Pseudo dice [np.float32(0.7916)] 
2025-08-28 06:29:24.729513: Epoch time: 15.88 s 
2025-08-28 06:29:25.580307:  
2025-08-28 06:29:25.588995: Epoch 767 
2025-08-28 06:29:25.593438: Current learning rate: 0.0027 
2025-08-28 06:29:42.293566: train_loss -0.5389 
2025-08-28 06:29:42.301338: val_loss -0.585 
2025-08-28 06:29:42.310170: Pseudo dice [np.float32(0.7678)] 
2025-08-28 06:29:42.317263: Epoch time: 16.71 s 
2025-08-28 06:29:42.989529:  
2025-08-28 06:29:42.997871: Epoch 768 
2025-08-28 06:29:43.002406: Current learning rate: 0.00268 
2025-08-28 06:29:59.660420: train_loss -0.5543 
2025-08-28 06:29:59.673170: val_loss -0.4913 
2025-08-28 06:29:59.681574: Pseudo dice [np.float32(0.7762)] 
2025-08-28 06:29:59.687451: Epoch time: 16.67 s 
2025-08-28 06:30:00.369371:  
2025-08-28 06:30:00.377763: Epoch 769 
2025-08-28 06:30:00.381931: Current learning rate: 0.00267 
2025-08-28 06:30:17.173754: train_loss -0.5664 
2025-08-28 06:30:17.182045: val_loss -0.5915 
2025-08-28 06:30:17.190353: Pseudo dice [np.float32(0.764)] 
2025-08-28 06:30:17.196918: Epoch time: 16.8 s 
2025-08-28 06:30:17.886981:  
2025-08-28 06:30:17.895247: Epoch 770 
2025-08-28 06:30:17.899411: Current learning rate: 0.00266 
2025-08-28 06:30:34.558001: train_loss -0.5846 
2025-08-28 06:30:34.566333: val_loss -0.5093 
2025-08-28 06:30:34.570203: Pseudo dice [np.float32(0.7856)] 
2025-08-28 06:30:34.580052: Epoch time: 16.68 s 
2025-08-28 06:30:35.254225:  
2025-08-28 06:30:35.262560: Epoch 771 
2025-08-28 06:30:35.266756: Current learning rate: 0.00265 
2025-08-28 06:30:51.984558: train_loss -0.5416 
2025-08-28 06:30:51.996063: val_loss -0.5358 
2025-08-28 06:30:52.000157: Pseudo dice [np.float32(0.7372)] 
2025-08-28 06:30:52.009224: Epoch time: 16.73 s 
2025-08-28 06:30:52.692808:  
2025-08-28 06:30:52.700852: Epoch 772 
2025-08-28 06:30:52.705339: Current learning rate: 0.00264 
2025-08-28 06:31:09.546775: train_loss -0.5331 
2025-08-28 06:31:09.555134: val_loss -0.5824 
2025-08-28 06:31:09.559299: Pseudo dice [np.float32(0.7672)] 
2025-08-28 06:31:09.568570: Epoch time: 16.85 s 
2025-08-28 06:31:10.268620:  
2025-08-28 06:31:10.276697: Epoch 773 
2025-08-28 06:31:10.280921: Current learning rate: 0.00263 
2025-08-28 06:31:26.989519: train_loss -0.5137 
2025-08-28 06:31:26.997859: val_loss -0.5963 
2025-08-28 06:31:27.005637: Pseudo dice [np.float32(0.7955)] 
2025-08-28 06:31:27.011567: Epoch time: 16.72 s 
2025-08-28 06:31:27.856745:  
2025-08-28 06:31:27.865088: Epoch 774 
2025-08-28 06:31:27.869240: Current learning rate: 0.00262 
2025-08-28 06:31:44.414947: train_loss -0.5126 
2025-08-28 06:31:44.424003: val_loss -0.6242 
2025-08-28 06:31:44.431666: Pseudo dice [np.float32(0.7786)] 
2025-08-28 06:31:44.438024: Epoch time: 16.56 s 
2025-08-28 06:31:45.115684:  
2025-08-28 06:31:45.124032: Epoch 775 
2025-08-28 06:31:45.128161: Current learning rate: 0.00261 
2025-08-28 06:32:01.899479: train_loss -0.5392 
2025-08-28 06:32:01.911689: val_loss -0.5758 
2025-08-28 06:32:01.915756: Pseudo dice [np.float32(0.8021)] 
2025-08-28 06:32:01.923887: Epoch time: 16.79 s 
2025-08-28 06:32:02.612280:  
2025-08-28 06:32:02.616458: Epoch 776 
2025-08-28 06:32:02.624828: Current learning rate: 0.0026 
2025-08-28 06:32:19.350199: train_loss -0.5646 
2025-08-28 06:32:19.358435: val_loss -0.5177 
2025-08-28 06:32:19.366549: Pseudo dice [np.float32(0.7735)] 
2025-08-28 06:32:19.372720: Epoch time: 16.74 s 
2025-08-28 06:32:20.055141:  
2025-08-28 06:32:20.063148: Epoch 777 
2025-08-28 06:32:20.067560: Current learning rate: 0.00259 
2025-08-28 06:32:36.530327: train_loss -0.5704 
2025-08-28 06:32:36.537878: val_loss -0.5979 
2025-08-28 06:32:36.547004: Pseudo dice [np.float32(0.8121)] 
2025-08-28 06:32:36.553659: Epoch time: 16.48 s 
2025-08-28 06:32:37.234356:  
2025-08-28 06:32:37.243013: Epoch 778 
2025-08-28 06:32:37.246935: Current learning rate: 0.00258 
2025-08-28 06:32:54.047270: train_loss -0.4995 
2025-08-28 06:32:54.059549: val_loss -0.603 
2025-08-28 06:32:54.067851: Pseudo dice [np.float32(0.773)] 
2025-08-28 06:32:54.072852: Epoch time: 16.81 s 
2025-08-28 06:32:54.756012:  
2025-08-28 06:32:54.764396: Epoch 779 
2025-08-28 06:32:54.768790: Current learning rate: 0.00257 
2025-08-28 06:33:10.200864: train_loss -0.5299 
2025-08-28 06:33:10.209363: val_loss -0.6077 
2025-08-28 06:33:10.213445: Pseudo dice [np.float32(0.8237)] 
2025-08-28 06:33:10.221249: Epoch time: 15.45 s 
2025-08-28 06:33:11.068164:  
2025-08-28 06:33:11.076530: Epoch 780 
2025-08-28 06:33:11.080709: Current learning rate: 0.00256 
2025-08-28 06:33:26.738035: train_loss -0.5419 
2025-08-28 06:33:26.746281: val_loss -0.6002 
2025-08-28 06:33:26.750461: Pseudo dice [np.float32(0.8009)] 
2025-08-28 06:33:26.759641: Epoch time: 15.67 s 
2025-08-28 06:33:27.451464:  
2025-08-28 06:33:27.459532: Epoch 781 
2025-08-28 06:33:27.463682: Current learning rate: 0.00255 
2025-08-28 06:33:42.954345: train_loss -0.5522 
2025-08-28 06:33:42.962524: val_loss -0.5567 
2025-08-28 06:33:42.966666: Pseudo dice [np.float32(0.7816)] 
2025-08-28 06:33:42.975984: Epoch time: 15.5 s 
2025-08-28 06:33:43.650659:  
2025-08-28 06:33:43.659451: Epoch 782 
2025-08-28 06:33:43.663152: Current learning rate: 0.00254 
2025-08-28 06:33:59.258178: train_loss -0.5646 
2025-08-28 06:33:59.270470: val_loss -0.6254 
2025-08-28 06:33:59.274590: Pseudo dice [np.float32(0.7878)] 
2025-08-28 06:33:59.282985: Epoch time: 15.61 s 
2025-08-28 06:33:59.960713:  
2025-08-28 06:33:59.967624: Epoch 783 
2025-08-28 06:33:59.975351: Current learning rate: 0.00253 
2025-08-28 06:34:16.800447: train_loss -0.5449 
2025-08-28 06:34:16.809068: val_loss -0.6049 
2025-08-28 06:34:16.817675: Pseudo dice [np.float32(0.8307)] 
2025-08-28 06:34:16.822613: Epoch time: 16.84 s 
2025-08-28 06:34:17.520535:  
2025-08-28 06:34:17.526526: Epoch 784 
2025-08-28 06:34:17.530643: Current learning rate: 0.00252 
2025-08-28 06:34:34.501598: train_loss -0.5743 
2025-08-28 06:34:34.509797: val_loss -0.6021 
2025-08-28 06:34:34.514230: Pseudo dice [np.float32(0.7633)] 
2025-08-28 06:34:34.523623: Epoch time: 16.98 s 
2025-08-28 06:34:35.202146:  
2025-08-28 06:34:35.210498: Epoch 785 
2025-08-28 06:34:35.214702: Current learning rate: 0.00251 
2025-08-28 06:34:52.056485: train_loss -0.5635 
2025-08-28 06:34:52.064867: val_loss -0.6213 
2025-08-28 06:34:52.073208: Pseudo dice [np.float32(0.8083)] 
2025-08-28 06:34:52.078441: Epoch time: 16.85 s 
2025-08-28 06:34:52.757194:  
2025-08-28 06:34:52.765786: Epoch 786 
2025-08-28 06:34:52.773613: Current learning rate: 0.0025 
2025-08-28 06:35:09.574296: train_loss -0.5543 
2025-08-28 06:35:09.582317: val_loss -0.5316 
2025-08-28 06:35:09.590938: Pseudo dice [np.float32(0.7428)] 
2025-08-28 06:35:09.598217: Epoch time: 16.82 s 
2025-08-28 06:35:10.441519:  
2025-08-28 06:35:10.449905: Epoch 787 
2025-08-28 06:35:10.454306: Current learning rate: 0.00249 
2025-08-28 06:35:27.033077: train_loss -0.5824 
2025-08-28 06:35:27.041731: val_loss -0.5722 
2025-08-28 06:35:27.045900: Pseudo dice [np.float32(0.7745)] 
2025-08-28 06:35:27.053999: Epoch time: 16.6 s 
2025-08-28 06:35:27.729648:  
2025-08-28 06:35:27.738046: Epoch 788 
2025-08-28 06:35:27.742125: Current learning rate: 0.00248 
2025-08-28 06:35:44.401043: train_loss -0.559 
2025-08-28 06:35:44.412801: val_loss -0.5745 
2025-08-28 06:35:44.417439: Pseudo dice [np.float32(0.815)] 
2025-08-28 06:35:44.424409: Epoch time: 16.68 s 
2025-08-28 06:35:45.109855:  
2025-08-28 06:35:45.117845: Epoch 789 
2025-08-28 06:35:45.122023: Current learning rate: 0.00247 
2025-08-28 06:36:02.097249: train_loss -0.5373 
2025-08-28 06:36:02.110086: val_loss -0.5997 
2025-08-28 06:36:02.113926: Pseudo dice [np.float32(0.7711)] 
2025-08-28 06:36:02.123113: Epoch time: 16.99 s 
2025-08-28 06:36:02.803360:  
2025-08-28 06:36:02.812454: Epoch 790 
2025-08-28 06:36:02.818654: Current learning rate: 0.00245 
2025-08-28 06:36:19.760801: train_loss -0.5689 
2025-08-28 06:36:19.769068: val_loss -0.5584 
2025-08-28 06:36:19.773237: Pseudo dice [np.float32(0.7397)] 
2025-08-28 06:36:19.781402: Epoch time: 16.96 s 
2025-08-28 06:36:20.561524:  
2025-08-28 06:36:20.569866: Epoch 791 
2025-08-28 06:36:20.578545: Current learning rate: 0.00244 
2025-08-28 06:36:37.465910: train_loss -0.5231 
2025-08-28 06:36:37.476330: val_loss -0.5319 
2025-08-28 06:36:37.478335: Pseudo dice [np.float32(0.8102)] 
2025-08-28 06:36:37.487571: Epoch time: 16.9 s 
2025-08-28 06:36:38.162831:  
2025-08-28 06:36:38.170815: Epoch 792 
2025-08-28 06:36:38.175327: Current learning rate: 0.00243 
2025-08-28 06:36:55.004682: train_loss -0.5541 
2025-08-28 06:36:55.017119: val_loss -0.5985 
2025-08-28 06:36:55.025204: Pseudo dice [np.float32(0.8102)] 
2025-08-28 06:36:55.030654: Epoch time: 16.85 s 
2025-08-28 06:36:55.875966:  
2025-08-28 06:36:55.884296: Epoch 793 
2025-08-28 06:36:55.888812: Current learning rate: 0.00242 
2025-08-28 06:37:12.492511: train_loss -0.5315 
2025-08-28 06:37:12.500893: val_loss -0.6123 
2025-08-28 06:37:12.505260: Pseudo dice [np.float32(0.8026)] 
2025-08-28 06:37:12.514292: Epoch time: 16.62 s 
2025-08-28 06:37:13.197417:  
2025-08-28 06:37:13.205801: Epoch 794 
2025-08-28 06:37:13.210278: Current learning rate: 0.00241 
2025-08-28 06:37:30.018703: train_loss -0.5581 
2025-08-28 06:37:30.026732: val_loss -0.58 
2025-08-28 06:37:30.033163: Pseudo dice [np.float32(0.782)] 
2025-08-28 06:37:30.040748: Epoch time: 16.82 s 
2025-08-28 06:37:30.719109:  
2025-08-28 06:37:30.727467: Epoch 795 
2025-08-28 06:37:30.731878: Current learning rate: 0.0024 
2025-08-28 06:37:47.648502: train_loss -0.5522 
2025-08-28 06:37:47.657126: val_loss -0.5376 
2025-08-28 06:37:47.661093: Pseudo dice [np.float32(0.7392)] 
2025-08-28 06:37:47.670255: Epoch time: 16.93 s 
2025-08-28 06:37:48.349189:  
2025-08-28 06:37:48.357565: Epoch 796 
2025-08-28 06:37:48.361713: Current learning rate: 0.00239 
2025-08-28 06:38:04.932341: train_loss -0.5743 
2025-08-28 06:38:04.941056: val_loss -0.527 
2025-08-28 06:38:04.949141: Pseudo dice [np.float32(0.7932)] 
2025-08-28 06:38:04.956250: Epoch time: 16.58 s 
2025-08-28 06:38:05.637650:  
2025-08-28 06:38:05.645709: Epoch 797 
2025-08-28 06:38:05.653736: Current learning rate: 0.00238 
2025-08-28 06:38:22.517046: train_loss -0.5905 
2025-08-28 06:38:22.525025: val_loss -0.5181 
2025-08-28 06:38:22.529191: Pseudo dice [np.float32(0.7104)] 
2025-08-28 06:38:22.538373: Epoch time: 16.88 s 
2025-08-28 06:38:23.242403:  
2025-08-28 06:38:23.250756: Epoch 798 
2025-08-28 06:38:23.254888: Current learning rate: 0.00237 
2025-08-28 06:38:38.704214: train_loss -0.5557 
2025-08-28 06:38:38.712003: val_loss -0.5903 
2025-08-28 06:38:38.720317: Pseudo dice [np.float32(0.8061)] 
2025-08-28 06:38:38.727844: Epoch time: 15.47 s 
2025-08-28 06:38:39.433885:  
2025-08-28 06:38:39.441885: Epoch 799 
2025-08-28 06:38:39.446073: Current learning rate: 0.00236 
2025-08-28 06:38:55.074507: train_loss -0.5664 
2025-08-28 06:38:55.086700: val_loss -0.6658 
2025-08-28 06:38:55.090839: Pseudo dice [np.float32(0.8182)] 
2025-08-28 06:38:55.098147: Epoch time: 15.65 s 
2025-08-28 06:38:56.246513:  
2025-08-28 06:38:56.254536: Epoch 800 
2025-08-28 06:38:56.258676: Current learning rate: 0.00235 
2025-08-28 06:39:12.916969: train_loss -0.5559 
2025-08-28 06:39:12.929375: val_loss -0.6273 
2025-08-28 06:39:12.934020: Pseudo dice [np.float32(0.8047)] 
2025-08-28 06:39:12.942092: Epoch time: 16.67 s 
2025-08-28 06:39:13.630198:  
2025-08-28 06:39:13.638533: Epoch 801 
2025-08-28 06:39:13.642679: Current learning rate: 0.00234 
2025-08-28 06:39:30.572121: train_loss -0.5519 
2025-08-28 06:39:30.584508: val_loss -0.5227 
2025-08-28 06:39:30.589134: Pseudo dice [np.float32(0.7905)] 
2025-08-28 06:39:30.597035: Epoch time: 16.94 s 
2025-08-28 06:39:31.281146:  
2025-08-28 06:39:31.289563: Epoch 802 
2025-08-28 06:39:31.293893: Current learning rate: 0.00233 
2025-08-28 06:39:48.133310: train_loss -0.5372 
2025-08-28 06:39:48.139961: val_loss -0.4801 
2025-08-28 06:39:48.147997: Pseudo dice [np.float32(0.7188)] 
2025-08-28 06:39:48.155690: Epoch time: 16.85 s 
2025-08-28 06:39:48.841861:  
2025-08-28 06:39:48.848983: Epoch 803 
2025-08-28 06:39:48.852976: Current learning rate: 0.00232 
2025-08-28 06:40:05.716264: train_loss -0.5437 
2025-08-28 06:40:05.728148: val_loss -0.5979 
2025-08-28 06:40:05.736195: Pseudo dice [np.float32(0.7932)] 
2025-08-28 06:40:05.741894: Epoch time: 16.88 s 
2025-08-28 06:40:06.432950:  
2025-08-28 06:40:06.441311: Epoch 804 
2025-08-28 06:40:06.445420: Current learning rate: 0.00231 
2025-08-28 06:40:23.245586: train_loss -0.4959 
2025-08-28 06:40:23.253891: val_loss -0.5794 
2025-08-28 06:40:23.262252: Pseudo dice [np.float32(0.8107)] 
2025-08-28 06:40:23.268119: Epoch time: 16.82 s 
2025-08-28 06:40:23.950978:  
2025-08-28 06:40:23.960773: Epoch 805 
2025-08-28 06:40:23.965242: Current learning rate: 0.0023 
2025-08-28 06:40:40.915969: train_loss -0.5606 
2025-08-28 06:40:40.921882: val_loss -0.5349 
2025-08-28 06:40:40.929864: Pseudo dice [np.float32(0.7984)] 
2025-08-28 06:40:40.937244: Epoch time: 16.96 s 
2025-08-28 06:40:41.764360:  
2025-08-28 06:40:41.772439: Epoch 806 
2025-08-28 06:40:41.780385: Current learning rate: 0.00229 
2025-08-28 06:40:58.138738: train_loss -0.5483 
2025-08-28 06:40:58.151257: val_loss -0.5675 
2025-08-28 06:40:58.159564: Pseudo dice [np.float32(0.7832)] 
2025-08-28 06:40:58.164980: Epoch time: 16.37 s 
2025-08-28 06:40:58.852256:  
2025-08-28 06:40:58.860266: Epoch 807 
2025-08-28 06:40:58.864468: Current learning rate: 0.00228 
2025-08-28 06:41:15.348373: train_loss -0.5968 
2025-08-28 06:41:15.355934: val_loss -0.5836 
2025-08-28 06:41:15.360084: Pseudo dice [np.float32(0.7309)] 
2025-08-28 06:41:15.368439: Epoch time: 16.5 s 
2025-08-28 06:41:16.056623:  
2025-08-28 06:41:16.064931: Epoch 808 
2025-08-28 06:41:16.069118: Current learning rate: 0.00226 
2025-08-28 06:41:32.519920: train_loss -0.5717 
2025-08-28 06:41:32.527571: val_loss -0.5784 
2025-08-28 06:41:32.535571: Pseudo dice [np.float32(0.816)] 
2025-08-28 06:41:32.541181: Epoch time: 16.47 s 
2025-08-28 06:41:33.228297:  
2025-08-28 06:41:33.236258: Epoch 809 
2025-08-28 06:41:33.240877: Current learning rate: 0.00225 
2025-08-28 06:41:49.790563: train_loss -0.5365 
2025-08-28 06:41:49.798665: val_loss -0.5787 
2025-08-28 06:41:49.807008: Pseudo dice [np.float32(0.7174)] 
2025-08-28 06:41:49.812500: Epoch time: 16.56 s 
2025-08-28 06:41:50.507714:  
2025-08-28 06:41:50.516024: Epoch 810 
2025-08-28 06:41:50.520534: Current learning rate: 0.00224 
2025-08-28 06:42:07.099232: train_loss -0.5486 
2025-08-28 06:42:07.111765: val_loss -0.6025 
2025-08-28 06:42:07.115919: Pseudo dice [np.float32(0.7713)] 
2025-08-28 06:42:07.124224: Epoch time: 16.59 s 
2025-08-28 06:42:07.812198:  
2025-08-28 06:42:07.820839: Epoch 811 
2025-08-28 06:42:07.824964: Current learning rate: 0.00223 
2025-08-28 06:42:24.049487: train_loss -0.547 
2025-08-28 06:42:24.058261: val_loss -0.5971 
2025-08-28 06:42:24.066183: Pseudo dice [np.float32(0.8182)] 
2025-08-28 06:42:24.072168: Epoch time: 16.24 s 
2025-08-28 06:42:24.912926:  
2025-08-28 06:42:24.921275: Epoch 812 
2025-08-28 06:42:24.925408: Current learning rate: 0.00222 
2025-08-28 06:42:41.713284: train_loss -0.5796 
2025-08-28 06:42:41.721313: val_loss -0.5104 
2025-08-28 06:42:41.729659: Pseudo dice [np.float32(0.7653)] 
2025-08-28 06:42:41.736295: Epoch time: 16.8 s 
2025-08-28 06:42:42.422004:  
2025-08-28 06:42:42.430393: Epoch 813 
2025-08-28 06:42:42.438815: Current learning rate: 0.00221 
2025-08-28 06:42:58.980579: train_loss -0.5678 
2025-08-28 06:42:58.992765: val_loss -0.5342 
2025-08-28 06:42:58.996929: Pseudo dice [np.float32(0.7771)] 
2025-08-28 06:42:59.005057: Epoch time: 16.56 s 
2025-08-28 06:42:59.689254:  
2025-08-28 06:42:59.693423: Epoch 814 
2025-08-28 06:42:59.701850: Current learning rate: 0.0022 
2025-08-28 06:43:16.439318: train_loss -0.5402 
2025-08-28 06:43:16.448027: val_loss -0.5691 
2025-08-28 06:43:16.452206: Pseudo dice [np.float32(0.7866)] 
2025-08-28 06:43:16.461379: Epoch time: 16.75 s 
2025-08-28 06:43:17.148408:  
2025-08-28 06:43:17.156736: Epoch 815 
2025-08-28 06:43:17.160909: Current learning rate: 0.00219 
2025-08-28 06:43:33.910913: train_loss -0.5713 
2025-08-28 06:43:33.919272: val_loss -0.5914 
2025-08-28 06:43:33.923446: Pseudo dice [np.float32(0.7847)] 
2025-08-28 06:43:33.932573: Epoch time: 16.76 s 
2025-08-28 06:43:34.616071:  
2025-08-28 06:43:34.620060: Epoch 816 
2025-08-28 06:43:34.628402: Current learning rate: 0.00218 
2025-08-28 06:43:51.357527: train_loss -0.5656 
2025-08-28 06:43:51.365859: val_loss -0.6098 
2025-08-28 06:43:51.374241: Pseudo dice [np.float32(0.8447)] 
2025-08-28 06:43:51.380317: Epoch time: 16.75 s 
2025-08-28 06:43:52.091588:  
2025-08-28 06:43:52.100378: Epoch 817 
2025-08-28 06:43:52.104070: Current learning rate: 0.00217 
2025-08-28 06:44:08.116381: train_loss -0.5507 
2025-08-28 06:44:08.124247: val_loss -0.6057 
2025-08-28 06:44:08.132997: Pseudo dice [np.float32(0.8075)] 
2025-08-28 06:44:08.140302: Epoch time: 16.02 s 
2025-08-28 06:44:08.834713:  
2025-08-28 06:44:08.842919: Epoch 818 
2025-08-28 06:44:08.846064: Current learning rate: 0.00216 
2025-08-28 06:44:25.241410: train_loss -0.5638 
2025-08-28 06:44:25.249775: val_loss -0.5142 
2025-08-28 06:44:25.254186: Pseudo dice [np.float32(0.7362)] 
2025-08-28 06:44:25.262036: Epoch time: 16.41 s 
2025-08-28 06:44:26.117397:  
2025-08-28 06:44:26.125571: Epoch 819 
2025-08-28 06:44:26.134218: Current learning rate: 0.00215 
2025-08-28 06:44:42.350434: train_loss -0.5625 
2025-08-28 06:44:42.358446: val_loss -0.5343 
2025-08-28 06:44:42.366822: Pseudo dice [np.float32(0.7809)] 
2025-08-28 06:44:42.371781: Epoch time: 16.23 s 
2025-08-28 06:44:43.034128:  
2025-08-28 06:44:43.042578: Epoch 820 
2025-08-28 06:44:43.050827: Current learning rate: 0.00214 
2025-08-28 06:44:59.463037: train_loss -0.5862 
2025-08-28 06:44:59.475917: val_loss -0.6099 
2025-08-28 06:44:59.483918: Pseudo dice [np.float32(0.779)] 
2025-08-28 06:44:59.490422: Epoch time: 16.43 s 
2025-08-28 06:45:00.155389:  
2025-08-28 06:45:00.164012: Epoch 821 
2025-08-28 06:45:00.168195: Current learning rate: 0.00213 
2025-08-28 06:45:16.963878: train_loss -0.5863 
2025-08-28 06:45:16.972407: val_loss -0.5913 
2025-08-28 06:45:16.980500: Pseudo dice [np.float32(0.7511)] 
2025-08-28 06:45:16.986666: Epoch time: 16.81 s 
2025-08-28 06:45:17.644005:  
2025-08-28 06:45:17.652140: Epoch 822 
2025-08-28 06:45:17.656265: Current learning rate: 0.00212 
2025-08-28 06:45:34.293789: train_loss -0.5542 
2025-08-28 06:45:34.302274: val_loss -0.6418 
2025-08-28 06:45:34.310036: Pseudo dice [np.float32(0.8075)] 
2025-08-28 06:45:34.316030: Epoch time: 16.65 s 
2025-08-28 06:45:34.990158:  
2025-08-28 06:45:34.998551: Epoch 823 
2025-08-28 06:45:35.004915: Current learning rate: 0.0021 
2025-08-28 06:45:51.761098: train_loss -0.5603 
2025-08-28 06:45:51.773681: val_loss -0.5644 
2025-08-28 06:45:51.777819: Pseudo dice [np.float32(0.7731)] 
2025-08-28 06:45:51.787604: Epoch time: 16.77 s 
2025-08-28 06:45:52.448956:  
2025-08-28 06:45:52.453513: Epoch 824 
2025-08-28 06:45:52.461791: Current learning rate: 0.00209 
2025-08-28 06:46:09.216303: train_loss -0.5757 
2025-08-28 06:46:09.224423: val_loss -0.5734 
2025-08-28 06:46:09.232778: Pseudo dice [np.float32(0.7641)] 
2025-08-28 06:46:09.238157: Epoch time: 16.77 s 
2025-08-28 06:46:10.050203:  
2025-08-28 06:46:10.058503: Epoch 825 
2025-08-28 06:46:10.062704: Current learning rate: 0.00208 
2025-08-28 06:46:26.971313: train_loss -0.5504 
2025-08-28 06:46:26.983653: val_loss -0.6065 
2025-08-28 06:46:26.988173: Pseudo dice [np.float32(0.8298)] 
2025-08-28 06:46:26.995525: Epoch time: 16.93 s 
2025-08-28 06:46:27.651137:  
2025-08-28 06:46:27.659431: Epoch 826 
2025-08-28 06:46:27.667808: Current learning rate: 0.00207 
2025-08-28 06:46:44.230161: train_loss -0.5939 
2025-08-28 06:46:44.238936: val_loss -0.5925 
2025-08-28 06:46:44.246889: Pseudo dice [np.float32(0.843)] 
2025-08-28 06:46:44.253077: Epoch time: 16.58 s 
2025-08-28 06:46:44.909978:  
2025-08-28 06:46:44.918342: Epoch 827 
2025-08-28 06:46:44.926714: Current learning rate: 0.00206 
2025-08-28 06:47:01.860564: train_loss -0.5719 
2025-08-28 06:47:01.873133: val_loss -0.6229 
2025-08-28 06:47:01.876934: Pseudo dice [np.float32(0.7794)] 
2025-08-28 06:47:01.885283: Epoch time: 16.95 s 
2025-08-28 06:47:02.540135:  
2025-08-28 06:47:02.548528: Epoch 828 
2025-08-28 06:47:02.553100: Current learning rate: 0.00205 
2025-08-28 06:47:19.090234: train_loss -0.5548 
2025-08-28 06:47:19.098631: val_loss -0.5508 
2025-08-28 06:47:19.106637: Pseudo dice [np.float32(0.7677)] 
2025-08-28 06:47:19.112983: Epoch time: 16.55 s 
2025-08-28 06:47:19.773978:  
2025-08-28 06:47:19.782471: Epoch 829 
2025-08-28 06:47:19.786477: Current learning rate: 0.00204 
2025-08-28 06:47:36.645026: train_loss -0.5861 
2025-08-28 06:47:36.653666: val_loss -0.525 
2025-08-28 06:47:36.657848: Pseudo dice [np.float32(0.7736)] 
2025-08-28 06:47:36.666696: Epoch time: 16.88 s 
2025-08-28 06:47:37.329212:  
2025-08-28 06:47:37.338773: Epoch 830 
2025-08-28 06:47:37.345060: Current learning rate: 0.00203 
2025-08-28 06:47:53.849744: train_loss -0.5767 
2025-08-28 06:47:53.862183: val_loss -0.5169 
2025-08-28 06:47:53.866678: Pseudo dice [np.float32(0.7039)] 
2025-08-28 06:47:53.875505: Epoch time: 16.52 s 
2025-08-28 06:47:54.554519:  
2025-08-28 06:47:54.567052: Epoch 831 
2025-08-28 06:47:54.571211: Current learning rate: 0.00202 
2025-08-28 06:48:11.296258: train_loss -0.5474 
2025-08-28 06:48:11.304596: val_loss -0.6035 
2025-08-28 06:48:11.312945: Pseudo dice [np.float32(0.83)] 
2025-08-28 06:48:11.319219: Epoch time: 16.74 s 
2025-08-28 06:48:12.134568:  
2025-08-28 06:48:12.142938: Epoch 832 
2025-08-28 06:48:12.147078: Current learning rate: 0.00201 
2025-08-28 06:48:28.634726: train_loss -0.5845 
2025-08-28 06:48:28.643039: val_loss -0.6562 
2025-08-28 06:48:28.647189: Pseudo dice [np.float32(0.8651)] 
2025-08-28 06:48:28.654386: Epoch time: 16.5 s 
2025-08-28 06:48:29.314236:  
2025-08-28 06:48:29.324840: Epoch 833 
2025-08-28 06:48:29.330931: Current learning rate: 0.002 
2025-08-28 06:48:45.876611: train_loss -0.5835 
2025-08-28 06:48:45.885746: val_loss -0.603 
2025-08-28 06:48:45.893512: Pseudo dice [np.float32(0.7949)] 
2025-08-28 06:48:45.899576: Epoch time: 16.56 s 
2025-08-28 06:48:46.556719:  
2025-08-28 06:48:46.564805: Epoch 834 
2025-08-28 06:48:46.569015: Current learning rate: 0.00199 
2025-08-28 06:49:03.135611: train_loss -0.5513 
2025-08-28 06:49:03.148111: val_loss -0.5882 
2025-08-28 06:49:03.152448: Pseudo dice [np.float32(0.8109)] 
2025-08-28 06:49:03.160563: Epoch time: 16.58 s 
2025-08-28 06:49:03.167201: Yayy! New best EMA pseudo Dice: 0.79339998960495 
2025-08-28 06:49:04.015564:  
2025-08-28 06:49:04.023885: Epoch 835 
2025-08-28 06:49:04.028255: Current learning rate: 0.00198 
2025-08-28 06:49:20.708443: train_loss -0.5696 
2025-08-28 06:49:20.715628: val_loss -0.5932 
2025-08-28 06:49:20.723917: Pseudo dice [np.float32(0.8343)] 
2025-08-28 06:49:20.730154: Epoch time: 16.7 s 
2025-08-28 06:49:20.736763: Yayy! New best EMA pseudo Dice: 0.7975000143051147 
2025-08-28 06:49:21.575104:  
2025-08-28 06:49:21.583195: Epoch 836 
2025-08-28 06:49:21.587312: Current learning rate: 0.00196 
2025-08-28 06:49:37.819826: train_loss -0.5773 
2025-08-28 06:49:37.828577: val_loss -0.621 
2025-08-28 06:49:37.834221: Pseudo dice [np.float32(0.8175)] 
2025-08-28 06:49:37.840696: Epoch time: 16.25 s 
2025-08-28 06:49:37.847728: Yayy! New best EMA pseudo Dice: 0.7994999885559082 
2025-08-28 06:49:38.683505:  
2025-08-28 06:49:38.691858: Epoch 837 
2025-08-28 06:49:38.696029: Current learning rate: 0.00195 
2025-08-28 06:49:54.962362: train_loss -0.5844 
2025-08-28 06:49:54.970677: val_loss -0.5694 
2025-08-28 06:49:54.979018: Pseudo dice [np.float32(0.8024)] 
2025-08-28 06:49:54.985206: Epoch time: 16.28 s 
2025-08-28 06:49:54.991893: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-08-28 06:49:55.825629:  
2025-08-28 06:49:55.836475: Epoch 838 
2025-08-28 06:49:55.842834: Current learning rate: 0.00194 
2025-08-28 06:50:11.895947: train_loss -0.5668 
2025-08-28 06:50:11.904438: val_loss -0.5419 
2025-08-28 06:50:11.912517: Pseudo dice [np.float32(0.8047)] 
2025-08-28 06:50:11.918743: Epoch time: 16.07 s 
2025-08-28 06:50:11.925546: Yayy! New best EMA pseudo Dice: 0.8003000020980835 
2025-08-28 06:50:12.921918:  
2025-08-28 06:50:12.930503: Epoch 839 
2025-08-28 06:50:12.934364: Current learning rate: 0.00193 
2025-08-28 06:50:28.996633: train_loss -0.5482 
2025-08-28 06:50:29.004582: val_loss -0.5059 
2025-08-28 06:50:29.012935: Pseudo dice [np.float32(0.741)] 
2025-08-28 06:50:29.017951: Epoch time: 16.07 s 
2025-08-28 06:50:29.676078:  
2025-08-28 06:50:29.684459: Epoch 840 
2025-08-28 06:50:29.692791: Current learning rate: 0.00192 
2025-08-28 06:50:46.021613: train_loss -0.5714 
2025-08-28 06:50:46.030337: val_loss -0.5549 
2025-08-28 06:50:46.034090: Pseudo dice [np.float32(0.8017)] 
2025-08-28 06:50:46.043268: Epoch time: 16.35 s 
2025-08-28 06:50:46.709510:  
2025-08-28 06:50:46.713964: Epoch 841 
2025-08-28 06:50:46.722296: Current learning rate: 0.00191 
2025-08-28 06:51:02.650676: train_loss -0.5401 
2025-08-28 06:51:02.659042: val_loss -0.5821 
2025-08-28 06:51:02.668923: Pseudo dice [np.float32(0.8068)] 
2025-08-28 06:51:02.673613: Epoch time: 15.95 s 
2025-08-28 06:51:03.344537:  
2025-08-28 06:51:03.351581: Epoch 842 
2025-08-28 06:51:03.355935: Current learning rate: 0.0019 
2025-08-28 06:51:19.922530: train_loss -0.5737 
2025-08-28 06:51:19.930465: val_loss -0.5769 
2025-08-28 06:51:19.938788: Pseudo dice [np.float32(0.7765)] 
2025-08-28 06:51:19.944326: Epoch time: 16.58 s 
2025-08-28 06:51:20.606109:  
2025-08-28 06:51:20.614478: Epoch 843 
2025-08-28 06:51:20.622813: Current learning rate: 0.00189 
2025-08-28 06:51:36.764226: train_loss -0.5736 
2025-08-28 06:51:36.772263: val_loss -0.591 
2025-08-28 06:51:36.776823: Pseudo dice [np.float32(0.8004)] 
2025-08-28 06:51:36.785721: Epoch time: 16.16 s 
2025-08-28 06:51:37.443763:  
2025-08-28 06:51:37.452108: Epoch 844 
2025-08-28 06:51:37.456286: Current learning rate: 0.00188 
2025-08-28 06:51:54.406777: train_loss -0.5844 
2025-08-28 06:51:54.414908: val_loss -0.6466 
2025-08-28 06:51:54.423224: Pseudo dice [np.float32(0.811)] 
2025-08-28 06:51:54.430475: Epoch time: 16.97 s 
2025-08-28 06:51:55.232399:  
2025-08-28 06:51:55.240714: Epoch 845 
2025-08-28 06:51:55.244876: Current learning rate: 0.00187 
2025-08-28 06:52:12.029479: train_loss -0.5531 
2025-08-28 06:52:12.036986: val_loss -0.5712 
2025-08-28 06:52:12.044997: Pseudo dice [np.float32(0.8046)] 
2025-08-28 06:52:12.051455: Epoch time: 16.8 s 
2025-08-28 06:52:12.704010:  
2025-08-28 06:52:12.712327: Epoch 846 
2025-08-28 06:52:12.716491: Current learning rate: 0.00186 
2025-08-28 06:52:29.862816: train_loss -0.5684 
2025-08-28 06:52:29.871130: val_loss -0.5498 
2025-08-28 06:52:29.879472: Pseudo dice [np.float32(0.7557)] 
2025-08-28 06:52:29.885037: Epoch time: 17.16 s 
2025-08-28 06:52:30.546799:  
2025-08-28 06:52:30.555150: Epoch 847 
2025-08-28 06:52:30.559302: Current learning rate: 0.00185 
2025-08-28 06:52:47.263878: train_loss -0.5522 
2025-08-28 06:52:47.271824: val_loss -0.6656 
2025-08-28 06:52:47.280169: Pseudo dice [np.float32(0.7986)] 
2025-08-28 06:52:47.285125: Epoch time: 16.72 s 
2025-08-28 06:52:47.955859:  
2025-08-28 06:52:47.964539: Epoch 848 
2025-08-28 06:52:47.968385: Current learning rate: 0.00184 
2025-08-28 06:53:03.538094: train_loss -0.5663 
2025-08-28 06:53:03.550933: val_loss -0.5341 
2025-08-28 06:53:03.555026: Pseudo dice [np.float32(0.7319)] 
2025-08-28 06:53:03.563078: Epoch time: 15.59 s 
2025-08-28 06:53:04.221411:  
2025-08-28 06:53:04.229264: Epoch 849 
2025-08-28 06:53:04.235596: Current learning rate: 0.00182 
2025-08-28 06:53:19.879390: train_loss -0.5877 
2025-08-28 06:53:19.891989: val_loss -0.5451 
2025-08-28 06:53:19.896561: Pseudo dice [np.float32(0.7475)] 
2025-08-28 06:53:19.904361: Epoch time: 15.66 s 
2025-08-28 06:53:20.738888:  
2025-08-28 06:53:20.746918: Epoch 850 
2025-08-28 06:53:20.751335: Current learning rate: 0.00181 
2025-08-28 06:53:37.784791: train_loss -0.6064 
2025-08-28 06:53:37.797640: val_loss -0.5879 
2025-08-28 06:53:37.801474: Pseudo dice [np.float32(0.7618)] 
2025-08-28 06:53:37.809656: Epoch time: 17.05 s 
2025-08-28 06:53:38.464682:  
2025-08-28 06:53:38.473196: Epoch 851 
2025-08-28 06:53:38.477192: Current learning rate: 0.0018 
2025-08-28 06:53:55.202822: train_loss -0.5543 
2025-08-28 06:53:55.214674: val_loss -0.5366 
2025-08-28 06:53:55.219088: Pseudo dice [np.float32(0.8359)] 
2025-08-28 06:53:55.228056: Epoch time: 16.74 s 
2025-08-28 06:53:56.040519:  
2025-08-28 06:53:56.044685: Epoch 852 
2025-08-28 06:53:56.053048: Current learning rate: 0.00179 
2025-08-28 06:54:12.690452: train_loss -0.5992 
2025-08-28 06:54:12.698813: val_loss -0.6357 
2025-08-28 06:54:12.702984: Pseudo dice [np.float32(0.8496)] 
2025-08-28 06:54:12.711443: Epoch time: 16.65 s 
2025-08-28 06:54:13.361977:  
2025-08-28 06:54:13.371015: Epoch 853 
2025-08-28 06:54:13.374962: Current learning rate: 0.00178 
2025-08-28 06:54:29.249007: train_loss -0.5564 
2025-08-28 06:54:29.261176: val_loss -0.6328 
2025-08-28 06:54:29.265563: Pseudo dice [np.float32(0.8185)] 
2025-08-28 06:54:29.274561: Epoch time: 15.89 s 
2025-08-28 06:54:29.928521:  
2025-08-28 06:54:29.936862: Epoch 854 
2025-08-28 06:54:29.941040: Current learning rate: 0.00177 
2025-08-28 06:54:46.386600: train_loss -0.5688 
2025-08-28 06:54:46.394993: val_loss -0.6048 
2025-08-28 06:54:46.399152: Pseudo dice [np.float32(0.7969)] 
2025-08-28 06:54:46.407286: Epoch time: 16.46 s 
2025-08-28 06:54:47.070796:  
2025-08-28 06:54:47.078589: Epoch 855 
2025-08-28 06:54:47.083154: Current learning rate: 0.00176 
2025-08-28 06:55:03.758545: train_loss -0.5824 
2025-08-28 06:55:03.770669: val_loss -0.5167 
2025-08-28 06:55:03.775181: Pseudo dice [np.float32(0.7909)] 
2025-08-28 06:55:03.783952: Epoch time: 16.69 s 
2025-08-28 06:55:04.446330:  
2025-08-28 06:55:04.454699: Epoch 856 
2025-08-28 06:55:04.459201: Current learning rate: 0.00175 
2025-08-28 06:55:21.417471: train_loss -0.6048 
2025-08-28 06:55:21.426074: val_loss -0.5897 
2025-08-28 06:55:21.429938: Pseudo dice [np.float32(0.7832)] 
2025-08-28 06:55:21.439093: Epoch time: 16.97 s 
2025-08-28 06:55:22.084786:  
2025-08-28 06:55:22.093146: Epoch 857 
2025-08-28 06:55:22.097278: Current learning rate: 0.00174 
2025-08-28 06:55:38.930738: train_loss -0.5941 
2025-08-28 06:55:38.939118: val_loss -0.6212 
2025-08-28 06:55:38.943257: Pseudo dice [np.float32(0.8081)] 
2025-08-28 06:55:38.951609: Epoch time: 16.85 s 
2025-08-28 06:55:39.598140:  
2025-08-28 06:55:39.606699: Epoch 858 
2025-08-28 06:55:39.610653: Current learning rate: 0.00173 
2025-08-28 06:55:56.502807: train_loss -0.5712 
2025-08-28 06:55:56.510844: val_loss -0.6129 
2025-08-28 06:55:56.519155: Pseudo dice [np.float32(0.7998)] 
2025-08-28 06:55:56.526348: Epoch time: 16.9 s 
2025-08-28 06:55:57.332644:  
2025-08-28 06:55:57.342608: Epoch 859 
2025-08-28 06:55:57.345320: Current learning rate: 0.00172 
2025-08-28 06:56:14.024159: train_loss -0.5756 
2025-08-28 06:56:14.032507: val_loss -0.631 
2025-08-28 06:56:14.036977: Pseudo dice [np.float32(0.7987)] 
2025-08-28 06:56:14.044757: Epoch time: 16.7 s 
2025-08-28 06:56:14.695724:  
2025-08-28 06:56:14.703992: Epoch 860 
2025-08-28 06:56:14.708183: Current learning rate: 0.0017 
2025-08-28 06:56:31.474873: train_loss -0.6043 
2025-08-28 06:56:31.483234: val_loss -0.5934 
2025-08-28 06:56:31.487399: Pseudo dice [np.float32(0.7541)] 
2025-08-28 06:56:31.496597: Epoch time: 16.78 s 
2025-08-28 06:56:32.138085:  
2025-08-28 06:56:32.146435: Epoch 861 
2025-08-28 06:56:32.150574: Current learning rate: 0.00169 
2025-08-28 06:56:48.420969: train_loss -0.5726 
2025-08-28 06:56:48.433488: val_loss -0.5928 
2025-08-28 06:56:48.437659: Pseudo dice [np.float32(0.7807)] 
2025-08-28 06:56:48.446800: Epoch time: 16.28 s 
2025-08-28 06:56:49.092524:  
2025-08-28 06:56:49.101103: Epoch 862 
2025-08-28 06:56:49.109177: Current learning rate: 0.00168 
2025-08-28 06:57:06.059812: train_loss -0.5293 
2025-08-28 06:57:06.067770: val_loss -0.5817 
2025-08-28 06:57:06.076455: Pseudo dice [np.float32(0.7766)] 
2025-08-28 06:57:06.082247: Epoch time: 16.97 s 
2025-08-28 06:57:06.726741:  
2025-08-28 06:57:06.735123: Epoch 863 
2025-08-28 06:57:06.739542: Current learning rate: 0.00167 
2025-08-28 06:57:23.201529: train_loss -0.5902 
2025-08-28 06:57:23.209885: val_loss -0.5717 
2025-08-28 06:57:23.214052: Pseudo dice [np.float32(0.8264)] 
2025-08-28 06:57:23.223612: Epoch time: 16.47 s 
2025-08-28 06:57:23.873038:  
2025-08-28 06:57:23.877233: Epoch 864 
2025-08-28 06:57:23.885590: Current learning rate: 0.00166 
2025-08-28 06:57:40.744620: train_loss -0.5859 
2025-08-28 06:57:40.752407: val_loss -0.5838 
2025-08-28 06:57:40.760849: Pseudo dice [np.float32(0.8057)] 
2025-08-28 06:57:40.766967: Epoch time: 16.88 s 
2025-08-28 06:57:41.424274:  
2025-08-28 06:57:41.432276: Epoch 865 
2025-08-28 06:57:41.436449: Current learning rate: 0.00165 
2025-08-28 06:57:58.169772: train_loss -0.584 
2025-08-28 06:57:58.178166: val_loss -0.612 
2025-08-28 06:57:58.186480: Pseudo dice [np.float32(0.8075)] 
2025-08-28 06:57:58.191861: Epoch time: 16.75 s 
2025-08-28 06:57:58.862160:  
2025-08-28 06:57:58.870523: Epoch 866 
2025-08-28 06:57:58.874671: Current learning rate: 0.00164 
2025-08-28 06:58:15.466587: train_loss -0.59 
2025-08-28 06:58:15.474854: val_loss -0.6249 
2025-08-28 06:58:15.483024: Pseudo dice [np.float32(0.8053)] 
2025-08-28 06:58:15.488502: Epoch time: 16.6 s 
2025-08-28 06:58:16.325774:  
2025-08-28 06:58:16.329597: Epoch 867 
2025-08-28 06:58:16.339409: Current learning rate: 0.00163 
2025-08-28 06:58:32.891967: train_loss -0.5703 
2025-08-28 06:58:32.900344: val_loss -0.5967 
2025-08-28 06:58:32.908644: Pseudo dice [np.float32(0.7818)] 
2025-08-28 06:58:32.914831: Epoch time: 16.57 s 
2025-08-28 06:58:33.563465:  
2025-08-28 06:58:33.572135: Epoch 868 
2025-08-28 06:58:33.575984: Current learning rate: 0.00162 
2025-08-28 06:58:50.251012: train_loss -0.5996 
2025-08-28 06:58:50.263583: val_loss -0.5858 
2025-08-28 06:58:50.272091: Pseudo dice [np.float32(0.7954)] 
2025-08-28 06:58:50.279069: Epoch time: 16.69 s 
2025-08-28 06:58:50.947489:  
2025-08-28 06:58:50.960013: Epoch 869 
2025-08-28 06:58:50.968359: Current learning rate: 0.00161 
2025-08-28 06:59:07.447359: train_loss -0.6013 
2025-08-28 06:59:07.455648: val_loss -0.5913 
2025-08-28 06:59:07.464003: Pseudo dice [np.float32(0.8111)] 
2025-08-28 06:59:07.470627: Epoch time: 16.5 s 
2025-08-28 06:59:08.118850:  
2025-08-28 06:59:08.127526: Epoch 870 
2025-08-28 06:59:08.131610: Current learning rate: 0.00159 
2025-08-28 06:59:24.760708: train_loss -0.6112 
2025-08-28 06:59:24.769070: val_loss -0.6333 
2025-08-28 06:59:24.777174: Pseudo dice [np.float32(0.8271)] 
2025-08-28 06:59:24.783458: Epoch time: 16.64 s 
2025-08-28 06:59:25.436130:  
2025-08-28 06:59:25.440460: Epoch 871 
2025-08-28 06:59:25.448709: Current learning rate: 0.00158 
2025-08-28 06:59:42.106981: train_loss -0.5996 
2025-08-28 06:59:42.115256: val_loss -0.5457 
2025-08-28 06:59:42.123611: Pseudo dice [np.float32(0.7467)] 
2025-08-28 06:59:42.129982: Epoch time: 16.68 s 
2025-08-28 06:59:42.778191:  
2025-08-28 06:59:42.782622: Epoch 872 
2025-08-28 06:59:42.790945: Current learning rate: 0.00157 
2025-08-28 06:59:59.691126: train_loss -0.5714 
2025-08-28 06:59:59.704038: val_loss -0.5758 
2025-08-28 06:59:59.708153: Pseudo dice [np.float32(0.8193)] 
2025-08-28 06:59:59.716021: Epoch time: 16.92 s 
2025-08-28 07:00:00.371026:  
2025-08-28 07:00:00.379357: Epoch 873 
2025-08-28 07:00:00.387722: Current learning rate: 0.00156 
2025-08-28 07:00:17.075184: train_loss -0.5721 
2025-08-28 07:00:17.083508: val_loss -0.5988 
2025-08-28 07:00:17.087693: Pseudo dice [np.float32(0.7337)] 
2025-08-28 07:00:17.095901: Epoch time: 16.7 s 
2025-08-28 07:00:17.897232:  
2025-08-28 07:00:17.905242: Epoch 874 
2025-08-28 07:00:17.909431: Current learning rate: 0.00155 
2025-08-28 07:00:34.613863: train_loss -0.5418 
2025-08-28 07:00:34.621853: val_loss -0.576 
2025-08-28 07:00:34.630590: Pseudo dice [np.float32(0.7832)] 
2025-08-28 07:00:34.635836: Epoch time: 16.72 s 
2025-08-28 07:00:35.289179:  
2025-08-28 07:00:35.293365: Epoch 875 
2025-08-28 07:00:35.301707: Current learning rate: 0.00154 
2025-08-28 07:00:51.797439: train_loss -0.5735 
2025-08-28 07:00:51.809845: val_loss -0.6087 
2025-08-28 07:00:51.813930: Pseudo dice [np.float32(0.8084)] 
2025-08-28 07:00:51.823730: Epoch time: 16.51 s 
2025-08-28 07:00:52.468888:  
2025-08-28 07:00:52.477244: Epoch 876 
2025-08-28 07:00:52.481432: Current learning rate: 0.00153 
2025-08-28 07:01:08.743486: train_loss -0.5811 
2025-08-28 07:01:08.751810: val_loss -0.5845 
2025-08-28 07:01:08.760130: Pseudo dice [np.float32(0.8294)] 
2025-08-28 07:01:08.767475: Epoch time: 16.28 s 
2025-08-28 07:01:09.415001:  
2025-08-28 07:01:09.423383: Epoch 877 
2025-08-28 07:01:09.427698: Current learning rate: 0.00152 
2025-08-28 07:01:25.785539: train_loss -0.5746 
2025-08-28 07:01:25.794108: val_loss -0.6076 
2025-08-28 07:01:25.798044: Pseudo dice [np.float32(0.7804)] 
2025-08-28 07:01:25.806329: Epoch time: 16.37 s 
2025-08-28 07:01:26.452805:  
2025-08-28 07:01:26.461157: Epoch 878 
2025-08-28 07:01:26.469475: Current learning rate: 0.00151 
2025-08-28 07:01:43.265784: train_loss -0.5676 
2025-08-28 07:01:43.273742: val_loss -0.5849 
2025-08-28 07:01:43.282096: Pseudo dice [np.float32(0.7943)] 
2025-08-28 07:01:43.289388: Epoch time: 16.81 s 
2025-08-28 07:01:43.949517:  
2025-08-28 07:01:43.957761: Epoch 879 
2025-08-28 07:01:43.966106: Current learning rate: 0.00149 
2025-08-28 07:02:00.904906: train_loss -0.5643 
2025-08-28 07:02:00.916372: val_loss -0.5617 
2025-08-28 07:02:00.920912: Pseudo dice [np.float32(0.8131)] 
2025-08-28 07:02:00.928828: Epoch time: 16.96 s 
2025-08-28 07:02:01.733870:  
2025-08-28 07:02:01.742201: Epoch 880 
2025-08-28 07:02:01.746366: Current learning rate: 0.00148 
2025-08-28 07:02:18.767520: train_loss -0.5982 
2025-08-28 07:02:18.775918: val_loss -0.5717 
2025-08-28 07:02:18.784235: Pseudo dice [np.float32(0.802)] 
2025-08-28 07:02:18.789666: Epoch time: 17.03 s 
2025-08-28 07:02:19.443214:  
2025-08-28 07:02:19.451547: Epoch 881 
2025-08-28 07:02:19.455754: Current learning rate: 0.00147 
2025-08-28 07:02:36.305909: train_loss -0.6037 
2025-08-28 07:02:36.314610: val_loss -0.5758 
2025-08-28 07:02:36.322579: Pseudo dice [np.float32(0.7796)] 
2025-08-28 07:02:36.331290: Epoch time: 16.87 s 
2025-08-28 07:02:36.981547:  
2025-08-28 07:02:36.985724: Epoch 882 
2025-08-28 07:02:36.994970: Current learning rate: 0.00146 
2025-08-28 07:02:53.598820: train_loss -0.5901 
2025-08-28 07:02:53.610668: val_loss -0.5955 
2025-08-28 07:02:53.615265: Pseudo dice [np.float32(0.8165)] 
2025-08-28 07:02:53.624101: Epoch time: 16.62 s 
2025-08-28 07:02:54.269624:  
2025-08-28 07:02:54.277986: Epoch 883 
2025-08-28 07:02:54.282207: Current learning rate: 0.00145 
2025-08-28 07:03:11.140679: train_loss -0.5858 
2025-08-28 07:03:11.149001: val_loss -0.5175 
2025-08-28 07:03:11.153133: Pseudo dice [np.float32(0.8169)] 
2025-08-28 07:03:11.161420: Epoch time: 16.88 s 
2025-08-28 07:03:11.812478:  
2025-08-28 07:03:11.820511: Epoch 884 
2025-08-28 07:03:11.824678: Current learning rate: 0.00144 
2025-08-28 07:03:28.249414: train_loss -0.5789 
2025-08-28 07:03:28.257989: val_loss -0.6434 
2025-08-28 07:03:28.262213: Pseudo dice [np.float32(0.7638)] 
2025-08-28 07:03:28.271158: Epoch time: 16.44 s 
2025-08-28 07:03:28.925150:  
2025-08-28 07:03:28.933467: Epoch 885 
2025-08-28 07:03:28.941483: Current learning rate: 0.00143 
2025-08-28 07:03:45.604550: train_loss -0.5978 
2025-08-28 07:03:45.612951: val_loss -0.5731 
2025-08-28 07:03:45.621044: Pseudo dice [np.float32(0.7843)] 
2025-08-28 07:03:45.628148: Epoch time: 16.68 s 
2025-08-28 07:03:46.288611:  
2025-08-28 07:03:46.296605: Epoch 886 
2025-08-28 07:03:46.300810: Current learning rate: 0.00142 
2025-08-28 07:04:02.850669: train_loss -0.587 
2025-08-28 07:04:02.863169: val_loss -0.6031 
2025-08-28 07:04:02.867357: Pseudo dice [np.float32(0.8091)] 
2025-08-28 07:04:02.873800: Epoch time: 16.57 s 
2025-08-28 07:04:03.530474:  
2025-08-28 07:04:03.538895: Epoch 887 
2025-08-28 07:04:03.543094: Current learning rate: 0.00141 
2025-08-28 07:04:20.394173: train_loss -0.5882 
2025-08-28 07:04:20.401794: val_loss -0.603 
2025-08-28 07:04:20.410543: Pseudo dice [np.float32(0.8454)] 
2025-08-28 07:04:20.416044: Epoch time: 16.87 s 
2025-08-28 07:04:20.423120: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-08-28 07:04:21.419487:  
2025-08-28 07:04:21.427617: Epoch 888 
2025-08-28 07:04:21.431984: Current learning rate: 0.00139 
2025-08-28 07:04:37.893975: train_loss -0.6174 
2025-08-28 07:04:37.902631: val_loss -0.5954 
2025-08-28 07:04:37.906775: Pseudo dice [np.float32(0.7662)] 
2025-08-28 07:04:37.915731: Epoch time: 16.48 s 
2025-08-28 07:04:38.565441:  
2025-08-28 07:04:38.573834: Epoch 889 
2025-08-28 07:04:38.577988: Current learning rate: 0.00138 
2025-08-28 07:04:55.469869: train_loss -0.5901 
2025-08-28 07:04:55.482356: val_loss -0.5571 
2025-08-28 07:04:55.486549: Pseudo dice [np.float32(0.7641)] 
2025-08-28 07:04:55.492858: Epoch time: 16.9 s 
2025-08-28 07:04:56.137269:  
2025-08-28 07:04:56.145561: Epoch 890 
2025-08-28 07:04:56.154186: Current learning rate: 0.00137 
2025-08-28 07:05:13.004019: train_loss -0.624 
2025-08-28 07:05:13.012403: val_loss -0.6228 
2025-08-28 07:05:13.021045: Pseudo dice [np.float32(0.8262)] 
2025-08-28 07:05:13.027953: Epoch time: 16.87 s 
2025-08-28 07:05:13.679677:  
2025-08-28 07:05:13.688042: Epoch 891 
2025-08-28 07:05:13.692218: Current learning rate: 0.00136 
2025-08-28 07:05:30.037760: train_loss -0.5521 
2025-08-28 07:05:30.046026: val_loss -0.5597 
2025-08-28 07:05:30.050546: Pseudo dice [np.float32(0.7884)] 
2025-08-28 07:05:30.059427: Epoch time: 16.36 s 
2025-08-28 07:05:30.709213:  
2025-08-28 07:05:30.717640: Epoch 892 
2025-08-28 07:05:30.722035: Current learning rate: 0.00135 
2025-08-28 07:05:47.204923: train_loss -0.5835 
2025-08-28 07:05:47.213136: val_loss -0.5751 
2025-08-28 07:05:47.221552: Pseudo dice [np.float32(0.7646)] 
2025-08-28 07:05:47.226920: Epoch time: 16.5 s 
2025-08-28 07:05:47.876379:  
2025-08-28 07:05:47.884785: Epoch 893 
2025-08-28 07:05:47.889136: Current learning rate: 0.00134 
2025-08-28 07:06:04.113361: train_loss -0.6043 
2025-08-28 07:06:04.121778: val_loss -0.6452 
2025-08-28 07:06:04.125943: Pseudo dice [np.float32(0.8426)] 
2025-08-28 07:06:04.134278: Epoch time: 16.24 s 
2025-08-28 07:06:04.780782:  
2025-08-28 07:06:04.789082: Epoch 894 
2025-08-28 07:06:04.797447: Current learning rate: 0.00133 
2025-08-28 07:06:21.539145: train_loss -0.5999 
2025-08-28 07:06:21.547470: val_loss -0.5999 
2025-08-28 07:06:21.551637: Pseudo dice [np.float32(0.7581)] 
2025-08-28 07:06:21.557800: Epoch time: 16.76 s 
2025-08-28 07:06:22.352431:  
2025-08-28 07:06:22.361125: Epoch 895 
2025-08-28 07:06:22.364944: Current learning rate: 0.00132 
2025-08-28 07:06:38.627033: train_loss -0.6319 
2025-08-28 07:06:38.635356: val_loss -0.6144 
2025-08-28 07:06:38.644304: Pseudo dice [np.float32(0.7951)] 
2025-08-28 07:06:38.649958: Epoch time: 16.27 s 
2025-08-28 07:06:39.290250:  
2025-08-28 07:06:39.300820: Epoch 896 
2025-08-28 07:06:39.307154: Current learning rate: 0.0013 
2025-08-28 07:06:55.802919: train_loss -0.5889 
2025-08-28 07:06:55.815018: val_loss -0.6424 
2025-08-28 07:06:55.819601: Pseudo dice [np.float32(0.8089)] 
2025-08-28 07:06:55.828012: Epoch time: 16.51 s 
2025-08-28 07:06:56.482073:  
2025-08-28 07:06:56.486595: Epoch 897 
2025-08-28 07:06:56.494900: Current learning rate: 0.00129 
2025-08-28 07:07:13.211603: train_loss -0.59 
2025-08-28 07:07:13.219923: val_loss -0.6132 
2025-08-28 07:07:13.228593: Pseudo dice [np.float32(0.7705)] 
2025-08-28 07:07:13.234569: Epoch time: 16.73 s 
2025-08-28 07:07:13.878899:  
2025-08-28 07:07:13.887243: Epoch 898 
2025-08-28 07:07:13.891788: Current learning rate: 0.00128 
2025-08-28 07:07:30.695954: train_loss -0.6079 
2025-08-28 07:07:30.704067: val_loss -0.6294 
2025-08-28 07:07:30.712764: Pseudo dice [np.float32(0.8235)] 
2025-08-28 07:07:30.718870: Epoch time: 16.82 s 
2025-08-28 07:07:31.367182:  
2025-08-28 07:07:31.375908: Epoch 899 
2025-08-28 07:07:31.379700: Current learning rate: 0.00127 
2025-08-28 07:07:47.821565: train_loss -0.5893 
2025-08-28 07:07:47.832134: val_loss -0.5418 
2025-08-28 07:07:47.839267: Pseudo dice [np.float32(0.8027)] 
2025-08-28 07:07:47.844152: Epoch time: 16.45 s 
2025-08-28 07:07:48.667824:  
2025-08-28 07:07:48.672267: Epoch 900 
2025-08-28 07:07:48.680696: Current learning rate: 0.00126 
2025-08-28 07:08:05.564183: train_loss -0.5987 
2025-08-28 07:08:05.576756: val_loss -0.6184 
2025-08-28 07:08:05.580789: Pseudo dice [np.float32(0.7853)] 
2025-08-28 07:08:05.589860: Epoch time: 16.9 s 
2025-08-28 07:08:06.402216:  
2025-08-28 07:08:06.410484: Epoch 901 
2025-08-28 07:08:06.419262: Current learning rate: 0.00125 
2025-08-28 07:08:22.986474: train_loss -0.5994 
2025-08-28 07:08:22.997920: val_loss -0.6338 
2025-08-28 07:08:23.002113: Pseudo dice [np.float32(0.8192)] 
2025-08-28 07:08:23.009265: Epoch time: 16.58 s 
2025-08-28 07:08:23.669426:  
2025-08-28 07:08:23.677775: Epoch 902 
2025-08-28 07:08:23.686232: Current learning rate: 0.00124 
2025-08-28 07:08:40.473700: train_loss -0.584 
2025-08-28 07:08:40.482369: val_loss -0.5921 
2025-08-28 07:08:40.490075: Pseudo dice [np.float32(0.7854)] 
2025-08-28 07:08:40.497519: Epoch time: 16.8 s 
2025-08-28 07:08:41.145236:  
2025-08-28 07:08:41.153589: Epoch 903 
2025-08-28 07:08:41.162470: Current learning rate: 0.00122 
2025-08-28 07:08:57.995404: train_loss -0.5818 
2025-08-28 07:08:58.007916: val_loss -0.5516 
2025-08-28 07:08:58.012077: Pseudo dice [np.float32(0.7739)] 
2025-08-28 07:08:58.021372: Epoch time: 16.85 s 
2025-08-28 07:08:58.666864:  
2025-08-28 07:08:58.675251: Epoch 904 
2025-08-28 07:08:58.679416: Current learning rate: 0.00121 
2025-08-28 07:09:15.279269: train_loss -0.5909 
2025-08-28 07:09:15.287928: val_loss -0.6102 
2025-08-28 07:09:15.296075: Pseudo dice [np.float32(0.8076)] 
2025-08-28 07:09:15.301452: Epoch time: 16.61 s 
2025-08-28 07:09:15.963308:  
2025-08-28 07:09:15.971655: Epoch 905 
2025-08-28 07:09:15.980004: Current learning rate: 0.0012 
2025-08-28 07:09:32.830130: train_loss -0.6134 
2025-08-28 07:09:32.837563: val_loss -0.5921 
2025-08-28 07:09:32.847207: Pseudo dice [np.float32(0.8094)] 
2025-08-28 07:09:32.852950: Epoch time: 16.87 s 
2025-08-28 07:09:33.505940:  
2025-08-28 07:09:33.514266: Epoch 906 
2025-08-28 07:09:33.522562: Current learning rate: 0.00119 
2025-08-28 07:09:50.439384: train_loss -0.593 
2025-08-28 07:09:50.447777: val_loss -0.5733 
2025-08-28 07:09:50.456358: Pseudo dice [np.float32(0.8331)] 
2025-08-28 07:09:50.461575: Epoch time: 16.93 s 
2025-08-28 07:09:51.115207:  
2025-08-28 07:09:51.123811: Epoch 907 
2025-08-28 07:09:51.127635: Current learning rate: 0.00118 
2025-08-28 07:10:07.514979: train_loss -0.5717 
2025-08-28 07:10:07.523128: val_loss -0.6436 
2025-08-28 07:10:07.531504: Pseudo dice [np.float32(0.8227)] 
2025-08-28 07:10:07.538764: Epoch time: 16.4 s 
2025-08-28 07:10:07.545383: Yayy! New best EMA pseudo Dice: 0.8029999732971191 
2025-08-28 07:10:08.611738:  
2025-08-28 07:10:08.620054: Epoch 908 
2025-08-28 07:10:08.628407: Current learning rate: 0.00117 
2025-08-28 07:10:25.269971: train_loss -0.565 
2025-08-28 07:10:25.278658: val_loss -0.5609 
2025-08-28 07:10:25.282896: Pseudo dice [np.float32(0.787)] 
2025-08-28 07:10:25.290864: Epoch time: 16.66 s 
2025-08-28 07:10:25.941575:  
2025-08-28 07:10:25.949918: Epoch 909 
2025-08-28 07:10:25.954069: Current learning rate: 0.00116 
2025-08-28 07:10:42.445757: train_loss -0.5722 
2025-08-28 07:10:42.453848: val_loss -0.53 
2025-08-28 07:10:42.462228: Pseudo dice [np.float32(0.7375)] 
2025-08-28 07:10:42.467826: Epoch time: 16.51 s 
2025-08-28 07:10:43.117079:  
2025-08-28 07:10:43.129281: Epoch 910 
2025-08-28 07:10:43.133779: Current learning rate: 0.00115 
2025-08-28 07:10:59.779789: train_loss -0.6192 
2025-08-28 07:10:59.788076: val_loss -0.6016 
2025-08-28 07:10:59.796160: Pseudo dice [np.float32(0.8215)] 
2025-08-28 07:10:59.802327: Epoch time: 16.66 s 
2025-08-28 07:11:00.459720:  
2025-08-28 07:11:00.467709: Epoch 911 
2025-08-28 07:11:00.471875: Current learning rate: 0.00113 
2025-08-28 07:11:17.505861: train_loss -0.611 
2025-08-28 07:11:17.513897: val_loss -0.5684 
2025-08-28 07:11:17.518358: Pseudo dice [np.float32(0.7932)] 
2025-08-28 07:11:17.527172: Epoch time: 17.05 s 
2025-08-28 07:11:18.177009:  
2025-08-28 07:11:18.185369: Epoch 912 
2025-08-28 07:11:18.193744: Current learning rate: 0.00112 
2025-08-28 07:11:34.856689: train_loss -0.5819 
2025-08-28 07:11:34.864536: val_loss -0.6521 
2025-08-28 07:11:34.873215: Pseudo dice [np.float32(0.8231)] 
2025-08-28 07:11:34.878482: Epoch time: 16.68 s 
2025-08-28 07:11:35.548777:  
2025-08-28 07:11:35.556884: Epoch 913 
2025-08-28 07:11:35.565249: Current learning rate: 0.00111 
2025-08-28 07:11:52.561314: train_loss -0.5667 
2025-08-28 07:11:52.569692: val_loss -0.6317 
2025-08-28 07:11:52.578382: Pseudo dice [np.float32(0.8142)] 
2025-08-28 07:11:52.584243: Epoch time: 17.01 s 
2025-08-28 07:11:53.237053:  
2025-08-28 07:11:53.245409: Epoch 914 
2025-08-28 07:11:53.249760: Current learning rate: 0.0011 
2025-08-28 07:12:09.991466: train_loss -0.5767 
2025-08-28 07:12:09.999597: val_loss -0.6662 
2025-08-28 07:12:10.007977: Pseudo dice [np.float32(0.8301)] 
2025-08-28 07:12:10.015063: Epoch time: 16.75 s 
2025-08-28 07:12:10.020745: Yayy! New best EMA pseudo Dice: 0.804099977016449 
2025-08-28 07:12:11.113206:  
2025-08-28 07:12:11.121593: Epoch 915 
2025-08-28 07:12:11.125917: Current learning rate: 0.00109 
2025-08-28 07:12:27.946700: train_loss -0.5955 
2025-08-28 07:12:27.955022: val_loss -0.6213 
2025-08-28 07:12:27.959234: Pseudo dice [np.float32(0.8045)] 
2025-08-28 07:12:27.967381: Epoch time: 16.84 s 
2025-08-28 07:12:27.973050: Yayy! New best EMA pseudo Dice: 0.8041999936103821 
2025-08-28 07:12:28.793460:  
2025-08-28 07:12:28.801795: Epoch 916 
2025-08-28 07:12:28.810065: Current learning rate: 0.00108 
2025-08-28 07:12:44.454838: train_loss -0.5693 
2025-08-28 07:12:44.463459: val_loss -0.6407 
2025-08-28 07:12:44.467600: Pseudo dice [np.float32(0.8385)] 
2025-08-28 07:12:44.475406: Epoch time: 15.66 s 
2025-08-28 07:12:44.481301: Yayy! New best EMA pseudo Dice: 0.8076000213623047 
2025-08-28 07:12:45.318204:  
2025-08-28 07:12:45.326884: Epoch 917 
2025-08-28 07:12:45.331128: Current learning rate: 0.00106 
2025-08-28 07:13:01.034667: train_loss -0.5592 
2025-08-28 07:13:01.046772: val_loss -0.567 
2025-08-28 07:13:01.050611: Pseudo dice [np.float32(0.8268)] 
2025-08-28 07:13:01.057830: Epoch time: 15.72 s 
2025-08-28 07:13:01.064606: Yayy! New best EMA pseudo Dice: 0.809499979019165 
2025-08-28 07:13:01.897259:  
2025-08-28 07:13:01.905900: Epoch 918 
2025-08-28 07:13:01.914025: Current learning rate: 0.00105 
2025-08-28 07:13:18.126453: train_loss -0.605 
2025-08-28 07:13:18.134583: val_loss -0.6419 
2025-08-28 07:13:18.142755: Pseudo dice [np.float32(0.8435)] 
2025-08-28 07:13:18.150176: Epoch time: 16.23 s 
2025-08-28 07:13:18.156899: Yayy! New best EMA pseudo Dice: 0.8129000067710876 
2025-08-28 07:13:18.985166:  
2025-08-28 07:13:18.993845: Epoch 919 
2025-08-28 07:13:19.002243: Current learning rate: 0.00104 
2025-08-28 07:13:35.751896: train_loss -0.5988 
2025-08-28 07:13:35.760616: val_loss -0.5635 
2025-08-28 07:13:35.764693: Pseudo dice [np.float32(0.7585)] 
2025-08-28 07:13:35.770736: Epoch time: 16.77 s 
2025-08-28 07:13:36.431772:  
2025-08-28 07:13:36.440125: Epoch 920 
2025-08-28 07:13:36.444244: Current learning rate: 0.00103 
2025-08-28 07:13:53.077568: train_loss -0.6053 
2025-08-28 07:13:53.090038: val_loss -0.6296 
2025-08-28 07:13:53.094199: Pseudo dice [np.float32(0.8149)] 
2025-08-28 07:13:53.102481: Epoch time: 16.65 s 
2025-08-28 07:13:53.756908:  
2025-08-28 07:13:53.761528: Epoch 921 
2025-08-28 07:13:53.770178: Current learning rate: 0.00102 
2025-08-28 07:14:10.102873: train_loss -0.5995 
2025-08-28 07:14:10.111198: val_loss -0.6007 
2025-08-28 07:14:10.119583: Pseudo dice [np.float32(0.8075)] 
2025-08-28 07:14:10.125789: Epoch time: 16.35 s 
2025-08-28 07:14:10.932911:  
2025-08-28 07:14:10.945456: Epoch 922 
2025-08-28 07:14:10.949590: Current learning rate: 0.00101 
2025-08-28 07:14:27.437244: train_loss -0.6225 
2025-08-28 07:14:27.445178: val_loss -0.6313 
2025-08-28 07:14:27.453873: Pseudo dice [np.float32(0.8538)] 
2025-08-28 07:14:27.458527: Epoch time: 16.5 s 
2025-08-28 07:14:28.116668:  
2025-08-28 07:14:28.125040: Epoch 923 
2025-08-28 07:14:28.129102: Current learning rate: 0.001 
2025-08-28 07:14:44.537406: train_loss -0.5992 
2025-08-28 07:14:44.546012: val_loss -0.5114 
2025-08-28 07:14:44.553835: Pseudo dice [np.float32(0.7226)] 
2025-08-28 07:14:44.559032: Epoch time: 16.42 s 
2025-08-28 07:14:45.254669:  
2025-08-28 07:14:45.263011: Epoch 924 
2025-08-28 07:14:45.267122: Current learning rate: 0.00098 
2025-08-28 07:15:02.337102: train_loss -0.5573 
2025-08-28 07:15:02.350788: val_loss -0.5914 
2025-08-28 07:15:02.355179: Pseudo dice [np.float32(0.8063)] 
2025-08-28 07:15:02.363300: Epoch time: 17.08 s 
2025-08-28 07:15:03.014297:  
2025-08-28 07:15:03.018492: Epoch 925 
2025-08-28 07:15:03.026928: Current learning rate: 0.00097 
2025-08-28 07:15:19.926758: train_loss -0.605 
2025-08-28 07:15:19.939767: val_loss -0.5298 
2025-08-28 07:15:19.947923: Pseudo dice [np.float32(0.8249)] 
2025-08-28 07:15:19.956926: Epoch time: 16.92 s 
2025-08-28 07:15:20.631625:  
2025-08-28 07:15:20.639965: Epoch 926 
2025-08-28 07:15:20.644293: Current learning rate: 0.00096 
2025-08-28 07:15:37.527669: train_loss -0.6075 
2025-08-28 07:15:37.535952: val_loss -0.6083 
2025-08-28 07:15:37.540195: Pseudo dice [np.float32(0.7875)] 
2025-08-28 07:15:37.549485: Epoch time: 16.9 s 
2025-08-28 07:15:38.199167:  
2025-08-28 07:15:38.207806: Epoch 927 
2025-08-28 07:15:38.215843: Current learning rate: 0.00095 
2025-08-28 07:15:54.740721: train_loss -0.5542 
2025-08-28 07:15:54.749152: val_loss -0.7135 
2025-08-28 07:15:54.757410: Pseudo dice [np.float32(0.8544)] 
2025-08-28 07:15:54.764647: Epoch time: 16.54 s 
2025-08-28 07:15:55.566506:  
2025-08-28 07:15:55.574897: Epoch 928 
2025-08-28 07:15:55.578984: Current learning rate: 0.00094 
2025-08-28 07:16:12.437511: train_loss -0.575 
2025-08-28 07:16:12.445916: val_loss -0.5988 
2025-08-28 07:16:12.450017: Pseudo dice [np.float32(0.8213)] 
2025-08-28 07:16:12.458368: Epoch time: 16.87 s 
2025-08-28 07:16:13.100673:  
2025-08-28 07:16:13.109393: Epoch 929 
2025-08-28 07:16:13.113423: Current learning rate: 0.00092 
2025-08-28 07:16:29.729791: train_loss -0.6049 
2025-08-28 07:16:29.738411: val_loss -0.6312 
2025-08-28 07:16:29.746561: Pseudo dice [np.float32(0.8194)] 
2025-08-28 07:16:29.751942: Epoch time: 16.63 s 
2025-08-28 07:16:30.401284:  
2025-08-28 07:16:30.409634: Epoch 930 
2025-08-28 07:16:30.413777: Current learning rate: 0.00091 
2025-08-28 07:16:47.152043: train_loss -0.5849 
2025-08-28 07:16:47.159908: val_loss -0.5553 
2025-08-28 07:16:47.164141: Pseudo dice [np.float32(0.8156)] 
2025-08-28 07:16:47.172075: Epoch time: 16.75 s 
2025-08-28 07:16:47.840240:  
2025-08-28 07:16:47.847919: Epoch 931 
2025-08-28 07:16:47.852267: Current learning rate: 0.0009 
2025-08-28 07:17:04.506190: train_loss -0.5948 
2025-08-28 07:17:04.514762: val_loss -0.6018 
2025-08-28 07:17:04.522891: Pseudo dice [np.float32(0.7711)] 
2025-08-28 07:17:04.529308: Epoch time: 16.67 s 
2025-08-28 07:17:05.177700:  
2025-08-28 07:17:05.186082: Epoch 932 
2025-08-28 07:17:05.194379: Current learning rate: 0.00089 
2025-08-28 07:17:22.203365: train_loss -0.6127 
2025-08-28 07:17:22.211422: val_loss -0.6221 
2025-08-28 07:17:22.215547: Pseudo dice [np.float32(0.8368)] 
2025-08-28 07:17:22.224747: Epoch time: 17.03 s 
2025-08-28 07:17:22.878696:  
2025-08-28 07:17:22.882883: Epoch 933 
2025-08-28 07:17:22.891582: Current learning rate: 0.00088 
2025-08-28 07:17:39.699654: train_loss -0.5981 
2025-08-28 07:17:39.708009: val_loss -0.5871 
2025-08-28 07:17:39.716354: Pseudo dice [np.float32(0.8339)] 
2025-08-28 07:17:39.725152: Epoch time: 16.83 s 
2025-08-28 07:17:39.731312: Yayy! New best EMA pseudo Dice: 0.8129000067710876 
2025-08-28 07:17:40.650622:  
2025-08-28 07:17:40.658975: Epoch 934 
2025-08-28 07:17:40.663116: Current learning rate: 0.00087 
2025-08-28 07:17:57.642565: train_loss -0.6086 
2025-08-28 07:17:57.655829: val_loss -0.632 
2025-08-28 07:17:57.659261: Pseudo dice [np.float32(0.8174)] 
2025-08-28 07:17:57.667808: Epoch time: 16.99 s 
2025-08-28 07:17:57.674404: Yayy! New best EMA pseudo Dice: 0.8133999705314636 
2025-08-28 07:17:58.681393:  
2025-08-28 07:17:58.689545: Epoch 935 
2025-08-28 07:17:58.697807: Current learning rate: 0.00085 
2025-08-28 07:18:14.376139: train_loss -0.5892 
2025-08-28 07:18:14.384300: val_loss -0.6652 
2025-08-28 07:18:14.388777: Pseudo dice [np.float32(0.8066)] 
2025-08-28 07:18:14.397635: Epoch time: 15.69 s 
2025-08-28 07:18:15.051708:  
2025-08-28 07:18:15.059980: Epoch 936 
2025-08-28 07:18:15.064539: Current learning rate: 0.00084 
2025-08-28 07:18:30.675994: train_loss -0.6004 
2025-08-28 07:18:30.684273: val_loss -0.6046 
2025-08-28 07:18:30.688592: Pseudo dice [np.float32(0.8347)] 
2025-08-28 07:18:30.698252: Epoch time: 15.63 s 
2025-08-28 07:18:30.705207: Yayy! New best EMA pseudo Dice: 0.8148999810218811 
2025-08-28 07:18:31.538927:  
2025-08-28 07:18:31.547314: Epoch 937 
2025-08-28 07:18:31.551455: Current learning rate: 0.00083 
2025-08-28 07:18:47.546772: train_loss -0.5904 
2025-08-28 07:18:47.555257: val_loss -0.6183 
2025-08-28 07:18:47.559102: Pseudo dice [np.float32(0.776)] 
2025-08-28 07:18:47.568398: Epoch time: 16.01 s 
2025-08-28 07:18:48.222241:  
2025-08-28 07:18:48.230633: Epoch 938 
2025-08-28 07:18:48.234803: Current learning rate: 0.00082 
2025-08-28 07:19:04.254970: train_loss -0.6122 
2025-08-28 07:19:04.267446: val_loss -0.6422 
2025-08-28 07:19:04.271887: Pseudo dice [np.float32(0.8263)] 
2025-08-28 07:19:04.278834: Epoch time: 16.03 s 
2025-08-28 07:19:04.939053:  
2025-08-28 07:19:04.947610: Epoch 939 
2025-08-28 07:19:04.951468: Current learning rate: 0.00081 
2025-08-28 07:19:21.117598: train_loss -0.6228 
2025-08-28 07:19:21.126234: val_loss -0.5821 
2025-08-28 07:19:21.134369: Pseudo dice [np.float32(0.7896)] 
2025-08-28 07:19:21.140521: Epoch time: 16.18 s 
2025-08-28 07:19:21.801648:  
2025-08-28 07:19:21.809964: Epoch 940 
2025-08-28 07:19:21.814141: Current learning rate: 0.00079 
2025-08-28 07:19:38.168004: train_loss -0.6499 
2025-08-28 07:19:38.180482: val_loss -0.5351 
2025-08-28 07:19:38.184633: Pseudo dice [np.float32(0.7475)] 
2025-08-28 07:19:38.192196: Epoch time: 16.37 s 
2025-08-28 07:19:38.868690:  
2025-08-28 07:19:38.877054: Epoch 941 
2025-08-28 07:19:38.881449: Current learning rate: 0.00078 
2025-08-28 07:19:55.406043: train_loss -0.6187 
2025-08-28 07:19:55.414349: val_loss -0.6161 
2025-08-28 07:19:55.422691: Pseudo dice [np.float32(0.8048)] 
2025-08-28 07:19:55.430388: Epoch time: 16.54 s 
2025-08-28 07:19:56.231904:  
2025-08-28 07:19:56.236070: Epoch 942 
2025-08-28 07:19:56.244409: Current learning rate: 0.00077 
2025-08-28 07:20:12.878247: train_loss -0.6149 
2025-08-28 07:20:12.885960: val_loss -0.5518 
2025-08-28 07:20:12.890126: Pseudo dice [np.float32(0.7802)] 
2025-08-28 07:20:12.899520: Epoch time: 16.65 s 
2025-08-28 07:20:13.549169:  
2025-08-28 07:20:13.557504: Epoch 943 
2025-08-28 07:20:13.561638: Current learning rate: 0.00076 
2025-08-28 07:20:30.599508: train_loss -0.6302 
2025-08-28 07:20:30.607825: val_loss -0.6163 
2025-08-28 07:20:30.616176: Pseudo dice [np.float32(0.8233)] 
2025-08-28 07:20:30.621086: Epoch time: 17.05 s 
2025-08-28 07:20:31.275176:  
2025-08-28 07:20:31.283797: Epoch 944 
2025-08-28 07:20:31.287745: Current learning rate: 0.00075 
2025-08-28 07:20:47.900118: train_loss -0.6146 
2025-08-28 07:20:47.908822: val_loss -0.6203 
2025-08-28 07:20:47.916795: Pseudo dice [np.float32(0.8051)] 
2025-08-28 07:20:47.924097: Epoch time: 16.63 s 
2025-08-28 07:20:48.572135:  
2025-08-28 07:20:48.580627: Epoch 945 
2025-08-28 07:20:48.586056: Current learning rate: 0.00074 
2025-08-28 07:21:05.263275: train_loss -0.6095 
2025-08-28 07:21:05.271610: val_loss -0.6192 
2025-08-28 07:21:05.279959: Pseudo dice [np.float32(0.8301)] 
2025-08-28 07:21:05.287378: Epoch time: 16.69 s 
2025-08-28 07:21:05.943457:  
2025-08-28 07:21:05.951813: Epoch 946 
2025-08-28 07:21:05.955999: Current learning rate: 0.00072 
2025-08-28 07:21:22.317801: train_loss -0.5834 
2025-08-28 07:21:22.326140: val_loss -0.6551 
2025-08-28 07:21:22.330307: Pseudo dice [np.float32(0.8342)] 
2025-08-28 07:21:22.339452: Epoch time: 16.37 s 
2025-08-28 07:21:22.989298:  
2025-08-28 07:21:22.997656: Epoch 947 
2025-08-28 07:21:23.001811: Current learning rate: 0.00071 
2025-08-28 07:21:39.635816: train_loss -0.6074 
2025-08-28 07:21:39.643756: val_loss -0.6395 
2025-08-28 07:21:39.652268: Pseudo dice [np.float32(0.8397)] 
2025-08-28 07:21:39.661172: Epoch time: 16.65 s 
2025-08-28 07:21:40.338027:  
2025-08-28 07:21:40.345613: Epoch 948 
2025-08-28 07:21:40.348638: Current learning rate: 0.0007 
2025-08-28 07:21:57.240156: train_loss -0.6071 
2025-08-28 07:21:57.253028: val_loss -0.5892 
2025-08-28 07:21:57.261032: Pseudo dice [np.float32(0.7943)] 
2025-08-28 07:21:57.267529: Epoch time: 16.9 s 
2025-08-28 07:21:58.074333:  
2025-08-28 07:21:58.082676: Epoch 949 
2025-08-28 07:21:58.086845: Current learning rate: 0.00069 
2025-08-28 07:22:14.729052: train_loss -0.6066 
2025-08-28 07:22:14.736841: val_loss -0.6624 
2025-08-28 07:22:14.745180: Pseudo dice [np.float32(0.8424)] 
2025-08-28 07:22:14.752515: Epoch time: 16.66 s 
2025-08-28 07:22:15.579375:  
2025-08-28 07:22:15.587979: Epoch 950 
2025-08-28 07:22:15.592174: Current learning rate: 0.00067 
2025-08-28 07:22:31.766353: train_loss -0.6005 
2025-08-28 07:22:31.774707: val_loss -0.5687 
2025-08-28 07:22:31.783059: Pseudo dice [np.float32(0.7738)] 
2025-08-28 07:22:31.788708: Epoch time: 16.19 s 
2025-08-28 07:22:32.446526:  
2025-08-28 07:22:32.454548: Epoch 951 
2025-08-28 07:22:32.458678: Current learning rate: 0.00066 
2025-08-28 07:22:48.658511: train_loss -0.5988 
2025-08-28 07:22:48.666517: val_loss -0.6775 
2025-08-28 07:22:48.674693: Pseudo dice [np.float32(0.8528)] 
2025-08-28 07:22:48.680446: Epoch time: 16.21 s 
2025-08-28 07:22:49.338401:  
2025-08-28 07:22:49.346310: Epoch 952 
2025-08-28 07:22:49.350857: Current learning rate: 0.00065 
2025-08-28 07:23:05.191492: train_loss -0.5872 
2025-08-28 07:23:05.203862: val_loss -0.5575 
2025-08-28 07:23:05.208278: Pseudo dice [np.float32(0.7689)] 
2025-08-28 07:23:05.217249: Epoch time: 15.86 s 
2025-08-28 07:23:05.875364:  
2025-08-28 07:23:05.883757: Epoch 953 
2025-08-28 07:23:05.888252: Current learning rate: 0.00064 
2025-08-28 07:23:22.229569: train_loss -0.5872 
2025-08-28 07:23:22.237633: val_loss -0.6606 
2025-08-28 07:23:22.245923: Pseudo dice [np.float32(0.8166)] 
2025-08-28 07:23:22.251291: Epoch time: 16.35 s 
2025-08-28 07:23:22.909106:  
2025-08-28 07:23:22.917403: Epoch 954 
2025-08-28 07:23:22.925762: Current learning rate: 0.00063 
2025-08-28 07:23:39.058779: train_loss -0.6063 
2025-08-28 07:23:39.071083: val_loss -0.6382 
2025-08-28 07:23:39.075471: Pseudo dice [np.float32(0.8138)] 
2025-08-28 07:23:39.082560: Epoch time: 16.15 s 
2025-08-28 07:23:39.892700:  
2025-08-28 07:23:39.896862: Epoch 955 
2025-08-28 07:23:39.905832: Current learning rate: 0.00061 
2025-08-28 07:23:55.466098: train_loss -0.6152 
2025-08-28 07:23:55.474894: val_loss -0.7234 
2025-08-28 07:23:55.483248: Pseudo dice [np.float32(0.876)] 
2025-08-28 07:23:55.489458: Epoch time: 15.58 s 
2025-08-28 07:23:55.496087: Yayy! New best EMA pseudo Dice: 0.8170999884605408 
2025-08-28 07:23:56.329945:  
2025-08-28 07:23:56.338747: Epoch 956 
2025-08-28 07:23:56.344884: Current learning rate: 0.0006 
2025-08-28 07:24:11.966915: train_loss -0.6084 
2025-08-28 07:24:11.974732: val_loss -0.6151 
2025-08-28 07:24:11.982878: Pseudo dice [np.float32(0.8268)] 
2025-08-28 07:24:11.988019: Epoch time: 15.64 s 
2025-08-28 07:24:11.992354: Yayy! New best EMA pseudo Dice: 0.8180999755859375 
2025-08-28 07:24:12.835986:  
2025-08-28 07:24:12.843756: Epoch 957 
2025-08-28 07:24:12.846701: Current learning rate: 0.00059 
2025-08-28 07:24:28.720613: train_loss -0.5917 
2025-08-28 07:24:28.728997: val_loss -0.6643 
2025-08-28 07:24:28.733131: Pseudo dice [np.float32(0.8172)] 
2025-08-28 07:24:28.742368: Epoch time: 15.89 s 
2025-08-28 07:24:29.400978:  
2025-08-28 07:24:29.409101: Epoch 958 
2025-08-28 07:24:29.413245: Current learning rate: 0.00058 
2025-08-28 07:24:45.608375: train_loss -0.6425 
2025-08-28 07:24:45.616688: val_loss -0.6515 
2025-08-28 07:24:45.621172: Pseudo dice [np.float32(0.835)] 
2025-08-28 07:24:45.630033: Epoch time: 16.21 s 
2025-08-28 07:24:45.634284: Yayy! New best EMA pseudo Dice: 0.8197000026702881 
2025-08-28 07:24:46.475834:  
2025-08-28 07:24:46.484257: Epoch 959 
2025-08-28 07:24:46.488446: Current learning rate: 0.00056 
2025-08-28 07:25:03.238706: train_loss -0.6107 
2025-08-28 07:25:03.247102: val_loss -0.6771 
2025-08-28 07:25:03.255174: Pseudo dice [np.float32(0.8062)] 
2025-08-28 07:25:03.261522: Epoch time: 16.76 s 
2025-08-28 07:25:03.914073:  
2025-08-28 07:25:03.922421: Epoch 960 
2025-08-28 07:25:03.930769: Current learning rate: 0.00055 
2025-08-28 07:25:20.893581: train_loss -0.6279 
2025-08-28 07:25:20.901923: val_loss -0.6024 
2025-08-28 07:25:20.906084: Pseudo dice [np.float32(0.8031)] 
2025-08-28 07:25:20.915179: Epoch time: 16.98 s 
2025-08-28 07:25:21.673503:  
2025-08-28 07:25:21.682167: Epoch 961 
2025-08-28 07:25:21.690222: Current learning rate: 0.00054 
2025-08-28 07:25:38.527807: train_loss -0.6156 
2025-08-28 07:25:38.536453: val_loss -0.6251 
2025-08-28 07:25:38.544795: Pseudo dice [np.float32(0.7633)] 
2025-08-28 07:25:38.551525: Epoch time: 16.85 s 
2025-08-28 07:25:39.349793:  
2025-08-28 07:25:39.357804: Epoch 962 
2025-08-28 07:25:39.362302: Current learning rate: 0.00053 
2025-08-28 07:25:56.103698: train_loss -0.641 
2025-08-28 07:25:56.112417: val_loss -0.6618 
2025-08-28 07:25:56.120405: Pseudo dice [np.float32(0.8241)] 
2025-08-28 07:25:56.127674: Epoch time: 16.75 s 
2025-08-28 07:25:56.779374:  
2025-08-28 07:25:56.787717: Epoch 963 
2025-08-28 07:25:56.796072: Current learning rate: 0.00051 
2025-08-28 07:26:12.920920: train_loss -0.6405 
2025-08-28 07:26:12.928833: val_loss -0.6369 
2025-08-28 07:26:12.937160: Pseudo dice [np.float32(0.793)] 
2025-08-28 07:26:12.943338: Epoch time: 16.14 s 
2025-08-28 07:26:13.604829:  
2025-08-28 07:26:13.612857: Epoch 964 
2025-08-28 07:26:13.617040: Current learning rate: 0.0005 
2025-08-28 07:26:30.467200: train_loss -0.6179 
2025-08-28 07:26:30.475504: val_loss -0.6021 
2025-08-28 07:26:30.483870: Pseudo dice [np.float32(0.8418)] 
2025-08-28 07:26:30.491293: Epoch time: 16.86 s 
2025-08-28 07:26:31.151244:  
2025-08-28 07:26:31.159813: Epoch 965 
2025-08-28 07:26:31.163780: Current learning rate: 0.00049 
2025-08-28 07:26:47.856422: train_loss -0.6258 
2025-08-28 07:26:47.863732: val_loss -0.6864 
2025-08-28 07:26:47.872421: Pseudo dice [np.float32(0.8168)] 
2025-08-28 07:26:47.877578: Epoch time: 16.71 s 
2025-08-28 07:26:48.531048:  
2025-08-28 07:26:48.535260: Epoch 966 
2025-08-28 07:26:48.544117: Current learning rate: 0.00048 
2025-08-28 07:27:05.301949: train_loss -0.6117 
2025-08-28 07:27:05.310309: val_loss -0.5902 
2025-08-28 07:27:05.318642: Pseudo dice [np.float32(0.771)] 
2025-08-28 07:27:05.324325: Epoch time: 16.78 s 
2025-08-28 07:27:05.985996:  
2025-08-28 07:27:05.994642: Epoch 967 
2025-08-28 07:27:05.998822: Current learning rate: 0.00046 
2025-08-28 07:27:22.744369: train_loss -0.6386 
2025-08-28 07:27:22.753146: val_loss -0.6046 
2025-08-28 07:27:22.757281: Pseudo dice [np.float32(0.8244)] 
2025-08-28 07:27:22.766180: Epoch time: 16.76 s 
2025-08-28 07:27:23.582779:  
2025-08-28 07:27:23.591067: Epoch 968 
2025-08-28 07:27:23.599387: Current learning rate: 0.00045 
2025-08-28 07:27:40.187174: train_loss -0.6179 
2025-08-28 07:27:40.195132: val_loss -0.5232 
2025-08-28 07:27:40.203983: Pseudo dice [np.float32(0.751)] 
2025-08-28 07:27:40.208856: Epoch time: 16.6 s 
2025-08-28 07:27:40.866728:  
2025-08-28 07:27:40.875044: Epoch 969 
2025-08-28 07:27:40.879245: Current learning rate: 0.00044 
2025-08-28 07:27:57.850656: train_loss -0.6005 
2025-08-28 07:27:57.862603: val_loss -0.6742 
2025-08-28 07:27:57.869817: Pseudo dice [np.float32(0.8378)] 
2025-08-28 07:27:57.876642: Epoch time: 16.98 s 
2025-08-28 07:27:58.538480:  
2025-08-28 07:27:58.547070: Epoch 970 
2025-08-28 07:27:58.555152: Current learning rate: 0.00043 
2025-08-28 07:28:15.505491: train_loss -0.6318 
2025-08-28 07:28:15.513786: val_loss -0.6199 
2025-08-28 07:28:15.518222: Pseudo dice [np.float32(0.7831)] 
2025-08-28 07:28:15.527197: Epoch time: 16.97 s 
2025-08-28 07:28:16.202003:  
2025-08-28 07:28:16.210263: Epoch 971 
2025-08-28 07:28:16.214454: Current learning rate: 0.00041 
2025-08-28 07:28:33.094454: train_loss -0.6214 
2025-08-28 07:28:33.102512: val_loss -0.5775 
2025-08-28 07:28:33.110758: Pseudo dice [np.float32(0.8612)] 
2025-08-28 07:28:33.117183: Epoch time: 16.9 s 
2025-08-28 07:28:33.777821:  
2025-08-28 07:28:33.781986: Epoch 972 
2025-08-28 07:28:33.790575: Current learning rate: 0.0004 
2025-08-28 07:28:50.544902: train_loss -0.6224 
2025-08-28 07:28:50.557135: val_loss -0.5714 
2025-08-28 07:28:50.561249: Pseudo dice [np.float32(0.8031)] 
2025-08-28 07:28:50.570405: Epoch time: 16.77 s 
2025-08-28 07:28:51.224405:  
2025-08-28 07:28:51.233036: Epoch 973 
2025-08-28 07:28:51.237189: Current learning rate: 0.00039 
2025-08-28 07:29:08.053769: train_loss -0.5999 
2025-08-28 07:29:08.062450: val_loss -0.6827 
2025-08-28 07:29:08.070404: Pseudo dice [np.float32(0.8033)] 
2025-08-28 07:29:08.076715: Epoch time: 16.83 s 
2025-08-28 07:29:08.737709:  
2025-08-28 07:29:08.746072: Epoch 974 
2025-08-28 07:29:08.750237: Current learning rate: 0.00037 
2025-08-28 07:29:25.725542: train_loss -0.6321 
2025-08-28 07:29:25.733868: val_loss -0.671 
2025-08-28 07:29:25.742218: Pseudo dice [np.float32(0.8332)] 
2025-08-28 07:29:25.748674: Epoch time: 16.99 s 
2025-08-28 07:29:26.572181:  
2025-08-28 07:29:26.580842: Epoch 975 
2025-08-28 07:29:26.584805: Current learning rate: 0.00036 
2025-08-28 07:29:43.218303: train_loss -0.6217 
2025-08-28 07:29:43.226333: val_loss -0.6758 
2025-08-28 07:29:43.234723: Pseudo dice [np.float32(0.8033)] 
2025-08-28 07:29:43.240215: Epoch time: 16.65 s 
2025-08-28 07:29:43.914582:  
2025-08-28 07:29:43.923204: Epoch 976 
2025-08-28 07:29:43.927036: Current learning rate: 0.00035 
2025-08-28 07:30:00.647893: train_loss -0.608 
2025-08-28 07:30:00.660756: val_loss -0.5983 
2025-08-28 07:30:00.668745: Pseudo dice [np.float32(0.7833)] 
2025-08-28 07:30:00.677050: Epoch time: 16.73 s 
2025-08-28 07:30:01.338135:  
2025-08-28 07:30:01.348524: Epoch 977 
2025-08-28 07:30:01.352773: Current learning rate: 0.00034 
2025-08-28 07:30:18.390597: train_loss -0.6504 
2025-08-28 07:30:18.398998: val_loss -0.5331 
2025-08-28 07:30:18.403134: Pseudo dice [np.float32(0.7872)] 
2025-08-28 07:30:18.411319: Epoch time: 17.05 s 
2025-08-28 07:30:19.070496:  
2025-08-28 07:30:19.078808: Epoch 978 
2025-08-28 07:30:19.083279: Current learning rate: 0.00032 
2025-08-28 07:30:36.321001: train_loss -0.6299 
2025-08-28 07:30:36.333553: val_loss -0.6571 
2025-08-28 07:30:36.340372: Pseudo dice [np.float32(0.8419)] 
2025-08-28 07:30:36.346657: Epoch time: 17.25 s 
2025-08-28 07:30:37.009181:  
2025-08-28 07:30:37.013679: Epoch 979 
2025-08-28 07:30:37.022082: Current learning rate: 0.00031 
2025-08-28 07:30:53.659453: train_loss -0.6366 
2025-08-28 07:30:53.671669: val_loss -0.6416 
2025-08-28 07:30:53.676164: Pseudo dice [np.float32(0.8085)] 
2025-08-28 07:30:53.684235: Epoch time: 16.65 s 
2025-08-28 07:30:54.364047:  
2025-08-28 07:30:54.372380: Epoch 980 
2025-08-28 07:30:54.381304: Current learning rate: 0.0003 
2025-08-28 07:31:11.514742: train_loss -0.6242 
2025-08-28 07:31:11.522893: val_loss -0.6348 
2025-08-28 07:31:11.531268: Pseudo dice [np.float32(0.8029)] 
2025-08-28 07:31:11.536706: Epoch time: 17.15 s 
2025-08-28 07:31:12.198514:  
2025-08-28 07:31:12.206846: Epoch 981 
2025-08-28 07:31:12.216079: Current learning rate: 0.00028 
2025-08-28 07:31:28.919445: train_loss -0.6161 
2025-08-28 07:31:28.927788: val_loss -0.6385 
2025-08-28 07:31:28.931875: Pseudo dice [np.float32(0.858)] 
2025-08-28 07:31:28.941039: Epoch time: 16.72 s 
2025-08-28 07:31:29.612081:  
2025-08-28 07:31:29.620377: Epoch 982 
2025-08-28 07:31:29.624315: Current learning rate: 0.00027 
2025-08-28 07:31:46.391639: train_loss -0.6131 
2025-08-28 07:31:46.399416: val_loss -0.6345 
2025-08-28 07:31:46.403512: Pseudo dice [np.float32(0.8156)] 
2025-08-28 07:31:46.412684: Epoch time: 16.78 s 
2025-08-28 07:31:47.237704:  
2025-08-28 07:31:47.246049: Epoch 983 
2025-08-28 07:31:47.254387: Current learning rate: 0.00026 
2025-08-28 07:32:04.046395: train_loss -0.6098 
2025-08-28 07:32:04.058630: val_loss -0.6423 
2025-08-28 07:32:04.062764: Pseudo dice [np.float32(0.8301)] 
2025-08-28 07:32:04.071949: Epoch time: 16.81 s 
2025-08-28 07:32:04.743019:  
2025-08-28 07:32:04.751348: Epoch 984 
2025-08-28 07:32:04.755167: Current learning rate: 0.00024 
2025-08-28 07:32:21.555531: train_loss -0.6076 
2025-08-28 07:32:21.563625: val_loss -0.6249 
2025-08-28 07:32:21.572050: Pseudo dice [np.float32(0.8304)] 
2025-08-28 07:32:21.579285: Epoch time: 16.81 s 
2025-08-28 07:32:22.235116:  
2025-08-28 07:32:22.243832: Epoch 985 
2025-08-28 07:32:22.247946: Current learning rate: 0.00023 
2025-08-28 07:32:38.747424: train_loss -0.622 
2025-08-28 07:32:38.755993: val_loss -0.5871 
2025-08-28 07:32:38.764068: Pseudo dice [np.float32(0.8024)] 
2025-08-28 07:32:38.771305: Epoch time: 16.51 s 
2025-08-28 07:32:39.431483:  
2025-08-28 07:32:39.439877: Epoch 986 
2025-08-28 07:32:39.443978: Current learning rate: 0.00021 
2025-08-28 07:32:56.294448: train_loss -0.6317 
2025-08-28 07:32:56.306724: val_loss -0.6625 
2025-08-28 07:32:56.311168: Pseudo dice [np.float32(0.8441)] 
2025-08-28 07:32:56.319087: Epoch time: 16.86 s 
2025-08-28 07:32:56.982701:  
2025-08-28 07:32:56.990753: Epoch 987 
2025-08-28 07:32:56.995117: Current learning rate: 0.0002 
2025-08-28 07:33:13.686475: train_loss -0.6169 
2025-08-28 07:33:13.694853: val_loss -0.6549 
2025-08-28 07:33:13.699023: Pseudo dice [np.float32(0.798)] 
2025-08-28 07:33:13.707278: Epoch time: 16.7 s 
2025-08-28 07:33:14.378850:  
2025-08-28 07:33:14.383415: Epoch 988 
2025-08-28 07:33:14.391735: Current learning rate: 0.00019 
2025-08-28 07:33:31.495952: train_loss -0.5906 
2025-08-28 07:33:31.504894: val_loss -0.6617 
2025-08-28 07:33:31.512639: Pseudo dice [np.float32(0.8455)] 
2025-08-28 07:33:31.518184: Epoch time: 17.12 s 
2025-08-28 07:33:32.326042:  
2025-08-28 07:33:32.334039: Epoch 989 
2025-08-28 07:33:32.340170: Current learning rate: 0.00017 
2025-08-28 07:33:48.796875: train_loss -0.6317 
2025-08-28 07:33:48.804909: val_loss -0.6257 
2025-08-28 07:33:48.809370: Pseudo dice [np.float32(0.8214)] 
2025-08-28 07:33:48.818779: Epoch time: 16.48 s 
2025-08-28 07:33:49.476388:  
2025-08-28 07:33:49.480586: Epoch 990 
2025-08-28 07:33:49.488936: Current learning rate: 0.00016 
2025-08-28 07:34:06.251716: train_loss -0.6193 
2025-08-28 07:34:06.263998: val_loss -0.6226 
2025-08-28 07:34:06.268340: Pseudo dice [np.float32(0.8698)] 
2025-08-28 07:34:06.277342: Epoch time: 16.78 s 
2025-08-28 07:34:06.281626: Yayy! New best EMA pseudo Dice: 0.8245999813079834 
2025-08-28 07:34:07.110727:  
2025-08-28 07:34:07.119046: Epoch 991 
2025-08-28 07:34:07.127343: Current learning rate: 0.00014 
2025-08-28 07:34:23.310078: train_loss -0.6394 
2025-08-28 07:34:23.318543: val_loss -0.708 
2025-08-28 07:34:23.322958: Pseudo dice [np.float32(0.8635)] 
2025-08-28 07:34:23.330220: Epoch time: 16.2 s 
2025-08-28 07:34:23.339242: Yayy! New best EMA pseudo Dice: 0.828499972820282 
2025-08-28 07:34:24.177812:  
2025-08-28 07:34:24.186287: Epoch 992 
2025-08-28 07:34:24.190281: Current learning rate: 0.00013 
2025-08-28 07:34:40.923621: train_loss -0.6235 
2025-08-28 07:34:40.931973: val_loss -0.6542 
2025-08-28 07:34:40.936140: Pseudo dice [np.float32(0.845)] 
2025-08-28 07:34:40.944315: Epoch time: 16.75 s 
2025-08-28 07:34:40.951265: Yayy! New best EMA pseudo Dice: 0.8302000164985657 
2025-08-28 07:34:41.799792:  
2025-08-28 07:34:41.807877: Epoch 993 
2025-08-28 07:34:41.812005: Current learning rate: 0.00011 
2025-08-28 07:34:57.961492: train_loss -0.647 
2025-08-28 07:34:57.969847: val_loss -0.6023 
2025-08-28 07:34:57.978184: Pseudo dice [np.float32(0.8437)] 
2025-08-28 07:34:57.983695: Epoch time: 16.16 s 
2025-08-28 07:34:57.987458: Yayy! New best EMA pseudo Dice: 0.8314999938011169 
2025-08-28 07:34:58.831807:  
2025-08-28 07:34:58.840849: Epoch 994 
2025-08-28 07:34:58.846107: Current learning rate: 0.0001 
2025-08-28 07:35:15.654111: train_loss -0.6236 
2025-08-28 07:35:15.662484: val_loss -0.7064 
2025-08-28 07:35:15.670824: Pseudo dice [np.float32(0.8218)] 
2025-08-28 07:35:15.677758: Epoch time: 16.83 s 
2025-08-28 07:35:16.504975:  
2025-08-28 07:35:16.513648: Epoch 995 
2025-08-28 07:35:16.521718: Current learning rate: 8e-05 
2025-08-28 07:35:32.996776: train_loss -0.6412 
2025-08-28 07:35:33.004797: val_loss -0.5962 
2025-08-28 07:35:33.013263: Pseudo dice [np.float32(0.8237)] 
2025-08-28 07:35:33.020329: Epoch time: 16.49 s 
2025-08-28 07:35:33.684646:  
2025-08-28 07:35:33.689282: Epoch 996 
2025-08-28 07:35:33.697478: Current learning rate: 7e-05 
2025-08-28 07:35:50.372849: train_loss -0.6143 
2025-08-28 07:35:50.384655: val_loss -0.5563 
2025-08-28 07:35:50.388856: Pseudo dice [np.float32(0.7737)] 
2025-08-28 07:35:50.397989: Epoch time: 16.69 s 
2025-08-28 07:35:51.056129:  
2025-08-28 07:35:51.060637: Epoch 997 
2025-08-28 07:35:51.068786: Current learning rate: 5e-05 
2025-08-28 07:36:07.914640: train_loss -0.6159 
2025-08-28 07:36:07.923116: val_loss -0.6465 
2025-08-28 07:36:07.927293: Pseudo dice [np.float32(0.807)] 
2025-08-28 07:36:07.935551: Epoch time: 16.86 s 
2025-08-28 07:36:08.594503:  
2025-08-28 07:36:08.602853: Epoch 998 
2025-08-28 07:36:08.607030: Current learning rate: 4e-05 
2025-08-28 07:36:24.998265: train_loss -0.625 
2025-08-28 07:36:25.006481: val_loss -0.6113 
2025-08-28 07:36:25.010982: Pseudo dice [np.float32(0.7699)] 
2025-08-28 07:36:25.017137: Epoch time: 16.4 s 
2025-08-28 07:36:25.678235:  
2025-08-28 07:36:25.686603: Epoch 999 
2025-08-28 07:36:25.694907: Current learning rate: 2e-05 
2025-08-28 07:36:42.595146: train_loss -0.6274 
2025-08-28 07:36:42.603800: val_loss -0.7443 
2025-08-28 07:36:42.612181: Pseudo dice [np.float32(0.8853)] 
2025-08-28 07:36:42.620120: Epoch time: 16.92 s 
2025-08-28 07:36:43.479453: Training done. 
2025-08-28 07:36:43.712995: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 07:36:43.725443: The split file contains 5 splits. 
2025-08-28 07:36:43.734078: Desired fold for training: 1 
2025-08-28 07:36:43.743063: This split has 524 training and 131 validation cases. 
2025-08-28 07:36:43.752932: predicting sub-r001s003 
2025-08-28 07:36:44.046587: sub-r001s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:36:53.576669: predicting sub-r001s004 
2025-08-28 07:36:53.860630: sub-r001s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:04.250067: predicting sub-r001s010 
2025-08-28 07:37:04.483638: sub-r001s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:14.973274: predicting sub-r001s012 
2025-08-28 07:37:15.223534: sub-r001s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:25.246309: predicting sub-r001s019 
2025-08-28 07:37:25.533861: sub-r001s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:36.540864: predicting sub-r001s021 
2025-08-28 07:37:36.790920: sub-r001s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:46.829962: predicting sub-r001s025 
2025-08-28 07:37:47.059518: sub-r001s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:37:57.828652: predicting sub-r001s028 
2025-08-28 07:37:58.145623: sub-r001s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:08.522909: predicting sub-r001s029 
2025-08-28 07:38:08.818769: sub-r001s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:19.836581: predicting sub-r001s034 
2025-08-28 07:38:20.067494: sub-r001s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:30.019445: predicting sub-r001s037 
2025-08-28 07:38:30.252655: sub-r001s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:40.000146: predicting sub-r002s003 
2025-08-28 07:38:40.229134: sub-r002s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:49.530132: predicting sub-r003s003 
2025-08-28 07:38:49.755442: sub-r003s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:38:59.774007: predicting sub-r004s001 
2025-08-28 07:39:00.036138: sub-r004s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:09.308370: predicting sub-r004s002 
2025-08-28 07:39:09.566953: sub-r004s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:19.756229: predicting sub-r004s004 
2025-08-28 07:39:19.989885: sub-r004s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:29.653744: predicting sub-r004s006 
2025-08-28 07:39:29.883332: sub-r004s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:39.660293: predicting sub-r004s011 
2025-08-28 07:39:39.888833: sub-r004s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:49.010439: predicting sub-r004s020 
2025-08-28 07:39:49.277399: sub-r004s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:39:59.345689: predicting sub-r004s021 
2025-08-28 07:39:59.600284: sub-r004s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:40:08.763743: predicting sub-r004s025 
2025-08-28 07:40:08.993017: sub-r004s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:40:19.161712: predicting sub-r004s029 
2025-08-28 07:40:19.457520: sub-r004s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:40:29.759481: predicting sub-r004s033 
2025-08-28 07:40:30.005910: sub-r004s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:40:40.265805: predicting sub-r004s035 
2025-08-28 07:40:40.533062: sub-r004s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:40:50.067559: predicting sub-r004s036 
2025-08-28 07:40:50.305099: sub-r004s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:00.002177: predicting sub-r004s037 
2025-08-28 07:41:00.244086: sub-r004s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:09.657664: predicting sub-r005s046 
2025-08-28 07:41:09.891232: sub-r005s046, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:20.064165: predicting sub-r005s055 
2025-08-28 07:41:20.314439: sub-r005s055, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:29.711027: predicting sub-r005s058 
2025-08-28 07:41:29.952991: sub-r005s058, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:39.908653: predicting sub-r005s069 
2025-08-28 07:41:40.150608: sub-r005s069, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:49.334788: predicting sub-r009s001 
2025-08-28 07:41:49.585032: sub-r009s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:41:59.603376: predicting sub-r009s021 
2025-08-28 07:41:59.870299: sub-r009s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:09.158829: predicting sub-r009s027 
2025-08-28 07:42:09.429945: sub-r009s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:19.842908: predicting sub-r009s031 
2025-08-28 07:42:20.103018: sub-r009s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:29.379137: predicting sub-r009s034 
2025-08-28 07:42:29.666730: sub-r009s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:39.664499: predicting sub-r009s037 
2025-08-28 07:42:39.910309: sub-r009s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:49.406869: predicting sub-r009s040 
2025-08-28 07:42:49.678390: sub-r009s040, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:42:59.818033: predicting sub-r009s044 
2025-08-28 07:43:00.076288: sub-r009s044, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:09.489839: predicting sub-r009s048 
2025-08-28 07:43:09.751327: sub-r009s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:19.629131: predicting sub-r009s062 
2025-08-28 07:43:19.892206: sub-r009s062, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:29.305456: predicting sub-r009s065 
2025-08-28 07:43:29.551622: sub-r009s065, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:39.444758: predicting sub-r009s071 
2025-08-28 07:43:39.686681: sub-r009s071, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:49.079360: predicting sub-r009s073 
2025-08-28 07:43:49.335304: sub-r009s073, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:43:58.626724: predicting sub-r009s076 
2025-08-28 07:43:58.905875: sub-r009s076, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:08.348727: predicting sub-r009s077 
2025-08-28 07:44:08.594749: sub-r009s077, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:18.392188: predicting sub-r009s084 
2025-08-28 07:44:18.667251: sub-r009s084, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:28.418738: predicting sub-r009s110 
2025-08-28 07:44:28.665107: sub-r009s110, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:38.741240: predicting sub-r009s119 
2025-08-28 07:44:38.995886: sub-r009s119, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:48.534613: predicting sub-r010s003 
2025-08-28 07:44:48.776500: sub-r010s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:44:58.678364: predicting sub-r010s014 
2025-08-28 07:44:58.936633: sub-r010s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:08.679772: predicting sub-r010s029 
2025-08-28 07:45:08.925828: sub-r010s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:18.931670: predicting sub-r011s015 
2025-08-28 07:45:19.169492: sub-r011s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:28.975281: predicting sub-r011s017 
2025-08-28 07:45:29.212702: sub-r011s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:38.959948: predicting sub-r011s019 
2025-08-28 07:45:39.197680: sub-r011s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:48.557061: predicting sub-r011s026 
2025-08-28 07:45:48.815632: sub-r011s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:45:58.529809: predicting sub-r011s030 
2025-08-28 07:45:58.788167: sub-r011s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:08.585359: predicting sub-r014s010 
2025-08-28 07:46:08.836867: sub-r014s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:18.687406: predicting sub-r015s011 
2025-08-28 07:46:18.937649: sub-r015s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:28.505627: predicting sub-r015s018 
2025-08-28 07:46:28.768025: sub-r015s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:38.486069: predicting sub-r017s117 
2025-08-28 07:46:38.744684: sub-r017s117, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:48.467128: predicting sub-r018s001 
2025-08-28 07:46:48.717452: sub-r018s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:46:58.193234: predicting sub-r019s001 
2025-08-28 07:46:58.472728: sub-r019s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:08.862243: predicting sub-r023s001 
2025-08-28 07:47:09.104185: sub-r023s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:18.818295: predicting sub-r023s008 
2025-08-28 07:47:19.047537: sub-r023s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:29.628818: predicting sub-r024s008 
2025-08-28 07:47:29.862656: sub-r024s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:39.618211: predicting sub-r027s001 
2025-08-28 07:47:39.859848: sub-r027s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:49.607050: predicting sub-r028s009 
2025-08-28 07:47:49.848911: sub-r028s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:47:58.970618: predicting sub-r028s012 
2025-08-28 07:47:59.233036: sub-r028s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:09.643809: predicting sub-r031s001 
2025-08-28 07:48:09.902390: sub-r031s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:19.015963: predicting sub-r031s008 
2025-08-28 07:48:19.249304: sub-r031s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:29.484758: predicting sub-r031s018 
2025-08-28 07:48:29.738854: sub-r031s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:39.102668: predicting sub-r031s024 
2025-08-28 07:48:39.327976: sub-r031s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:49.087337: predicting sub-r034s013 
2025-08-28 07:48:49.320923: sub-r034s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:48:58.659386: predicting sub-r034s014 
2025-08-28 07:48:58.926666: sub-r034s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:09.182505: predicting sub-r034s032 
2025-08-28 07:49:09.453515: sub-r034s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:18.708623: predicting sub-r034s036 
2025-08-28 07:49:18.967277: sub-r034s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:29.314996: predicting sub-r034s046 
2025-08-28 07:49:29.569547: sub-r034s046, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:38.891238: predicting sub-r035s014 
2025-08-28 07:49:39.120686: sub-r035s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:48.909576: predicting sub-r038s010 
2025-08-28 07:49:49.172421: sub-r038s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:49:58.444388: predicting sub-r038s014 
2025-08-28 07:49:58.698562: sub-r038s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:09.025749: predicting sub-r038s020 
2025-08-28 07:50:09.267432: sub-r038s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:18.405648: predicting sub-r038s021 
2025-08-28 07:50:18.643468: sub-r038s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:28.177981: predicting sub-r038s023 
2025-08-28 07:50:28.428592: sub-r038s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:37.883539: predicting sub-r038s040 
2025-08-28 07:50:38.112922: sub-r038s040, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:48.319211: predicting sub-r038s047 
2025-08-28 07:50:48.556691: sub-r038s047, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:50:57.719895: predicting sub-r038s058 
2025-08-28 07:50:57.982760: sub-r038s058, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:08.255775: predicting sub-r038s060 
2025-08-28 07:51:08.489045: sub-r038s060, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:17.886044: predicting sub-r038s074 
2025-08-28 07:51:18.127887: sub-r038s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:28.492499: predicting sub-r038s082 
2025-08-28 07:51:28.742638: sub-r038s082, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:38.098043: predicting sub-r038s089 
2025-08-28 07:51:38.342257: sub-r038s089, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:48.470670: predicting sub-r038s091 
2025-08-28 07:51:48.712584: sub-r038s091, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:51:58.263635: predicting sub-r038s096 
2025-08-28 07:51:58.526531: sub-r038s096, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:07.752378: predicting sub-r040s002 
2025-08-28 07:52:08.006916: sub-r040s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:17.286958: predicting sub-r040s004 
2025-08-28 07:52:17.533010: sub-r040s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:27.701822: predicting sub-r040s010 
2025-08-28 07:52:27.951755: sub-r040s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:37.248875: predicting sub-r040s013 
2025-08-28 07:52:37.527975: sub-r040s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:47.321096: predicting sub-r040s024 
2025-08-28 07:52:47.567264: sub-r040s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:52:56.734652: predicting sub-r040s039 
2025-08-28 07:52:56.985224: sub-r040s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:06.970166: predicting sub-r040s048 
2025-08-28 07:53:07.203493: sub-r040s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:16.633757: predicting sub-r040s053 
2025-08-28 07:53:16.871410: sub-r040s053, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:26.985533: predicting sub-r040s067 
2025-08-28 07:53:27.223514: sub-r040s067, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:36.620326: predicting sub-r040s078 
2025-08-28 07:53:36.878999: sub-r040s078, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:46.401242: predicting sub-r042s008 
2025-08-28 07:53:46.642870: sub-r042s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:53:56.265002: predicting sub-r042s011 
2025-08-28 07:53:56.523763: sub-r042s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:06.570959: predicting sub-r042s018 
2025-08-28 07:54:06.808982: sub-r042s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:16.168166: predicting sub-r042s023 
2025-08-28 07:54:16.430997: sub-r042s023, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:25.827785: predicting sub-r042s028 
2025-08-28 07:54:26.078056: sub-r042s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:35.366778: predicting sub-r042s030 
2025-08-28 07:54:35.612902: sub-r042s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:45.142920: predicting sub-r042s035 
2025-08-28 07:54:45.374106: sub-r042s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:54:55.461513: predicting sub-r044s002 
2025-08-28 07:54:55.720130: sub-r044s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:05.480161: predicting sub-r046s005 
2025-08-28 07:55:05.705215: sub-r046s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:15.539948: predicting sub-r046s007 
2025-08-28 07:55:15.777681: sub-r046s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:25.308351: predicting sub-r047s006 
2025-08-28 07:55:25.570793: sub-r047s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:35.168298: predicting sub-r047s007 
2025-08-28 07:55:35.418145: sub-r047s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:45.528534: predicting sub-r047s016 
2025-08-28 07:55:45.782663: sub-r047s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:55:55.700888: predicting sub-r047s031 
2025-08-28 07:55:55.955376: sub-r047s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:05.953067: predicting sub-r047s035 
2025-08-28 07:56:06.198887: sub-r047s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:15.783454: predicting sub-r047s039 
2025-08-28 07:56:16.021232: sub-r047s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:25.301558: predicting sub-r047s041 
2025-08-28 07:56:25.526551: sub-r047s041, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:35.102956: predicting sub-r047s043 
2025-08-28 07:56:35.352957: sub-r047s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:45.075215: predicting sub-r047s046 
2025-08-28 07:56:45.321293: sub-r047s046, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:56:54.768259: predicting sub-r048s011 
2025-08-28 07:56:55.047704: sub-r048s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:04.586349: predicting sub-r048s022 
2025-08-28 07:57:04.835130: sub-r048s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:14.717476: predicting sub-r049s010 
2025-08-28 07:57:14.995601: sub-r049s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:24.406163: predicting sub-r049s018 
2025-08-28 07:57:24.664987: sub-r049s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:34.923441: predicting sub-r049s020 
2025-08-28 07:57:35.191943: sub-r049s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:44.368068: predicting sub-r050s003 
2025-08-28 07:57:44.626335: sub-r050s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:57:55.345973: predicting sub-r052s007 
2025-08-28 07:57:55.616927: sub-r052s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:58:05.017511: predicting sub-r052s025 
2025-08-28 07:58:05.255309: sub-r052s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:58:15.982730: predicting sub-r052s027 
2025-08-28 07:58:16.233209: sub-r052s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:58:25.930172: predicting sub-r052s032 
2025-08-28 07:58:26.159823: sub-r052s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 07:58:44.698529: Validation complete 
2025-08-28 07:58:44.707387: Mean Validation Dice:  0.5173393056077434 
