
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-28 18:01:50.457056: do_dummy_2d_data_aug: False 
2025-08-28 18:01:50.465426: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 18:01:50.472757: The split file contains 5 splits. 
2025-08-28 18:01:50.477510: Desired fold for training: 4 
2025-08-28 18:01:50.482383: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-28 18:01:57.736820: Unable to plot network architecture: 
2025-08-28 18:01:57.745272: No module named 'hiddenlayer' 
2025-08-28 18:01:57.793693:  
2025-08-28 18:01:57.801896: Epoch 0 
2025-08-28 18:01:57.806087: Current learning rate: 0.01 
2025-08-28 18:02:14.873152: train_loss 0.1034 
2025-08-28 18:02:14.877258: val_loss 0.0702 
2025-08-28 18:02:14.885619: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:02:14.890577: Epoch time: 17.08 s 
2025-08-28 18:02:14.894735: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-28 18:02:15.660584:  
2025-08-28 18:02:15.665581: Epoch 1 
2025-08-28 18:02:15.669713: Current learning rate: 0.00999 
2025-08-28 18:02:32.244632: train_loss 0.0348 
2025-08-28 18:02:32.253025: val_loss 0.0286 
2025-08-28 18:02:32.261038: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:02:32.265481: Epoch time: 16.59 s 
2025-08-28 18:02:32.953644:  
2025-08-28 18:02:32.961993: Epoch 2 
2025-08-28 18:02:32.966143: Current learning rate: 0.00998 
2025-08-28 18:02:49.995986: train_loss 0.0301 
2025-08-28 18:02:50.004292: val_loss 0.0136 
2025-08-28 18:02:50.012115: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:02:50.017351: Epoch time: 17.04 s 
2025-08-28 18:02:50.633805:  
2025-08-28 18:02:50.642143: Epoch 3 
2025-08-28 18:02:50.646262: Current learning rate: 0.00997 
2025-08-28 18:03:07.538351: train_loss 0.0142 
2025-08-28 18:03:07.546506: val_loss -0.0049 
2025-08-28 18:03:07.550678: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:03:07.557230: Epoch time: 16.9 s 
2025-08-28 18:03:08.155468:  
2025-08-28 18:03:08.164131: Epoch 4 
2025-08-28 18:03:08.167959: Current learning rate: 0.00996 
2025-08-28 18:03:25.372623: train_loss 0.0002 
2025-08-28 18:03:25.377039: val_loss -0.0007 
2025-08-28 18:03:25.385170: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:03:25.391302: Epoch time: 17.22 s 
2025-08-28 18:03:26.011179:  
2025-08-28 18:03:26.019191: Epoch 5 
2025-08-28 18:03:26.023260: Current learning rate: 0.00995 
2025-08-28 18:03:43.127888: train_loss 0.0053 
2025-08-28 18:03:43.136209: val_loss -0.0125 
2025-08-28 18:03:43.140671: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:03:43.146469: Epoch time: 17.12 s 
2025-08-28 18:03:43.757719:  
2025-08-28 18:03:43.766038: Epoch 6 
2025-08-28 18:03:43.770184: Current learning rate: 0.00995 
2025-08-28 18:04:01.292150: train_loss 0.0064 
2025-08-28 18:04:01.304353: val_loss -0.003 
2025-08-28 18:04:01.308527: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:04:01.316512: Epoch time: 17.53 s 
2025-08-28 18:04:01.917492:  
2025-08-28 18:04:01.925813: Epoch 7 
2025-08-28 18:04:01.930316: Current learning rate: 0.00994 
2025-08-28 18:04:19.076658: train_loss 0.0027 
2025-08-28 18:04:19.084602: val_loss -0.0129 
2025-08-28 18:04:19.089108: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:04:19.096860: Epoch time: 17.16 s 
2025-08-28 18:04:19.847889:  
2025-08-28 18:04:19.852311: Epoch 8 
2025-08-28 18:04:19.860729: Current learning rate: 0.00993 
2025-08-28 18:04:36.806754: train_loss 0.0003 
2025-08-28 18:04:36.815185: val_loss -0.0014 
2025-08-28 18:04:36.818984: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:04:36.825137: Epoch time: 16.96 s 
2025-08-28 18:04:37.436313:  
2025-08-28 18:04:37.444617: Epoch 9 
2025-08-28 18:04:37.448986: Current learning rate: 0.00992 
2025-08-28 18:04:54.532801: train_loss -0.0025 
2025-08-28 18:04:54.540867: val_loss -0.0041 
2025-08-28 18:04:54.544922: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:04:54.552066: Epoch time: 17.1 s 
2025-08-28 18:04:55.145619:  
2025-08-28 18:04:55.153960: Epoch 10 
2025-08-28 18:04:55.162307: Current learning rate: 0.00991 
2025-08-28 18:05:12.053949: train_loss -0.0072 
2025-08-28 18:05:12.058372: val_loss -0.0113 
2025-08-28 18:05:12.066705: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:05:12.071851: Epoch time: 16.91 s 
2025-08-28 18:05:12.655028:  
2025-08-28 18:05:12.663168: Epoch 11 
2025-08-28 18:05:12.667589: Current learning rate: 0.0099 
2025-08-28 18:05:29.233794: train_loss -0.0055 
2025-08-28 18:05:29.242165: val_loss -0.0229 
2025-08-28 18:05:29.246367: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:05:29.254600: Epoch time: 16.58 s 
2025-08-28 18:05:29.846921:  
2025-08-28 18:05:29.853619: Epoch 12 
2025-08-28 18:05:29.859815: Current learning rate: 0.00989 
2025-08-28 18:05:46.192452: train_loss -0.0194 
2025-08-28 18:05:46.201039: val_loss -0.0055 
2025-08-28 18:05:46.205192: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:05:46.212220: Epoch time: 16.35 s 
2025-08-28 18:05:46.813898:  
2025-08-28 18:05:46.822258: Epoch 13 
2025-08-28 18:05:46.826425: Current learning rate: 0.00988 
2025-08-28 18:06:03.701587: train_loss -0.0087 
2025-08-28 18:06:03.710270: val_loss -0.0264 
2025-08-28 18:06:03.718300: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:06:03.723740: Epoch time: 16.89 s 
2025-08-28 18:06:04.331362:  
2025-08-28 18:06:04.339768: Epoch 14 
2025-08-28 18:06:04.343886: Current learning rate: 0.00987 
2025-08-28 18:06:21.210751: train_loss -0.0115 
2025-08-28 18:06:21.219199: val_loss -0.0331 
2025-08-28 18:06:21.223211: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:06:21.232350: Epoch time: 16.88 s 
2025-08-28 18:06:21.978153:  
2025-08-28 18:06:21.986482: Epoch 15 
2025-08-28 18:06:21.994833: Current learning rate: 0.00986 
2025-08-28 18:06:39.044693: train_loss -0.0139 
2025-08-28 18:06:39.049682: val_loss -0.0342 
2025-08-28 18:06:39.057947: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:06:39.063301: Epoch time: 17.07 s 
2025-08-28 18:06:39.675293:  
2025-08-28 18:06:39.683374: Epoch 16 
2025-08-28 18:06:39.687518: Current learning rate: 0.00986 
2025-08-28 18:06:56.404490: train_loss -0.0218 
2025-08-28 18:06:56.412539: val_loss -0.0145 
2025-08-28 18:06:56.420881: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:06:56.427002: Epoch time: 16.73 s 
2025-08-28 18:06:57.046506:  
2025-08-28 18:06:57.054851: Epoch 17 
2025-08-28 18:06:57.059264: Current learning rate: 0.00985 
2025-08-28 18:07:14.238723: train_loss -0.0122 
2025-08-28 18:07:14.247101: val_loss -0.0321 
2025-08-28 18:07:14.251181: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:07:14.258392: Epoch time: 17.19 s 
2025-08-28 18:07:14.885165:  
2025-08-28 18:07:14.893471: Epoch 18 
2025-08-28 18:07:14.897640: Current learning rate: 0.00984 
2025-08-28 18:07:31.535174: train_loss -0.025 
2025-08-28 18:07:31.543444: val_loss -0.0344 
2025-08-28 18:07:31.547567: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:07:31.553716: Epoch time: 16.65 s 
2025-08-28 18:07:32.169413:  
2025-08-28 18:07:32.177406: Epoch 19 
2025-08-28 18:07:32.185763: Current learning rate: 0.00983 
2025-08-28 18:07:48.973334: train_loss -0.0243 
2025-08-28 18:07:48.986146: val_loss -0.0392 
2025-08-28 18:07:48.990376: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:07:48.997144: Epoch time: 16.8 s 
2025-08-28 18:07:49.615682:  
2025-08-28 18:07:49.624032: Epoch 20 
2025-08-28 18:07:49.628186: Current learning rate: 0.00982 
2025-08-28 18:08:06.407466: train_loss -0.0257 
2025-08-28 18:08:06.419947: val_loss -0.037 
2025-08-28 18:08:06.424264: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:08:06.432649: Epoch time: 16.79 s 
2025-08-28 18:08:07.208391:  
2025-08-28 18:08:07.216602: Epoch 21 
2025-08-28 18:08:07.220984: Current learning rate: 0.00981 
2025-08-28 18:08:24.350775: train_loss -0.0283 
2025-08-28 18:08:24.358689: val_loss -0.0325 
2025-08-28 18:08:24.367001: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:08:24.371942: Epoch time: 17.15 s 
2025-08-28 18:08:24.980217:  
2025-08-28 18:08:24.988482: Epoch 22 
2025-08-28 18:08:24.992889: Current learning rate: 0.0098 
2025-08-28 18:08:41.647968: train_loss -0.0279 
2025-08-28 18:08:41.655121: val_loss -0.0313 
2025-08-28 18:08:41.659249: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:08:41.667357: Epoch time: 16.67 s 
2025-08-28 18:08:42.272367:  
2025-08-28 18:08:42.279016: Epoch 23 
2025-08-28 18:08:42.284906: Current learning rate: 0.00979 
2025-08-28 18:08:58.910152: train_loss -0.0307 
2025-08-28 18:08:58.922530: val_loss -0.0439 
2025-08-28 18:08:58.926776: Pseudo dice [np.float32(0.0)] 
2025-08-28 18:08:58.933579: Epoch time: 16.64 s 
2025-08-28 18:08:59.518848:  
2025-08-28 18:08:59.526815: Epoch 24 
2025-08-28 18:08:59.535222: Current learning rate: 0.00978 
2025-08-28 18:09:16.635944: train_loss -0.0386 
2025-08-28 18:09:16.644119: val_loss -0.0538 
2025-08-28 18:09:16.648470: Pseudo dice [np.float32(0.0018)] 
2025-08-28 18:09:16.654944: Epoch time: 17.11 s 
2025-08-28 18:09:16.659048: Yayy! New best EMA pseudo Dice: 0.00019999999494757503 
2025-08-28 18:09:17.457839:  
2025-08-28 18:09:17.465913: Epoch 25 
2025-08-28 18:09:17.470077: Current learning rate: 0.00977 
2025-08-28 18:09:34.495689: train_loss -0.0591 
2025-08-28 18:09:34.503712: val_loss -0.0701 
2025-08-28 18:09:34.507887: Pseudo dice [np.float32(0.0672)] 
2025-08-28 18:09:34.516991: Epoch time: 17.04 s 
2025-08-28 18:09:34.522152: Yayy! New best EMA pseudo Dice: 0.006899999920278788 
2025-08-28 18:09:35.312847:  
2025-08-28 18:09:35.321228: Epoch 26 
2025-08-28 18:09:35.325391: Current learning rate: 0.00977 
2025-08-28 18:09:51.466822: train_loss -0.0659 
2025-08-28 18:09:51.475133: val_loss -0.0598 
2025-08-28 18:09:51.483172: Pseudo dice [np.float32(0.1255)] 
2025-08-28 18:09:51.488821: Epoch time: 16.15 s 
2025-08-28 18:09:51.492481: Yayy! New best EMA pseudo Dice: 0.018699999898672104 
2025-08-28 18:09:52.283947:  
2025-08-28 18:09:52.292559: Epoch 27 
2025-08-28 18:09:52.296519: Current learning rate: 0.00976 
2025-08-28 18:10:07.661684: train_loss -0.0675 
2025-08-28 18:10:07.675568: val_loss -0.0931 
2025-08-28 18:10:07.681852: Pseudo dice [np.float32(0.2166)] 
2025-08-28 18:10:07.687339: Epoch time: 15.38 s 
2025-08-28 18:10:07.692033: Yayy! New best EMA pseudo Dice: 0.03849999979138374 
2025-08-28 18:10:08.618798:  
2025-08-28 18:10:08.629494: Epoch 28 
2025-08-28 18:10:08.639231: Current learning rate: 0.00975 
2025-08-28 18:10:24.066282: train_loss -0.0777 
2025-08-28 18:10:24.074663: val_loss -0.0732 
2025-08-28 18:10:24.078836: Pseudo dice [np.float32(0.1764)] 
2025-08-28 18:10:24.087210: Epoch time: 15.45 s 
2025-08-28 18:10:24.090562: Yayy! New best EMA pseudo Dice: 0.052299998700618744 
2025-08-28 18:10:24.872324:  
2025-08-28 18:10:24.880574: Epoch 29 
2025-08-28 18:10:24.884747: Current learning rate: 0.00974 
2025-08-28 18:10:40.201817: train_loss -0.0704 
2025-08-28 18:10:40.211342: val_loss -0.0876 
2025-08-28 18:10:40.219031: Pseudo dice [np.float32(0.2039)] 
2025-08-28 18:10:40.223762: Epoch time: 15.33 s 
2025-08-28 18:10:40.232084: Yayy! New best EMA pseudo Dice: 0.06750000268220901 
2025-08-28 18:10:41.004691:  
2025-08-28 18:10:41.012174: Epoch 30 
2025-08-28 18:10:41.017453: Current learning rate: 0.00973 
2025-08-28 18:10:56.322908: train_loss -0.061 
2025-08-28 18:10:56.331854: val_loss -0.1015 
2025-08-28 18:10:56.335975: Pseudo dice [np.float32(0.1757)] 
2025-08-28 18:10:56.343778: Epoch time: 15.32 s 
2025-08-28 18:10:56.347900: Yayy! New best EMA pseudo Dice: 0.07829999923706055 
2025-08-28 18:10:57.139271:  
2025-08-28 18:10:57.146634: Epoch 31 
2025-08-28 18:10:57.154018: Current learning rate: 0.00972 
2025-08-28 18:11:11.976150: train_loss -0.0629 
2025-08-28 18:11:11.984601: val_loss -0.0671 
2025-08-28 18:11:11.988767: Pseudo dice [np.float32(0.1709)] 
2025-08-28 18:11:11.996444: Epoch time: 14.84 s 
2025-08-28 18:11:12.001695: Yayy! New best EMA pseudo Dice: 0.08760000020265579 
2025-08-28 18:11:12.763135:  
2025-08-28 18:11:12.771525: Epoch 32 
2025-08-28 18:11:12.777076: Current learning rate: 0.00971 
2025-08-28 18:11:28.108801: train_loss -0.0663 
2025-08-28 18:11:28.117199: val_loss -0.0499 
2025-08-28 18:11:28.125471: Pseudo dice [np.float32(0.1152)] 
2025-08-28 18:11:28.130788: Epoch time: 15.35 s 
2025-08-28 18:11:28.134457: Yayy! New best EMA pseudo Dice: 0.09030000120401382 
2025-08-28 18:11:28.929272:  
2025-08-28 18:11:28.936658: Epoch 33 
2025-08-28 18:11:28.941912: Current learning rate: 0.0097 
2025-08-28 18:11:43.346939: train_loss -0.0896 
2025-08-28 18:11:43.353674: val_loss -0.0901 
2025-08-28 18:11:43.357291: Pseudo dice [np.float32(0.1919)] 
2025-08-28 18:11:43.366634: Epoch time: 14.42 s 
2025-08-28 18:11:43.370145: Yayy! New best EMA pseudo Dice: 0.10050000250339508 
2025-08-28 18:11:44.298815:  
2025-08-28 18:11:44.307256: Epoch 34 
2025-08-28 18:11:44.313505: Current learning rate: 0.00969 
2025-08-28 18:11:59.223174: train_loss -0.079 
2025-08-28 18:11:59.231546: val_loss -0.0845 
2025-08-28 18:11:59.235689: Pseudo dice [np.float32(0.1788)] 
2025-08-28 18:11:59.243427: Epoch time: 14.93 s 
2025-08-28 18:11:59.248759: Yayy! New best EMA pseudo Dice: 0.10830000042915344 
2025-08-28 18:12:00.061421:  
2025-08-28 18:12:00.075107: Epoch 35 
2025-08-28 18:12:00.088601: Current learning rate: 0.00968 
2025-08-28 18:12:15.752205: train_loss -0.0916 
2025-08-28 18:12:15.760214: val_loss -0.0893 
2025-08-28 18:12:15.764739: Pseudo dice [np.float32(0.1486)] 
2025-08-28 18:12:15.770004: Epoch time: 15.69 s 
2025-08-28 18:12:15.773637: Yayy! New best EMA pseudo Dice: 0.11230000108480453 
2025-08-28 18:12:16.551833:  
2025-08-28 18:12:16.559160: Epoch 36 
2025-08-28 18:12:16.564325: Current learning rate: 0.00968 
2025-08-28 18:12:31.054963: train_loss -0.0795 
2025-08-28 18:12:31.059148: val_loss -0.0908 
2025-08-28 18:12:31.067820: Pseudo dice [np.float32(0.2165)] 
2025-08-28 18:12:31.072762: Epoch time: 14.5 s 
2025-08-28 18:12:31.077758: Yayy! New best EMA pseudo Dice: 0.12280000001192093 
2025-08-28 18:12:31.876491:  
2025-08-28 18:12:31.886033: Epoch 37 
2025-08-28 18:12:31.891191: Current learning rate: 0.00967 
2025-08-28 18:12:46.991282: train_loss -0.1035 
2025-08-28 18:12:46.995905: val_loss -0.0893 
2025-08-28 18:12:47.000041: Pseudo dice [np.float32(0.1759)] 
2025-08-28 18:12:47.008426: Epoch time: 15.12 s 
2025-08-28 18:12:47.013632: Yayy! New best EMA pseudo Dice: 0.12809999287128448 
2025-08-28 18:12:47.790371:  
2025-08-28 18:12:47.798729: Epoch 38 
2025-08-28 18:12:47.803867: Current learning rate: 0.00966 
2025-08-28 18:13:02.788831: train_loss -0.0915 
2025-08-28 18:13:02.799160: val_loss -0.0752 
2025-08-28 18:13:02.803373: Pseudo dice [np.float32(0.1336)] 
2025-08-28 18:13:02.810356: Epoch time: 15.0 s 
2025-08-28 18:13:02.816354: Yayy! New best EMA pseudo Dice: 0.12860000133514404 
2025-08-28 18:13:03.611338:  
2025-08-28 18:13:03.618711: Epoch 39 
2025-08-28 18:13:03.624898: Current learning rate: 0.00965 
2025-08-28 18:13:18.577402: train_loss -0.0948 
2025-08-28 18:13:18.585764: val_loss -0.1131 
2025-08-28 18:13:18.590228: Pseudo dice [np.float32(0.2231)] 
2025-08-28 18:13:18.597074: Epoch time: 14.97 s 
2025-08-28 18:13:18.603004: Yayy! New best EMA pseudo Dice: 0.13809999823570251 
2025-08-28 18:13:19.559632:  
2025-08-28 18:13:19.569106: Epoch 40 
2025-08-28 18:13:19.575248: Current learning rate: 0.00964 
2025-08-28 18:13:33.454820: train_loss -0.0853 
2025-08-28 18:13:33.463694: val_loss -0.0761 
2025-08-28 18:13:33.471484: Pseudo dice [np.float32(0.1234)] 
2025-08-28 18:13:33.478438: Epoch time: 13.9 s 
2025-08-28 18:13:34.108430:  
2025-08-28 18:13:34.117786: Epoch 41 
2025-08-28 18:13:34.123130: Current learning rate: 0.00963 
2025-08-28 18:13:49.011950: train_loss -0.1023 
2025-08-28 18:13:49.020307: val_loss -0.137 
2025-08-28 18:13:49.024502: Pseudo dice [np.float32(0.2488)] 
2025-08-28 18:13:49.033349: Epoch time: 14.9 s 
2025-08-28 18:13:49.037800: Yayy! New best EMA pseudo Dice: 0.1477999985218048 
2025-08-28 18:13:49.818323:  
2025-08-28 18:13:49.826224: Epoch 42 
2025-08-28 18:13:49.832470: Current learning rate: 0.00962 
2025-08-28 18:14:04.727659: train_loss -0.0877 
2025-08-28 18:14:04.736001: val_loss -0.0881 
2025-08-28 18:14:04.744340: Pseudo dice [np.float32(0.2225)] 
2025-08-28 18:14:04.751038: Epoch time: 14.91 s 
2025-08-28 18:14:04.757502: Yayy! New best EMA pseudo Dice: 0.15530000627040863 
2025-08-28 18:14:05.513788:  
2025-08-28 18:14:05.524132: Epoch 43 
2025-08-28 18:14:05.532601: Current learning rate: 0.00961 
2025-08-28 18:14:20.485323: train_loss -0.0927 
2025-08-28 18:14:20.493358: val_loss -0.0982 
2025-08-28 18:14:20.501784: Pseudo dice [np.float32(0.1881)] 
2025-08-28 18:14:20.507020: Epoch time: 14.97 s 
2025-08-28 18:14:20.510770: Yayy! New best EMA pseudo Dice: 0.15860000252723694 
2025-08-28 18:14:21.285763:  
2025-08-28 18:14:21.294037: Epoch 44 
2025-08-28 18:14:21.300453: Current learning rate: 0.0096 
2025-08-28 18:14:37.177037: train_loss -0.0899 
2025-08-28 18:14:37.185066: val_loss -0.1094 
2025-08-28 18:14:37.193632: Pseudo dice [np.float32(0.258)] 
2025-08-28 18:14:37.201709: Epoch time: 15.89 s 
2025-08-28 18:14:37.206787: Yayy! New best EMA pseudo Dice: 0.16850000619888306 
2025-08-28 18:14:37.973216:  
2025-08-28 18:14:37.983933: Epoch 45 
2025-08-28 18:14:37.989888: Current learning rate: 0.00959 
2025-08-28 18:14:53.163516: train_loss -0.0886 
2025-08-28 18:14:53.171864: val_loss -0.1034 
2025-08-28 18:14:53.176028: Pseudo dice [np.float32(0.1906)] 
2025-08-28 18:14:53.183588: Epoch time: 15.19 s 
2025-08-28 18:14:53.188912: Yayy! New best EMA pseudo Dice: 0.17069999873638153 
2025-08-28 18:14:53.956998:  
2025-08-28 18:14:53.965321: Epoch 46 
2025-08-28 18:14:53.970796: Current learning rate: 0.00959 
2025-08-28 18:15:09.767637: train_loss -0.0962 
2025-08-28 18:15:09.780114: val_loss -0.1052 
2025-08-28 18:15:09.784510: Pseudo dice [np.float32(0.2287)] 
2025-08-28 18:15:09.791351: Epoch time: 15.81 s 
2025-08-28 18:15:09.797600: Yayy! New best EMA pseudo Dice: 0.17649999260902405 
2025-08-28 18:15:10.804599:  
2025-08-28 18:15:10.813076: Epoch 47 
2025-08-28 18:15:10.819742: Current learning rate: 0.00958 
2025-08-28 18:15:27.026766: train_loss -0.1082 
2025-08-28 18:15:27.034869: val_loss -0.1284 
2025-08-28 18:15:27.043181: Pseudo dice [np.float32(0.2125)] 
2025-08-28 18:15:27.048492: Epoch time: 16.22 s 
2025-08-28 18:15:27.053239: Yayy! New best EMA pseudo Dice: 0.1800999939441681 
2025-08-28 18:15:27.886751:  
2025-08-28 18:15:27.895117: Epoch 48 
2025-08-28 18:15:27.901204: Current learning rate: 0.00957 
2025-08-28 18:15:44.589855: train_loss -0.0951 
2025-08-28 18:15:44.598186: val_loss -0.08 
2025-08-28 18:15:44.602378: Pseudo dice [np.float32(0.1918)] 
2025-08-28 18:15:44.610411: Epoch time: 16.71 s 
2025-08-28 18:15:44.616963: Yayy! New best EMA pseudo Dice: 0.18129999935626984 
2025-08-28 18:15:45.460465:  
2025-08-28 18:15:45.470057: Epoch 49 
2025-08-28 18:15:45.478063: Current learning rate: 0.00956 
2025-08-28 18:16:01.465034: train_loss -0.105 
2025-08-28 18:16:01.473401: val_loss -0.1293 
2025-08-28 18:16:01.481743: Pseudo dice [np.float32(0.2949)] 
2025-08-28 18:16:01.487979: Epoch time: 16.01 s 
2025-08-28 18:16:01.661051: Yayy! New best EMA pseudo Dice: 0.19269999861717224 
2025-08-28 18:16:02.487393:  
2025-08-28 18:16:02.496382: Epoch 50 
2025-08-28 18:16:02.503608: Current learning rate: 0.00955 
2025-08-28 18:16:19.007861: train_loss -0.2489 
2025-08-28 18:16:19.015888: val_loss -0.2067 
2025-08-28 18:16:19.024247: Pseudo dice [np.float32(0.3946)] 
2025-08-28 18:16:19.029511: Epoch time: 16.52 s 
2025-08-28 18:16:19.036043: Yayy! New best EMA pseudo Dice: 0.21279999613761902 
2025-08-28 18:16:19.909515:  
2025-08-28 18:16:19.918514: Epoch 51 
2025-08-28 18:16:19.926162: Current learning rate: 0.00954 
2025-08-28 18:16:36.821475: train_loss -0.1919 
2025-08-28 18:16:36.829535: val_loss -0.2135 
2025-08-28 18:16:36.833698: Pseudo dice [np.float32(0.3735)] 
2025-08-28 18:16:36.842844: Epoch time: 16.91 s 
2025-08-28 18:16:36.850337: Yayy! New best EMA pseudo Dice: 0.2289000004529953 
2025-08-28 18:16:37.709386:  
2025-08-28 18:16:37.717747: Epoch 52 
2025-08-28 18:16:37.724100: Current learning rate: 0.00953 
2025-08-28 18:16:54.372048: train_loss -0.2058 
2025-08-28 18:16:54.380371: val_loss -0.1785 
2025-08-28 18:16:54.389367: Pseudo dice [np.float32(0.3429)] 
2025-08-28 18:16:54.395000: Epoch time: 16.66 s 
2025-08-28 18:16:54.400627: Yayy! New best EMA pseudo Dice: 0.2402999997138977 
2025-08-28 18:16:55.413589:  
2025-08-28 18:16:55.421934: Epoch 53 
2025-08-28 18:16:55.428269: Current learning rate: 0.00952 
2025-08-28 18:17:11.426714: train_loss -0.1655 
2025-08-28 18:17:11.434909: val_loss -0.2678 
2025-08-28 18:17:11.439409: Pseudo dice [np.float32(0.4206)] 
2025-08-28 18:17:11.446953: Epoch time: 16.01 s 
2025-08-28 18:17:11.452223: Yayy! New best EMA pseudo Dice: 0.2583000063896179 
2025-08-28 18:17:12.289804:  
2025-08-28 18:17:12.298088: Epoch 54 
2025-08-28 18:17:12.304447: Current learning rate: 0.00951 
2025-08-28 18:17:28.352149: train_loss -0.2395 
2025-08-28 18:17:28.360170: val_loss -0.2471 
2025-08-28 18:17:28.364293: Pseudo dice [np.float32(0.4615)] 
2025-08-28 18:17:28.373312: Epoch time: 16.06 s 
2025-08-28 18:17:28.377472: Yayy! New best EMA pseudo Dice: 0.27869999408721924 
2025-08-28 18:17:29.231751:  
2025-08-28 18:17:29.242412: Epoch 55 
2025-08-28 18:17:29.249574: Current learning rate: 0.0095 
2025-08-28 18:17:46.345152: train_loss -0.1959 
2025-08-28 18:17:46.353091: val_loss -0.313 
2025-08-28 18:17:46.357254: Pseudo dice [np.float32(0.5256)] 
2025-08-28 18:17:46.366541: Epoch time: 17.12 s 
2025-08-28 18:17:46.370389: Yayy! New best EMA pseudo Dice: 0.3034000098705292 
2025-08-28 18:17:47.199647:  
2025-08-28 18:17:47.209212: Epoch 56 
2025-08-28 18:17:47.215380: Current learning rate: 0.00949 
2025-08-28 18:18:03.407658: train_loss -0.2206 
2025-08-28 18:18:03.415991: val_loss -0.2911 
2025-08-28 18:18:03.420362: Pseudo dice [np.float32(0.545)] 
2025-08-28 18:18:03.428239: Epoch time: 16.21 s 
2025-08-28 18:18:03.433443: Yayy! New best EMA pseudo Dice: 0.32749998569488525 
2025-08-28 18:18:04.251442:  
2025-08-28 18:18:04.260466: Epoch 57 
2025-08-28 18:18:04.268860: Current learning rate: 0.00949 
2025-08-28 18:18:21.113018: train_loss -0.239 
2025-08-28 18:18:21.121135: val_loss -0.3756 
2025-08-28 18:18:21.125559: Pseudo dice [np.float32(0.6145)] 
2025-08-28 18:18:21.133982: Epoch time: 16.86 s 
2025-08-28 18:18:21.138196: Yayy! New best EMA pseudo Dice: 0.3562000095844269 
2025-08-28 18:18:21.960587:  
2025-08-28 18:18:21.969869: Epoch 58 
2025-08-28 18:18:21.975008: Current learning rate: 0.00948 
2025-08-28 18:18:38.092361: train_loss -0.2388 
2025-08-28 18:18:38.100594: val_loss -0.1718 
2025-08-28 18:18:38.105117: Pseudo dice [np.float32(0.3192)] 
2025-08-28 18:18:38.111481: Epoch time: 16.13 s 
2025-08-28 18:18:38.790842:  
2025-08-28 18:18:38.798105: Epoch 59 
2025-08-28 18:18:38.803307: Current learning rate: 0.00947 
2025-08-28 18:18:55.080015: train_loss -0.2117 
2025-08-28 18:18:55.088728: val_loss -0.2597 
2025-08-28 18:18:55.092822: Pseudo dice [np.float32(0.4441)] 
2025-08-28 18:18:55.096769: Epoch time: 16.29 s 
2025-08-28 18:18:55.104051: Yayy! New best EMA pseudo Dice: 0.36169999837875366 
2025-08-28 18:18:56.111253:  
2025-08-28 18:18:56.119416: Epoch 60 
2025-08-28 18:18:56.125417: Current learning rate: 0.00946 
2025-08-28 18:19:12.080597: train_loss -0.1771 
2025-08-28 18:19:12.088725: val_loss -0.2628 
2025-08-28 18:19:12.093204: Pseudo dice [np.float32(0.483)] 
2025-08-28 18:19:12.099758: Epoch time: 15.97 s 
2025-08-28 18:19:12.105331: Yayy! New best EMA pseudo Dice: 0.37380000948905945 
2025-08-28 18:19:12.951870:  
2025-08-28 18:19:12.962479: Epoch 61 
2025-08-28 18:19:12.968870: Current learning rate: 0.00945 
2025-08-28 18:19:28.972178: train_loss -0.2109 
2025-08-28 18:19:28.980827: val_loss -0.3368 
2025-08-28 18:19:28.984590: Pseudo dice [np.float32(0.5846)] 
2025-08-28 18:19:28.991663: Epoch time: 16.02 s 
2025-08-28 18:19:28.997501: Yayy! New best EMA pseudo Dice: 0.39489999413490295 
2025-08-28 18:19:29.781172:  
2025-08-28 18:19:29.790697: Epoch 62 
2025-08-28 18:19:29.795854: Current learning rate: 0.00944 
2025-08-28 18:19:44.513013: train_loss -0.2481 
2025-08-28 18:19:44.521328: val_loss -0.3846 
2025-08-28 18:19:44.529402: Pseudo dice [np.float32(0.5864)] 
2025-08-28 18:19:44.534235: Epoch time: 14.73 s 
2025-08-28 18:19:44.539204: Yayy! New best EMA pseudo Dice: 0.414000004529953 
2025-08-28 18:19:45.332618:  
2025-08-28 18:19:45.340636: Epoch 63 
2025-08-28 18:19:45.345706: Current learning rate: 0.00943 
2025-08-28 18:20:00.427371: train_loss -0.2625 
2025-08-28 18:20:00.437993: val_loss -0.2942 
2025-08-28 18:20:00.446606: Pseudo dice [np.float32(0.4903)] 
2025-08-28 18:20:00.452842: Epoch time: 15.1 s 
2025-08-28 18:20:00.459804: Yayy! New best EMA pseudo Dice: 0.42170000076293945 
2025-08-28 18:20:01.319030:  
2025-08-28 18:20:01.327358: Epoch 64 
2025-08-28 18:20:01.335726: Current learning rate: 0.00942 
2025-08-28 18:20:20.223909: train_loss -0.2425 
2025-08-28 18:20:20.232340: val_loss -0.2893 
2025-08-28 18:20:20.240103: Pseudo dice [np.float32(0.4455)] 
2025-08-28 18:20:20.246231: Epoch time: 18.91 s 
2025-08-28 18:20:20.253234: Yayy! New best EMA pseudo Dice: 0.42399999499320984 
2025-08-28 18:20:21.368545:  
2025-08-28 18:20:21.392708: Epoch 65 
2025-08-28 18:20:21.405953: Current learning rate: 0.00941 
2025-08-28 18:20:38.900217: train_loss -0.2054 
2025-08-28 18:20:38.909109: val_loss -0.3179 
2025-08-28 18:20:38.913208: Pseudo dice [np.float32(0.5708)] 
2025-08-28 18:20:38.920285: Epoch time: 17.53 s 
2025-08-28 18:20:38.926153: Yayy! New best EMA pseudo Dice: 0.43869999051094055 
2025-08-28 18:20:39.977484:  
2025-08-28 18:20:39.985817: Epoch 66 
2025-08-28 18:20:39.993032: Current learning rate: 0.0094 
2025-08-28 18:20:56.994624: train_loss -0.2772 
2025-08-28 18:20:57.006371: val_loss -0.3575 
2025-08-28 18:20:57.014168: Pseudo dice [np.float32(0.5234)] 
2025-08-28 18:20:57.020344: Epoch time: 17.02 s 
2025-08-28 18:20:57.030045: Yayy! New best EMA pseudo Dice: 0.4472000002861023 
2025-08-28 18:20:57.930765:  
2025-08-28 18:20:57.938061: Epoch 67 
2025-08-28 18:20:57.943223: Current learning rate: 0.00939 
2025-08-28 18:21:14.548775: train_loss -0.2681 
2025-08-28 18:21:14.557135: val_loss -0.3404 
2025-08-28 18:21:14.561334: Pseudo dice [np.float32(0.5608)] 
2025-08-28 18:21:14.567117: Epoch time: 16.62 s 
2025-08-28 18:21:14.570253: Yayy! New best EMA pseudo Dice: 0.4586000144481659 
2025-08-28 18:21:15.379535:  
2025-08-28 18:21:15.386626: Epoch 68 
2025-08-28 18:21:15.392983: Current learning rate: 0.00939 
2025-08-28 18:21:29.688565: train_loss -0.2942 
2025-08-28 18:21:29.696765: val_loss -0.2236 
2025-08-28 18:21:29.701443: Pseudo dice [np.float32(0.4132)] 
2025-08-28 18:21:29.709387: Epoch time: 14.31 s 
2025-08-28 18:21:30.340278:  
2025-08-28 18:21:30.347413: Epoch 69 
2025-08-28 18:21:30.352711: Current learning rate: 0.00938 
2025-08-28 18:21:45.225259: train_loss -0.2749 
2025-08-28 18:21:45.233627: val_loss -0.2829 
2025-08-28 18:21:45.237781: Pseudo dice [np.float32(0.455)] 
2025-08-28 18:21:45.243724: Epoch time: 14.89 s 
2025-08-28 18:21:45.860322:  
2025-08-28 18:21:45.868277: Epoch 70 
2025-08-28 18:21:45.874464: Current learning rate: 0.00937 
2025-08-28 18:22:01.445605: train_loss -0.2578 
2025-08-28 18:22:01.457769: val_loss -0.4085 
2025-08-28 18:22:01.462325: Pseudo dice [np.float32(0.6379)] 
2025-08-28 18:22:01.471277: Epoch time: 15.59 s 
2025-08-28 18:22:01.480492: Yayy! New best EMA pseudo Dice: 0.4724999964237213 
2025-08-28 18:22:02.272110:  
2025-08-28 18:22:02.281626: Epoch 71 
2025-08-28 18:22:02.287637: Current learning rate: 0.00936 
2025-08-28 18:22:17.156785: train_loss -0.3028 
2025-08-28 18:22:17.165447: val_loss -0.3101 
2025-08-28 18:22:17.169573: Pseudo dice [np.float32(0.5114)] 
2025-08-28 18:22:17.177339: Epoch time: 14.89 s 
2025-08-28 18:22:17.182291: Yayy! New best EMA pseudo Dice: 0.4763999879360199 
2025-08-28 18:22:17.972090:  
2025-08-28 18:22:17.979468: Epoch 72 
2025-08-28 18:22:17.984639: Current learning rate: 0.00935 
2025-08-28 18:22:32.826594: train_loss -0.3184 
2025-08-28 18:22:32.834939: val_loss -0.2776 
2025-08-28 18:22:32.839369: Pseudo dice [np.float32(0.4573)] 
2025-08-28 18:22:32.848308: Epoch time: 14.86 s 
2025-08-28 18:22:33.630471:  
2025-08-28 18:22:33.636781: Epoch 73 
2025-08-28 18:22:33.641929: Current learning rate: 0.00934 
2025-08-28 18:22:48.726199: train_loss -0.2618 
2025-08-28 18:22:48.734653: val_loss -0.335 
2025-08-28 18:22:48.742875: Pseudo dice [np.float32(0.5635)] 
2025-08-28 18:22:48.748068: Epoch time: 15.1 s 
2025-08-28 18:22:48.751786: Yayy! New best EMA pseudo Dice: 0.48339998722076416 
2025-08-28 18:22:49.550476:  
2025-08-28 18:22:49.557802: Epoch 74 
2025-08-28 18:22:49.562964: Current learning rate: 0.00933 
2025-08-28 18:23:04.325145: train_loss -0.3216 
2025-08-28 18:23:04.337759: val_loss -0.4431 
2025-08-28 18:23:04.341829: Pseudo dice [np.float32(0.6075)] 
2025-08-28 18:23:04.348462: Epoch time: 14.78 s 
2025-08-28 18:23:04.353702: Yayy! New best EMA pseudo Dice: 0.4957999885082245 
2025-08-28 18:23:05.162964:  
2025-08-28 18:23:05.170221: Epoch 75 
2025-08-28 18:23:05.175369: Current learning rate: 0.00932 
2025-08-28 18:23:20.065822: train_loss -0.3331 
2025-08-28 18:23:20.073872: val_loss -0.3522 
2025-08-28 18:23:20.078270: Pseudo dice [np.float32(0.5329)] 
2025-08-28 18:23:20.086056: Epoch time: 14.9 s 
2025-08-28 18:23:20.092419: Yayy! New best EMA pseudo Dice: 0.49950000643730164 
2025-08-28 18:23:20.886975:  
2025-08-28 18:23:20.894392: Epoch 76 
2025-08-28 18:23:20.899428: Current learning rate: 0.00931 
2025-08-28 18:23:35.969165: train_loss -0.3304 
2025-08-28 18:23:35.973355: val_loss -0.3028 
2025-08-28 18:23:35.981876: Pseudo dice [np.float32(0.4151)] 
2025-08-28 18:23:35.987480: Epoch time: 15.08 s 
2025-08-28 18:23:36.609992:  
2025-08-28 18:23:36.619668: Epoch 77 
2025-08-28 18:23:36.626589: Current learning rate: 0.0093 
2025-08-28 18:23:52.782070: train_loss -0.2628 
2025-08-28 18:23:52.790140: val_loss -0.4987 
2025-08-28 18:23:52.797901: Pseudo dice [np.float32(0.6708)] 
2025-08-28 18:23:52.802353: Epoch time: 16.17 s 
2025-08-28 18:23:52.809006: Yayy! New best EMA pseudo Dice: 0.5090000033378601 
2025-08-28 18:23:53.691899:  
2025-08-28 18:23:53.703161: Epoch 78 
2025-08-28 18:23:53.710394: Current learning rate: 0.0093 
2025-08-28 18:24:09.098098: train_loss -0.3209 
2025-08-28 18:24:09.110715: val_loss -0.2475 
2025-08-28 18:24:09.114847: Pseudo dice [np.float32(0.405)] 
2025-08-28 18:24:09.123671: Epoch time: 15.41 s 
2025-08-28 18:24:09.899526:  
2025-08-28 18:24:09.907851: Epoch 79 
2025-08-28 18:24:09.912038: Current learning rate: 0.00929 
2025-08-28 18:24:25.132224: train_loss -0.239 
2025-08-28 18:24:25.139081: val_loss -0.3484 
2025-08-28 18:24:25.143296: Pseudo dice [np.float32(0.5375)] 
2025-08-28 18:24:25.152208: Epoch time: 15.23 s 
2025-08-28 18:24:25.790397:  
2025-08-28 18:24:25.798747: Epoch 80 
2025-08-28 18:24:25.806082: Current learning rate: 0.00928 
2025-08-28 18:24:40.746136: train_loss -0.3229 
2025-08-28 18:24:40.750799: val_loss -0.4251 
2025-08-28 18:24:40.758894: Pseudo dice [np.float32(0.632)] 
2025-08-28 18:24:40.764738: Epoch time: 14.96 s 
2025-08-28 18:24:40.770954: Yayy! New best EMA pseudo Dice: 0.515500009059906 
2025-08-28 18:24:41.585320:  
2025-08-28 18:24:41.594659: Epoch 81 
2025-08-28 18:24:41.603066: Current learning rate: 0.00927 
2025-08-28 18:24:56.499869: train_loss -0.2924 
2025-08-28 18:24:56.512042: val_loss -0.3565 
2025-08-28 18:24:56.516326: Pseudo dice [np.float32(0.5894)] 
2025-08-28 18:24:56.522094: Epoch time: 14.92 s 
2025-08-28 18:24:56.529101: Yayy! New best EMA pseudo Dice: 0.5228999853134155 
2025-08-28 18:24:57.356591:  
2025-08-28 18:24:57.364087: Epoch 82 
2025-08-28 18:24:57.370351: Current learning rate: 0.00926 
2025-08-28 18:25:11.760565: train_loss -0.3344 
2025-08-28 18:25:11.768988: val_loss -0.386 
2025-08-28 18:25:11.773222: Pseudo dice [np.float32(0.5869)] 
2025-08-28 18:25:11.778972: Epoch time: 14.4 s 
2025-08-28 18:25:11.782127: Yayy! New best EMA pseudo Dice: 0.5292999744415283 
2025-08-28 18:25:12.563291:  
2025-08-28 18:25:12.570567: Epoch 83 
2025-08-28 18:25:12.578780: Current learning rate: 0.00925 
2025-08-28 18:25:27.588893: train_loss -0.3406 
2025-08-28 18:25:27.593125: val_loss -0.4158 
2025-08-28 18:25:27.600787: Pseudo dice [np.float32(0.6747)] 
2025-08-28 18:25:27.606004: Epoch time: 15.03 s 
2025-08-28 18:25:27.610328: Yayy! New best EMA pseudo Dice: 0.5437999963760376 
2025-08-28 18:25:28.561390:  
2025-08-28 18:25:28.568873: Epoch 84 
2025-08-28 18:25:28.574956: Current learning rate: 0.00924 
2025-08-28 18:25:43.801127: train_loss -0.385 
2025-08-28 18:25:43.809307: val_loss -0.381 
2025-08-28 18:25:43.813643: Pseudo dice [np.float32(0.5886)] 
2025-08-28 18:25:43.820427: Epoch time: 15.24 s 
2025-08-28 18:25:43.826314: Yayy! New best EMA pseudo Dice: 0.54830002784729 
2025-08-28 18:25:44.603469:  
2025-08-28 18:25:44.611832: Epoch 85 
2025-08-28 18:25:44.619114: Current learning rate: 0.00923 
2025-08-28 18:25:59.116101: train_loss -0.3236 
2025-08-28 18:25:59.124558: val_loss -0.3989 
2025-08-28 18:25:59.132589: Pseudo dice [np.float32(0.6259)] 
2025-08-28 18:25:59.136762: Epoch time: 14.51 s 
2025-08-28 18:25:59.141905: Yayy! New best EMA pseudo Dice: 0.5559999942779541 
2025-08-28 18:25:59.927031:  
2025-08-28 18:25:59.937438: Epoch 86 
2025-08-28 18:25:59.943829: Current learning rate: 0.00922 
2025-08-28 18:26:15.495034: train_loss -0.3686 
2025-08-28 18:26:15.503578: val_loss -0.4435 
2025-08-28 18:26:15.507544: Pseudo dice [np.float32(0.6435)] 
2025-08-28 18:26:15.515598: Epoch time: 15.57 s 
2025-08-28 18:26:15.520718: Yayy! New best EMA pseudo Dice: 0.5648000240325928 
2025-08-28 18:26:16.303815:  
2025-08-28 18:26:16.310068: Epoch 87 
2025-08-28 18:26:16.315229: Current learning rate: 0.00921 
2025-08-28 18:26:30.593576: train_loss -0.2957 
2025-08-28 18:26:30.601866: val_loss -0.2853 
2025-08-28 18:26:30.606170: Pseudo dice [np.float32(0.5819)] 
2025-08-28 18:26:30.613877: Epoch time: 14.29 s 
2025-08-28 18:26:30.619945: Yayy! New best EMA pseudo Dice: 0.5665000081062317 
2025-08-28 18:26:31.414762:  
2025-08-28 18:26:31.422976: Epoch 88 
2025-08-28 18:26:31.428306: Current learning rate: 0.0092 
2025-08-28 18:26:46.505303: train_loss -0.2981 
2025-08-28 18:26:46.513538: val_loss -0.3906 
2025-08-28 18:26:46.521330: Pseudo dice [np.float32(0.5938)] 
2025-08-28 18:26:46.526551: Epoch time: 15.09 s 
2025-08-28 18:26:46.530816: Yayy! New best EMA pseudo Dice: 0.5691999793052673 
2025-08-28 18:26:47.324356:  
2025-08-28 18:26:47.331815: Epoch 89 
2025-08-28 18:26:47.337856: Current learning rate: 0.0092 
2025-08-28 18:27:02.350207: train_loss -0.3099 
2025-08-28 18:27:02.358561: val_loss -0.3617 
2025-08-28 18:27:02.366890: Pseudo dice [np.float32(0.6116)] 
2025-08-28 18:27:02.371989: Epoch time: 15.03 s 
2025-08-28 18:27:02.375833: Yayy! New best EMA pseudo Dice: 0.5734999775886536 
2025-08-28 18:27:03.176761:  
2025-08-28 18:27:03.183841: Epoch 90 
2025-08-28 18:27:03.189186: Current learning rate: 0.00919 
2025-08-28 18:27:18.107579: train_loss -0.2952 
2025-08-28 18:27:18.115971: val_loss -0.3143 
2025-08-28 18:27:18.120142: Pseudo dice [np.float32(0.5256)] 
2025-08-28 18:27:18.125771: Epoch time: 14.93 s 
2025-08-28 18:27:18.895493:  
2025-08-28 18:27:18.904067: Epoch 91 
2025-08-28 18:27:18.910068: Current learning rate: 0.00918 
2025-08-28 18:27:33.998444: train_loss -0.3343 
2025-08-28 18:27:34.006470: val_loss -0.351 
2025-08-28 18:27:34.010934: Pseudo dice [np.float32(0.6394)] 
2025-08-28 18:27:34.018690: Epoch time: 15.1 s 
2025-08-28 18:27:34.024729: Yayy! New best EMA pseudo Dice: 0.5756999850273132 
2025-08-28 18:27:34.799942:  
2025-08-28 18:27:34.807165: Epoch 92 
2025-08-28 18:27:34.812475: Current learning rate: 0.00917 
2025-08-28 18:27:49.873117: train_loss -0.3779 
2025-08-28 18:27:49.881371: val_loss -0.45 
2025-08-28 18:27:49.889346: Pseudo dice [np.float32(0.6679)] 
2025-08-28 18:27:49.896201: Epoch time: 15.07 s 
2025-08-28 18:27:49.902088: Yayy! New best EMA pseudo Dice: 0.5849999785423279 
2025-08-28 18:27:50.683533:  
2025-08-28 18:27:50.690788: Epoch 93 
2025-08-28 18:27:50.694788: Current learning rate: 0.00916 
2025-08-28 18:28:06.843901: train_loss -0.3663 
2025-08-28 18:28:06.852239: val_loss -0.4289 
2025-08-28 18:28:06.856280: Pseudo dice [np.float32(0.6591)] 
2025-08-28 18:28:06.864103: Epoch time: 16.16 s 
2025-08-28 18:28:06.870111: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-08-28 18:28:07.707776:  
2025-08-28 18:28:07.714951: Epoch 94 
2025-08-28 18:28:07.724744: Current learning rate: 0.00915 
2025-08-28 18:28:24.911405: train_loss -0.3081 
2025-08-28 18:28:24.920230: val_loss -0.418 
2025-08-28 18:28:24.924630: Pseudo dice [np.float32(0.6426)] 
2025-08-28 18:28:24.933561: Epoch time: 17.21 s 
2025-08-28 18:28:24.941857: Yayy! New best EMA pseudo Dice: 0.5974000096321106 
2025-08-28 18:28:25.809207:  
2025-08-28 18:28:25.821739: Epoch 95 
2025-08-28 18:28:25.829816: Current learning rate: 0.00914 
2025-08-28 18:28:42.058232: train_loss -0.2966 
2025-08-28 18:28:42.066513: val_loss -0.3757 
2025-08-28 18:28:42.074892: Pseudo dice [np.float32(0.679)] 
2025-08-28 18:28:42.080374: Epoch time: 16.25 s 
2025-08-28 18:28:42.086740: Yayy! New best EMA pseudo Dice: 0.6055999994277954 
2025-08-28 18:28:42.934638:  
2025-08-28 18:28:42.943963: Epoch 96 
2025-08-28 18:28:42.952472: Current learning rate: 0.00913 
2025-08-28 18:28:59.079263: train_loss -0.2573 
2025-08-28 18:28:59.087631: val_loss -0.3142 
2025-08-28 18:28:59.091392: Pseudo dice [np.float32(0.5615)] 
2025-08-28 18:28:59.099757: Epoch time: 16.15 s 
2025-08-28 18:28:59.946257:  
2025-08-28 18:28:59.954601: Epoch 97 
2025-08-28 18:28:59.961945: Current learning rate: 0.00912 
2025-08-28 18:29:16.175591: train_loss -0.3185 
2025-08-28 18:29:16.183875: val_loss -0.334 
2025-08-28 18:29:16.188008: Pseudo dice [np.float32(0.5524)] 
2025-08-28 18:29:16.196848: Epoch time: 16.23 s 
2025-08-28 18:29:16.878921:  
2025-08-28 18:29:16.886163: Epoch 98 
2025-08-28 18:29:16.891399: Current learning rate: 0.00911 
2025-08-28 18:29:32.792384: train_loss -0.2979 
2025-08-28 18:29:32.800062: val_loss -0.3341 
2025-08-28 18:29:32.804557: Pseudo dice [np.float32(0.5247)] 
2025-08-28 18:29:32.813399: Epoch time: 15.92 s 
2025-08-28 18:29:33.472670:  
2025-08-28 18:29:33.482002: Epoch 99 
2025-08-28 18:29:33.491223: Current learning rate: 0.0091 
2025-08-28 18:29:49.492099: train_loss -0.3615 
2025-08-28 18:29:49.500054: val_loss -0.3302 
2025-08-28 18:29:49.508716: Pseudo dice [np.float32(0.5879)] 
2025-08-28 18:29:49.514681: Epoch time: 16.02 s 
2025-08-28 18:29:50.374767:  
2025-08-28 18:29:50.384190: Epoch 100 
2025-08-28 18:29:50.393755: Current learning rate: 0.0091 
2025-08-28 18:30:06.513182: train_loss -0.3427 
2025-08-28 18:30:06.521591: val_loss -0.3988 
2025-08-28 18:30:06.525767: Pseudo dice [np.float32(0.6601)] 
2025-08-28 18:30:06.532903: Epoch time: 16.14 s 
2025-08-28 18:30:07.208343:  
2025-08-28 18:30:07.215666: Epoch 101 
2025-08-28 18:30:07.221747: Current learning rate: 0.00909 
2025-08-28 18:30:23.292500: train_loss -0.2938 
2025-08-28 18:30:23.300485: val_loss -0.3055 
2025-08-28 18:30:23.308903: Pseudo dice [np.float32(0.552)] 
2025-08-28 18:30:23.313018: Epoch time: 16.09 s 
2025-08-28 18:30:23.998043:  
2025-08-28 18:30:24.009451: Epoch 102 
2025-08-28 18:30:24.015228: Current learning rate: 0.00908 
2025-08-28 18:30:40.163426: train_loss -0.2695 
2025-08-28 18:30:40.171827: val_loss -0.2855 
2025-08-28 18:30:40.176032: Pseudo dice [np.float32(0.4282)] 
2025-08-28 18:30:40.182075: Epoch time: 16.17 s 
2025-08-28 18:30:40.854455:  
2025-08-28 18:30:40.861707: Epoch 103 
2025-08-28 18:30:40.868152: Current learning rate: 0.00907 
2025-08-28 18:30:57.018110: train_loss -0.3091 
2025-08-28 18:30:57.026163: val_loss -0.3457 
2025-08-28 18:30:57.034021: Pseudo dice [np.float32(0.5807)] 
2025-08-28 18:30:57.038353: Epoch time: 16.17 s 
2025-08-28 18:30:57.879768:  
2025-08-28 18:30:57.889044: Epoch 104 
2025-08-28 18:30:57.894353: Current learning rate: 0.00906 
2025-08-28 18:31:14.195460: train_loss -0.317 
2025-08-28 18:31:14.201822: val_loss -0.3174 
2025-08-28 18:31:14.209525: Pseudo dice [np.float32(0.5154)] 
2025-08-28 18:31:14.214799: Epoch time: 16.32 s 
2025-08-28 18:31:14.894660:  
2025-08-28 18:31:14.903008: Epoch 105 
2025-08-28 18:31:14.910243: Current learning rate: 0.00905 
2025-08-28 18:31:31.143532: train_loss -0.3346 
2025-08-28 18:31:31.151386: val_loss -0.3594 
2025-08-28 18:31:31.156201: Pseudo dice [np.float32(0.5893)] 
2025-08-28 18:31:31.162314: Epoch time: 16.25 s 
2025-08-28 18:31:31.839602:  
2025-08-28 18:31:31.846899: Epoch 106 
2025-08-28 18:31:31.853257: Current learning rate: 0.00904 
2025-08-28 18:31:48.152244: train_loss -0.3771 
2025-08-28 18:31:48.160606: val_loss -0.3084 
2025-08-28 18:31:48.168934: Pseudo dice [np.float32(0.6067)] 
2025-08-28 18:31:48.174889: Epoch time: 16.31 s 
2025-08-28 18:31:48.861009:  
2025-08-28 18:31:48.869244: Epoch 107 
2025-08-28 18:31:48.876292: Current learning rate: 0.00903 
2025-08-28 18:32:05.052490: train_loss -0.3339 
2025-08-28 18:32:05.060741: val_loss -0.4201 
2025-08-28 18:32:05.068740: Pseudo dice [np.float32(0.645)] 
2025-08-28 18:32:05.074247: Epoch time: 16.19 s 
2025-08-28 18:32:05.760967:  
2025-08-28 18:32:05.769436: Epoch 108 
2025-08-28 18:32:05.775618: Current learning rate: 0.00902 
2025-08-28 18:32:21.989778: train_loss -0.3954 
2025-08-28 18:32:21.998152: val_loss -0.4534 
2025-08-28 18:32:22.002650: Pseudo dice [np.float32(0.7121)] 
2025-08-28 18:32:22.011978: Epoch time: 16.23 s 
2025-08-28 18:32:22.693529:  
2025-08-28 18:32:22.700832: Epoch 109 
2025-08-28 18:32:22.706018: Current learning rate: 0.00901 
2025-08-28 18:32:38.898709: train_loss -0.3913 
2025-08-28 18:32:38.907036: val_loss -0.413 
2025-08-28 18:32:38.910870: Pseudo dice [np.float32(0.6634)] 
2025-08-28 18:32:38.919074: Epoch time: 16.21 s 
2025-08-28 18:32:39.607223:  
2025-08-28 18:32:39.614566: Epoch 110 
2025-08-28 18:32:39.619744: Current learning rate: 0.009 
2025-08-28 18:32:55.978318: train_loss -0.3619 
2025-08-28 18:32:55.990829: val_loss -0.4006 
2025-08-28 18:32:55.994982: Pseudo dice [np.float32(0.595)] 
2025-08-28 18:32:56.001001: Epoch time: 16.37 s 
2025-08-28 18:32:56.846463:  
2025-08-28 18:32:56.854877: Epoch 111 
2025-08-28 18:32:56.863696: Current learning rate: 0.009 
2025-08-28 18:33:13.193496: train_loss -0.34 
2025-08-28 18:33:13.199658: val_loss -0.3531 
2025-08-28 18:33:13.207623: Pseudo dice [np.float32(0.537)] 
2025-08-28 18:33:13.211791: Epoch time: 16.35 s 
2025-08-28 18:33:13.866441:  
2025-08-28 18:33:13.874770: Epoch 112 
2025-08-28 18:33:13.880109: Current learning rate: 0.00899 
2025-08-28 18:33:29.887040: train_loss -0.3787 
2025-08-28 18:33:29.895516: val_loss -0.3119 
2025-08-28 18:33:29.903355: Pseudo dice [np.float32(0.562)] 
2025-08-28 18:33:29.909150: Epoch time: 16.02 s 
2025-08-28 18:33:30.587380:  
2025-08-28 18:33:30.596833: Epoch 113 
2025-08-28 18:33:30.606101: Current learning rate: 0.00898 
2025-08-28 18:33:46.728001: train_loss -0.3156 
2025-08-28 18:33:46.733109: val_loss -0.3405 
2025-08-28 18:33:46.741140: Pseudo dice [np.float32(0.5811)] 
2025-08-28 18:33:46.746488: Epoch time: 16.14 s 
2025-08-28 18:33:47.421721:  
2025-08-28 18:33:47.429082: Epoch 114 
2025-08-28 18:33:47.434095: Current learning rate: 0.00897 
2025-08-28 18:34:03.738122: train_loss -0.3341 
2025-08-28 18:34:03.750107: val_loss -0.3604 
2025-08-28 18:34:03.754341: Pseudo dice [np.float32(0.5741)] 
2025-08-28 18:34:03.761083: Epoch time: 16.32 s 
2025-08-28 18:34:04.443092:  
2025-08-28 18:34:04.452056: Epoch 115 
2025-08-28 18:34:04.459775: Current learning rate: 0.00896 
2025-08-28 18:34:20.700394: train_loss -0.317 
2025-08-28 18:34:20.708624: val_loss -0.3411 
2025-08-28 18:34:20.712890: Pseudo dice [np.float32(0.5909)] 
2025-08-28 18:34:20.719585: Epoch time: 16.26 s 
2025-08-28 18:34:21.417240:  
2025-08-28 18:34:21.425673: Epoch 116 
2025-08-28 18:34:21.431909: Current learning rate: 0.00895 
2025-08-28 18:34:37.617384: train_loss -0.3509 
2025-08-28 18:34:37.625529: val_loss -0.3908 
2025-08-28 18:34:37.629389: Pseudo dice [np.float32(0.6385)] 
2025-08-28 18:34:37.637715: Epoch time: 16.2 s 
2025-08-28 18:34:38.328938:  
2025-08-28 18:34:38.337286: Epoch 117 
2025-08-28 18:34:38.343600: Current learning rate: 0.00894 
2025-08-28 18:34:54.759302: train_loss -0.2989 
2025-08-28 18:34:54.767774: val_loss -0.4463 
2025-08-28 18:34:54.771909: Pseudo dice [np.float32(0.7025)] 
2025-08-28 18:34:54.778207: Epoch time: 16.43 s 
2025-08-28 18:34:55.624360:  
2025-08-28 18:34:55.631793: Epoch 118 
2025-08-28 18:34:55.636851: Current learning rate: 0.00893 
2025-08-28 18:35:12.005680: train_loss -0.3442 
2025-08-28 18:35:12.014062: val_loss -0.4356 
2025-08-28 18:35:12.018302: Pseudo dice [np.float32(0.6385)] 
2025-08-28 18:35:12.026133: Epoch time: 16.38 s 
2025-08-28 18:35:12.032185: Yayy! New best EMA pseudo Dice: 0.608299970626831 
2025-08-28 18:35:12.875900:  
2025-08-28 18:35:12.885324: Epoch 119 
2025-08-28 18:35:12.890594: Current learning rate: 0.00892 
2025-08-28 18:35:29.131026: train_loss -0.3231 
2025-08-28 18:35:29.139550: val_loss -0.3736 
2025-08-28 18:35:29.143642: Pseudo dice [np.float32(0.6611)] 
2025-08-28 18:35:29.149632: Epoch time: 16.26 s 
2025-08-28 18:35:29.156402: Yayy! New best EMA pseudo Dice: 0.6136000156402588 
2025-08-28 18:35:30.045259:  
2025-08-28 18:35:30.054565: Epoch 120 
2025-08-28 18:35:30.063011: Current learning rate: 0.00891 
2025-08-28 18:35:46.189823: train_loss -0.3158 
2025-08-28 18:35:46.198363: val_loss -0.4732 
2025-08-28 18:35:46.206567: Pseudo dice [np.float32(0.6689)] 
2025-08-28 18:35:46.213425: Epoch time: 16.15 s 
2025-08-28 18:35:46.219516: Yayy! New best EMA pseudo Dice: 0.6190999746322632 
2025-08-28 18:35:47.123568:  
2025-08-28 18:35:47.130920: Epoch 121 
2025-08-28 18:35:47.137247: Current learning rate: 0.0089 
2025-08-28 18:36:03.144388: train_loss -0.3351 
2025-08-28 18:36:03.152642: val_loss -0.4325 
2025-08-28 18:36:03.156843: Pseudo dice [np.float32(0.7273)] 
2025-08-28 18:36:03.164788: Epoch time: 16.02 s 
2025-08-28 18:36:03.169894: Yayy! New best EMA pseudo Dice: 0.6298999786376953 
2025-08-28 18:36:04.045635:  
2025-08-28 18:36:04.056220: Epoch 122 
2025-08-28 18:36:04.066210: Current learning rate: 0.00889 
2025-08-28 18:36:19.989922: train_loss -0.3928 
2025-08-28 18:36:19.999061: val_loss -0.4366 
2025-08-28 18:36:20.003245: Pseudo dice [np.float32(0.648)] 
2025-08-28 18:36:20.012170: Epoch time: 15.95 s 
2025-08-28 18:36:20.018558: Yayy! New best EMA pseudo Dice: 0.6316999793052673 
2025-08-28 18:36:20.882308:  
2025-08-28 18:36:20.890213: Epoch 123 
2025-08-28 18:36:20.897010: Current learning rate: 0.00889 
2025-08-28 18:36:36.915463: train_loss -0.3633 
2025-08-28 18:36:36.923884: val_loss -0.3851 
2025-08-28 18:36:36.932220: Pseudo dice [np.float32(0.6074)] 
2025-08-28 18:36:36.937911: Epoch time: 16.04 s 
2025-08-28 18:36:37.566800:  
2025-08-28 18:36:37.574264: Epoch 124 
2025-08-28 18:36:37.580364: Current learning rate: 0.00888 
2025-08-28 18:36:52.643366: train_loss -0.3803 
2025-08-28 18:36:52.651502: val_loss -0.3474 
2025-08-28 18:36:52.656232: Pseudo dice [np.float32(0.5194)] 
2025-08-28 18:36:52.662898: Epoch time: 15.08 s 
2025-08-28 18:36:53.445153:  
2025-08-28 18:36:53.453469: Epoch 125 
2025-08-28 18:36:53.461962: Current learning rate: 0.00887 
2025-08-28 18:37:08.501641: train_loss -0.3786 
2025-08-28 18:37:08.513232: val_loss -0.5129 
2025-08-28 18:37:08.517898: Pseudo dice [np.float32(0.753)] 
2025-08-28 18:37:08.523581: Epoch time: 15.06 s 
2025-08-28 18:37:08.526766: Yayy! New best EMA pseudo Dice: 0.6317999958992004 
2025-08-28 18:37:09.322309:  
2025-08-28 18:37:09.330647: Epoch 126 
2025-08-28 18:37:09.338024: Current learning rate: 0.00886 
2025-08-28 18:37:24.466755: train_loss -0.3352 
2025-08-28 18:37:24.475121: val_loss -0.4073 
2025-08-28 18:37:24.479607: Pseudo dice [np.float32(0.692)] 
2025-08-28 18:37:24.486395: Epoch time: 15.15 s 
2025-08-28 18:37:24.492450: Yayy! New best EMA pseudo Dice: 0.6377999782562256 
2025-08-28 18:37:25.276973:  
2025-08-28 18:37:25.286263: Epoch 127 
2025-08-28 18:37:25.292403: Current learning rate: 0.00885 
2025-08-28 18:37:40.090680: train_loss -0.3617 
2025-08-28 18:37:40.099339: val_loss -0.4116 
2025-08-28 18:37:40.103197: Pseudo dice [np.float32(0.6822)] 
2025-08-28 18:37:40.111219: Epoch time: 14.82 s 
2025-08-28 18:37:40.117250: Yayy! New best EMA pseudo Dice: 0.6421999931335449 
2025-08-28 18:37:40.911175:  
2025-08-28 18:37:40.918525: Epoch 128 
2025-08-28 18:37:40.923693: Current learning rate: 0.00884 
2025-08-28 18:37:56.057057: train_loss -0.3041 
2025-08-28 18:37:56.065384: val_loss -0.5012 
2025-08-28 18:37:56.073414: Pseudo dice [np.float32(0.6599)] 
2025-08-28 18:37:56.078428: Epoch time: 15.15 s 
2025-08-28 18:37:56.082622: Yayy! New best EMA pseudo Dice: 0.6439999938011169 
2025-08-28 18:37:56.886800:  
2025-08-28 18:37:56.894826: Epoch 129 
2025-08-28 18:37:56.902286: Current learning rate: 0.00883 
2025-08-28 18:38:11.392837: train_loss -0.2837 
2025-08-28 18:38:11.401612: val_loss -0.372 
2025-08-28 18:38:11.409563: Pseudo dice [np.float32(0.6518)] 
2025-08-28 18:38:11.415026: Epoch time: 14.51 s 
2025-08-28 18:38:11.422606: Yayy! New best EMA pseudo Dice: 0.6448000073432922 
2025-08-28 18:38:12.241507:  
2025-08-28 18:38:12.248902: Epoch 130 
2025-08-28 18:38:12.253977: Current learning rate: 0.00882 
2025-08-28 18:38:27.963504: train_loss -0.3942 
2025-08-28 18:38:27.972125: val_loss -0.4133 
2025-08-28 18:38:27.980575: Pseudo dice [np.float32(0.6324)] 
2025-08-28 18:38:27.986288: Epoch time: 15.72 s 
2025-08-28 18:38:28.766315:  
2025-08-28 18:38:28.774666: Epoch 131 
2025-08-28 18:38:28.780803: Current learning rate: 0.00881 
2025-08-28 18:38:43.758685: train_loss -0.3336 
2025-08-28 18:38:43.767116: val_loss -0.3864 
2025-08-28 18:38:43.771581: Pseudo dice [np.float32(0.5727)] 
2025-08-28 18:38:43.781042: Epoch time: 14.99 s 
2025-08-28 18:38:44.406914:  
2025-08-28 18:38:44.415263: Epoch 132 
2025-08-28 18:38:44.421517: Current learning rate: 0.0088 
2025-08-28 18:38:59.674765: train_loss -0.3495 
2025-08-28 18:38:59.687227: val_loss -0.4178 
2025-08-28 18:38:59.691384: Pseudo dice [np.float32(0.7108)] 
2025-08-28 18:38:59.699996: Epoch time: 15.27 s 
2025-08-28 18:39:00.415573:  
2025-08-28 18:39:00.423928: Epoch 133 
2025-08-28 18:39:00.429131: Current learning rate: 0.00879 
2025-08-28 18:39:16.203750: train_loss -0.3289 
2025-08-28 18:39:16.212161: val_loss -0.4436 
2025-08-28 18:39:16.216293: Pseudo dice [np.float32(0.6664)] 
2025-08-28 18:39:16.224167: Epoch time: 15.79 s 
2025-08-28 18:39:16.229630: Yayy! New best EMA pseudo Dice: 0.6460999846458435 
2025-08-28 18:39:17.062354:  
2025-08-28 18:39:17.070714: Epoch 134 
2025-08-28 18:39:17.079235: Current learning rate: 0.00879 
2025-08-28 18:39:32.502767: train_loss -0.3665 
2025-08-28 18:39:32.511093: val_loss -0.3646 
2025-08-28 18:39:32.516003: Pseudo dice [np.float32(0.5691)] 
2025-08-28 18:39:32.521587: Epoch time: 15.44 s 
2025-08-28 18:39:33.160754:  
2025-08-28 18:39:33.170278: Epoch 135 
2025-08-28 18:39:33.176456: Current learning rate: 0.00878 
2025-08-28 18:39:48.348571: train_loss -0.4164 
2025-08-28 18:39:48.356559: val_loss -0.4216 
2025-08-28 18:39:48.360705: Pseudo dice [np.float32(0.6078)] 
2025-08-28 18:39:48.367692: Epoch time: 15.19 s 
2025-08-28 18:39:49.000603:  
2025-08-28 18:39:49.009016: Epoch 136 
2025-08-28 18:39:49.016315: Current learning rate: 0.00877 
2025-08-28 18:40:04.130367: train_loss -0.3707 
2025-08-28 18:40:04.138657: val_loss -0.3637 
2025-08-28 18:40:04.147009: Pseudo dice [np.float32(0.6567)] 
2025-08-28 18:40:04.151196: Epoch time: 15.13 s 
2025-08-28 18:40:04.792356:  
2025-08-28 18:40:04.801799: Epoch 137 
2025-08-28 18:40:04.808033: Current learning rate: 0.00876 
2025-08-28 18:40:20.326171: train_loss -0.3092 
2025-08-28 18:40:20.334480: val_loss -0.3134 
2025-08-28 18:40:20.342597: Pseudo dice [np.float32(0.5632)] 
2025-08-28 18:40:20.347635: Epoch time: 15.53 s 
2025-08-28 18:40:20.984635:  
2025-08-28 18:40:20.991831: Epoch 138 
2025-08-28 18:40:20.997142: Current learning rate: 0.00875 
2025-08-28 18:40:36.930194: train_loss -0.3922 
2025-08-28 18:40:36.938540: val_loss -0.4008 
2025-08-28 18:40:36.942758: Pseudo dice [np.float32(0.6866)] 
2025-08-28 18:40:36.951587: Epoch time: 15.95 s 
2025-08-28 18:40:37.657105:  
2025-08-28 18:40:37.665107: Epoch 139 
2025-08-28 18:40:37.672041: Current learning rate: 0.00874 
2025-08-28 18:40:54.217890: train_loss -0.3558 
2025-08-28 18:40:54.225911: val_loss -0.3191 
2025-08-28 18:40:54.230697: Pseudo dice [np.float32(0.5478)] 
2025-08-28 18:40:54.236709: Epoch time: 16.56 s 
2025-08-28 18:40:54.932075:  
2025-08-28 18:40:54.944347: Epoch 140 
2025-08-28 18:40:54.950300: Current learning rate: 0.00873 
2025-08-28 18:41:11.710756: train_loss -0.3469 
2025-08-28 18:41:11.719037: val_loss -0.4201 
2025-08-28 18:41:11.726844: Pseudo dice [np.float32(0.6575)] 
2025-08-28 18:41:11.732110: Epoch time: 16.78 s 
2025-08-28 18:41:12.415061:  
2025-08-28 18:41:12.422376: Epoch 141 
2025-08-28 18:41:12.427527: Current learning rate: 0.00872 
2025-08-28 18:41:29.165548: train_loss -0.3607 
2025-08-28 18:41:29.173565: val_loss -0.3963 
2025-08-28 18:41:29.178127: Pseudo dice [np.float32(0.6176)] 
2025-08-28 18:41:29.185046: Epoch time: 16.75 s 
2025-08-28 18:41:29.878290:  
2025-08-28 18:41:29.886639: Epoch 142 
2025-08-28 18:41:29.892069: Current learning rate: 0.00871 
2025-08-28 18:41:47.100247: train_loss -0.3581 
2025-08-28 18:41:47.108446: val_loss -0.3691 
2025-08-28 18:41:47.112691: Pseudo dice [np.float32(0.6754)] 
2025-08-28 18:41:47.120620: Epoch time: 17.22 s 
2025-08-28 18:41:47.778570:  
2025-08-28 18:41:47.785938: Epoch 143 
2025-08-28 18:41:47.791012: Current learning rate: 0.0087 
2025-08-28 18:42:04.709457: train_loss -0.3488 
2025-08-28 18:42:04.717790: val_loss -0.3466 
2025-08-28 18:42:04.722082: Pseudo dice [np.float32(0.5957)] 
2025-08-28 18:42:04.729978: Epoch time: 16.93 s 
2025-08-28 18:42:05.552573:  
2025-08-28 18:42:05.559764: Epoch 144 
2025-08-28 18:42:05.566114: Current learning rate: 0.00869 
2025-08-28 18:42:22.539756: train_loss -0.3656 
2025-08-28 18:42:22.548099: val_loss -0.3725 
2025-08-28 18:42:22.555788: Pseudo dice [np.float32(0.733)] 
2025-08-28 18:42:22.561214: Epoch time: 16.99 s 
2025-08-28 18:42:23.270216:  
2025-08-28 18:42:23.277532: Epoch 145 
2025-08-28 18:42:23.283763: Current learning rate: 0.00868 
2025-08-28 18:42:40.156600: train_loss -0.3353 
2025-08-28 18:42:40.161115: val_loss -0.3822 
2025-08-28 18:42:40.169122: Pseudo dice [np.float32(0.6477)] 
2025-08-28 18:42:40.173720: Epoch time: 16.88 s 
2025-08-28 18:42:40.847154:  
2025-08-28 18:42:40.855480: Epoch 146 
2025-08-28 18:42:40.860736: Current learning rate: 0.00868 
2025-08-28 18:42:57.587225: train_loss -0.3737 
2025-08-28 18:42:57.595641: val_loss -0.4829 
2025-08-28 18:42:57.603397: Pseudo dice [np.float32(0.6906)] 
2025-08-28 18:42:57.607816: Epoch time: 16.74 s 
2025-08-28 18:42:58.325945:  
2025-08-28 18:42:58.333409: Epoch 147 
2025-08-28 18:42:58.339599: Current learning rate: 0.00867 
2025-08-28 18:43:15.083337: train_loss -0.3983 
2025-08-28 18:43:15.088046: val_loss -0.4168 
2025-08-28 18:43:15.096513: Pseudo dice [np.float32(0.6504)] 
2025-08-28 18:43:15.101455: Epoch time: 16.76 s 
2025-08-28 18:43:15.105283: Yayy! New best EMA pseudo Dice: 0.6462000012397766 
2025-08-28 18:43:15.979121:  
2025-08-28 18:43:15.988401: Epoch 148 
2025-08-28 18:43:15.993750: Current learning rate: 0.00866 
2025-08-28 18:43:33.026818: train_loss -0.3704 
2025-08-28 18:43:33.035167: val_loss -0.4096 
2025-08-28 18:43:33.043462: Pseudo dice [np.float32(0.6228)] 
2025-08-28 18:43:33.048557: Epoch time: 17.05 s 
2025-08-28 18:43:33.734715:  
2025-08-28 18:43:33.741657: Epoch 149 
2025-08-28 18:43:33.746870: Current learning rate: 0.00865 
2025-08-28 18:43:50.619290: train_loss -0.3793 
2025-08-28 18:43:50.627595: val_loss -0.4474 
2025-08-28 18:43:50.635982: Pseudo dice [np.float32(0.7496)] 
2025-08-28 18:43:50.642218: Epoch time: 16.89 s 
2025-08-28 18:43:50.965187: Yayy! New best EMA pseudo Dice: 0.6543999910354614 
2025-08-28 18:43:51.837837:  
2025-08-28 18:43:51.845025: Epoch 150 
2025-08-28 18:43:51.851518: Current learning rate: 0.00864 
2025-08-28 18:44:08.678963: train_loss -0.3762 
2025-08-28 18:44:08.691499: val_loss -0.4425 
2025-08-28 18:44:08.695662: Pseudo dice [np.float32(0.6813)] 
2025-08-28 18:44:08.701085: Epoch time: 16.84 s 
2025-08-28 18:44:08.704623: Yayy! New best EMA pseudo Dice: 0.6571000218391418 
2025-08-28 18:44:09.589892:  
2025-08-28 18:44:09.598236: Epoch 151 
2025-08-28 18:44:09.606594: Current learning rate: 0.00863 
2025-08-28 18:44:25.599695: train_loss -0.387 
2025-08-28 18:44:25.608552: val_loss -0.3797 
2025-08-28 18:44:25.616413: Pseudo dice [np.float32(0.6606)] 
2025-08-28 18:44:25.622617: Epoch time: 16.01 s 
2025-08-28 18:44:25.628859: Yayy! New best EMA pseudo Dice: 0.6575000286102295 
2025-08-28 18:44:26.447439:  
2025-08-28 18:44:26.457824: Epoch 152 
2025-08-28 18:44:26.464096: Current learning rate: 0.00862 
2025-08-28 18:44:40.523334: train_loss -0.3828 
2025-08-28 18:44:40.531661: val_loss -0.3984 
2025-08-28 18:44:40.535767: Pseudo dice [np.float32(0.6622)] 
2025-08-28 18:44:40.543780: Epoch time: 14.08 s 
2025-08-28 18:44:40.548916: Yayy! New best EMA pseudo Dice: 0.6579999923706055 
2025-08-28 18:44:41.374796:  
2025-08-28 18:44:41.383173: Epoch 153 
2025-08-28 18:44:41.390461: Current learning rate: 0.00861 
2025-08-28 18:44:56.151406: train_loss -0.3688 
2025-08-28 18:44:56.163956: val_loss -0.4157 
2025-08-28 18:44:56.168119: Pseudo dice [np.float32(0.6877)] 
2025-08-28 18:44:56.178424: Epoch time: 14.78 s 
2025-08-28 18:44:56.188558: Yayy! New best EMA pseudo Dice: 0.6608999967575073 
2025-08-28 18:44:57.049787:  
2025-08-28 18:44:57.057121: Epoch 154 
2025-08-28 18:44:57.063303: Current learning rate: 0.0086 
2025-08-28 18:45:12.008903: train_loss -0.3889 
2025-08-28 18:45:12.017323: val_loss -0.4593 
2025-08-28 18:45:12.021441: Pseudo dice [np.float32(0.6764)] 
2025-08-28 18:45:12.029323: Epoch time: 14.96 s 
2025-08-28 18:45:12.034349: Yayy! New best EMA pseudo Dice: 0.6625000238418579 
2025-08-28 18:45:12.842582:  
2025-08-28 18:45:12.853047: Epoch 155 
2025-08-28 18:45:12.858259: Current learning rate: 0.00859 
2025-08-28 18:45:27.974491: train_loss -0.3577 
2025-08-28 18:45:27.983152: val_loss -0.3454 
2025-08-28 18:45:27.991156: Pseudo dice [np.float32(0.5417)] 
2025-08-28 18:45:27.997375: Epoch time: 15.13 s 
2025-08-28 18:45:28.637480:  
2025-08-28 18:45:28.645829: Epoch 156 
2025-08-28 18:45:28.652181: Current learning rate: 0.00858 
2025-08-28 18:45:43.273155: train_loss -0.3683 
2025-08-28 18:45:43.281790: val_loss -0.4171 
2025-08-28 18:45:43.286028: Pseudo dice [np.float32(0.6082)] 
2025-08-28 18:45:43.292854: Epoch time: 14.64 s 
2025-08-28 18:45:43.933110:  
2025-08-28 18:45:43.941421: Epoch 157 
2025-08-28 18:45:43.947594: Current learning rate: 0.00858 
2025-08-28 18:45:59.026623: train_loss -0.3508 
2025-08-28 18:45:59.038851: val_loss -0.2769 
2025-08-28 18:45:59.043404: Pseudo dice [np.float32(0.5204)] 
2025-08-28 18:45:59.050237: Epoch time: 15.09 s 
2025-08-28 18:45:59.695178:  
2025-08-28 18:45:59.705101: Epoch 158 
2025-08-28 18:45:59.711360: Current learning rate: 0.00857 
2025-08-28 18:46:13.799945: train_loss -0.3308 
2025-08-28 18:46:13.808124: val_loss -0.4164 
2025-08-28 18:46:13.812287: Pseudo dice [np.float32(0.6089)] 
2025-08-28 18:46:13.821065: Epoch time: 14.11 s 
2025-08-28 18:46:14.473904:  
2025-08-28 18:46:14.484463: Epoch 159 
2025-08-28 18:46:14.490611: Current learning rate: 0.00856 
2025-08-28 18:46:29.081645: train_loss -0.3706 
2025-08-28 18:46:29.089684: val_loss -0.4733 
2025-08-28 18:46:29.094240: Pseudo dice [np.float32(0.7152)] 
2025-08-28 18:46:29.101051: Epoch time: 14.61 s 
2025-08-28 18:46:29.745496:  
2025-08-28 18:46:29.752701: Epoch 160 
2025-08-28 18:46:29.758047: Current learning rate: 0.00855 
2025-08-28 18:46:44.910019: train_loss -0.3165 
2025-08-28 18:46:44.918310: val_loss -0.4411 
2025-08-28 18:46:44.922128: Pseudo dice [np.float32(0.6765)] 
2025-08-28 18:46:44.930364: Epoch time: 15.17 s 
2025-08-28 18:46:45.721785:  
2025-08-28 18:46:45.731279: Epoch 161 
2025-08-28 18:46:45.737477: Current learning rate: 0.00854 
2025-08-28 18:47:00.183466: train_loss -0.3859 
2025-08-28 18:47:00.191559: val_loss -0.4373 
2025-08-28 18:47:00.196064: Pseudo dice [np.float32(0.6756)] 
2025-08-28 18:47:00.203792: Epoch time: 14.46 s 
2025-08-28 18:47:00.839058:  
2025-08-28 18:47:00.846280: Epoch 162 
2025-08-28 18:47:00.851513: Current learning rate: 0.00853 
2025-08-28 18:47:16.220603: train_loss -0.3501 
2025-08-28 18:47:16.228792: val_loss -0.458 
2025-08-28 18:47:16.233049: Pseudo dice [np.float32(0.7107)] 
2025-08-28 18:47:16.240367: Epoch time: 15.38 s 
2025-08-28 18:47:16.891428:  
2025-08-28 18:47:16.901996: Epoch 163 
2025-08-28 18:47:16.908090: Current learning rate: 0.00852 
2025-08-28 18:47:31.706342: train_loss -0.3687 
2025-08-28 18:47:31.715119: val_loss -0.414 
2025-08-28 18:47:31.723364: Pseudo dice [np.float32(0.6347)] 
2025-08-28 18:47:31.728515: Epoch time: 14.82 s 
2025-08-28 18:47:32.415932:  
2025-08-28 18:47:32.423624: Epoch 164 
2025-08-28 18:47:32.429013: Current learning rate: 0.00851 
2025-08-28 18:47:46.446488: train_loss -0.3965 
2025-08-28 18:47:46.454760: val_loss -0.4303 
2025-08-28 18:47:46.458901: Pseudo dice [np.float32(0.635)] 
2025-08-28 18:47:46.467765: Epoch time: 14.03 s 
2025-08-28 18:47:47.116409:  
2025-08-28 18:47:47.123737: Epoch 165 
2025-08-28 18:47:47.133163: Current learning rate: 0.0085 
2025-08-28 18:48:01.636527: train_loss -0.3389 
2025-08-28 18:48:01.649186: val_loss -0.4043 
2025-08-28 18:48:01.653516: Pseudo dice [np.float32(0.6308)] 
2025-08-28 18:48:01.660120: Epoch time: 14.52 s 
2025-08-28 18:48:02.297230:  
2025-08-28 18:48:02.305571: Epoch 166 
2025-08-28 18:48:02.310823: Current learning rate: 0.00849 
2025-08-28 18:48:17.648765: train_loss -0.4007 
2025-08-28 18:48:17.656779: val_loss -0.5165 
2025-08-28 18:48:17.664817: Pseudo dice [np.float32(0.7036)] 
2025-08-28 18:48:17.669913: Epoch time: 15.35 s 
2025-08-28 18:48:18.362736:  
2025-08-28 18:48:18.371630: Epoch 167 
2025-08-28 18:48:18.379634: Current learning rate: 0.00848 
2025-08-28 18:48:34.857444: train_loss -0.3501 
2025-08-28 18:48:34.865652: val_loss -0.4658 
2025-08-28 18:48:34.874021: Pseudo dice [np.float32(0.6996)] 
2025-08-28 18:48:34.879249: Epoch time: 16.5 s 
2025-08-28 18:48:35.748287:  
2025-08-28 18:48:35.756653: Epoch 168 
2025-08-28 18:48:35.761815: Current learning rate: 0.00847 
2025-08-28 18:48:52.532850: train_loss -0.3549 
2025-08-28 18:48:52.537531: val_loss -0.4658 
2025-08-28 18:48:52.545834: Pseudo dice [np.float32(0.6992)] 
2025-08-28 18:48:52.551202: Epoch time: 16.79 s 
2025-08-28 18:48:53.276723:  
2025-08-28 18:48:53.283715: Epoch 169 
2025-08-28 18:48:53.289669: Current learning rate: 0.00847 
2025-08-28 18:49:09.983913: train_loss -0.3213 
2025-08-28 18:49:09.996168: val_loss -0.4343 
2025-08-28 18:49:10.000630: Pseudo dice [np.float32(0.632)] 
2025-08-28 18:49:10.007689: Epoch time: 16.71 s 
2025-08-28 18:49:10.697674:  
2025-08-28 18:49:10.706052: Epoch 170 
2025-08-28 18:49:10.711555: Current learning rate: 0.00846 
2025-08-28 18:49:27.518423: train_loss -0.3697 
2025-08-28 18:49:27.526646: val_loss -0.3567 
2025-08-28 18:49:27.530665: Pseudo dice [np.float32(0.5916)] 
2025-08-28 18:49:27.539624: Epoch time: 16.83 s 
2025-08-28 18:49:28.237040:  
2025-08-28 18:49:28.243989: Epoch 171 
2025-08-28 18:49:28.252939: Current learning rate: 0.00845 
2025-08-28 18:49:45.044319: train_loss -0.3663 
2025-08-28 18:49:45.052373: val_loss -0.3371 
2025-08-28 18:49:45.060406: Pseudo dice [np.float32(0.6241)] 
2025-08-28 18:49:45.065382: Epoch time: 16.81 s 
2025-08-28 18:49:45.755791:  
2025-08-28 18:49:45.763036: Epoch 172 
2025-08-28 18:49:45.769198: Current learning rate: 0.00844 
2025-08-28 18:50:02.528167: train_loss -0.3691 
2025-08-28 18:50:02.536841: val_loss -0.5586 
2025-08-28 18:50:02.544479: Pseudo dice [np.float32(0.7507)] 
2025-08-28 18:50:02.549578: Epoch time: 16.77 s 
2025-08-28 18:50:03.238836:  
2025-08-28 18:50:03.247144: Epoch 173 
2025-08-28 18:50:03.254143: Current learning rate: 0.00843 
2025-08-28 18:50:19.978974: train_loss -0.394 
2025-08-28 18:50:19.987246: val_loss -0.4527 
2025-08-28 18:50:19.991442: Pseudo dice [np.float32(0.7149)] 
2025-08-28 18:50:19.999261: Epoch time: 16.74 s 
2025-08-28 18:50:20.005256: Yayy! New best EMA pseudo Dice: 0.6650999784469604 
2025-08-28 18:50:21.095773:  
2025-08-28 18:50:21.104644: Epoch 174 
2025-08-28 18:50:21.111768: Current learning rate: 0.00842 
2025-08-28 18:50:37.667400: train_loss -0.3792 
2025-08-28 18:50:37.675367: val_loss -0.4281 
2025-08-28 18:50:37.683717: Pseudo dice [np.float32(0.6147)] 
2025-08-28 18:50:37.687960: Epoch time: 16.57 s 
2025-08-28 18:50:38.384234:  
2025-08-28 18:50:38.392672: Epoch 175 
2025-08-28 18:50:38.400929: Current learning rate: 0.00841 
2025-08-28 18:50:55.293469: train_loss -0.3843 
2025-08-28 18:50:55.305985: val_loss -0.5205 
2025-08-28 18:50:55.310183: Pseudo dice [np.float32(0.7286)] 
2025-08-28 18:50:55.318545: Epoch time: 16.91 s 
2025-08-28 18:50:55.325054: Yayy! New best EMA pseudo Dice: 0.6668999791145325 
2025-08-28 18:50:56.319023:  
2025-08-28 18:50:56.327306: Epoch 176 
2025-08-28 18:50:56.335561: Current learning rate: 0.0084 
2025-08-28 18:51:13.073494: train_loss -0.3691 
2025-08-28 18:51:13.077734: val_loss -0.5073 
2025-08-28 18:51:13.086120: Pseudo dice [np.float32(0.6707)] 
2025-08-28 18:51:13.093919: Epoch time: 16.76 s 
2025-08-28 18:51:13.099933: Yayy! New best EMA pseudo Dice: 0.6672999858856201 
2025-08-28 18:51:13.989779:  
2025-08-28 18:51:13.996974: Epoch 177 
2025-08-28 18:51:14.002178: Current learning rate: 0.00839 
2025-08-28 18:51:30.520247: train_loss -0.4157 
2025-08-28 18:51:30.528590: val_loss -0.38 
2025-08-28 18:51:30.532920: Pseudo dice [np.float32(0.5649)] 
2025-08-28 18:51:30.540037: Epoch time: 16.53 s 
2025-08-28 18:51:31.230804:  
2025-08-28 18:51:31.240217: Epoch 178 
2025-08-28 18:51:31.246514: Current learning rate: 0.00838 
2025-08-28 18:51:47.841101: train_loss -0.3522 
2025-08-28 18:51:47.845768: val_loss -0.4412 
2025-08-28 18:51:47.853947: Pseudo dice [np.float32(0.694)] 
2025-08-28 18:51:47.858881: Epoch time: 16.61 s 
2025-08-28 18:51:48.573217:  
2025-08-28 18:51:48.581489: Epoch 179 
2025-08-28 18:51:48.587649: Current learning rate: 0.00837 
2025-08-28 18:52:05.667810: train_loss -0.3568 
2025-08-28 18:52:05.680309: val_loss -0.5163 
2025-08-28 18:52:05.684477: Pseudo dice [np.float32(0.7379)] 
2025-08-28 18:52:05.690250: Epoch time: 17.1 s 
2025-08-28 18:52:05.696537: Yayy! New best EMA pseudo Dice: 0.6685000061988831 
2025-08-28 18:52:06.575449:  
2025-08-28 18:52:06.583915: Epoch 180 
2025-08-28 18:52:06.590130: Current learning rate: 0.00836 
2025-08-28 18:52:23.231029: train_loss -0.4405 
2025-08-28 18:52:23.239427: val_loss -0.3969 
2025-08-28 18:52:23.243244: Pseudo dice [np.float32(0.6907)] 
2025-08-28 18:52:23.249489: Epoch time: 16.66 s 
2025-08-28 18:52:23.255738: Yayy! New best EMA pseudo Dice: 0.6707000136375427 
2025-08-28 18:52:24.291144:  
2025-08-28 18:52:24.298295: Epoch 181 
2025-08-28 18:52:24.305468: Current learning rate: 0.00836 
2025-08-28 18:52:40.782069: train_loss -0.3886 
2025-08-28 18:52:40.790352: val_loss -0.4433 
2025-08-28 18:52:40.794480: Pseudo dice [np.float32(0.7104)] 
2025-08-28 18:52:40.802788: Epoch time: 16.49 s 
2025-08-28 18:52:40.808410: Yayy! New best EMA pseudo Dice: 0.6747000217437744 
2025-08-28 18:52:41.671993:  
2025-08-28 18:52:41.679445: Epoch 182 
2025-08-28 18:52:41.684511: Current learning rate: 0.00835 
2025-08-28 18:52:58.232701: train_loss -0.3712 
2025-08-28 18:52:58.244872: val_loss -0.5456 
2025-08-28 18:52:58.249460: Pseudo dice [np.float32(0.7534)] 
2025-08-28 18:52:58.254586: Epoch time: 16.56 s 
2025-08-28 18:52:58.258325: Yayy! New best EMA pseudo Dice: 0.6825000047683716 
2025-08-28 18:52:59.146880:  
2025-08-28 18:52:59.155143: Epoch 183 
2025-08-28 18:52:59.160315: Current learning rate: 0.00834 
2025-08-28 18:53:15.512414: train_loss -0.4226 
2025-08-28 18:53:15.520960: val_loss -0.4343 
2025-08-28 18:53:15.525026: Pseudo dice [np.float32(0.7481)] 
2025-08-28 18:53:15.531006: Epoch time: 16.37 s 
2025-08-28 18:53:15.537120: Yayy! New best EMA pseudo Dice: 0.6891000270843506 
2025-08-28 18:53:16.425357:  
2025-08-28 18:53:16.433995: Epoch 184 
2025-08-28 18:53:16.439029: Current learning rate: 0.00833 
2025-08-28 18:53:32.708487: train_loss -0.4053 
2025-08-28 18:53:32.717342: val_loss -0.4746 
2025-08-28 18:53:32.720930: Pseudo dice [np.float32(0.666)] 
2025-08-28 18:53:32.729348: Epoch time: 16.29 s 
2025-08-28 18:53:33.440743:  
2025-08-28 18:53:33.447452: Epoch 185 
2025-08-28 18:53:33.456006: Current learning rate: 0.00832 
2025-08-28 18:53:49.483882: train_loss -0.3853 
2025-08-28 18:53:49.492303: val_loss -0.3965 
2025-08-28 18:53:49.496392: Pseudo dice [np.float32(0.6609)] 
2025-08-28 18:53:49.503608: Epoch time: 16.05 s 
2025-08-28 18:53:50.207069:  
2025-08-28 18:53:50.215108: Epoch 186 
2025-08-28 18:53:50.219004: Current learning rate: 0.00831 
2025-08-28 18:54:06.659358: train_loss -0.393 
2025-08-28 18:54:06.667740: val_loss -0.449 
2025-08-28 18:54:06.676036: Pseudo dice [np.float32(0.7369)] 
2025-08-28 18:54:06.681622: Epoch time: 16.45 s 
2025-08-28 18:54:06.688181: Yayy! New best EMA pseudo Dice: 0.6894999742507935 
2025-08-28 18:54:07.687188:  
2025-08-28 18:54:07.696361: Epoch 187 
2025-08-28 18:54:07.704743: Current learning rate: 0.0083 
2025-08-28 18:54:23.897566: train_loss -0.3844 
2025-08-28 18:54:23.905766: val_loss -0.4189 
2025-08-28 18:54:23.913572: Pseudo dice [np.float32(0.6818)] 
2025-08-28 18:54:23.917963: Epoch time: 16.21 s 
2025-08-28 18:54:24.625791:  
2025-08-28 18:54:24.633138: Epoch 188 
2025-08-28 18:54:24.639276: Current learning rate: 0.00829 
2025-08-28 18:54:40.910365: train_loss -0.386 
2025-08-28 18:54:40.918679: val_loss -0.4802 
2025-08-28 18:54:40.926943: Pseudo dice [np.float32(0.7359)] 
2025-08-28 18:54:40.932338: Epoch time: 16.29 s 
2025-08-28 18:54:40.937968: Yayy! New best EMA pseudo Dice: 0.6934000253677368 
2025-08-28 18:54:41.814797:  
2025-08-28 18:54:41.822077: Epoch 189 
2025-08-28 18:54:41.827355: Current learning rate: 0.00828 
2025-08-28 18:54:58.135388: train_loss -0.4005 
2025-08-28 18:54:58.144166: val_loss -0.4001 
2025-08-28 18:54:58.148301: Pseudo dice [np.float32(0.6657)] 
2025-08-28 18:54:58.156439: Epoch time: 16.32 s 
2025-08-28 18:54:58.857943:  
2025-08-28 18:54:58.865124: Epoch 190 
2025-08-28 18:54:58.870458: Current learning rate: 0.00827 
2025-08-28 18:55:15.419688: train_loss -0.3506 
2025-08-28 18:55:15.428074: val_loss -0.3427 
2025-08-28 18:55:15.432253: Pseudo dice [np.float32(0.5107)] 
2025-08-28 18:55:15.440073: Epoch time: 16.56 s 
2025-08-28 18:55:16.129421:  
2025-08-28 18:55:16.136548: Epoch 191 
2025-08-28 18:55:16.141966: Current learning rate: 0.00826 
2025-08-28 18:55:32.857881: train_loss -0.3114 
2025-08-28 18:55:32.865889: val_loss -0.4008 
2025-08-28 18:55:32.870403: Pseudo dice [np.float32(0.6721)] 
2025-08-28 18:55:32.878457: Epoch time: 16.73 s 
2025-08-28 18:55:33.595605:  
2025-08-28 18:55:33.602013: Epoch 192 
2025-08-28 18:55:33.604539: Current learning rate: 0.00825 
2025-08-28 18:55:50.337926: train_loss -0.3972 
2025-08-28 18:55:50.345776: val_loss -0.4463 
2025-08-28 18:55:50.350466: Pseudo dice [np.float32(0.6964)] 
2025-08-28 18:55:50.356500: Epoch time: 16.75 s 
2025-08-28 18:55:51.225632:  
2025-08-28 18:55:51.233400: Epoch 193 
2025-08-28 18:55:51.240584: Current learning rate: 0.00824 
2025-08-28 18:56:07.671797: train_loss -0.3822 
2025-08-28 18:56:07.679827: val_loss -0.4728 
2025-08-28 18:56:07.684341: Pseudo dice [np.float32(0.6906)] 
2025-08-28 18:56:07.693189: Epoch time: 16.45 s 
2025-08-28 18:56:08.406220:  
2025-08-28 18:56:08.413740: Epoch 194 
2025-08-28 18:56:08.422205: Current learning rate: 0.00824 
2025-08-28 18:56:24.772345: train_loss -0.4106 
2025-08-28 18:56:24.780007: val_loss -0.4567 
2025-08-28 18:56:24.784868: Pseudo dice [np.float32(0.6285)] 
2025-08-28 18:56:24.790701: Epoch time: 16.37 s 
2025-08-28 18:56:25.509709:  
2025-08-28 18:56:25.517083: Epoch 195 
2025-08-28 18:56:25.523668: Current learning rate: 0.00823 
2025-08-28 18:56:42.147984: train_loss -0.3253 
2025-08-28 18:56:42.156217: val_loss -0.3824 
2025-08-28 18:56:42.160445: Pseudo dice [np.float32(0.579)] 
2025-08-28 18:56:42.167611: Epoch time: 16.64 s 
2025-08-28 18:56:42.885617:  
2025-08-28 18:56:42.893918: Epoch 196 
2025-08-28 18:56:42.899356: Current learning rate: 0.00822 
2025-08-28 18:56:59.419312: train_loss -0.4117 
2025-08-28 18:56:59.427764: val_loss -0.4724 
2025-08-28 18:56:59.436062: Pseudo dice [np.float32(0.7218)] 
2025-08-28 18:56:59.441488: Epoch time: 16.54 s 
2025-08-28 18:57:00.148386:  
2025-08-28 18:57:00.154000: Epoch 197 
2025-08-28 18:57:00.161392: Current learning rate: 0.00821 
2025-08-28 18:57:17.041103: train_loss -0.4149 
2025-08-28 18:57:17.049425: val_loss -0.4576 
2025-08-28 18:57:17.053236: Pseudo dice [np.float32(0.6555)] 
2025-08-28 18:57:17.060459: Epoch time: 16.89 s 
2025-08-28 18:57:17.762309:  
2025-08-28 18:57:17.770611: Epoch 198 
2025-08-28 18:57:17.777143: Current learning rate: 0.0082 
2025-08-28 18:57:34.429252: train_loss -0.4124 
2025-08-28 18:57:34.433499: val_loss -0.4918 
2025-08-28 18:57:34.441929: Pseudo dice [np.float32(0.7146)] 
2025-08-28 18:57:34.446589: Epoch time: 16.67 s 
2025-08-28 18:57:35.318370:  
2025-08-28 18:57:35.326367: Epoch 199 
2025-08-28 18:57:35.331881: Current learning rate: 0.00819 
2025-08-28 18:57:52.017666: train_loss -0.3871 
2025-08-28 18:57:52.026007: val_loss -0.4215 
2025-08-28 18:57:52.029818: Pseudo dice [np.float32(0.7264)] 
2025-08-28 18:57:52.038254: Epoch time: 16.7 s 
2025-08-28 18:57:52.917148:  
2025-08-28 18:57:52.925578: Epoch 200 
2025-08-28 18:57:52.931721: Current learning rate: 0.00818 
2025-08-28 18:58:09.250757: train_loss -0.4163 
2025-08-28 18:58:09.260045: val_loss -0.435 
2025-08-28 18:58:09.264212: Pseudo dice [np.float32(0.7335)] 
2025-08-28 18:58:09.271127: Epoch time: 16.33 s 
2025-08-28 18:58:09.992474:  
2025-08-28 18:58:10.000772: Epoch 201 
2025-08-28 18:58:10.006962: Current learning rate: 0.00817 
2025-08-28 18:58:26.318526: train_loss -0.3888 
2025-08-28 18:58:26.327085: val_loss -0.4547 
2025-08-28 18:58:26.331161: Pseudo dice [np.float32(0.6961)] 
2025-08-28 18:58:26.336563: Epoch time: 16.33 s 
2025-08-28 18:58:27.054519:  
2025-08-28 18:58:27.061164: Epoch 202 
2025-08-28 18:58:27.065366: Current learning rate: 0.00816 
2025-08-28 18:58:43.477386: train_loss -0.3917 
2025-08-28 18:58:43.485731: val_loss -0.4459 
2025-08-28 18:58:43.489868: Pseudo dice [np.float32(0.6934)] 
2025-08-28 18:58:43.497905: Epoch time: 16.42 s 
2025-08-28 18:58:44.223611:  
2025-08-28 18:58:44.231768: Epoch 203 
2025-08-28 18:58:44.238158: Current learning rate: 0.00815 
2025-08-28 18:59:00.669673: train_loss -0.3862 
2025-08-28 18:59:00.677936: val_loss -0.5616 
2025-08-28 18:59:00.685623: Pseudo dice [np.float32(0.6929)] 
2025-08-28 18:59:00.690051: Epoch time: 16.45 s 
2025-08-28 18:59:01.406015:  
2025-08-28 18:59:01.415595: Epoch 204 
2025-08-28 18:59:01.421081: Current learning rate: 0.00814 
2025-08-28 18:59:17.683955: train_loss -0.4088 
2025-08-28 18:59:17.695211: val_loss -0.4664 
2025-08-28 18:59:17.702897: Pseudo dice [np.float32(0.6232)] 
2025-08-28 18:59:17.712062: Epoch time: 16.28 s 
2025-08-28 18:59:18.610954:  
2025-08-28 18:59:18.620305: Epoch 205 
2025-08-28 18:59:18.625630: Current learning rate: 0.00813 
2025-08-28 18:59:35.056172: train_loss -0.4343 
2025-08-28 18:59:35.062279: val_loss -0.5041 
2025-08-28 18:59:35.066362: Pseudo dice [np.float32(0.7391)] 
2025-08-28 18:59:35.074574: Epoch time: 16.45 s 
2025-08-28 18:59:35.771456:  
2025-08-28 18:59:35.780992: Epoch 206 
2025-08-28 18:59:35.786436: Current learning rate: 0.00813 
2025-08-28 18:59:51.866140: train_loss -0.4052 
2025-08-28 18:59:51.874830: val_loss -0.4507 
2025-08-28 18:59:51.878935: Pseudo dice [np.float32(0.7337)] 
2025-08-28 18:59:51.887073: Epoch time: 16.09 s 
2025-08-28 18:59:52.598475:  
2025-08-28 18:59:52.607402: Epoch 207 
2025-08-28 18:59:52.616931: Current learning rate: 0.00812 
2025-08-28 19:00:08.870980: train_loss -0.364 
2025-08-28 19:00:08.883459: val_loss -0.4105 
2025-08-28 19:00:08.887725: Pseudo dice [np.float32(0.6618)] 
2025-08-28 19:00:08.893739: Epoch time: 16.27 s 
2025-08-28 19:00:09.572478:  
2025-08-28 19:00:09.580148: Epoch 208 
2025-08-28 19:00:09.584237: Current learning rate: 0.00811 
2025-08-28 19:00:25.787865: train_loss -0.3697 
2025-08-28 19:00:25.796377: val_loss -0.3555 
2025-08-28 19:00:25.804610: Pseudo dice [np.float32(0.6844)] 
2025-08-28 19:00:25.810078: Epoch time: 16.22 s 
2025-08-28 19:00:26.487037:  
2025-08-28 19:00:26.494380: Epoch 209 
2025-08-28 19:00:26.499642: Current learning rate: 0.0081 
2025-08-28 19:00:42.738180: train_loss -0.374 
2025-08-28 19:00:42.746527: val_loss -0.4749 
2025-08-28 19:00:42.754971: Pseudo dice [np.float32(0.7235)] 
2025-08-28 19:00:42.759526: Epoch time: 16.25 s 
2025-08-28 19:00:43.426961:  
2025-08-28 19:00:43.435337: Epoch 210 
2025-08-28 19:00:43.442410: Current learning rate: 0.00809 
2025-08-28 19:00:59.679679: train_loss -0.4082 
2025-08-28 19:00:59.688507: val_loss -0.4567 
2025-08-28 19:00:59.692588: Pseudo dice [np.float32(0.6715)] 
2025-08-28 19:00:59.699461: Epoch time: 16.25 s 
2025-08-28 19:01:00.390759:  
2025-08-28 19:01:00.399191: Epoch 211 
2025-08-28 19:01:00.405449: Current learning rate: 0.00808 
2025-08-28 19:01:16.367632: train_loss -0.3122 
2025-08-28 19:01:16.376109: val_loss -0.3608 
2025-08-28 19:01:16.384272: Pseudo dice [np.float32(0.65)] 
2025-08-28 19:01:16.389468: Epoch time: 15.98 s 
2025-08-28 19:01:17.231302:  
2025-08-28 19:01:17.238952: Epoch 212 
2025-08-28 19:01:17.244510: Current learning rate: 0.00807 
2025-08-28 19:01:33.397210: train_loss -0.3732 
2025-08-28 19:01:33.405070: val_loss -0.4311 
2025-08-28 19:01:33.409660: Pseudo dice [np.float32(0.7137)] 
2025-08-28 19:01:33.415576: Epoch time: 16.17 s 
2025-08-28 19:01:34.112921:  
2025-08-28 19:01:34.121144: Epoch 213 
2025-08-28 19:01:34.128960: Current learning rate: 0.00806 
2025-08-28 19:01:49.976220: train_loss -0.4329 
2025-08-28 19:01:49.984396: val_loss -0.3554 
2025-08-28 19:01:49.992173: Pseudo dice [np.float32(0.6423)] 
2025-08-28 19:01:49.996619: Epoch time: 15.87 s 
2025-08-28 19:01:50.681636:  
2025-08-28 19:01:50.689951: Epoch 214 
2025-08-28 19:01:50.695137: Current learning rate: 0.00805 
2025-08-28 19:02:06.901353: train_loss -0.3904 
2025-08-28 19:02:06.909745: val_loss -0.4577 
2025-08-28 19:02:06.913828: Pseudo dice [np.float32(0.6912)] 
2025-08-28 19:02:06.921902: Epoch time: 16.22 s 
2025-08-28 19:02:07.619380:  
2025-08-28 19:02:07.626667: Epoch 215 
2025-08-28 19:02:07.632876: Current learning rate: 0.00804 
2025-08-28 19:02:23.985291: train_loss -0.3941 
2025-08-28 19:02:23.993485: val_loss -0.4566 
2025-08-28 19:02:23.997654: Pseudo dice [np.float32(0.6994)] 
2025-08-28 19:02:24.006322: Epoch time: 16.37 s 
2025-08-28 19:02:24.686434:  
2025-08-28 19:02:24.693576: Epoch 216 
2025-08-28 19:02:24.702037: Current learning rate: 0.00803 
2025-08-28 19:02:40.446397: train_loss -0.4082 
2025-08-28 19:02:40.451533: val_loss -0.4545 
2025-08-28 19:02:40.459982: Pseudo dice [np.float32(0.6761)] 
2025-08-28 19:02:40.465345: Epoch time: 15.76 s 
2025-08-28 19:02:41.147006:  
2025-08-28 19:02:41.154380: Epoch 217 
2025-08-28 19:02:41.160716: Current learning rate: 0.00802 
2025-08-28 19:02:56.722201: train_loss -0.4029 
2025-08-28 19:02:56.734134: val_loss -0.3882 
2025-08-28 19:02:56.738316: Pseudo dice [np.float32(0.5503)] 
2025-08-28 19:02:56.743805: Epoch time: 15.58 s 
2025-08-28 19:02:57.446116:  
2025-08-28 19:02:57.454463: Epoch 218 
2025-08-28 19:02:57.462798: Current learning rate: 0.00801 
2025-08-28 19:03:13.100789: train_loss -0.4333 
2025-08-28 19:03:13.109183: val_loss -0.4541 
2025-08-28 19:03:13.116996: Pseudo dice [np.float32(0.7234)] 
2025-08-28 19:03:13.122214: Epoch time: 15.66 s 
2025-08-28 19:03:13.978945:  
2025-08-28 19:03:13.985680: Epoch 219 
2025-08-28 19:03:13.992962: Current learning rate: 0.00801 
2025-08-28 19:03:29.492236: train_loss -0.4432 
2025-08-28 19:03:29.500497: val_loss -0.5261 
2025-08-28 19:03:29.504696: Pseudo dice [np.float32(0.7204)] 
2025-08-28 19:03:29.512790: Epoch time: 15.52 s 
2025-08-28 19:03:30.201418:  
2025-08-28 19:03:30.207802: Epoch 220 
2025-08-28 19:03:30.213877: Current learning rate: 0.008 
2025-08-28 19:03:45.683614: train_loss -0.3929 
2025-08-28 19:03:45.692008: val_loss -0.517 
2025-08-28 19:03:45.695959: Pseudo dice [np.float32(0.7088)] 
2025-08-28 19:03:45.704060: Epoch time: 15.49 s 
2025-08-28 19:03:46.386289:  
2025-08-28 19:03:46.395968: Epoch 221 
2025-08-28 19:03:46.404834: Current learning rate: 0.00799 
2025-08-28 19:04:01.862199: train_loss -0.4131 
2025-08-28 19:04:01.873940: val_loss -0.4721 
2025-08-28 19:04:01.878688: Pseudo dice [np.float32(0.7395)] 
2025-08-28 19:04:01.884700: Epoch time: 15.48 s 
2025-08-28 19:04:02.566391:  
2025-08-28 19:04:02.573665: Epoch 222 
2025-08-28 19:04:02.580013: Current learning rate: 0.00798 
2025-08-28 19:04:18.224004: train_loss -0.4301 
2025-08-28 19:04:18.232092: val_loss -0.4848 
2025-08-28 19:04:18.236608: Pseudo dice [np.float32(0.7436)] 
2025-08-28 19:04:18.242976: Epoch time: 15.66 s 
2025-08-28 19:04:18.250301: Yayy! New best EMA pseudo Dice: 0.6947000026702881 
2025-08-28 19:04:19.090235:  
2025-08-28 19:04:19.095884: Epoch 223 
2025-08-28 19:04:19.103375: Current learning rate: 0.00797 
2025-08-28 19:04:36.087725: train_loss -0.4424 
2025-08-28 19:04:36.095614: val_loss -0.4629 
2025-08-28 19:04:36.101435: Pseudo dice [np.float32(0.6856)] 
2025-08-28 19:04:36.106371: Epoch time: 17.0 s 
2025-08-28 19:04:36.787058:  
2025-08-28 19:04:36.794327: Epoch 224 
2025-08-28 19:04:36.800462: Current learning rate: 0.00796 
2025-08-28 19:04:53.241892: train_loss -0.4117 
2025-08-28 19:04:53.250389: val_loss -0.4415 
2025-08-28 19:04:53.254886: Pseudo dice [np.float32(0.7328)] 
2025-08-28 19:04:53.261023: Epoch time: 16.46 s 
2025-08-28 19:04:53.263802: Yayy! New best EMA pseudo Dice: 0.697700023651123 
2025-08-28 19:04:54.192993:  
2025-08-28 19:04:54.201180: Epoch 225 
2025-08-28 19:04:54.207495: Current learning rate: 0.00795 
2025-08-28 19:05:11.281357: train_loss -0.3582 
2025-08-28 19:05:11.293341: val_loss -0.4873 
2025-08-28 19:05:11.297891: Pseudo dice [np.float32(0.7688)] 
2025-08-28 19:05:11.303208: Epoch time: 17.09 s 
2025-08-28 19:05:11.307398: Yayy! New best EMA pseudo Dice: 0.704800009727478 
2025-08-28 19:05:12.350909:  
2025-08-28 19:05:12.358982: Epoch 226 
2025-08-28 19:05:12.365341: Current learning rate: 0.00794 
2025-08-28 19:05:29.188749: train_loss -0.3889 
2025-08-28 19:05:29.195089: val_loss -0.5406 
2025-08-28 19:05:29.203343: Pseudo dice [np.float32(0.7074)] 
2025-08-28 19:05:29.208029: Epoch time: 16.84 s 
2025-08-28 19:05:29.212261: Yayy! New best EMA pseudo Dice: 0.7049999833106995 
2025-08-28 19:05:30.090179:  
2025-08-28 19:05:30.100673: Epoch 227 
2025-08-28 19:05:30.108247: Current learning rate: 0.00793 
2025-08-28 19:05:47.029505: train_loss -0.4224 
2025-08-28 19:05:47.037486: val_loss -0.436 
2025-08-28 19:05:47.041654: Pseudo dice [np.float32(0.7032)] 
2025-08-28 19:05:47.049417: Epoch time: 16.94 s 
2025-08-28 19:05:47.721392:  
2025-08-28 19:05:47.730599: Epoch 228 
2025-08-28 19:05:47.738889: Current learning rate: 0.00792 
2025-08-28 19:06:04.463829: train_loss -0.4204 
2025-08-28 19:06:04.471861: val_loss -0.4221 
2025-08-28 19:06:04.476060: Pseudo dice [np.float32(0.649)] 
2025-08-28 19:06:04.484008: Epoch time: 16.74 s 
2025-08-28 19:06:05.180762:  
2025-08-28 19:06:05.187785: Epoch 229 
2025-08-28 19:06:05.195104: Current learning rate: 0.00791 
2025-08-28 19:06:21.885243: train_loss -0.3986 
2025-08-28 19:06:21.893049: val_loss -0.5374 
2025-08-28 19:06:21.901794: Pseudo dice [np.float32(0.7593)] 
2025-08-28 19:06:21.907070: Epoch time: 16.71 s 
2025-08-28 19:06:21.912754: Yayy! New best EMA pseudo Dice: 0.705299973487854 
2025-08-28 19:06:22.757581:  
2025-08-28 19:06:22.767731: Epoch 230 
2025-08-28 19:06:22.775455: Current learning rate: 0.0079 
2025-08-28 19:06:39.473505: train_loss -0.4286 
2025-08-28 19:06:39.481836: val_loss -0.4294 
2025-08-28 19:06:39.489665: Pseudo dice [np.float32(0.6744)] 
2025-08-28 19:06:39.495368: Epoch time: 16.72 s 
2025-08-28 19:06:40.187332:  
2025-08-28 19:06:40.196391: Epoch 231 
2025-08-28 19:06:40.202954: Current learning rate: 0.00789 
2025-08-28 19:06:57.095172: train_loss -0.418 
2025-08-28 19:06:57.107878: val_loss -0.4509 
2025-08-28 19:06:57.112054: Pseudo dice [np.float32(0.7546)] 
2025-08-28 19:06:57.118970: Epoch time: 16.91 s 
2025-08-28 19:06:57.124759: Yayy! New best EMA pseudo Dice: 0.7074000239372253 
2025-08-28 19:06:58.119733:  
2025-08-28 19:06:58.129137: Epoch 232 
2025-08-28 19:06:58.137866: Current learning rate: 0.00789 
2025-08-28 19:07:14.708728: train_loss -0.3544 
2025-08-28 19:07:14.716955: val_loss -0.5269 
2025-08-28 19:07:14.721217: Pseudo dice [np.float32(0.7481)] 
2025-08-28 19:07:14.730106: Epoch time: 16.59 s 
2025-08-28 19:07:14.734238: Yayy! New best EMA pseudo Dice: 0.7114999890327454 
2025-08-28 19:07:15.586193:  
2025-08-28 19:07:15.593553: Epoch 233 
2025-08-28 19:07:15.598741: Current learning rate: 0.00788 
2025-08-28 19:07:31.338118: train_loss -0.3719 
2025-08-28 19:07:31.346212: val_loss -0.4641 
2025-08-28 19:07:31.350643: Pseudo dice [np.float32(0.6941)] 
2025-08-28 19:07:31.358303: Epoch time: 15.75 s 
2025-08-28 19:07:32.042151:  
2025-08-28 19:07:32.051643: Epoch 234 
2025-08-28 19:07:32.057641: Current learning rate: 0.00787 
2025-08-28 19:07:47.791317: train_loss -0.4384 
2025-08-28 19:07:47.795874: val_loss -0.5028 
2025-08-28 19:07:47.804358: Pseudo dice [np.float32(0.7645)] 
2025-08-28 19:07:47.808948: Epoch time: 15.75 s 
2025-08-28 19:07:47.814190: Yayy! New best EMA pseudo Dice: 0.7152000069618225 
2025-08-28 19:07:48.652503:  
2025-08-28 19:07:48.659862: Epoch 235 
2025-08-28 19:07:48.667173: Current learning rate: 0.00786 
2025-08-28 19:08:04.140440: train_loss -0.4061 
2025-08-28 19:08:04.149325: val_loss -0.4815 
2025-08-28 19:08:04.153874: Pseudo dice [np.float32(0.6921)] 
2025-08-28 19:08:04.161987: Epoch time: 15.49 s 
2025-08-28 19:08:04.851057:  
2025-08-28 19:08:04.858217: Epoch 236 
2025-08-28 19:08:04.864650: Current learning rate: 0.00785 
2025-08-28 19:08:20.449033: train_loss -0.4164 
2025-08-28 19:08:20.457677: val_loss -0.5376 
2025-08-28 19:08:20.461830: Pseudo dice [np.float32(0.7827)] 
2025-08-28 19:08:20.469004: Epoch time: 15.6 s 
2025-08-28 19:08:20.474636: Yayy! New best EMA pseudo Dice: 0.7199000120162964 
2025-08-28 19:08:21.319475:  
2025-08-28 19:08:21.327419: Epoch 237 
2025-08-28 19:08:21.334796: Current learning rate: 0.00784 
2025-08-28 19:08:37.007546: train_loss -0.4552 
2025-08-28 19:08:37.015947: val_loss -0.4636 
2025-08-28 19:08:37.020027: Pseudo dice [np.float32(0.6942)] 
2025-08-28 19:08:37.026056: Epoch time: 15.69 s 
2025-08-28 19:08:37.700500:  
2025-08-28 19:08:37.709308: Epoch 238 
2025-08-28 19:08:37.717026: Current learning rate: 0.00783 
2025-08-28 19:08:53.327967: train_loss -0.4105 
2025-08-28 19:08:53.335946: val_loss -0.4663 
2025-08-28 19:08:53.340430: Pseudo dice [np.float32(0.7117)] 
2025-08-28 19:08:53.346371: Epoch time: 15.63 s 
2025-08-28 19:08:54.182774:  
2025-08-28 19:08:54.190906: Epoch 239 
2025-08-28 19:08:54.195608: Current learning rate: 0.00782 
2025-08-28 19:09:09.719493: train_loss -0.3645 
2025-08-28 19:09:09.727736: val_loss -0.5478 
2025-08-28 19:09:09.736109: Pseudo dice [np.float32(0.7592)] 
2025-08-28 19:09:09.740908: Epoch time: 15.54 s 
2025-08-28 19:09:09.744934: Yayy! New best EMA pseudo Dice: 0.7210000157356262 
2025-08-28 19:09:10.618190:  
2025-08-28 19:09:10.625178: Epoch 240 
2025-08-28 19:09:10.633791: Current learning rate: 0.00781 
2025-08-28 19:09:26.907545: train_loss -0.416 
2025-08-28 19:09:26.915987: val_loss -0.4173 
2025-08-28 19:09:26.924246: Pseudo dice [np.float32(0.6453)] 
2025-08-28 19:09:26.931968: Epoch time: 16.29 s 
2025-08-28 19:09:27.616427:  
2025-08-28 19:09:27.624861: Epoch 241 
2025-08-28 19:09:27.630865: Current learning rate: 0.0078 
2025-08-28 19:09:43.895175: train_loss -0.4371 
2025-08-28 19:09:43.903452: val_loss -0.5013 
2025-08-28 19:09:43.907686: Pseudo dice [np.float32(0.6767)] 
2025-08-28 19:09:43.915158: Epoch time: 16.28 s 
2025-08-28 19:09:44.593368:  
2025-08-28 19:09:44.602579: Epoch 242 
2025-08-28 19:09:44.608303: Current learning rate: 0.00779 
2025-08-28 19:10:00.853250: train_loss -0.4153 
2025-08-28 19:10:00.862087: val_loss -0.4186 
2025-08-28 19:10:00.866244: Pseudo dice [np.float32(0.6333)] 
2025-08-28 19:10:00.873068: Epoch time: 16.26 s 
2025-08-28 19:10:01.572576:  
2025-08-28 19:10:01.579696: Epoch 243 
2025-08-28 19:10:01.586244: Current learning rate: 0.00778 
2025-08-28 19:10:17.579993: train_loss -0.4082 
2025-08-28 19:10:17.587051: val_loss -0.4863 
2025-08-28 19:10:17.594903: Pseudo dice [np.float32(0.7325)] 
2025-08-28 19:10:17.600157: Epoch time: 16.01 s 
2025-08-28 19:10:18.281509:  
2025-08-28 19:10:18.289619: Epoch 244 
2025-08-28 19:10:18.297818: Current learning rate: 0.00777 
2025-08-28 19:10:34.554162: train_loss -0.3661 
2025-08-28 19:10:34.562331: val_loss -0.3593 
2025-08-28 19:10:34.570838: Pseudo dice [np.float32(0.691)] 
2025-08-28 19:10:34.576047: Epoch time: 16.28 s 
2025-08-28 19:10:35.272148:  
2025-08-28 19:10:35.280231: Epoch 245 
2025-08-28 19:10:35.287711: Current learning rate: 0.00777 
2025-08-28 19:10:51.299977: train_loss -0.4255 
2025-08-28 19:10:51.308414: val_loss -0.4465 
2025-08-28 19:10:51.312553: Pseudo dice [np.float32(0.6204)] 
2025-08-28 19:10:51.321923: Epoch time: 16.03 s 
2025-08-28 19:10:52.159828:  
2025-08-28 19:10:52.169183: Epoch 246 
2025-08-28 19:10:52.175419: Current learning rate: 0.00776 
2025-08-28 19:11:08.162766: train_loss -0.382 
2025-08-28 19:11:08.175103: val_loss -0.4878 
2025-08-28 19:11:08.179382: Pseudo dice [np.float32(0.7607)] 
2025-08-28 19:11:08.185272: Epoch time: 16.01 s 
2025-08-28 19:11:08.892383:  
2025-08-28 19:11:08.900494: Epoch 247 
2025-08-28 19:11:08.906668: Current learning rate: 0.00775 
2025-08-28 19:11:25.016979: train_loss -0.4491 
2025-08-28 19:11:25.025358: val_loss -0.4967 
2025-08-28 19:11:25.033659: Pseudo dice [np.float32(0.7275)] 
2025-08-28 19:11:25.039706: Epoch time: 16.13 s 
2025-08-28 19:11:25.734282:  
2025-08-28 19:11:25.741453: Epoch 248 
2025-08-28 19:11:25.748117: Current learning rate: 0.00774 
2025-08-28 19:11:41.894742: train_loss -0.4066 
2025-08-28 19:11:41.900438: val_loss -0.4381 
2025-08-28 19:11:41.908829: Pseudo dice [np.float32(0.6972)] 
2025-08-28 19:11:41.914728: Epoch time: 16.16 s 
2025-08-28 19:11:42.612035:  
2025-08-28 19:11:42.621235: Epoch 249 
2025-08-28 19:11:42.626899: Current learning rate: 0.00773 
2025-08-28 19:11:58.608398: train_loss -0.4426 
2025-08-28 19:11:58.613323: val_loss -0.4428 
2025-08-28 19:11:58.621338: Pseudo dice [np.float32(0.69)] 
2025-08-28 19:11:58.626591: Epoch time: 16.0 s 
2025-08-28 19:11:59.478885:  
2025-08-28 19:11:59.486065: Epoch 250 
2025-08-28 19:11:59.492651: Current learning rate: 0.00772 
2025-08-28 19:12:16.180478: train_loss -0.4011 
2025-08-28 19:12:16.188985: val_loss -0.3776 
2025-08-28 19:12:16.193167: Pseudo dice [np.float32(0.6453)] 
2025-08-28 19:12:16.199857: Epoch time: 16.7 s 
2025-08-28 19:12:16.891175:  
2025-08-28 19:12:16.898497: Epoch 251 
2025-08-28 19:12:16.904830: Current learning rate: 0.00771 
2025-08-28 19:12:33.714716: train_loss -0.3758 
2025-08-28 19:12:33.723053: val_loss -0.445 
2025-08-28 19:12:33.730725: Pseudo dice [np.float32(0.7395)] 
2025-08-28 19:12:33.736025: Epoch time: 16.83 s 
2025-08-28 19:12:34.570313:  
2025-08-28 19:12:34.579821: Epoch 252 
2025-08-28 19:12:34.586655: Current learning rate: 0.0077 
2025-08-28 19:12:51.365738: train_loss -0.4281 
2025-08-28 19:12:51.373965: val_loss -0.4845 
2025-08-28 19:12:51.378107: Pseudo dice [np.float32(0.7441)] 
2025-08-28 19:12:51.385107: Epoch time: 16.8 s 
2025-08-28 19:12:52.056449:  
2025-08-28 19:12:52.064795: Epoch 253 
2025-08-28 19:12:52.070071: Current learning rate: 0.00769 
2025-08-28 19:13:08.974833: train_loss -0.4433 
2025-08-28 19:13:08.983285: val_loss -0.4383 
2025-08-28 19:13:08.987454: Pseudo dice [np.float32(0.7191)] 
2025-08-28 19:13:08.995229: Epoch time: 16.92 s 
2025-08-28 19:13:09.658340:  
2025-08-28 19:13:09.668830: Epoch 254 
2025-08-28 19:13:09.674739: Current learning rate: 0.00768 
2025-08-28 19:13:26.372476: train_loss -0.4018 
2025-08-28 19:13:26.379778: val_loss -0.4455 
2025-08-28 19:13:26.387491: Pseudo dice [np.float32(0.6856)] 
2025-08-28 19:13:26.392772: Epoch time: 16.72 s 
2025-08-28 19:13:27.076958:  
2025-08-28 19:13:27.084235: Epoch 255 
2025-08-28 19:13:27.091073: Current learning rate: 0.00767 
2025-08-28 19:13:44.089292: train_loss -0.4567 
2025-08-28 19:13:44.097478: val_loss -0.4624 
2025-08-28 19:13:44.101808: Pseudo dice [np.float32(0.7295)] 
2025-08-28 19:13:44.109681: Epoch time: 17.01 s 
2025-08-28 19:13:44.812271:  
2025-08-28 19:13:44.820699: Epoch 256 
2025-08-28 19:13:44.826865: Current learning rate: 0.00766 
2025-08-28 19:14:01.552340: train_loss -0.4206 
2025-08-28 19:14:01.560321: val_loss -0.5007 
2025-08-28 19:14:01.568681: Pseudo dice [np.float32(0.7596)] 
2025-08-28 19:14:01.573990: Epoch time: 16.74 s 
2025-08-28 19:14:02.247338:  
2025-08-28 19:14:02.255481: Epoch 257 
2025-08-28 19:14:02.262036: Current learning rate: 0.00765 
2025-08-28 19:14:19.266425: train_loss -0.401 
2025-08-28 19:14:19.274410: val_loss -0.4059 
2025-08-28 19:14:19.278440: Pseudo dice [np.float32(0.6498)] 
2025-08-28 19:14:19.284263: Epoch time: 17.02 s 
2025-08-28 19:14:19.974395:  
2025-08-28 19:14:19.981770: Epoch 258 
2025-08-28 19:14:19.989061: Current learning rate: 0.00764 
2025-08-28 19:14:36.608293: train_loss -0.455 
2025-08-28 19:14:36.616615: val_loss -0.4173 
2025-08-28 19:14:36.620782: Pseudo dice [np.float32(0.6029)] 
2025-08-28 19:14:36.627824: Epoch time: 16.64 s 
2025-08-28 19:14:37.450818:  
2025-08-28 19:14:37.458321: Epoch 259 
2025-08-28 19:14:37.463861: Current learning rate: 0.00764 
2025-08-28 19:14:54.271956: train_loss -0.4023 
2025-08-28 19:14:54.279989: val_loss -0.4203 
2025-08-28 19:14:54.287953: Pseudo dice [np.float32(0.6728)] 
2025-08-28 19:14:54.293159: Epoch time: 16.82 s 
2025-08-28 19:14:54.967813:  
2025-08-28 19:14:54.976096: Epoch 260 
2025-08-28 19:14:54.981083: Current learning rate: 0.00763 
2025-08-28 19:15:11.631319: train_loss -0.3505 
2025-08-28 19:15:11.638945: val_loss -0.4489 
2025-08-28 19:15:11.647516: Pseudo dice [np.float32(0.6898)] 
2025-08-28 19:15:11.652093: Epoch time: 16.67 s 
2025-08-28 19:15:12.347651:  
2025-08-28 19:15:12.355915: Epoch 261 
2025-08-28 19:15:12.362880: Current learning rate: 0.00762 
2025-08-28 19:15:29.081399: train_loss -0.4092 
2025-08-28 19:15:29.089744: val_loss -0.4453 
2025-08-28 19:15:29.093979: Pseudo dice [np.float32(0.6591)] 
2025-08-28 19:15:29.099247: Epoch time: 16.74 s 
2025-08-28 19:15:29.792048:  
2025-08-28 19:15:29.799928: Epoch 262 
2025-08-28 19:15:29.803615: Current learning rate: 0.00761 
2025-08-28 19:15:46.629015: train_loss -0.3891 
2025-08-28 19:15:46.636524: val_loss -0.4694 
2025-08-28 19:15:46.640666: Pseudo dice [np.float32(0.718)] 
2025-08-28 19:15:46.646465: Epoch time: 16.84 s 
2025-08-28 19:15:47.336641:  
2025-08-28 19:15:47.343971: Epoch 263 
2025-08-28 19:15:47.351300: Current learning rate: 0.0076 
2025-08-28 19:16:04.058069: train_loss -0.4481 
2025-08-28 19:16:04.065960: val_loss -0.5785 
2025-08-28 19:16:04.075032: Pseudo dice [np.float32(0.7581)] 
2025-08-28 19:16:04.080530: Epoch time: 16.72 s 
2025-08-28 19:16:04.780192:  
2025-08-28 19:16:04.788556: Epoch 264 
2025-08-28 19:16:04.795115: Current learning rate: 0.00759 
2025-08-28 19:16:20.895341: train_loss -0.3966 
2025-08-28 19:16:20.903925: val_loss -0.3659 
2025-08-28 19:16:20.911627: Pseudo dice [np.float32(0.5829)] 
2025-08-28 19:16:20.916127: Epoch time: 16.12 s 
2025-08-28 19:16:21.759652:  
2025-08-28 19:16:21.767492: Epoch 265 
2025-08-28 19:16:21.773540: Current learning rate: 0.00758 
2025-08-28 19:16:37.837760: train_loss -0.4358 
2025-08-28 19:16:37.845971: val_loss -0.5148 
2025-08-28 19:16:37.850080: Pseudo dice [np.float32(0.7633)] 
2025-08-28 19:16:37.856895: Epoch time: 16.08 s 
2025-08-28 19:16:38.548237:  
2025-08-28 19:16:38.555673: Epoch 266 
2025-08-28 19:16:38.559755: Current learning rate: 0.00757 
2025-08-28 19:16:54.687777: train_loss -0.4142 
2025-08-28 19:16:54.698261: val_loss -0.4773 
2025-08-28 19:16:54.704036: Pseudo dice [np.float32(0.6252)] 
2025-08-28 19:16:54.709571: Epoch time: 16.14 s 
2025-08-28 19:16:55.401571:  
2025-08-28 19:16:55.409979: Epoch 267 
2025-08-28 19:16:55.415898: Current learning rate: 0.00756 
2025-08-28 19:17:11.379715: train_loss -0.4062 
2025-08-28 19:17:11.387733: val_loss -0.5281 
2025-08-28 19:17:11.391929: Pseudo dice [np.float32(0.7592)] 
2025-08-28 19:17:11.399765: Epoch time: 15.98 s 
2025-08-28 19:17:12.091057:  
2025-08-28 19:17:12.099878: Epoch 268 
2025-08-28 19:17:12.109899: Current learning rate: 0.00755 
2025-08-28 19:17:28.446504: train_loss -0.4205 
2025-08-28 19:17:28.454818: val_loss -0.5046 
2025-08-28 19:17:28.458908: Pseudo dice [np.float32(0.6871)] 
2025-08-28 19:17:28.466894: Epoch time: 16.36 s 
2025-08-28 19:17:29.177999:  
2025-08-28 19:17:29.185999: Epoch 269 
2025-08-28 19:17:29.192468: Current learning rate: 0.00754 
2025-08-28 19:17:45.475925: train_loss -0.4467 
2025-08-28 19:17:45.484303: val_loss -0.4435 
2025-08-28 19:17:45.488480: Pseudo dice [np.float32(0.6139)] 
2025-08-28 19:17:45.496504: Epoch time: 16.3 s 
2025-08-28 19:17:46.201257:  
2025-08-28 19:17:46.209027: Epoch 270 
2025-08-28 19:17:46.216016: Current learning rate: 0.00753 
2025-08-28 19:18:02.630503: train_loss -0.4081 
2025-08-28 19:18:02.638855: val_loss -0.5028 
2025-08-28 19:18:02.646898: Pseudo dice [np.float32(0.6941)] 
2025-08-28 19:18:02.651953: Epoch time: 16.43 s 
2025-08-28 19:18:03.347433:  
2025-08-28 19:18:03.354767: Epoch 271 
2025-08-28 19:18:03.359765: Current learning rate: 0.00752 
2025-08-28 19:18:20.001537: train_loss -0.4246 
2025-08-28 19:18:20.006307: val_loss -0.5066 
2025-08-28 19:18:20.014632: Pseudo dice [np.float32(0.7144)] 
2025-08-28 19:18:20.020140: Epoch time: 16.66 s 
2025-08-28 19:18:20.881614:  
2025-08-28 19:18:20.888935: Epoch 272 
2025-08-28 19:18:20.894956: Current learning rate: 0.00751 
2025-08-28 19:18:37.060656: train_loss -0.3998 
2025-08-28 19:18:37.069254: val_loss -0.3898 
2025-08-28 19:18:37.073288: Pseudo dice [np.float32(0.6785)] 
2025-08-28 19:18:37.079478: Epoch time: 16.18 s 
2025-08-28 19:18:37.750576:  
2025-08-28 19:18:37.757923: Epoch 273 
2025-08-28 19:18:37.763093: Current learning rate: 0.00751 
2025-08-28 19:18:54.040128: train_loss -0.4284 
2025-08-28 19:18:54.048574: val_loss -0.4883 
2025-08-28 19:18:54.052747: Pseudo dice [np.float32(0.7507)] 
2025-08-28 19:18:54.059760: Epoch time: 16.29 s 
2025-08-28 19:18:54.793700:  
2025-08-28 19:18:54.800971: Epoch 274 
2025-08-28 19:18:54.808290: Current learning rate: 0.0075 
2025-08-28 19:19:10.869557: train_loss -0.4079 
2025-08-28 19:19:10.881659: val_loss -0.4713 
2025-08-28 19:19:10.886201: Pseudo dice [np.float32(0.7222)] 
2025-08-28 19:19:10.891560: Epoch time: 16.08 s 
2025-08-28 19:19:11.558325:  
2025-08-28 19:19:11.565506: Epoch 275 
2025-08-28 19:19:11.569713: Current learning rate: 0.00749 
2025-08-28 19:19:27.657641: train_loss -0.4374 
2025-08-28 19:19:27.665650: val_loss -0.5478 
2025-08-28 19:19:27.669616: Pseudo dice [np.float32(0.7475)] 
2025-08-28 19:19:27.676802: Epoch time: 16.1 s 
2025-08-28 19:19:28.371991:  
2025-08-28 19:19:28.380905: Epoch 276 
2025-08-28 19:19:28.392123: Current learning rate: 0.00748 
2025-08-28 19:19:44.261245: train_loss -0.3962 
2025-08-28 19:19:44.269552: val_loss -0.4569 
2025-08-28 19:19:44.273661: Pseudo dice [np.float32(0.7344)] 
2025-08-28 19:19:44.281718: Epoch time: 15.89 s 
2025-08-28 19:19:44.986333:  
2025-08-28 19:19:44.994701: Epoch 277 
2025-08-28 19:19:45.000703: Current learning rate: 0.00747 
2025-08-28 19:20:01.065572: train_loss -0.4194 
2025-08-28 19:20:01.073806: val_loss -0.433 
2025-08-28 19:20:01.077903: Pseudo dice [np.float32(0.6763)] 
2025-08-28 19:20:01.086891: Epoch time: 16.08 s 
2025-08-28 19:20:01.777247:  
2025-08-28 19:20:01.784552: Epoch 278 
2025-08-28 19:20:01.789641: Current learning rate: 0.00746 
2025-08-28 19:20:17.936733: train_loss -0.4078 
2025-08-28 19:20:17.944883: val_loss -0.4697 
2025-08-28 19:20:17.949029: Pseudo dice [np.float32(0.7056)] 
2025-08-28 19:20:17.956932: Epoch time: 16.16 s 
2025-08-28 19:20:18.803497:  
2025-08-28 19:20:18.814528: Epoch 279 
2025-08-28 19:20:18.821775: Current learning rate: 0.00745 
2025-08-28 19:20:34.782450: train_loss -0.4573 
2025-08-28 19:20:34.786711: val_loss -0.5698 
2025-08-28 19:20:34.794497: Pseudo dice [np.float32(0.7597)] 
2025-08-28 19:20:34.799779: Epoch time: 15.98 s 
2025-08-28 19:20:35.519182:  
2025-08-28 19:20:35.528661: Epoch 280 
2025-08-28 19:20:35.537830: Current learning rate: 0.00744 
2025-08-28 19:20:51.115469: train_loss -0.4131 
2025-08-28 19:20:51.123427: val_loss -0.5101 
2025-08-28 19:20:51.127973: Pseudo dice [np.float32(0.7201)] 
2025-08-28 19:20:51.133939: Epoch time: 15.6 s 
2025-08-28 19:20:51.825234:  
2025-08-28 19:20:51.833651: Epoch 281 
2025-08-28 19:20:51.842309: Current learning rate: 0.00743 
2025-08-28 19:21:07.510891: train_loss -0.4526 
2025-08-28 19:21:07.523217: val_loss -0.5207 
2025-08-28 19:21:07.527627: Pseudo dice [np.float32(0.7114)] 
2025-08-28 19:21:07.533923: Epoch time: 15.69 s 
2025-08-28 19:21:08.227817:  
2025-08-28 19:21:08.236553: Epoch 282 
2025-08-28 19:21:08.247291: Current learning rate: 0.00742 
2025-08-28 19:21:23.656279: train_loss -0.4431 
2025-08-28 19:21:23.664576: val_loss -0.5481 
2025-08-28 19:21:23.672978: Pseudo dice [np.float32(0.7411)] 
2025-08-28 19:21:23.678290: Epoch time: 15.43 s 
2025-08-28 19:21:24.407663:  
2025-08-28 19:21:24.414836: Epoch 283 
2025-08-28 19:21:24.421160: Current learning rate: 0.00741 
2025-08-28 19:21:39.935679: train_loss -0.4448 
2025-08-28 19:21:39.942997: val_loss -0.5106 
2025-08-28 19:21:39.947483: Pseudo dice [np.float32(0.7476)] 
2025-08-28 19:21:39.954641: Epoch time: 15.53 s 
2025-08-28 19:21:40.646728:  
2025-08-28 19:21:40.654123: Epoch 284 
2025-08-28 19:21:40.662534: Current learning rate: 0.0074 
2025-08-28 19:21:56.113150: train_loss -0.4698 
2025-08-28 19:21:56.121960: val_loss -0.4585 
2025-08-28 19:21:56.129807: Pseudo dice [np.float32(0.6589)] 
2025-08-28 19:21:56.134219: Epoch time: 15.47 s 
2025-08-28 19:21:56.907506:  
2025-08-28 19:21:56.914063: Epoch 285 
2025-08-28 19:21:56.921293: Current learning rate: 0.00739 
2025-08-28 19:22:12.730708: train_loss -0.3978 
2025-08-28 19:22:12.738620: val_loss -0.4907 
2025-08-28 19:22:12.742737: Pseudo dice [np.float32(0.7058)] 
2025-08-28 19:22:12.750683: Epoch time: 15.83 s 
2025-08-28 19:22:13.605726:  
2025-08-28 19:22:13.615342: Epoch 286 
2025-08-28 19:22:13.622998: Current learning rate: 0.00738 
2025-08-28 19:22:29.084768: train_loss -0.3925 
2025-08-28 19:22:29.092450: val_loss -0.4832 
2025-08-28 19:22:29.100352: Pseudo dice [np.float32(0.6923)] 
2025-08-28 19:22:29.104574: Epoch time: 15.48 s 
2025-08-28 19:22:29.788451:  
2025-08-28 19:22:29.795764: Epoch 287 
2025-08-28 19:22:29.802134: Current learning rate: 0.00738 
2025-08-28 19:22:45.387647: train_loss -0.4609 
2025-08-28 19:22:45.396225: val_loss -0.5394 
2025-08-28 19:22:45.400352: Pseudo dice [np.float32(0.7694)] 
2025-08-28 19:22:45.407751: Epoch time: 15.6 s 
2025-08-28 19:22:46.113193:  
2025-08-28 19:22:46.121540: Epoch 288 
2025-08-28 19:22:46.127753: Current learning rate: 0.00737 
2025-08-28 19:23:01.708138: train_loss -0.4218 
2025-08-28 19:23:01.716702: val_loss -0.4706 
2025-08-28 19:23:01.724662: Pseudo dice [np.float32(0.691)] 
2025-08-28 19:23:01.728892: Epoch time: 15.6 s 
2025-08-28 19:23:02.428371:  
2025-08-28 19:23:02.436683: Epoch 289 
2025-08-28 19:23:02.442683: Current learning rate: 0.00736 
2025-08-28 19:23:17.979254: train_loss -0.4127 
2025-08-28 19:23:17.987333: val_loss -0.4677 
2025-08-28 19:23:17.991191: Pseudo dice [np.float32(0.7402)] 
2025-08-28 19:23:17.999221: Epoch time: 15.55 s 
2025-08-28 19:23:18.695746:  
2025-08-28 19:23:18.706337: Epoch 290 
2025-08-28 19:23:18.713262: Current learning rate: 0.00735 
2025-08-28 19:23:34.182035: train_loss -0.417 
2025-08-28 19:23:34.190389: val_loss -0.461 
2025-08-28 19:23:34.194959: Pseudo dice [np.float32(0.6984)] 
2025-08-28 19:23:34.200383: Epoch time: 15.49 s 
2025-08-28 19:23:34.925569:  
2025-08-28 19:23:34.933570: Epoch 291 
2025-08-28 19:23:34.943082: Current learning rate: 0.00734 
2025-08-28 19:23:50.490642: train_loss -0.4124 
2025-08-28 19:23:50.498829: val_loss -0.5049 
2025-08-28 19:23:50.502833: Pseudo dice [np.float32(0.6787)] 
2025-08-28 19:23:50.510773: Epoch time: 15.57 s 
2025-08-28 19:23:51.359469:  
2025-08-28 19:23:51.367800: Epoch 292 
2025-08-28 19:23:51.375110: Current learning rate: 0.00733 
2025-08-28 19:24:06.803123: train_loss -0.4184 
2025-08-28 19:24:06.815072: val_loss -0.442 
2025-08-28 19:24:06.819211: Pseudo dice [np.float32(0.6677)] 
2025-08-28 19:24:06.826105: Epoch time: 15.45 s 
2025-08-28 19:24:07.516400:  
2025-08-28 19:24:07.526675: Epoch 293 
2025-08-28 19:24:07.531921: Current learning rate: 0.00732 
2025-08-28 19:24:22.922791: train_loss -0.4349 
2025-08-28 19:24:22.931168: val_loss -0.4729 
2025-08-28 19:24:22.935336: Pseudo dice [np.float32(0.6994)] 
2025-08-28 19:24:22.941276: Epoch time: 15.41 s 
2025-08-28 19:24:23.636631:  
2025-08-28 19:24:23.643763: Epoch 294 
2025-08-28 19:24:23.649139: Current learning rate: 0.00731 
2025-08-28 19:24:39.143186: train_loss -0.4021 
2025-08-28 19:24:39.151211: val_loss -0.4501 
2025-08-28 19:24:39.155589: Pseudo dice [np.float32(0.634)] 
2025-08-28 19:24:39.161614: Epoch time: 15.51 s 
2025-08-28 19:24:39.853389:  
2025-08-28 19:24:39.861863: Epoch 295 
2025-08-28 19:24:39.871545: Current learning rate: 0.0073 
2025-08-28 19:24:55.421610: train_loss -0.4229 
2025-08-28 19:24:55.430196: val_loss -0.5181 
2025-08-28 19:24:55.434326: Pseudo dice [np.float32(0.742)] 
2025-08-28 19:24:55.442223: Epoch time: 15.57 s 
2025-08-28 19:24:56.138772:  
2025-08-28 19:24:56.146040: Epoch 296 
2025-08-28 19:24:56.151217: Current learning rate: 0.00729 
2025-08-28 19:25:12.004229: train_loss -0.4533 
2025-08-28 19:25:12.009360: val_loss -0.5268 
2025-08-28 19:25:12.018037: Pseudo dice [np.float32(0.7243)] 
2025-08-28 19:25:12.023927: Epoch time: 15.87 s 
2025-08-28 19:25:12.776291:  
2025-08-28 19:25:12.784540: Epoch 297 
2025-08-28 19:25:12.792994: Current learning rate: 0.00728 
2025-08-28 19:25:28.450572: train_loss -0.4093 
2025-08-28 19:25:28.458966: val_loss -0.4698 
2025-08-28 19:25:28.463220: Pseudo dice [np.float32(0.6982)] 
2025-08-28 19:25:28.471239: Epoch time: 15.68 s 
2025-08-28 19:25:29.331340:  
2025-08-28 19:25:29.338601: Epoch 298 
2025-08-28 19:25:29.346017: Current learning rate: 0.00727 
2025-08-28 19:25:45.196692: train_loss -0.3822 
2025-08-28 19:25:45.204423: val_loss -0.4355 
2025-08-28 19:25:45.209187: Pseudo dice [np.float32(0.685)] 
2025-08-28 19:25:45.215097: Epoch time: 15.87 s 
2025-08-28 19:25:45.966278:  
2025-08-28 19:25:45.972497: Epoch 299 
2025-08-28 19:25:45.980233: Current learning rate: 0.00726 
2025-08-28 19:26:01.980209: train_loss -0.4647 
2025-08-28 19:26:01.992037: val_loss -0.4576 
2025-08-28 19:26:01.996746: Pseudo dice [np.float32(0.6918)] 
2025-08-28 19:26:02.001837: Epoch time: 16.02 s 
2025-08-28 19:26:02.896127:  
2025-08-28 19:26:02.903901: Epoch 300 
2025-08-28 19:26:02.911395: Current learning rate: 0.00725 
2025-08-28 19:26:18.934536: train_loss -0.4257 
2025-08-28 19:26:18.942523: val_loss -0.5192 
2025-08-28 19:26:18.947032: Pseudo dice [np.float32(0.736)] 
2025-08-28 19:26:18.952243: Epoch time: 16.04 s 
2025-08-28 19:26:19.669189:  
2025-08-28 19:26:19.676376: Epoch 301 
2025-08-28 19:26:19.681644: Current learning rate: 0.00724 
2025-08-28 19:26:35.546999: train_loss -0.457 
2025-08-28 19:26:35.555160: val_loss -0.4925 
2025-08-28 19:26:35.559302: Pseudo dice [np.float32(0.7267)] 
2025-08-28 19:26:35.567327: Epoch time: 15.88 s 
2025-08-28 19:26:36.282539:  
2025-08-28 19:26:36.290853: Epoch 302 
2025-08-28 19:26:36.301087: Current learning rate: 0.00724 
2025-08-28 19:26:52.351235: train_loss -0.4522 
2025-08-28 19:26:52.359419: val_loss -0.435 
2025-08-28 19:26:52.363544: Pseudo dice [np.float32(0.6609)] 
2025-08-28 19:26:52.371786: Epoch time: 16.07 s 
2025-08-28 19:26:53.077494:  
2025-08-28 19:26:53.087664: Epoch 303 
2025-08-28 19:26:53.094146: Current learning rate: 0.00723 
2025-08-28 19:27:09.388372: train_loss -0.4127 
2025-08-28 19:27:09.397363: val_loss -0.5001 
2025-08-28 19:27:09.401517: Pseudo dice [np.float32(0.6847)] 
2025-08-28 19:27:09.408459: Epoch time: 16.31 s 
2025-08-28 19:27:10.119576:  
2025-08-28 19:27:10.127968: Epoch 304 
2025-08-28 19:27:10.136776: Current learning rate: 0.00722 
2025-08-28 19:27:26.288643: train_loss -0.4619 
2025-08-28 19:27:26.293608: val_loss -0.4793 
2025-08-28 19:27:26.302014: Pseudo dice [np.float32(0.6874)] 
2025-08-28 19:27:26.311085: Epoch time: 16.17 s 
2025-08-28 19:27:27.184462:  
2025-08-28 19:27:27.195904: Epoch 305 
2025-08-28 19:27:27.207749: Current learning rate: 0.00721 
2025-08-28 19:27:43.331301: train_loss -0.4481 
2025-08-28 19:27:43.341433: val_loss -0.5341 
2025-08-28 19:27:43.347986: Pseudo dice [np.float32(0.7373)] 
2025-08-28 19:27:43.352625: Epoch time: 16.15 s 
2025-08-28 19:27:44.049207:  
2025-08-28 19:27:44.056360: Epoch 306 
2025-08-28 19:27:44.065981: Current learning rate: 0.0072 
2025-08-28 19:28:00.404262: train_loss -0.4736 
2025-08-28 19:28:00.414860: val_loss -0.355 
2025-08-28 19:28:00.418790: Pseudo dice [np.float32(0.62)] 
2025-08-28 19:28:00.424361: Epoch time: 16.36 s 
2025-08-28 19:28:01.125344:  
2025-08-28 19:28:01.132432: Epoch 307 
2025-08-28 19:28:01.136604: Current learning rate: 0.00719 
2025-08-28 19:28:17.527945: train_loss -0.4127 
2025-08-28 19:28:17.535810: val_loss -0.3981 
2025-08-28 19:28:17.540467: Pseudo dice [np.float32(0.6229)] 
2025-08-28 19:28:17.546430: Epoch time: 16.4 s 
2025-08-28 19:28:18.252931:  
2025-08-28 19:28:18.261339: Epoch 308 
2025-08-28 19:28:18.271344: Current learning rate: 0.00718 
2025-08-28 19:28:34.398999: train_loss -0.4372 
2025-08-28 19:28:34.407276: val_loss -0.5464 
2025-08-28 19:28:34.415017: Pseudo dice [np.float32(0.7229)] 
2025-08-28 19:28:34.420706: Epoch time: 16.15 s 
2025-08-28 19:28:35.188833:  
2025-08-28 19:28:35.198994: Epoch 309 
2025-08-28 19:28:35.208140: Current learning rate: 0.00717 
2025-08-28 19:28:51.444299: train_loss -0.424 
2025-08-28 19:28:51.452999: val_loss -0.4874 
2025-08-28 19:28:51.457602: Pseudo dice [np.float32(0.64)] 
2025-08-28 19:28:51.462854: Epoch time: 16.26 s 
2025-08-28 19:28:52.177541:  
2025-08-28 19:28:52.185901: Epoch 310 
2025-08-28 19:28:52.196582: Current learning rate: 0.00716 
2025-08-28 19:29:08.078415: train_loss -0.4006 
2025-08-28 19:29:08.086672: val_loss -0.3837 
2025-08-28 19:29:08.090756: Pseudo dice [np.float32(0.6253)] 
2025-08-28 19:29:08.098788: Epoch time: 15.9 s 
2025-08-28 19:29:08.956835:  
2025-08-28 19:29:08.967970: Epoch 311 
2025-08-28 19:29:08.975164: Current learning rate: 0.00715 
2025-08-28 19:29:25.141226: train_loss -0.445 
2025-08-28 19:29:25.148975: val_loss -0.5024 
2025-08-28 19:29:25.153711: Pseudo dice [np.float32(0.6534)] 
2025-08-28 19:29:25.158489: Epoch time: 16.19 s 
2025-08-28 19:29:25.867486:  
2025-08-28 19:29:25.877904: Epoch 312 
2025-08-28 19:29:25.887309: Current learning rate: 0.00714 
2025-08-28 19:29:41.891381: train_loss -0.4389 
2025-08-28 19:29:41.899595: val_loss -0.5346 
2025-08-28 19:29:41.903800: Pseudo dice [np.float32(0.7988)] 
2025-08-28 19:29:41.912779: Epoch time: 16.03 s 
2025-08-28 19:29:42.625639:  
2025-08-28 19:29:42.635714: Epoch 313 
2025-08-28 19:29:42.644416: Current learning rate: 0.00713 
2025-08-28 19:29:58.829037: train_loss -0.4702 
2025-08-28 19:29:58.837343: val_loss -0.4918 
2025-08-28 19:29:58.841403: Pseudo dice [np.float32(0.765)] 
2025-08-28 19:29:58.847306: Epoch time: 16.2 s 
2025-08-28 19:29:59.563634:  
2025-08-28 19:29:59.575006: Epoch 314 
2025-08-28 19:29:59.582782: Current learning rate: 0.00712 
2025-08-28 19:30:15.745965: train_loss -0.4251 
2025-08-28 19:30:15.754213: val_loss -0.4532 
2025-08-28 19:30:15.758375: Pseudo dice [np.float32(0.6566)] 
2025-08-28 19:30:15.765238: Epoch time: 16.18 s 
2025-08-28 19:30:16.486793:  
2025-08-28 19:30:16.495954: Epoch 315 
2025-08-28 19:30:16.504524: Current learning rate: 0.00711 
2025-08-28 19:30:32.821141: train_loss -0.4229 
2025-08-28 19:30:32.829197: val_loss -0.4453 
2025-08-28 19:30:32.833397: Pseudo dice [np.float32(0.7165)] 
2025-08-28 19:30:32.841764: Epoch time: 16.34 s 
2025-08-28 19:30:33.549600:  
2025-08-28 19:30:33.556903: Epoch 316 
2025-08-28 19:30:33.563084: Current learning rate: 0.0071 
2025-08-28 19:30:49.717302: train_loss -0.4395 
2025-08-28 19:30:49.725589: val_loss -0.4998 
2025-08-28 19:30:49.729379: Pseudo dice [np.float32(0.711)] 
2025-08-28 19:30:49.737708: Epoch time: 16.17 s 
2025-08-28 19:30:50.456123:  
2025-08-28 19:30:50.464592: Epoch 317 
2025-08-28 19:30:50.471742: Current learning rate: 0.0071 
2025-08-28 19:31:06.638273: train_loss -0.47 
2025-08-28 19:31:06.646683: val_loss -0.5462 
2025-08-28 19:31:06.650757: Pseudo dice [np.float32(0.7498)] 
2025-08-28 19:31:06.658723: Epoch time: 16.18 s 
2025-08-28 19:31:07.543815:  
2025-08-28 19:31:07.555528: Epoch 318 
2025-08-28 19:31:07.562375: Current learning rate: 0.00709 
2025-08-28 19:31:23.613953: train_loss -0.4732 
2025-08-28 19:31:23.621973: val_loss -0.533 
2025-08-28 19:31:23.626289: Pseudo dice [np.float32(0.69)] 
2025-08-28 19:31:23.633712: Epoch time: 16.07 s 
2025-08-28 19:31:24.348322:  
2025-08-28 19:31:24.357453: Epoch 319 
2025-08-28 19:31:24.365589: Current learning rate: 0.00708 
2025-08-28 19:31:40.167845: train_loss -0.4945 
2025-08-28 19:31:40.175888: val_loss -0.5605 
2025-08-28 19:31:40.180269: Pseudo dice [np.float32(0.7135)] 
2025-08-28 19:31:40.186994: Epoch time: 15.82 s 
2025-08-28 19:31:40.890819:  
2025-08-28 19:31:40.901328: Epoch 320 
2025-08-28 19:31:40.908282: Current learning rate: 0.00707 
2025-08-28 19:31:56.984352: train_loss -0.4676 
2025-08-28 19:31:56.996953: val_loss -0.5492 
2025-08-28 19:31:57.001121: Pseudo dice [np.float32(0.72)] 
2025-08-28 19:31:57.007996: Epoch time: 16.09 s 
2025-08-28 19:31:57.721154:  
2025-08-28 19:31:57.728272: Epoch 321 
2025-08-28 19:31:57.735804: Current learning rate: 0.00706 
2025-08-28 19:32:13.859793: train_loss -0.4741 
2025-08-28 19:32:13.868057: val_loss -0.5145 
2025-08-28 19:32:13.875793: Pseudo dice [np.float32(0.7021)] 
2025-08-28 19:32:13.880969: Epoch time: 16.14 s 
2025-08-28 19:32:14.581891:  
2025-08-28 19:32:14.588960: Epoch 322 
2025-08-28 19:32:14.594319: Current learning rate: 0.00705 
2025-08-28 19:32:30.831174: train_loss -0.4437 
2025-08-28 19:32:30.839300: val_loss -0.4946 
2025-08-28 19:32:30.843384: Pseudo dice [np.float32(0.6745)] 
2025-08-28 19:32:30.852325: Epoch time: 16.25 s 
2025-08-28 19:32:31.563281:  
2025-08-28 19:32:31.570650: Epoch 323 
2025-08-28 19:32:31.575745: Current learning rate: 0.00704 
2025-08-28 19:32:47.764287: train_loss -0.4976 
2025-08-28 19:32:47.772348: val_loss -0.4834 
2025-08-28 19:32:47.776731: Pseudo dice [np.float32(0.6137)] 
2025-08-28 19:32:47.785669: Epoch time: 16.2 s 
2025-08-28 19:32:48.634497:  
2025-08-28 19:32:48.642940: Epoch 324 
2025-08-28 19:32:48.648987: Current learning rate: 0.00703 
2025-08-28 19:33:04.944044: train_loss -0.44 
2025-08-28 19:33:04.956080: val_loss -0.497 
2025-08-28 19:33:04.960654: Pseudo dice [np.float32(0.7474)] 
2025-08-28 19:33:04.966676: Epoch time: 16.31 s 
2025-08-28 19:33:05.668143:  
2025-08-28 19:33:05.675477: Epoch 325 
2025-08-28 19:33:05.684957: Current learning rate: 0.00702 
2025-08-28 19:33:21.864911: train_loss -0.4945 
2025-08-28 19:33:21.873306: val_loss -0.5183 
2025-08-28 19:33:21.881292: Pseudo dice [np.float32(0.7067)] 
2025-08-28 19:33:21.886384: Epoch time: 16.2 s 
2025-08-28 19:33:22.594485:  
2025-08-28 19:33:22.604064: Epoch 326 
2025-08-28 19:33:22.611668: Current learning rate: 0.00701 
2025-08-28 19:33:38.674845: train_loss -0.4784 
2025-08-28 19:33:38.681732: val_loss -0.4265 
2025-08-28 19:33:38.685622: Pseudo dice [np.float32(0.6289)] 
2025-08-28 19:33:38.693915: Epoch time: 16.08 s 
2025-08-28 19:33:39.427163:  
2025-08-28 19:33:39.432839: Epoch 327 
2025-08-28 19:33:39.440542: Current learning rate: 0.007 
2025-08-28 19:33:55.278692: train_loss -0.4357 
2025-08-28 19:33:55.285857: val_loss -0.4457 
2025-08-28 19:33:55.294230: Pseudo dice [np.float32(0.7058)] 
2025-08-28 19:33:55.302066: Epoch time: 15.85 s 
2025-08-28 19:33:55.999749:  
2025-08-28 19:33:56.009042: Epoch 328 
2025-08-28 19:33:56.018276: Current learning rate: 0.00699 
2025-08-28 19:34:11.944245: train_loss -0.4583 
2025-08-28 19:34:11.952539: val_loss -0.5241 
2025-08-28 19:34:11.960813: Pseudo dice [np.float32(0.7659)] 
2025-08-28 19:34:11.966878: Epoch time: 15.95 s 
2025-08-28 19:34:12.680849:  
2025-08-28 19:34:12.688280: Epoch 329 
2025-08-28 19:34:12.694461: Current learning rate: 0.00698 
2025-08-28 19:34:28.806799: train_loss -0.4272 
2025-08-28 19:34:28.815164: val_loss -0.5065 
2025-08-28 19:34:28.819422: Pseudo dice [np.float32(0.6264)] 
2025-08-28 19:34:28.827278: Epoch time: 16.13 s 
2025-08-28 19:34:29.688654:  
2025-08-28 19:34:29.696842: Epoch 330 
2025-08-28 19:34:29.702995: Current learning rate: 0.00697 
2025-08-28 19:34:45.727944: train_loss -0.4576 
2025-08-28 19:34:45.736262: val_loss -0.5761 
2025-08-28 19:34:45.740442: Pseudo dice [np.float32(0.7343)] 
2025-08-28 19:34:45.747984: Epoch time: 16.04 s 
2025-08-28 19:34:46.447899:  
2025-08-28 19:34:46.457207: Epoch 331 
2025-08-28 19:34:46.462163: Current learning rate: 0.00696 
2025-08-28 19:35:02.473872: train_loss -0.4549 
2025-08-28 19:35:02.486255: val_loss -0.5373 
2025-08-28 19:35:02.490481: Pseudo dice [np.float32(0.6919)] 
2025-08-28 19:35:02.497276: Epoch time: 16.03 s 
2025-08-28 19:35:03.193776:  
2025-08-28 19:35:03.202101: Epoch 332 
2025-08-28 19:35:03.207305: Current learning rate: 0.00696 
2025-08-28 19:35:19.257245: train_loss -0.4556 
2025-08-28 19:35:19.265175: val_loss -0.5423 
2025-08-28 19:35:19.269693: Pseudo dice [np.float32(0.7329)] 
2025-08-28 19:35:19.274808: Epoch time: 16.06 s 
2025-08-28 19:35:19.962683:  
2025-08-28 19:35:19.969958: Epoch 333 
2025-08-28 19:35:19.975437: Current learning rate: 0.00695 
2025-08-28 19:35:36.274164: train_loss -0.4638 
2025-08-28 19:35:36.282550: val_loss -0.3677 
2025-08-28 19:35:36.290532: Pseudo dice [np.float32(0.563)] 
2025-08-28 19:35:36.295649: Epoch time: 16.32 s 
2025-08-28 19:35:37.007677:  
2025-08-28 19:35:37.012536: Epoch 334 
2025-08-28 19:35:37.020377: Current learning rate: 0.00694 
2025-08-28 19:35:53.232696: train_loss -0.4202 
2025-08-28 19:35:53.241102: val_loss -0.3377 
2025-08-28 19:35:53.245265: Pseudo dice [np.float32(0.5978)] 
2025-08-28 19:35:53.251244: Epoch time: 16.23 s 
2025-08-28 19:35:53.997515:  
2025-08-28 19:35:54.005220: Epoch 335 
2025-08-28 19:35:54.011211: Current learning rate: 0.00693 
2025-08-28 19:36:10.203020: train_loss -0.3747 
2025-08-28 19:36:10.212280: val_loss -0.3729 
2025-08-28 19:36:10.216448: Pseudo dice [np.float32(0.5843)] 
2025-08-28 19:36:10.223304: Epoch time: 16.21 s 
2025-08-28 19:36:10.938683:  
2025-08-28 19:36:10.947044: Epoch 336 
2025-08-28 19:36:10.955380: Current learning rate: 0.00692 
2025-08-28 19:36:26.967491: train_loss -0.4333 
2025-08-28 19:36:26.974757: val_loss -0.5017 
2025-08-28 19:36:26.978953: Pseudo dice [np.float32(0.7387)] 
2025-08-28 19:36:26.987001: Epoch time: 16.03 s 
2025-08-28 19:36:27.868125:  
2025-08-28 19:36:27.877376: Epoch 337 
2025-08-28 19:36:27.885871: Current learning rate: 0.00691 
2025-08-28 19:36:44.087349: train_loss -0.4703 
2025-08-28 19:36:44.091934: val_loss -0.4781 
2025-08-28 19:36:44.100267: Pseudo dice [np.float32(0.7483)] 
2025-08-28 19:36:44.105619: Epoch time: 16.22 s 
2025-08-28 19:36:44.810946:  
2025-08-28 19:36:44.819357: Epoch 338 
2025-08-28 19:36:44.826746: Current learning rate: 0.0069 
2025-08-28 19:37:00.899790: train_loss -0.42 
2025-08-28 19:37:00.908654: val_loss -0.4436 
2025-08-28 19:37:00.917058: Pseudo dice [np.float32(0.7077)] 
2025-08-28 19:37:00.923115: Epoch time: 16.09 s 
2025-08-28 19:37:01.660075:  
2025-08-28 19:37:01.669440: Epoch 339 
2025-08-28 19:37:01.679301: Current learning rate: 0.00689 
2025-08-28 19:37:17.621275: train_loss -0.4203 
2025-08-28 19:37:17.629494: val_loss -0.3772 
2025-08-28 19:37:17.638011: Pseudo dice [np.float32(0.6058)] 
2025-08-28 19:37:17.645819: Epoch time: 15.96 s 
2025-08-28 19:37:18.403521:  
2025-08-28 19:37:18.411128: Epoch 340 
2025-08-28 19:37:18.416313: Current learning rate: 0.00688 
2025-08-28 19:37:34.437239: train_loss -0.4412 
2025-08-28 19:37:34.442178: val_loss -0.5348 
2025-08-28 19:37:34.450575: Pseudo dice [np.float32(0.7204)] 
2025-08-28 19:37:34.456478: Epoch time: 16.04 s 
2025-08-28 19:37:35.176887:  
2025-08-28 19:37:35.184024: Epoch 341 
2025-08-28 19:37:35.189384: Current learning rate: 0.00687 
2025-08-28 19:37:51.108968: train_loss -0.4587 
2025-08-28 19:37:51.117122: val_loss -0.4922 
2025-08-28 19:37:51.121416: Pseudo dice [np.float32(0.7049)] 
2025-08-28 19:37:51.127326: Epoch time: 15.93 s 
2025-08-28 19:37:51.846531:  
2025-08-28 19:37:51.854846: Epoch 342 
2025-08-28 19:37:51.859608: Current learning rate: 0.00686 
2025-08-28 19:38:08.225956: train_loss -0.4868 
2025-08-28 19:38:08.238465: val_loss -0.502 
2025-08-28 19:38:08.242593: Pseudo dice [np.float32(0.7208)] 
2025-08-28 19:38:08.250523: Epoch time: 16.38 s 
2025-08-28 19:38:09.106639:  
2025-08-28 19:38:09.114922: Epoch 343 
2025-08-28 19:38:09.120096: Current learning rate: 0.00685 
2025-08-28 19:38:25.176214: train_loss -0.4805 
2025-08-28 19:38:25.184205: val_loss -0.5293 
2025-08-28 19:38:25.192420: Pseudo dice [np.float32(0.7462)] 
2025-08-28 19:38:25.198172: Epoch time: 16.07 s 
2025-08-28 19:38:25.921179:  
2025-08-28 19:38:25.928532: Epoch 344 
2025-08-28 19:38:25.934685: Current learning rate: 0.00684 
2025-08-28 19:38:42.047189: train_loss -0.485 
2025-08-28 19:38:42.055484: val_loss -0.6266 
2025-08-28 19:38:42.059796: Pseudo dice [np.float32(0.7522)] 
2025-08-28 19:38:42.068664: Epoch time: 16.13 s 
2025-08-28 19:38:42.818325:  
2025-08-28 19:38:42.827288: Epoch 345 
2025-08-28 19:38:42.832930: Current learning rate: 0.00683 
2025-08-28 19:38:58.914048: train_loss -0.4841 
2025-08-28 19:38:58.926535: val_loss -0.4837 
2025-08-28 19:38:58.931226: Pseudo dice [np.float32(0.6789)] 
2025-08-28 19:38:58.936628: Epoch time: 16.1 s 
2025-08-28 19:38:59.634110:  
2025-08-28 19:38:59.640129: Epoch 346 
2025-08-28 19:38:59.649452: Current learning rate: 0.00682 
2025-08-28 19:39:16.014443: train_loss -0.438 
2025-08-28 19:39:16.022691: val_loss -0.5289 
2025-08-28 19:39:16.026589: Pseudo dice [np.float32(0.6897)] 
2025-08-28 19:39:16.034571: Epoch time: 16.38 s 
2025-08-28 19:39:16.747043:  
2025-08-28 19:39:16.755257: Epoch 347 
2025-08-28 19:39:16.760452: Current learning rate: 0.00681 
2025-08-28 19:39:32.585403: train_loss -0.4218 
2025-08-28 19:39:32.593603: val_loss -0.5179 
2025-08-28 19:39:32.601897: Pseudo dice [np.float32(0.7439)] 
2025-08-28 19:39:32.608383: Epoch time: 15.84 s 
2025-08-28 19:39:33.330220:  
2025-08-28 19:39:33.339489: Epoch 348 
2025-08-28 19:39:33.345868: Current learning rate: 0.0068 
2025-08-28 19:39:49.439629: train_loss -0.4381 
2025-08-28 19:39:49.447415: val_loss -0.5387 
2025-08-28 19:39:49.455653: Pseudo dice [np.float32(0.7684)] 
2025-08-28 19:39:49.461256: Epoch time: 16.11 s 
2025-08-28 19:39:50.181338:  
2025-08-28 19:39:50.188678: Epoch 349 
2025-08-28 19:39:50.196600: Current learning rate: 0.0068 
2025-08-28 19:40:06.172910: train_loss -0.4854 
2025-08-28 19:40:06.185390: val_loss -0.5091 
2025-08-28 19:40:06.189449: Pseudo dice [np.float32(0.6998)] 
2025-08-28 19:40:06.195393: Epoch time: 15.99 s 
2025-08-28 19:40:07.220339:  
2025-08-28 19:40:07.227571: Epoch 350 
2025-08-28 19:40:07.234982: Current learning rate: 0.00679 
2025-08-28 19:40:23.786304: train_loss -0.476 
2025-08-28 19:40:23.796119: val_loss -0.5032 
2025-08-28 19:40:23.798784: Pseudo dice [np.float32(0.687)] 
2025-08-28 19:40:23.806893: Epoch time: 16.57 s 
2025-08-28 19:40:24.515700:  
2025-08-28 19:40:24.524278: Epoch 351 
2025-08-28 19:40:24.533477: Current learning rate: 0.00678 
2025-08-28 19:40:41.191080: train_loss -0.4419 
2025-08-28 19:40:41.199402: val_loss -0.534 
2025-08-28 19:40:41.207431: Pseudo dice [np.float32(0.7294)] 
2025-08-28 19:40:41.213152: Epoch time: 16.68 s 
2025-08-28 19:40:41.895468:  
2025-08-28 19:40:41.904140: Epoch 352 
2025-08-28 19:40:41.912314: Current learning rate: 0.00677 
2025-08-28 19:40:58.508675: train_loss -0.4651 
2025-08-28 19:40:58.520924: val_loss -0.4826 
2025-08-28 19:40:58.525092: Pseudo dice [np.float32(0.6963)] 
2025-08-28 19:40:58.532589: Epoch time: 16.62 s 
2025-08-28 19:40:59.242482:  
2025-08-28 19:40:59.251572: Epoch 353 
2025-08-28 19:40:59.257620: Current learning rate: 0.00676 
2025-08-28 19:41:16.055278: train_loss -0.4719 
2025-08-28 19:41:16.066519: val_loss -0.52 
2025-08-28 19:41:16.075482: Pseudo dice [np.float32(0.743)] 
2025-08-28 19:41:16.081539: Epoch time: 16.81 s 
2025-08-28 19:41:16.817927:  
2025-08-28 19:41:16.826718: Epoch 354 
2025-08-28 19:41:16.832212: Current learning rate: 0.00675 
2025-08-28 19:41:33.468627: train_loss -0.434 
2025-08-28 19:41:33.476635: val_loss -0.5646 
2025-08-28 19:41:33.480871: Pseudo dice [np.float32(0.7431)] 
2025-08-28 19:41:33.488685: Epoch time: 16.65 s 
2025-08-28 19:41:34.226975:  
2025-08-28 19:41:34.235194: Epoch 355 
2025-08-28 19:41:34.240584: Current learning rate: 0.00674 
2025-08-28 19:41:51.114673: train_loss -0.4529 
2025-08-28 19:41:51.122932: val_loss -0.4684 
2025-08-28 19:41:51.127649: Pseudo dice [np.float32(0.6227)] 
2025-08-28 19:41:51.133504: Epoch time: 16.89 s 
2025-08-28 19:41:51.988408:  
2025-08-28 19:41:51.995792: Epoch 356 
2025-08-28 19:41:52.001932: Current learning rate: 0.00673 
2025-08-28 19:42:08.407465: train_loss -0.469 
2025-08-28 19:42:08.415710: val_loss -0.5524 
2025-08-28 19:42:08.419932: Pseudo dice [np.float32(0.7298)] 
2025-08-28 19:42:08.426895: Epoch time: 16.42 s 
2025-08-28 19:42:09.127363:  
2025-08-28 19:42:09.134716: Epoch 357 
2025-08-28 19:42:09.140969: Current learning rate: 0.00672 
2025-08-28 19:42:25.824824: train_loss -0.4812 
2025-08-28 19:42:25.833154: val_loss -0.4288 
2025-08-28 19:42:25.837253: Pseudo dice [np.float32(0.6786)] 
2025-08-28 19:42:25.846220: Epoch time: 16.7 s 
2025-08-28 19:42:26.543760:  
2025-08-28 19:42:26.551075: Epoch 358 
2025-08-28 19:42:26.556271: Current learning rate: 0.00671 
2025-08-28 19:42:42.878296: train_loss -0.4619 
2025-08-28 19:42:42.883448: val_loss -0.5119 
2025-08-28 19:42:42.891804: Pseudo dice [np.float32(0.7204)] 
2025-08-28 19:42:42.897014: Epoch time: 16.34 s 
2025-08-28 19:42:43.598323:  
2025-08-28 19:42:43.605715: Epoch 359 
2025-08-28 19:42:43.611864: Current learning rate: 0.0067 
2025-08-28 19:43:00.442429: train_loss -0.4543 
2025-08-28 19:43:00.455218: val_loss -0.4954 
2025-08-28 19:43:00.459374: Pseudo dice [np.float32(0.7592)] 
2025-08-28 19:43:00.464470: Epoch time: 16.85 s 
2025-08-28 19:43:01.172704:  
2025-08-28 19:43:01.183198: Epoch 360 
2025-08-28 19:43:01.189740: Current learning rate: 0.00669 
2025-08-28 19:43:17.475951: train_loss -0.4632 
2025-08-28 19:43:17.484273: val_loss -0.4494 
2025-08-28 19:43:17.488956: Pseudo dice [np.float32(0.6022)] 
2025-08-28 19:43:17.496019: Epoch time: 16.3 s 
2025-08-28 19:43:18.236986:  
2025-08-28 19:43:18.246411: Epoch 361 
2025-08-28 19:43:18.253411: Current learning rate: 0.00668 
2025-08-28 19:43:34.877132: train_loss -0.4446 
2025-08-28 19:43:34.885417: val_loss -0.455 
2025-08-28 19:43:34.893119: Pseudo dice [np.float32(0.6325)] 
2025-08-28 19:43:34.898294: Epoch time: 16.64 s 
2025-08-28 19:43:35.750388:  
2025-08-28 19:43:35.758746: Epoch 362 
2025-08-28 19:43:35.765008: Current learning rate: 0.00667 
2025-08-28 19:43:52.624027: train_loss -0.4971 
2025-08-28 19:43:52.632311: val_loss -0.6291 
2025-08-28 19:43:52.640238: Pseudo dice [np.float32(0.7787)] 
2025-08-28 19:43:52.645993: Epoch time: 16.87 s 
2025-08-28 19:43:53.368956:  
2025-08-28 19:43:53.378455: Epoch 363 
2025-08-28 19:43:53.383647: Current learning rate: 0.00666 
2025-08-28 19:44:10.191782: train_loss -0.4174 
2025-08-28 19:44:10.203468: val_loss -0.4054 
2025-08-28 19:44:10.208151: Pseudo dice [np.float32(0.6619)] 
2025-08-28 19:44:10.213428: Epoch time: 16.82 s 
2025-08-28 19:44:10.913657:  
2025-08-28 19:44:10.923017: Epoch 364 
2025-08-28 19:44:10.930172: Current learning rate: 0.00665 
2025-08-28 19:44:27.403969: train_loss -0.4944 
2025-08-28 19:44:27.412378: val_loss -0.4297 
2025-08-28 19:44:27.417020: Pseudo dice [np.float32(0.6775)] 
2025-08-28 19:44:27.422331: Epoch time: 16.49 s 
2025-08-28 19:44:28.110975:  
2025-08-28 19:44:28.117155: Epoch 365 
2025-08-28 19:44:28.123477: Current learning rate: 0.00665 
2025-08-28 19:44:44.874341: train_loss -0.4721 
2025-08-28 19:44:44.879876: val_loss -0.4926 
2025-08-28 19:44:44.888533: Pseudo dice [np.float32(0.7011)] 
2025-08-28 19:44:44.893708: Epoch time: 16.77 s 
2025-08-28 19:44:45.642106:  
2025-08-28 19:44:45.651159: Epoch 366 
2025-08-28 19:44:45.656687: Current learning rate: 0.00664 
2025-08-28 19:45:02.160047: train_loss -0.4288 
2025-08-28 19:45:02.171752: val_loss -0.589 
2025-08-28 19:45:02.176659: Pseudo dice [np.float32(0.7778)] 
2025-08-28 19:45:02.182600: Epoch time: 16.52 s 
2025-08-28 19:45:02.904348:  
2025-08-28 19:45:02.910832: Epoch 367 
2025-08-28 19:45:02.918943: Current learning rate: 0.00663 
2025-08-28 19:45:19.668835: train_loss -0.4909 
2025-08-28 19:45:19.677438: val_loss -0.4859 
2025-08-28 19:45:19.681698: Pseudo dice [np.float32(0.6721)] 
2025-08-28 19:45:19.689099: Epoch time: 16.77 s 
2025-08-28 19:45:20.584201:  
2025-08-28 19:45:20.592563: Epoch 368 
2025-08-28 19:45:20.600325: Current learning rate: 0.00662 
2025-08-28 19:45:37.015609: train_loss -0.4739 
2025-08-28 19:45:37.023470: val_loss -0.5425 
2025-08-28 19:45:37.028248: Pseudo dice [np.float32(0.7349)] 
2025-08-28 19:45:37.035207: Epoch time: 16.43 s 
2025-08-28 19:45:37.724124:  
2025-08-28 19:45:37.731503: Epoch 369 
2025-08-28 19:45:37.736749: Current learning rate: 0.00661 
2025-08-28 19:45:54.332281: train_loss -0.4984 
2025-08-28 19:45:54.336718: val_loss -0.5257 
2025-08-28 19:45:54.345435: Pseudo dice [np.float32(0.7175)] 
2025-08-28 19:45:54.350045: Epoch time: 16.61 s 
2025-08-28 19:45:55.056124:  
2025-08-28 19:45:55.065893: Epoch 370 
2025-08-28 19:45:55.071340: Current learning rate: 0.0066 
2025-08-28 19:46:11.833719: train_loss -0.4578 
2025-08-28 19:46:11.842156: val_loss -0.5132 
2025-08-28 19:46:11.846256: Pseudo dice [np.float32(0.7126)] 
2025-08-28 19:46:11.853275: Epoch time: 16.78 s 
2025-08-28 19:46:12.556930:  
2025-08-28 19:46:12.564371: Epoch 371 
2025-08-28 19:46:12.569458: Current learning rate: 0.00659 
2025-08-28 19:46:29.146180: train_loss -0.4846 
2025-08-28 19:46:29.150945: val_loss -0.5506 
2025-08-28 19:46:29.159403: Pseudo dice [np.float32(0.7253)] 
2025-08-28 19:46:29.163990: Epoch time: 16.59 s 
2025-08-28 19:46:29.870032:  
2025-08-28 19:46:29.878000: Epoch 372 
2025-08-28 19:46:29.883563: Current learning rate: 0.00658 
2025-08-28 19:46:46.364076: train_loss -0.4974 
2025-08-28 19:46:46.372481: val_loss -0.605 
2025-08-28 19:46:46.376616: Pseudo dice [np.float32(0.76)] 
2025-08-28 19:46:46.385477: Epoch time: 16.5 s 
2025-08-28 19:46:47.083054:  
2025-08-28 19:46:47.091407: Epoch 373 
2025-08-28 19:46:47.098775: Current learning rate: 0.00657 
2025-08-28 19:47:03.590366: train_loss -0.4809 
2025-08-28 19:47:03.602058: val_loss -0.5826 
2025-08-28 19:47:03.606236: Pseudo dice [np.float32(0.7586)] 
2025-08-28 19:47:03.615103: Epoch time: 16.51 s 
2025-08-28 19:47:04.324307:  
2025-08-28 19:47:04.332633: Epoch 374 
2025-08-28 19:47:04.337804: Current learning rate: 0.00656 
2025-08-28 19:47:21.378249: train_loss -0.5073 
2025-08-28 19:47:21.386536: val_loss -0.4962 
2025-08-28 19:47:21.390691: Pseudo dice [np.float32(0.697)] 
2025-08-28 19:47:21.400274: Epoch time: 17.06 s 
2025-08-28 19:47:22.327694:  
2025-08-28 19:47:22.334946: Epoch 375 
2025-08-28 19:47:22.343411: Current learning rate: 0.00655 
2025-08-28 19:47:38.728834: train_loss -0.5203 
2025-08-28 19:47:38.737093: val_loss -0.4375 
2025-08-28 19:47:38.741363: Pseudo dice [np.float32(0.6645)] 
2025-08-28 19:47:38.748272: Epoch time: 16.4 s 
2025-08-28 19:47:39.453996:  
2025-08-28 19:47:39.461367: Epoch 376 
2025-08-28 19:47:39.466512: Current learning rate: 0.00654 
2025-08-28 19:47:56.229826: train_loss -0.496 
2025-08-28 19:47:56.242223: val_loss -0.4877 
2025-08-28 19:47:56.246399: Pseudo dice [np.float32(0.6841)] 
2025-08-28 19:47:56.252234: Epoch time: 16.78 s 
2025-08-28 19:47:56.966361:  
2025-08-28 19:47:56.974730: Epoch 377 
2025-08-28 19:47:56.984375: Current learning rate: 0.00653 
2025-08-28 19:48:13.659462: train_loss -0.4772 
2025-08-28 19:48:13.667814: val_loss -0.5417 
2025-08-28 19:48:13.675456: Pseudo dice [np.float32(0.7587)] 
2025-08-28 19:48:13.679996: Epoch time: 16.7 s 
2025-08-28 19:48:14.383712:  
2025-08-28 19:48:14.391891: Epoch 378 
2025-08-28 19:48:14.397232: Current learning rate: 0.00652 
2025-08-28 19:48:31.139827: train_loss -0.4578 
2025-08-28 19:48:31.148042: val_loss -0.5382 
2025-08-28 19:48:31.152045: Pseudo dice [np.float32(0.7485)] 
2025-08-28 19:48:31.158911: Epoch time: 16.76 s 
2025-08-28 19:48:31.863766:  
2025-08-28 19:48:31.871011: Epoch 379 
2025-08-28 19:48:31.878341: Current learning rate: 0.00651 
2025-08-28 19:48:48.027525: train_loss -0.4713 
2025-08-28 19:48:48.035516: val_loss -0.5552 
2025-08-28 19:48:48.044267: Pseudo dice [np.float32(0.7443)] 
2025-08-28 19:48:48.049997: Epoch time: 16.17 s 
2025-08-28 19:48:48.748217:  
2025-08-28 19:48:48.756549: Epoch 380 
2025-08-28 19:48:48.762855: Current learning rate: 0.0065 
2025-08-28 19:49:05.632473: train_loss -0.4293 
2025-08-28 19:49:05.640804: val_loss -0.4955 
2025-08-28 19:49:05.648968: Pseudo dice [np.float32(0.6742)] 
2025-08-28 19:49:05.654301: Epoch time: 16.89 s 
2025-08-28 19:49:06.392869:  
2025-08-28 19:49:06.410240: Epoch 381 
2025-08-28 19:49:06.417062: Current learning rate: 0.00649 
2025-08-28 19:49:22.920492: train_loss -0.495 
2025-08-28 19:49:22.928742: val_loss -0.5596 
2025-08-28 19:49:22.937061: Pseudo dice [np.float32(0.7277)] 
2025-08-28 19:49:22.942260: Epoch time: 16.53 s 
2025-08-28 19:49:23.667635:  
2025-08-28 19:49:23.677147: Epoch 382 
2025-08-28 19:49:23.683151: Current learning rate: 0.00648 
2025-08-28 19:49:39.974497: train_loss -0.5127 
2025-08-28 19:49:39.982832: val_loss -0.5316 
2025-08-28 19:49:39.987328: Pseudo dice [np.float32(0.7856)] 
2025-08-28 19:49:39.994934: Epoch time: 16.31 s 
2025-08-28 19:49:40.000191: Yayy! New best EMA pseudo Dice: 0.7232000231742859 
2025-08-28 19:49:40.909775:  
2025-08-28 19:49:40.916924: Epoch 383 
2025-08-28 19:49:40.924298: Current learning rate: 0.00648 
2025-08-28 19:49:56.816762: train_loss -0.5241 
2025-08-28 19:49:56.829151: val_loss -0.5203 
2025-08-28 19:49:56.833348: Pseudo dice [np.float32(0.739)] 
2025-08-28 19:49:56.839365: Epoch time: 15.91 s 
2025-08-28 19:49:56.843035: Yayy! New best EMA pseudo Dice: 0.7247999906539917 
2025-08-28 19:49:57.725350:  
2025-08-28 19:49:57.734440: Epoch 384 
2025-08-28 19:49:57.742190: Current learning rate: 0.00647 
2025-08-28 19:50:14.346890: train_loss -0.48 
2025-08-28 19:50:14.355179: val_loss -0.5113 
2025-08-28 19:50:14.359257: Pseudo dice [np.float32(0.7513)] 
2025-08-28 19:50:14.368043: Epoch time: 16.62 s 
2025-08-28 19:50:14.374064: Yayy! New best EMA pseudo Dice: 0.727400004863739 
2025-08-28 19:50:15.275222:  
2025-08-28 19:50:15.283563: Epoch 385 
2025-08-28 19:50:15.292049: Current learning rate: 0.00646 
2025-08-28 19:50:31.960381: train_loss -0.4591 
2025-08-28 19:50:31.968544: val_loss -0.528 
2025-08-28 19:50:31.977005: Pseudo dice [np.float32(0.6875)] 
2025-08-28 19:50:31.982081: Epoch time: 16.69 s 
2025-08-28 19:50:32.860635:  
2025-08-28 19:50:32.869630: Epoch 386 
2025-08-28 19:50:32.875426: Current learning rate: 0.00645 
2025-08-28 19:50:49.336739: train_loss -0.4788 
2025-08-28 19:50:49.344159: val_loss -0.471 
2025-08-28 19:50:49.348420: Pseudo dice [np.float32(0.6582)] 
2025-08-28 19:50:49.357206: Epoch time: 16.48 s 
2025-08-28 19:50:50.075670:  
2025-08-28 19:50:50.085006: Epoch 387 
2025-08-28 19:50:50.092050: Current learning rate: 0.00644 
2025-08-28 19:51:06.677834: train_loss -0.4828 
2025-08-28 19:51:06.686439: val_loss -0.5057 
2025-08-28 19:51:06.694829: Pseudo dice [np.float32(0.692)] 
2025-08-28 19:51:06.701656: Epoch time: 16.6 s 
2025-08-28 19:51:07.459649:  
2025-08-28 19:51:07.467610: Epoch 388 
2025-08-28 19:51:07.474243: Current learning rate: 0.00643 
2025-08-28 19:51:24.170648: train_loss -0.5163 
2025-08-28 19:51:24.181450: val_loss -0.4927 
2025-08-28 19:51:24.187235: Pseudo dice [np.float32(0.6798)] 
2025-08-28 19:51:24.193263: Epoch time: 16.71 s 
2025-08-28 19:51:24.909831:  
2025-08-28 19:51:24.917344: Epoch 389 
2025-08-28 19:51:24.921410: Current learning rate: 0.00642 
2025-08-28 19:51:41.746508: train_loss -0.5067 
2025-08-28 19:51:41.754320: val_loss -0.5792 
2025-08-28 19:51:41.759001: Pseudo dice [np.float32(0.7927)] 
2025-08-28 19:51:41.764902: Epoch time: 16.84 s 
2025-08-28 19:51:42.504114:  
2025-08-28 19:51:42.511367: Epoch 390 
2025-08-28 19:51:42.518365: Current learning rate: 0.00641 
2025-08-28 19:51:59.380804: train_loss -0.5123 
2025-08-28 19:51:59.389114: val_loss -0.536 
2025-08-28 19:51:59.397455: Pseudo dice [np.float32(0.7018)] 
2025-08-28 19:51:59.402659: Epoch time: 16.88 s 
2025-08-28 19:52:00.113249:  
2025-08-28 19:52:00.120606: Epoch 391 
2025-08-28 19:52:00.126738: Current learning rate: 0.0064 
2025-08-28 19:52:17.040697: train_loss -0.5061 
2025-08-28 19:52:17.047974: val_loss -0.5152 
2025-08-28 19:52:17.052128: Pseudo dice [np.float32(0.7171)] 
2025-08-28 19:52:17.061266: Epoch time: 16.93 s 
2025-08-28 19:52:17.937365:  
2025-08-28 19:52:17.945708: Epoch 392 
2025-08-28 19:52:17.955038: Current learning rate: 0.00639 
2025-08-28 19:52:34.592522: train_loss -0.4457 
2025-08-28 19:52:34.599295: val_loss -0.4821 
2025-08-28 19:52:34.604969: Pseudo dice [np.float32(0.7147)] 
2025-08-28 19:52:34.610567: Epoch time: 16.66 s 
2025-08-28 19:52:35.317236:  
2025-08-28 19:52:35.326840: Epoch 393 
2025-08-28 19:52:35.334884: Current learning rate: 0.00638 
2025-08-28 19:52:51.678857: train_loss -0.4763 
2025-08-28 19:52:51.687180: val_loss -0.4739 
2025-08-28 19:52:51.691318: Pseudo dice [np.float32(0.6877)] 
2025-08-28 19:52:51.697417: Epoch time: 16.36 s 
2025-08-28 19:52:52.407284:  
2025-08-28 19:52:52.418185: Epoch 394 
2025-08-28 19:52:52.424441: Current learning rate: 0.00637 
2025-08-28 19:53:09.325550: train_loss -0.4833 
2025-08-28 19:53:09.333917: val_loss -0.6051 
2025-08-28 19:53:09.341702: Pseudo dice [np.float32(0.73)] 
2025-08-28 19:53:09.346125: Epoch time: 16.92 s 
2025-08-28 19:53:10.062229:  
2025-08-28 19:53:10.071726: Epoch 395 
2025-08-28 19:53:10.081687: Current learning rate: 0.00636 
2025-08-28 19:53:26.297471: train_loss -0.4931 
2025-08-28 19:53:26.305267: val_loss -0.5239 
2025-08-28 19:53:26.312856: Pseudo dice [np.float32(0.7515)] 
2025-08-28 19:53:26.318958: Epoch time: 16.24 s 
2025-08-28 19:53:27.095731:  
2025-08-28 19:53:27.103734: Epoch 396 
2025-08-28 19:53:27.110095: Current learning rate: 0.00635 
2025-08-28 19:53:42.412338: train_loss -0.4893 
2025-08-28 19:53:42.421227: val_loss -0.5587 
2025-08-28 19:53:42.429386: Pseudo dice [np.float32(0.7609)] 
2025-08-28 19:53:42.434404: Epoch time: 15.32 s 
2025-08-28 19:53:43.096746:  
2025-08-28 19:53:43.105081: Epoch 397 
2025-08-28 19:53:43.109173: Current learning rate: 0.00634 
2025-08-28 19:53:58.620560: train_loss -0.5052 
2025-08-28 19:53:58.628928: val_loss -0.5185 
2025-08-28 19:53:58.637284: Pseudo dice [np.float32(0.7205)] 
2025-08-28 19:53:58.643064: Epoch time: 15.52 s 
2025-08-28 19:53:59.310393:  
2025-08-28 19:53:59.317881: Epoch 398 
2025-08-28 19:53:59.323947: Current learning rate: 0.00633 
2025-08-28 19:54:15.067783: train_loss -0.4794 
2025-08-28 19:54:15.074563: val_loss -0.5782 
2025-08-28 19:54:15.082471: Pseudo dice [np.float32(0.7849)] 
2025-08-28 19:54:15.087521: Epoch time: 15.76 s 
2025-08-28 19:54:15.092781: Yayy! New best EMA pseudo Dice: 0.7293999791145325 
2025-08-28 19:54:16.106377:  
2025-08-28 19:54:16.115695: Epoch 399 
2025-08-28 19:54:16.119858: Current learning rate: 0.00632 
2025-08-28 19:54:31.478204: train_loss -0.4659 
2025-08-28 19:54:31.486389: val_loss -0.5098 
2025-08-28 19:54:31.490541: Pseudo dice [np.float32(0.6479)] 
2025-08-28 19:54:31.498808: Epoch time: 15.37 s 
2025-08-28 19:54:32.348633:  
2025-08-28 19:54:32.359206: Epoch 400 
2025-08-28 19:54:32.366616: Current learning rate: 0.00631 
2025-08-28 19:54:47.277115: train_loss -0.5006 
2025-08-28 19:54:47.285466: val_loss -0.5435 
2025-08-28 19:54:47.289662: Pseudo dice [np.float32(0.7178)] 
2025-08-28 19:54:47.298054: Epoch time: 14.93 s 
2025-08-28 19:54:47.960035:  
2025-08-28 19:54:47.968370: Epoch 401 
2025-08-28 19:54:47.973504: Current learning rate: 0.0063 
2025-08-28 19:55:02.538422: train_loss -0.4634 
2025-08-28 19:55:02.550724: val_loss -0.5468 
2025-08-28 19:55:02.554913: Pseudo dice [np.float32(0.727)] 
2025-08-28 19:55:02.560126: Epoch time: 14.58 s 
2025-08-28 19:55:03.221078:  
2025-08-28 19:55:03.228484: Epoch 402 
2025-08-28 19:55:03.233554: Current learning rate: 0.0063 
2025-08-28 19:55:18.779614: train_loss -0.4436 
2025-08-28 19:55:18.787745: val_loss -0.467 
2025-08-28 19:55:18.791918: Pseudo dice [np.float32(0.636)] 
2025-08-28 19:55:18.799849: Epoch time: 15.56 s 
2025-08-28 19:55:19.453987:  
2025-08-28 19:55:19.463290: Epoch 403 
2025-08-28 19:55:19.468590: Current learning rate: 0.00629 
2025-08-28 19:55:33.723486: train_loss -0.4924 
2025-08-28 19:55:33.731838: val_loss -0.5713 
2025-08-28 19:55:33.740181: Pseudo dice [np.float32(0.7468)] 
2025-08-28 19:55:33.746084: Epoch time: 14.27 s 
2025-08-28 19:55:34.549162:  
2025-08-28 19:55:34.557551: Epoch 404 
2025-08-28 19:55:34.562828: Current learning rate: 0.00628 
2025-08-28 19:55:49.072137: train_loss -0.5004 
2025-08-28 19:55:49.080492: val_loss -0.5069 
2025-08-28 19:55:49.085383: Pseudo dice [np.float32(0.6958)] 
2025-08-28 19:55:49.091736: Epoch time: 14.52 s 
2025-08-28 19:55:49.749901:  
2025-08-28 19:55:49.759289: Epoch 405 
2025-08-28 19:55:49.764345: Current learning rate: 0.00627 
2025-08-28 19:56:05.067271: train_loss -0.4724 
2025-08-28 19:56:05.075680: val_loss -0.5294 
2025-08-28 19:56:05.083971: Pseudo dice [np.float32(0.7824)] 
2025-08-28 19:56:05.088936: Epoch time: 15.32 s 
2025-08-28 19:56:05.761633:  
2025-08-28 19:56:05.770068: Epoch 406 
2025-08-28 19:56:05.776265: Current learning rate: 0.00626 
2025-08-28 19:56:20.495511: train_loss -0.4797 
2025-08-28 19:56:20.503528: val_loss -0.526 
2025-08-28 19:56:20.508030: Pseudo dice [np.float32(0.7583)] 
2025-08-28 19:56:20.514797: Epoch time: 14.74 s 
2025-08-28 19:56:21.173950:  
2025-08-28 19:56:21.181283: Epoch 407 
2025-08-28 19:56:21.187385: Current learning rate: 0.00625 
2025-08-28 19:56:36.381955: train_loss -0.5101 
2025-08-28 19:56:36.390230: val_loss -0.5535 
2025-08-28 19:56:36.394460: Pseudo dice [np.float32(0.7246)] 
2025-08-28 19:56:36.402647: Epoch time: 15.21 s 
2025-08-28 19:56:37.067013:  
2025-08-28 19:56:37.075334: Epoch 408 
2025-08-28 19:56:37.081427: Current learning rate: 0.00624 
2025-08-28 19:56:52.323030: train_loss -0.4769 
2025-08-28 19:56:52.331149: val_loss -0.5985 
2025-08-28 19:56:52.335305: Pseudo dice [np.float32(0.7956)] 
2025-08-28 19:56:52.342515: Epoch time: 15.26 s 
2025-08-28 19:56:52.348263: Yayy! New best EMA pseudo Dice: 0.7318999767303467 
2025-08-28 19:56:53.175659:  
2025-08-28 19:56:53.183054: Epoch 409 
2025-08-28 19:56:53.189249: Current learning rate: 0.00623 
2025-08-28 19:57:08.288728: train_loss -0.5015 
2025-08-28 19:57:08.297386: val_loss -0.4796 
2025-08-28 19:57:08.305431: Pseudo dice [np.float32(0.7335)] 
2025-08-28 19:57:08.310929: Epoch time: 15.12 s 
2025-08-28 19:57:08.314651: Yayy! New best EMA pseudo Dice: 0.7319999933242798 
2025-08-28 19:57:09.341803:  
2025-08-28 19:57:09.351107: Epoch 410 
2025-08-28 19:57:09.356311: Current learning rate: 0.00622 
2025-08-28 19:57:23.800421: train_loss -0.4647 
2025-08-28 19:57:23.808411: val_loss -0.5031 
2025-08-28 19:57:23.812566: Pseudo dice [np.float32(0.7146)] 
2025-08-28 19:57:23.819590: Epoch time: 14.46 s 
2025-08-28 19:57:24.457913:  
2025-08-28 19:57:24.466289: Epoch 411 
2025-08-28 19:57:24.471387: Current learning rate: 0.00621 
2025-08-28 19:57:39.415985: train_loss -0.483 
2025-08-28 19:57:39.423987: val_loss -0.4897 
2025-08-28 19:57:39.428475: Pseudo dice [np.float32(0.6817)] 
2025-08-28 19:57:39.437194: Epoch time: 14.96 s 
2025-08-28 19:57:40.085976:  
2025-08-28 19:57:40.093332: Epoch 412 
2025-08-28 19:57:40.098477: Current learning rate: 0.0062 
2025-08-28 19:57:54.943655: train_loss -0.4638 
2025-08-28 19:57:54.952204: val_loss -0.471 
2025-08-28 19:57:54.956196: Pseudo dice [np.float32(0.6357)] 
2025-08-28 19:57:54.963192: Epoch time: 14.86 s 
2025-08-28 19:57:55.603672:  
2025-08-28 19:57:55.612992: Epoch 413 
2025-08-28 19:57:55.618172: Current learning rate: 0.00619 
2025-08-28 19:58:10.380257: train_loss -0.4958 
2025-08-28 19:58:10.388234: val_loss -0.5409 
2025-08-28 19:58:10.392400: Pseudo dice [np.float32(0.7763)] 
2025-08-28 19:58:10.402075: Epoch time: 14.78 s 
2025-08-28 19:58:11.049258:  
2025-08-28 19:58:11.057559: Epoch 414 
2025-08-28 19:58:11.063793: Current learning rate: 0.00618 
2025-08-28 19:58:26.637801: train_loss -0.5115 
2025-08-28 19:58:26.646143: val_loss -0.5115 
2025-08-28 19:58:26.650312: Pseudo dice [np.float32(0.7104)] 
2025-08-28 19:58:26.656540: Epoch time: 15.59 s 
2025-08-28 19:58:27.345344:  
2025-08-28 19:58:27.354070: Epoch 415 
2025-08-28 19:58:27.359168: Current learning rate: 0.00617 
2025-08-28 19:58:43.955105: train_loss -0.4831 
2025-08-28 19:58:43.963442: val_loss -0.4691 
2025-08-28 19:58:43.967974: Pseudo dice [np.float32(0.7062)] 
2025-08-28 19:58:43.973843: Epoch time: 16.61 s 
2025-08-28 19:58:44.665224:  
2025-08-28 19:58:44.673533: Epoch 416 
2025-08-28 19:58:44.680529: Current learning rate: 0.00616 
2025-08-28 19:59:01.526814: train_loss -0.5025 
2025-08-28 19:59:01.539237: val_loss -0.5491 
2025-08-28 19:59:01.543521: Pseudo dice [np.float32(0.7777)] 
2025-08-28 19:59:01.548515: Epoch time: 16.86 s 
2025-08-28 19:59:02.415074:  
2025-08-28 19:59:02.422859: Epoch 417 
2025-08-28 19:59:02.428721: Current learning rate: 0.00615 
2025-08-28 19:59:19.098496: train_loss -0.4901 
2025-08-28 19:59:19.107175: val_loss -0.4874 
2025-08-28 19:59:19.115192: Pseudo dice [np.float32(0.6692)] 
2025-08-28 19:59:19.120713: Epoch time: 16.69 s 
2025-08-28 19:59:19.804203:  
2025-08-28 19:59:19.814794: Epoch 418 
2025-08-28 19:59:19.824232: Current learning rate: 0.00614 
2025-08-28 19:59:36.361608: train_loss -0.469 
2025-08-28 19:59:36.370452: val_loss -0.4668 
2025-08-28 19:59:36.374091: Pseudo dice [np.float32(0.6803)] 
2025-08-28 19:59:36.383569: Epoch time: 16.56 s 
2025-08-28 19:59:37.099654:  
2025-08-28 19:59:37.108057: Epoch 419 
2025-08-28 19:59:37.116576: Current learning rate: 0.00613 
2025-08-28 19:59:53.970828: train_loss -0.5 
2025-08-28 19:59:53.979162: val_loss -0.467 
2025-08-28 19:59:53.983596: Pseudo dice [np.float32(0.7363)] 
2025-08-28 19:59:53.992510: Epoch time: 16.87 s 
2025-08-28 19:59:54.688134:  
2025-08-28 19:59:54.700668: Epoch 420 
2025-08-28 19:59:54.709585: Current learning rate: 0.00612 
2025-08-28 20:00:11.451090: train_loss -0.5016 
2025-08-28 20:00:11.459139: val_loss -0.5188 
2025-08-28 20:00:11.463603: Pseudo dice [np.float32(0.7536)] 
2025-08-28 20:00:11.469409: Epoch time: 16.76 s 
2025-08-28 20:00:12.180642:  
2025-08-28 20:00:12.189273: Epoch 421 
2025-08-28 20:00:12.198164: Current learning rate: 0.00612 
2025-08-28 20:00:28.718056: train_loss -0.4732 
2025-08-28 20:00:28.726358: val_loss -0.5265 
2025-08-28 20:00:28.730771: Pseudo dice [np.float32(0.6669)] 
2025-08-28 20:00:28.738666: Epoch time: 16.54 s 
2025-08-28 20:00:29.448557:  
2025-08-28 20:00:29.456151: Epoch 422 
2025-08-28 20:00:29.463634: Current learning rate: 0.00611 
2025-08-28 20:00:45.785032: train_loss -0.5153 
2025-08-28 20:00:45.789433: val_loss -0.4912 
2025-08-28 20:00:45.797570: Pseudo dice [np.float32(0.7723)] 
2025-08-28 20:00:45.803033: Epoch time: 16.34 s 
2025-08-28 20:00:46.497201:  
2025-08-28 20:00:46.505280: Epoch 423 
2025-08-28 20:00:46.510610: Current learning rate: 0.0061 
2025-08-28 20:01:03.319307: train_loss -0.4721 
2025-08-28 20:01:03.331748: val_loss -0.5197 
2025-08-28 20:01:03.335951: Pseudo dice [np.float32(0.7438)] 
2025-08-28 20:01:03.343328: Epoch time: 16.82 s 
2025-08-28 20:01:04.194944:  
2025-08-28 20:01:04.203389: Epoch 424 
2025-08-28 20:01:04.211956: Current learning rate: 0.00609 
2025-08-28 20:01:21.020559: train_loss -0.4441 
2025-08-28 20:01:21.028636: val_loss -0.4706 
2025-08-28 20:01:21.032744: Pseudo dice [np.float32(0.7459)] 
2025-08-28 20:01:21.039882: Epoch time: 16.83 s 
2025-08-28 20:01:21.756314:  
2025-08-28 20:01:21.767982: Epoch 425 
2025-08-28 20:01:21.778141: Current learning rate: 0.00608 
2025-08-28 20:01:38.646184: train_loss -0.48 
2025-08-28 20:01:38.654494: val_loss -0.4612 
2025-08-28 20:01:38.662383: Pseudo dice [np.float32(0.7713)] 
2025-08-28 20:01:38.667915: Epoch time: 16.89 s 
2025-08-28 20:01:39.386459:  
2025-08-28 20:01:39.396692: Epoch 426 
2025-08-28 20:01:39.406862: Current learning rate: 0.00607 
2025-08-28 20:01:55.892541: train_loss -0.5055 
2025-08-28 20:01:55.905058: val_loss -0.465 
2025-08-28 20:01:55.909256: Pseudo dice [np.float32(0.6605)] 
2025-08-28 20:01:55.916766: Epoch time: 16.51 s 
2025-08-28 20:01:56.608291:  
2025-08-28 20:01:56.616259: Epoch 427 
2025-08-28 20:01:56.622370: Current learning rate: 0.00606 
2025-08-28 20:02:13.622732: train_loss -0.4068 
2025-08-28 20:02:13.631107: val_loss -0.4167 
2025-08-28 20:02:13.635258: Pseudo dice [np.float32(0.5979)] 
2025-08-28 20:02:13.643421: Epoch time: 17.02 s 
2025-08-28 20:02:14.328670:  
2025-08-28 20:02:14.337795: Epoch 428 
2025-08-28 20:02:14.346364: Current learning rate: 0.00605 
2025-08-28 20:02:31.236167: train_loss -0.4777 
2025-08-28 20:02:31.244517: val_loss -0.4866 
2025-08-28 20:02:31.252894: Pseudo dice [np.float32(0.7001)] 
2025-08-28 20:02:31.257825: Epoch time: 16.91 s 
2025-08-28 20:02:31.942034:  
2025-08-28 20:02:31.950497: Epoch 429 
2025-08-28 20:02:31.957619: Current learning rate: 0.00604 
2025-08-28 20:02:48.820446: train_loss -0.4975 
2025-08-28 20:02:48.828745: val_loss -0.4677 
2025-08-28 20:02:48.832902: Pseudo dice [np.float32(0.6681)] 
2025-08-28 20:02:48.842051: Epoch time: 16.88 s 
2025-08-28 20:02:49.538791:  
2025-08-28 20:02:49.547166: Epoch 430 
2025-08-28 20:02:49.553162: Current learning rate: 0.00603 
2025-08-28 20:03:06.116854: train_loss -0.5086 
2025-08-28 20:03:06.129383: val_loss -0.6393 
2025-08-28 20:03:06.133553: Pseudo dice [np.float32(0.8008)] 
2025-08-28 20:03:06.139490: Epoch time: 16.58 s 
2025-08-28 20:03:06.987365:  
2025-08-28 20:03:06.995825: Epoch 431 
2025-08-28 20:03:07.003758: Current learning rate: 0.00602 
2025-08-28 20:03:23.922181: train_loss -0.5086 
2025-08-28 20:03:23.930466: val_loss -0.4821 
2025-08-28 20:03:23.934609: Pseudo dice [np.float32(0.675)] 
2025-08-28 20:03:23.942838: Epoch time: 16.94 s 
2025-08-28 20:03:24.629079:  
2025-08-28 20:03:24.636319: Epoch 432 
2025-08-28 20:03:24.641584: Current learning rate: 0.00601 
2025-08-28 20:03:41.152139: train_loss -0.4889 
2025-08-28 20:03:41.160190: val_loss -0.5895 
2025-08-28 20:03:41.164320: Pseudo dice [np.float32(0.7067)] 
2025-08-28 20:03:41.170712: Epoch time: 16.52 s 
2025-08-28 20:03:41.850389:  
2025-08-28 20:03:41.858803: Epoch 433 
2025-08-28 20:03:41.863867: Current learning rate: 0.006 
2025-08-28 20:03:58.569521: train_loss -0.4621 
2025-08-28 20:03:58.582065: val_loss -0.4884 
2025-08-28 20:03:58.585875: Pseudo dice [np.float32(0.701)] 
2025-08-28 20:03:58.591992: Epoch time: 16.72 s 
2025-08-28 20:03:59.275192:  
2025-08-28 20:03:59.283499: Epoch 434 
2025-08-28 20:03:59.288572: Current learning rate: 0.00599 
2025-08-28 20:04:15.965749: train_loss -0.4906 
2025-08-28 20:04:15.974086: val_loss -0.5228 
2025-08-28 20:04:15.982441: Pseudo dice [np.float32(0.6863)] 
2025-08-28 20:04:15.988015: Epoch time: 16.69 s 
2025-08-28 20:04:16.701828:  
2025-08-28 20:04:16.711827: Epoch 435 
2025-08-28 20:04:16.718551: Current learning rate: 0.00598 
2025-08-28 20:04:33.587498: train_loss -0.5144 
2025-08-28 20:04:33.595848: val_loss -0.5206 
2025-08-28 20:04:33.600311: Pseudo dice [np.float32(0.699)] 
2025-08-28 20:04:33.607118: Epoch time: 16.89 s 
2025-08-28 20:04:34.323678:  
2025-08-28 20:04:34.332678: Epoch 436 
2025-08-28 20:04:34.340306: Current learning rate: 0.00597 
2025-08-28 20:04:51.025733: train_loss -0.5124 
2025-08-28 20:04:51.034107: val_loss -0.5421 
2025-08-28 20:04:51.042442: Pseudo dice [np.float32(0.7538)] 
2025-08-28 20:04:51.047439: Epoch time: 16.7 s 
2025-08-28 20:04:51.882774:  
2025-08-28 20:04:51.890221: Epoch 437 
2025-08-28 20:04:51.895314: Current learning rate: 0.00596 
2025-08-28 20:05:08.599941: train_loss -0.5098 
2025-08-28 20:05:08.605796: val_loss -0.5224 
2025-08-28 20:05:08.614137: Pseudo dice [np.float32(0.716)] 
2025-08-28 20:05:08.620503: Epoch time: 16.72 s 
2025-08-28 20:05:09.308612:  
2025-08-28 20:05:09.315882: Epoch 438 
2025-08-28 20:05:09.321059: Current learning rate: 0.00595 
2025-08-28 20:05:26.123384: train_loss -0.5065 
2025-08-28 20:05:26.131649: val_loss -0.5028 
2025-08-28 20:05:26.135822: Pseudo dice [np.float32(0.6453)] 
2025-08-28 20:05:26.142011: Epoch time: 16.82 s 
2025-08-28 20:05:26.862555:  
2025-08-28 20:05:26.870552: Epoch 439 
2025-08-28 20:05:26.877087: Current learning rate: 0.00594 
2025-08-28 20:05:43.324358: train_loss -0.4932 
2025-08-28 20:05:43.332425: val_loss -0.5509 
2025-08-28 20:05:43.340861: Pseudo dice [np.float32(0.7518)] 
2025-08-28 20:05:43.346030: Epoch time: 16.46 s 
2025-08-28 20:05:44.028499:  
2025-08-28 20:05:44.036845: Epoch 440 
2025-08-28 20:05:44.042269: Current learning rate: 0.00593 
2025-08-28 20:06:00.595949: train_loss -0.512 
2025-08-28 20:06:00.603869: val_loss -0.5748 
2025-08-28 20:06:00.607781: Pseudo dice [np.float32(0.7511)] 
2025-08-28 20:06:00.617041: Epoch time: 16.57 s 
2025-08-28 20:06:01.314945:  
2025-08-28 20:06:01.322802: Epoch 441 
2025-08-28 20:06:01.328175: Current learning rate: 0.00592 
2025-08-28 20:06:17.870803: train_loss -0.4582 
2025-08-28 20:06:17.879146: val_loss -0.5139 
2025-08-28 20:06:17.883355: Pseudo dice [np.float32(0.7551)] 
2025-08-28 20:06:17.890727: Epoch time: 16.56 s 
2025-08-28 20:06:18.597095:  
2025-08-28 20:06:18.605918: Epoch 442 
2025-08-28 20:06:18.613917: Current learning rate: 0.00592 
2025-08-28 20:06:35.271499: train_loss -0.4895 
2025-08-28 20:06:35.279839: val_loss -0.4222 
2025-08-28 20:06:35.284019: Pseudo dice [np.float32(0.6283)] 
2025-08-28 20:06:35.293135: Epoch time: 16.68 s 
2025-08-28 20:06:35.992970:  
2025-08-28 20:06:36.001257: Epoch 443 
2025-08-28 20:06:36.006634: Current learning rate: 0.00591 
2025-08-28 20:06:52.630794: train_loss -0.4537 
2025-08-28 20:06:52.639111: val_loss -0.4761 
2025-08-28 20:06:52.643066: Pseudo dice [np.float32(0.7328)] 
2025-08-28 20:06:52.651161: Epoch time: 16.64 s 
2025-08-28 20:06:53.505269:  
2025-08-28 20:06:53.512676: Epoch 444 
2025-08-28 20:06:53.517799: Current learning rate: 0.0059 
2025-08-28 20:07:10.077096: train_loss -0.5078 
2025-08-28 20:07:10.089585: val_loss -0.53 
2025-08-28 20:07:10.093757: Pseudo dice [np.float32(0.689)] 
2025-08-28 20:07:10.100025: Epoch time: 16.57 s 
2025-08-28 20:07:10.773449:  
2025-08-28 20:07:10.780791: Epoch 445 
2025-08-28 20:07:10.787150: Current learning rate: 0.00589 
2025-08-28 20:07:27.498669: train_loss -0.4974 
2025-08-28 20:07:27.507000: val_loss -0.5229 
2025-08-28 20:07:27.511560: Pseudo dice [np.float32(0.7241)] 
2025-08-28 20:07:27.517558: Epoch time: 16.73 s 
2025-08-28 20:07:28.223215:  
2025-08-28 20:07:28.230562: Epoch 446 
2025-08-28 20:07:28.236796: Current learning rate: 0.00588 
2025-08-28 20:07:44.978795: train_loss -0.4861 
2025-08-28 20:07:44.986967: val_loss -0.6199 
2025-08-28 20:07:44.991508: Pseudo dice [np.float32(0.755)] 
2025-08-28 20:07:44.999405: Epoch time: 16.76 s 
2025-08-28 20:07:45.726269:  
2025-08-28 20:07:45.734593: Epoch 447 
2025-08-28 20:07:45.742995: Current learning rate: 0.00587 
2025-08-28 20:08:02.521125: train_loss -0.4807 
2025-08-28 20:08:02.529463: val_loss -0.5656 
2025-08-28 20:08:02.537801: Pseudo dice [np.float32(0.7707)] 
2025-08-28 20:08:02.543177: Epoch time: 16.8 s 
2025-08-28 20:08:03.231281:  
2025-08-28 20:08:03.239496: Epoch 448 
2025-08-28 20:08:03.246909: Current learning rate: 0.00586 
2025-08-28 20:08:20.243287: train_loss -0.5088 
2025-08-28 20:08:20.251367: val_loss -0.5165 
2025-08-28 20:08:20.259688: Pseudo dice [np.float32(0.748)] 
2025-08-28 20:08:20.264609: Epoch time: 17.01 s 
2025-08-28 20:08:20.976926:  
2025-08-28 20:08:20.984315: Epoch 449 
2025-08-28 20:08:20.989477: Current learning rate: 0.00585 
2025-08-28 20:08:37.656249: train_loss -0.4826 
2025-08-28 20:08:37.664551: val_loss -0.554 
2025-08-28 20:08:37.672936: Pseudo dice [np.float32(0.706)] 
2025-08-28 20:08:37.678143: Epoch time: 16.68 s 
2025-08-28 20:08:38.624842:  
2025-08-28 20:08:38.632108: Epoch 450 
2025-08-28 20:08:38.638356: Current learning rate: 0.00584 
2025-08-28 20:08:55.153284: train_loss -0.4684 
2025-08-28 20:08:55.161212: val_loss -0.553 
2025-08-28 20:08:55.165357: Pseudo dice [np.float32(0.7747)] 
2025-08-28 20:08:55.174651: Epoch time: 16.53 s 
2025-08-28 20:08:56.014054:  
2025-08-28 20:08:56.022495: Epoch 451 
2025-08-28 20:08:56.027579: Current learning rate: 0.00583 
2025-08-28 20:09:12.582812: train_loss -0.4282 
2025-08-28 20:09:12.590954: val_loss -0.5709 
2025-08-28 20:09:12.595628: Pseudo dice [np.float32(0.7386)] 
2025-08-28 20:09:12.601763: Epoch time: 16.57 s 
2025-08-28 20:09:13.297034:  
2025-08-28 20:09:13.304155: Epoch 452 
2025-08-28 20:09:13.309555: Current learning rate: 0.00582 
2025-08-28 20:09:29.695738: train_loss -0.4729 
2025-08-28 20:09:29.704001: val_loss -0.5425 
2025-08-28 20:09:29.708424: Pseudo dice [np.float32(0.7483)] 
2025-08-28 20:09:29.717509: Epoch time: 16.4 s 
2025-08-28 20:09:30.398406:  
2025-08-28 20:09:30.406413: Epoch 453 
2025-08-28 20:09:30.412932: Current learning rate: 0.00581 
2025-08-28 20:09:46.971276: train_loss -0.4374 
2025-08-28 20:09:46.979881: val_loss -0.481 
2025-08-28 20:09:46.987981: Pseudo dice [np.float32(0.6703)] 
2025-08-28 20:09:46.994493: Epoch time: 16.57 s 
2025-08-28 20:09:47.689716:  
2025-08-28 20:09:47.698056: Epoch 454 
2025-08-28 20:09:47.703223: Current learning rate: 0.0058 
2025-08-28 20:10:03.124409: train_loss -0.4821 
2025-08-28 20:10:03.133257: val_loss -0.5027 
2025-08-28 20:10:03.137424: Pseudo dice [np.float32(0.7167)] 
2025-08-28 20:10:03.145342: Epoch time: 15.43 s 
2025-08-28 20:10:03.785985:  
2025-08-28 20:10:03.794273: Epoch 455 
2025-08-28 20:10:03.801944: Current learning rate: 0.00579 
2025-08-28 20:10:18.786592: train_loss -0.4738 
2025-08-28 20:10:18.794758: val_loss -0.5279 
2025-08-28 20:10:18.803087: Pseudo dice [np.float32(0.7157)] 
2025-08-28 20:10:18.808308: Epoch time: 15.0 s 
2025-08-28 20:10:19.436907:  
2025-08-28 20:10:19.444219: Epoch 456 
2025-08-28 20:10:19.449342: Current learning rate: 0.00578 
2025-08-28 20:10:34.356078: train_loss -0.4754 
2025-08-28 20:10:34.364417: val_loss -0.5488 
2025-08-28 20:10:34.368574: Pseudo dice [np.float32(0.7465)] 
2025-08-28 20:10:34.373899: Epoch time: 14.92 s 
2025-08-28 20:10:35.150583:  
2025-08-28 20:10:35.157901: Epoch 457 
2025-08-28 20:10:35.163071: Current learning rate: 0.00577 
2025-08-28 20:10:50.013439: train_loss -0.4887 
2025-08-28 20:10:50.021779: val_loss -0.6093 
2025-08-28 20:10:50.026150: Pseudo dice [np.float32(0.7861)] 
2025-08-28 20:10:50.033025: Epoch time: 14.86 s 
2025-08-28 20:10:50.662872:  
2025-08-28 20:10:50.672208: Epoch 458 
2025-08-28 20:10:50.680648: Current learning rate: 0.00576 
2025-08-28 20:11:05.758245: train_loss -0.5069 
2025-08-28 20:11:05.766838: val_loss -0.4171 
2025-08-28 20:11:05.770774: Pseudo dice [np.float32(0.66)] 
2025-08-28 20:11:05.780411: Epoch time: 15.1 s 
2025-08-28 20:11:06.409904:  
2025-08-28 20:11:06.418341: Epoch 459 
2025-08-28 20:11:06.425602: Current learning rate: 0.00575 
2025-08-28 20:11:21.244861: train_loss -0.4845 
2025-08-28 20:11:21.252923: val_loss -0.5053 
2025-08-28 20:11:21.257090: Pseudo dice [np.float32(0.7507)] 
2025-08-28 20:11:21.265055: Epoch time: 14.84 s 
2025-08-28 20:11:21.898297:  
2025-08-28 20:11:21.906556: Epoch 460 
2025-08-28 20:11:21.914973: Current learning rate: 0.00574 
2025-08-28 20:11:36.593253: train_loss -0.497 
2025-08-28 20:11:36.601568: val_loss -0.4525 
2025-08-28 20:11:36.605980: Pseudo dice [np.float32(0.6165)] 
2025-08-28 20:11:36.614518: Epoch time: 14.7 s 
2025-08-28 20:11:37.256309:  
2025-08-28 20:11:37.264637: Epoch 461 
2025-08-28 20:11:37.272388: Current learning rate: 0.00573 
2025-08-28 20:11:51.992032: train_loss -0.5042 
2025-08-28 20:11:52.000259: val_loss -0.5561 
2025-08-28 20:11:52.004426: Pseudo dice [np.float32(0.7806)] 
2025-08-28 20:11:52.013392: Epoch time: 14.74 s 
2025-08-28 20:11:52.646583:  
2025-08-28 20:11:52.654933: Epoch 462 
2025-08-28 20:11:52.661272: Current learning rate: 0.00572 
2025-08-28 20:12:07.849658: train_loss -0.5232 
2025-08-28 20:12:07.861941: val_loss -0.5605 
2025-08-28 20:12:07.866374: Pseudo dice [np.float32(0.7396)] 
2025-08-28 20:12:07.872190: Epoch time: 15.2 s 
2025-08-28 20:12:08.508244:  
2025-08-28 20:12:08.516665: Epoch 463 
2025-08-28 20:12:08.522957: Current learning rate: 0.00571 
2025-08-28 20:12:23.352568: train_loss -0.5153 
2025-08-28 20:12:23.361201: val_loss -0.566 
2025-08-28 20:12:23.369077: Pseudo dice [np.float32(0.7666)] 
2025-08-28 20:12:23.375708: Epoch time: 14.85 s 
2025-08-28 20:12:24.160533:  
2025-08-28 20:12:24.168747: Epoch 464 
2025-08-28 20:12:24.173953: Current learning rate: 0.0057 
2025-08-28 20:12:39.205754: train_loss -0.5085 
2025-08-28 20:12:39.214082: val_loss -0.5544 
2025-08-28 20:12:39.218805: Pseudo dice [np.float32(0.7957)] 
2025-08-28 20:12:39.225377: Epoch time: 15.05 s 
2025-08-28 20:12:39.230524: Yayy! New best EMA pseudo Dice: 0.7348999977111816 
2025-08-28 20:12:40.046148:  
2025-08-28 20:12:40.055429: Epoch 465 
2025-08-28 20:12:40.062758: Current learning rate: 0.0057 
2025-08-28 20:12:54.996557: train_loss -0.4831 
2025-08-28 20:12:55.007333: val_loss -0.4977 
2025-08-28 20:12:55.009023: Pseudo dice [np.float32(0.5739)] 
2025-08-28 20:12:55.018099: Epoch time: 14.95 s 
2025-08-28 20:12:55.652426:  
2025-08-28 20:12:55.660721: Epoch 466 
2025-08-28 20:12:55.669014: Current learning rate: 0.00569 
2025-08-28 20:13:10.432810: train_loss -0.5349 
2025-08-28 20:13:10.441089: val_loss -0.489 
2025-08-28 20:13:10.445307: Pseudo dice [np.float32(0.7397)] 
2025-08-28 20:13:10.451248: Epoch time: 14.78 s 
2025-08-28 20:13:11.101119:  
2025-08-28 20:13:11.110429: Epoch 467 
2025-08-28 20:13:11.115587: Current learning rate: 0.00568 
2025-08-28 20:13:25.798391: train_loss -0.4895 
2025-08-28 20:13:25.806438: val_loss -0.559 
2025-08-28 20:13:25.810599: Pseudo dice [np.float32(0.7746)] 
2025-08-28 20:13:25.820234: Epoch time: 14.7 s 
2025-08-28 20:13:26.448574:  
2025-08-28 20:13:26.458115: Epoch 468 
2025-08-28 20:13:26.464344: Current learning rate: 0.00567 
2025-08-28 20:13:41.438904: train_loss -0.528 
2025-08-28 20:13:41.447041: val_loss -0.5608 
2025-08-28 20:13:41.451220: Pseudo dice [np.float32(0.7391)] 
2025-08-28 20:13:41.458241: Epoch time: 14.99 s 
2025-08-28 20:13:42.099698:  
2025-08-28 20:13:42.108203: Epoch 469 
2025-08-28 20:13:42.115439: Current learning rate: 0.00566 
2025-08-28 20:13:57.200347: train_loss -0.5391 
2025-08-28 20:13:57.208884: val_loss -0.565 
2025-08-28 20:13:57.217275: Pseudo dice [np.float32(0.7662)] 
2025-08-28 20:13:57.222332: Epoch time: 15.1 s 
2025-08-28 20:13:57.872638:  
2025-08-28 20:13:57.884140: Epoch 470 
2025-08-28 20:13:57.889475: Current learning rate: 0.00565 
2025-08-28 20:14:14.461639: train_loss -0.555 
2025-08-28 20:14:14.467888: val_loss -0.5569 
2025-08-28 20:14:14.475881: Pseudo dice [np.float32(0.7807)] 
2025-08-28 20:14:14.483201: Epoch time: 16.59 s 
2025-08-28 20:14:14.489825: Yayy! New best EMA pseudo Dice: 0.7364000082015991 
2025-08-28 20:14:15.504911:  
2025-08-28 20:14:15.512347: Epoch 471 
2025-08-28 20:14:15.517427: Current learning rate: 0.00564 
2025-08-28 20:14:32.164682: train_loss -0.5169 
2025-08-28 20:14:32.173039: val_loss -0.5345 
2025-08-28 20:14:32.181056: Pseudo dice [np.float32(0.7212)] 
2025-08-28 20:14:32.187418: Epoch time: 16.66 s 
2025-08-28 20:14:32.866176:  
2025-08-28 20:14:32.873277: Epoch 472 
2025-08-28 20:14:32.878623: Current learning rate: 0.00563 
2025-08-28 20:14:49.223511: train_loss -0.5183 
2025-08-28 20:14:49.231448: val_loss -0.4365 
2025-08-28 20:14:49.236178: Pseudo dice [np.float32(0.6961)] 
2025-08-28 20:14:49.241854: Epoch time: 16.36 s 
2025-08-28 20:14:49.904022:  
2025-08-28 20:14:49.913359: Epoch 473 
2025-08-28 20:14:49.919458: Current learning rate: 0.00562 
2025-08-28 20:15:06.940752: train_loss -0.5284 
2025-08-28 20:15:06.949513: val_loss -0.5459 
2025-08-28 20:15:06.957724: Pseudo dice [np.float32(0.7003)] 
2025-08-28 20:15:06.962424: Epoch time: 17.04 s 
2025-08-28 20:15:07.649659:  
2025-08-28 20:15:07.657005: Epoch 474 
2025-08-28 20:15:07.662172: Current learning rate: 0.00561 
2025-08-28 20:15:24.233211: train_loss -0.5193 
2025-08-28 20:15:24.241367: val_loss -0.4815 
2025-08-28 20:15:24.245513: Pseudo dice [np.float32(0.7265)] 
2025-08-28 20:15:24.254183: Epoch time: 16.59 s 
2025-08-28 20:15:24.959899:  
2025-08-28 20:15:24.968120: Epoch 475 
2025-08-28 20:15:24.974119: Current learning rate: 0.0056 
2025-08-28 20:15:41.708780: train_loss -0.5523 
2025-08-28 20:15:41.712989: val_loss -0.514 
2025-08-28 20:15:41.721646: Pseudo dice [np.float32(0.7848)] 
2025-08-28 20:15:41.726711: Epoch time: 16.75 s 
2025-08-28 20:15:42.421865:  
2025-08-28 20:15:42.429176: Epoch 476 
2025-08-28 20:15:42.434363: Current learning rate: 0.00559 
2025-08-28 20:15:59.092934: train_loss -0.5074 
2025-08-28 20:15:59.105743: val_loss -0.5377 
2025-08-28 20:15:59.111139: Pseudo dice [np.float32(0.7922)] 
2025-08-28 20:15:59.117650: Epoch time: 16.67 s 
2025-08-28 20:15:59.123412: Yayy! New best EMA pseudo Dice: 0.739300012588501 
2025-08-28 20:16:00.091722:  
2025-08-28 20:16:00.102040: Epoch 477 
2025-08-28 20:16:00.110545: Current learning rate: 0.00558 
2025-08-28 20:16:17.019269: train_loss -0.5071 
2025-08-28 20:16:17.027388: val_loss -0.5063 
2025-08-28 20:16:17.031473: Pseudo dice [np.float32(0.7061)] 
2025-08-28 20:16:17.039692: Epoch time: 16.93 s 
2025-08-28 20:16:17.890586:  
2025-08-28 20:16:17.897940: Epoch 478 
2025-08-28 20:16:17.902092: Current learning rate: 0.00557 
2025-08-28 20:16:34.432602: train_loss -0.4999 
2025-08-28 20:16:34.441060: val_loss -0.6213 
2025-08-28 20:16:34.445156: Pseudo dice [np.float32(0.7639)] 
2025-08-28 20:16:34.451081: Epoch time: 16.55 s 
2025-08-28 20:16:35.155910:  
2025-08-28 20:16:35.164192: Epoch 479 
2025-08-28 20:16:35.169370: Current learning rate: 0.00556 
2025-08-28 20:16:51.407594: train_loss -0.4786 
2025-08-28 20:16:51.415922: val_loss -0.5487 
2025-08-28 20:16:51.424586: Pseudo dice [np.float32(0.7971)] 
2025-08-28 20:16:51.430379: Epoch time: 16.25 s 
2025-08-28 20:16:51.435832: Yayy! New best EMA pseudo Dice: 0.7445999979972839 
2025-08-28 20:16:52.319848:  
2025-08-28 20:16:52.332307: Epoch 480 
2025-08-28 20:16:52.341702: Current learning rate: 0.00555 
2025-08-28 20:17:08.449565: train_loss -0.543 
2025-08-28 20:17:08.462104: val_loss -0.609 
2025-08-28 20:17:08.466272: Pseudo dice [np.float32(0.7801)] 
2025-08-28 20:17:08.474468: Epoch time: 16.13 s 
2025-08-28 20:17:08.480266: Yayy! New best EMA pseudo Dice: 0.748199999332428 
2025-08-28 20:17:09.353508:  
2025-08-28 20:17:09.362895: Epoch 481 
2025-08-28 20:17:09.369270: Current learning rate: 0.00554 
2025-08-28 20:17:25.762755: train_loss -0.4924 
2025-08-28 20:17:25.771043: val_loss -0.5697 
2025-08-28 20:17:25.775219: Pseudo dice [np.float32(0.7258)] 
2025-08-28 20:17:25.784337: Epoch time: 16.41 s 
2025-08-28 20:17:26.479996:  
2025-08-28 20:17:26.487563: Epoch 482 
2025-08-28 20:17:26.492505: Current learning rate: 0.00553 
2025-08-28 20:17:43.321974: train_loss -0.5015 
2025-08-28 20:17:43.330302: val_loss -0.5998 
2025-08-28 20:17:43.338608: Pseudo dice [np.float32(0.7997)] 
2025-08-28 20:17:43.344909: Epoch time: 16.84 s 
2025-08-28 20:17:43.351635: Yayy! New best EMA pseudo Dice: 0.7512999773025513 
2025-08-28 20:17:44.244784:  
2025-08-28 20:17:44.254020: Epoch 483 
2025-08-28 20:17:44.262393: Current learning rate: 0.00552 
2025-08-28 20:18:00.931250: train_loss -0.4445 
2025-08-28 20:18:00.939512: val_loss -0.549 
2025-08-28 20:18:00.943646: Pseudo dice [np.float32(0.6608)] 
2025-08-28 20:18:00.951742: Epoch time: 16.69 s 
2025-08-28 20:18:01.808117:  
2025-08-28 20:18:01.815206: Epoch 484 
2025-08-28 20:18:01.821601: Current learning rate: 0.00551 
2025-08-28 20:18:18.277825: train_loss -0.4969 
2025-08-28 20:18:18.286163: val_loss -0.5313 
2025-08-28 20:18:18.294491: Pseudo dice [np.float32(0.7814)] 
2025-08-28 20:18:18.301429: Epoch time: 16.47 s 
2025-08-28 20:18:19.001230:  
2025-08-28 20:18:19.008539: Epoch 485 
2025-08-28 20:18:19.013710: Current learning rate: 0.0055 
2025-08-28 20:18:35.720125: train_loss -0.4597 
2025-08-28 20:18:35.728159: val_loss -0.4973 
2025-08-28 20:18:35.732636: Pseudo dice [np.float32(0.6733)] 
2025-08-28 20:18:35.738834: Epoch time: 16.72 s 
2025-08-28 20:18:36.418710:  
2025-08-28 20:18:36.426939: Epoch 486 
2025-08-28 20:18:36.433093: Current learning rate: 0.00549 
2025-08-28 20:18:53.283357: train_loss -0.4841 
2025-08-28 20:18:53.290702: val_loss -0.5651 
2025-08-28 20:18:53.295954: Pseudo dice [np.float32(0.7267)] 
2025-08-28 20:18:53.302166: Epoch time: 16.87 s 
2025-08-28 20:18:53.999467:  
2025-08-28 20:18:54.010172: Epoch 487 
2025-08-28 20:18:54.017828: Current learning rate: 0.00548 
2025-08-28 20:19:10.942510: train_loss -0.5107 
2025-08-28 20:19:10.951085: val_loss -0.5627 
2025-08-28 20:19:10.955230: Pseudo dice [np.float32(0.7689)] 
2025-08-28 20:19:10.963430: Epoch time: 16.94 s 
2025-08-28 20:19:11.667286:  
2025-08-28 20:19:11.676679: Epoch 488 
2025-08-28 20:19:11.684048: Current learning rate: 0.00547 
2025-08-28 20:19:28.473161: train_loss -0.5106 
2025-08-28 20:19:28.481650: val_loss -0.5325 
2025-08-28 20:19:28.489497: Pseudo dice [np.float32(0.7771)] 
2025-08-28 20:19:28.494554: Epoch time: 16.81 s 
2025-08-28 20:19:29.197402:  
2025-08-28 20:19:29.205670: Epoch 489 
2025-08-28 20:19:29.210821: Current learning rate: 0.00546 
2025-08-28 20:19:46.086142: train_loss -0.5325 
2025-08-28 20:19:46.094514: val_loss -0.5314 
2025-08-28 20:19:46.098719: Pseudo dice [np.float32(0.7054)] 
2025-08-28 20:19:46.106147: Epoch time: 16.89 s 
2025-08-28 20:19:46.805554:  
2025-08-28 20:19:46.813994: Epoch 490 
2025-08-28 20:19:46.821229: Current learning rate: 0.00546 
2025-08-28 20:20:03.966533: train_loss -0.3934 
2025-08-28 20:20:03.979064: val_loss -0.5377 
2025-08-28 20:20:03.983131: Pseudo dice [np.float32(0.6654)] 
2025-08-28 20:20:03.991432: Epoch time: 17.16 s 
2025-08-28 20:20:04.908943:  
2025-08-28 20:20:04.916493: Epoch 491 
2025-08-28 20:20:04.922618: Current learning rate: 0.00545 
2025-08-28 20:20:21.517380: train_loss -0.4985 
2025-08-28 20:20:21.526043: val_loss -0.5791 
2025-08-28 20:20:21.534060: Pseudo dice [np.float32(0.78)] 
2025-08-28 20:20:21.538993: Epoch time: 16.61 s 
2025-08-28 20:20:22.227484:  
2025-08-28 20:20:22.235639: Epoch 492 
2025-08-28 20:20:22.242636: Current learning rate: 0.00544 
2025-08-28 20:20:39.089086: train_loss -0.4968 
2025-08-28 20:20:39.097698: val_loss -0.5241 
2025-08-28 20:20:39.101597: Pseudo dice [np.float32(0.6946)] 
2025-08-28 20:20:39.110623: Epoch time: 16.86 s 
2025-08-28 20:20:39.813753:  
2025-08-28 20:20:39.820996: Epoch 493 
2025-08-28 20:20:39.827227: Current learning rate: 0.00543 
2025-08-28 20:20:56.485672: train_loss -0.486 
2025-08-28 20:20:56.494256: val_loss -0.5425 
2025-08-28 20:20:56.501950: Pseudo dice [np.float32(0.7595)] 
2025-08-28 20:20:56.507321: Epoch time: 16.67 s 
2025-08-28 20:20:57.197752:  
2025-08-28 20:20:57.205100: Epoch 494 
2025-08-28 20:20:57.211200: Current learning rate: 0.00542 
2025-08-28 20:21:13.840477: train_loss -0.4954 
2025-08-28 20:21:13.849156: val_loss -0.5664 
2025-08-28 20:21:13.852998: Pseudo dice [np.float32(0.7539)] 
2025-08-28 20:21:13.861344: Epoch time: 16.64 s 
2025-08-28 20:21:14.557681:  
2025-08-28 20:21:14.566068: Epoch 495 
2025-08-28 20:21:14.571453: Current learning rate: 0.00541 
2025-08-28 20:21:31.403807: train_loss -0.5068 
2025-08-28 20:21:31.412150: val_loss -0.5531 
2025-08-28 20:21:31.416346: Pseudo dice [np.float32(0.7514)] 
2025-08-28 20:21:31.422587: Epoch time: 16.85 s 
2025-08-28 20:21:32.112772:  
2025-08-28 20:21:32.121053: Epoch 496 
2025-08-28 20:21:32.127480: Current learning rate: 0.0054 
2025-08-28 20:21:48.466681: train_loss -0.5024 
2025-08-28 20:21:48.475074: val_loss -0.5736 
2025-08-28 20:21:48.483431: Pseudo dice [np.float32(0.7858)] 
2025-08-28 20:21:48.488758: Epoch time: 16.36 s 
2025-08-28 20:21:49.318779:  
2025-08-28 20:21:49.326949: Epoch 497 
2025-08-28 20:21:49.332194: Current learning rate: 0.00539 
2025-08-28 20:22:05.754976: train_loss -0.5194 
2025-08-28 20:22:05.767334: val_loss -0.4994 
2025-08-28 20:22:05.771903: Pseudo dice [np.float32(0.6936)] 
2025-08-28 20:22:05.780619: Epoch time: 16.44 s 
2025-08-28 20:22:06.483628:  
2025-08-28 20:22:06.490943: Epoch 498 
2025-08-28 20:22:06.497028: Current learning rate: 0.00538 
2025-08-28 20:22:23.105141: train_loss -0.4717 
2025-08-28 20:22:23.113350: val_loss -0.4637 
2025-08-28 20:22:23.118040: Pseudo dice [np.float32(0.6779)] 
2025-08-28 20:22:23.124275: Epoch time: 16.62 s 
2025-08-28 20:22:23.821671:  
2025-08-28 20:22:23.830111: Epoch 499 
2025-08-28 20:22:23.836189: Current learning rate: 0.00537 
2025-08-28 20:22:40.493650: train_loss -0.513 
2025-08-28 20:22:40.502084: val_loss -0.5657 
2025-08-28 20:22:40.506435: Pseudo dice [np.float32(0.7351)] 
2025-08-28 20:22:40.512587: Epoch time: 16.67 s 
2025-08-28 20:22:41.413169:  
2025-08-28 20:22:41.420591: Epoch 500 
2025-08-28 20:22:41.425590: Current learning rate: 0.00536 
2025-08-28 20:22:57.642344: train_loss -0.4492 
2025-08-28 20:22:57.652469: val_loss -0.5019 
2025-08-28 20:22:57.656954: Pseudo dice [np.float32(0.7482)] 
2025-08-28 20:22:57.662806: Epoch time: 16.23 s 
2025-08-28 20:22:58.376006:  
2025-08-28 20:22:58.384387: Epoch 501 
2025-08-28 20:22:58.390538: Current learning rate: 0.00535 
2025-08-28 20:23:15.111594: train_loss -0.5131 
2025-08-28 20:23:15.119911: val_loss -0.4756 
2025-08-28 20:23:15.124323: Pseudo dice [np.float32(0.7033)] 
2025-08-28 20:23:15.131074: Epoch time: 16.74 s 
2025-08-28 20:23:15.836159:  
2025-08-28 20:23:15.844536: Epoch 502 
2025-08-28 20:23:15.850873: Current learning rate: 0.00534 
2025-08-28 20:23:32.492449: train_loss -0.5349 
2025-08-28 20:23:32.499789: val_loss -0.532 
2025-08-28 20:23:32.503946: Pseudo dice [np.float32(0.7587)] 
2025-08-28 20:23:32.512142: Epoch time: 16.66 s 
2025-08-28 20:23:33.206906:  
2025-08-28 20:23:33.214086: Epoch 503 
2025-08-28 20:23:33.220201: Current learning rate: 0.00533 
2025-08-28 20:23:49.942392: train_loss -0.5062 
2025-08-28 20:23:49.950503: val_loss -0.4631 
2025-08-28 20:23:49.958873: Pseudo dice [np.float32(0.6828)] 
2025-08-28 20:23:49.964268: Epoch time: 16.74 s 
2025-08-28 20:23:50.750181:  
2025-08-28 20:23:50.757482: Epoch 504 
2025-08-28 20:23:50.763643: Current learning rate: 0.00532 
2025-08-28 20:24:06.133483: train_loss -0.4585 
2025-08-28 20:24:06.141675: val_loss -0.558 
2025-08-28 20:24:06.150012: Pseudo dice [np.float32(0.7389)] 
2025-08-28 20:24:06.154212: Epoch time: 15.38 s 
2025-08-28 20:24:06.799580:  
2025-08-28 20:24:06.806831: Epoch 505 
2025-08-28 20:24:06.811004: Current learning rate: 0.00531 
2025-08-28 20:24:21.957768: train_loss -0.5343 
2025-08-28 20:24:21.965803: val_loss -0.508 
2025-08-28 20:24:21.970000: Pseudo dice [np.float32(0.7101)] 
2025-08-28 20:24:21.978248: Epoch time: 15.16 s 
2025-08-28 20:24:22.620449:  
2025-08-28 20:24:22.628811: Epoch 506 
2025-08-28 20:24:22.634145: Current learning rate: 0.0053 
2025-08-28 20:24:37.252017: train_loss -0.4928 
2025-08-28 20:24:37.260246: val_loss -0.6107 
2025-08-28 20:24:37.264427: Pseudo dice [np.float32(0.805)] 
2025-08-28 20:24:37.272411: Epoch time: 14.63 s 
2025-08-28 20:24:37.907733:  
2025-08-28 20:24:37.916189: Epoch 507 
2025-08-28 20:24:37.921245: Current learning rate: 0.00529 
2025-08-28 20:24:53.030063: train_loss -0.5137 
2025-08-28 20:24:53.038552: val_loss -0.4903 
2025-08-28 20:24:53.046877: Pseudo dice [np.float32(0.6638)] 
2025-08-28 20:24:53.052949: Epoch time: 15.12 s 
2025-08-28 20:24:53.691161:  
2025-08-28 20:24:53.699643: Epoch 508 
2025-08-28 20:24:53.705684: Current learning rate: 0.00528 
2025-08-28 20:25:08.795919: train_loss -0.4901 
2025-08-28 20:25:08.804258: val_loss -0.5083 
2025-08-28 20:25:08.808403: Pseudo dice [np.float32(0.7505)] 
2025-08-28 20:25:08.816409: Epoch time: 15.11 s 
2025-08-28 20:25:09.468470:  
2025-08-28 20:25:09.477779: Epoch 509 
2025-08-28 20:25:09.484020: Current learning rate: 0.00527 
2025-08-28 20:25:24.157504: train_loss -0.5203 
2025-08-28 20:25:24.165431: val_loss -0.5379 
2025-08-28 20:25:24.173932: Pseudo dice [np.float32(0.7175)] 
2025-08-28 20:25:24.180786: Epoch time: 14.69 s 
2025-08-28 20:25:24.967420:  
2025-08-28 20:25:24.976630: Epoch 510 
2025-08-28 20:25:24.982781: Current learning rate: 0.00526 
2025-08-28 20:25:40.339903: train_loss -0.4462 
2025-08-28 20:25:40.348278: val_loss -0.5054 
2025-08-28 20:25:40.356925: Pseudo dice [np.float32(0.6992)] 
2025-08-28 20:25:40.362654: Epoch time: 15.37 s 
2025-08-28 20:25:41.006105:  
2025-08-28 20:25:41.013447: Epoch 511 
2025-08-28 20:25:41.019641: Current learning rate: 0.00525 
2025-08-28 20:25:56.139454: train_loss -0.4737 
2025-08-28 20:25:56.151556: val_loss -0.4713 
2025-08-28 20:25:56.155740: Pseudo dice [np.float32(0.6927)] 
2025-08-28 20:25:56.161765: Epoch time: 15.13 s 
2025-08-28 20:25:56.809428:  
2025-08-28 20:25:56.816844: Epoch 512 
2025-08-28 20:25:56.821947: Current learning rate: 0.00524 
2025-08-28 20:26:11.963158: train_loss -0.4947 
2025-08-28 20:26:11.971806: val_loss -0.5139 
2025-08-28 20:26:11.979876: Pseudo dice [np.float32(0.7647)] 
2025-08-28 20:26:11.985217: Epoch time: 15.16 s 
2025-08-28 20:26:12.624154:  
2025-08-28 20:26:12.631613: Epoch 513 
2025-08-28 20:26:12.636735: Current learning rate: 0.00523 
2025-08-28 20:26:27.485263: train_loss -0.5103 
2025-08-28 20:26:27.493217: val_loss -0.59 
2025-08-28 20:26:27.500519: Pseudo dice [np.float32(0.8015)] 
2025-08-28 20:26:27.508883: Epoch time: 14.86 s 
2025-08-28 20:26:28.173004:  
2025-08-28 20:26:28.182387: Epoch 514 
2025-08-28 20:26:28.188745: Current learning rate: 0.00522 
2025-08-28 20:26:43.511300: train_loss -0.5357 
2025-08-28 20:26:43.523837: val_loss -0.4225 
2025-08-28 20:26:43.528182: Pseudo dice [np.float32(0.6483)] 
2025-08-28 20:26:43.534039: Epoch time: 15.34 s 
2025-08-28 20:26:44.177502:  
2025-08-28 20:26:44.185842: Epoch 515 
2025-08-28 20:26:44.194256: Current learning rate: 0.00521 
2025-08-28 20:26:59.185324: train_loss -0.4963 
2025-08-28 20:26:59.197820: val_loss -0.5621 
2025-08-28 20:26:59.201989: Pseudo dice [np.float32(0.813)] 
2025-08-28 20:26:59.208108: Epoch time: 15.01 s 
2025-08-28 20:26:59.862017:  
2025-08-28 20:26:59.871448: Epoch 516 
2025-08-28 20:26:59.877968: Current learning rate: 0.0052 
2025-08-28 20:27:14.913512: train_loss -0.479 
2025-08-28 20:27:14.921851: val_loss -0.5854 
2025-08-28 20:27:14.926005: Pseudo dice [np.float32(0.7322)] 
2025-08-28 20:27:14.935132: Epoch time: 15.05 s 
2025-08-28 20:27:15.740431:  
2025-08-28 20:27:15.747501: Epoch 517 
2025-08-28 20:27:15.752861: Current learning rate: 0.00519 
2025-08-28 20:27:30.954612: train_loss -0.5082 
2025-08-28 20:27:30.962875: val_loss -0.4804 
2025-08-28 20:27:30.967263: Pseudo dice [np.float32(0.6636)] 
2025-08-28 20:27:30.974102: Epoch time: 15.22 s 
2025-08-28 20:27:31.617521:  
2025-08-28 20:27:31.625906: Epoch 518 
2025-08-28 20:27:31.631229: Current learning rate: 0.00518 
2025-08-28 20:27:46.478548: train_loss -0.5029 
2025-08-28 20:27:46.486721: val_loss -0.6476 
2025-08-28 20:27:46.495073: Pseudo dice [np.float32(0.7622)] 
2025-08-28 20:27:46.500468: Epoch time: 14.86 s 
2025-08-28 20:27:47.150864:  
2025-08-28 20:27:47.158070: Epoch 519 
2025-08-28 20:27:47.163478: Current learning rate: 0.00518 
2025-08-28 20:28:01.802208: train_loss -0.4995 
2025-08-28 20:28:01.814519: val_loss -0.3984 
2025-08-28 20:28:01.818711: Pseudo dice [np.float32(0.5761)] 
2025-08-28 20:28:01.825630: Epoch time: 14.65 s 
2025-08-28 20:28:02.472554:  
2025-08-28 20:28:02.480755: Epoch 520 
2025-08-28 20:28:02.485857: Current learning rate: 0.00517 
2025-08-28 20:28:17.655383: train_loss -0.3795 
2025-08-28 20:28:17.663671: val_loss -0.5632 
2025-08-28 20:28:17.667858: Pseudo dice [np.float32(0.7658)] 
2025-08-28 20:28:17.676911: Epoch time: 15.18 s 
2025-08-28 20:28:18.344608:  
2025-08-28 20:28:18.351708: Epoch 521 
2025-08-28 20:28:18.357045: Current learning rate: 0.00516 
2025-08-28 20:28:33.446097: train_loss -0.4637 
2025-08-28 20:28:33.454432: val_loss -0.456 
2025-08-28 20:28:33.458913: Pseudo dice [np.float32(0.7409)] 
2025-08-28 20:28:33.466933: Epoch time: 15.1 s 
2025-08-28 20:28:34.107146:  
2025-08-28 20:28:34.114429: Epoch 522 
2025-08-28 20:28:34.119606: Current learning rate: 0.00515 
2025-08-28 20:28:49.171769: train_loss -0.5028 
2025-08-28 20:28:49.179891: val_loss -0.4913 
2025-08-28 20:28:49.186773: Pseudo dice [np.float32(0.818)] 
2025-08-28 20:28:49.192780: Epoch time: 15.07 s 
2025-08-28 20:28:49.847872:  
2025-08-28 20:28:49.856187: Epoch 523 
2025-08-28 20:28:49.863538: Current learning rate: 0.00514 
2025-08-28 20:29:05.044291: train_loss -0.493 
2025-08-28 20:29:05.052638: val_loss -0.5238 
2025-08-28 20:29:05.060982: Pseudo dice [np.float32(0.7558)] 
2025-08-28 20:29:05.066403: Epoch time: 15.2 s 
2025-08-28 20:29:05.862800:  
2025-08-28 20:29:05.871180: Epoch 524 
2025-08-28 20:29:05.876341: Current learning rate: 0.00513 
2025-08-28 20:29:21.356406: train_loss -0.5187 
2025-08-28 20:29:21.364819: val_loss -0.6136 
2025-08-28 20:29:21.368949: Pseudo dice [np.float32(0.7793)] 
2025-08-28 20:29:21.378332: Epoch time: 15.5 s 
2025-08-28 20:29:22.020743:  
2025-08-28 20:29:22.028937: Epoch 525 
2025-08-28 20:29:22.034111: Current learning rate: 0.00512 
2025-08-28 20:29:36.830263: train_loss -0.5156 
2025-08-28 20:29:36.838551: val_loss -0.553 
2025-08-28 20:29:36.847599: Pseudo dice [np.float32(0.7628)] 
2025-08-28 20:29:36.851712: Epoch time: 14.81 s 
2025-08-28 20:29:37.499619:  
2025-08-28 20:29:37.505762: Epoch 526 
2025-08-28 20:29:37.512071: Current learning rate: 0.00511 
2025-08-28 20:29:52.153841: train_loss -0.5105 
2025-08-28 20:29:52.162184: val_loss -0.5583 
2025-08-28 20:29:52.166356: Pseudo dice [np.float32(0.716)] 
2025-08-28 20:29:52.175456: Epoch time: 14.66 s 
2025-08-28 20:29:52.825175:  
2025-08-28 20:29:52.832573: Epoch 527 
2025-08-28 20:29:52.837689: Current learning rate: 0.0051 
2025-08-28 20:30:07.882884: train_loss -0.5018 
2025-08-28 20:30:07.890393: val_loss -0.4271 
2025-08-28 20:30:07.899077: Pseudo dice [np.float32(0.6232)] 
2025-08-28 20:30:07.904123: Epoch time: 15.06 s 
2025-08-28 20:30:08.551504:  
2025-08-28 20:30:08.559781: Epoch 528 
2025-08-28 20:30:08.565912: Current learning rate: 0.00509 
2025-08-28 20:30:23.668667: train_loss -0.5077 
2025-08-28 20:30:23.677023: val_loss -0.579 
2025-08-28 20:30:23.681139: Pseudo dice [np.float32(0.7428)] 
2025-08-28 20:30:23.688228: Epoch time: 15.12 s 
2025-08-28 20:30:24.333830:  
2025-08-28 20:30:24.342283: Epoch 529 
2025-08-28 20:30:24.348496: Current learning rate: 0.00508 
2025-08-28 20:30:39.288960: train_loss -0.5147 
2025-08-28 20:30:39.296788: val_loss -0.4692 
2025-08-28 20:30:39.300938: Pseudo dice [np.float32(0.6804)] 
2025-08-28 20:30:39.309076: Epoch time: 14.96 s 
2025-08-28 20:30:39.978509:  
2025-08-28 20:30:39.985948: Epoch 530 
2025-08-28 20:30:39.990121: Current learning rate: 0.00507 
2025-08-28 20:30:55.166655: train_loss -0.5382 
2025-08-28 20:30:55.170946: val_loss -0.5772 
2025-08-28 20:30:55.179273: Pseudo dice [np.float32(0.7831)] 
2025-08-28 20:30:55.185355: Epoch time: 15.19 s 
2025-08-28 20:30:56.000827:  
2025-08-28 20:30:56.011295: Epoch 531 
2025-08-28 20:30:56.019670: Current learning rate: 0.00506 
2025-08-28 20:31:11.007121: train_loss -0.5093 
2025-08-28 20:31:11.011795: val_loss -0.5035 
2025-08-28 20:31:11.020123: Pseudo dice [np.float32(0.7263)] 
2025-08-28 20:31:11.025080: Epoch time: 15.01 s 
2025-08-28 20:31:11.660327:  
2025-08-28 20:31:11.667620: Epoch 532 
2025-08-28 20:31:11.672837: Current learning rate: 0.00505 
2025-08-28 20:31:26.593851: train_loss -0.5461 
2025-08-28 20:31:26.602315: val_loss -0.5485 
2025-08-28 20:31:26.606492: Pseudo dice [np.float32(0.7283)] 
2025-08-28 20:31:26.614793: Epoch time: 14.94 s 
2025-08-28 20:31:27.270682:  
2025-08-28 20:31:27.279010: Epoch 533 
2025-08-28 20:31:27.284177: Current learning rate: 0.00504 
2025-08-28 20:31:42.360130: train_loss -0.5336 
2025-08-28 20:31:42.368054: val_loss -0.6074 
2025-08-28 20:31:42.372242: Pseudo dice [np.float32(0.8007)] 
2025-08-28 20:31:42.380183: Epoch time: 15.09 s 
2025-08-28 20:31:43.047824:  
2025-08-28 20:31:43.057270: Epoch 534 
2025-08-28 20:31:43.062434: Current learning rate: 0.00503 
2025-08-28 20:31:57.896232: train_loss -0.5685 
2025-08-28 20:31:57.904422: val_loss -0.5686 
2025-08-28 20:31:57.912755: Pseudo dice [np.float32(0.7585)] 
2025-08-28 20:31:57.917660: Epoch time: 14.85 s 
2025-08-28 20:31:58.552898:  
2025-08-28 20:31:58.561291: Epoch 535 
2025-08-28 20:31:58.568744: Current learning rate: 0.00502 
2025-08-28 20:32:13.440729: train_loss -0.5166 
2025-08-28 20:32:13.449098: val_loss -0.5506 
2025-08-28 20:32:13.453271: Pseudo dice [np.float32(0.764)] 
2025-08-28 20:32:13.460317: Epoch time: 14.89 s 
2025-08-28 20:32:14.109081:  
2025-08-28 20:32:14.116290: Epoch 536 
2025-08-28 20:32:14.121685: Current learning rate: 0.00501 
2025-08-28 20:32:29.127246: train_loss -0.5245 
2025-08-28 20:32:29.135598: val_loss -0.4927 
2025-08-28 20:32:29.139754: Pseudo dice [np.float32(0.7204)] 
2025-08-28 20:32:29.145874: Epoch time: 15.02 s 
2025-08-28 20:32:29.779018:  
2025-08-28 20:32:29.788453: Epoch 537 
2025-08-28 20:32:29.794434: Current learning rate: 0.005 
2025-08-28 20:32:45.014388: train_loss -0.5289 
2025-08-28 20:32:45.022286: val_loss -0.5546 
2025-08-28 20:32:45.026800: Pseudo dice [np.float32(0.7518)] 
2025-08-28 20:32:45.035482: Epoch time: 15.24 s 
2025-08-28 20:32:45.821899:  
2025-08-28 20:32:45.829245: Epoch 538 
2025-08-28 20:32:45.834497: Current learning rate: 0.00499 
2025-08-28 20:33:01.805796: train_loss -0.5073 
2025-08-28 20:33:01.818225: val_loss -0.5086 
2025-08-28 20:33:01.822393: Pseudo dice [np.float32(0.663)] 
2025-08-28 20:33:01.829645: Epoch time: 15.98 s 
2025-08-28 20:33:02.518251:  
2025-08-28 20:33:02.526191: Epoch 539 
2025-08-28 20:33:02.532191: Current learning rate: 0.00498 
2025-08-28 20:33:19.265296: train_loss -0.5158 
2025-08-28 20:33:19.273168: val_loss -0.4783 
2025-08-28 20:33:19.277601: Pseudo dice [np.float32(0.7453)] 
2025-08-28 20:33:19.285772: Epoch time: 16.75 s 
2025-08-28 20:33:19.994555:  
2025-08-28 20:33:20.001709: Epoch 540 
2025-08-28 20:33:20.007122: Current learning rate: 0.00497 
2025-08-28 20:33:36.836522: train_loss -0.505 
2025-08-28 20:33:36.845161: val_loss -0.5867 
2025-08-28 20:33:36.853251: Pseudo dice [np.float32(0.7453)] 
2025-08-28 20:33:36.858743: Epoch time: 16.84 s 
2025-08-28 20:33:37.559161:  
2025-08-28 20:33:37.566265: Epoch 541 
2025-08-28 20:33:37.572688: Current learning rate: 0.00496 
2025-08-28 20:33:54.399899: train_loss -0.4964 
2025-08-28 20:33:54.408228: val_loss -0.5338 
2025-08-28 20:33:54.416612: Pseudo dice [np.float32(0.7377)] 
2025-08-28 20:33:54.421546: Epoch time: 16.84 s 
2025-08-28 20:33:55.140963:  
2025-08-28 20:33:55.148557: Epoch 542 
2025-08-28 20:33:55.154630: Current learning rate: 0.00495 
2025-08-28 20:34:11.776297: train_loss -0.5363 
2025-08-28 20:34:11.788097: val_loss -0.6088 
2025-08-28 20:34:11.792588: Pseudo dice [np.float32(0.7437)] 
2025-08-28 20:34:11.798372: Epoch time: 16.64 s 
2025-08-28 20:34:12.539580:  
2025-08-28 20:34:12.547035: Epoch 543 
2025-08-28 20:34:12.554434: Current learning rate: 0.00494 
2025-08-28 20:34:29.163680: train_loss -0.5422 
2025-08-28 20:34:29.172124: val_loss -0.5118 
2025-08-28 20:34:29.176327: Pseudo dice [np.float32(0.7438)] 
2025-08-28 20:34:29.183466: Epoch time: 16.63 s 
2025-08-28 20:34:30.042669:  
2025-08-28 20:34:30.051021: Epoch 544 
2025-08-28 20:34:30.057332: Current learning rate: 0.00493 
2025-08-28 20:34:46.556126: train_loss -0.5092 
2025-08-28 20:34:46.564488: val_loss -0.5001 
2025-08-28 20:34:46.568979: Pseudo dice [np.float32(0.6982)] 
2025-08-28 20:34:46.577776: Epoch time: 16.51 s 
2025-08-28 20:34:47.284900:  
2025-08-28 20:34:47.291205: Epoch 545 
2025-08-28 20:34:47.297464: Current learning rate: 0.00492 
2025-08-28 20:35:04.040294: train_loss -0.5195 
2025-08-28 20:35:04.048618: val_loss -0.5463 
2025-08-28 20:35:04.056955: Pseudo dice [np.float32(0.803)] 
2025-08-28 20:35:04.063354: Epoch time: 16.76 s 
2025-08-28 20:35:04.758752:  
2025-08-28 20:35:04.765904: Epoch 546 
2025-08-28 20:35:04.772233: Current learning rate: 0.00491 
2025-08-28 20:35:21.215748: train_loss -0.516 
2025-08-28 20:35:21.224087: val_loss -0.6312 
2025-08-28 20:35:21.228281: Pseudo dice [np.float32(0.7787)] 
2025-08-28 20:35:21.236497: Epoch time: 16.46 s 
2025-08-28 20:35:21.956828:  
2025-08-28 20:35:21.965372: Epoch 547 
2025-08-28 20:35:21.971771: Current learning rate: 0.0049 
2025-08-28 20:35:38.674844: train_loss -0.5368 
2025-08-28 20:35:38.683184: val_loss -0.6597 
2025-08-28 20:35:38.687347: Pseudo dice [np.float32(0.7855)] 
2025-08-28 20:35:38.694725: Epoch time: 16.72 s 
2025-08-28 20:35:39.408827:  
2025-08-28 20:35:39.417253: Epoch 548 
2025-08-28 20:35:39.422511: Current learning rate: 0.00489 
2025-08-28 20:35:55.858725: train_loss -0.5262 
2025-08-28 20:35:55.871233: val_loss -0.5443 
2025-08-28 20:35:55.875392: Pseudo dice [np.float32(0.7662)] 
2025-08-28 20:35:55.881542: Epoch time: 16.45 s 
2025-08-28 20:35:56.587822:  
2025-08-28 20:35:56.594745: Epoch 549 
2025-08-28 20:35:56.600743: Current learning rate: 0.00488 
2025-08-28 20:36:13.330678: train_loss -0.5228 
2025-08-28 20:36:13.339131: val_loss -0.5338 
2025-08-28 20:36:13.347004: Pseudo dice [np.float32(0.7534)] 
2025-08-28 20:36:13.352816: Epoch time: 16.74 s 
2025-08-28 20:36:14.381262:  
2025-08-28 20:36:14.389511: Epoch 550 
2025-08-28 20:36:14.395511: Current learning rate: 0.00487 
2025-08-28 20:36:31.069590: train_loss -0.5372 
2025-08-28 20:36:31.077189: val_loss -0.5292 
2025-08-28 20:36:31.081352: Pseudo dice [np.float32(0.764)] 
2025-08-28 20:36:31.087811: Epoch time: 16.69 s 
2025-08-28 20:36:31.093885: Yayy! New best EMA pseudo Dice: 0.7516000270843506 
2025-08-28 20:36:31.968613:  
2025-08-28 20:36:31.978360: Epoch 551 
2025-08-28 20:36:31.985274: Current learning rate: 0.00486 
2025-08-28 20:36:48.995064: train_loss -0.5407 
2025-08-28 20:36:49.004712: val_loss -0.5937 
2025-08-28 20:36:49.007589: Pseudo dice [np.float32(0.8044)] 
2025-08-28 20:36:49.016767: Epoch time: 17.03 s 
2025-08-28 20:36:49.021977: Yayy! New best EMA pseudo Dice: 0.7569000124931335 
2025-08-28 20:36:49.919928:  
2025-08-28 20:36:49.928162: Epoch 552 
2025-08-28 20:36:49.937661: Current learning rate: 0.00485 
2025-08-28 20:37:06.007940: train_loss -0.5404 
2025-08-28 20:37:06.016267: val_loss -0.584 
2025-08-28 20:37:06.024641: Pseudo dice [np.float32(0.7451)] 
2025-08-28 20:37:06.029549: Epoch time: 16.09 s 
2025-08-28 20:37:06.755503:  
2025-08-28 20:37:06.763826: Epoch 553 
2025-08-28 20:37:06.771826: Current learning rate: 0.00484 
2025-08-28 20:37:22.749582: train_loss -0.5369 
2025-08-28 20:37:22.758317: val_loss -0.5549 
2025-08-28 20:37:22.762105: Pseudo dice [np.float32(0.7716)] 
2025-08-28 20:37:22.770391: Epoch time: 16.0 s 
2025-08-28 20:37:22.776306: Yayy! New best EMA pseudo Dice: 0.7573000192642212 
2025-08-28 20:37:23.714158:  
2025-08-28 20:37:23.721248: Epoch 554 
2025-08-28 20:37:23.727592: Current learning rate: 0.00484 
2025-08-28 20:37:39.654034: train_loss -0.5709 
2025-08-28 20:37:39.662620: val_loss -0.4542 
2025-08-28 20:37:39.666528: Pseudo dice [np.float32(0.7339)] 
2025-08-28 20:37:39.671837: Epoch time: 15.94 s 
2025-08-28 20:37:40.462996:  
2025-08-28 20:37:40.471306: Epoch 555 
2025-08-28 20:37:40.476730: Current learning rate: 0.00483 
2025-08-28 20:37:56.399848: train_loss -0.5609 
2025-08-28 20:37:56.412374: val_loss -0.5186 
2025-08-28 20:37:56.416592: Pseudo dice [np.float32(0.7544)] 
2025-08-28 20:37:56.423644: Epoch time: 15.94 s 
2025-08-28 20:37:57.129646:  
2025-08-28 20:37:57.137949: Epoch 556 
2025-08-28 20:37:57.143299: Current learning rate: 0.00482 
2025-08-28 20:38:13.158540: train_loss -0.5542 
2025-08-28 20:38:13.166677: val_loss -0.5947 
2025-08-28 20:38:13.170818: Pseudo dice [np.float32(0.7781)] 
2025-08-28 20:38:13.177068: Epoch time: 16.03 s 
2025-08-28 20:38:14.035722:  
2025-08-28 20:38:14.043527: Epoch 557 
2025-08-28 20:38:14.049755: Current learning rate: 0.00481 
2025-08-28 20:38:30.020981: train_loss -0.5229 
2025-08-28 20:38:30.029323: val_loss -0.4856 
2025-08-28 20:38:30.037663: Pseudo dice [np.float32(0.7114)] 
2025-08-28 20:38:30.042926: Epoch time: 15.99 s 
2025-08-28 20:38:30.740377:  
2025-08-28 20:38:30.750581: Epoch 558 
2025-08-28 20:38:30.759178: Current learning rate: 0.0048 
2025-08-28 20:38:46.608423: train_loss -0.5376 
2025-08-28 20:38:46.616759: val_loss -0.5087 
2025-08-28 20:38:46.620866: Pseudo dice [np.float32(0.7785)] 
2025-08-28 20:38:46.628397: Epoch time: 15.87 s 
2025-08-28 20:38:47.343292:  
2025-08-28 20:38:47.351812: Epoch 559 
2025-08-28 20:38:47.358958: Current learning rate: 0.00479 
2025-08-28 20:39:03.270942: train_loss -0.5099 
2025-08-28 20:39:03.283351: val_loss -0.5794 
2025-08-28 20:39:03.287503: Pseudo dice [np.float32(0.7705)] 
2025-08-28 20:39:03.293896: Epoch time: 15.93 s 
2025-08-28 20:39:04.001851:  
2025-08-28 20:39:04.010044: Epoch 560 
2025-08-28 20:39:04.016047: Current learning rate: 0.00478 
2025-08-28 20:39:20.446582: train_loss -0.4999 
2025-08-28 20:39:20.454699: val_loss -0.5153 
2025-08-28 20:39:20.458790: Pseudo dice [np.float32(0.7051)] 
2025-08-28 20:39:20.466969: Epoch time: 16.45 s 
2025-08-28 20:39:21.173884:  
2025-08-28 20:39:21.182446: Epoch 561 
2025-08-28 20:39:21.188546: Current learning rate: 0.00477 
2025-08-28 20:39:37.221743: train_loss -0.5357 
2025-08-28 20:39:37.229711: val_loss -0.5711 
2025-08-28 20:39:37.238427: Pseudo dice [np.float32(0.7371)] 
2025-08-28 20:39:37.245360: Epoch time: 16.05 s 
2025-08-28 20:39:37.972134:  
2025-08-28 20:39:37.982698: Epoch 562 
2025-08-28 20:39:37.991346: Current learning rate: 0.00476 
2025-08-28 20:39:53.212816: train_loss -0.5398 
2025-08-28 20:39:53.212816: val_loss -0.5815 
2025-08-28 20:39:53.224227: Pseudo dice [np.float32(0.746)] 
2025-08-28 20:39:53.229991: Epoch time: 15.24 s 
2025-08-28 20:39:54.038591:  
2025-08-28 20:39:54.038591: Epoch 563 
2025-08-28 20:39:54.046440: Current learning rate: 0.00475 
2025-08-28 20:40:08.953039: train_loss -0.5372 
2025-08-28 20:40:08.953039: val_loss -0.5543 
2025-08-28 20:40:08.964154: Pseudo dice [np.float32(0.6804)] 
2025-08-28 20:40:08.970500: Epoch time: 14.92 s 
2025-08-28 20:40:09.650638:  
2025-08-28 20:40:09.663575: Epoch 564 
2025-08-28 20:40:09.672462: Current learning rate: 0.00474 
2025-08-28 20:40:24.489388: train_loss -0.4988 
2025-08-28 20:40:24.497764: val_loss -0.5483 
2025-08-28 20:40:24.501919: Pseudo dice [np.float32(0.7555)] 
2025-08-28 20:40:24.509848: Epoch time: 14.84 s 
2025-08-28 20:40:25.168083:  
2025-08-28 20:40:25.176479: Epoch 565 
2025-08-28 20:40:25.186720: Current learning rate: 0.00473 
2025-08-28 20:40:39.310099: train_loss -0.5289 
2025-08-28 20:40:39.316709: val_loss -0.556 
2025-08-28 20:40:39.320862: Pseudo dice [np.float32(0.7269)] 
2025-08-28 20:40:39.329262: Epoch time: 14.14 s 
2025-08-28 20:40:39.972568:  
2025-08-28 20:40:39.980175: Epoch 566 
2025-08-28 20:40:39.985078: Current learning rate: 0.00472 
2025-08-28 20:40:54.514031: train_loss -0.5546 
2025-08-28 20:40:54.522381: val_loss -0.5831 
2025-08-28 20:40:54.529717: Pseudo dice [np.float32(0.7533)] 
2025-08-28 20:40:54.543712: Epoch time: 14.54 s 
2025-08-28 20:40:55.190854:  
2025-08-28 20:40:55.199121: Epoch 567 
2025-08-28 20:40:55.204412: Current learning rate: 0.00471 
2025-08-28 20:41:10.476997: train_loss -0.5063 
2025-08-28 20:41:10.485423: val_loss -0.5611 
2025-08-28 20:41:10.493915: Pseudo dice [np.float32(0.7337)] 
2025-08-28 20:41:10.499781: Epoch time: 15.29 s 
2025-08-28 20:41:11.135864:  
2025-08-28 20:41:11.144178: Epoch 568 
2025-08-28 20:41:11.151590: Current learning rate: 0.0047 
2025-08-28 20:41:25.216754: train_loss -0.5059 
2025-08-28 20:41:25.225041: val_loss -0.5176 
2025-08-28 20:41:25.233407: Pseudo dice [np.float32(0.7139)] 
2025-08-28 20:41:25.238331: Epoch time: 14.08 s 
2025-08-28 20:41:25.881969:  
2025-08-28 20:41:25.890299: Epoch 569 
2025-08-28 20:41:25.897576: Current learning rate: 0.00469 
2025-08-28 20:41:41.396001: train_loss -0.4727 
2025-08-28 20:41:41.403690: val_loss -0.5794 
2025-08-28 20:41:41.407871: Pseudo dice [np.float32(0.7352)] 
2025-08-28 20:41:41.415825: Epoch time: 15.52 s 
2025-08-28 20:41:42.213849:  
2025-08-28 20:41:42.222176: Epoch 570 
2025-08-28 20:41:42.227352: Current learning rate: 0.00468 
2025-08-28 20:41:56.660622: train_loss -0.5284 
2025-08-28 20:41:56.673328: val_loss -0.5889 
2025-08-28 20:41:56.678899: Pseudo dice [np.float32(0.7327)] 
2025-08-28 20:41:56.686191: Epoch time: 14.45 s 
2025-08-28 20:41:57.333353:  
2025-08-28 20:41:57.341491: Epoch 571 
2025-08-28 20:41:57.345652: Current learning rate: 0.00467 
2025-08-28 20:42:11.479689: train_loss -0.4583 
2025-08-28 20:42:11.488147: val_loss -0.4358 
2025-08-28 20:42:11.496255: Pseudo dice [np.float32(0.6144)] 
2025-08-28 20:42:11.501595: Epoch time: 14.15 s 
2025-08-28 20:42:12.147927:  
2025-08-28 20:42:12.155167: Epoch 572 
2025-08-28 20:42:12.160521: Current learning rate: 0.00466 
2025-08-28 20:42:27.078124: train_loss -0.509 
2025-08-28 20:42:27.082703: val_loss -0.5335 
2025-08-28 20:42:27.090977: Pseudo dice [np.float32(0.6413)] 
2025-08-28 20:42:27.096981: Epoch time: 14.93 s 
2025-08-28 20:42:27.754057:  
2025-08-28 20:42:27.761399: Epoch 573 
2025-08-28 20:42:27.766488: Current learning rate: 0.00465 
2025-08-28 20:42:42.610848: train_loss -0.5327 
2025-08-28 20:42:42.619279: val_loss -0.5381 
2025-08-28 20:42:42.623161: Pseudo dice [np.float32(0.6731)] 
2025-08-28 20:42:42.631304: Epoch time: 14.86 s 
2025-08-28 20:42:43.286280:  
2025-08-28 20:42:43.293508: Epoch 574 
2025-08-28 20:42:43.298823: Current learning rate: 0.00464 
2025-08-28 20:42:58.251555: train_loss -0.5469 
2025-08-28 20:42:58.259860: val_loss -0.6016 
2025-08-28 20:42:58.267949: Pseudo dice [np.float32(0.7874)] 
2025-08-28 20:42:58.272830: Epoch time: 14.97 s 
2025-08-28 20:42:58.930981:  
2025-08-28 20:42:58.939312: Epoch 575 
2025-08-28 20:42:58.944632: Current learning rate: 0.00463 
2025-08-28 20:43:14.050434: train_loss -0.5435 
2025-08-28 20:43:14.058951: val_loss -0.5265 
2025-08-28 20:43:14.063129: Pseudo dice [np.float32(0.7465)] 
2025-08-28 20:43:14.068785: Epoch time: 15.12 s 
2025-08-28 20:43:14.867774:  
2025-08-28 20:43:14.875019: Epoch 576 
2025-08-28 20:43:14.880199: Current learning rate: 0.00462 
2025-08-28 20:43:29.786915: train_loss -0.5122 
2025-08-28 20:43:29.795249: val_loss -0.5368 
2025-08-28 20:43:29.799455: Pseudo dice [np.float32(0.7308)] 
2025-08-28 20:43:29.808540: Epoch time: 14.92 s 
2025-08-28 20:43:30.463691:  
2025-08-28 20:43:30.473009: Epoch 577 
2025-08-28 20:43:30.481442: Current learning rate: 0.00461 
2025-08-28 20:43:44.610184: train_loss -0.5081 
2025-08-28 20:43:44.618389: val_loss -0.5659 
2025-08-28 20:43:44.622485: Pseudo dice [np.float32(0.7749)] 
2025-08-28 20:43:44.630585: Epoch time: 14.15 s 
2025-08-28 20:43:45.283629:  
2025-08-28 20:43:45.292117: Epoch 578 
2025-08-28 20:43:45.303053: Current learning rate: 0.0046 
2025-08-28 20:44:00.063214: train_loss -0.559 
2025-08-28 20:44:00.071325: val_loss -0.5855 
2025-08-28 20:44:00.079797: Pseudo dice [np.float32(0.7504)] 
2025-08-28 20:44:00.084991: Epoch time: 14.78 s 
2025-08-28 20:44:00.738504:  
2025-08-28 20:44:00.746922: Epoch 579 
2025-08-28 20:44:00.755325: Current learning rate: 0.00459 
2025-08-28 20:44:16.542371: train_loss -0.5226 
2025-08-28 20:44:16.550604: val_loss -0.5977 
2025-08-28 20:44:16.558636: Pseudo dice [np.float32(0.8026)] 
2025-08-28 20:44:16.564901: Epoch time: 15.8 s 
2025-08-28 20:44:17.274879:  
2025-08-28 20:44:17.282705: Epoch 580 
2025-08-28 20:44:17.291668: Current learning rate: 0.00458 
2025-08-28 20:44:33.404628: train_loss -0.5049 
2025-08-28 20:44:33.412962: val_loss -0.4288 
2025-08-28 20:44:33.421293: Pseudo dice [np.float32(0.5351)] 
2025-08-28 20:44:33.426771: Epoch time: 16.13 s 
2025-08-28 20:44:34.154832:  
2025-08-28 20:44:34.162626: Epoch 581 
2025-08-28 20:44:34.170337: Current learning rate: 0.00457 
2025-08-28 20:44:50.321520: train_loss -0.468 
2025-08-28 20:44:50.330178: val_loss -0.5435 
2025-08-28 20:44:50.338207: Pseudo dice [np.float32(0.7502)] 
2025-08-28 20:44:50.344547: Epoch time: 16.17 s 
2025-08-28 20:44:51.067091:  
2025-08-28 20:44:51.076305: Epoch 582 
2025-08-28 20:44:51.084304: Current learning rate: 0.00456 
2025-08-28 20:45:07.171903: train_loss -0.5151 
2025-08-28 20:45:07.184202: val_loss -0.5531 
2025-08-28 20:45:07.188996: Pseudo dice [np.float32(0.7639)] 
2025-08-28 20:45:07.195662: Epoch time: 16.11 s 
2025-08-28 20:45:08.050602:  
2025-08-28 20:45:08.059968: Epoch 583 
2025-08-28 20:45:08.068492: Current learning rate: 0.00455 
2025-08-28 20:45:24.268142: train_loss -0.5404 
2025-08-28 20:45:24.276240: val_loss -0.5502 
2025-08-28 20:45:24.280423: Pseudo dice [np.float32(0.7645)] 
2025-08-28 20:45:24.289119: Epoch time: 16.22 s 
2025-08-28 20:45:24.999902:  
2025-08-28 20:45:25.010339: Epoch 584 
2025-08-28 20:45:25.018155: Current learning rate: 0.00454 
2025-08-28 20:45:40.772189: train_loss -0.4997 
2025-08-28 20:45:40.780217: val_loss -0.5369 
2025-08-28 20:45:40.788598: Pseudo dice [np.float32(0.7073)] 
2025-08-28 20:45:40.794659: Epoch time: 15.77 s 
2025-08-28 20:45:41.518490:  
2025-08-28 20:45:41.526825: Epoch 585 
2025-08-28 20:45:41.533018: Current learning rate: 0.00453 
2025-08-28 20:45:57.217460: train_loss -0.5566 
2025-08-28 20:45:57.225827: val_loss -0.5818 
2025-08-28 20:45:57.234463: Pseudo dice [np.float32(0.7526)] 
2025-08-28 20:45:57.239123: Epoch time: 15.7 s 
2025-08-28 20:45:57.955531:  
2025-08-28 20:45:57.965273: Epoch 586 
2025-08-28 20:45:57.974859: Current learning rate: 0.00452 
2025-08-28 20:46:14.030358: train_loss -0.5703 
2025-08-28 20:46:14.038463: val_loss -0.6188 
2025-08-28 20:46:14.042864: Pseudo dice [np.float32(0.7897)] 
2025-08-28 20:46:14.052037: Epoch time: 16.08 s 
2025-08-28 20:46:14.778683:  
2025-08-28 20:46:14.787057: Epoch 587 
2025-08-28 20:46:14.793540: Current learning rate: 0.00451 
2025-08-28 20:46:30.851048: train_loss -0.5277 
2025-08-28 20:46:30.859394: val_loss -0.513 
2025-08-28 20:46:30.863563: Pseudo dice [np.float32(0.6995)] 
2025-08-28 20:46:30.872649: Epoch time: 16.07 s 
2025-08-28 20:46:31.579889:  
2025-08-28 20:46:31.586249: Epoch 588 
2025-08-28 20:46:31.595454: Current learning rate: 0.0045 
2025-08-28 20:46:47.609462: train_loss -0.5159 
2025-08-28 20:46:47.618122: val_loss -0.5526 
2025-08-28 20:46:47.626408: Pseudo dice [np.float32(0.7295)] 
2025-08-28 20:46:47.631743: Epoch time: 16.03 s 
2025-08-28 20:46:48.379011:  
2025-08-28 20:46:48.387237: Epoch 589 
2025-08-28 20:46:48.391459: Current learning rate: 0.00449 
2025-08-28 20:47:04.405844: train_loss -0.5284 
2025-08-28 20:47:04.417901: val_loss -0.5945 
2025-08-28 20:47:04.422391: Pseudo dice [np.float32(0.7443)] 
2025-08-28 20:47:04.430420: Epoch time: 16.03 s 
2025-08-28 20:47:05.305234:  
2025-08-28 20:47:05.312459: Epoch 590 
2025-08-28 20:47:05.317700: Current learning rate: 0.00448 
2025-08-28 20:47:21.639522: train_loss -0.486 
2025-08-28 20:47:21.647615: val_loss -0.5627 
2025-08-28 20:47:21.651738: Pseudo dice [np.float32(0.6666)] 
2025-08-28 20:47:21.659967: Epoch time: 16.34 s 
2025-08-28 20:47:22.367057:  
2025-08-28 20:47:22.378514: Epoch 591 
2025-08-28 20:47:22.385795: Current learning rate: 0.00447 
2025-08-28 20:47:38.356272: train_loss -0.5152 
2025-08-28 20:47:38.364273: val_loss -0.4999 
2025-08-28 20:47:38.372919: Pseudo dice [np.float32(0.7294)] 
2025-08-28 20:47:38.378197: Epoch time: 15.99 s 
2025-08-28 20:47:39.092023:  
2025-08-28 20:47:39.102404: Epoch 592 
2025-08-28 20:47:39.113864: Current learning rate: 0.00446 
2025-08-28 20:47:55.481409: train_loss -0.5422 
2025-08-28 20:47:55.489723: val_loss -0.5215 
2025-08-28 20:47:55.493783: Pseudo dice [np.float32(0.734)] 
2025-08-28 20:47:55.502997: Epoch time: 16.39 s 
2025-08-28 20:47:56.235419:  
2025-08-28 20:47:56.244633: Epoch 593 
2025-08-28 20:47:56.251926: Current learning rate: 0.00445 
2025-08-28 20:48:12.331743: train_loss -0.5145 
2025-08-28 20:48:12.344049: val_loss -0.5805 
2025-08-28 20:48:12.348225: Pseudo dice [np.float32(0.7551)] 
2025-08-28 20:48:12.353750: Epoch time: 16.1 s 
2025-08-28 20:48:13.062599:  
2025-08-28 20:48:13.072022: Epoch 594 
2025-08-28 20:48:13.078474: Current learning rate: 0.00444 
2025-08-28 20:48:29.085777: train_loss -0.5215 
2025-08-28 20:48:29.094115: val_loss -0.5717 
2025-08-28 20:48:29.098287: Pseudo dice [np.float32(0.7411)] 
2025-08-28 20:48:29.106901: Epoch time: 16.03 s 
2025-08-28 20:48:29.846730:  
2025-08-28 20:48:29.858093: Epoch 595 
2025-08-28 20:48:29.865756: Current learning rate: 0.00443 
2025-08-28 20:48:46.240734: train_loss -0.4971 
2025-08-28 20:48:46.248780: val_loss -0.5473 
2025-08-28 20:48:46.257112: Pseudo dice [np.float32(0.7223)] 
2025-08-28 20:48:46.262042: Epoch time: 16.4 s 
2025-08-28 20:48:47.116534:  
2025-08-28 20:48:47.126977: Epoch 596 
2025-08-28 20:48:47.134969: Current learning rate: 0.00442 
2025-08-28 20:49:03.757910: train_loss -0.5077 
2025-08-28 20:49:03.770469: val_loss -0.4706 
2025-08-28 20:49:03.774629: Pseudo dice [np.float32(0.6724)] 
2025-08-28 20:49:03.780753: Epoch time: 16.64 s 
2025-08-28 20:49:04.501880:  
2025-08-28 20:49:04.509068: Epoch 597 
2025-08-28 20:49:04.515840: Current learning rate: 0.00441 
2025-08-28 20:49:20.937444: train_loss -0.5365 
2025-08-28 20:49:20.945889: val_loss -0.5009 
2025-08-28 20:49:20.954218: Pseudo dice [np.float32(0.763)] 
2025-08-28 20:49:20.959729: Epoch time: 16.44 s 
2025-08-28 20:49:21.669556:  
2025-08-28 20:49:21.680619: Epoch 598 
2025-08-28 20:49:21.688231: Current learning rate: 0.0044 
2025-08-28 20:49:38.046608: train_loss -0.4989 
2025-08-28 20:49:38.054631: val_loss -0.5309 
2025-08-28 20:49:38.058799: Pseudo dice [np.float32(0.7582)] 
2025-08-28 20:49:38.067987: Epoch time: 16.38 s 
2025-08-28 20:49:38.773017:  
2025-08-28 20:49:38.780263: Epoch 599 
2025-08-28 20:49:38.784409: Current learning rate: 0.00439 
2025-08-28 20:49:55.713912: train_loss -0.5337 
2025-08-28 20:49:55.722279: val_loss -0.5507 
2025-08-28 20:49:55.730614: Pseudo dice [np.float32(0.7609)] 
2025-08-28 20:49:55.737010: Epoch time: 16.94 s 
2025-08-28 20:49:56.648707:  
2025-08-28 20:49:56.659044: Epoch 600 
2025-08-28 20:49:56.665126: Current learning rate: 0.00438 
2025-08-28 20:50:12.947812: train_loss -0.527 
2025-08-28 20:50:12.956165: val_loss -0.5779 
2025-08-28 20:50:12.960327: Pseudo dice [np.float32(0.7702)] 
2025-08-28 20:50:12.969584: Epoch time: 16.3 s 
2025-08-28 20:50:13.676541:  
2025-08-28 20:50:13.686161: Epoch 601 
2025-08-28 20:50:13.690141: Current learning rate: 0.00437 
2025-08-28 20:50:30.302629: train_loss -0.5126 
2025-08-28 20:50:30.311015: val_loss -0.5425 
2025-08-28 20:50:30.315147: Pseudo dice [np.float32(0.7637)] 
2025-08-28 20:50:30.323443: Epoch time: 16.63 s 
2025-08-28 20:50:31.192038:  
2025-08-28 20:50:31.200418: Epoch 602 
2025-08-28 20:50:31.206580: Current learning rate: 0.00436 
2025-08-28 20:50:47.815949: train_loss -0.5241 
2025-08-28 20:50:47.824338: val_loss -0.5268 
2025-08-28 20:50:47.832650: Pseudo dice [np.float32(0.7173)] 
2025-08-28 20:50:47.838337: Epoch time: 16.63 s 
2025-08-28 20:50:48.547201:  
2025-08-28 20:50:48.558141: Epoch 603 
2025-08-28 20:50:48.565687: Current learning rate: 0.00435 
2025-08-28 20:51:05.087799: train_loss -0.5577 
2025-08-28 20:51:05.099884: val_loss -0.6004 
2025-08-28 20:51:05.104273: Pseudo dice [np.float32(0.7358)] 
2025-08-28 20:51:05.112110: Epoch time: 16.54 s 
2025-08-28 20:51:05.839521:  
2025-08-28 20:51:05.847879: Epoch 604 
2025-08-28 20:51:05.855885: Current learning rate: 0.00434 
2025-08-28 20:51:22.517770: train_loss -0.5093 
2025-08-28 20:51:22.525664: val_loss -0.5079 
2025-08-28 20:51:22.529811: Pseudo dice [np.float32(0.7685)] 
2025-08-28 20:51:22.538163: Epoch time: 16.68 s 
2025-08-28 20:51:23.260367:  
2025-08-28 20:51:23.268539: Epoch 605 
2025-08-28 20:51:23.275261: Current learning rate: 0.00433 
2025-08-28 20:51:40.005597: train_loss -0.5534 
2025-08-28 20:51:40.014215: val_loss -0.5527 
2025-08-28 20:51:40.018416: Pseudo dice [np.float32(0.7473)] 
2025-08-28 20:51:40.024083: Epoch time: 16.75 s 
2025-08-28 20:51:40.742280:  
2025-08-28 20:51:40.753352: Epoch 606 
2025-08-28 20:51:40.762320: Current learning rate: 0.00432 
2025-08-28 20:51:57.194182: train_loss -0.4926 
2025-08-28 20:51:57.206383: val_loss -0.62 
2025-08-28 20:51:57.210264: Pseudo dice [np.float32(0.7743)] 
2025-08-28 20:51:57.219310: Epoch time: 16.45 s 
2025-08-28 20:51:57.906595:  
2025-08-28 20:51:57.915030: Epoch 607 
2025-08-28 20:51:57.921317: Current learning rate: 0.00431 
2025-08-28 20:52:14.644315: train_loss -0.5287 
2025-08-28 20:52:14.652660: val_loss -0.5451 
2025-08-28 20:52:14.656815: Pseudo dice [np.float32(0.7668)] 
2025-08-28 20:52:14.665947: Epoch time: 16.74 s 
2025-08-28 20:52:15.360640:  
2025-08-28 20:52:15.368983: Epoch 608 
2025-08-28 20:52:15.374038: Current learning rate: 0.0043 
2025-08-28 20:52:31.882372: train_loss -0.5634 
2025-08-28 20:52:31.890717: val_loss -0.5799 
2025-08-28 20:52:31.899091: Pseudo dice [np.float32(0.8073)] 
2025-08-28 20:52:31.905365: Epoch time: 16.52 s 
2025-08-28 20:52:32.777967:  
2025-08-28 20:52:32.787355: Epoch 609 
2025-08-28 20:52:32.795702: Current learning rate: 0.00429 
2025-08-28 20:52:49.308089: train_loss -0.5448 
2025-08-28 20:52:49.316476: val_loss -0.6021 
2025-08-28 20:52:49.320645: Pseudo dice [np.float32(0.8024)] 
2025-08-28 20:52:49.327058: Epoch time: 16.53 s 
2025-08-28 20:52:49.333639: Yayy! New best EMA pseudo Dice: 0.7580000162124634 
2025-08-28 20:52:50.235016:  
2025-08-28 20:52:50.243378: Epoch 610 
2025-08-28 20:52:50.249536: Current learning rate: 0.00429 
2025-08-28 20:53:06.146435: train_loss -0.5352 
2025-08-28 20:53:06.158262: val_loss -0.5614 
2025-08-28 20:53:06.162440: Pseudo dice [np.float32(0.744)] 
2025-08-28 20:53:06.170761: Epoch time: 15.91 s 
2025-08-28 20:53:06.867243:  
2025-08-28 20:53:06.875497: Epoch 611 
2025-08-28 20:53:06.880824: Current learning rate: 0.00428 
2025-08-28 20:53:22.704189: train_loss -0.5438 
2025-08-28 20:53:22.712555: val_loss -0.5672 
2025-08-28 20:53:22.720308: Pseudo dice [np.float32(0.7653)] 
2025-08-28 20:53:22.726233: Epoch time: 15.84 s 
2025-08-28 20:53:23.459891:  
2025-08-28 20:53:23.469234: Epoch 612 
2025-08-28 20:53:23.479071: Current learning rate: 0.00427 
2025-08-28 20:53:39.654301: train_loss -0.5137 
2025-08-28 20:53:39.662534: val_loss -0.581 
2025-08-28 20:53:39.671210: Pseudo dice [np.float32(0.7833)] 
2025-08-28 20:53:39.677166: Epoch time: 16.2 s 
2025-08-28 20:53:39.683250: Yayy! New best EMA pseudo Dice: 0.7601000070571899 
2025-08-28 20:53:40.577081:  
2025-08-28 20:53:40.587381: Epoch 613 
2025-08-28 20:53:40.593701: Current learning rate: 0.00426 
2025-08-28 20:53:56.379244: train_loss -0.5155 
2025-08-28 20:53:56.391744: val_loss -0.5541 
2025-08-28 20:53:56.395928: Pseudo dice [np.float32(0.7496)] 
2025-08-28 20:53:56.405142: Epoch time: 15.8 s 
2025-08-28 20:53:57.142719:  
2025-08-28 20:53:57.153038: Epoch 614 
2025-08-28 20:53:57.162915: Current learning rate: 0.00425 
2025-08-28 20:54:13.066984: train_loss -0.5185 
2025-08-28 20:54:13.075105: val_loss -0.5208 
2025-08-28 20:54:13.079534: Pseudo dice [np.float32(0.7254)] 
2025-08-28 20:54:13.088484: Epoch time: 15.93 s 
2025-08-28 20:54:13.999871:  
2025-08-28 20:54:14.008227: Epoch 615 
2025-08-28 20:54:14.015478: Current learning rate: 0.00424 
2025-08-28 20:54:29.829070: train_loss -0.5241 
2025-08-28 20:54:29.837707: val_loss -0.5635 
2025-08-28 20:54:29.841915: Pseudo dice [np.float32(0.7641)] 
2025-08-28 20:54:29.847949: Epoch time: 15.83 s 
2025-08-28 20:54:30.544634:  
2025-08-28 20:54:30.555098: Epoch 616 
2025-08-28 20:54:30.562627: Current learning rate: 0.00423 
2025-08-28 20:54:46.508256: train_loss -0.5255 
2025-08-28 20:54:46.512866: val_loss -0.5443 
2025-08-28 20:54:46.521009: Pseudo dice [np.float32(0.773)] 
2025-08-28 20:54:46.526270: Epoch time: 15.96 s 
2025-08-28 20:54:47.228876:  
2025-08-28 20:54:47.237261: Epoch 617 
2025-08-28 20:54:47.246842: Current learning rate: 0.00422 
2025-08-28 20:55:03.312737: train_loss -0.5586 
2025-08-28 20:55:03.321191: val_loss -0.5369 
2025-08-28 20:55:03.329428: Pseudo dice [np.float32(0.6854)] 
2025-08-28 20:55:03.335001: Epoch time: 16.09 s 
2025-08-28 20:55:04.043828:  
2025-08-28 20:55:04.053859: Epoch 618 
2025-08-28 20:55:04.061356: Current learning rate: 0.00421 
2025-08-28 20:55:20.205172: train_loss -0.5194 
2025-08-28 20:55:20.213239: val_loss -0.6038 
2025-08-28 20:55:20.220058: Pseudo dice [np.float32(0.7941)] 
2025-08-28 20:55:20.226336: Epoch time: 16.16 s 
2025-08-28 20:55:20.959896:  
2025-08-28 20:55:20.964018: Epoch 619 
2025-08-28 20:55:20.973083: Current learning rate: 0.0042 
2025-08-28 20:55:37.226190: train_loss -0.5133 
2025-08-28 20:55:37.234161: val_loss -0.5775 
2025-08-28 20:55:37.242576: Pseudo dice [np.float32(0.7959)] 
2025-08-28 20:55:37.249281: Epoch time: 16.27 s 
2025-08-28 20:55:37.974422:  
2025-08-28 20:55:37.985662: Epoch 620 
2025-08-28 20:55:37.995247: Current learning rate: 0.00419 
2025-08-28 20:55:54.163515: train_loss -0.5414 
2025-08-28 20:55:54.171859: val_loss -0.5459 
2025-08-28 20:55:54.176360: Pseudo dice [np.float32(0.7305)] 
2025-08-28 20:55:54.183148: Epoch time: 16.19 s 
2025-08-28 20:55:54.921433:  
2025-08-28 20:55:54.929858: Epoch 621 
2025-08-28 20:55:54.938332: Current learning rate: 0.00418 
2025-08-28 20:56:10.938837: train_loss -0.5844 
2025-08-28 20:56:10.951406: val_loss -0.5886 
2025-08-28 20:56:10.955286: Pseudo dice [np.float32(0.773)] 
2025-08-28 20:56:10.963494: Epoch time: 16.02 s 
2025-08-28 20:56:11.843637:  
2025-08-28 20:56:11.850949: Epoch 622 
2025-08-28 20:56:11.856082: Current learning rate: 0.00417 
2025-08-28 20:56:27.867978: train_loss -0.5367 
2025-08-28 20:56:27.876353: val_loss -0.5979 
2025-08-28 20:56:27.880486: Pseudo dice [np.float32(0.783)] 
2025-08-28 20:56:27.888304: Epoch time: 16.03 s 
2025-08-28 20:56:27.894394: Yayy! New best EMA pseudo Dice: 0.7605999708175659 
2025-08-28 20:56:28.829871:  
2025-08-28 20:56:28.837663: Epoch 623 
2025-08-28 20:56:28.845712: Current learning rate: 0.00416 
2025-08-28 20:56:44.668103: train_loss -0.5306 
2025-08-28 20:56:44.676468: val_loss -0.4932 
2025-08-28 20:56:44.684778: Pseudo dice [np.float32(0.754)] 
2025-08-28 20:56:44.690243: Epoch time: 15.84 s 
2025-08-28 20:56:45.416790:  
2025-08-28 20:56:45.427275: Epoch 624 
2025-08-28 20:56:45.436178: Current learning rate: 0.00415 
2025-08-28 20:57:01.276392: train_loss -0.5537 
2025-08-28 20:57:01.288876: val_loss -0.5498 
2025-08-28 20:57:01.293366: Pseudo dice [np.float32(0.7913)] 
2025-08-28 20:57:01.300086: Epoch time: 15.86 s 
2025-08-28 20:57:01.306079: Yayy! New best EMA pseudo Dice: 0.7630000114440918 
2025-08-28 20:57:02.212717:  
2025-08-28 20:57:02.223819: Epoch 625 
2025-08-28 20:57:02.232307: Current learning rate: 0.00414 
2025-08-28 20:57:17.776531: train_loss -0.5197 
2025-08-28 20:57:17.784561: val_loss -0.6048 
2025-08-28 20:57:17.788680: Pseudo dice [np.float32(0.7721)] 
2025-08-28 20:57:17.797161: Epoch time: 15.57 s 
2025-08-28 20:57:17.803783: Yayy! New best EMA pseudo Dice: 0.7638999819755554 
2025-08-28 20:57:18.655092:  
2025-08-28 20:57:18.664524: Epoch 626 
2025-08-28 20:57:18.669726: Current learning rate: 0.00413 
2025-08-28 20:57:33.329516: train_loss -0.4833 
2025-08-28 20:57:33.337531: val_loss -0.5452 
2025-08-28 20:57:33.341989: Pseudo dice [np.float32(0.7354)] 
2025-08-28 20:57:33.350803: Epoch time: 14.68 s 
2025-08-28 20:57:34.005905:  
2025-08-28 20:57:34.014313: Epoch 627 
2025-08-28 20:57:34.019376: Current learning rate: 0.00412 
2025-08-28 20:57:49.257659: train_loss -0.5103 
2025-08-28 20:57:49.265943: val_loss -0.5336 
2025-08-28 20:57:49.270122: Pseudo dice [np.float32(0.7609)] 
2025-08-28 20:57:49.279158: Epoch time: 15.25 s 
2025-08-28 20:57:50.079164:  
2025-08-28 20:57:50.089733: Epoch 628 
2025-08-28 20:57:50.095776: Current learning rate: 0.00411 
2025-08-28 20:58:04.446203: train_loss -0.5041 
2025-08-28 20:58:04.456126: val_loss -0.5985 
2025-08-28 20:58:04.460862: Pseudo dice [np.float32(0.7633)] 
2025-08-28 20:58:04.466432: Epoch time: 14.37 s 
2025-08-28 20:58:05.122371:  
2025-08-28 20:58:05.130655: Epoch 629 
2025-08-28 20:58:05.136963: Current learning rate: 0.0041 
2025-08-28 20:58:20.180219: train_loss -0.4986 
2025-08-28 20:58:20.188527: val_loss -0.5701 
2025-08-28 20:58:20.192652: Pseudo dice [np.float32(0.755)] 
2025-08-28 20:58:20.202005: Epoch time: 15.06 s 
2025-08-28 20:58:20.866262:  
2025-08-28 20:58:20.875522: Epoch 630 
2025-08-28 20:58:20.882962: Current learning rate: 0.00409 
2025-08-28 20:58:35.322253: train_loss -0.5119 
2025-08-28 20:58:35.328674: val_loss -0.4702 
2025-08-28 20:58:35.336945: Pseudo dice [np.float32(0.6967)] 
2025-08-28 20:58:35.342935: Epoch time: 14.46 s 
2025-08-28 20:58:36.020838:  
2025-08-28 20:58:36.032364: Epoch 631 
2025-08-28 20:58:36.042864: Current learning rate: 0.00408 
2025-08-28 20:58:50.155968: train_loss -0.5498 
2025-08-28 20:58:50.164300: val_loss -0.6369 
2025-08-28 20:58:50.168411: Pseudo dice [np.float32(0.8283)] 
2025-08-28 20:58:50.175650: Epoch time: 14.14 s 
2025-08-28 20:58:50.832631:  
2025-08-28 20:58:50.840933: Epoch 632 
2025-08-28 20:58:50.847129: Current learning rate: 0.00407 
2025-08-28 20:59:06.021760: train_loss -0.5356 
2025-08-28 20:59:06.030092: val_loss -0.5708 
2025-08-28 20:59:06.038461: Pseudo dice [np.float32(0.7532)] 
2025-08-28 20:59:06.044124: Epoch time: 15.19 s 
2025-08-28 20:59:06.696295:  
2025-08-28 20:59:06.704589: Epoch 633 
2025-08-28 20:59:06.711950: Current learning rate: 0.00406 
2025-08-28 20:59:21.449914: train_loss -0.5543 
2025-08-28 20:59:21.458038: val_loss -0.5795 
2025-08-28 20:59:21.462463: Pseudo dice [np.float32(0.8006)] 
2025-08-28 20:59:21.469304: Epoch time: 14.76 s 
2025-08-28 20:59:21.475208: Yayy! New best EMA pseudo Dice: 0.7648000121116638 
2025-08-28 20:59:22.299377:  
2025-08-28 20:59:22.307710: Epoch 634 
2025-08-28 20:59:22.316313: Current learning rate: 0.00405 
2025-08-28 20:59:37.307491: train_loss -0.571 
2025-08-28 20:59:37.315775: val_loss -0.5625 
2025-08-28 20:59:37.320040: Pseudo dice [np.float32(0.7865)] 
2025-08-28 20:59:37.326763: Epoch time: 15.01 s 
2025-08-28 20:59:37.333713: Yayy! New best EMA pseudo Dice: 0.7670000195503235 
2025-08-28 20:59:38.333062:  
2025-08-28 20:59:38.341421: Epoch 635 
2025-08-28 20:59:38.347732: Current learning rate: 0.00404 
2025-08-28 20:59:53.085405: train_loss -0.5681 
2025-08-28 20:59:53.093750: val_loss -0.5703 
2025-08-28 20:59:53.097916: Pseudo dice [np.float32(0.809)] 
2025-08-28 20:59:53.104478: Epoch time: 14.75 s 
2025-08-28 20:59:53.112827: Yayy! New best EMA pseudo Dice: 0.7712000012397766 
2025-08-28 20:59:53.938362:  
2025-08-28 20:59:53.946665: Epoch 636 
2025-08-28 20:59:53.951776: Current learning rate: 0.00403 
2025-08-28 21:00:08.509147: train_loss -0.551 
2025-08-28 21:00:08.517821: val_loss -0.5547 
2025-08-28 21:00:08.521701: Pseudo dice [np.float32(0.7244)] 
2025-08-28 21:00:08.530795: Epoch time: 14.57 s 
2025-08-28 21:00:09.184743:  
2025-08-28 21:00:09.192073: Epoch 637 
2025-08-28 21:00:09.198337: Current learning rate: 0.00402 
2025-08-28 21:00:23.286392: train_loss -0.496 
2025-08-28 21:00:23.294780: val_loss -0.525 
2025-08-28 21:00:23.303111: Pseudo dice [np.float32(0.7113)] 
2025-08-28 21:00:23.308628: Epoch time: 14.1 s 
2025-08-28 21:00:23.957801:  
2025-08-28 21:00:23.966125: Epoch 638 
2025-08-28 21:00:23.971435: Current learning rate: 0.00401 
2025-08-28 21:00:38.998532: train_loss -0.5208 
2025-08-28 21:00:39.006269: val_loss -0.4937 
2025-08-28 21:00:39.010457: Pseudo dice [np.float32(0.6556)] 
2025-08-28 21:00:39.019524: Epoch time: 15.04 s 
2025-08-28 21:00:39.690242:  
2025-08-28 21:00:39.701621: Epoch 639 
2025-08-28 21:00:39.707309: Current learning rate: 0.004 
2025-08-28 21:00:54.809623: train_loss -0.5386 
2025-08-28 21:00:54.817889: val_loss -0.612 
2025-08-28 21:00:54.826261: Pseudo dice [np.float32(0.8224)] 
2025-08-28 21:00:54.832404: Epoch time: 15.12 s 
2025-08-28 21:00:55.474910:  
2025-08-28 21:00:55.483152: Epoch 640 
2025-08-28 21:00:55.488218: Current learning rate: 0.00399 
2025-08-28 21:01:09.945504: train_loss -0.5696 
2025-08-28 21:01:09.953833: val_loss -0.5753 
2025-08-28 21:01:09.962229: Pseudo dice [np.float32(0.789)] 
2025-08-28 21:01:09.967696: Epoch time: 14.47 s 
2025-08-28 21:01:10.767027:  
2025-08-28 21:01:10.774335: Epoch 641 
2025-08-28 21:01:10.779480: Current learning rate: 0.00398 
2025-08-28 21:01:26.608214: train_loss -0.5336 
2025-08-28 21:01:26.616354: val_loss -0.5047 
2025-08-28 21:01:26.620502: Pseudo dice [np.float32(0.6255)] 
2025-08-28 21:01:26.629880: Epoch time: 15.84 s 
2025-08-28 21:01:27.345454:  
2025-08-28 21:01:27.355540: Epoch 642 
2025-08-28 21:01:27.363476: Current learning rate: 0.00397 
2025-08-28 21:01:43.303806: train_loss -0.5419 
2025-08-28 21:01:43.312158: val_loss -0.6363 
2025-08-28 21:01:43.316339: Pseudo dice [np.float32(0.8253)] 
2025-08-28 21:01:43.324545: Epoch time: 15.96 s 
2025-08-28 21:01:44.009780:  
2025-08-28 21:01:44.018038: Epoch 643 
2025-08-28 21:01:44.023283: Current learning rate: 0.00396 
2025-08-28 21:01:59.665914: train_loss -0.5864 
2025-08-28 21:01:59.678783: val_loss -0.5879 
2025-08-28 21:01:59.682679: Pseudo dice [np.float32(0.7876)] 
2025-08-28 21:01:59.689936: Epoch time: 15.66 s 
2025-08-28 21:02:00.393804:  
2025-08-28 21:02:00.401060: Epoch 644 
2025-08-28 21:02:00.407209: Current learning rate: 0.00395 
2025-08-28 21:02:16.449404: train_loss -0.5461 
2025-08-28 21:02:16.458073: val_loss -0.515 
2025-08-28 21:02:16.461920: Pseudo dice [np.float32(0.7327)] 
2025-08-28 21:02:16.471073: Epoch time: 16.06 s 
2025-08-28 21:02:17.190473:  
2025-08-28 21:02:17.200588: Epoch 645 
2025-08-28 21:02:17.208480: Current learning rate: 0.00394 
2025-08-28 21:02:32.970097: train_loss -0.5083 
2025-08-28 21:02:32.980145: val_loss -0.6039 
2025-08-28 21:02:32.988353: Pseudo dice [np.float32(0.7657)] 
2025-08-28 21:02:32.992917: Epoch time: 15.78 s 
2025-08-28 21:02:33.685429:  
2025-08-28 21:02:33.693640: Epoch 646 
2025-08-28 21:02:33.698816: Current learning rate: 0.00393 
2025-08-28 21:02:49.841380: train_loss -0.543 
2025-08-28 21:02:49.849428: val_loss -0.5583 
2025-08-28 21:02:49.858384: Pseudo dice [np.float32(0.7619)] 
2025-08-28 21:02:49.863889: Epoch time: 16.16 s 
2025-08-28 21:02:50.562491:  
2025-08-28 21:02:50.569803: Epoch 647 
2025-08-28 21:02:50.577237: Current learning rate: 0.00392 
2025-08-28 21:03:06.753805: train_loss -0.576 
2025-08-28 21:03:06.762158: val_loss -0.6237 
2025-08-28 21:03:06.766629: Pseudo dice [np.float32(0.7866)] 
2025-08-28 21:03:06.774744: Epoch time: 16.19 s 
2025-08-28 21:03:07.639076:  
2025-08-28 21:03:07.649535: Epoch 648 
2025-08-28 21:03:07.656447: Current learning rate: 0.00391 
2025-08-28 21:03:23.745866: train_loss -0.5762 
2025-08-28 21:03:23.754457: val_loss -0.6074 
2025-08-28 21:03:23.762463: Pseudo dice [np.float32(0.7367)] 
2025-08-28 21:03:23.767950: Epoch time: 16.11 s 
2025-08-28 21:03:24.495383:  
2025-08-28 21:03:24.501789: Epoch 649 
2025-08-28 21:03:24.505140: Current learning rate: 0.0039 
2025-08-28 21:03:40.379090: train_loss -0.5399 
2025-08-28 21:03:40.387400: val_loss -0.5548 
2025-08-28 21:03:40.391605: Pseudo dice [np.float32(0.7717)] 
2025-08-28 21:03:40.397861: Epoch time: 15.89 s 
2025-08-28 21:03:41.277874:  
2025-08-28 21:03:41.285126: Epoch 650 
2025-08-28 21:03:41.290291: Current learning rate: 0.00389 
2025-08-28 21:03:58.013368: train_loss -0.5412 
2025-08-28 21:03:58.021666: val_loss -0.5629 
2025-08-28 21:03:58.025825: Pseudo dice [np.float32(0.7335)] 
2025-08-28 21:03:58.035088: Epoch time: 16.74 s 
2025-08-28 21:03:58.710876:  
2025-08-28 21:03:58.719307: Epoch 651 
2025-08-28 21:03:58.725358: Current learning rate: 0.00388 
2025-08-28 21:04:15.497690: train_loss -0.528 
2025-08-28 21:04:15.505820: val_loss -0.5987 
2025-08-28 21:04:15.510168: Pseudo dice [np.float32(0.8053)] 
2025-08-28 21:04:15.518146: Epoch time: 16.79 s 
2025-08-28 21:04:16.212709:  
2025-08-28 21:04:16.220097: Epoch 652 
2025-08-28 21:04:16.225239: Current learning rate: 0.00387 
2025-08-28 21:04:32.722965: train_loss -0.5032 
2025-08-28 21:04:32.731320: val_loss -0.5668 
2025-08-28 21:04:32.735338: Pseudo dice [np.float32(0.7438)] 
2025-08-28 21:04:32.744578: Epoch time: 16.51 s 
2025-08-28 21:04:33.439204:  
2025-08-28 21:04:33.449312: Epoch 653 
2025-08-28 21:04:33.457534: Current learning rate: 0.00386 
2025-08-28 21:04:49.894270: train_loss -0.5244 
2025-08-28 21:04:49.902637: val_loss -0.5602 
2025-08-28 21:04:49.911008: Pseudo dice [np.float32(0.8121)] 
2025-08-28 21:04:49.915958: Epoch time: 16.46 s 
2025-08-28 21:04:50.754639:  
2025-08-28 21:04:50.762922: Epoch 654 
2025-08-28 21:04:50.770069: Current learning rate: 0.00385 
2025-08-28 21:05:07.336758: train_loss -0.5098 
2025-08-28 21:05:07.345098: val_loss -0.5329 
2025-08-28 21:05:07.349569: Pseudo dice [np.float32(0.7506)] 
2025-08-28 21:05:07.357362: Epoch time: 16.58 s 
2025-08-28 21:05:08.061307:  
2025-08-28 21:05:08.070919: Epoch 655 
2025-08-28 21:05:08.078906: Current learning rate: 0.00384 
2025-08-28 21:05:24.533435: train_loss -0.5112 
2025-08-28 21:05:24.541426: val_loss -0.4859 
2025-08-28 21:05:24.545498: Pseudo dice [np.float32(0.7604)] 
2025-08-28 21:05:24.553720: Epoch time: 16.48 s 
2025-08-28 21:05:25.236833:  
2025-08-28 21:05:25.245096: Epoch 656 
2025-08-28 21:05:25.251496: Current learning rate: 0.00383 
2025-08-28 21:05:41.746450: train_loss -0.5577 
2025-08-28 21:05:41.754739: val_loss -0.6132 
2025-08-28 21:05:41.758574: Pseudo dice [np.float32(0.7792)] 
2025-08-28 21:05:41.766273: Epoch time: 16.51 s 
2025-08-28 21:05:42.489215:  
2025-08-28 21:05:42.497823: Epoch 657 
2025-08-28 21:05:42.504043: Current learning rate: 0.00382 
2025-08-28 21:05:58.985227: train_loss -0.527 
2025-08-28 21:05:58.996621: val_loss -0.566 
2025-08-28 21:05:59.000896: Pseudo dice [np.float32(0.762)] 
2025-08-28 21:05:59.010438: Epoch time: 16.5 s 
2025-08-28 21:05:59.719192:  
2025-08-28 21:05:59.726499: Epoch 658 
2025-08-28 21:05:59.733726: Current learning rate: 0.00381 
2025-08-28 21:06:16.397649: train_loss -0.5592 
2025-08-28 21:06:16.405693: val_loss -0.6017 
2025-08-28 21:06:16.409840: Pseudo dice [np.float32(0.7997)] 
2025-08-28 21:06:16.417259: Epoch time: 16.68 s 
2025-08-28 21:06:17.120974:  
2025-08-28 21:06:17.129314: Epoch 659 
2025-08-28 21:06:17.136581: Current learning rate: 0.0038 
2025-08-28 21:06:33.935678: train_loss -0.5886 
2025-08-28 21:06:33.944024: val_loss -0.5919 
2025-08-28 21:06:33.948383: Pseudo dice [np.float32(0.7678)] 
2025-08-28 21:06:33.954464: Epoch time: 16.82 s 
2025-08-28 21:06:34.639478:  
2025-08-28 21:06:34.647754: Epoch 660 
2025-08-28 21:06:34.652920: Current learning rate: 0.00379 
2025-08-28 21:06:51.399032: train_loss -0.5414 
2025-08-28 21:06:51.407303: val_loss -0.5542 
2025-08-28 21:06:51.411516: Pseudo dice [np.float32(0.7722)] 
2025-08-28 21:06:51.419723: Epoch time: 16.76 s 
2025-08-28 21:06:52.274827:  
2025-08-28 21:06:52.284246: Epoch 661 
2025-08-28 21:06:52.294494: Current learning rate: 0.00378 
2025-08-28 21:07:09.112492: train_loss -0.5071 
2025-08-28 21:07:09.125033: val_loss -0.5037 
2025-08-28 21:07:09.129129: Pseudo dice [np.float32(0.6803)] 
2025-08-28 21:07:09.136312: Epoch time: 16.84 s 
2025-08-28 21:07:09.840221:  
2025-08-28 21:07:09.848768: Epoch 662 
2025-08-28 21:07:09.854754: Current learning rate: 0.00377 
2025-08-28 21:07:26.363348: train_loss -0.5283 
2025-08-28 21:07:26.371395: val_loss -0.4835 
2025-08-28 21:07:26.380027: Pseudo dice [np.float32(0.703)] 
2025-08-28 21:07:26.387248: Epoch time: 16.53 s 
2025-08-28 21:07:27.096426:  
2025-08-28 21:07:27.105684: Epoch 663 
2025-08-28 21:07:27.114589: Current learning rate: 0.00376 
2025-08-28 21:07:43.936749: train_loss -0.5297 
2025-08-28 21:07:43.943126: val_loss -0.5887 
2025-08-28 21:07:43.951432: Pseudo dice [np.float32(0.7941)] 
2025-08-28 21:07:43.956383: Epoch time: 16.84 s 
2025-08-28 21:07:44.637525:  
2025-08-28 21:07:44.645807: Epoch 664 
2025-08-28 21:07:44.652039: Current learning rate: 0.00375 
2025-08-28 21:08:01.431450: train_loss -0.5178 
2025-08-28 21:08:01.439751: val_loss -0.5302 
2025-08-28 21:08:01.448090: Pseudo dice [np.float32(0.6718)] 
2025-08-28 21:08:01.453004: Epoch time: 16.79 s 
2025-08-28 21:08:02.183808:  
2025-08-28 21:08:02.192445: Epoch 665 
2025-08-28 21:08:02.198757: Current learning rate: 0.00374 
2025-08-28 21:08:19.237002: train_loss -0.5459 
2025-08-28 21:08:19.245337: val_loss -0.5917 
2025-08-28 21:08:19.249462: Pseudo dice [np.float32(0.7933)] 
2025-08-28 21:08:19.257274: Epoch time: 17.06 s 
2025-08-28 21:08:19.953890:  
2025-08-28 21:08:19.961245: Epoch 666 
2025-08-28 21:08:19.966420: Current learning rate: 0.00373 
2025-08-28 21:08:36.453885: train_loss -0.5752 
2025-08-28 21:08:36.462185: val_loss -0.6418 
2025-08-28 21:08:36.466356: Pseudo dice [np.float32(0.8037)] 
2025-08-28 21:08:36.474483: Epoch time: 16.5 s 
2025-08-28 21:08:37.177500:  
2025-08-28 21:08:37.186855: Epoch 667 
2025-08-28 21:08:37.191964: Current learning rate: 0.00372 
2025-08-28 21:08:54.297141: train_loss -0.5446 
2025-08-28 21:08:54.304966: val_loss -0.5309 
2025-08-28 21:08:54.313369: Pseudo dice [np.float32(0.7306)] 
2025-08-28 21:08:54.318255: Epoch time: 17.12 s 
2025-08-28 21:08:55.180739:  
2025-08-28 21:08:55.189169: Epoch 668 
2025-08-28 21:08:55.194474: Current learning rate: 0.00371 
2025-08-28 21:09:11.626471: train_loss -0.5449 
2025-08-28 21:09:11.639052: val_loss -0.578 
2025-08-28 21:09:11.647087: Pseudo dice [np.float32(0.7623)] 
2025-08-28 21:09:11.652251: Epoch time: 16.45 s 
2025-08-28 21:09:12.372917:  
2025-08-28 21:09:12.381347: Epoch 669 
2025-08-28 21:09:12.387576: Current learning rate: 0.0037 
2025-08-28 21:09:29.225822: train_loss -0.5178 
2025-08-28 21:09:29.235016: val_loss -0.5183 
2025-08-28 21:09:29.239883: Pseudo dice [np.float32(0.7503)] 
2025-08-28 21:09:29.246253: Epoch time: 16.85 s 
2025-08-28 21:09:29.950951:  
2025-08-28 21:09:29.960396: Epoch 670 
2025-08-28 21:09:29.970616: Current learning rate: 0.00369 
2025-08-28 21:09:46.586415: train_loss -0.5361 
2025-08-28 21:09:46.594732: val_loss -0.5215 
2025-08-28 21:09:46.603076: Pseudo dice [np.float32(0.6847)] 
2025-08-28 21:09:46.608467: Epoch time: 16.64 s 
2025-08-28 21:09:47.325728:  
2025-08-28 21:09:47.337625: Epoch 671 
2025-08-28 21:09:47.344523: Current learning rate: 0.00368 
2025-08-28 21:10:03.791546: train_loss -0.5721 
2025-08-28 21:10:03.803590: val_loss -0.6042 
2025-08-28 21:10:03.807749: Pseudo dice [np.float32(0.7842)] 
2025-08-28 21:10:03.815034: Epoch time: 16.47 s 
2025-08-28 21:10:04.547133:  
2025-08-28 21:10:04.557364: Epoch 672 
2025-08-28 21:10:04.563081: Current learning rate: 0.00367 
2025-08-28 21:10:21.250739: train_loss -0.5393 
2025-08-28 21:10:21.258512: val_loss -0.5874 
2025-08-28 21:10:21.262683: Pseudo dice [np.float32(0.8051)] 
2025-08-28 21:10:21.272284: Epoch time: 16.7 s 
2025-08-28 21:10:21.985317:  
2025-08-28 21:10:21.992593: Epoch 673 
2025-08-28 21:10:21.997774: Current learning rate: 0.00366 
2025-08-28 21:10:38.634373: train_loss -0.5582 
2025-08-28 21:10:38.642532: val_loss -0.4889 
2025-08-28 21:10:38.650889: Pseudo dice [np.float32(0.7302)] 
2025-08-28 21:10:38.656425: Epoch time: 16.65 s 
2025-08-28 21:10:39.505891:  
2025-08-28 21:10:39.515730: Epoch 674 
2025-08-28 21:10:39.522355: Current learning rate: 0.00365 
2025-08-28 21:10:56.422860: train_loss -0.5353 
2025-08-28 21:10:56.435310: val_loss -0.5265 
2025-08-28 21:10:56.439511: Pseudo dice [np.float32(0.7542)] 
2025-08-28 21:10:56.446762: Epoch time: 16.92 s 
2025-08-28 21:10:57.144286:  
2025-08-28 21:10:57.153691: Epoch 675 
2025-08-28 21:10:57.160876: Current learning rate: 0.00364 
2025-08-28 21:11:13.856855: train_loss -0.5442 
2025-08-28 21:11:13.864946: val_loss -0.5958 
2025-08-28 21:11:13.869667: Pseudo dice [np.float32(0.7814)] 
2025-08-28 21:11:13.875634: Epoch time: 16.71 s 
2025-08-28 21:11:14.582511:  
2025-08-28 21:11:14.589778: Epoch 676 
2025-08-28 21:11:14.596153: Current learning rate: 0.00363 
2025-08-28 21:11:31.332514: train_loss -0.583 
2025-08-28 21:11:31.340696: val_loss -0.5969 
2025-08-28 21:11:31.345481: Pseudo dice [np.float32(0.7946)] 
2025-08-28 21:11:31.352277: Epoch time: 16.75 s 
2025-08-28 21:11:32.054121:  
2025-08-28 21:11:32.061424: Epoch 677 
2025-08-28 21:11:32.067749: Current learning rate: 0.00362 
2025-08-28 21:11:48.946129: train_loss -0.5271 
2025-08-28 21:11:48.954509: val_loss -0.6229 
2025-08-28 21:11:48.958849: Pseudo dice [np.float32(0.7988)] 
2025-08-28 21:11:48.964896: Epoch time: 16.89 s 
2025-08-28 21:11:49.666476:  
2025-08-28 21:11:49.675815: Epoch 678 
2025-08-28 21:11:49.685582: Current learning rate: 0.00361 
2025-08-28 21:12:06.717977: train_loss -0.5668 
2025-08-28 21:12:06.730509: val_loss -0.5859 
2025-08-28 21:12:06.735034: Pseudo dice [np.float32(0.7839)] 
2025-08-28 21:12:06.740944: Epoch time: 17.05 s 
2025-08-28 21:12:07.428044:  
2025-08-28 21:12:07.437412: Epoch 679 
2025-08-28 21:12:07.443545: Current learning rate: 0.0036 
2025-08-28 21:12:24.469040: train_loss -0.5261 
2025-08-28 21:12:24.477400: val_loss -0.627 
2025-08-28 21:12:24.485761: Pseudo dice [np.float32(0.7675)] 
2025-08-28 21:12:24.493967: Epoch time: 17.04 s 
2025-08-28 21:12:25.203037:  
2025-08-28 21:12:25.210958: Epoch 680 
2025-08-28 21:12:25.216656: Current learning rate: 0.00359 
2025-08-28 21:12:41.974092: train_loss -0.5619 
2025-08-28 21:12:41.982577: val_loss -0.6042 
2025-08-28 21:12:41.990717: Pseudo dice [np.float32(0.7836)] 
2025-08-28 21:12:41.996967: Epoch time: 16.77 s 
2025-08-28 21:12:42.842599:  
2025-08-28 21:12:42.849750: Epoch 681 
2025-08-28 21:12:42.855133: Current learning rate: 0.00358 
2025-08-28 21:12:59.599918: train_loss -0.5741 
2025-08-28 21:12:59.612532: val_loss -0.5236 
2025-08-28 21:12:59.616906: Pseudo dice [np.float32(0.7066)] 
2025-08-28 21:12:59.624891: Epoch time: 16.76 s 
2025-08-28 21:13:00.327684:  
2025-08-28 21:13:00.335143: Epoch 682 
2025-08-28 21:13:00.340215: Current learning rate: 0.00357 
2025-08-28 21:13:17.138313: train_loss -0.5433 
2025-08-28 21:13:17.146662: val_loss -0.5699 
2025-08-28 21:13:17.155030: Pseudo dice [np.float32(0.7669)] 
2025-08-28 21:13:17.159900: Epoch time: 16.81 s 
2025-08-28 21:13:17.861861:  
2025-08-28 21:13:17.871242: Epoch 683 
2025-08-28 21:13:17.877631: Current learning rate: 0.00356 
2025-08-28 21:13:34.608515: train_loss -0.5316 
2025-08-28 21:13:34.614142: val_loss -0.5496 
2025-08-28 21:13:34.622779: Pseudo dice [np.float32(0.7981)] 
2025-08-28 21:13:34.627965: Epoch time: 16.75 s 
2025-08-28 21:13:35.349242:  
2025-08-28 21:13:35.359647: Epoch 684 
2025-08-28 21:13:35.369091: Current learning rate: 0.00355 
2025-08-28 21:13:51.714507: train_loss -0.5459 
2025-08-28 21:13:51.722857: val_loss -0.5903 
2025-08-28 21:13:51.731621: Pseudo dice [np.float32(0.7542)] 
2025-08-28 21:13:51.737555: Epoch time: 16.37 s 
2025-08-28 21:13:52.466483:  
2025-08-28 21:13:52.478322: Epoch 685 
2025-08-28 21:13:52.491330: Current learning rate: 0.00354 
2025-08-28 21:14:09.378012: train_loss -0.5114 
2025-08-28 21:14:09.386614: val_loss -0.5285 
2025-08-28 21:14:09.394670: Pseudo dice [np.float32(0.7231)] 
2025-08-28 21:14:09.399716: Epoch time: 16.91 s 
2025-08-28 21:14:10.097359:  
2025-08-28 21:14:10.104842: Epoch 686 
2025-08-28 21:14:10.110890: Current learning rate: 0.00353 
2025-08-28 21:14:26.716315: train_loss -0.5178 
2025-08-28 21:14:26.724512: val_loss -0.5314 
2025-08-28 21:14:26.728638: Pseudo dice [np.float32(0.7297)] 
2025-08-28 21:14:26.736743: Epoch time: 16.62 s 
2025-08-28 21:14:27.658569:  
2025-08-28 21:14:27.668595: Epoch 687 
2025-08-28 21:14:27.676040: Current learning rate: 0.00352 
2025-08-28 21:14:44.521703: train_loss -0.5651 
2025-08-28 21:14:44.529753: val_loss -0.5516 
2025-08-28 21:14:44.533945: Pseudo dice [np.float32(0.7561)] 
2025-08-28 21:14:44.540224: Epoch time: 16.87 s 
2025-08-28 21:14:45.245990:  
2025-08-28 21:14:45.253350: Epoch 688 
2025-08-28 21:14:45.258570: Current learning rate: 0.00351 
2025-08-28 21:15:01.822009: train_loss -0.5057 
2025-08-28 21:15:01.830369: val_loss -0.5322 
2025-08-28 21:15:01.834834: Pseudo dice [np.float32(0.7217)] 
2025-08-28 21:15:01.842677: Epoch time: 16.58 s 
2025-08-28 21:15:02.552984:  
2025-08-28 21:15:02.560189: Epoch 689 
2025-08-28 21:15:02.566463: Current learning rate: 0.0035 
2025-08-28 21:15:19.519146: train_loss -0.5565 
2025-08-28 21:15:19.527213: val_loss -0.5409 
2025-08-28 21:15:19.531354: Pseudo dice [np.float32(0.7963)] 
2025-08-28 21:15:19.539711: Epoch time: 16.97 s 
2025-08-28 21:15:20.246625:  
2025-08-28 21:15:20.255000: Epoch 690 
2025-08-28 21:15:20.261135: Current learning rate: 0.00349 
2025-08-28 21:15:36.827445: train_loss -0.5932 
2025-08-28 21:15:36.831984: val_loss -0.5623 
2025-08-28 21:15:36.840518: Pseudo dice [np.float32(0.731)] 
2025-08-28 21:15:36.845791: Epoch time: 16.58 s 
2025-08-28 21:15:37.538871:  
2025-08-28 21:15:37.547276: Epoch 691 
2025-08-28 21:15:37.552355: Current learning rate: 0.00348 
2025-08-28 21:15:54.186712: train_loss -0.5451 
2025-08-28 21:15:54.195140: val_loss -0.6001 
2025-08-28 21:15:54.199327: Pseudo dice [np.float32(0.7772)] 
2025-08-28 21:15:54.207497: Epoch time: 16.65 s 
2025-08-28 21:15:54.904390:  
2025-08-28 21:15:54.912420: Epoch 692 
2025-08-28 21:15:54.917114: Current learning rate: 0.00346 
2025-08-28 21:16:11.583599: train_loss -0.5638 
2025-08-28 21:16:11.591774: val_loss -0.5991 
2025-08-28 21:16:11.595842: Pseudo dice [np.float32(0.777)] 
2025-08-28 21:16:11.604207: Epoch time: 16.68 s 
2025-08-28 21:16:12.316302:  
2025-08-28 21:16:12.325675: Epoch 693 
2025-08-28 21:16:12.329783: Current learning rate: 0.00345 
2025-08-28 21:16:29.075814: train_loss -0.5199 
2025-08-28 21:16:29.084230: val_loss -0.5763 
2025-08-28 21:16:29.088339: Pseudo dice [np.float32(0.775)] 
2025-08-28 21:16:29.097454: Epoch time: 16.76 s 
2025-08-28 21:16:29.976631:  
2025-08-28 21:16:29.984890: Epoch 694 
2025-08-28 21:16:29.990240: Current learning rate: 0.00344 
2025-08-28 21:16:46.493573: train_loss -0.5971 
2025-08-28 21:16:46.503995: val_loss -0.5534 
2025-08-28 21:16:46.509877: Pseudo dice [np.float32(0.7932)] 
2025-08-28 21:16:46.515400: Epoch time: 16.52 s 
2025-08-28 21:16:47.232466:  
2025-08-28 21:16:47.241830: Epoch 695 
2025-08-28 21:16:47.247002: Current learning rate: 0.00343 
2025-08-28 21:17:03.793906: train_loss -0.5356 
2025-08-28 21:17:03.802443: val_loss -0.478 
2025-08-28 21:17:03.811127: Pseudo dice [np.float32(0.749)] 
2025-08-28 21:17:03.816779: Epoch time: 16.56 s 
2025-08-28 21:17:04.523717:  
2025-08-28 21:17:04.531897: Epoch 696 
2025-08-28 21:17:04.538334: Current learning rate: 0.00342 
2025-08-28 21:17:20.976003: train_loss -0.5376 
2025-08-28 21:17:20.982167: val_loss -0.6272 
2025-08-28 21:17:20.990183: Pseudo dice [np.float32(0.7544)] 
2025-08-28 21:17:20.995590: Epoch time: 16.45 s 
2025-08-28 21:17:21.689780:  
2025-08-28 21:17:21.697181: Epoch 697 
2025-08-28 21:17:21.702228: Current learning rate: 0.00341 
2025-08-28 21:17:38.341160: train_loss -0.5592 
2025-08-28 21:17:38.349648: val_loss -0.6423 
2025-08-28 21:17:38.355380: Pseudo dice [np.float32(0.8261)] 
2025-08-28 21:17:38.361393: Epoch time: 16.65 s 
2025-08-28 21:17:39.073771:  
2025-08-28 21:17:39.081064: Epoch 698 
2025-08-28 21:17:39.087263: Current learning rate: 0.0034 
2025-08-28 21:17:55.804196: train_loss -0.533 
2025-08-28 21:17:55.812570: val_loss -0.6203 
2025-08-28 21:17:55.816656: Pseudo dice [np.float32(0.8228)] 
2025-08-28 21:17:55.824795: Epoch time: 16.73 s 
2025-08-28 21:17:55.830626: Yayy! New best EMA pseudo Dice: 0.7738000154495239 
2025-08-28 21:17:56.763405:  
2025-08-28 21:17:56.771543: Epoch 699 
2025-08-28 21:17:56.777016: Current learning rate: 0.00339 
2025-08-28 21:18:13.667810: train_loss -0.5481 
2025-08-28 21:18:13.676157: val_loss -0.4628 
2025-08-28 21:18:13.680328: Pseudo dice [np.float32(0.7696)] 
2025-08-28 21:18:13.687392: Epoch time: 16.91 s 
2025-08-28 21:18:14.779313:  
2025-08-28 21:18:14.787706: Epoch 700 
2025-08-28 21:18:14.792833: Current learning rate: 0.00338 
2025-08-28 21:18:31.498045: train_loss -0.5318 
2025-08-28 21:18:31.506429: val_loss -0.5941 
2025-08-28 21:18:31.510639: Pseudo dice [np.float32(0.8059)] 
2025-08-28 21:18:31.518844: Epoch time: 16.72 s 
2025-08-28 21:18:31.524476: Yayy! New best EMA pseudo Dice: 0.7767000198364258 
2025-08-28 21:18:32.425017:  
2025-08-28 21:18:32.432294: Epoch 701 
2025-08-28 21:18:32.437456: Current learning rate: 0.00337 
2025-08-28 21:18:48.753190: train_loss -0.5392 
2025-08-28 21:18:48.761431: val_loss -0.5521 
2025-08-28 21:18:48.765396: Pseudo dice [np.float32(0.7481)] 
2025-08-28 21:18:48.774381: Epoch time: 16.33 s 
2025-08-28 21:18:49.481573:  
2025-08-28 21:18:49.489891: Epoch 702 
2025-08-28 21:18:49.495045: Current learning rate: 0.00336 
2025-08-28 21:19:06.249452: train_loss -0.5472 
2025-08-28 21:19:06.257837: val_loss -0.5846 
2025-08-28 21:19:06.261998: Pseudo dice [np.float32(0.7302)] 
2025-08-28 21:19:06.270172: Epoch time: 16.77 s 
2025-08-28 21:19:06.974990:  
2025-08-28 21:19:06.983421: Epoch 703 
2025-08-28 21:19:06.988722: Current learning rate: 0.00335 
2025-08-28 21:19:23.900404: train_loss -0.5731 
2025-08-28 21:19:23.909051: val_loss -0.6325 
2025-08-28 21:19:23.917408: Pseudo dice [np.float32(0.7833)] 
2025-08-28 21:19:23.924560: Epoch time: 16.93 s 
2025-08-28 21:19:24.623988:  
2025-08-28 21:19:24.631366: Epoch 704 
2025-08-28 21:19:24.636572: Current learning rate: 0.00334 
2025-08-28 21:19:41.105266: train_loss -0.5978 
2025-08-28 21:19:41.113433: val_loss -0.6092 
2025-08-28 21:19:41.117524: Pseudo dice [np.float32(0.8474)] 
2025-08-28 21:19:41.124796: Epoch time: 16.48 s 
2025-08-28 21:19:41.131579: Yayy! New best EMA pseudo Dice: 0.7785000205039978 
2025-08-28 21:19:42.073782:  
2025-08-28 21:19:42.084239: Epoch 705 
2025-08-28 21:19:42.092754: Current learning rate: 0.00333 
2025-08-28 21:19:58.485177: train_loss -0.5851 
2025-08-28 21:19:58.493294: val_loss -0.5266 
2025-08-28 21:19:58.497456: Pseudo dice [np.float32(0.6844)] 
2025-08-28 21:19:58.505815: Epoch time: 16.41 s 
2025-08-28 21:19:59.240447:  
2025-08-28 21:19:59.249266: Epoch 706 
2025-08-28 21:19:59.256536: Current learning rate: 0.00332 
2025-08-28 21:20:16.207035: train_loss -0.5296 
2025-08-28 21:20:16.215498: val_loss -0.5669 
2025-08-28 21:20:16.219824: Pseudo dice [np.float32(0.7494)] 
2025-08-28 21:20:16.227613: Epoch time: 16.97 s 
2025-08-28 21:20:17.096287:  
2025-08-28 21:20:17.104618: Epoch 707 
2025-08-28 21:20:17.112875: Current learning rate: 0.00331 
2025-08-28 21:20:33.724909: train_loss -0.5689 
2025-08-28 21:20:33.732661: val_loss -0.5798 
2025-08-28 21:20:33.741003: Pseudo dice [np.float32(0.7911)] 
2025-08-28 21:20:33.746512: Epoch time: 16.63 s 
2025-08-28 21:20:34.447211:  
2025-08-28 21:20:34.455272: Epoch 708 
2025-08-28 21:20:34.460348: Current learning rate: 0.0033 
2025-08-28 21:20:51.133739: train_loss -0.5541 
2025-08-28 21:20:51.141702: val_loss -0.5647 
2025-08-28 21:20:51.149921: Pseudo dice [np.float32(0.7584)] 
2025-08-28 21:20:51.155853: Epoch time: 16.69 s 
2025-08-28 21:20:51.918601:  
2025-08-28 21:20:51.931000: Epoch 709 
2025-08-28 21:20:51.938864: Current learning rate: 0.00329 
2025-08-28 21:21:08.705071: train_loss -0.5314 
2025-08-28 21:21:08.717597: val_loss -0.54 
2025-08-28 21:21:08.721761: Pseudo dice [np.float32(0.7568)] 
2025-08-28 21:21:08.729932: Epoch time: 16.79 s 
2025-08-28 21:21:09.447340:  
2025-08-28 21:21:09.455745: Epoch 710 
2025-08-28 21:21:09.463297: Current learning rate: 0.00328 
2025-08-28 21:21:26.406126: train_loss -0.5699 
2025-08-28 21:21:26.414716: val_loss -0.5822 
2025-08-28 21:21:26.422456: Pseudo dice [np.float32(0.7696)] 
2025-08-28 21:21:26.427683: Epoch time: 16.96 s 
2025-08-28 21:21:27.156767:  
2025-08-28 21:21:27.164966: Epoch 711 
2025-08-28 21:21:27.171377: Current learning rate: 0.00327 
2025-08-28 21:21:44.098768: train_loss -0.5768 
2025-08-28 21:21:44.107085: val_loss -0.5752 
2025-08-28 21:21:44.111268: Pseudo dice [np.float32(0.7916)] 
2025-08-28 21:21:44.119369: Epoch time: 16.94 s 
2025-08-28 21:21:44.862033:  
2025-08-28 21:21:44.870352: Epoch 712 
2025-08-28 21:21:44.877360: Current learning rate: 0.00326 
2025-08-28 21:22:01.341568: train_loss -0.545 
2025-08-28 21:22:01.353833: val_loss -0.5288 
2025-08-28 21:22:01.358013: Pseudo dice [np.float32(0.7)] 
2025-08-28 21:22:01.366154: Epoch time: 16.48 s 
2025-08-28 21:22:02.250114:  
2025-08-28 21:22:02.258431: Epoch 713 
2025-08-28 21:22:02.268675: Current learning rate: 0.00325 
2025-08-28 21:22:19.041660: train_loss -0.5585 
2025-08-28 21:22:19.048373: val_loss -0.5033 
2025-08-28 21:22:19.054505: Pseudo dice [np.float32(0.7487)] 
2025-08-28 21:22:19.060015: Epoch time: 16.79 s 
2025-08-28 21:22:19.760663:  
2025-08-28 21:22:19.769349: Epoch 714 
2025-08-28 21:22:19.776098: Current learning rate: 0.00324 
2025-08-28 21:22:36.267500: train_loss -0.5168 
2025-08-28 21:22:36.275872: val_loss -0.5757 
2025-08-28 21:22:36.283737: Pseudo dice [np.float32(0.7605)] 
2025-08-28 21:22:36.289139: Epoch time: 16.51 s 
2025-08-28 21:22:37.013985:  
2025-08-28 21:22:37.022409: Epoch 715 
2025-08-28 21:22:37.029092: Current learning rate: 0.00323 
2025-08-28 21:22:53.389108: train_loss -0.5518 
2025-08-28 21:22:53.397439: val_loss -0.5408 
2025-08-28 21:22:53.401629: Pseudo dice [np.float32(0.8229)] 
2025-08-28 21:22:53.409520: Epoch time: 16.38 s 
2025-08-28 21:22:54.141751:  
2025-08-28 21:22:54.152847: Epoch 716 
2025-08-28 21:22:54.159303: Current learning rate: 0.00322 
2025-08-28 21:23:10.685774: train_loss -0.5772 
2025-08-28 21:23:10.698256: val_loss -0.6194 
2025-08-28 21:23:10.706567: Pseudo dice [np.float32(0.808)] 
2025-08-28 21:23:10.715399: Epoch time: 16.55 s 
2025-08-28 21:23:11.444225:  
2025-08-28 21:23:11.453829: Epoch 717 
2025-08-28 21:23:11.463047: Current learning rate: 0.00321 
2025-08-28 21:23:27.802307: train_loss -0.5711 
2025-08-28 21:23:27.810671: val_loss -0.6505 
2025-08-28 21:23:27.814815: Pseudo dice [np.float32(0.8035)] 
2025-08-28 21:23:27.824222: Epoch time: 16.36 s 
2025-08-28 21:23:28.546767:  
2025-08-28 21:23:28.556195: Epoch 718 
2025-08-28 21:23:28.562481: Current learning rate: 0.0032 
2025-08-28 21:23:44.940251: train_loss -0.5382 
2025-08-28 21:23:44.948658: val_loss -0.6345 
2025-08-28 21:23:44.952837: Pseudo dice [np.float32(0.7812)] 
2025-08-28 21:23:44.961117: Epoch time: 16.39 s 
2025-08-28 21:23:45.672184:  
2025-08-28 21:23:45.680532: Epoch 719 
2025-08-28 21:23:45.685784: Current learning rate: 0.00319 
2025-08-28 21:24:02.286769: train_loss -0.5538 
2025-08-28 21:24:02.299321: val_loss -0.5523 
2025-08-28 21:24:02.303487: Pseudo dice [np.float32(0.7897)] 
2025-08-28 21:24:02.311123: Epoch time: 16.62 s 
2025-08-28 21:24:03.217952:  
2025-08-28 21:24:03.226295: Epoch 720 
2025-08-28 21:24:03.232478: Current learning rate: 0.00318 
2025-08-28 21:24:19.708337: train_loss -0.5992 
2025-08-28 21:24:19.716682: val_loss -0.5214 
2025-08-28 21:24:19.720818: Pseudo dice [np.float32(0.7465)] 
2025-08-28 21:24:19.727016: Epoch time: 16.49 s 
2025-08-28 21:24:20.455939:  
2025-08-28 21:24:20.463691: Epoch 721 
2025-08-28 21:24:20.473337: Current learning rate: 0.00317 
2025-08-28 21:24:37.229994: train_loss -0.5763 
2025-08-28 21:24:37.238326: val_loss -0.5682 
2025-08-28 21:24:37.242793: Pseudo dice [np.float32(0.7876)] 
2025-08-28 21:24:37.250648: Epoch time: 16.78 s 
2025-08-28 21:24:37.969239:  
2025-08-28 21:24:37.976501: Epoch 722 
2025-08-28 21:24:37.982846: Current learning rate: 0.00316 
2025-08-28 21:24:54.513932: train_loss -0.5849 
2025-08-28 21:24:54.522278: val_loss -0.5785 
2025-08-28 21:24:54.526444: Pseudo dice [np.float32(0.766)] 
2025-08-28 21:24:54.533429: Epoch time: 16.55 s 
2025-08-28 21:24:55.241666:  
2025-08-28 21:24:55.247860: Epoch 723 
2025-08-28 21:24:55.253278: Current learning rate: 0.00315 
2025-08-28 21:25:11.964830: train_loss -0.558 
2025-08-28 21:25:11.977602: val_loss -0.5644 
2025-08-28 21:25:11.981351: Pseudo dice [np.float32(0.7962)] 
2025-08-28 21:25:11.988827: Epoch time: 16.73 s 
2025-08-28 21:25:12.695644:  
2025-08-28 21:25:12.702774: Epoch 724 
2025-08-28 21:25:12.708208: Current learning rate: 0.00314 
2025-08-28 21:25:29.327766: train_loss -0.4978 
2025-08-28 21:25:29.336214: val_loss -0.5859 
2025-08-28 21:25:29.344679: Pseudo dice [np.float32(0.7537)] 
2025-08-28 21:25:29.352050: Epoch time: 16.63 s 
2025-08-28 21:25:30.072353:  
2025-08-28 21:25:30.082584: Epoch 725 
2025-08-28 21:25:30.089971: Current learning rate: 0.00313 
2025-08-28 21:25:46.737449: train_loss -0.5581 
2025-08-28 21:25:46.745236: val_loss -0.5693 
2025-08-28 21:25:46.749412: Pseudo dice [np.float32(0.8055)] 
2025-08-28 21:25:46.758084: Epoch time: 16.67 s 
2025-08-28 21:25:47.622195:  
2025-08-28 21:25:47.629298: Epoch 726 
2025-08-28 21:25:47.637536: Current learning rate: 0.00312 
2025-08-28 21:26:03.954098: train_loss -0.5602 
2025-08-28 21:26:03.966616: val_loss -0.5372 
2025-08-28 21:26:03.970791: Pseudo dice [np.float32(0.7989)] 
2025-08-28 21:26:03.978326: Epoch time: 16.33 s 
2025-08-28 21:26:03.984717: Yayy! New best EMA pseudo Dice: 0.7795000076293945 
2025-08-28 21:26:04.906147:  
2025-08-28 21:26:04.913231: Epoch 727 
2025-08-28 21:26:04.921587: Current learning rate: 0.00311 
2025-08-28 21:26:21.688781: train_loss -0.5539 
2025-08-28 21:26:21.696824: val_loss -0.5616 
2025-08-28 21:26:21.701281: Pseudo dice [np.float32(0.7786)] 
2025-08-28 21:26:21.710278: Epoch time: 16.78 s 
2025-08-28 21:26:22.423562:  
2025-08-28 21:26:22.431926: Epoch 728 
2025-08-28 21:26:22.442769: Current learning rate: 0.0031 
2025-08-28 21:26:38.976562: train_loss -0.5821 
2025-08-28 21:26:38.984781: val_loss -0.6199 
2025-08-28 21:26:38.989369: Pseudo dice [np.float32(0.8303)] 
2025-08-28 21:26:38.995396: Epoch time: 16.56 s 
2025-08-28 21:26:39.001561: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-08-28 21:26:39.918102:  
2025-08-28 21:26:39.926358: Epoch 729 
2025-08-28 21:26:39.932952: Current learning rate: 0.00309 
2025-08-28 21:26:56.564563: train_loss -0.5394 
2025-08-28 21:26:56.573379: val_loss -0.6202 
2025-08-28 21:26:56.577511: Pseudo dice [np.float32(0.8057)] 
2025-08-28 21:26:56.584596: Epoch time: 16.65 s 
2025-08-28 21:26:56.591327: Yayy! New best EMA pseudo Dice: 0.7865999937057495 
2025-08-28 21:26:57.507475:  
2025-08-28 21:26:57.516940: Epoch 730 
2025-08-28 21:26:57.523167: Current learning rate: 0.00308 
2025-08-28 21:27:14.262325: train_loss -0.56 
2025-08-28 21:27:14.270510: val_loss -0.5609 
2025-08-28 21:27:14.278512: Pseudo dice [np.float32(0.7242)] 
2025-08-28 21:27:14.283956: Epoch time: 16.76 s 
2025-08-28 21:27:15.002070:  
2025-08-28 21:27:15.011395: Epoch 731 
2025-08-28 21:27:15.018812: Current learning rate: 0.00307 
2025-08-28 21:27:31.629074: train_loss -0.5777 
2025-08-28 21:27:31.637607: val_loss -0.556 
2025-08-28 21:27:31.644734: Pseudo dice [np.float32(0.7157)] 
2025-08-28 21:27:31.650872: Epoch time: 16.63 s 
2025-08-28 21:27:32.489552:  
2025-08-28 21:27:32.497765: Epoch 732 
2025-08-28 21:27:32.502954: Current learning rate: 0.00306 
2025-08-28 21:27:49.326203: train_loss -0.6164 
2025-08-28 21:27:49.334338: val_loss -0.5907 
2025-08-28 21:27:49.342678: Pseudo dice [np.float32(0.7576)] 
2025-08-28 21:27:49.348859: Epoch time: 16.84 s 
2025-08-28 21:27:50.059898:  
2025-08-28 21:27:50.067364: Epoch 733 
2025-08-28 21:27:50.072422: Current learning rate: 0.00305 
2025-08-28 21:28:06.960591: train_loss -0.5615 
2025-08-28 21:28:06.972802: val_loss -0.539 
2025-08-28 21:28:06.977423: Pseudo dice [np.float32(0.6903)] 
2025-08-28 21:28:06.985268: Epoch time: 16.9 s 
2025-08-28 21:28:07.714203:  
2025-08-28 21:28:07.725578: Epoch 734 
2025-08-28 21:28:07.734536: Current learning rate: 0.00304 
2025-08-28 21:28:24.294477: train_loss -0.5414 
2025-08-28 21:28:24.302581: val_loss -0.5634 
2025-08-28 21:28:24.306984: Pseudo dice [np.float32(0.7599)] 
2025-08-28 21:28:24.315995: Epoch time: 16.58 s 
2025-08-28 21:28:25.015709:  
2025-08-28 21:28:25.024091: Epoch 735 
2025-08-28 21:28:25.029342: Current learning rate: 0.00303 
2025-08-28 21:28:41.924351: train_loss -0.5261 
2025-08-28 21:28:41.932779: val_loss -0.4834 
2025-08-28 21:28:41.936852: Pseudo dice [np.float32(0.7148)] 
2025-08-28 21:28:41.944121: Epoch time: 16.91 s 
2025-08-28 21:28:42.658256:  
2025-08-28 21:28:42.665596: Epoch 736 
2025-08-28 21:28:42.670790: Current learning rate: 0.00302 
2025-08-28 21:28:59.687449: train_loss -0.5826 
2025-08-28 21:28:59.696383: val_loss -0.5382 
2025-08-28 21:28:59.700713: Pseudo dice [np.float32(0.7407)] 
2025-08-28 21:28:59.707636: Epoch time: 17.03 s 
2025-08-28 21:29:00.427279:  
2025-08-28 21:29:00.434337: Epoch 737 
2025-08-28 21:29:00.440674: Current learning rate: 0.00301 
2025-08-28 21:29:17.059875: train_loss -0.5467 
2025-08-28 21:29:17.069838: val_loss -0.5864 
2025-08-28 21:29:17.076161: Pseudo dice [np.float32(0.7476)] 
2025-08-28 21:29:17.081597: Epoch time: 16.63 s 
2025-08-28 21:29:17.926876:  
2025-08-28 21:29:17.936347: Epoch 738 
2025-08-28 21:29:17.941578: Current learning rate: 0.003 
2025-08-28 21:29:34.761058: train_loss -0.5483 
2025-08-28 21:29:34.768793: val_loss -0.6428 
2025-08-28 21:29:34.776896: Pseudo dice [np.float32(0.7899)] 
2025-08-28 21:29:34.782610: Epoch time: 16.84 s 
2025-08-28 21:29:35.493395:  
2025-08-28 21:29:35.501709: Epoch 739 
2025-08-28 21:29:35.508057: Current learning rate: 0.00299 
2025-08-28 21:29:52.499033: train_loss -0.5471 
2025-08-28 21:29:52.507371: val_loss -0.5803 
2025-08-28 21:29:52.516034: Pseudo dice [np.float32(0.7679)] 
2025-08-28 21:29:52.521141: Epoch time: 17.01 s 
2025-08-28 21:29:53.220479:  
2025-08-28 21:29:53.228734: Epoch 740 
2025-08-28 21:29:53.234139: Current learning rate: 0.00297 
2025-08-28 21:30:10.195851: train_loss -0.509 
2025-08-28 21:30:10.204482: val_loss -0.6082 
2025-08-28 21:30:10.208681: Pseudo dice [np.float32(0.7577)] 
2025-08-28 21:30:10.216639: Epoch time: 16.98 s 
2025-08-28 21:30:10.936130:  
2025-08-28 21:30:10.944499: Epoch 741 
2025-08-28 21:30:10.950758: Current learning rate: 0.00296 
2025-08-28 21:30:27.834320: train_loss -0.5418 
2025-08-28 21:30:27.842654: val_loss -0.5406 
2025-08-28 21:30:27.846825: Pseudo dice [np.float32(0.7025)] 
2025-08-28 21:30:27.854061: Epoch time: 16.9 s 
2025-08-28 21:30:28.577434:  
2025-08-28 21:30:28.585455: Epoch 742 
2025-08-28 21:30:28.591277: Current learning rate: 0.00295 
2025-08-28 21:30:45.531124: train_loss -0.5622 
2025-08-28 21:30:45.539822: val_loss -0.6348 
2025-08-28 21:30:45.547831: Pseudo dice [np.float32(0.8001)] 
2025-08-28 21:30:45.553372: Epoch time: 16.96 s 
2025-08-28 21:30:46.278790:  
2025-08-28 21:30:46.287172: Epoch 743 
2025-08-28 21:30:46.293331: Current learning rate: 0.00294 
2025-08-28 21:31:02.769176: train_loss -0.5827 
2025-08-28 21:31:02.777522: val_loss -0.5807 
2025-08-28 21:31:02.786448: Pseudo dice [np.float32(0.7656)] 
2025-08-28 21:31:02.792101: Epoch time: 16.49 s 
2025-08-28 21:31:03.635585:  
2025-08-28 21:31:03.644912: Epoch 744 
2025-08-28 21:31:03.650352: Current learning rate: 0.00293 
2025-08-28 21:31:20.115687: train_loss -0.5836 
2025-08-28 21:31:20.124043: val_loss -0.5679 
2025-08-28 21:31:20.128513: Pseudo dice [np.float32(0.7728)] 
2025-08-28 21:31:20.136436: Epoch time: 16.48 s 
2025-08-28 21:31:20.834057:  
2025-08-28 21:31:20.842410: Epoch 745 
2025-08-28 21:31:20.847579: Current learning rate: 0.00292 
2025-08-28 21:31:37.570613: train_loss -0.571 
2025-08-28 21:31:37.578963: val_loss -0.5998 
2025-08-28 21:31:37.587295: Pseudo dice [np.float32(0.8215)] 
2025-08-28 21:31:37.592760: Epoch time: 16.74 s 
2025-08-28 21:31:38.312871:  
2025-08-28 21:31:38.322856: Epoch 746 
2025-08-28 21:31:38.332479: Current learning rate: 0.00291 
2025-08-28 21:31:54.829525: train_loss -0.5837 
2025-08-28 21:31:54.838140: val_loss -0.6598 
2025-08-28 21:31:54.842333: Pseudo dice [np.float32(0.7879)] 
2025-08-28 21:31:54.849400: Epoch time: 16.52 s 
2025-08-28 21:31:55.557527:  
2025-08-28 21:31:55.565604: Epoch 747 
2025-08-28 21:31:55.574971: Current learning rate: 0.0029 
2025-08-28 21:32:12.217723: train_loss -0.5887 
2025-08-28 21:32:12.230225: val_loss -0.5315 
2025-08-28 21:32:12.239142: Pseudo dice [np.float32(0.7796)] 
2025-08-28 21:32:12.244072: Epoch time: 16.66 s 
2025-08-28 21:32:12.949690:  
2025-08-28 21:32:12.958065: Epoch 748 
2025-08-28 21:32:12.963135: Current learning rate: 0.00289 
2025-08-28 21:32:29.585078: train_loss -0.6001 
2025-08-28 21:32:29.593670: val_loss -0.5985 
2025-08-28 21:32:29.597624: Pseudo dice [np.float32(0.8212)] 
2025-08-28 21:32:29.604954: Epoch time: 16.64 s 
2025-08-28 21:32:30.333734:  
2025-08-28 21:32:30.342062: Epoch 749 
2025-08-28 21:32:30.348300: Current learning rate: 0.00288 
2025-08-28 21:32:47.160959: train_loss -0.5868 
2025-08-28 21:32:47.169280: val_loss -0.6089 
2025-08-28 21:32:47.177655: Pseudo dice [np.float32(0.7734)] 
2025-08-28 21:32:47.184414: Epoch time: 16.83 s 
2025-08-28 21:32:48.084695:  
2025-08-28 21:32:48.093151: Epoch 750 
2025-08-28 21:32:48.099338: Current learning rate: 0.00287 
2025-08-28 21:33:03.435463: train_loss -0.5871 
2025-08-28 21:33:03.443870: val_loss -0.6235 
2025-08-28 21:33:03.448348: Pseudo dice [np.float32(0.8086)] 
2025-08-28 21:33:03.456125: Epoch time: 15.35 s 
2025-08-28 21:33:04.104906:  
2025-08-28 21:33:04.113249: Epoch 751 
2025-08-28 21:33:04.118386: Current learning rate: 0.00286 
2025-08-28 21:33:19.197202: train_loss -0.5819 
2025-08-28 21:33:19.205964: val_loss -0.5543 
2025-08-28 21:33:19.213776: Pseudo dice [np.float32(0.7864)] 
2025-08-28 21:33:19.220181: Epoch time: 15.09 s 
2025-08-28 21:33:19.881027:  
2025-08-28 21:33:19.890471: Epoch 752 
2025-08-28 21:33:19.896631: Current learning rate: 0.00285 
2025-08-28 21:33:35.133870: train_loss -0.5513 
2025-08-28 21:33:35.142227: val_loss -0.5937 
2025-08-28 21:33:35.146392: Pseudo dice [np.float32(0.7546)] 
2025-08-28 21:33:35.154748: Epoch time: 15.25 s 
2025-08-28 21:33:35.827495:  
2025-08-28 21:33:35.836549: Epoch 753 
2025-08-28 21:33:35.842789: Current learning rate: 0.00284 
2025-08-28 21:33:50.887486: train_loss -0.5565 
2025-08-28 21:33:50.895423: val_loss -0.5043 
2025-08-28 21:33:50.903810: Pseudo dice [np.float32(0.7317)] 
2025-08-28 21:33:50.911061: Epoch time: 15.06 s 
2025-08-28 21:33:51.562652:  
2025-08-28 21:33:51.574157: Epoch 754 
2025-08-28 21:33:51.580472: Current learning rate: 0.00283 
2025-08-28 21:34:06.239955: train_loss -0.5369 
2025-08-28 21:34:06.252440: val_loss -0.5733 
2025-08-28 21:34:06.256605: Pseudo dice [np.float32(0.7476)] 
2025-08-28 21:34:06.263714: Epoch time: 14.68 s 
2025-08-28 21:34:06.936279:  
2025-08-28 21:34:06.945946: Epoch 755 
2025-08-28 21:34:06.952054: Current learning rate: 0.00282 
2025-08-28 21:34:22.214197: train_loss -0.5592 
2025-08-28 21:34:22.222556: val_loss -0.6037 
2025-08-28 21:34:22.227017: Pseudo dice [np.float32(0.7857)] 
2025-08-28 21:34:22.236325: Epoch time: 15.28 s 
2025-08-28 21:34:22.897103:  
2025-08-28 21:34:22.906478: Epoch 756 
2025-08-28 21:34:22.911815: Current learning rate: 0.00281 
2025-08-28 21:34:37.842347: train_loss -0.5471 
2025-08-28 21:34:37.850694: val_loss -0.5578 
2025-08-28 21:34:37.854823: Pseudo dice [np.float32(0.7494)] 
2025-08-28 21:34:37.862906: Epoch time: 14.95 s 
2025-08-28 21:34:38.684663:  
2025-08-28 21:34:38.692995: Epoch 757 
2025-08-28 21:34:38.698507: Current learning rate: 0.0028 
2025-08-28 21:34:53.341117: train_loss -0.5436 
2025-08-28 21:34:53.349471: val_loss -0.5483 
2025-08-28 21:34:53.353683: Pseudo dice [np.float32(0.7353)] 
2025-08-28 21:34:53.361718: Epoch time: 14.65 s 
2025-08-28 21:34:54.013886:  
2025-08-28 21:34:54.022971: Epoch 758 
2025-08-28 21:34:54.029151: Current learning rate: 0.00279 
2025-08-28 21:35:09.403016: train_loss -0.5582 
2025-08-28 21:35:09.415559: val_loss -0.5646 
2025-08-28 21:35:09.419720: Pseudo dice [np.float32(0.7809)] 
2025-08-28 21:35:09.428655: Epoch time: 15.39 s 
2025-08-28 21:35:10.088111:  
2025-08-28 21:35:10.096365: Epoch 759 
2025-08-28 21:35:10.102628: Current learning rate: 0.00278 
2025-08-28 21:35:25.489902: train_loss -0.5679 
2025-08-28 21:35:25.498281: val_loss -0.5419 
2025-08-28 21:35:25.502458: Pseudo dice [np.float32(0.771)] 
2025-08-28 21:35:25.510489: Epoch time: 15.4 s 
2025-08-28 21:35:26.160237:  
2025-08-28 21:35:26.166590: Epoch 760 
2025-08-28 21:35:26.172829: Current learning rate: 0.00277 
2025-08-28 21:35:40.967909: train_loss -0.5658 
2025-08-28 21:35:40.976202: val_loss -0.5715 
2025-08-28 21:35:40.984211: Pseudo dice [np.float32(0.7145)] 
2025-08-28 21:35:40.988927: Epoch time: 14.81 s 
2025-08-28 21:35:41.653879:  
2025-08-28 21:35:41.661252: Epoch 761 
2025-08-28 21:35:41.667435: Current learning rate: 0.00276 
2025-08-28 21:35:56.508444: train_loss -0.5824 
2025-08-28 21:35:56.516791: val_loss -0.5695 
2025-08-28 21:35:56.525085: Pseudo dice [np.float32(0.7553)] 
2025-08-28 21:35:56.530420: Epoch time: 14.86 s 
2025-08-28 21:35:57.193432:  
2025-08-28 21:35:57.201781: Epoch 762 
2025-08-28 21:35:57.206915: Current learning rate: 0.00275 
2025-08-28 21:36:12.403436: train_loss -0.5768 
2025-08-28 21:36:12.411780: val_loss -0.5901 
2025-08-28 21:36:12.415947: Pseudo dice [np.float32(0.7472)] 
2025-08-28 21:36:12.422101: Epoch time: 15.21 s 
2025-08-28 21:36:13.243757:  
2025-08-28 21:36:13.253346: Epoch 763 
2025-08-28 21:36:13.259507: Current learning rate: 0.00274 
2025-08-28 21:36:28.663403: train_loss -0.5624 
2025-08-28 21:36:28.672679: val_loss -0.6078 
2025-08-28 21:36:28.680037: Pseudo dice [np.float32(0.7717)] 
2025-08-28 21:36:28.687422: Epoch time: 15.42 s 
2025-08-28 21:36:29.363048:  
2025-08-28 21:36:29.372421: Epoch 764 
2025-08-28 21:36:29.378685: Current learning rate: 0.00273 
2025-08-28 21:36:44.493817: train_loss -0.5699 
2025-08-28 21:36:44.504848: val_loss -0.5006 
2025-08-28 21:36:44.510482: Pseudo dice [np.float32(0.6768)] 
2025-08-28 21:36:44.516541: Epoch time: 15.13 s 
2025-08-28 21:36:45.171493:  
2025-08-28 21:36:45.181087: Epoch 765 
2025-08-28 21:36:45.186030: Current learning rate: 0.00272 
2025-08-28 21:37:00.706311: train_loss -0.5909 
2025-08-28 21:37:00.718370: val_loss -0.5184 
2025-08-28 21:37:00.722519: Pseudo dice [np.float32(0.753)] 
2025-08-28 21:37:00.732669: Epoch time: 15.54 s 
2025-08-28 21:37:01.393873:  
2025-08-28 21:37:01.403419: Epoch 766 
2025-08-28 21:37:01.408652: Current learning rate: 0.00271 
2025-08-28 21:37:16.755693: train_loss -0.5369 
2025-08-28 21:37:16.763541: val_loss -0.6111 
2025-08-28 21:37:16.771886: Pseudo dice [np.float32(0.8047)] 
2025-08-28 21:37:16.777336: Epoch time: 15.36 s 
2025-08-28 21:37:17.450840:  
2025-08-28 21:37:17.461279: Epoch 767 
2025-08-28 21:37:17.468304: Current learning rate: 0.0027 
2025-08-28 21:37:32.358262: train_loss -0.5914 
2025-08-28 21:37:32.366620: val_loss -0.5525 
2025-08-28 21:37:32.372077: Pseudo dice [np.float32(0.7641)] 
2025-08-28 21:37:32.379797: Epoch time: 14.91 s 
2025-08-28 21:37:33.044415:  
2025-08-28 21:37:33.052685: Epoch 768 
2025-08-28 21:37:33.057825: Current learning rate: 0.00268 
2025-08-28 21:37:47.961364: train_loss -0.5481 
2025-08-28 21:37:47.969722: val_loss -0.6106 
2025-08-28 21:37:47.973879: Pseudo dice [np.float32(0.7968)] 
2025-08-28 21:37:47.982997: Epoch time: 14.92 s 
2025-08-28 21:37:48.799570:  
2025-08-28 21:37:48.809050: Epoch 769 
2025-08-28 21:37:48.814217: Current learning rate: 0.00267 
2025-08-28 21:38:03.702120: train_loss -0.5452 
2025-08-28 21:38:03.714593: val_loss -0.6535 
2025-08-28 21:38:03.718757: Pseudo dice [np.float32(0.7933)] 
2025-08-28 21:38:03.725766: Epoch time: 14.9 s 
2025-08-28 21:38:04.393435:  
2025-08-28 21:38:04.401660: Epoch 770 
2025-08-28 21:38:04.408034: Current learning rate: 0.00266 
2025-08-28 21:38:19.626371: train_loss -0.5658 
2025-08-28 21:38:19.634651: val_loss -0.5711 
2025-08-28 21:38:19.638752: Pseudo dice [np.float32(0.7894)] 
2025-08-28 21:38:19.647386: Epoch time: 15.23 s 
2025-08-28 21:38:20.320689:  
2025-08-28 21:38:20.330090: Epoch 771 
2025-08-28 21:38:20.337358: Current learning rate: 0.00265 
2025-08-28 21:38:35.225217: train_loss -0.583 
2025-08-28 21:38:35.233581: val_loss -0.5909 
2025-08-28 21:38:35.237636: Pseudo dice [np.float32(0.7824)] 
2025-08-28 21:38:35.250270: Epoch time: 14.91 s 
2025-08-28 21:38:35.935776:  
2025-08-28 21:38:35.942637: Epoch 772 
2025-08-28 21:38:35.947093: Current learning rate: 0.00264 
2025-08-28 21:38:51.304051: train_loss -0.6059 
2025-08-28 21:38:51.312130: val_loss -0.6245 
2025-08-28 21:38:51.318675: Pseudo dice [np.float32(0.7911)] 
2025-08-28 21:38:51.324234: Epoch time: 15.37 s 
2025-08-28 21:38:51.981560:  
2025-08-28 21:38:51.990879: Epoch 773 
2025-08-28 21:38:51.997262: Current learning rate: 0.00263 
2025-08-28 21:39:06.919395: train_loss -0.5718 
2025-08-28 21:39:06.932033: val_loss -0.5686 
2025-08-28 21:39:06.940226: Pseudo dice [np.float32(0.7495)] 
2025-08-28 21:39:06.945136: Epoch time: 14.94 s 
2025-08-28 21:39:07.605418:  
2025-08-28 21:39:07.613852: Epoch 774 
2025-08-28 21:39:07.619911: Current learning rate: 0.00262 
2025-08-28 21:39:23.377944: train_loss -0.5574 
2025-08-28 21:39:23.386147: val_loss -0.5478 
2025-08-28 21:39:23.390243: Pseudo dice [np.float32(0.7179)] 
2025-08-28 21:39:23.399012: Epoch time: 15.77 s 
2025-08-28 21:39:24.120929:  
2025-08-28 21:39:24.130341: Epoch 775 
2025-08-28 21:39:24.138610: Current learning rate: 0.00261 
2025-08-28 21:39:40.899424: train_loss -0.5583 
2025-08-28 21:39:40.907505: val_loss -0.5561 
2025-08-28 21:39:40.915840: Pseudo dice [np.float32(0.8186)] 
2025-08-28 21:39:40.922236: Epoch time: 16.78 s 
2025-08-28 21:39:41.646833:  
2025-08-28 21:39:41.653952: Epoch 776 
2025-08-28 21:39:41.659448: Current learning rate: 0.0026 
2025-08-28 21:39:58.241485: train_loss -0.5742 
2025-08-28 21:39:58.253988: val_loss -0.5174 
2025-08-28 21:39:58.262348: Pseudo dice [np.float32(0.7967)] 
2025-08-28 21:39:58.268041: Epoch time: 16.6 s 
2025-08-28 21:39:58.994363:  
2025-08-28 21:39:59.002596: Epoch 777 
2025-08-28 21:39:59.007758: Current learning rate: 0.00259 
2025-08-28 21:40:14.853861: train_loss -0.5739 
2025-08-28 21:40:14.866417: val_loss -0.5543 
2025-08-28 21:40:14.870585: Pseudo dice [np.float32(0.8055)] 
2025-08-28 21:40:14.877609: Epoch time: 15.86 s 
2025-08-28 21:40:15.593153:  
2025-08-28 21:40:15.602772: Epoch 778 
2025-08-28 21:40:15.608660: Current learning rate: 0.00258 
2025-08-28 21:40:30.298509: train_loss -0.5574 
2025-08-28 21:40:30.306817: val_loss -0.6392 
2025-08-28 21:40:30.311011: Pseudo dice [np.float32(0.8215)] 
2025-08-28 21:40:30.323511: Epoch time: 14.71 s 
2025-08-28 21:40:30.985643:  
2025-08-28 21:40:30.996104: Epoch 779 
2025-08-28 21:40:31.003222: Current learning rate: 0.00257 
2025-08-28 21:40:46.001663: train_loss -0.572 
2025-08-28 21:40:46.014195: val_loss -0.6001 
2025-08-28 21:40:46.018355: Pseudo dice [np.float32(0.752)] 
2025-08-28 21:40:46.024360: Epoch time: 15.02 s 
2025-08-28 21:40:46.701244:  
2025-08-28 21:40:46.709543: Epoch 780 
2025-08-28 21:40:46.714709: Current learning rate: 0.00256 
2025-08-28 21:41:01.921787: train_loss -0.57 
2025-08-28 21:41:01.934243: val_loss -0.5576 
2025-08-28 21:41:01.938439: Pseudo dice [np.float32(0.7801)] 
2025-08-28 21:41:01.947862: Epoch time: 15.22 s 
2025-08-28 21:41:02.611974:  
2025-08-28 21:41:02.624722: Epoch 781 
2025-08-28 21:41:02.631799: Current learning rate: 0.00255 
2025-08-28 21:41:18.096665: train_loss -0.5642 
2025-08-28 21:41:18.104579: val_loss -0.6018 
2025-08-28 21:41:18.112921: Pseudo dice [np.float32(0.8204)] 
2025-08-28 21:41:18.118388: Epoch time: 15.49 s 
2025-08-28 21:41:18.923123:  
2025-08-28 21:41:18.933449: Epoch 782 
2025-08-28 21:41:18.941821: Current learning rate: 0.00254 
2025-08-28 21:41:33.837095: train_loss -0.5933 
2025-08-28 21:41:33.845306: val_loss -0.5634 
2025-08-28 21:41:33.849399: Pseudo dice [np.float32(0.7777)] 
2025-08-28 21:41:33.856436: Epoch time: 14.92 s 
2025-08-28 21:41:34.518895:  
2025-08-28 21:41:34.528216: Epoch 783 
2025-08-28 21:41:34.533296: Current learning rate: 0.00253 
2025-08-28 21:41:49.848768: train_loss -0.5417 
2025-08-28 21:41:49.857123: val_loss -0.6233 
2025-08-28 21:41:49.865226: Pseudo dice [np.float32(0.7745)] 
2025-08-28 21:41:49.871020: Epoch time: 15.33 s 
2025-08-28 21:41:50.536780:  
2025-08-28 21:41:50.546472: Epoch 784 
2025-08-28 21:41:50.552506: Current learning rate: 0.00252 
2025-08-28 21:42:05.893656: train_loss -0.5665 
2025-08-28 21:42:05.906470: val_loss -0.6118 
2025-08-28 21:42:05.910909: Pseudo dice [np.float32(0.8292)] 
2025-08-28 21:42:05.918514: Epoch time: 15.36 s 
2025-08-28 21:42:06.583172:  
2025-08-28 21:42:06.593668: Epoch 785 
2025-08-28 21:42:06.598682: Current learning rate: 0.00251 
2025-08-28 21:42:21.413977: train_loss -0.5966 
2025-08-28 21:42:21.421979: val_loss -0.5639 
2025-08-28 21:42:21.430325: Pseudo dice [np.float32(0.7687)] 
2025-08-28 21:42:21.435707: Epoch time: 14.83 s 
2025-08-28 21:42:22.093346:  
2025-08-28 21:42:22.102894: Epoch 786 
2025-08-28 21:42:22.109972: Current learning rate: 0.0025 
2025-08-28 21:42:37.329494: train_loss -0.598 
2025-08-28 21:42:37.337894: val_loss -0.6205 
2025-08-28 21:42:37.342021: Pseudo dice [np.float32(0.8007)] 
2025-08-28 21:42:37.351118: Epoch time: 15.24 s 
2025-08-28 21:42:38.023017:  
2025-08-28 21:42:38.033231: Epoch 787 
2025-08-28 21:42:38.040554: Current learning rate: 0.00249 
2025-08-28 21:42:53.328804: train_loss -0.5791 
2025-08-28 21:42:53.337154: val_loss -0.5886 
2025-08-28 21:42:53.341322: Pseudo dice [np.float32(0.8014)] 
2025-08-28 21:42:53.350827: Epoch time: 15.31 s 
2025-08-28 21:42:53.357331: Yayy! New best EMA pseudo Dice: 0.7871999740600586 
2025-08-28 21:42:54.347600:  
2025-08-28 21:42:54.356880: Epoch 788 
2025-08-28 21:42:54.363092: Current learning rate: 0.00248 
2025-08-28 21:43:09.499592: train_loss -0.5664 
2025-08-28 21:43:09.511522: val_loss -0.5721 
2025-08-28 21:43:09.519856: Pseudo dice [np.float32(0.7303)] 
2025-08-28 21:43:09.526128: Epoch time: 15.15 s 
2025-08-28 21:43:10.193499:  
2025-08-28 21:43:10.200905: Epoch 789 
2025-08-28 21:43:10.206003: Current learning rate: 0.00247 
2025-08-28 21:43:25.064720: train_loss -0.5801 
2025-08-28 21:43:25.073024: val_loss -0.6766 
2025-08-28 21:43:25.077446: Pseudo dice [np.float32(0.856)] 
2025-08-28 21:43:25.086265: Epoch time: 14.87 s 
2025-08-28 21:43:25.092209: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-08-28 21:43:25.961244:  
2025-08-28 21:43:25.971771: Epoch 790 
2025-08-28 21:43:25.977989: Current learning rate: 0.00245 
2025-08-28 21:43:41.527107: train_loss -0.5787 
2025-08-28 21:43:41.535298: val_loss -0.6242 
2025-08-28 21:43:41.539779: Pseudo dice [np.float32(0.8081)] 
2025-08-28 21:43:41.548465: Epoch time: 15.57 s 
2025-08-28 21:43:41.554542: Yayy! New best EMA pseudo Dice: 0.7908999919891357 
2025-08-28 21:43:42.428861:  
2025-08-28 21:43:42.437208: Epoch 791 
2025-08-28 21:43:42.442390: Current learning rate: 0.00244 
2025-08-28 21:43:57.130412: train_loss -0.5542 
2025-08-28 21:43:57.142828: val_loss -0.5962 
2025-08-28 21:43:57.146727: Pseudo dice [np.float32(0.7812)] 
2025-08-28 21:43:57.153912: Epoch time: 14.7 s 
2025-08-28 21:43:57.829667:  
2025-08-28 21:43:57.838952: Epoch 792 
2025-08-28 21:43:57.846260: Current learning rate: 0.00243 
2025-08-28 21:44:13.221535: train_loss -0.5648 
2025-08-28 21:44:13.229920: val_loss -0.4683 
2025-08-28 21:44:13.238210: Pseudo dice [np.float32(0.7452)] 
2025-08-28 21:44:13.244514: Epoch time: 15.39 s 
2025-08-28 21:44:14.114688:  
2025-08-28 21:44:14.124129: Epoch 793 
2025-08-28 21:44:14.130186: Current learning rate: 0.00242 
2025-08-28 21:44:30.421882: train_loss -0.5795 
2025-08-28 21:44:30.429995: val_loss -0.6383 
2025-08-28 21:44:30.434138: Pseudo dice [np.float32(0.7972)] 
2025-08-28 21:44:30.443336: Epoch time: 16.31 s 
2025-08-28 21:44:31.156725:  
2025-08-28 21:44:31.163932: Epoch 794 
2025-08-28 21:44:31.169183: Current learning rate: 0.00241 
2025-08-28 21:44:47.317660: train_loss -0.5597 
2025-08-28 21:44:47.326381: val_loss -0.5407 
2025-08-28 21:44:47.334345: Pseudo dice [np.float32(0.804)] 
2025-08-28 21:44:47.339827: Epoch time: 16.16 s 
2025-08-28 21:44:48.061061:  
2025-08-28 21:44:48.068738: Epoch 795 
2025-08-28 21:44:48.073073: Current learning rate: 0.0024 
2025-08-28 21:45:04.126152: train_loss -0.594 
2025-08-28 21:45:04.134488: val_loss -0.5798 
2025-08-28 21:45:04.138508: Pseudo dice [np.float32(0.7848)] 
2025-08-28 21:45:04.147789: Epoch time: 16.07 s 
2025-08-28 21:45:04.880846:  
2025-08-28 21:45:04.888206: Epoch 796 
2025-08-28 21:45:04.893378: Current learning rate: 0.00239 
2025-08-28 21:45:20.926207: train_loss -0.5478 
2025-08-28 21:45:20.934560: val_loss -0.5369 
2025-08-28 21:45:20.943558: Pseudo dice [np.float32(0.7637)] 
2025-08-28 21:45:20.948535: Epoch time: 16.05 s 
2025-08-28 21:45:21.675825:  
2025-08-28 21:45:21.686968: Epoch 797 
2025-08-28 21:45:21.693689: Current learning rate: 0.00238 
2025-08-28 21:45:38.018321: train_loss -0.5836 
2025-08-28 21:45:38.026687: val_loss -0.5872 
2025-08-28 21:45:38.034968: Pseudo dice [np.float32(0.7827)] 
2025-08-28 21:45:38.040053: Epoch time: 16.34 s 
2025-08-28 21:45:38.764739:  
2025-08-28 21:45:38.773126: Epoch 798 
2025-08-28 21:45:38.780207: Current learning rate: 0.00237 
2025-08-28 21:45:54.810081: train_loss -0.5714 
2025-08-28 21:45:54.818437: val_loss -0.5501 
2025-08-28 21:45:54.822659: Pseudo dice [np.float32(0.7159)] 
2025-08-28 21:45:54.830745: Epoch time: 16.05 s 
2025-08-28 21:45:55.571250:  
2025-08-28 21:45:55.579612: Epoch 799 
2025-08-28 21:45:55.585672: Current learning rate: 0.00236 
2025-08-28 21:46:11.739701: train_loss -0.5862 
2025-08-28 21:46:11.752810: val_loss -0.6274 
2025-08-28 21:46:11.756180: Pseudo dice [np.float32(0.7782)] 
2025-08-28 21:46:11.764344: Epoch time: 16.17 s 
2025-08-28 21:46:12.842655:  
2025-08-28 21:46:12.851030: Epoch 800 
2025-08-28 21:46:12.856074: Current learning rate: 0.00235 
2025-08-28 21:46:29.701616: train_loss -0.5903 
2025-08-28 21:46:29.707732: val_loss -0.5721 
2025-08-28 21:46:29.715754: Pseudo dice [np.float32(0.8132)] 
2025-08-28 21:46:29.721375: Epoch time: 16.86 s 
2025-08-28 21:46:30.444490:  
2025-08-28 21:46:30.455229: Epoch 801 
2025-08-28 21:46:30.463431: Current learning rate: 0.00234 
2025-08-28 21:46:46.970836: train_loss -0.5672 
2025-08-28 21:46:46.979335: val_loss -0.5485 
2025-08-28 21:46:46.983001: Pseudo dice [np.float32(0.7651)] 
2025-08-28 21:46:46.992438: Epoch time: 16.53 s 
2025-08-28 21:46:47.700326:  
2025-08-28 21:46:47.708565: Epoch 802 
2025-08-28 21:46:47.714962: Current learning rate: 0.00233 
2025-08-28 21:47:04.342092: train_loss -0.5864 
2025-08-28 21:47:04.359097: val_loss -0.5849 
2025-08-28 21:47:04.367470: Pseudo dice [np.float32(0.7756)] 
2025-08-28 21:47:04.378721: Epoch time: 16.64 s 
2025-08-28 21:47:05.116627:  
2025-08-28 21:47:05.124603: Epoch 803 
2025-08-28 21:47:05.129205: Current learning rate: 0.00232 
2025-08-28 21:47:21.663436: train_loss -0.5751 
2025-08-28 21:47:21.672031: val_loss -0.5848 
2025-08-28 21:47:21.680143: Pseudo dice [np.float32(0.7712)] 
2025-08-28 21:47:21.686286: Epoch time: 16.55 s 
2025-08-28 21:47:22.426543:  
2025-08-28 21:47:22.436755: Epoch 804 
2025-08-28 21:47:22.443954: Current learning rate: 0.00231 
2025-08-28 21:47:39.009940: train_loss -0.5821 
2025-08-28 21:47:39.018624: val_loss -0.6283 
2025-08-28 21:47:39.022681: Pseudo dice [np.float32(0.8032)] 
2025-08-28 21:47:39.032161: Epoch time: 16.59 s 
2025-08-28 21:47:39.891071:  
2025-08-28 21:47:39.902773: Epoch 805 
2025-08-28 21:47:39.911358: Current learning rate: 0.0023 
2025-08-28 21:47:56.231350: train_loss -0.6026 
2025-08-28 21:47:56.239661: val_loss -0.5739 
2025-08-28 21:47:56.243885: Pseudo dice [np.float32(0.7707)] 
2025-08-28 21:47:56.252932: Epoch time: 16.34 s 
2025-08-28 21:47:56.972651:  
2025-08-28 21:47:56.980896: Epoch 806 
2025-08-28 21:47:56.986089: Current learning rate: 0.00229 
2025-08-28 21:48:13.982355: train_loss -0.6201 
2025-08-28 21:48:13.990712: val_loss -0.6158 
2025-08-28 21:48:13.999061: Pseudo dice [np.float32(0.7833)] 
2025-08-28 21:48:14.006359: Epoch time: 17.01 s 
2025-08-28 21:48:14.735934:  
2025-08-28 21:48:14.746627: Epoch 807 
2025-08-28 21:48:14.754377: Current learning rate: 0.00228 
2025-08-28 21:48:31.383343: train_loss -0.5533 
2025-08-28 21:48:31.391419: val_loss -0.6169 
2025-08-28 21:48:31.395629: Pseudo dice [np.float32(0.7661)] 
2025-08-28 21:48:31.401803: Epoch time: 16.65 s 
2025-08-28 21:48:32.112818:  
2025-08-28 21:48:32.123184: Epoch 808 
2025-08-28 21:48:32.133992: Current learning rate: 0.00226 
2025-08-28 21:48:48.880060: train_loss -0.6005 
2025-08-28 21:48:48.888428: val_loss -0.5906 
2025-08-28 21:48:48.892246: Pseudo dice [np.float32(0.7794)] 
2025-08-28 21:48:48.899346: Epoch time: 16.77 s 
2025-08-28 21:48:49.625290:  
2025-08-28 21:48:49.636314: Epoch 809 
2025-08-28 21:48:49.643297: Current learning rate: 0.00225 
2025-08-28 21:49:06.226220: train_loss -0.5673 
2025-08-28 21:49:06.234560: val_loss -0.5472 
2025-08-28 21:49:06.242907: Pseudo dice [np.float32(0.757)] 
2025-08-28 21:49:06.248400: Epoch time: 16.6 s 
2025-08-28 21:49:06.981046:  
2025-08-28 21:49:06.990480: Epoch 810 
2025-08-28 21:49:06.995646: Current learning rate: 0.00224 
2025-08-28 21:49:23.138921: train_loss -0.5793 
2025-08-28 21:49:23.147268: val_loss -0.5665 
2025-08-28 21:49:23.151410: Pseudo dice [np.float32(0.7854)] 
2025-08-28 21:49:23.160516: Epoch time: 16.16 s 
2025-08-28 21:49:23.832392:  
2025-08-28 21:49:23.842938: Epoch 811 
2025-08-28 21:49:23.847969: Current learning rate: 0.00223 
2025-08-28 21:49:39.384731: train_loss -0.5803 
2025-08-28 21:49:39.392661: val_loss -0.5576 
2025-08-28 21:49:39.401035: Pseudo dice [np.float32(0.7897)] 
2025-08-28 21:49:39.406363: Epoch time: 15.55 s 
2025-08-28 21:49:40.242368:  
2025-08-28 21:49:40.251746: Epoch 812 
2025-08-28 21:49:40.257028: Current learning rate: 0.00222 
2025-08-28 21:49:55.667241: train_loss -0.5697 
2025-08-28 21:49:55.675600: val_loss -0.6702 
2025-08-28 21:49:55.679757: Pseudo dice [np.float32(0.7925)] 
2025-08-28 21:49:55.689124: Epoch time: 15.43 s 
2025-08-28 21:49:56.360595:  
2025-08-28 21:49:56.372045: Epoch 813 
2025-08-28 21:49:56.381456: Current learning rate: 0.00221 
2025-08-28 21:50:11.358028: train_loss -0.5824 
2025-08-28 21:50:11.366250: val_loss -0.646 
2025-08-28 21:50:11.370418: Pseudo dice [np.float32(0.7926)] 
2025-08-28 21:50:11.378389: Epoch time: 15.0 s 
2025-08-28 21:50:12.053326:  
2025-08-28 21:50:12.061632: Epoch 814 
2025-08-28 21:50:12.069975: Current learning rate: 0.0022 
2025-08-28 21:50:27.115337: train_loss -0.6022 
2025-08-28 21:50:27.123652: val_loss -0.5812 
2025-08-28 21:50:27.132421: Pseudo dice [np.float32(0.7922)] 
2025-08-28 21:50:27.138098: Epoch time: 15.06 s 
2025-08-28 21:50:27.820078:  
2025-08-28 21:50:27.831393: Epoch 815 
2025-08-28 21:50:27.838139: Current learning rate: 0.00219 
2025-08-28 21:50:43.198767: train_loss -0.5862 
2025-08-28 21:50:43.206638: val_loss -0.5897 
2025-08-28 21:50:43.214741: Pseudo dice [np.float32(0.7955)] 
2025-08-28 21:50:43.220716: Epoch time: 15.38 s 
2025-08-28 21:50:43.899084:  
2025-08-28 21:50:43.906999: Epoch 816 
2025-08-28 21:50:43.914394: Current learning rate: 0.00218 
2025-08-28 21:50:58.496664: train_loss -0.5654 
2025-08-28 21:50:58.509182: val_loss -0.6452 
2025-08-28 21:50:58.513345: Pseudo dice [np.float32(0.7826)] 
2025-08-28 21:50:58.521584: Epoch time: 14.6 s 
2025-08-28 21:50:59.196188:  
2025-08-28 21:50:59.204614: Epoch 817 
2025-08-28 21:50:59.210984: Current learning rate: 0.00217 
2025-08-28 21:51:14.666962: train_loss -0.623 
2025-08-28 21:51:14.678073: val_loss -0.6209 
2025-08-28 21:51:14.683671: Pseudo dice [np.float32(0.8101)] 
2025-08-28 21:51:14.689868: Epoch time: 15.47 s 
2025-08-28 21:51:15.505205:  
2025-08-28 21:51:15.513643: Epoch 818 
2025-08-28 21:51:15.518928: Current learning rate: 0.00216 
2025-08-28 21:51:30.582859: train_loss -0.6092 
2025-08-28 21:51:30.591254: val_loss -0.6506 
2025-08-28 21:51:30.595393: Pseudo dice [np.float32(0.7961)] 
2025-08-28 21:51:30.605825: Epoch time: 15.08 s 
2025-08-28 21:51:31.280478:  
2025-08-28 21:51:31.288778: Epoch 819 
2025-08-28 21:51:31.294956: Current learning rate: 0.00215 
2025-08-28 21:51:45.994269: train_loss -0.5766 
2025-08-28 21:51:46.002454: val_loss -0.5896 
2025-08-28 21:51:46.006578: Pseudo dice [np.float32(0.7826)] 
2025-08-28 21:51:46.012707: Epoch time: 14.71 s 
2025-08-28 21:51:46.662477:  
2025-08-28 21:51:46.669600: Epoch 820 
2025-08-28 21:51:46.675006: Current learning rate: 0.00214 
2025-08-28 21:52:01.814504: train_loss -0.5944 
2025-08-28 21:52:01.826576: val_loss -0.6051 
2025-08-28 21:52:01.830740: Pseudo dice [np.float32(0.7875)] 
2025-08-28 21:52:01.839253: Epoch time: 15.15 s 
2025-08-28 21:52:02.488663:  
2025-08-28 21:52:02.496919: Epoch 821 
2025-08-28 21:52:02.506304: Current learning rate: 0.00213 
2025-08-28 21:52:17.842532: train_loss -0.6065 
2025-08-28 21:52:17.851300: val_loss -0.5959 
2025-08-28 21:52:17.855070: Pseudo dice [np.float32(0.7867)] 
2025-08-28 21:52:17.863063: Epoch time: 15.36 s 
2025-08-28 21:52:18.513901:  
2025-08-28 21:52:18.522254: Epoch 822 
2025-08-28 21:52:18.530444: Current learning rate: 0.00212 
2025-08-28 21:52:33.992190: train_loss -0.5708 
2025-08-28 21:52:34.000365: val_loss -0.5421 
2025-08-28 21:52:34.004730: Pseudo dice [np.float32(0.7673)] 
2025-08-28 21:52:34.013717: Epoch time: 15.48 s 
2025-08-28 21:52:34.681216:  
2025-08-28 21:52:34.689612: Epoch 823 
2025-08-28 21:52:34.696766: Current learning rate: 0.0021 
2025-08-28 21:52:49.628484: train_loss -0.5793 
2025-08-28 21:52:49.636825: val_loss -0.5823 
2025-08-28 21:52:49.641028: Pseudo dice [np.float32(0.7834)] 
2025-08-28 21:52:49.650119: Epoch time: 14.95 s 
2025-08-28 21:52:50.302059:  
2025-08-28 21:52:50.310339: Epoch 824 
2025-08-28 21:52:50.316494: Current learning rate: 0.00209 
2025-08-28 21:53:06.141146: train_loss -0.5938 
2025-08-28 21:53:06.149162: val_loss -0.5744 
2025-08-28 21:53:06.157527: Pseudo dice [np.float32(0.7784)] 
2025-08-28 21:53:06.163594: Epoch time: 15.84 s 
2025-08-28 21:53:06.966566:  
2025-08-28 21:53:06.975996: Epoch 825 
2025-08-28 21:53:06.983156: Current learning rate: 0.00208 
2025-08-28 21:53:22.890907: train_loss -0.6023 
2025-08-28 21:53:22.899210: val_loss -0.5961 
2025-08-28 21:53:22.903651: Pseudo dice [np.float32(0.7914)] 
2025-08-28 21:53:22.912555: Epoch time: 15.93 s 
2025-08-28 21:53:23.599748:  
2025-08-28 21:53:23.609260: Epoch 826 
2025-08-28 21:53:23.615513: Current learning rate: 0.00207 
2025-08-28 21:53:40.095602: train_loss -0.6075 
2025-08-28 21:53:40.107423: val_loss -0.5599 
2025-08-28 21:53:40.112136: Pseudo dice [np.float32(0.7859)] 
2025-08-28 21:53:40.118427: Epoch time: 16.5 s 
2025-08-28 21:53:40.809834:  
2025-08-28 21:53:40.819187: Epoch 827 
2025-08-28 21:53:40.825772: Current learning rate: 0.00206 
2025-08-28 21:53:57.567732: train_loss -0.5669 
2025-08-28 21:53:57.579744: val_loss -0.5296 
2025-08-28 21:53:57.583859: Pseudo dice [np.float32(0.7078)] 
2025-08-28 21:53:57.591142: Epoch time: 16.76 s 
2025-08-28 21:53:58.290841:  
2025-08-28 21:53:58.301136: Epoch 828 
2025-08-28 21:53:58.310635: Current learning rate: 0.00205 
2025-08-28 21:54:15.030450: train_loss -0.6029 
2025-08-28 21:54:15.039141: val_loss -0.6609 
2025-08-28 21:54:15.043287: Pseudo dice [np.float32(0.8036)] 
2025-08-28 21:54:15.052365: Epoch time: 16.74 s 
2025-08-28 21:54:15.761463:  
2025-08-28 21:54:15.772820: Epoch 829 
2025-08-28 21:54:15.780965: Current learning rate: 0.00204 
2025-08-28 21:54:32.673047: train_loss -0.6223 
2025-08-28 21:54:32.681606: val_loss -0.5701 
2025-08-28 21:54:32.689723: Pseudo dice [np.float32(0.7872)] 
2025-08-28 21:54:32.695122: Epoch time: 16.91 s 
2025-08-28 21:54:33.384120:  
2025-08-28 21:54:33.394426: Epoch 830 
2025-08-28 21:54:33.402987: Current learning rate: 0.00203 
2025-08-28 21:54:49.949002: train_loss -0.5841 
2025-08-28 21:54:49.957267: val_loss -0.6549 
2025-08-28 21:54:49.961431: Pseudo dice [np.float32(0.8236)] 
2025-08-28 21:54:49.970438: Epoch time: 16.57 s 
2025-08-28 21:54:50.669133:  
2025-08-28 21:54:50.677378: Epoch 831 
2025-08-28 21:54:50.686934: Current learning rate: 0.00202 
2025-08-28 21:55:07.662193: train_loss -0.6058 
2025-08-28 21:55:07.670522: val_loss -0.6277 
2025-08-28 21:55:07.678864: Pseudo dice [np.float32(0.8002)] 
2025-08-28 21:55:07.684300: Epoch time: 17.0 s 
2025-08-28 21:55:08.537847:  
2025-08-28 21:55:08.546275: Epoch 832 
2025-08-28 21:55:08.554738: Current learning rate: 0.00201 
2025-08-28 21:55:25.133792: train_loss -0.5939 
2025-08-28 21:55:25.142127: val_loss -0.5452 
2025-08-28 21:55:25.150780: Pseudo dice [np.float32(0.8002)] 
2025-08-28 21:55:25.156722: Epoch time: 16.6 s 
2025-08-28 21:55:25.851057:  
2025-08-28 21:55:25.860910: Epoch 833 
2025-08-28 21:55:25.869505: Current learning rate: 0.002 
2025-08-28 21:55:42.747231: train_loss -0.58 
2025-08-28 21:55:42.755549: val_loss -0.6246 
2025-08-28 21:55:42.763902: Pseudo dice [np.float32(0.815)] 
2025-08-28 21:55:42.769377: Epoch time: 16.9 s 
2025-08-28 21:55:43.458373:  
2025-08-28 21:55:43.466620: Epoch 834 
2025-08-28 21:55:43.472860: Current learning rate: 0.00199 
2025-08-28 21:55:59.944008: train_loss -0.5894 
2025-08-28 21:55:59.956422: val_loss -0.5964 
2025-08-28 21:55:59.960584: Pseudo dice [np.float32(0.8371)] 
2025-08-28 21:55:59.967645: Epoch time: 16.49 s 
2025-08-28 21:55:59.974307: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2025-08-28 21:56:00.875466:  
2025-08-28 21:56:00.886167: Epoch 835 
2025-08-28 21:56:00.895053: Current learning rate: 0.00198 
2025-08-28 21:56:17.586226: train_loss -0.5986 
2025-08-28 21:56:17.594508: val_loss -0.5884 
2025-08-28 21:56:17.598718: Pseudo dice [np.float32(0.7747)] 
2025-08-28 21:56:17.607962: Epoch time: 16.71 s 
2025-08-28 21:56:18.312148:  
2025-08-28 21:56:18.322838: Epoch 836 
2025-08-28 21:56:18.329618: Current learning rate: 0.00196 
2025-08-28 21:56:35.107812: train_loss -0.5984 
2025-08-28 21:56:35.116176: val_loss -0.6217 
2025-08-28 21:56:35.124522: Pseudo dice [np.float32(0.7945)] 
2025-08-28 21:56:35.130347: Epoch time: 16.8 s 
2025-08-28 21:56:35.844927:  
2025-08-28 21:56:35.855513: Epoch 837 
2025-08-28 21:56:35.864226: Current learning rate: 0.00195 
2025-08-28 21:56:52.608639: train_loss -0.6043 
2025-08-28 21:56:52.617291: val_loss -0.5437 
2025-08-28 21:56:52.625334: Pseudo dice [np.float32(0.723)] 
2025-08-28 21:56:52.631563: Epoch time: 16.77 s 
2025-08-28 21:56:53.333074:  
2025-08-28 21:56:53.341617: Epoch 838 
2025-08-28 21:56:53.349158: Current learning rate: 0.00194 
2025-08-28 21:57:10.172338: train_loss -0.5938 
2025-08-28 21:57:10.184865: val_loss -0.5019 
2025-08-28 21:57:10.188999: Pseudo dice [np.float32(0.7275)] 
2025-08-28 21:57:10.195869: Epoch time: 16.84 s 
2025-08-28 21:57:11.058237:  
2025-08-28 21:57:11.068709: Epoch 839 
2025-08-28 21:57:11.080230: Current learning rate: 0.00193 
2025-08-28 21:57:27.748610: train_loss -0.5666 
2025-08-28 21:57:27.756253: val_loss -0.5482 
2025-08-28 21:57:27.764919: Pseudo dice [np.float32(0.7345)] 
2025-08-28 21:57:27.769974: Epoch time: 16.69 s 
2025-08-28 21:57:28.462192:  
2025-08-28 21:57:28.473615: Epoch 840 
2025-08-28 21:57:28.480478: Current learning rate: 0.00192 
2025-08-28 21:57:45.203084: train_loss -0.5721 
2025-08-28 21:57:45.211180: val_loss -0.6111 
2025-08-28 21:57:45.215364: Pseudo dice [np.float32(0.7986)] 
2025-08-28 21:57:45.223669: Epoch time: 16.74 s 
2025-08-28 21:57:45.929568:  
2025-08-28 21:57:45.940051: Epoch 841 
2025-08-28 21:57:45.949245: Current learning rate: 0.00191 
2025-08-28 21:58:02.248833: train_loss -0.6103 
2025-08-28 21:58:02.257409: val_loss -0.6249 
2025-08-28 21:58:02.265709: Pseudo dice [np.float32(0.821)] 
2025-08-28 21:58:02.271042: Epoch time: 16.32 s 
2025-08-28 21:58:02.963288:  
2025-08-28 21:58:02.975002: Epoch 842 
2025-08-28 21:58:02.982486: Current learning rate: 0.0019 
2025-08-28 21:58:19.703962: train_loss -0.5512 
2025-08-28 21:58:19.712315: val_loss -0.6292 
2025-08-28 21:58:19.720631: Pseudo dice [np.float32(0.8216)] 
2025-08-28 21:58:19.725851: Epoch time: 16.74 s 
2025-08-28 21:58:20.424400:  
2025-08-28 21:58:20.437830: Epoch 843 
2025-08-28 21:58:20.446326: Current learning rate: 0.00189 
2025-08-28 21:58:36.587567: train_loss -0.5798 
2025-08-28 21:58:36.595883: val_loss -0.6385 
2025-08-28 21:58:36.603861: Pseudo dice [np.float32(0.8074)] 
2025-08-28 21:58:36.609263: Epoch time: 16.17 s 
2025-08-28 21:58:37.297541:  
2025-08-28 21:58:37.306870: Epoch 844 
2025-08-28 21:58:37.314207: Current learning rate: 0.00188 
2025-08-28 21:58:53.641848: train_loss -0.604 
2025-08-28 21:58:53.650395: val_loss -0.6362 
2025-08-28 21:58:53.654537: Pseudo dice [np.float32(0.8009)] 
2025-08-28 21:58:53.661764: Epoch time: 16.35 s 
2025-08-28 21:58:54.511636:  
2025-08-28 21:58:54.520013: Epoch 845 
2025-08-28 21:58:54.525090: Current learning rate: 0.00187 
2025-08-28 21:59:10.984489: train_loss -0.585 
2025-08-28 21:59:10.992693: val_loss -0.5938 
2025-08-28 21:59:11.000417: Pseudo dice [np.float32(0.806)] 
2025-08-28 21:59:11.005855: Epoch time: 16.48 s 
2025-08-28 21:59:11.704826:  
2025-08-28 21:59:11.714848: Epoch 846 
2025-08-28 21:59:11.723078: Current learning rate: 0.00186 
2025-08-28 21:59:28.422633: train_loss -0.5809 
2025-08-28 21:59:28.434782: val_loss -0.5942 
2025-08-28 21:59:28.439609: Pseudo dice [np.float32(0.7574)] 
2025-08-28 21:59:28.446597: Epoch time: 16.72 s 
2025-08-28 21:59:29.148234:  
2025-08-28 21:59:29.160825: Epoch 847 
2025-08-28 21:59:29.167412: Current learning rate: 0.00185 
2025-08-28 21:59:45.627519: train_loss -0.5706 
2025-08-28 21:59:45.635619: val_loss -0.5871 
2025-08-28 21:59:45.640157: Pseudo dice [np.float32(0.7808)] 
2025-08-28 21:59:45.646986: Epoch time: 16.48 s 
2025-08-28 21:59:46.343525:  
2025-08-28 21:59:46.350848: Epoch 848 
2025-08-28 21:59:46.356056: Current learning rate: 0.00184 
2025-08-28 22:00:03.341818: train_loss -0.599 
2025-08-28 22:00:03.349146: val_loss -0.5891 
2025-08-28 22:00:03.353346: Pseudo dice [np.float32(0.8007)] 
2025-08-28 22:00:03.362612: Epoch time: 17.0 s 
2025-08-28 22:00:04.075612:  
2025-08-28 22:00:04.083697: Epoch 849 
2025-08-28 22:00:04.093626: Current learning rate: 0.00182 
2025-08-28 22:00:20.733540: train_loss -0.5493 
2025-08-28 22:00:20.741501: val_loss -0.6046 
2025-08-28 22:00:20.745676: Pseudo dice [np.float32(0.7921)] 
2025-08-28 22:00:20.752984: Epoch time: 16.66 s 
2025-08-28 22:00:21.668546:  
2025-08-28 22:00:21.676879: Epoch 850 
2025-08-28 22:00:21.681944: Current learning rate: 0.00181 
2025-08-28 22:00:38.455408: train_loss -0.594 
2025-08-28 22:00:38.463436: val_loss -0.5615 
2025-08-28 22:00:38.471769: Pseudo dice [np.float32(0.789)] 
2025-08-28 22:00:38.478424: Epoch time: 16.79 s 
2025-08-28 22:00:39.156745:  
2025-08-28 22:00:39.165145: Epoch 851 
2025-08-28 22:00:39.170310: Current learning rate: 0.0018 
2025-08-28 22:00:55.985052: train_loss -0.548 
2025-08-28 22:00:55.993379: val_loss -0.5836 
2025-08-28 22:00:55.997839: Pseudo dice [np.float32(0.7812)] 
2025-08-28 22:00:56.005745: Epoch time: 16.83 s 
2025-08-28 22:00:56.846795:  
2025-08-28 22:00:56.856731: Epoch 852 
2025-08-28 22:00:56.866597: Current learning rate: 0.00179 
2025-08-28 22:01:13.886538: train_loss -0.5952 
2025-08-28 22:01:13.895604: val_loss -0.5703 
2025-08-28 22:01:13.901687: Pseudo dice [np.float32(0.7195)] 
2025-08-28 22:01:13.906435: Epoch time: 17.04 s 
2025-08-28 22:01:14.620159:  
2025-08-28 22:01:14.628566: Epoch 853 
2025-08-28 22:01:14.638098: Current learning rate: 0.00178 
2025-08-28 22:01:31.429420: train_loss -0.6035 
2025-08-28 22:01:31.437108: val_loss -0.5272 
2025-08-28 22:01:31.441428: Pseudo dice [np.float32(0.7777)] 
2025-08-28 22:01:31.450502: Epoch time: 16.81 s 
2025-08-28 22:01:32.127299:  
2025-08-28 22:01:32.135649: Epoch 854 
2025-08-28 22:01:32.143048: Current learning rate: 0.00177 
2025-08-28 22:01:49.113363: train_loss -0.5844 
2025-08-28 22:01:49.121672: val_loss -0.6181 
2025-08-28 22:01:49.130166: Pseudo dice [np.float32(0.7861)] 
2025-08-28 22:01:49.135252: Epoch time: 16.99 s 
2025-08-28 22:01:49.831564:  
2025-08-28 22:01:49.845802: Epoch 855 
2025-08-28 22:01:49.851719: Current learning rate: 0.00176 
2025-08-28 22:02:06.726572: train_loss -0.597 
2025-08-28 22:02:06.735151: val_loss -0.629 
2025-08-28 22:02:06.743191: Pseudo dice [np.float32(0.7613)] 
2025-08-28 22:02:06.749420: Epoch time: 16.9 s 
2025-08-28 22:02:07.462628:  
2025-08-28 22:02:07.473673: Epoch 856 
2025-08-28 22:02:07.482514: Current learning rate: 0.00175 
2025-08-28 22:02:23.868976: train_loss -0.5551 
2025-08-28 22:02:23.876963: val_loss -0.6669 
2025-08-28 22:02:23.881146: Pseudo dice [np.float32(0.8058)] 
2025-08-28 22:02:23.888406: Epoch time: 16.41 s 
2025-08-28 22:02:24.596355:  
2025-08-28 22:02:24.604627: Epoch 857 
2025-08-28 22:02:24.612162: Current learning rate: 0.00174 
2025-08-28 22:02:41.373759: train_loss -0.6169 
2025-08-28 22:02:41.386137: val_loss -0.5496 
2025-08-28 22:02:41.390569: Pseudo dice [np.float32(0.7536)] 
2025-08-28 22:02:41.397549: Epoch time: 16.78 s 
2025-08-28 22:02:42.088833:  
2025-08-28 22:02:42.096295: Epoch 858 
2025-08-28 22:02:42.102401: Current learning rate: 0.00173 
2025-08-28 22:02:58.645807: train_loss -0.6151 
2025-08-28 22:02:58.653381: val_loss -0.5706 
2025-08-28 22:02:58.657825: Pseudo dice [np.float32(0.775)] 
2025-08-28 22:02:58.665885: Epoch time: 16.56 s 
2025-08-28 22:02:59.492716:  
2025-08-28 22:02:59.502060: Epoch 859 
2025-08-28 22:02:59.514873: Current learning rate: 0.00172 
2025-08-28 22:03:15.977319: train_loss -0.5862 
2025-08-28 22:03:15.989411: val_loss -0.5582 
2025-08-28 22:03:15.998056: Pseudo dice [np.float32(0.7081)] 
2025-08-28 22:03:16.008717: Epoch time: 16.49 s 
2025-08-28 22:03:16.725453:  
2025-08-28 22:03:16.736063: Epoch 860 
2025-08-28 22:03:16.746461: Current learning rate: 0.0017 
2025-08-28 22:03:33.296558: train_loss -0.5984 
2025-08-28 22:03:33.304658: val_loss -0.6295 
2025-08-28 22:03:33.308851: Pseudo dice [np.float32(0.8004)] 
2025-08-28 22:03:33.318091: Epoch time: 16.57 s 
2025-08-28 22:03:34.011600:  
2025-08-28 22:03:34.019899: Epoch 861 
2025-08-28 22:03:34.026145: Current learning rate: 0.00169 
2025-08-28 22:03:50.763798: train_loss -0.5975 
2025-08-28 22:03:50.772118: val_loss -0.5781 
2025-08-28 22:03:50.776267: Pseudo dice [np.float32(0.7396)] 
2025-08-28 22:03:50.783829: Epoch time: 16.75 s 
2025-08-28 22:03:51.477967:  
2025-08-28 22:03:51.487096: Epoch 862 
2025-08-28 22:03:51.496958: Current learning rate: 0.00168 
2025-08-28 22:04:07.876686: train_loss -0.6068 
2025-08-28 22:04:07.885025: val_loss -0.6158 
2025-08-28 22:04:07.893401: Pseudo dice [np.float32(0.7765)] 
2025-08-28 22:04:07.898323: Epoch time: 16.4 s 
2025-08-28 22:04:08.579462:  
2025-08-28 22:04:08.589536: Epoch 863 
2025-08-28 22:04:08.598769: Current learning rate: 0.00167 
2025-08-28 22:04:25.502968: train_loss -0.5937 
2025-08-28 22:04:25.510963: val_loss -0.5563 
2025-08-28 22:04:25.515128: Pseudo dice [np.float32(0.8103)] 
2025-08-28 22:04:25.524161: Epoch time: 16.92 s 
2025-08-28 22:04:26.219931:  
2025-08-28 22:04:26.228441: Epoch 864 
2025-08-28 22:04:26.233566: Current learning rate: 0.00166 
2025-08-28 22:04:42.966278: train_loss -0.6015 
2025-08-28 22:04:42.974240: val_loss -0.6457 
2025-08-28 22:04:42.981330: Pseudo dice [np.float32(0.7821)] 
2025-08-28 22:04:42.987533: Epoch time: 16.75 s 
2025-08-28 22:04:43.837489:  
2025-08-28 22:04:43.848500: Epoch 865 
2025-08-28 22:04:43.854679: Current learning rate: 0.00165 
2025-08-28 22:05:00.529247: train_loss -0.5775 
2025-08-28 22:05:00.537605: val_loss -0.6154 
2025-08-28 22:05:00.545940: Pseudo dice [np.float32(0.8299)] 
2025-08-28 22:05:00.551509: Epoch time: 16.69 s 
2025-08-28 22:05:01.252916:  
2025-08-28 22:05:01.262274: Epoch 866 
2025-08-28 22:05:01.272575: Current learning rate: 0.00164 
2025-08-28 22:05:17.655628: train_loss -0.572 
2025-08-28 22:05:17.663077: val_loss -0.4894 
2025-08-28 22:05:17.671794: Pseudo dice [np.float32(0.7021)] 
2025-08-28 22:05:17.677585: Epoch time: 16.4 s 
2025-08-28 22:05:18.384544:  
2025-08-28 22:05:18.395331: Epoch 867 
2025-08-28 22:05:18.405672: Current learning rate: 0.00163 
2025-08-28 22:05:35.105452: train_loss -0.5982 
2025-08-28 22:05:35.113837: val_loss -0.6203 
2025-08-28 22:05:35.117965: Pseudo dice [np.float32(0.7811)] 
2025-08-28 22:05:35.124084: Epoch time: 16.72 s 
2025-08-28 22:05:35.797658:  
2025-08-28 22:05:35.805982: Epoch 868 
2025-08-28 22:05:35.811351: Current learning rate: 0.00162 
2025-08-28 22:05:52.372802: train_loss -0.6179 
2025-08-28 22:05:52.381051: val_loss -0.5799 
2025-08-28 22:05:52.389418: Pseudo dice [np.float32(0.7414)] 
2025-08-28 22:05:52.394872: Epoch time: 16.58 s 
2025-08-28 22:05:53.088932:  
2025-08-28 22:05:53.099731: Epoch 869 
2025-08-28 22:05:53.108800: Current learning rate: 0.00161 
2025-08-28 22:06:09.961082: train_loss -0.6121 
2025-08-28 22:06:09.973629: val_loss -0.6553 
2025-08-28 22:06:09.977818: Pseudo dice [np.float32(0.8478)] 
2025-08-28 22:06:09.987008: Epoch time: 16.87 s 
2025-08-28 22:06:10.677308:  
2025-08-28 22:06:10.687913: Epoch 870 
2025-08-28 22:06:10.691373: Current learning rate: 0.00159 
2025-08-28 22:06:27.198873: train_loss -0.6342 
2025-08-28 22:06:27.203329: val_loss -0.6296 
2025-08-28 22:06:27.211675: Pseudo dice [np.float32(0.8168)] 
2025-08-28 22:06:27.217143: Epoch time: 16.52 s 
2025-08-28 22:06:27.921695:  
2025-08-28 22:06:27.930054: Epoch 871 
2025-08-28 22:06:27.936310: Current learning rate: 0.00158 
2025-08-28 22:06:44.545689: train_loss -0.5943 
2025-08-28 22:06:44.554010: val_loss -0.6347 
2025-08-28 22:06:44.562330: Pseudo dice [np.float32(0.7902)] 
2025-08-28 22:06:44.567310: Epoch time: 16.63 s 
2025-08-28 22:06:45.237898:  
2025-08-28 22:06:45.247368: Epoch 872 
2025-08-28 22:06:45.252531: Current learning rate: 0.00157 
2025-08-28 22:07:02.159070: train_loss -0.6396 
2025-08-28 22:07:02.171907: val_loss -0.5566 
2025-08-28 22:07:02.180119: Pseudo dice [np.float32(0.7967)] 
2025-08-28 22:07:02.186237: Epoch time: 16.92 s 
2025-08-28 22:07:03.051363:  
2025-08-28 22:07:03.064791: Epoch 873 
2025-08-28 22:07:03.071521: Current learning rate: 0.00156 
2025-08-28 22:07:19.705753: train_loss -0.6121 
2025-08-28 22:07:19.714099: val_loss -0.5958 
2025-08-28 22:07:19.718304: Pseudo dice [np.float32(0.7846)] 
2025-08-28 22:07:19.726351: Epoch time: 16.66 s 
2025-08-28 22:07:20.423105:  
2025-08-28 22:07:20.432192: Epoch 874 
2025-08-28 22:07:20.437699: Current learning rate: 0.00155 
2025-08-28 22:07:36.781477: train_loss -0.6172 
2025-08-28 22:07:36.789502: val_loss -0.5879 
2025-08-28 22:07:36.797829: Pseudo dice [np.float32(0.8086)] 
2025-08-28 22:07:36.803488: Epoch time: 16.36 s 
2025-08-28 22:07:37.508885:  
2025-08-28 22:07:37.516304: Epoch 875 
2025-08-28 22:07:37.522409: Current learning rate: 0.00154 
2025-08-28 22:07:54.086896: train_loss -0.5856 
2025-08-28 22:07:54.094277: val_loss -0.6042 
2025-08-28 22:07:54.102956: Pseudo dice [np.float32(0.8337)] 
2025-08-28 22:07:54.108025: Epoch time: 16.58 s 
2025-08-28 22:07:54.805370:  
2025-08-28 22:07:54.815763: Epoch 876 
2025-08-28 22:07:54.823696: Current learning rate: 0.00153 
2025-08-28 22:08:11.478534: train_loss -0.6146 
2025-08-28 22:08:11.486972: val_loss -0.5249 
2025-08-28 22:08:11.495003: Pseudo dice [np.float32(0.8057)] 
2025-08-28 22:08:11.499921: Epoch time: 16.68 s 
2025-08-28 22:08:12.184315:  
2025-08-28 22:08:12.192656: Epoch 877 
2025-08-28 22:08:12.200979: Current learning rate: 0.00152 
2025-08-28 22:08:28.949898: train_loss -0.6102 
2025-08-28 22:08:28.958249: val_loss -0.6274 
2025-08-28 22:08:28.962445: Pseudo dice [np.float32(0.7924)] 
2025-08-28 22:08:28.971686: Epoch time: 16.77 s 
2025-08-28 22:08:29.671753:  
2025-08-28 22:08:29.682443: Epoch 878 
2025-08-28 22:08:29.689243: Current learning rate: 0.00151 
2025-08-28 22:08:46.513267: train_loss -0.6236 
2025-08-28 22:08:46.521645: val_loss -0.5521 
2025-08-28 22:08:46.526230: Pseudo dice [np.float32(0.7575)] 
2025-08-28 22:08:46.533090: Epoch time: 16.84 s 
2025-08-28 22:08:47.230579:  
2025-08-28 22:08:47.238851: Epoch 879 
2025-08-28 22:08:47.248308: Current learning rate: 0.00149 
2025-08-28 22:09:03.672600: train_loss -0.5877 
2025-08-28 22:09:03.684603: val_loss -0.6344 
2025-08-28 22:09:03.688782: Pseudo dice [np.float32(0.8048)] 
2025-08-28 22:09:03.695927: Epoch time: 16.44 s 
2025-08-28 22:09:04.531128:  
2025-08-28 22:09:04.541492: Epoch 880 
2025-08-28 22:09:04.551186: Current learning rate: 0.00148 
2025-08-28 22:09:21.156823: train_loss -0.6135 
2025-08-28 22:09:21.164552: val_loss -0.5992 
2025-08-28 22:09:21.172920: Pseudo dice [np.float32(0.8079)] 
2025-08-28 22:09:21.179086: Epoch time: 16.63 s 
2025-08-28 22:09:21.866272:  
2025-08-28 22:09:21.877631: Epoch 881 
2025-08-28 22:09:21.887476: Current learning rate: 0.00147 
2025-08-28 22:09:38.064853: train_loss -0.6053 
2025-08-28 22:09:38.073128: val_loss -0.6705 
2025-08-28 22:09:38.081459: Pseudo dice [np.float32(0.8384)] 
2025-08-28 22:09:38.087751: Epoch time: 16.2 s 
2025-08-28 22:09:38.093689: Yayy! New best EMA pseudo Dice: 0.7972999811172485 
2025-08-28 22:09:38.968750:  
2025-08-28 22:09:38.978033: Epoch 882 
2025-08-28 22:09:38.988248: Current learning rate: 0.00146 
2025-08-28 22:09:55.761595: train_loss -0.5858 
2025-08-28 22:09:55.769950: val_loss -0.5659 
2025-08-28 22:09:55.778294: Pseudo dice [np.float32(0.7864)] 
2025-08-28 22:09:55.783373: Epoch time: 16.79 s 
2025-08-28 22:09:56.464362:  
2025-08-28 22:09:56.475919: Epoch 883 
2025-08-28 22:09:56.487031: Current learning rate: 0.00145 
2025-08-28 22:10:13.099759: train_loss -0.6025 
2025-08-28 22:10:13.108109: val_loss -0.6118 
2025-08-28 22:10:13.112214: Pseudo dice [np.float32(0.7704)] 
2025-08-28 22:10:13.121492: Epoch time: 16.64 s 
2025-08-28 22:10:13.799370:  
2025-08-28 22:10:13.806651: Epoch 884 
2025-08-28 22:10:13.813973: Current learning rate: 0.00144 
2025-08-28 22:10:30.387249: train_loss -0.6029 
2025-08-28 22:10:30.392044: val_loss -0.6382 
2025-08-28 22:10:30.400418: Pseudo dice [np.float32(0.8118)] 
2025-08-28 22:10:30.406564: Epoch time: 16.59 s 
2025-08-28 22:10:31.100919:  
2025-08-28 22:10:31.111677: Epoch 885 
2025-08-28 22:10:31.122301: Current learning rate: 0.00143 
2025-08-28 22:10:48.005744: train_loss -0.611 
2025-08-28 22:10:48.013819: val_loss -0.6035 
2025-08-28 22:10:48.018456: Pseudo dice [np.float32(0.8216)] 
2025-08-28 22:10:48.026409: Epoch time: 16.91 s 
2025-08-28 22:10:48.031400: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2025-08-28 22:10:49.071021:  
2025-08-28 22:10:49.079474: Epoch 886 
2025-08-28 22:10:49.087475: Current learning rate: 0.00142 
2025-08-28 22:11:05.189328: train_loss -0.5972 
2025-08-28 22:11:05.197650: val_loss -0.555 
2025-08-28 22:11:05.205542: Pseudo dice [np.float32(0.7913)] 
2025-08-28 22:11:05.210173: Epoch time: 16.12 s 
2025-08-28 22:11:05.899369:  
2025-08-28 22:11:05.909883: Epoch 887 
2025-08-28 22:11:05.916816: Current learning rate: 0.00141 
2025-08-28 22:11:22.469028: train_loss -0.5999 
2025-08-28 22:11:22.481560: val_loss -0.5838 
2025-08-28 22:11:22.486037: Pseudo dice [np.float32(0.7897)] 
2025-08-28 22:11:22.493289: Epoch time: 16.57 s 
2025-08-28 22:11:23.205121:  
2025-08-28 22:11:23.215506: Epoch 888 
2025-08-28 22:11:23.224561: Current learning rate: 0.00139 
2025-08-28 22:11:39.919801: train_loss -0.6071 
2025-08-28 22:11:39.928152: val_loss -0.6162 
2025-08-28 22:11:39.936504: Pseudo dice [np.float32(0.7976)] 
2025-08-28 22:11:39.942038: Epoch time: 16.72 s 
2025-08-28 22:11:40.634120:  
2025-08-28 22:11:40.642447: Epoch 889 
2025-08-28 22:11:40.651748: Current learning rate: 0.00138 
2025-08-28 22:11:57.100142: train_loss -0.5833 
2025-08-28 22:11:57.111959: val_loss -0.5833 
2025-08-28 22:11:57.116453: Pseudo dice [np.float32(0.7775)] 
2025-08-28 22:11:57.123423: Epoch time: 16.47 s 
2025-08-28 22:11:57.815699:  
2025-08-28 22:11:57.826448: Epoch 890 
2025-08-28 22:11:57.833840: Current learning rate: 0.00137 
2025-08-28 22:12:14.256764: train_loss -0.6047 
2025-08-28 22:12:14.262768: val_loss -0.5918 
2025-08-28 22:12:14.270794: Pseudo dice [np.float32(0.7728)] 
2025-08-28 22:12:14.277184: Epoch time: 16.44 s 
2025-08-28 22:12:14.974921:  
2025-08-28 22:12:14.985019: Epoch 891 
2025-08-28 22:12:14.994231: Current learning rate: 0.00136 
2025-08-28 22:12:31.625622: train_loss -0.5737 
2025-08-28 22:12:31.633861: val_loss -0.5952 
2025-08-28 22:12:31.638119: Pseudo dice [np.float32(0.8071)] 
2025-08-28 22:12:31.646531: Epoch time: 16.65 s 
2025-08-28 22:12:32.350008:  
2025-08-28 22:12:32.358698: Epoch 892 
2025-08-28 22:12:32.364222: Current learning rate: 0.00135 
2025-08-28 22:12:47.904627: train_loss -0.5946 
2025-08-28 22:12:47.912745: val_loss -0.5975 
2025-08-28 22:12:47.916907: Pseudo dice [np.float32(0.7629)] 
2025-08-28 22:12:47.925901: Epoch time: 15.56 s 
2025-08-28 22:12:48.715500:  
2025-08-28 22:12:48.724838: Epoch 893 
2025-08-28 22:12:48.731189: Current learning rate: 0.00134 
2025-08-28 22:13:03.686757: train_loss -0.6017 
2025-08-28 22:13:03.699280: val_loss -0.6245 
2025-08-28 22:13:03.703459: Pseudo dice [np.float32(0.8176)] 
2025-08-28 22:13:03.712728: Epoch time: 14.97 s 
2025-08-28 22:13:04.363559:  
2025-08-28 22:13:04.372828: Epoch 894 
2025-08-28 22:13:04.384289: Current learning rate: 0.00133 
2025-08-28 22:13:19.331897: train_loss -0.6126 
2025-08-28 22:13:19.339963: val_loss -0.577 
2025-08-28 22:13:19.348283: Pseudo dice [np.float32(0.7625)] 
2025-08-28 22:13:19.353662: Epoch time: 14.97 s 
2025-08-28 22:13:19.996821:  
2025-08-28 22:13:20.005132: Epoch 895 
2025-08-28 22:13:20.010264: Current learning rate: 0.00132 
2025-08-28 22:13:35.393456: train_loss -0.5945 
2025-08-28 22:13:35.402252: val_loss -0.5531 
2025-08-28 22:13:35.412106: Pseudo dice [np.float32(0.6883)] 
2025-08-28 22:13:35.418441: Epoch time: 15.4 s 
2025-08-28 22:13:36.053752:  
2025-08-28 22:13:36.061903: Epoch 896 
2025-08-28 22:13:36.069006: Current learning rate: 0.0013 
2025-08-28 22:13:50.980208: train_loss -0.5832 
2025-08-28 22:13:50.988232: val_loss -0.6604 
2025-08-28 22:13:50.996534: Pseudo dice [np.float32(0.8148)] 
2025-08-28 22:13:51.001917: Epoch time: 14.93 s 
2025-08-28 22:13:51.645042:  
2025-08-28 22:13:51.653380: Epoch 897 
2025-08-28 22:13:51.658536: Current learning rate: 0.00129 
2025-08-28 22:14:06.616813: train_loss -0.5769 
2025-08-28 22:14:06.629025: val_loss -0.5908 
2025-08-28 22:14:06.633429: Pseudo dice [np.float32(0.7718)] 
2025-08-28 22:14:06.641022: Epoch time: 14.97 s 
2025-08-28 22:14:07.283539:  
2025-08-28 22:14:07.291832: Epoch 898 
2025-08-28 22:14:07.298173: Current learning rate: 0.00128 
2025-08-28 22:14:22.565583: train_loss -0.6161 
2025-08-28 22:14:22.573891: val_loss -0.6594 
2025-08-28 22:14:22.578111: Pseudo dice [np.float32(0.8235)] 
2025-08-28 22:14:22.586222: Epoch time: 15.28 s 
2025-08-28 22:14:23.232877:  
2025-08-28 22:14:23.241100: Epoch 899 
2025-08-28 22:14:23.248502: Current learning rate: 0.00127 
2025-08-28 22:14:38.218941: train_loss -0.5923 
2025-08-28 22:14:38.227230: val_loss -0.7027 
2025-08-28 22:14:38.231294: Pseudo dice [np.float32(0.8486)] 
2025-08-28 22:14:38.238500: Epoch time: 14.98 s 
2025-08-28 22:14:39.205013:  
2025-08-28 22:14:39.215365: Epoch 900 
2025-08-28 22:14:39.223751: Current learning rate: 0.00126 
2025-08-28 22:14:54.543391: train_loss -0.6245 
2025-08-28 22:14:54.551728: val_loss -0.64 
2025-08-28 22:14:54.556098: Pseudo dice [np.float32(0.7863)] 
2025-08-28 22:14:54.565586: Epoch time: 15.34 s 
2025-08-28 22:14:55.215375:  
2025-08-28 22:14:55.223047: Epoch 901 
2025-08-28 22:14:55.228441: Current learning rate: 0.00125 
2025-08-28 22:15:10.075530: train_loss -0.6196 
2025-08-28 22:15:10.083872: val_loss -0.5905 
2025-08-28 22:15:10.092194: Pseudo dice [np.float32(0.7657)] 
2025-08-28 22:15:10.098792: Epoch time: 14.86 s 
2025-08-28 22:15:10.748103:  
2025-08-28 22:15:10.756428: Epoch 902 
2025-08-28 22:15:10.761533: Current learning rate: 0.00124 
2025-08-28 22:15:26.154499: train_loss -0.624 
2025-08-28 22:15:26.162926: val_loss -0.686 
2025-08-28 22:15:26.166622: Pseudo dice [np.float32(0.7911)] 
2025-08-28 22:15:26.175609: Epoch time: 15.41 s 
2025-08-28 22:15:26.822405:  
2025-08-28 22:15:26.830771: Epoch 903 
2025-08-28 22:15:26.835954: Current learning rate: 0.00122 
2025-08-28 22:15:41.982378: train_loss -0.6171 
2025-08-28 22:15:41.992973: val_loss -0.6166 
2025-08-28 22:15:41.999054: Pseudo dice [np.float32(0.7666)] 
2025-08-28 22:15:42.004443: Epoch time: 15.16 s 
2025-08-28 22:15:42.665304:  
2025-08-28 22:15:42.678360: Epoch 904 
2025-08-28 22:15:42.683313: Current learning rate: 0.00121 
2025-08-28 22:15:57.639903: train_loss -0.6091 
2025-08-28 22:15:57.652227: val_loss -0.6312 
2025-08-28 22:15:57.656394: Pseudo dice [np.float32(0.7354)] 
2025-08-28 22:15:57.662472: Epoch time: 14.98 s 
2025-08-28 22:15:58.300739:  
2025-08-28 22:15:58.308015: Epoch 905 
2025-08-28 22:15:58.313196: Current learning rate: 0.0012 
2025-08-28 22:16:13.526367: train_loss -0.6032 
2025-08-28 22:16:13.534722: val_loss -0.6424 
2025-08-28 22:16:13.538882: Pseudo dice [np.float32(0.8119)] 
2025-08-28 22:16:13.545958: Epoch time: 15.23 s 
2025-08-28 22:16:14.194866:  
2025-08-28 22:16:14.201941: Epoch 906 
2025-08-28 22:16:14.208328: Current learning rate: 0.00119 
2025-08-28 22:16:29.484173: train_loss -0.6146 
2025-08-28 22:16:29.492326: val_loss -0.5128 
2025-08-28 22:16:29.496498: Pseudo dice [np.float32(0.7456)] 
2025-08-28 22:16:29.506069: Epoch time: 15.29 s 
2025-08-28 22:16:30.287853:  
2025-08-28 22:16:30.295215: Epoch 907 
2025-08-28 22:16:30.301300: Current learning rate: 0.00118 
2025-08-28 22:16:46.301544: train_loss -0.6105 
2025-08-28 22:16:46.309119: val_loss -0.6368 
2025-08-28 22:16:46.313334: Pseudo dice [np.float32(0.7937)] 
2025-08-28 22:16:46.322461: Epoch time: 16.01 s 
2025-08-28 22:16:47.035948:  
2025-08-28 22:16:47.044425: Epoch 908 
2025-08-28 22:16:47.054909: Current learning rate: 0.00117 
2025-08-28 22:17:03.672814: train_loss -0.6074 
2025-08-28 22:17:03.680653: val_loss -0.6333 
2025-08-28 22:17:03.689003: Pseudo dice [np.float32(0.7775)] 
2025-08-28 22:17:03.694379: Epoch time: 16.64 s 
2025-08-28 22:17:04.389569:  
2025-08-28 22:17:04.399151: Epoch 909 
2025-08-28 22:17:04.406925: Current learning rate: 0.00116 
2025-08-28 22:17:20.964573: train_loss -0.5822 
2025-08-28 22:17:20.972916: val_loss -0.671 
2025-08-28 22:17:20.981679: Pseudo dice [np.float32(0.8073)] 
2025-08-28 22:17:20.986761: Epoch time: 16.58 s 
2025-08-28 22:17:21.689211:  
2025-08-28 22:17:21.699687: Epoch 910 
2025-08-28 22:17:21.709885: Current learning rate: 0.00115 
2025-08-28 22:17:38.202951: train_loss -0.6123 
2025-08-28 22:17:38.210970: val_loss -0.6361 
2025-08-28 22:17:38.219193: Pseudo dice [np.float32(0.8184)] 
2025-08-28 22:17:38.224758: Epoch time: 16.52 s 
2025-08-28 22:17:38.923975:  
2025-08-28 22:17:38.935807: Epoch 911 
2025-08-28 22:17:38.942497: Current learning rate: 0.00113 
2025-08-28 22:17:55.186353: train_loss -0.6138 
2025-08-28 22:17:55.194609: val_loss -0.6142 
2025-08-28 22:17:55.198804: Pseudo dice [np.float32(0.8266)] 
2025-08-28 22:17:55.207920: Epoch time: 16.26 s 
2025-08-28 22:17:55.917246:  
2025-08-28 22:17:55.927610: Epoch 912 
2025-08-28 22:17:55.937134: Current learning rate: 0.00112 
2025-08-28 22:18:12.499378: train_loss -0.6162 
2025-08-28 22:18:12.507731: val_loss -0.6418 
2025-08-28 22:18:12.516053: Pseudo dice [np.float32(0.7976)] 
2025-08-28 22:18:12.522214: Epoch time: 16.58 s 
2025-08-28 22:18:13.354200:  
2025-08-28 22:18:13.362568: Epoch 913 
2025-08-28 22:18:13.368635: Current learning rate: 0.00111 
2025-08-28 22:18:30.004712: train_loss -0.6142 
2025-08-28 22:18:30.012685: val_loss -0.5862 
2025-08-28 22:18:30.021049: Pseudo dice [np.float32(0.8098)] 
2025-08-28 22:18:30.026449: Epoch time: 16.65 s 
2025-08-28 22:18:30.702913:  
2025-08-28 22:18:30.710338: Epoch 914 
2025-08-28 22:18:30.717445: Current learning rate: 0.0011 
2025-08-28 22:18:47.509320: train_loss -0.6097 
2025-08-28 22:18:47.517971: val_loss -0.6508 
2025-08-28 22:18:47.521849: Pseudo dice [np.float32(0.8193)] 
2025-08-28 22:18:47.530318: Epoch time: 16.81 s 
2025-08-28 22:18:48.237133:  
2025-08-28 22:18:48.247732: Epoch 915 
2025-08-28 22:18:48.256520: Current learning rate: 0.00109 
2025-08-28 22:19:05.077394: train_loss -0.6243 
2025-08-28 22:19:05.089562: val_loss -0.6596 
2025-08-28 22:19:05.097833: Pseudo dice [np.float32(0.8184)] 
2025-08-28 22:19:05.104263: Epoch time: 16.84 s 
2025-08-28 22:19:05.113692: Yayy! New best EMA pseudo Dice: 0.798799991607666 
2025-08-28 22:19:06.035951:  
2025-08-28 22:19:06.047269: Epoch 916 
2025-08-28 22:19:06.055459: Current learning rate: 0.00108 
2025-08-28 22:19:22.823787: train_loss -0.5917 
2025-08-28 22:19:22.832147: val_loss -0.6162 
2025-08-28 22:19:22.836555: Pseudo dice [np.float32(0.7976)] 
2025-08-28 22:19:22.843383: Epoch time: 16.79 s 
2025-08-28 22:19:23.531701:  
2025-08-28 22:19:23.540093: Epoch 917 
2025-08-28 22:19:23.545146: Current learning rate: 0.00106 
2025-08-28 22:19:40.057667: train_loss -0.611 
2025-08-28 22:19:40.065999: val_loss -0.6579 
2025-08-28 22:19:40.070187: Pseudo dice [np.float32(0.8065)] 
2025-08-28 22:19:40.076339: Epoch time: 16.53 s 
2025-08-28 22:19:40.083009: Yayy! New best EMA pseudo Dice: 0.7994999885559082 
2025-08-28 22:19:40.958415:  
2025-08-28 22:19:40.966769: Epoch 918 
2025-08-28 22:19:40.976352: Current learning rate: 0.00105 
2025-08-28 22:19:57.671291: train_loss -0.6047 
2025-08-28 22:19:57.679704: val_loss -0.6292 
2025-08-28 22:19:57.687394: Pseudo dice [np.float32(0.7884)] 
2025-08-28 22:19:57.691957: Epoch time: 16.71 s 
2025-08-28 22:19:58.384144:  
2025-08-28 22:19:58.392451: Epoch 919 
2025-08-28 22:19:58.397789: Current learning rate: 0.00104 
2025-08-28 22:20:14.926014: train_loss -0.6711 
2025-08-28 22:20:14.934125: val_loss -0.6087 
2025-08-28 22:20:14.938472: Pseudo dice [np.float32(0.7601)] 
2025-08-28 22:20:14.947437: Epoch time: 16.54 s 
2025-08-28 22:20:15.799542:  
2025-08-28 22:20:15.811610: Epoch 920 
2025-08-28 22:20:15.818297: Current learning rate: 0.00103 
2025-08-28 22:20:32.455846: train_loss -0.6129 
2025-08-28 22:20:32.464421: val_loss -0.5843 
2025-08-28 22:20:32.468324: Pseudo dice [np.float32(0.7729)] 
2025-08-28 22:20:32.475718: Epoch time: 16.66 s 
2025-08-28 22:20:33.164723:  
2025-08-28 22:20:33.175181: Epoch 921 
2025-08-28 22:20:33.182117: Current learning rate: 0.00102 
2025-08-28 22:20:49.518666: train_loss -0.6065 
2025-08-28 22:20:49.527260: val_loss -0.6525 
2025-08-28 22:20:49.535357: Pseudo dice [np.float32(0.7984)] 
2025-08-28 22:20:49.541593: Epoch time: 16.36 s 
2025-08-28 22:20:50.209953:  
2025-08-28 22:20:50.217257: Epoch 922 
2025-08-28 22:20:50.225664: Current learning rate: 0.00101 
2025-08-28 22:21:06.608029: train_loss -0.6265 
2025-08-28 22:21:06.619373: val_loss -0.5851 
2025-08-28 22:21:06.627796: Pseudo dice [np.float32(0.7587)] 
2025-08-28 22:21:06.633387: Epoch time: 16.4 s 
2025-08-28 22:21:07.370914:  
2025-08-28 22:21:07.378912: Epoch 923 
2025-08-28 22:21:07.384469: Current learning rate: 0.001 
2025-08-28 22:21:23.895534: train_loss -0.6271 
2025-08-28 22:21:23.903053: val_loss -0.5891 
2025-08-28 22:21:23.907695: Pseudo dice [np.float32(0.7728)] 
2025-08-28 22:21:23.914392: Epoch time: 16.53 s 
2025-08-28 22:21:24.588102:  
2025-08-28 22:21:24.596389: Epoch 924 
2025-08-28 22:21:24.601562: Current learning rate: 0.00098 
2025-08-28 22:21:41.578963: train_loss -0.6145 
2025-08-28 22:21:41.587508: val_loss -0.6085 
2025-08-28 22:21:41.595935: Pseudo dice [np.float32(0.8141)] 
2025-08-28 22:21:41.601893: Epoch time: 16.99 s 
2025-08-28 22:21:42.302593:  
2025-08-28 22:21:42.310915: Epoch 925 
2025-08-28 22:21:42.317128: Current learning rate: 0.00097 
2025-08-28 22:21:58.783792: train_loss -0.6258 
2025-08-28 22:21:58.796190: val_loss -0.6146 
2025-08-28 22:21:58.800362: Pseudo dice [np.float32(0.8289)] 
2025-08-28 22:21:58.808481: Epoch time: 16.48 s 
2025-08-28 22:21:59.512490:  
2025-08-28 22:21:59.520856: Epoch 926 
2025-08-28 22:21:59.526857: Current learning rate: 0.00096 
2025-08-28 22:22:15.788555: train_loss -0.6232 
2025-08-28 22:22:15.796649: val_loss -0.5614 
2025-08-28 22:22:15.805675: Pseudo dice [np.float32(0.8191)] 
2025-08-28 22:22:15.810674: Epoch time: 16.28 s 
2025-08-28 22:22:16.652554:  
2025-08-28 22:22:16.660846: Epoch 927 
2025-08-28 22:22:16.666050: Current learning rate: 0.00095 
2025-08-28 22:22:33.088855: train_loss -0.6095 
2025-08-28 22:22:33.097193: val_loss -0.5828 
2025-08-28 22:22:33.101346: Pseudo dice [np.float32(0.8225)] 
2025-08-28 22:22:33.110446: Epoch time: 16.44 s 
2025-08-28 22:22:33.800894:  
2025-08-28 22:22:33.808243: Epoch 928 
2025-08-28 22:22:33.814399: Current learning rate: 0.00094 
2025-08-28 22:22:50.256198: train_loss -0.6233 
2025-08-28 22:22:50.264312: val_loss -0.6549 
2025-08-28 22:22:50.272607: Pseudo dice [np.float32(0.7817)] 
2025-08-28 22:22:50.278058: Epoch time: 16.46 s 
2025-08-28 22:22:50.976342:  
2025-08-28 22:22:50.987480: Epoch 929 
2025-08-28 22:22:50.995921: Current learning rate: 0.00092 
2025-08-28 22:23:07.402378: train_loss -0.6337 
2025-08-28 22:23:07.410556: val_loss -0.6185 
2025-08-28 22:23:07.418891: Pseudo dice [np.float32(0.7997)] 
2025-08-28 22:23:07.424312: Epoch time: 16.43 s 
2025-08-28 22:23:08.150942:  
2025-08-28 22:23:08.161266: Epoch 930 
2025-08-28 22:23:08.165876: Current learning rate: 0.00091 
2025-08-28 22:23:24.444474: train_loss -0.6301 
2025-08-28 22:23:24.452569: val_loss -0.6354 
2025-08-28 22:23:24.456618: Pseudo dice [np.float32(0.7853)] 
2025-08-28 22:23:24.465097: Epoch time: 16.3 s 
2025-08-28 22:23:25.136484:  
2025-08-28 22:23:25.144776: Epoch 931 
2025-08-28 22:23:25.150134: Current learning rate: 0.0009 
2025-08-28 22:23:41.690956: train_loss -0.6363 
2025-08-28 22:23:41.701715: val_loss -0.6511 
2025-08-28 22:23:41.707542: Pseudo dice [np.float32(0.8294)] 
2025-08-28 22:23:41.713664: Epoch time: 16.56 s 
2025-08-28 22:23:41.719816: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-08-28 22:23:42.596718:  
2025-08-28 22:23:42.605055: Epoch 932 
2025-08-28 22:23:42.610251: Current learning rate: 0.00089 
2025-08-28 22:23:59.208133: train_loss -0.6043 
2025-08-28 22:23:59.216658: val_loss -0.6691 
2025-08-28 22:23:59.224814: Pseudo dice [np.float32(0.8097)] 
2025-08-28 22:23:59.231972: Epoch time: 16.61 s 
2025-08-28 22:23:59.237631: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-08-28 22:24:00.273982:  
2025-08-28 22:24:00.282099: Epoch 933 
2025-08-28 22:24:00.288195: Current learning rate: 0.00088 
2025-08-28 22:24:17.238618: train_loss -0.625 
2025-08-28 22:24:17.250717: val_loss -0.5443 
2025-08-28 22:24:17.255349: Pseudo dice [np.float32(0.7699)] 
2025-08-28 22:24:17.260817: Epoch time: 16.97 s 
2025-08-28 22:24:17.928833:  
2025-08-28 22:24:17.937235: Epoch 934 
2025-08-28 22:24:17.943340: Current learning rate: 0.00087 
2025-08-28 22:24:34.432070: train_loss -0.628 
2025-08-28 22:24:34.439142: val_loss -0.7107 
2025-08-28 22:24:34.447473: Pseudo dice [np.float32(0.8379)] 
2025-08-28 22:24:34.453970: Epoch time: 16.51 s 
2025-08-28 22:24:34.460546: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2025-08-28 22:24:35.326448:  
2025-08-28 22:24:35.333709: Epoch 935 
2025-08-28 22:24:35.341023: Current learning rate: 0.00085 
2025-08-28 22:24:51.948303: train_loss -0.6211 
2025-08-28 22:24:51.956980: val_loss -0.5821 
2025-08-28 22:24:51.965000: Pseudo dice [np.float32(0.817)] 
2025-08-28 22:24:51.971223: Epoch time: 16.62 s 
2025-08-28 22:24:51.977329: Yayy! New best EMA pseudo Dice: 0.8033000230789185 
2025-08-28 22:24:52.885488:  
2025-08-28 22:24:52.896924: Epoch 936 
2025-08-28 22:24:52.904265: Current learning rate: 0.00084 
2025-08-28 22:25:09.607563: train_loss -0.6045 
2025-08-28 22:25:09.616132: val_loss -0.6073 
2025-08-28 22:25:09.624615: Pseudo dice [np.float32(0.8042)] 
2025-08-28 22:25:09.629687: Epoch time: 16.72 s 
2025-08-28 22:25:09.636583: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2025-08-28 22:25:10.537661:  
2025-08-28 22:25:10.550134: Epoch 937 
2025-08-28 22:25:10.560571: Current learning rate: 0.00083 
2025-08-28 22:25:27.580842: train_loss -0.6155 
2025-08-28 22:25:27.591054: val_loss -0.6465 
2025-08-28 22:25:27.598402: Pseudo dice [np.float32(0.804)] 
2025-08-28 22:25:27.604746: Epoch time: 17.04 s 
2025-08-28 22:25:27.612398: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2025-08-28 22:25:28.516974:  
2025-08-28 22:25:28.524337: Epoch 938 
2025-08-28 22:25:28.531734: Current learning rate: 0.00082 
2025-08-28 22:25:44.442376: train_loss -0.629 
2025-08-28 22:25:44.450761: val_loss -0.6184 
2025-08-28 22:25:44.457110: Pseudo dice [np.float32(0.8025)] 
2025-08-28 22:25:44.464182: Epoch time: 15.93 s 
2025-08-28 22:25:45.161776:  
2025-08-28 22:25:45.170082: Epoch 939 
2025-08-28 22:25:45.175363: Current learning rate: 0.00081 
2025-08-28 22:26:00.954707: train_loss -0.6392 
2025-08-28 22:26:00.967208: val_loss -0.68 
2025-08-28 22:26:00.971677: Pseudo dice [np.float32(0.7857)] 
2025-08-28 22:26:00.980998: Epoch time: 15.79 s 
2025-08-28 22:26:01.838781:  
2025-08-28 22:26:01.846516: Epoch 940 
2025-08-28 22:26:01.853470: Current learning rate: 0.00079 
2025-08-28 22:26:17.775795: train_loss -0.6097 
2025-08-28 22:26:17.784052: val_loss -0.6291 
2025-08-28 22:26:17.788202: Pseudo dice [np.float32(0.8401)] 
2025-08-28 22:26:17.796355: Epoch time: 15.94 s 
2025-08-28 22:26:17.802394: Yayy! New best EMA pseudo Dice: 0.805400013923645 
2025-08-28 22:26:18.702698:  
2025-08-28 22:26:18.710945: Epoch 941 
2025-08-28 22:26:18.718123: Current learning rate: 0.00078 
2025-08-28 22:26:34.580214: train_loss -0.6045 
2025-08-28 22:26:34.588313: val_loss -0.6458 
2025-08-28 22:26:34.592737: Pseudo dice [np.float32(0.8381)] 
2025-08-28 22:26:34.599892: Epoch time: 15.88 s 
2025-08-28 22:26:34.606545: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2025-08-28 22:26:35.481908:  
2025-08-28 22:26:35.489078: Epoch 942 
2025-08-28 22:26:35.494400: Current learning rate: 0.00077 
2025-08-28 22:26:51.716030: train_loss -0.602 
2025-08-28 22:26:51.722142: val_loss -0.6423 
2025-08-28 22:26:51.726262: Pseudo dice [np.float32(0.7806)] 
2025-08-28 22:26:51.735354: Epoch time: 16.24 s 
2025-08-28 22:26:52.431093:  
2025-08-28 22:26:52.440094: Epoch 943 
2025-08-28 22:26:52.446662: Current learning rate: 0.00076 
2025-08-28 22:27:08.568056: train_loss -0.6039 
2025-08-28 22:27:08.580817: val_loss -0.6339 
2025-08-28 22:27:08.584888: Pseudo dice [np.float32(0.8212)] 
2025-08-28 22:27:08.594046: Epoch time: 16.14 s 
2025-08-28 22:27:09.297784:  
2025-08-28 22:27:09.306885: Epoch 944 
2025-08-28 22:27:09.314542: Current learning rate: 0.00075 
2025-08-28 22:27:25.122376: train_loss -0.6157 
2025-08-28 22:27:25.130774: val_loss -0.6435 
2025-08-28 22:27:25.139104: Pseudo dice [np.float32(0.7772)] 
2025-08-28 22:27:25.144504: Epoch time: 15.83 s 
2025-08-28 22:27:25.853997:  
2025-08-28 22:27:25.862365: Epoch 945 
2025-08-28 22:27:25.868587: Current learning rate: 0.00074 
2025-08-28 22:27:41.747077: train_loss -0.6205 
2025-08-28 22:27:41.755403: val_loss -0.5896 
2025-08-28 22:27:41.759551: Pseudo dice [np.float32(0.8368)] 
2025-08-28 22:27:41.768755: Epoch time: 15.9 s 
2025-08-28 22:27:42.641117:  
2025-08-28 22:27:42.649590: Epoch 946 
2025-08-28 22:27:42.656530: Current learning rate: 0.00072 
2025-08-28 22:27:58.918666: train_loss -0.6253 
2025-08-28 22:27:58.926967: val_loss -0.6107 
2025-08-28 22:27:58.935058: Pseudo dice [np.float32(0.8194)] 
2025-08-28 22:27:58.941449: Epoch time: 16.28 s 
2025-08-28 22:27:58.947388: Yayy! New best EMA pseudo Dice: 0.8087999820709229 
2025-08-28 22:27:59.850562:  
2025-08-28 22:27:59.861695: Epoch 947 
2025-08-28 22:27:59.865864: Current learning rate: 0.00071 
2025-08-28 22:28:15.739941: train_loss -0.6317 
2025-08-28 22:28:15.748239: val_loss -0.6579 
2025-08-28 22:28:15.756011: Pseudo dice [np.float32(0.8131)] 
2025-08-28 22:28:15.761601: Epoch time: 15.89 s 
2025-08-28 22:28:15.765906: Yayy! New best EMA pseudo Dice: 0.8091999888420105 
2025-08-28 22:28:16.662128:  
2025-08-28 22:28:16.670442: Epoch 948 
2025-08-28 22:28:16.680522: Current learning rate: 0.0007 
2025-08-28 22:28:32.797995: train_loss -0.6235 
2025-08-28 22:28:32.806247: val_loss -0.6132 
2025-08-28 22:28:32.810405: Pseudo dice [np.float32(0.7904)] 
2025-08-28 22:28:32.817593: Epoch time: 16.14 s 
2025-08-28 22:28:33.513282:  
2025-08-28 22:28:33.524632: Epoch 949 
2025-08-28 22:28:33.535531: Current learning rate: 0.00069 
2025-08-28 22:28:49.593919: train_loss -0.6236 
2025-08-28 22:28:49.602170: val_loss -0.606 
2025-08-28 22:28:49.606581: Pseudo dice [np.float32(0.7905)] 
2025-08-28 22:28:49.615639: Epoch time: 16.08 s 
2025-08-28 22:28:50.518781:  
2025-08-28 22:28:50.528229: Epoch 950 
2025-08-28 22:28:50.538503: Current learning rate: 0.00067 
2025-08-28 22:29:07.349440: train_loss -0.6015 
2025-08-28 22:29:07.361748: val_loss -0.5874 
2025-08-28 22:29:07.365865: Pseudo dice [np.float32(0.7928)] 
2025-08-28 22:29:07.374977: Epoch time: 16.83 s 
2025-08-28 22:29:08.063831:  
2025-08-28 22:29:08.073022: Epoch 951 
2025-08-28 22:29:08.080520: Current learning rate: 0.00066 
2025-08-28 22:29:24.670328: train_loss -0.6146 
2025-08-28 22:29:24.679098: val_loss -0.6958 
2025-08-28 22:29:24.683450: Pseudo dice [np.float32(0.8609)] 
2025-08-28 22:29:24.689423: Epoch time: 16.61 s 
2025-08-28 22:29:24.695514: Yayy! New best EMA pseudo Dice: 0.8100000023841858 
2025-08-28 22:29:25.708093:  
2025-08-28 22:29:25.716425: Epoch 952 
2025-08-28 22:29:25.724788: Current learning rate: 0.00065 
2025-08-28 22:29:42.379974: train_loss -0.6639 
2025-08-28 22:29:42.388350: val_loss -0.6754 
2025-08-28 22:29:42.392506: Pseudo dice [np.float32(0.8197)] 
2025-08-28 22:29:42.400990: Epoch time: 16.67 s 
2025-08-28 22:29:42.406384: Yayy! New best EMA pseudo Dice: 0.8109999895095825 
2025-08-28 22:29:43.293314:  
2025-08-28 22:29:43.301647: Epoch 953 
2025-08-28 22:29:43.306952: Current learning rate: 0.00064 
2025-08-28 22:29:59.819077: train_loss -0.6366 
2025-08-28 22:29:59.831444: val_loss -0.6086 
2025-08-28 22:29:59.834923: Pseudo dice [np.float32(0.8325)] 
2025-08-28 22:29:59.843572: Epoch time: 16.53 s 
2025-08-28 22:29:59.850114: Yayy! New best EMA pseudo Dice: 0.8130999803543091 
2025-08-28 22:30:00.730519:  
2025-08-28 22:30:00.737900: Epoch 954 
2025-08-28 22:30:00.744098: Current learning rate: 0.00063 
2025-08-28 22:30:17.185510: train_loss -0.6262 
2025-08-28 22:30:17.194108: val_loss -0.6469 
2025-08-28 22:30:17.202174: Pseudo dice [np.float32(0.8126)] 
2025-08-28 22:30:17.208774: Epoch time: 16.46 s 
2025-08-28 22:30:17.905001:  
2025-08-28 22:30:17.915411: Epoch 955 
2025-08-28 22:30:17.923661: Current learning rate: 0.00061 
2025-08-28 22:30:34.473971: train_loss -0.6176 
2025-08-28 22:30:34.482083: val_loss -0.635 
2025-08-28 22:30:34.490740: Pseudo dice [np.float32(0.8143)] 
2025-08-28 22:30:34.496483: Epoch time: 16.57 s 
2025-08-28 22:30:34.502913: Yayy! New best EMA pseudo Dice: 0.8131999969482422 
2025-08-28 22:30:35.429850:  
2025-08-28 22:30:35.441397: Epoch 956 
2025-08-28 22:30:35.446628: Current learning rate: 0.0006 
2025-08-28 22:30:51.778748: train_loss -0.6488 
2025-08-28 22:30:51.786825: val_loss -0.645 
2025-08-28 22:30:51.790986: Pseudo dice [np.float32(0.8266)] 
2025-08-28 22:30:51.800233: Epoch time: 16.35 s 
2025-08-28 22:30:51.805883: Yayy! New best EMA pseudo Dice: 0.8145999908447266 
2025-08-28 22:30:52.704648:  
2025-08-28 22:30:52.715373: Epoch 957 
2025-08-28 22:30:52.723131: Current learning rate: 0.00059 
2025-08-28 22:31:09.275341: train_loss -0.5919 
2025-08-28 22:31:09.287609: val_loss -0.5524 
2025-08-28 22:31:09.292089: Pseudo dice [np.float32(0.7971)] 
2025-08-28 22:31:09.297964: Epoch time: 16.57 s 
2025-08-28 22:31:09.995543:  
2025-08-28 22:31:10.002849: Epoch 958 
2025-08-28 22:31:10.008989: Current learning rate: 0.00058 
2025-08-28 22:31:26.613233: train_loss -0.6571 
2025-08-28 22:31:26.621619: val_loss -0.6055 
2025-08-28 22:31:26.625736: Pseudo dice [np.float32(0.7862)] 
2025-08-28 22:31:26.633853: Epoch time: 16.62 s 
2025-08-28 22:31:27.485972:  
2025-08-28 22:31:27.495063: Epoch 959 
2025-08-28 22:31:27.501587: Current learning rate: 0.00056 
2025-08-28 22:31:44.026728: train_loss -0.6485 
2025-08-28 22:31:44.034832: val_loss -0.7041 
2025-08-28 22:31:44.039209: Pseudo dice [np.float32(0.8311)] 
2025-08-28 22:31:44.047243: Epoch time: 16.54 s 
2025-08-28 22:31:44.750122:  
2025-08-28 22:31:44.761868: Epoch 960 
2025-08-28 22:31:44.769271: Current learning rate: 0.00055 
2025-08-28 22:32:01.138968: train_loss -0.6304 
2025-08-28 22:32:01.147800: val_loss -0.6345 
2025-08-28 22:32:01.151935: Pseudo dice [np.float32(0.815)] 
2025-08-28 22:32:01.160257: Epoch time: 16.39 s 
2025-08-28 22:32:01.869215:  
2025-08-28 22:32:01.877546: Epoch 961 
2025-08-28 22:32:01.882827: Current learning rate: 0.00054 
2025-08-28 22:32:18.638485: train_loss -0.662 
2025-08-28 22:32:18.652755: val_loss -0.5755 
2025-08-28 22:32:18.662208: Pseudo dice [np.float32(0.8087)] 
2025-08-28 22:32:18.673529: Epoch time: 16.77 s 
2025-08-28 22:32:19.427391:  
2025-08-28 22:32:19.434743: Epoch 962 
2025-08-28 22:32:19.440879: Current learning rate: 0.00053 
2025-08-28 22:32:35.824286: train_loss -0.6476 
2025-08-28 22:32:35.832469: val_loss -0.6384 
2025-08-28 22:32:35.840741: Pseudo dice [np.float32(0.7631)] 
2025-08-28 22:32:35.845631: Epoch time: 16.4 s 
2025-08-28 22:32:36.538273:  
2025-08-28 22:32:36.546620: Epoch 963 
2025-08-28 22:32:36.556142: Current learning rate: 0.00051 
2025-08-28 22:32:53.550497: train_loss -0.6314 
2025-08-28 22:32:53.558407: val_loss -0.6503 
2025-08-28 22:32:53.566815: Pseudo dice [np.float32(0.8473)] 
2025-08-28 22:32:53.571965: Epoch time: 17.01 s 
2025-08-28 22:32:54.284068:  
2025-08-28 22:32:54.293926: Epoch 964 
2025-08-28 22:32:54.299737: Current learning rate: 0.0005 
2025-08-28 22:33:10.829823: train_loss -0.6375 
2025-08-28 22:33:10.841300: val_loss -0.6581 
2025-08-28 22:33:10.847434: Pseudo dice [np.float32(0.8305)] 
2025-08-28 22:33:10.852438: Epoch time: 16.55 s 
2025-08-28 22:33:11.691147:  
2025-08-28 22:33:11.699373: Epoch 965 
2025-08-28 22:33:11.705639: Current learning rate: 0.00049 
2025-08-28 22:33:28.168153: train_loss -0.6397 
2025-08-28 22:33:28.176319: val_loss -0.6123 
2025-08-28 22:33:28.180883: Pseudo dice [np.float32(0.8102)] 
2025-08-28 22:33:28.189617: Epoch time: 16.48 s 
2025-08-28 22:33:28.886463:  
2025-08-28 22:33:28.895829: Epoch 966 
2025-08-28 22:33:28.905313: Current learning rate: 0.00048 
2025-08-28 22:33:45.401721: train_loss -0.6378 
2025-08-28 22:33:45.410252: val_loss -0.6032 
2025-08-28 22:33:45.414363: Pseudo dice [np.float32(0.7725)] 
2025-08-28 22:33:45.421699: Epoch time: 16.52 s 
2025-08-28 22:33:46.124415:  
2025-08-28 22:33:46.132832: Epoch 967 
2025-08-28 22:33:46.138665: Current learning rate: 0.00046 
2025-08-28 22:34:02.485589: train_loss -0.5871 
2025-08-28 22:34:02.493921: val_loss -0.6336 
2025-08-28 22:34:02.502262: Pseudo dice [np.float32(0.8014)] 
2025-08-28 22:34:02.507241: Epoch time: 16.36 s 
2025-08-28 22:34:03.204058:  
2025-08-28 22:34:03.211135: Epoch 968 
2025-08-28 22:34:03.217476: Current learning rate: 0.00045 
2025-08-28 22:34:19.602838: train_loss -0.6223 
2025-08-28 22:34:19.611029: val_loss -0.5371 
2025-08-28 22:34:19.615106: Pseudo dice [np.float32(0.7205)] 
2025-08-28 22:34:19.623546: Epoch time: 16.4 s 
2025-08-28 22:34:20.317021:  
2025-08-28 22:34:20.325255: Epoch 969 
2025-08-28 22:34:20.330389: Current learning rate: 0.00044 
2025-08-28 22:34:36.548748: train_loss -0.6541 
2025-08-28 22:34:36.557100: val_loss -0.6976 
2025-08-28 22:34:36.561198: Pseudo dice [np.float32(0.8237)] 
2025-08-28 22:34:36.569457: Epoch time: 16.23 s 
2025-08-28 22:34:37.256665:  
2025-08-28 22:34:37.263969: Epoch 970 
2025-08-28 22:34:37.269133: Current learning rate: 0.00043 
2025-08-28 22:34:53.745318: train_loss -0.6268 
2025-08-28 22:34:53.753511: val_loss -0.6737 
2025-08-28 22:34:53.757620: Pseudo dice [np.float32(0.8293)] 
2025-08-28 22:34:53.766165: Epoch time: 16.49 s 
2025-08-28 22:34:54.480258:  
2025-08-28 22:34:54.490613: Epoch 971 
2025-08-28 22:34:54.497872: Current learning rate: 0.00041 
2025-08-28 22:35:11.150057: train_loss -0.6486 
2025-08-28 22:35:11.158325: val_loss -0.5569 
2025-08-28 22:35:11.166685: Pseudo dice [np.float32(0.8328)] 
2025-08-28 22:35:11.172078: Epoch time: 16.67 s 
2025-08-28 22:35:12.039433:  
2025-08-28 22:35:12.050794: Epoch 972 
2025-08-28 22:35:12.059845: Current learning rate: 0.0004 
2025-08-28 22:35:28.125248: train_loss -0.6418 
2025-08-28 22:35:28.133617: val_loss -0.6115 
2025-08-28 22:35:28.137787: Pseudo dice [np.float32(0.8135)] 
2025-08-28 22:35:28.143992: Epoch time: 16.09 s 
2025-08-28 22:35:28.856247:  
2025-08-28 22:35:28.864348: Epoch 973 
2025-08-28 22:35:28.873927: Current learning rate: 0.00039 
2025-08-28 22:35:44.362565: train_loss -0.6354 
2025-08-28 22:35:44.372884: val_loss -0.5164 
2025-08-28 22:35:44.379005: Pseudo dice [np.float32(0.7873)] 
2025-08-28 22:35:44.383997: Epoch time: 15.51 s 
2025-08-28 22:35:45.113069:  
2025-08-28 22:35:45.121085: Epoch 974 
2025-08-28 22:35:45.126612: Current learning rate: 0.00037 
2025-08-28 22:36:01.066506: train_loss -0.6302 
2025-08-28 22:36:01.078856: val_loss -0.545 
2025-08-28 22:36:01.083270: Pseudo dice [np.float32(0.7927)] 
2025-08-28 22:36:01.089470: Epoch time: 15.96 s 
2025-08-28 22:36:01.801599:  
2025-08-28 22:36:01.810597: Epoch 975 
2025-08-28 22:36:01.821376: Current learning rate: 0.00036 
2025-08-28 22:36:17.695596: train_loss -0.6231 
2025-08-28 22:36:17.703940: val_loss -0.6325 
2025-08-28 22:36:17.712301: Pseudo dice [np.float32(0.797)] 
2025-08-28 22:36:17.718463: Epoch time: 15.9 s 
2025-08-28 22:36:18.439131:  
2025-08-28 22:36:18.447417: Epoch 976 
2025-08-28 22:36:18.455293: Current learning rate: 0.00035 
2025-08-28 22:36:34.637516: train_loss -0.6264 
2025-08-28 22:36:34.646088: val_loss -0.6047 
2025-08-28 22:36:34.650039: Pseudo dice [np.float32(0.7951)] 
2025-08-28 22:36:34.657358: Epoch time: 16.2 s 
2025-08-28 22:36:35.364154:  
2025-08-28 22:36:35.373661: Epoch 977 
2025-08-28 22:36:35.384105: Current learning rate: 0.00034 
2025-08-28 22:36:51.495926: train_loss -0.6271 
2025-08-28 22:36:51.500183: val_loss -0.6006 
2025-08-28 22:36:51.508801: Pseudo dice [np.float32(0.807)] 
2025-08-28 22:36:51.514785: Epoch time: 16.13 s 
2025-08-28 22:36:52.229936:  
2025-08-28 22:36:52.238341: Epoch 978 
2025-08-28 22:36:52.246778: Current learning rate: 0.00032 
2025-08-28 22:37:08.542502: train_loss -0.6284 
2025-08-28 22:37:08.555057: val_loss -0.6365 
2025-08-28 22:37:08.558910: Pseudo dice [np.float32(0.8526)] 
2025-08-28 22:37:08.566983: Epoch time: 16.31 s 
2025-08-28 22:37:09.436641:  
2025-08-28 22:37:09.446245: Epoch 979 
2025-08-28 22:37:09.452502: Current learning rate: 0.00031 
2025-08-28 22:37:25.563379: train_loss -0.6106 
2025-08-28 22:37:25.571728: val_loss -0.728 
2025-08-28 22:37:25.576079: Pseudo dice [np.float32(0.8604)] 
2025-08-28 22:37:25.585621: Epoch time: 16.13 s 
2025-08-28 22:37:26.274517:  
2025-08-28 22:37:26.282770: Epoch 980 
2025-08-28 22:37:26.287937: Current learning rate: 0.0003 
2025-08-28 22:37:42.359322: train_loss -0.6338 
2025-08-28 22:37:42.371843: val_loss -0.6214 
2025-08-28 22:37:42.376051: Pseudo dice [np.float32(0.8097)] 
2025-08-28 22:37:42.382294: Epoch time: 16.09 s 
2025-08-28 22:37:43.087127:  
2025-08-28 22:37:43.094416: Epoch 981 
2025-08-28 22:37:43.099637: Current learning rate: 0.00028 
2025-08-28 22:37:59.188582: train_loss -0.6401 
2025-08-28 22:37:59.196984: val_loss -0.5917 
2025-08-28 22:37:59.205301: Pseudo dice [np.float32(0.8283)] 
2025-08-28 22:37:59.210675: Epoch time: 16.1 s 
2025-08-28 22:37:59.217663: Yayy! New best EMA pseudo Dice: 0.8145999908447266 
2025-08-28 22:38:00.116572:  
2025-08-28 22:38:00.126050: Epoch 982 
2025-08-28 22:38:00.134047: Current learning rate: 0.00027 
2025-08-28 22:38:16.010619: train_loss -0.664 
2025-08-28 22:38:16.017928: val_loss -0.6271 
2025-08-28 22:38:16.027134: Pseudo dice [np.float32(0.8094)] 
2025-08-28 22:38:16.035525: Epoch time: 15.9 s 
2025-08-28 22:38:16.762331:  
2025-08-28 22:38:16.771775: Epoch 983 
2025-08-28 22:38:16.782166: Current learning rate: 0.00026 
2025-08-28 22:38:32.717929: train_loss -0.6557 
2025-08-28 22:38:32.726277: val_loss -0.5895 
2025-08-28 22:38:32.734671: Pseudo dice [np.float32(0.8576)] 
2025-08-28 22:38:32.740119: Epoch time: 15.96 s 
2025-08-28 22:38:32.747519: Yayy! New best EMA pseudo Dice: 0.8184000253677368 
2025-08-28 22:38:33.633431:  
2025-08-28 22:38:33.642695: Epoch 984 
2025-08-28 22:38:33.649043: Current learning rate: 0.00024 
2025-08-28 22:38:50.352240: train_loss -0.6514 
2025-08-28 22:38:50.362042: val_loss -0.646 
2025-08-28 22:38:50.364814: Pseudo dice [np.float32(0.8158)] 
2025-08-28 22:38:50.374385: Epoch time: 16.72 s 
2025-08-28 22:38:51.226943:  
2025-08-28 22:38:51.235250: Epoch 985 
2025-08-28 22:38:51.240838: Current learning rate: 0.00023 
2025-08-28 22:39:07.811575: train_loss -0.6301 
2025-08-28 22:39:07.819724: val_loss -0.6988 
2025-08-28 22:39:07.828562: Pseudo dice [np.float32(0.836)] 
2025-08-28 22:39:07.833382: Epoch time: 16.59 s 
2025-08-28 22:39:07.839244: Yayy! New best EMA pseudo Dice: 0.8199999928474426 
2025-08-28 22:39:08.744809:  
2025-08-28 22:39:08.752935: Epoch 986 
2025-08-28 22:39:08.758007: Current learning rate: 0.00021 
2025-08-28 22:39:25.041076: train_loss -0.6238 
2025-08-28 22:39:25.049723: val_loss -0.6706 
2025-08-28 22:39:25.057715: Pseudo dice [np.float32(0.8173)] 
2025-08-28 22:39:25.062732: Epoch time: 16.3 s 
2025-08-28 22:39:25.762527:  
2025-08-28 22:39:25.771820: Epoch 987 
2025-08-28 22:39:25.779184: Current learning rate: 0.0002 
2025-08-28 22:39:42.491979: train_loss -0.6323 
2025-08-28 22:39:42.500249: val_loss -0.663 
2025-08-28 22:39:42.504294: Pseudo dice [np.float32(0.8415)] 
2025-08-28 22:39:42.511481: Epoch time: 16.73 s 
2025-08-28 22:39:42.518168: Yayy! New best EMA pseudo Dice: 0.8219000101089478 
2025-08-28 22:39:43.422917:  
2025-08-28 22:39:43.432287: Epoch 988 
2025-08-28 22:39:43.440826: Current learning rate: 0.00019 
2025-08-28 22:40:00.042792: train_loss -0.6368 
2025-08-28 22:40:00.055428: val_loss -0.6185 
2025-08-28 22:40:00.059634: Pseudo dice [np.float32(0.8087)] 
2025-08-28 22:40:00.068445: Epoch time: 16.62 s 
2025-08-28 22:40:00.746405:  
2025-08-28 22:40:00.754722: Epoch 989 
2025-08-28 22:40:00.759937: Current learning rate: 0.00017 
2025-08-28 22:40:17.639457: train_loss -0.6363 
2025-08-28 22:40:17.647784: val_loss -0.6713 
2025-08-28 22:40:17.651917: Pseudo dice [np.float32(0.8166)] 
2025-08-28 22:40:17.659032: Epoch time: 16.9 s 
2025-08-28 22:40:18.400610:  
2025-08-28 22:40:18.408944: Epoch 990 
2025-08-28 22:40:18.417216: Current learning rate: 0.00016 
2025-08-28 22:40:35.015497: train_loss -0.662 
2025-08-28 22:40:35.023415: val_loss -0.6368 
2025-08-28 22:40:35.031782: Pseudo dice [np.float32(0.7488)] 
2025-08-28 22:40:35.037280: Epoch time: 16.62 s 
2025-08-28 22:40:35.715681:  
2025-08-28 22:40:35.723944: Epoch 991 
2025-08-28 22:40:35.732364: Current learning rate: 0.00014 
2025-08-28 22:40:52.495009: train_loss -0.659 
2025-08-28 22:40:52.503415: val_loss -0.6376 
2025-08-28 22:40:52.507554: Pseudo dice [np.float32(0.8297)] 
2025-08-28 22:40:52.515880: Epoch time: 16.78 s 
2025-08-28 22:40:53.347950:  
2025-08-28 22:40:53.356325: Epoch 992 
2025-08-28 22:40:53.362401: Current learning rate: 0.00013 
2025-08-28 22:41:09.846193: train_loss -0.6396 
2025-08-28 22:41:09.858208: val_loss -0.6404 
2025-08-28 22:41:09.862549: Pseudo dice [np.float32(0.8336)] 
2025-08-28 22:41:09.868545: Epoch time: 16.5 s 
2025-08-28 22:41:10.545208:  
2025-08-28 22:41:10.553573: Epoch 993 
2025-08-28 22:41:10.559948: Current learning rate: 0.00011 
2025-08-28 22:41:27.521853: train_loss -0.6433 
2025-08-28 22:41:27.530074: val_loss -0.5845 
2025-08-28 22:41:27.538368: Pseudo dice [np.float32(0.7546)] 
2025-08-28 22:41:27.545112: Epoch time: 16.98 s 
2025-08-28 22:41:28.232731:  
2025-08-28 22:41:28.241112: Epoch 994 
2025-08-28 22:41:28.249474: Current learning rate: 0.0001 
2025-08-28 22:41:44.976619: train_loss -0.6513 
2025-08-28 22:41:44.985249: val_loss -0.6552 
2025-08-28 22:41:44.989164: Pseudo dice [np.float32(0.8079)] 
2025-08-28 22:41:44.996310: Epoch time: 16.74 s 
2025-08-28 22:41:45.668874:  
2025-08-28 22:41:45.676224: Epoch 995 
2025-08-28 22:41:45.682619: Current learning rate: 8e-05 
2025-08-28 22:42:02.315049: train_loss -0.6274 
2025-08-28 22:42:02.327552: val_loss -0.6394 
2025-08-28 22:42:02.331433: Pseudo dice [np.float32(0.81)] 
2025-08-28 22:42:02.338762: Epoch time: 16.65 s 
2025-08-28 22:42:03.049826:  
2025-08-28 22:42:03.057105: Epoch 996 
2025-08-28 22:42:03.063346: Current learning rate: 7e-05 
2025-08-28 22:42:20.020161: train_loss -0.6401 
2025-08-28 22:42:20.028521: val_loss -0.598 
2025-08-28 22:42:20.032685: Pseudo dice [np.float32(0.8085)] 
2025-08-28 22:42:20.041545: Epoch time: 16.97 s 
2025-08-28 22:42:20.768570:  
2025-08-28 22:42:20.777953: Epoch 997 
2025-08-28 22:42:20.783421: Current learning rate: 5e-05 
2025-08-28 22:42:37.529105: train_loss -0.6306 
2025-08-28 22:42:37.537420: val_loss -0.6376 
2025-08-28 22:42:37.545783: Pseudo dice [np.float32(0.8119)] 
2025-08-28 22:42:37.552136: Epoch time: 16.76 s 
2025-08-28 22:42:38.226686:  
2025-08-28 22:42:38.233917: Epoch 998 
2025-08-28 22:42:38.239264: Current learning rate: 4e-05 
2025-08-28 22:42:54.717208: train_loss -0.6427 
2025-08-28 22:42:54.725494: val_loss -0.6049 
2025-08-28 22:42:54.733779: Pseudo dice [np.float32(0.7612)] 
2025-08-28 22:42:54.738985: Epoch time: 16.49 s 
2025-08-28 22:42:55.602379:  
2025-08-28 22:42:55.610749: Epoch 999 
2025-08-28 22:42:55.615939: Current learning rate: 2e-05 
2025-08-28 22:43:12.184561: train_loss -0.6306 
2025-08-28 22:43:12.197044: val_loss -0.6193 
2025-08-28 22:43:12.201229: Pseudo dice [np.float32(0.8267)] 
2025-08-28 22:43:12.209263: Epoch time: 16.58 s 
2025-08-28 22:43:13.186574: Training done. 
2025-08-28 22:43:13.421463: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 22:43:13.435842: The split file contains 5 splits. 
2025-08-28 22:43:13.449409: Desired fold for training: 4 
2025-08-28 22:43:13.458681: This split has 524 training and 131 validation cases. 
2025-08-28 22:43:13.467023: predicting sub-r001s006 
2025-08-28 22:43:13.744433: sub-r001s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:43:24.305030: predicting sub-r001s024 
2025-08-28 22:43:24.517688: sub-r001s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:43:35.557929: predicting sub-r001s030 
2025-08-28 22:43:35.778932: sub-r001s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:43:46.005744: predicting sub-r001s033 
2025-08-28 22:43:46.218524: sub-r001s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:43:57.067192: predicting sub-r001s036 
2025-08-28 22:43:57.337795: sub-r001s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:44:07.756664: predicting sub-r001s038 
2025-08-28 22:44:07.981940: sub-r001s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:44:18.041977: predicting sub-r002s006 
2025-08-28 22:44:18.258853: sub-r002s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:44:28.356412: predicting sub-r003s009 
2025-08-28 22:44:28.573323: sub-r003s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:44:39.559329: predicting sub-r003s010 
2025-08-28 22:44:39.788704: sub-r003s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:44:49.840408: predicting sub-r003s014 
2025-08-28 22:44:50.053137: sub-r003s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:00.050580: predicting sub-r004s005 
2025-08-28 22:45:00.324689: sub-r004s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:09.823257: predicting sub-r004s008 
2025-08-28 22:45:10.039732: sub-r004s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:20.379593: predicting sub-r004s012 
2025-08-28 22:45:20.629488: sub-r004s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:29.872027: predicting sub-r004s013 
2025-08-28 22:45:30.088936: sub-r004s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:40.340877: predicting sub-r004s014 
2025-08-28 22:45:40.561898: sub-r004s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:45:49.929554: predicting sub-r004s017 
2025-08-28 22:45:50.159017: sub-r004s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:00.610719: predicting sub-r004s019 
2025-08-28 22:46:00.848822: sub-r004s019, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:10.304385: predicting sub-r004s022 
2025-08-28 22:46:10.525170: sub-r004s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:20.910431: predicting sub-r004s027 
2025-08-28 22:46:21.131478: sub-r004s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:30.849876: predicting sub-r004s028 
2025-08-28 22:46:31.066503: sub-r004s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:41.506147: predicting sub-r004s030 
2025-08-28 22:46:41.727132: sub-r004s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:46:51.382609: predicting sub-r004s032 
2025-08-28 22:46:51.603703: sub-r004s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:02.172621: predicting sub-r005s045 
2025-08-28 22:47:02.435396: sub-r005s045, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:11.732429: predicting sub-r005s048 
2025-08-28 22:47:11.974040: sub-r005s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:22.054917: predicting sub-r005s049 
2025-08-28 22:47:22.276012: sub-r005s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:31.485349: predicting sub-r005s075 
2025-08-28 22:47:31.693731: sub-r005s075, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:41.895910: predicting sub-r005s077 
2025-08-28 22:47:42.129145: sub-r005s077, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:47:51.747131: predicting sub-r009s002 
2025-08-28 22:47:51.976453: sub-r009s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:02.712095: predicting sub-r009s005 
2025-08-28 22:48:02.945769: sub-r009s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:12.296920: predicting sub-r009s006 
2025-08-28 22:48:12.542838: sub-r009s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:22.152656: predicting sub-r009s007 
2025-08-28 22:48:22.373787: sub-r009s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:32.525315: predicting sub-r009s010 
2025-08-28 22:48:32.758853: sub-r009s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:42.685468: predicting sub-r009s026 
2025-08-28 22:48:42.952384: sub-r009s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:48:53.108555: predicting sub-r009s029 
2025-08-28 22:48:53.337890: sub-r009s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:03.194616: predicting sub-r009s039 
2025-08-28 22:49:03.464533: sub-r009s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:13.528671: predicting sub-r009s052 
2025-08-28 22:49:13.758551: sub-r009s052, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:23.572122: predicting sub-r009s053 
2025-08-28 22:49:23.801506: sub-r009s053, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:33.832316: predicting sub-r009s058 
2025-08-28 22:49:34.078444: sub-r009s058, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:43.917702: predicting sub-r009s063 
2025-08-28 22:49:44.163367: sub-r009s063, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:49:54.186229: predicting sub-r009s075 
2025-08-28 22:49:54.423790: sub-r009s075, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:04.100079: predicting sub-r009s100 
2025-08-28 22:50:04.358733: sub-r009s100, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:14.689827: predicting sub-r009s106 
2025-08-28 22:50:14.931742: sub-r009s106, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:24.604226: predicting sub-r009s108 
2025-08-28 22:50:24.820845: sub-r009s108, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:34.922788: predicting sub-r009s120 
2025-08-28 22:50:35.160281: sub-r009s120, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:44.690533: predicting sub-r009s121 
2025-08-28 22:50:44.920036: sub-r009s121, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:50:54.809075: predicting sub-r009s122 
2025-08-28 22:50:55.059369: sub-r009s122, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:04.785975: predicting sub-r009s123 
2025-08-28 22:51:05.048472: sub-r009s123, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:14.912420: predicting sub-r009s124 
2025-08-28 22:51:15.158568: sub-r009s124, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:24.714193: predicting sub-r010s001 
2025-08-28 22:51:24.955902: sub-r010s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:34.415321: predicting sub-r010s002 
2025-08-28 22:51:34.657261: sub-r010s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:44.296269: predicting sub-r010s006 
2025-08-28 22:51:44.521263: sub-r010s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:51:54.485319: predicting sub-r010s012 
2025-08-28 22:51:54.731156: sub-r010s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:04.378788: predicting sub-r010s016 
2025-08-28 22:52:04.636879: sub-r010s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:14.029853: predicting sub-r010s024 
2025-08-28 22:52:14.267637: sub-r010s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:24.089932: predicting sub-r011s003 
2025-08-28 22:52:24.331825: sub-r011s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:34.295812: predicting sub-r011s010 
2025-08-28 22:52:34.525335: sub-r011s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:44.072375: predicting sub-r011s012 
2025-08-28 22:52:44.314307: sub-r011s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:52:53.815451: predicting sub-r011s013 
2025-08-28 22:52:54.061526: sub-r011s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:03.604583: predicting sub-r011s016 
2025-08-28 22:53:03.858825: sub-r011s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:14.002501: predicting sub-r011s018 
2025-08-28 22:53:14.236493: sub-r011s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:24.767480: predicting sub-r011s028 
2025-08-28 22:53:25.009119: sub-r011s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:35.415296: predicting sub-r011s034 
2025-08-28 22:53:35.644709: sub-r011s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:45.617179: predicting sub-r014s004 
2025-08-28 22:53:45.859109: sub-r014s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:53:55.443645: predicting sub-r014s008 
2025-08-28 22:53:55.698083: sub-r014s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:05.487024: predicting sub-r015s008 
2025-08-28 22:54:05.712292: sub-r015s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:15.200900: predicting sub-r015s009 
2025-08-28 22:54:15.455307: sub-r015s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:25.156376: predicting sub-r015s016 
2025-08-28 22:54:25.373550: sub-r015s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:34.928931: predicting sub-r015s026 
2025-08-28 22:54:35.175012: sub-r015s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:44.838935: predicting sub-r015s027 
2025-08-28 22:54:45.047412: sub-r015s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:54:55.111559: predicting sub-r017s116 
2025-08-28 22:54:55.346638: sub-r017s116, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:05.171632: predicting sub-r017s118 
2025-08-28 22:55:05.442745: sub-r017s118, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:15.536144: predicting sub-r018s011 
2025-08-28 22:55:15.773899: sub-r018s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:25.479401: predicting sub-r019s004 
2025-08-28 22:55:25.717484: sub-r019s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:36.094426: predicting sub-r019s009 
2025-08-28 22:55:36.331924: sub-r019s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:46.300265: predicting sub-r024s003 
2025-08-28 22:55:46.521558: sub-r024s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:55:56.314364: predicting sub-r024s012 
2025-08-28 22:55:56.564625: sub-r024s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:06.190904: predicting sub-r024s018 
2025-08-28 22:56:06.449507: sub-r024s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:16.505404: predicting sub-r027s006 
2025-08-28 22:56:16.747474: sub-r027s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:26.502869: predicting sub-r027s041 
2025-08-28 22:56:26.732270: sub-r027s041, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:36.823764: predicting sub-r027s050 
2025-08-28 22:56:37.046768: sub-r027s050, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:46.735598: predicting sub-r028s017 
2025-08-28 22:56:46.952513: sub-r028s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:56:56.424416: predicting sub-r028s026 
2025-08-28 22:56:56.649628: sub-r028s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:06.275899: predicting sub-r029s007 
2025-08-28 22:57:06.538751: sub-r029s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:16.653222: predicting sub-r031s006 
2025-08-28 22:57:16.869847: sub-r031s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:27.009124: predicting sub-r031s011 
2025-08-28 22:57:27.230194: sub-r031s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:37.686430: predicting sub-r031s013 
2025-08-28 22:57:37.907829: sub-r031s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:47.842713: predicting sub-r031s016 
2025-08-28 22:57:48.096887: sub-r031s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:57:57.881789: predicting sub-r031s017 
2025-08-28 22:57:58.131884: sub-r031s017, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:08.221111: predicting sub-r031s022 
2025-08-28 22:58:08.446400: sub-r031s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:17.968359: predicting sub-r031s026 
2025-08-28 22:58:18.210299: sub-r031s026, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:27.865646: predicting sub-r031s029 
2025-08-28 22:58:28.078476: sub-r031s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:37.404459: predicting sub-r031s033 
2025-08-28 22:58:37.625524: sub-r031s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:47.076633: predicting sub-r031s034 
2025-08-28 22:58:47.293474: sub-r031s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:58:57.253478: predicting sub-r034s010 
2025-08-28 22:58:57.524555: sub-r034s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:07.205373: predicting sub-r034s011 
2025-08-28 22:59:07.428730: sub-r034s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:17.594571: predicting sub-r034s021 
2025-08-28 22:59:17.857412: sub-r034s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:27.562828: predicting sub-r035s005 
2025-08-28 22:59:27.788102: sub-r035s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:38.056181: predicting sub-r035s007 
2025-08-28 22:59:38.281947: sub-r035s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:48.170949: predicting sub-r038s007 
2025-08-28 22:59:48.400393: sub-r038s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 22:59:58.710975: predicting sub-r038s022 
2025-08-28 22:59:58.973426: sub-r038s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:08.428960: predicting sub-r038s025 
2025-08-28 23:00:08.645609: sub-r038s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:18.706387: predicting sub-r038s054 
2025-08-28 23:00:18.960042: sub-r038s054, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:28.769831: predicting sub-r038s069 
2025-08-28 23:00:28.995061: sub-r038s069, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:38.542118: predicting sub-r038s078 
2025-08-28 23:00:38.763539: sub-r038s078, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:48.339374: predicting sub-r038s093 
2025-08-28 23:00:48.572950: sub-r038s093, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:00:58.582963: predicting sub-r040s001 
2025-08-28 23:00:58.854056: sub-r040s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:08.275982: predicting sub-r040s031 
2025-08-28 23:01:08.497050: sub-r040s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:18.484665: predicting sub-r040s037 
2025-08-28 23:01:18.694737: sub-r040s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:28.200264: predicting sub-r040s044 
2025-08-28 23:01:28.416929: sub-r040s044, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:37.684442: predicting sub-r040s051 
2025-08-28 23:01:37.930904: sub-r040s051, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:48.353506: predicting sub-r040s086 
2025-08-28 23:01:48.562044: sub-r040s086, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:01:58.801612: predicting sub-r042s010 
2025-08-28 23:01:59.055846: sub-r042s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:02:09.399523: predicting sub-r042s013 
2025-08-28 23:02:09.612262: sub-r042s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:02:19.409503: predicting sub-r042s021 
2025-08-28 23:02:19.626395: sub-r042s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:02:29.406904: predicting sub-r042s029 
2025-08-28 23:02:29.611383: sub-r042s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:02:39.587507: predicting sub-r046s011 
2025-08-28 23:02:39.829949: sub-r046s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:02:49.952355: predicting sub-r047s001 
2025-08-28 23:02:50.181983: sub-r047s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:00.484735: predicting sub-r047s010 
2025-08-28 23:03:00.704542: sub-r047s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:09.918312: predicting sub-r047s014 
2025-08-28 23:03:10.143518: sub-r047s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:19.302668: predicting sub-r047s036 
2025-08-28 23:03:19.536271: sub-r047s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:28.319989: predicting sub-r047s044 
2025-08-28 23:03:28.536879: sub-r047s044, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:38.738653: predicting sub-r047s048 
2025-08-28 23:03:38.972305: sub-r047s048, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:47.856203: predicting sub-r048s010 
2025-08-28 23:03:48.077224: sub-r048s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:03:58.049646: predicting sub-r048s016 
2025-08-28 23:03:58.270787: sub-r048s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:07.454834: predicting sub-r048s018 
2025-08-28 23:04:07.671789: sub-r048s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:17.694310: predicting sub-r048s021 
2025-08-28 23:04:17.923735: sub-r048s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:27.116203: predicting sub-r048s029 
2025-08-28 23:04:27.341452: sub-r048s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:37.451775: predicting sub-r048s031 
2025-08-28 23:04:37.689493: sub-r048s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:48.349782: predicting sub-r048s034 
2025-08-28 23:04:48.558482: sub-r048s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:04:58.201432: predicting sub-r048s039 
2025-08-28 23:04:58.426653: sub-r048s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:05:08.786867: predicting sub-r049s007 
2025-08-28 23:05:09.024743: sub-r049s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 23:05:27.868563: Validation complete 
2025-08-28 23:05:27.877103: Mean Validation Dice:  0.5475651066424354 
