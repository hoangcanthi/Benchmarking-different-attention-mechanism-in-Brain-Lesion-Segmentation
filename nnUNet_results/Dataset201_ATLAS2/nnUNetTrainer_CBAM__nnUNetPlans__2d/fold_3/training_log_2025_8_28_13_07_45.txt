
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-28 13:07:45.958398: do_dummy_2d_data_aug: False 
2025-08-28 13:07:45.966749: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 13:07:45.979186: The split file contains 5 splits. 
2025-08-28 13:07:45.983715: Desired fold for training: 3 
2025-08-28 13:07:45.987737: This split has 524 training and 131 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [256, 224], 'median_image_size_in_voxels': [233.0, 197.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_ATLAS2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [189, 233, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.528972625732422, 'mean': -0.4488435685634613, 'median': -0.34960058331489563, 'min': -4.37424898147583, 'percentile_00_5': -2.686936140060425, 'percentile_99_5': 1.7771409749984741, 'std': 0.9355628490447998}}} 
 
2025-08-28 13:07:53.211916: Unable to plot network architecture: 
2025-08-28 13:07:53.217931: No module named 'hiddenlayer' 
2025-08-28 13:07:53.266043:  
2025-08-28 13:07:53.270157: Epoch 0 
2025-08-28 13:07:53.278252: Current learning rate: 0.01 
2025-08-28 13:08:11.875925: train_loss 0.0974 
2025-08-28 13:08:11.880159: val_loss 0.0475 
2025-08-28 13:08:11.888468: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:08:11.893451: Epoch time: 18.61 s 
2025-08-28 13:08:11.897594: Yayy! New best EMA pseudo Dice: 0.0 
2025-08-28 13:08:12.647546:  
2025-08-28 13:08:12.655884: Epoch 1 
2025-08-28 13:08:12.660064: Current learning rate: 0.00999 
2025-08-28 13:08:29.439650: train_loss 0.0431 
2025-08-28 13:08:29.447652: val_loss 0.0249 
2025-08-28 13:08:29.452128: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:08:29.460459: Epoch time: 16.79 s 
2025-08-28 13:08:30.165246:  
2025-08-28 13:08:30.169263: Epoch 2 
2025-08-28 13:08:30.177570: Current learning rate: 0.00998 
2025-08-28 13:08:47.136131: train_loss 0.0314 
2025-08-28 13:08:47.140321: val_loss 0.0132 
2025-08-28 13:08:47.144475: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:08:47.152705: Epoch time: 16.98 s 
2025-08-28 13:08:47.770103:  
2025-08-28 13:08:47.778528: Epoch 3 
2025-08-28 13:08:47.782877: Current learning rate: 0.00997 
2025-08-28 13:09:04.795764: train_loss 0.019 
2025-08-28 13:09:04.803793: val_loss 0.0031 
2025-08-28 13:09:04.812511: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:09:04.818870: Epoch time: 17.03 s 
2025-08-28 13:09:05.433613:  
2025-08-28 13:09:05.441997: Epoch 4 
2025-08-28 13:09:05.446181: Current learning rate: 0.00996 
2025-08-28 13:09:22.675587: train_loss 0.0069 
2025-08-28 13:09:22.680036: val_loss 0.0046 
2025-08-28 13:09:22.684204: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:09:22.692406: Epoch time: 17.24 s 
2025-08-28 13:09:23.318150:  
2025-08-28 13:09:23.326448: Epoch 5 
2025-08-28 13:09:23.330609: Current learning rate: 0.00995 
2025-08-28 13:09:40.439372: train_loss 0.0057 
2025-08-28 13:09:40.447780: val_loss -0.0051 
2025-08-28 13:09:40.452017: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:09:40.458186: Epoch time: 17.12 s 
2025-08-28 13:09:41.056654:  
2025-08-28 13:09:41.061040: Epoch 6 
2025-08-28 13:09:41.064985: Current learning rate: 0.00995 
2025-08-28 13:09:57.860966: train_loss 0.0005 
2025-08-28 13:09:57.869305: val_loss 0.002 
2025-08-28 13:09:57.873461: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:09:57.880743: Epoch time: 16.81 s 
2025-08-28 13:09:58.486644:  
2025-08-28 13:09:58.491061: Epoch 7 
2025-08-28 13:09:58.499110: Current learning rate: 0.00994 
2025-08-28 13:10:15.641176: train_loss 0.0019 
2025-08-28 13:10:15.654069: val_loss -0.0097 
2025-08-28 13:10:15.657945: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:10:15.665689: Epoch time: 17.15 s 
2025-08-28 13:10:16.289994:  
2025-08-28 13:10:16.298448: Epoch 8 
2025-08-28 13:10:16.304824: Current learning rate: 0.00993 
2025-08-28 13:10:33.521549: train_loss -0.0033 
2025-08-28 13:10:33.530217: val_loss -0.0191 
2025-08-28 13:10:33.538204: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:10:33.543474: Epoch time: 17.23 s 
2025-08-28 13:10:34.163892:  
2025-08-28 13:10:34.172252: Epoch 9 
2025-08-28 13:10:34.176369: Current learning rate: 0.00992 
2025-08-28 13:10:51.135294: train_loss -0.0 
2025-08-28 13:10:51.143640: val_loss -0.0045 
2025-08-28 13:10:51.147978: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:10:51.156535: Epoch time: 16.97 s 
2025-08-28 13:10:51.786247:  
2025-08-28 13:10:51.796169: Epoch 10 
2025-08-28 13:10:51.802323: Current learning rate: 0.00991 
2025-08-28 13:11:07.451775: train_loss -0.0029 
2025-08-28 13:11:07.460159: val_loss -0.0169 
2025-08-28 13:11:07.464270: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:11:07.471162: Epoch time: 15.67 s 
2025-08-28 13:11:08.077841:  
2025-08-28 13:11:08.085258: Epoch 11 
2025-08-28 13:11:08.090890: Current learning rate: 0.0099 
2025-08-28 13:11:23.597609: train_loss -0.0022 
2025-08-28 13:11:23.605948: val_loss -0.0015 
2025-08-28 13:11:23.614332: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:11:23.620048: Epoch time: 15.52 s 
2025-08-28 13:11:24.205504:  
2025-08-28 13:11:24.213861: Epoch 12 
2025-08-28 13:11:24.217896: Current learning rate: 0.00989 
2025-08-28 13:11:39.300052: train_loss -0.0098 
2025-08-28 13:11:39.308062: val_loss -0.0187 
2025-08-28 13:11:39.316411: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:11:39.320609: Epoch time: 15.1 s 
2025-08-28 13:11:39.917030:  
2025-08-28 13:11:39.921221: Epoch 13 
2025-08-28 13:11:39.925366: Current learning rate: 0.00988 
2025-08-28 13:11:55.173974: train_loss -0.0123 
2025-08-28 13:11:55.182246: val_loss -0.0081 
2025-08-28 13:11:55.186412: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:11:55.192534: Epoch time: 15.26 s 
2025-08-28 13:11:55.787055:  
2025-08-28 13:11:55.795370: Epoch 14 
2025-08-28 13:11:55.799520: Current learning rate: 0.00987 
2025-08-28 13:12:11.294319: train_loss -0.0052 
2025-08-28 13:12:11.302510: val_loss -0.0306 
2025-08-28 13:12:11.306662: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:12:11.314709: Epoch time: 15.51 s 
2025-08-28 13:12:12.057682:  
2025-08-28 13:12:12.065827: Epoch 15 
2025-08-28 13:12:12.074107: Current learning rate: 0.00986 
2025-08-28 13:12:27.689833: train_loss -0.0078 
2025-08-28 13:12:27.698037: val_loss -0.0178 
2025-08-28 13:12:27.702229: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:12:27.710900: Epoch time: 15.63 s 
2025-08-28 13:12:28.306992:  
2025-08-28 13:12:28.315315: Epoch 16 
2025-08-28 13:12:28.319499: Current learning rate: 0.00986 
2025-08-28 13:12:43.442863: train_loss -0.0187 
2025-08-28 13:12:43.451335: val_loss -0.0169 
2025-08-28 13:12:43.455458: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:12:43.460813: Epoch time: 15.14 s 
2025-08-28 13:12:44.073028:  
2025-08-28 13:12:44.076875: Epoch 17 
2025-08-28 13:12:44.081073: Current learning rate: 0.00985 
2025-08-28 13:13:00.155481: train_loss -0.0208 
2025-08-28 13:13:00.159658: val_loss -0.0098 
2025-08-28 13:13:00.167966: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:13:00.172861: Epoch time: 16.09 s 
2025-08-28 13:13:00.772732:  
2025-08-28 13:13:00.776962: Epoch 18 
2025-08-28 13:13:00.785187: Current learning rate: 0.00984 
2025-08-28 13:13:16.709529: train_loss -0.0138 
2025-08-28 13:13:16.721997: val_loss -0.0132 
2025-08-28 13:13:16.726438: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:13:16.732650: Epoch time: 15.94 s 
2025-08-28 13:13:17.347623:  
2025-08-28 13:13:17.352048: Epoch 19 
2025-08-28 13:13:17.360131: Current learning rate: 0.00983 
2025-08-28 13:13:32.379452: train_loss -0.0226 
2025-08-28 13:13:32.387645: val_loss -0.0155 
2025-08-28 13:13:32.391790: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:13:32.399894: Epoch time: 15.04 s 
2025-08-28 13:13:33.004924:  
2025-08-28 13:13:33.013260: Epoch 20 
2025-08-28 13:13:33.017434: Current learning rate: 0.00982 
2025-08-28 13:13:48.453944: train_loss -0.0187 
2025-08-28 13:13:48.462085: val_loss -0.0338 
2025-08-28 13:13:48.466276: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:13:48.474207: Epoch time: 15.45 s 
2025-08-28 13:13:49.233629:  
2025-08-28 13:13:49.241965: Epoch 21 
2025-08-28 13:13:49.246382: Current learning rate: 0.00981 
2025-08-28 13:14:04.620111: train_loss -0.0196 
2025-08-28 13:14:04.628168: val_loss -0.0247 
2025-08-28 13:14:04.632313: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:14:04.641871: Epoch time: 15.39 s 
2025-08-28 13:14:05.224603:  
2025-08-28 13:14:05.232939: Epoch 22 
2025-08-28 13:14:05.237116: Current learning rate: 0.0098 
2025-08-28 13:14:20.214719: train_loss -0.0196 
2025-08-28 13:14:20.227070: val_loss -0.0333 
2025-08-28 13:14:20.231492: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:14:20.237449: Epoch time: 14.99 s 
2025-08-28 13:14:20.827694:  
2025-08-28 13:14:20.836024: Epoch 23 
2025-08-28 13:14:20.840187: Current learning rate: 0.00979 
2025-08-28 13:14:35.396799: train_loss -0.0241 
2025-08-28 13:14:35.404726: val_loss -0.044 
2025-08-28 13:14:35.409126: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:14:35.415957: Epoch time: 14.57 s 
2025-08-28 13:14:35.996996:  
2025-08-28 13:14:36.005324: Epoch 24 
2025-08-28 13:14:36.009489: Current learning rate: 0.00978 
2025-08-28 13:14:49.818500: train_loss -0.0229 
2025-08-28 13:14:49.823296: val_loss -0.0274 
2025-08-28 13:14:49.827445: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:14:49.835866: Epoch time: 13.82 s 
2025-08-28 13:14:50.423889:  
2025-08-28 13:14:50.428308: Epoch 25 
2025-08-28 13:14:50.436988: Current learning rate: 0.00977 
2025-08-28 13:15:04.509248: train_loss -0.0242 
2025-08-28 13:15:04.517145: val_loss -0.0425 
2025-08-28 13:15:04.521545: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:15:04.528284: Epoch time: 14.09 s 
2025-08-28 13:15:05.113572:  
2025-08-28 13:15:05.121912: Epoch 26 
2025-08-28 13:15:05.126090: Current learning rate: 0.00977 
2025-08-28 13:15:19.161047: train_loss -0.0224 
2025-08-28 13:15:19.169260: val_loss -0.0091 
2025-08-28 13:15:19.173411: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:15:19.180418: Epoch time: 14.05 s 
2025-08-28 13:15:19.778585:  
2025-08-28 13:15:19.786523: Epoch 27 
2025-08-28 13:15:19.790686: Current learning rate: 0.00976 
2025-08-28 13:15:34.391010: train_loss -0.0228 
2025-08-28 13:15:34.396964: val_loss -0.0269 
2025-08-28 13:15:34.405322: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:15:34.410190: Epoch time: 14.61 s 
2025-08-28 13:15:35.189458:  
2025-08-28 13:15:35.197790: Epoch 28 
2025-08-28 13:15:35.201939: Current learning rate: 0.00975 
2025-08-28 13:15:51.063629: train_loss -0.0248 
2025-08-28 13:15:51.071958: val_loss -0.0356 
2025-08-28 13:15:51.076437: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:15:51.085393: Epoch time: 15.87 s 
2025-08-28 13:15:51.693406:  
2025-08-28 13:15:51.701794: Epoch 29 
2025-08-28 13:15:51.706176: Current learning rate: 0.00974 
2025-08-28 13:16:06.304484: train_loss -0.0255 
2025-08-28 13:16:06.313136: val_loss -0.0347 
2025-08-28 13:16:06.316218: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:16:06.325086: Epoch time: 14.61 s 
2025-08-28 13:16:06.925265:  
2025-08-28 13:16:06.933604: Epoch 30 
2025-08-28 13:16:06.937757: Current learning rate: 0.00973 
2025-08-28 13:16:21.807191: train_loss -0.0253 
2025-08-28 13:16:21.815536: val_loss -0.0352 
2025-08-28 13:16:21.823923: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:16:21.828777: Epoch time: 14.88 s 
2025-08-28 13:16:22.429246:  
2025-08-28 13:16:22.438714: Epoch 31 
2025-08-28 13:16:22.445950: Current learning rate: 0.00972 
2025-08-28 13:16:38.011262: train_loss -0.0303 
2025-08-28 13:16:38.019299: val_loss -0.0327 
2025-08-28 13:16:38.023465: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:16:38.031342: Epoch time: 15.58 s 
2025-08-28 13:16:38.631776:  
2025-08-28 13:16:38.639104: Epoch 32 
2025-08-28 13:16:38.644285: Current learning rate: 0.00971 
2025-08-28 13:16:54.398238: train_loss -0.0264 
2025-08-28 13:16:54.405946: val_loss -0.0392 
2025-08-28 13:16:54.410690: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:16:54.415919: Epoch time: 15.77 s 
2025-08-28 13:16:55.090038:  
2025-08-28 13:16:55.095861: Epoch 33 
2025-08-28 13:16:55.102564: Current learning rate: 0.0097 
2025-08-28 13:17:10.026295: train_loss -0.0348 
2025-08-28 13:17:10.034720: val_loss -0.0386 
2025-08-28 13:17:10.043014: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:17:10.047999: Epoch time: 14.94 s 
2025-08-28 13:17:10.789757:  
2025-08-28 13:17:10.798060: Epoch 34 
2025-08-28 13:17:10.802064: Current learning rate: 0.00969 
2025-08-28 13:17:25.984423: train_loss -0.0322 
2025-08-28 13:17:25.992966: val_loss -0.0304 
2025-08-28 13:17:26.001201: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:17:26.006373: Epoch time: 15.19 s 
2025-08-28 13:17:26.613473:  
2025-08-28 13:17:26.617859: Epoch 35 
2025-08-28 13:17:26.626334: Current learning rate: 0.00968 
2025-08-28 13:17:42.403928: train_loss -0.0354 
2025-08-28 13:17:42.412122: val_loss -0.0409 
2025-08-28 13:17:42.417478: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:17:42.422641: Epoch time: 15.79 s 
2025-08-28 13:17:43.044454:  
2025-08-28 13:17:43.050354: Epoch 36 
2025-08-28 13:17:43.055674: Current learning rate: 0.00968 
2025-08-28 13:17:58.757926: train_loss -0.0288 
2025-08-28 13:17:58.766197: val_loss -0.0444 
2025-08-28 13:17:58.770360: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:17:58.778905: Epoch time: 15.71 s 
2025-08-28 13:17:59.388667:  
2025-08-28 13:17:59.397003: Epoch 37 
2025-08-28 13:17:59.401134: Current learning rate: 0.00967 
2025-08-28 13:18:15.333646: train_loss -0.041 
2025-08-28 13:18:15.341707: val_loss -0.037 
2025-08-28 13:18:15.346087: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:18:15.354366: Epoch time: 15.94 s 
2025-08-28 13:18:15.999945:  
2025-08-28 13:18:16.006071: Epoch 38 
2025-08-28 13:18:16.013460: Current learning rate: 0.00966 
2025-08-28 13:18:31.978907: train_loss -0.0341 
2025-08-28 13:18:31.987159: val_loss -0.0362 
2025-08-28 13:18:31.991360: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:18:31.999668: Epoch time: 15.98 s 
2025-08-28 13:18:32.654456:  
2025-08-28 13:18:32.662797: Epoch 39 
2025-08-28 13:18:32.666985: Current learning rate: 0.00965 
2025-08-28 13:18:48.637475: train_loss -0.0337 
2025-08-28 13:18:48.649649: val_loss -0.0405 
2025-08-28 13:18:48.658010: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:18:48.662167: Epoch time: 15.98 s 
2025-08-28 13:18:49.391643:  
2025-08-28 13:18:49.399345: Epoch 40 
2025-08-28 13:18:49.404562: Current learning rate: 0.00964 
2025-08-28 13:19:04.761190: train_loss -0.039 
2025-08-28 13:19:04.769849: val_loss -0.0511 
2025-08-28 13:19:04.773668: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:19:04.780709: Epoch time: 15.37 s 
2025-08-28 13:19:05.557638:  
2025-08-28 13:19:05.563016: Epoch 41 
2025-08-28 13:19:05.570301: Current learning rate: 0.00963 
2025-08-28 13:19:20.673455: train_loss -0.0324 
2025-08-28 13:19:20.681208: val_loss -0.0408 
2025-08-28 13:19:20.689567: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:19:20.694479: Epoch time: 15.12 s 
2025-08-28 13:19:21.291655:  
2025-08-28 13:19:21.299895: Epoch 42 
2025-08-28 13:19:21.303793: Current learning rate: 0.00962 
2025-08-28 13:19:36.517845: train_loss -0.0359 
2025-08-28 13:19:36.526207: val_loss -0.0428 
2025-08-28 13:19:36.530382: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:19:36.536010: Epoch time: 15.23 s 
2025-08-28 13:19:37.132052:  
2025-08-28 13:19:37.140380: Epoch 43 
2025-08-28 13:19:37.144561: Current learning rate: 0.00961 
2025-08-28 13:19:52.129323: train_loss -0.0371 
2025-08-28 13:19:52.137633: val_loss -0.0339 
2025-08-28 13:19:52.145501: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:19:52.149363: Epoch time: 15.0 s 
2025-08-28 13:19:52.738217:  
2025-08-28 13:19:52.744319: Epoch 44 
2025-08-28 13:19:52.750724: Current learning rate: 0.0096 
2025-08-28 13:20:07.252896: train_loss -0.0356 
2025-08-28 13:20:07.261048: val_loss -0.0352 
2025-08-28 13:20:07.269391: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:20:07.275171: Epoch time: 14.52 s 
2025-08-28 13:20:07.858599:  
2025-08-28 13:20:07.866914: Epoch 45 
2025-08-28 13:20:07.874161: Current learning rate: 0.00959 
2025-08-28 13:20:23.485304: train_loss -0.0404 
2025-08-28 13:20:23.493988: val_loss -0.045 
2025-08-28 13:20:23.498162: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:20:23.506692: Epoch time: 15.63 s 
2025-08-28 13:20:24.099803:  
2025-08-28 13:20:24.108495: Epoch 46 
2025-08-28 13:20:24.115375: Current learning rate: 0.00959 
2025-08-28 13:20:38.771671: train_loss -0.0356 
2025-08-28 13:20:38.780018: val_loss -0.0414 
2025-08-28 13:20:38.784184: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:20:38.790870: Epoch time: 14.67 s 
2025-08-28 13:20:39.515517:  
2025-08-28 13:20:39.523511: Epoch 47 
2025-08-28 13:20:39.527696: Current learning rate: 0.00958 
2025-08-28 13:20:53.991307: train_loss -0.0404 
2025-08-28 13:20:53.995218: val_loss -0.0271 
2025-08-28 13:20:54.003904: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:20:54.009294: Epoch time: 14.48 s 
2025-08-28 13:20:54.596871:  
2025-08-28 13:20:54.605575: Epoch 48 
2025-08-28 13:20:54.612510: Current learning rate: 0.00957 
2025-08-28 13:21:09.894814: train_loss -0.0489 
2025-08-28 13:21:09.903161: val_loss -0.0647 
2025-08-28 13:21:09.907302: Pseudo dice [np.float32(0.0)] 
2025-08-28 13:21:09.914577: Epoch time: 15.3 s 
2025-08-28 13:21:10.523074:  
2025-08-28 13:21:10.531407: Epoch 49 
2025-08-28 13:21:10.537749: Current learning rate: 0.00956 
2025-08-28 13:21:25.330645: train_loss -0.0541 
2025-08-28 13:21:25.339172: val_loss -0.0513 
2025-08-28 13:21:25.347656: Pseudo dice [np.float32(0.0199)] 
2025-08-28 13:21:25.353476: Epoch time: 14.81 s 
2025-08-28 13:21:25.518577: Yayy! New best EMA pseudo Dice: 0.0020000000949949026 
2025-08-28 13:21:26.305522:  
2025-08-28 13:21:26.313831: Epoch 50 
2025-08-28 13:21:26.319315: Current learning rate: 0.00955 
2025-08-28 13:21:41.376153: train_loss -0.0585 
2025-08-28 13:21:41.384540: val_loss -0.0765 
2025-08-28 13:21:41.392595: Pseudo dice [np.float32(0.1431)] 
2025-08-28 13:21:41.398498: Epoch time: 15.07 s 
2025-08-28 13:21:41.405462: Yayy! New best EMA pseudo Dice: 0.016100000590085983 
2025-08-28 13:21:42.188004:  
2025-08-28 13:21:42.195353: Epoch 51 
2025-08-28 13:21:42.199918: Current learning rate: 0.00954 
2025-08-28 13:21:57.279289: train_loss -0.0811 
2025-08-28 13:21:57.288085: val_loss -0.0573 
2025-08-28 13:21:57.295896: Pseudo dice [np.float32(0.0903)] 
2025-08-28 13:21:57.301217: Epoch time: 15.09 s 
2025-08-28 13:21:57.305125: Yayy! New best EMA pseudo Dice: 0.023499999195337296 
2025-08-28 13:21:58.078857:  
2025-08-28 13:21:58.086230: Epoch 52 
2025-08-28 13:21:58.092384: Current learning rate: 0.00953 
2025-08-28 13:22:13.228561: train_loss -0.0844 
2025-08-28 13:22:13.236879: val_loss -0.0946 
2025-08-28 13:22:13.245245: Pseudo dice [np.float32(0.1438)] 
2025-08-28 13:22:13.250557: Epoch time: 15.15 s 
2025-08-28 13:22:13.254280: Yayy! New best EMA pseudo Dice: 0.03550000116229057 
2025-08-28 13:22:14.034491:  
2025-08-28 13:22:14.043850: Epoch 53 
2025-08-28 13:22:14.051162: Current learning rate: 0.00952 
2025-08-28 13:22:28.986618: train_loss -0.0843 
2025-08-28 13:22:28.998819: val_loss -0.0833 
2025-08-28 13:22:29.009157: Pseudo dice [np.float32(0.1333)] 
2025-08-28 13:22:29.015459: Epoch time: 14.95 s 
2025-08-28 13:22:29.023746: Yayy! New best EMA pseudo Dice: 0.04529999941587448 
2025-08-28 13:22:30.038270:  
2025-08-28 13:22:30.045269: Epoch 54 
2025-08-28 13:22:30.053270: Current learning rate: 0.00951 
2025-08-28 13:22:45.394239: train_loss -0.0958 
2025-08-28 13:22:45.402247: val_loss -0.1035 
2025-08-28 13:22:45.406728: Pseudo dice [np.float32(0.2126)] 
2025-08-28 13:22:45.414275: Epoch time: 15.36 s 
2025-08-28 13:22:45.420510: Yayy! New best EMA pseudo Dice: 0.06199999898672104 
2025-08-28 13:22:46.252943:  
2025-08-28 13:22:46.260314: Epoch 55 
2025-08-28 13:22:46.264537: Current learning rate: 0.0095 
2025-08-28 13:23:01.268387: train_loss -0.1015 
2025-08-28 13:23:01.276789: val_loss -0.0973 
2025-08-28 13:23:01.284809: Pseudo dice [np.float32(0.1518)] 
2025-08-28 13:23:01.289760: Epoch time: 15.02 s 
2025-08-28 13:23:01.293989: Yayy! New best EMA pseudo Dice: 0.07100000232458115 
2025-08-28 13:23:02.068745:  
2025-08-28 13:23:02.075087: Epoch 56 
2025-08-28 13:23:02.080267: Current learning rate: 0.00949 
2025-08-28 13:23:16.671048: train_loss -0.0911 
2025-08-28 13:23:16.679300: val_loss -0.0876 
2025-08-28 13:23:16.687675: Pseudo dice [np.float32(0.1935)] 
2025-08-28 13:23:16.692698: Epoch time: 14.6 s 
2025-08-28 13:23:16.696917: Yayy! New best EMA pseudo Dice: 0.08330000191926956 
2025-08-28 13:23:17.477962:  
2025-08-28 13:23:17.485415: Epoch 57 
2025-08-28 13:23:17.490480: Current learning rate: 0.00949 
2025-08-28 13:23:32.845396: train_loss -0.1065 
2025-08-28 13:23:32.849641: val_loss -0.1065 
2025-08-28 13:23:32.858023: Pseudo dice [np.float32(0.2417)] 
2025-08-28 13:23:32.866015: Epoch time: 15.37 s 
2025-08-28 13:23:32.872818: Yayy! New best EMA pseudo Dice: 0.09910000115633011 
2025-08-28 13:23:33.645154:  
2025-08-28 13:23:33.653448: Epoch 58 
2025-08-28 13:23:33.658677: Current learning rate: 0.00948 
2025-08-28 13:23:48.506950: train_loss -0.1113 
2025-08-28 13:23:48.515260: val_loss -0.0976 
2025-08-28 13:23:48.519697: Pseudo dice [np.float32(0.21)] 
2025-08-28 13:23:48.525584: Epoch time: 14.86 s 
2025-08-28 13:23:48.528564: Yayy! New best EMA pseudo Dice: 0.11020000278949738 
2025-08-28 13:23:49.318187:  
2025-08-28 13:23:49.326424: Epoch 59 
2025-08-28 13:23:49.330604: Current learning rate: 0.00947 
2025-08-28 13:24:03.409359: train_loss -0.1081 
2025-08-28 13:24:03.417993: val_loss -0.0734 
2025-08-28 13:24:03.422213: Pseudo dice [np.float32(0.1198)] 
2025-08-28 13:24:03.429061: Epoch time: 14.09 s 
2025-08-28 13:24:03.434093: Yayy! New best EMA pseudo Dice: 0.1111999973654747 
2025-08-28 13:24:04.401823:  
2025-08-28 13:24:04.409191: Epoch 60 
2025-08-28 13:24:04.415512: Current learning rate: 0.00946 
2025-08-28 13:24:18.696099: train_loss -0.1 
2025-08-28 13:24:18.707981: val_loss -0.0864 
2025-08-28 13:24:18.712427: Pseudo dice [np.float32(0.1907)] 
2025-08-28 13:24:18.720159: Epoch time: 14.3 s 
2025-08-28 13:24:18.726069: Yayy! New best EMA pseudo Dice: 0.11909999698400497 
2025-08-28 13:24:19.503370:  
2025-08-28 13:24:19.510724: Epoch 61 
2025-08-28 13:24:19.518117: Current learning rate: 0.00945 
2025-08-28 13:24:35.065900: train_loss -0.1045 
2025-08-28 13:24:35.074216: val_loss -0.0733 
2025-08-28 13:24:35.078404: Pseudo dice [np.float32(0.1728)] 
2025-08-28 13:24:35.086324: Epoch time: 15.56 s 
2025-08-28 13:24:35.091274: Yayy! New best EMA pseudo Dice: 0.12449999898672104 
2025-08-28 13:24:35.874926:  
2025-08-28 13:24:35.884413: Epoch 62 
2025-08-28 13:24:35.892652: Current learning rate: 0.00944 
2025-08-28 13:24:50.452113: train_loss -0.1114 
2025-08-28 13:24:50.460750: val_loss -0.1185 
2025-08-28 13:24:50.464857: Pseudo dice [np.float32(0.2484)] 
2025-08-28 13:24:50.472533: Epoch time: 14.58 s 
2025-08-28 13:24:50.478818: Yayy! New best EMA pseudo Dice: 0.13689999282360077 
2025-08-28 13:24:51.252732:  
2025-08-28 13:24:51.260087: Epoch 63 
2025-08-28 13:24:51.268451: Current learning rate: 0.00943 
2025-08-28 13:25:05.984340: train_loss -0.1007 
2025-08-28 13:25:05.992650: val_loss -0.1026 
2025-08-28 13:25:05.997104: Pseudo dice [np.float32(0.1583)] 
2025-08-28 13:25:06.002563: Epoch time: 14.73 s 
2025-08-28 13:25:06.005943: Yayy! New best EMA pseudo Dice: 0.13899999856948853 
2025-08-28 13:25:06.779795:  
2025-08-28 13:25:06.787133: Epoch 64 
2025-08-28 13:25:06.792312: Current learning rate: 0.00942 
2025-08-28 13:25:22.142051: train_loss -0.102 
2025-08-28 13:25:22.150450: val_loss -0.1105 
2025-08-28 13:25:22.154637: Pseudo dice [np.float32(0.1961)] 
2025-08-28 13:25:22.160742: Epoch time: 15.36 s 
2025-08-28 13:25:22.167483: Yayy! New best EMA pseudo Dice: 0.14470000565052032 
2025-08-28 13:25:22.952216:  
2025-08-28 13:25:22.959397: Epoch 65 
2025-08-28 13:25:22.963576: Current learning rate: 0.00941 
2025-08-28 13:25:37.974241: train_loss -0.1057 
2025-08-28 13:25:37.979071: val_loss -0.0907 
2025-08-28 13:25:37.987075: Pseudo dice [np.float32(0.1599)] 
2025-08-28 13:25:37.993094: Epoch time: 15.02 s 
2025-08-28 13:25:37.996229: Yayy! New best EMA pseudo Dice: 0.1462000012397766 
2025-08-28 13:25:38.786727:  
2025-08-28 13:25:38.794183: Epoch 66 
2025-08-28 13:25:38.800288: Current learning rate: 0.0094 
2025-08-28 13:25:53.690227: train_loss -0.1091 
2025-08-28 13:25:53.698584: val_loss -0.1327 
2025-08-28 13:25:53.703100: Pseudo dice [np.float32(0.1817)] 
2025-08-28 13:25:53.710606: Epoch time: 14.9 s 
2025-08-28 13:25:53.716240: Yayy! New best EMA pseudo Dice: 0.14980000257492065 
2025-08-28 13:25:54.679825:  
2025-08-28 13:25:54.686908: Epoch 67 
2025-08-28 13:25:54.692251: Current learning rate: 0.00939 
2025-08-28 13:26:09.226955: train_loss -0.1008 
2025-08-28 13:26:09.235151: val_loss -0.0921 
2025-08-28 13:26:09.239440: Pseudo dice [np.float32(0.239)] 
2025-08-28 13:26:09.248279: Epoch time: 14.55 s 
2025-08-28 13:26:09.253103: Yayy! New best EMA pseudo Dice: 0.15870000422000885 
2025-08-28 13:26:10.037082:  
2025-08-28 13:26:10.046132: Epoch 68 
2025-08-28 13:26:10.051223: Current learning rate: 0.00939 
2025-08-28 13:26:26.122953: train_loss -0.114 
2025-08-28 13:26:26.131393: val_loss -0.1137 
2025-08-28 13:26:26.139128: Pseudo dice [np.float32(0.19)] 
2025-08-28 13:26:26.144289: Epoch time: 16.09 s 
2025-08-28 13:26:26.148668: Yayy! New best EMA pseudo Dice: 0.16179999709129333 
2025-08-28 13:26:27.131813:  
2025-08-28 13:26:27.140194: Epoch 69 
2025-08-28 13:26:27.146553: Current learning rate: 0.00938 
2025-08-28 13:26:44.074217: train_loss -0.1223 
2025-08-28 13:26:44.082655: val_loss -0.0805 
2025-08-28 13:26:44.086684: Pseudo dice [np.float32(0.1408)] 
2025-08-28 13:26:44.094537: Epoch time: 16.94 s 
2025-08-28 13:26:44.759964:  
2025-08-28 13:26:44.769341: Epoch 70 
2025-08-28 13:26:44.775617: Current learning rate: 0.00937 
2025-08-28 13:27:01.374809: train_loss -0.1314 
2025-08-28 13:27:01.382833: val_loss -0.1459 
2025-08-28 13:27:01.386989: Pseudo dice [np.float32(0.2901)] 
2025-08-28 13:27:01.393075: Epoch time: 16.62 s 
2025-08-28 13:27:01.396196: Yayy! New best EMA pseudo Dice: 0.1728000044822693 
2025-08-28 13:27:02.247097:  
2025-08-28 13:27:02.256277: Epoch 71 
2025-08-28 13:27:02.263897: Current learning rate: 0.00936 
2025-08-28 13:27:18.622114: train_loss -0.1764 
2025-08-28 13:27:18.629589: val_loss -0.2296 
2025-08-28 13:27:18.637635: Pseudo dice [np.float32(0.4377)] 
2025-08-28 13:27:18.642663: Epoch time: 16.38 s 
2025-08-28 13:27:18.646961: Yayy! New best EMA pseudo Dice: 0.19930000603199005 
2025-08-28 13:27:19.529998:  
2025-08-28 13:27:19.537306: Epoch 72 
2025-08-28 13:27:19.542500: Current learning rate: 0.00935 
2025-08-28 13:27:36.417789: train_loss -0.2507 
2025-08-28 13:27:36.422247: val_loss -0.1324 
2025-08-28 13:27:36.430307: Pseudo dice [np.float32(0.3251)] 
2025-08-28 13:27:36.435218: Epoch time: 16.89 s 
2025-08-28 13:27:36.439481: Yayy! New best EMA pseudo Dice: 0.211899995803833 
2025-08-28 13:27:37.464576:  
2025-08-28 13:27:37.474082: Epoch 73 
2025-08-28 13:27:37.478229: Current learning rate: 0.00934 
2025-08-28 13:27:54.160884: train_loss -0.2305 
2025-08-28 13:27:54.169402: val_loss -0.2315 
2025-08-28 13:27:54.177780: Pseudo dice [np.float32(0.4232)] 
2025-08-28 13:27:54.183444: Epoch time: 16.7 s 
2025-08-28 13:27:54.189704: Yayy! New best EMA pseudo Dice: 0.2329999953508377 
2025-08-28 13:27:55.071774:  
2025-08-28 13:27:55.079340: Epoch 74 
2025-08-28 13:27:55.086898: Current learning rate: 0.00933 
2025-08-28 13:28:11.517985: train_loss -0.1874 
2025-08-28 13:28:11.528266: val_loss -0.2628 
2025-08-28 13:28:11.532366: Pseudo dice [np.float32(0.4774)] 
2025-08-28 13:28:11.539108: Epoch time: 16.45 s 
2025-08-28 13:28:11.545125: Yayy! New best EMA pseudo Dice: 0.2574000060558319 
2025-08-28 13:28:12.404038:  
2025-08-28 13:28:12.407839: Epoch 75 
2025-08-28 13:28:12.414623: Current learning rate: 0.00932 
2025-08-28 13:28:28.584306: train_loss -0.1855 
2025-08-28 13:28:28.591039: val_loss -0.2256 
2025-08-28 13:28:28.599432: Pseudo dice [np.float32(0.4097)] 
2025-08-28 13:28:28.605192: Epoch time: 16.18 s 
2025-08-28 13:28:28.608382: Yayy! New best EMA pseudo Dice: 0.2727000117301941 
2025-08-28 13:28:29.475936:  
2025-08-28 13:28:29.483194: Epoch 76 
2025-08-28 13:28:29.489452: Current learning rate: 0.00931 
2025-08-28 13:28:46.041477: train_loss -0.2424 
2025-08-28 13:28:46.045919: val_loss -0.2571 
2025-08-28 13:28:46.053994: Pseudo dice [np.float32(0.4336)] 
2025-08-28 13:28:46.059630: Epoch time: 16.57 s 
2025-08-28 13:28:46.063307: Yayy! New best EMA pseudo Dice: 0.28870001435279846 
2025-08-28 13:28:46.912077:  
2025-08-28 13:28:46.919357: Epoch 77 
2025-08-28 13:28:46.925614: Current learning rate: 0.0093 
2025-08-28 13:29:03.688568: train_loss -0.2377 
2025-08-28 13:29:03.696953: val_loss -0.3148 
2025-08-28 13:29:03.700793: Pseudo dice [np.float32(0.5035)] 
2025-08-28 13:29:03.707012: Epoch time: 16.78 s 
2025-08-28 13:29:03.713110: Yayy! New best EMA pseudo Dice: 0.3102000057697296 
2025-08-28 13:29:04.595381:  
2025-08-28 13:29:04.603685: Epoch 78 
2025-08-28 13:29:04.614171: Current learning rate: 0.0093 
2025-08-28 13:29:21.081543: train_loss -0.2346 
2025-08-28 13:29:21.089349: val_loss -0.2591 
2025-08-28 13:29:21.097657: Pseudo dice [np.float32(0.428)] 
2025-08-28 13:29:21.102404: Epoch time: 16.49 s 
2025-08-28 13:29:21.106625: Yayy! New best EMA pseudo Dice: 0.32199999690055847 
2025-08-28 13:29:22.098336:  
2025-08-28 13:29:22.105810: Epoch 79 
2025-08-28 13:29:22.110919: Current learning rate: 0.00929 
2025-08-28 13:29:38.810819: train_loss -0.222 
2025-08-28 13:29:38.814999: val_loss -0.268 
2025-08-28 13:29:38.823906: Pseudo dice [np.float32(0.4272)] 
2025-08-28 13:29:38.828837: Epoch time: 16.71 s 
2025-08-28 13:29:38.834427: Yayy! New best EMA pseudo Dice: 0.33250001072883606 
2025-08-28 13:29:39.678344:  
2025-08-28 13:29:39.687750: Epoch 80 
2025-08-28 13:29:39.692898: Current learning rate: 0.00928 
2025-08-28 13:29:55.932420: train_loss -0.2475 
2025-08-28 13:29:55.940564: val_loss -0.2837 
2025-08-28 13:29:55.944897: Pseudo dice [np.float32(0.4457)] 
2025-08-28 13:29:55.950009: Epoch time: 16.26 s 
2025-08-28 13:29:55.953817: Yayy! New best EMA pseudo Dice: 0.34380000829696655 
2025-08-28 13:29:56.815124:  
2025-08-28 13:29:56.823473: Epoch 81 
2025-08-28 13:29:56.828767: Current learning rate: 0.00927 
2025-08-28 13:30:13.399516: train_loss -0.2331 
2025-08-28 13:30:13.407865: val_loss -0.2361 
2025-08-28 13:30:13.412033: Pseudo dice [np.float32(0.386)] 
2025-08-28 13:30:13.420293: Epoch time: 16.59 s 
2025-08-28 13:30:13.426011: Yayy! New best EMA pseudo Dice: 0.3481000065803528 
2025-08-28 13:30:14.296073:  
2025-08-28 13:30:14.303427: Epoch 82 
2025-08-28 13:30:14.308588: Current learning rate: 0.00926 
2025-08-28 13:30:30.562569: train_loss -0.2698 
2025-08-28 13:30:30.570814: val_loss -0.226 
2025-08-28 13:30:30.575036: Pseudo dice [np.float32(0.3819)] 
2025-08-28 13:30:30.582159: Epoch time: 16.27 s 
2025-08-28 13:30:30.587400: Yayy! New best EMA pseudo Dice: 0.3513999879360199 
2025-08-28 13:30:31.401134:  
2025-08-28 13:30:31.405234: Epoch 83 
2025-08-28 13:30:31.413380: Current learning rate: 0.00925 
2025-08-28 13:30:48.242656: train_loss -0.2745 
2025-08-28 13:30:48.251007: val_loss -0.2717 
2025-08-28 13:30:48.255048: Pseudo dice [np.float32(0.4816)] 
2025-08-28 13:30:48.260744: Epoch time: 16.84 s 
2025-08-28 13:30:48.264348: Yayy! New best EMA pseudo Dice: 0.3643999993801117 
2025-08-28 13:30:49.098672:  
2025-08-28 13:30:49.105826: Epoch 84 
2025-08-28 13:30:49.112174: Current learning rate: 0.00924 
2025-08-28 13:31:05.072007: train_loss -0.2447 
2025-08-28 13:31:05.080287: val_loss -0.2916 
2025-08-28 13:31:05.084894: Pseudo dice [np.float32(0.5226)] 
2025-08-28 13:31:05.093722: Epoch time: 15.98 s 
2025-08-28 13:31:05.099453: Yayy! New best EMA pseudo Dice: 0.38029998540878296 
2025-08-28 13:31:05.914276:  
2025-08-28 13:31:05.921655: Epoch 85 
2025-08-28 13:31:05.928007: Current learning rate: 0.00923 
2025-08-28 13:31:22.931502: train_loss -0.3138 
2025-08-28 13:31:22.939794: val_loss -0.3745 
2025-08-28 13:31:22.943950: Pseudo dice [np.float32(0.5671)] 
2025-08-28 13:31:22.950135: Epoch time: 17.02 s 
2025-08-28 13:31:22.953168: Yayy! New best EMA pseudo Dice: 0.39890000224113464 
2025-08-28 13:31:23.949585:  
2025-08-28 13:31:23.959041: Epoch 86 
2025-08-28 13:31:23.965841: Current learning rate: 0.00922 
2025-08-28 13:31:39.443790: train_loss -0.3315 
2025-08-28 13:31:39.452379: val_loss -0.4183 
2025-08-28 13:31:39.456340: Pseudo dice [np.float32(0.5993)] 
2025-08-28 13:31:39.464406: Epoch time: 15.49 s 
2025-08-28 13:31:39.469320: Yayy! New best EMA pseudo Dice: 0.4189999997615814 
2025-08-28 13:31:40.302793:  
2025-08-28 13:31:40.309178: Epoch 87 
2025-08-28 13:31:40.315281: Current learning rate: 0.00921 
2025-08-28 13:31:57.119865: train_loss -0.2964 
2025-08-28 13:31:57.128042: val_loss -0.3071 
2025-08-28 13:31:57.132566: Pseudo dice [np.float32(0.5185)] 
2025-08-28 13:31:57.138454: Epoch time: 16.82 s 
2025-08-28 13:31:57.141562: Yayy! New best EMA pseudo Dice: 0.42890000343322754 
2025-08-28 13:31:57.989637:  
2025-08-28 13:31:57.996633: Epoch 88 
2025-08-28 13:31:58.000446: Current learning rate: 0.0092 
2025-08-28 13:32:14.145425: train_loss -0.3468 
2025-08-28 13:32:14.158020: val_loss -0.3096 
2025-08-28 13:32:14.162069: Pseudo dice [np.float32(0.5476)] 
2025-08-28 13:32:14.169143: Epoch time: 16.16 s 
2025-08-28 13:32:14.174762: Yayy! New best EMA pseudo Dice: 0.4408000111579895 
2025-08-28 13:32:15.017013:  
2025-08-28 13:32:15.024858: Epoch 89 
2025-08-28 13:32:15.030285: Current learning rate: 0.0092 
2025-08-28 13:32:31.420668: train_loss -0.3297 
2025-08-28 13:32:31.429034: val_loss -0.3364 
2025-08-28 13:32:31.433199: Pseudo dice [np.float32(0.551)] 
2025-08-28 13:32:31.439198: Epoch time: 16.41 s 
2025-08-28 13:32:31.442345: Yayy! New best EMA pseudo Dice: 0.45179998874664307 
2025-08-28 13:32:32.306885:  
2025-08-28 13:32:32.315221: Epoch 90 
2025-08-28 13:32:32.320392: Current learning rate: 0.00919 
2025-08-28 13:32:48.800570: train_loss -0.3467 
2025-08-28 13:32:48.809182: val_loss -0.2317 
2025-08-28 13:32:48.813253: Pseudo dice [np.float32(0.5222)] 
2025-08-28 13:32:48.821393: Epoch time: 16.49 s 
2025-08-28 13:32:48.827045: Yayy! New best EMA pseudo Dice: 0.45890000462532043 
2025-08-28 13:32:49.644085:  
2025-08-28 13:32:49.652351: Epoch 91 
2025-08-28 13:32:49.658508: Current learning rate: 0.00918 
2025-08-28 13:33:05.959311: train_loss -0.3255 
2025-08-28 13:33:05.968677: val_loss -0.3244 
2025-08-28 13:33:05.976027: Pseudo dice [np.float32(0.5342)] 
2025-08-28 13:33:05.982284: Epoch time: 16.32 s 
2025-08-28 13:33:05.988499: Yayy! New best EMA pseudo Dice: 0.46639999747276306 
2025-08-28 13:33:06.954095:  
2025-08-28 13:33:06.963314: Epoch 92 
2025-08-28 13:33:06.968607: Current learning rate: 0.00917 
2025-08-28 13:33:21.413258: train_loss -0.3333 
2025-08-28 13:33:21.422557: val_loss -0.3534 
2025-08-28 13:33:21.426732: Pseudo dice [np.float32(0.5798)] 
2025-08-28 13:33:21.432645: Epoch time: 14.46 s 
2025-08-28 13:33:21.437203: Yayy! New best EMA pseudo Dice: 0.47769999504089355 
2025-08-28 13:33:22.199425:  
2025-08-28 13:33:22.205696: Epoch 93 
2025-08-28 13:33:22.210871: Current learning rate: 0.00916 
2025-08-28 13:33:36.673289: train_loss -0.3065 
2025-08-28 13:33:36.681952: val_loss -0.177 
2025-08-28 13:33:36.685800: Pseudo dice [np.float32(0.3368)] 
2025-08-28 13:33:36.693496: Epoch time: 14.48 s 
2025-08-28 13:33:37.339559:  
2025-08-28 13:33:37.352098: Epoch 94 
2025-08-28 13:33:37.359365: Current learning rate: 0.00915 
2025-08-28 13:33:52.672689: train_loss -0.3255 
2025-08-28 13:33:52.680944: val_loss -0.3695 
2025-08-28 13:33:52.685328: Pseudo dice [np.float32(0.5845)] 
2025-08-28 13:33:52.691360: Epoch time: 15.34 s 
2025-08-28 13:33:53.288708:  
2025-08-28 13:33:53.297147: Epoch 95 
2025-08-28 13:33:53.304579: Current learning rate: 0.00914 
2025-08-28 13:34:07.695916: train_loss -0.3681 
2025-08-28 13:34:07.704265: val_loss -0.3053 
2025-08-28 13:34:07.712716: Pseudo dice [np.float32(0.4371)] 
2025-08-28 13:34:07.717719: Epoch time: 14.41 s 
2025-08-28 13:34:08.328748:  
2025-08-28 13:34:08.337072: Epoch 96 
2025-08-28 13:34:08.342242: Current learning rate: 0.00913 
2025-08-28 13:34:23.257284: train_loss -0.3702 
2025-08-28 13:34:23.265214: val_loss -0.3266 
2025-08-28 13:34:23.269805: Pseudo dice [np.float32(0.4578)] 
2025-08-28 13:34:23.275106: Epoch time: 14.93 s 
2025-08-28 13:34:23.888111:  
2025-08-28 13:34:23.895290: Epoch 97 
2025-08-28 13:34:23.901012: Current learning rate: 0.00912 
2025-08-28 13:34:38.405977: train_loss -0.3832 
2025-08-28 13:34:38.414111: val_loss -0.3442 
2025-08-28 13:34:38.422444: Pseudo dice [np.float32(0.4743)] 
2025-08-28 13:34:38.427678: Epoch time: 14.52 s 
2025-08-28 13:34:39.039575:  
2025-08-28 13:34:39.048224: Epoch 98 
2025-08-28 13:34:39.054252: Current learning rate: 0.00911 
2025-08-28 13:34:53.283096: train_loss -0.3858 
2025-08-28 13:34:53.291460: val_loss -0.2956 
2025-08-28 13:34:53.295633: Pseudo dice [np.float32(0.5035)] 
2025-08-28 13:34:53.303341: Epoch time: 14.24 s 
2025-08-28 13:34:54.068352:  
2025-08-28 13:34:54.076624: Epoch 99 
2025-08-28 13:34:54.081788: Current learning rate: 0.0091 
2025-08-28 13:35:09.153239: train_loss -0.312 
2025-08-28 13:35:09.161473: val_loss -0.3217 
2025-08-28 13:35:09.169816: Pseudo dice [np.float32(0.5629)] 
2025-08-28 13:35:09.175092: Epoch time: 15.09 s 
2025-08-28 13:35:09.357549: Yayy! New best EMA pseudo Dice: 0.4830000102519989 
2025-08-28 13:35:10.130192:  
2025-08-28 13:35:10.137300: Epoch 100 
2025-08-28 13:35:10.143636: Current learning rate: 0.0091 
2025-08-28 13:35:24.931433: train_loss -0.3681 
2025-08-28 13:35:24.935821: val_loss -0.3874 
2025-08-28 13:35:24.943924: Pseudo dice [np.float32(0.6284)] 
2025-08-28 13:35:24.949173: Epoch time: 14.8 s 
2025-08-28 13:35:24.955008: Yayy! New best EMA pseudo Dice: 0.4975000023841858 
2025-08-28 13:35:25.757222:  
2025-08-28 13:35:25.767602: Epoch 101 
2025-08-28 13:35:25.776910: Current learning rate: 0.00909 
2025-08-28 13:35:41.101702: train_loss -0.2979 
2025-08-28 13:35:41.105873: val_loss -0.3215 
2025-08-28 13:35:41.114225: Pseudo dice [np.float32(0.557)] 
2025-08-28 13:35:41.119460: Epoch time: 15.35 s 
2025-08-28 13:35:41.123014: Yayy! New best EMA pseudo Dice: 0.5034999847412109 
2025-08-28 13:35:41.914033:  
2025-08-28 13:35:41.922263: Epoch 102 
2025-08-28 13:35:41.928530: Current learning rate: 0.00908 
2025-08-28 13:35:56.642542: train_loss -0.3464 
2025-08-28 13:35:56.650559: val_loss -0.4048 
2025-08-28 13:35:56.654728: Pseudo dice [np.float32(0.6258)] 
2025-08-28 13:35:56.664019: Epoch time: 14.73 s 
2025-08-28 13:35:56.667520: Yayy! New best EMA pseudo Dice: 0.5156999826431274 
2025-08-28 13:35:57.459631:  
2025-08-28 13:35:57.467865: Epoch 103 
2025-08-28 13:35:57.475196: Current learning rate: 0.00907 
2025-08-28 13:36:12.825029: train_loss -0.3402 
2025-08-28 13:36:12.833392: val_loss -0.3563 
2025-08-28 13:36:12.837798: Pseudo dice [np.float32(0.6847)] 
2025-08-28 13:36:12.845401: Epoch time: 15.37 s 
2025-08-28 13:36:12.850497: Yayy! New best EMA pseudo Dice: 0.5325999855995178 
2025-08-28 13:36:13.649709:  
2025-08-28 13:36:13.659175: Epoch 104 
2025-08-28 13:36:13.665405: Current learning rate: 0.00906 
2025-08-28 13:36:27.777453: train_loss -0.3449 
2025-08-28 13:36:27.785800: val_loss -0.4685 
2025-08-28 13:36:27.789960: Pseudo dice [np.float32(0.6556)] 
2025-08-28 13:36:27.798776: Epoch time: 14.13 s 
2025-08-28 13:36:27.806626: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2025-08-28 13:36:28.594777:  
2025-08-28 13:36:28.603127: Epoch 105 
2025-08-28 13:36:28.608497: Current learning rate: 0.00905 
2025-08-28 13:36:43.422249: train_loss -0.3558 
2025-08-28 13:36:43.430598: val_loss -0.3441 
2025-08-28 13:36:43.434765: Pseudo dice [np.float32(0.5679)] 
2025-08-28 13:36:43.442925: Epoch time: 14.83 s 
2025-08-28 13:36:43.447750: Yayy! New best EMA pseudo Dice: 0.5472000241279602 
2025-08-28 13:36:44.402237:  
2025-08-28 13:36:44.410576: Epoch 106 
2025-08-28 13:36:44.418056: Current learning rate: 0.00904 
2025-08-28 13:36:58.199727: train_loss -0.3371 
2025-08-28 13:36:58.207915: val_loss -0.3237 
2025-08-28 13:36:58.212004: Pseudo dice [np.float32(0.5468)] 
2025-08-28 13:36:58.219879: Epoch time: 13.8 s 
2025-08-28 13:36:58.833385:  
2025-08-28 13:36:58.840731: Epoch 107 
2025-08-28 13:36:58.849049: Current learning rate: 0.00903 
2025-08-28 13:37:12.588840: train_loss -0.3653 
2025-08-28 13:37:12.601381: val_loss -0.3805 
2025-08-28 13:37:12.605556: Pseudo dice [np.float32(0.5181)] 
2025-08-28 13:37:12.613476: Epoch time: 13.76 s 
2025-08-28 13:37:13.224940:  
2025-08-28 13:37:13.234198: Epoch 108 
2025-08-28 13:37:13.242479: Current learning rate: 0.00902 
2025-08-28 13:37:27.153545: train_loss -0.286 
2025-08-28 13:37:27.161756: val_loss -0.1685 
2025-08-28 13:37:27.165921: Pseudo dice [np.float32(0.3132)] 
2025-08-28 13:37:27.172821: Epoch time: 13.93 s 
2025-08-28 13:37:27.793638:  
2025-08-28 13:37:27.800904: Epoch 109 
2025-08-28 13:37:27.806064: Current learning rate: 0.00901 
2025-08-28 13:37:41.663688: train_loss -0.3056 
2025-08-28 13:37:41.672079: val_loss -0.4138 
2025-08-28 13:37:41.676732: Pseudo dice [np.float32(0.6314)] 
2025-08-28 13:37:41.682861: Epoch time: 13.87 s 
2025-08-28 13:37:42.293706:  
2025-08-28 13:37:42.301710: Epoch 110 
2025-08-28 13:37:42.310192: Current learning rate: 0.009 
2025-08-28 13:37:56.878921: train_loss -0.3619 
2025-08-28 13:37:56.886801: val_loss -0.373 
2025-08-28 13:37:56.891434: Pseudo dice [np.float32(0.6312)] 
2025-08-28 13:37:56.896684: Epoch time: 14.59 s 
2025-08-28 13:37:57.515882:  
2025-08-28 13:37:57.523307: Epoch 111 
2025-08-28 13:37:57.528415: Current learning rate: 0.009 
2025-08-28 13:38:12.298497: train_loss -0.3659 
2025-08-28 13:38:12.306827: val_loss -0.4089 
2025-08-28 13:38:12.311000: Pseudo dice [np.float32(0.5817)] 
2025-08-28 13:38:12.318057: Epoch time: 14.78 s 
2025-08-28 13:38:13.086058:  
2025-08-28 13:38:13.092951: Epoch 112 
2025-08-28 13:38:13.098113: Current learning rate: 0.00899 
2025-08-28 13:38:28.048097: train_loss -0.3606 
2025-08-28 13:38:28.055865: val_loss -0.3154 
2025-08-28 13:38:28.060035: Pseudo dice [np.float32(0.5251)] 
2025-08-28 13:38:28.068338: Epoch time: 14.96 s 
2025-08-28 13:38:28.689712:  
2025-08-28 13:38:28.697084: Epoch 113 
2025-08-28 13:38:28.703384: Current learning rate: 0.00898 
2025-08-28 13:38:44.046926: train_loss -0.422 
2025-08-28 13:38:44.055208: val_loss -0.4328 
2025-08-28 13:38:44.060168: Pseudo dice [np.float32(0.7095)] 
2025-08-28 13:38:44.064627: Epoch time: 15.36 s 
2025-08-28 13:38:44.070173: Yayy! New best EMA pseudo Dice: 0.5605000257492065 
2025-08-28 13:38:44.857228:  
2025-08-28 13:38:44.865317: Epoch 114 
2025-08-28 13:38:44.874718: Current learning rate: 0.00897 
2025-08-28 13:38:59.099351: train_loss -0.3587 
2025-08-28 13:38:59.107699: val_loss -0.298 
2025-08-28 13:38:59.116052: Pseudo dice [np.float32(0.5137)] 
2025-08-28 13:38:59.120224: Epoch time: 14.24 s 
2025-08-28 13:38:59.731151:  
2025-08-28 13:38:59.738528: Epoch 115 
2025-08-28 13:38:59.744764: Current learning rate: 0.00896 
2025-08-28 13:39:15.127869: train_loss -0.3803 
2025-08-28 13:39:15.136200: val_loss -0.3896 
2025-08-28 13:39:15.140370: Pseudo dice [np.float32(0.6963)] 
2025-08-28 13:39:15.147512: Epoch time: 15.4 s 
2025-08-28 13:39:15.152856: Yayy! New best EMA pseudo Dice: 0.5698999762535095 
2025-08-28 13:39:15.957013:  
2025-08-28 13:39:15.965136: Epoch 116 
2025-08-28 13:39:15.971371: Current learning rate: 0.00895 
2025-08-28 13:39:30.338861: train_loss -0.3789 
2025-08-28 13:39:30.347142: val_loss -0.3713 
2025-08-28 13:39:30.353801: Pseudo dice [np.float32(0.6123)] 
2025-08-28 13:39:30.359348: Epoch time: 14.38 s 
2025-08-28 13:39:30.364374: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-08-28 13:39:31.205287:  
2025-08-28 13:39:31.212610: Epoch 117 
2025-08-28 13:39:31.219963: Current learning rate: 0.00894 
2025-08-28 13:39:46.308968: train_loss -0.3916 
2025-08-28 13:39:46.317336: val_loss -0.388 
2025-08-28 13:39:46.321501: Pseudo dice [np.float32(0.5778)] 
2025-08-28 13:39:46.329167: Epoch time: 15.11 s 
2025-08-28 13:39:46.334639: Yayy! New best EMA pseudo Dice: 0.5745000243186951 
2025-08-28 13:39:47.124353:  
2025-08-28 13:39:47.132674: Epoch 118 
2025-08-28 13:39:47.137809: Current learning rate: 0.00893 
2025-08-28 13:40:02.308846: train_loss -0.3573 
2025-08-28 13:40:02.316643: val_loss -0.3342 
2025-08-28 13:40:02.320842: Pseudo dice [np.float32(0.5229)] 
2025-08-28 13:40:02.328732: Epoch time: 15.19 s 
2025-08-28 13:40:03.106949:  
2025-08-28 13:40:03.115292: Epoch 119 
2025-08-28 13:40:03.122826: Current learning rate: 0.00892 
2025-08-28 13:40:18.779221: train_loss -0.4127 
2025-08-28 13:40:18.787245: val_loss -0.3727 
2025-08-28 13:40:18.795622: Pseudo dice [np.float32(0.5977)] 
2025-08-28 13:40:18.801845: Epoch time: 15.67 s 
2025-08-28 13:40:19.473387:  
2025-08-28 13:40:19.481729: Epoch 120 
2025-08-28 13:40:19.486835: Current learning rate: 0.00891 
2025-08-28 13:40:36.429964: train_loss -0.3971 
2025-08-28 13:40:36.438217: val_loss -0.4318 
2025-08-28 13:40:36.442381: Pseudo dice [np.float32(0.6347)] 
2025-08-28 13:40:36.451732: Epoch time: 16.96 s 
2025-08-28 13:40:36.455213: Yayy! New best EMA pseudo Dice: 0.5784000158309937 
2025-08-28 13:40:37.303595:  
2025-08-28 13:40:37.310956: Epoch 121 
2025-08-28 13:40:37.317107: Current learning rate: 0.0089 
2025-08-28 13:40:53.437976: train_loss -0.4128 
2025-08-28 13:40:53.442677: val_loss -0.4978 
2025-08-28 13:40:53.446828: Pseudo dice [np.float32(0.6845)] 
2025-08-28 13:40:53.456309: Epoch time: 16.14 s 
2025-08-28 13:40:53.458307: Yayy! New best EMA pseudo Dice: 0.5889999866485596 
2025-08-28 13:40:54.288311:  
2025-08-28 13:40:54.295663: Epoch 122 
2025-08-28 13:40:54.301853: Current learning rate: 0.00889 
2025-08-28 13:41:10.402875: train_loss -0.4026 
2025-08-28 13:41:10.409636: val_loss -0.4292 
2025-08-28 13:41:10.413785: Pseudo dice [np.float32(0.657)] 
2025-08-28 13:41:10.422199: Epoch time: 16.12 s 
2025-08-28 13:41:10.427063: Yayy! New best EMA pseudo Dice: 0.59579998254776 
2025-08-28 13:41:11.292284:  
2025-08-28 13:41:11.300106: Epoch 123 
2025-08-28 13:41:11.307413: Current learning rate: 0.00889 
2025-08-28 13:41:27.806326: train_loss -0.4391 
2025-08-28 13:41:27.816753: val_loss -0.4183 
2025-08-28 13:41:27.818655: Pseudo dice [np.float32(0.6607)] 
2025-08-28 13:41:27.826583: Epoch time: 16.52 s 
2025-08-28 13:41:27.831793: Yayy! New best EMA pseudo Dice: 0.6022999882698059 
2025-08-28 13:41:28.677815:  
2025-08-28 13:41:28.685054: Epoch 124 
2025-08-28 13:41:28.690280: Current learning rate: 0.00888 
2025-08-28 13:41:45.536347: train_loss -0.3874 
2025-08-28 13:41:45.544747: val_loss -0.3409 
2025-08-28 13:41:45.553021: Pseudo dice [np.float32(0.4901)] 
2025-08-28 13:41:45.558285: Epoch time: 16.86 s 
2025-08-28 13:41:46.389317:  
2025-08-28 13:41:46.396598: Epoch 125 
2025-08-28 13:41:46.401770: Current learning rate: 0.00887 
2025-08-28 13:42:02.937486: train_loss -0.4011 
2025-08-28 13:42:02.945446: val_loss -0.3752 
2025-08-28 13:42:02.949565: Pseudo dice [np.float32(0.671)] 
2025-08-28 13:42:02.958220: Epoch time: 16.55 s 
2025-08-28 13:42:03.631460:  
2025-08-28 13:42:03.639898: Epoch 126 
2025-08-28 13:42:03.649156: Current learning rate: 0.00886 
2025-08-28 13:42:20.484017: train_loss -0.3894 
2025-08-28 13:42:20.492132: val_loss -0.4272 
2025-08-28 13:42:20.496460: Pseudo dice [np.float32(0.6901)] 
2025-08-28 13:42:20.505189: Epoch time: 16.85 s 
2025-08-28 13:42:20.509575: Yayy! New best EMA pseudo Dice: 0.6082000136375427 
2025-08-28 13:42:21.364818:  
2025-08-28 13:42:21.373217: Epoch 127 
2025-08-28 13:42:21.378387: Current learning rate: 0.00885 
2025-08-28 13:42:37.776786: train_loss -0.4051 
2025-08-28 13:42:37.784645: val_loss -0.3866 
2025-08-28 13:42:37.792763: Pseudo dice [np.float32(0.6087)] 
2025-08-28 13:42:37.798046: Epoch time: 16.41 s 
2025-08-28 13:42:37.806170: Yayy! New best EMA pseudo Dice: 0.6082000136375427 
2025-08-28 13:42:38.708216:  
2025-08-28 13:42:38.717605: Epoch 128 
2025-08-28 13:42:38.722697: Current learning rate: 0.00884 
2025-08-28 13:42:55.485850: train_loss -0.4195 
2025-08-28 13:42:55.493752: val_loss -0.4647 
2025-08-28 13:42:55.497916: Pseudo dice [np.float32(0.7062)] 
2025-08-28 13:42:55.505271: Epoch time: 16.78 s 
2025-08-28 13:42:55.511134: Yayy! New best EMA pseudo Dice: 0.6179999709129333 
2025-08-28 13:42:56.382051:  
2025-08-28 13:42:56.390604: Epoch 129 
2025-08-28 13:42:56.397585: Current learning rate: 0.00883 
2025-08-28 13:43:12.398117: train_loss -0.4127 
2025-08-28 13:43:12.406441: val_loss -0.4294 
2025-08-28 13:43:12.410600: Pseudo dice [np.float32(0.678)] 
2025-08-28 13:43:12.417911: Epoch time: 16.02 s 
2025-08-28 13:43:12.423947: Yayy! New best EMA pseudo Dice: 0.6240000128746033 
2025-08-28 13:43:13.270820:  
2025-08-28 13:43:13.279144: Epoch 130 
2025-08-28 13:43:13.284304: Current learning rate: 0.00882 
2025-08-28 13:43:30.070143: train_loss -0.4051 
2025-08-28 13:43:30.078545: val_loss -0.4096 
2025-08-28 13:43:30.086550: Pseudo dice [np.float32(0.7)] 
2025-08-28 13:43:30.091848: Epoch time: 16.8 s 
2025-08-28 13:43:30.096876: Yayy! New best EMA pseudo Dice: 0.631600022315979 
2025-08-28 13:43:30.974593:  
2025-08-28 13:43:30.985422: Epoch 131 
2025-08-28 13:43:30.992836: Current learning rate: 0.00881 
2025-08-28 13:43:47.121601: train_loss -0.3851 
2025-08-28 13:43:47.128597: val_loss -0.4505 
2025-08-28 13:43:47.132744: Pseudo dice [np.float32(0.6678)] 
2025-08-28 13:43:47.140747: Epoch time: 16.15 s 
2025-08-28 13:43:47.145822: Yayy! New best EMA pseudo Dice: 0.635200023651123 
2025-08-28 13:43:48.173163:  
2025-08-28 13:43:48.181388: Epoch 132 
2025-08-28 13:43:48.188018: Current learning rate: 0.0088 
2025-08-28 13:44:04.808743: train_loss -0.3829 
2025-08-28 13:44:04.817100: val_loss -0.4347 
2025-08-28 13:44:04.821540: Pseudo dice [np.float32(0.6664)] 
2025-08-28 13:44:04.826528: Epoch time: 16.64 s 
2025-08-28 13:44:04.831643: Yayy! New best EMA pseudo Dice: 0.6384000182151794 
2025-08-28 13:44:05.699226:  
2025-08-28 13:44:05.707505: Epoch 133 
2025-08-28 13:44:05.713730: Current learning rate: 0.00879 
2025-08-28 13:44:21.238304: train_loss -0.4625 
2025-08-28 13:44:21.250131: val_loss -0.4282 
2025-08-28 13:44:21.258763: Pseudo dice [np.float32(0.6864)] 
2025-08-28 13:44:21.265491: Epoch time: 15.54 s 
2025-08-28 13:44:21.271455: Yayy! New best EMA pseudo Dice: 0.6431999802589417 
2025-08-28 13:44:22.123975:  
2025-08-28 13:44:22.131554: Epoch 134 
2025-08-28 13:44:22.137131: Current learning rate: 0.00879 
2025-08-28 13:44:37.666119: train_loss -0.4101 
2025-08-28 13:44:37.670717: val_loss -0.49 
2025-08-28 13:44:37.679096: Pseudo dice [np.float32(0.6516)] 
2025-08-28 13:44:37.683218: Epoch time: 15.54 s 
2025-08-28 13:44:37.686205: Yayy! New best EMA pseudo Dice: 0.6439999938011169 
2025-08-28 13:44:38.579824:  
2025-08-28 13:44:38.587234: Epoch 135 
2025-08-28 13:44:38.593480: Current learning rate: 0.00878 
2025-08-28 13:44:54.570928: train_loss -0.3866 
2025-08-28 13:44:54.579666: val_loss -0.3884 
2025-08-28 13:44:54.583736: Pseudo dice [np.float32(0.6075)] 
2025-08-28 13:44:54.590277: Epoch time: 15.99 s 
2025-08-28 13:44:55.353160:  
2025-08-28 13:44:55.361203: Epoch 136 
2025-08-28 13:44:55.367458: Current learning rate: 0.00877 
2025-08-28 13:45:11.491982: train_loss -0.393 
2025-08-28 13:45:11.500322: val_loss -0.3672 
2025-08-28 13:45:11.504421: Pseudo dice [np.float32(0.6333)] 
2025-08-28 13:45:11.512849: Epoch time: 16.14 s 
2025-08-28 13:45:12.224881:  
2025-08-28 13:45:12.232275: Epoch 137 
2025-08-28 13:45:12.237462: Current learning rate: 0.00876 
2025-08-28 13:45:28.521490: train_loss -0.4628 
2025-08-28 13:45:28.525661: val_loss -0.4041 
2025-08-28 13:45:28.530159: Pseudo dice [np.float32(0.6023)] 
2025-08-28 13:45:28.538968: Epoch time: 16.3 s 
2025-08-28 13:45:29.377511:  
2025-08-28 13:45:29.384707: Epoch 138 
2025-08-28 13:45:29.391034: Current learning rate: 0.00875 
2025-08-28 13:45:45.580026: train_loss -0.4198 
2025-08-28 13:45:45.588219: val_loss -0.414 
2025-08-28 13:45:45.592773: Pseudo dice [np.float32(0.639)] 
2025-08-28 13:45:45.597977: Epoch time: 16.2 s 
2025-08-28 13:45:46.291437:  
2025-08-28 13:45:46.299598: Epoch 139 
2025-08-28 13:45:46.305755: Current learning rate: 0.00874 
2025-08-28 13:46:02.338878: train_loss -0.368 
2025-08-28 13:46:02.347119: val_loss -0.4116 
2025-08-28 13:46:02.351093: Pseudo dice [np.float32(0.6637)] 
2025-08-28 13:46:02.357394: Epoch time: 16.05 s 
2025-08-28 13:46:03.050694:  
2025-08-28 13:46:03.057976: Epoch 140 
2025-08-28 13:46:03.063223: Current learning rate: 0.00873 
2025-08-28 13:46:19.239214: train_loss -0.3744 
2025-08-28 13:46:19.247131: val_loss -0.3938 
2025-08-28 13:46:19.251600: Pseudo dice [np.float32(0.6295)] 
2025-08-28 13:46:19.257877: Epoch time: 16.19 s 
2025-08-28 13:46:19.945748:  
2025-08-28 13:46:19.955017: Epoch 141 
2025-08-28 13:46:19.960173: Current learning rate: 0.00872 
2025-08-28 13:46:36.159834: train_loss -0.451 
2025-08-28 13:46:36.168224: val_loss -0.4503 
2025-08-28 13:46:36.172340: Pseudo dice [np.float32(0.6114)] 
2025-08-28 13:46:36.180782: Epoch time: 16.22 s 
2025-08-28 13:46:36.873005:  
2025-08-28 13:46:36.881316: Epoch 142 
2025-08-28 13:46:36.887649: Current learning rate: 0.00871 
2025-08-28 13:46:52.810481: train_loss -0.3875 
2025-08-28 13:46:52.818165: val_loss -0.4287 
2025-08-28 13:46:52.822339: Pseudo dice [np.float32(0.6873)] 
2025-08-28 13:46:52.829451: Epoch time: 15.94 s 
2025-08-28 13:46:53.538551:  
2025-08-28 13:46:53.546962: Epoch 143 
2025-08-28 13:46:53.553232: Current learning rate: 0.0087 
2025-08-28 13:47:09.581092: train_loss -0.4312 
2025-08-28 13:47:09.589054: val_loss -0.3976 
2025-08-28 13:47:09.597396: Pseudo dice [np.float32(0.6213)] 
2025-08-28 13:47:09.602606: Epoch time: 16.04 s 
2025-08-28 13:47:10.444016:  
2025-08-28 13:47:10.451301: Epoch 144 
2025-08-28 13:47:10.458602: Current learning rate: 0.00869 
2025-08-28 13:47:26.743141: train_loss -0.3374 
2025-08-28 13:47:26.747861: val_loss -0.3847 
2025-08-28 13:47:26.756191: Pseudo dice [np.float32(0.6376)] 
2025-08-28 13:47:26.761507: Epoch time: 16.3 s 
2025-08-28 13:47:27.446457:  
2025-08-28 13:47:27.453818: Epoch 145 
2025-08-28 13:47:27.459908: Current learning rate: 0.00868 
2025-08-28 13:47:43.468766: train_loss -0.435 
2025-08-28 13:47:43.472887: val_loss -0.4546 
2025-08-28 13:47:43.481226: Pseudo dice [np.float32(0.6725)] 
2025-08-28 13:47:43.486573: Epoch time: 16.02 s 
2025-08-28 13:47:44.185001:  
2025-08-28 13:47:44.193360: Epoch 146 
2025-08-28 13:47:44.199716: Current learning rate: 0.00868 
2025-08-28 13:48:00.510714: train_loss -0.4086 
2025-08-28 13:48:00.519064: val_loss -0.2521 
2025-08-28 13:48:00.523246: Pseudo dice [np.float32(0.4365)] 
2025-08-28 13:48:00.530086: Epoch time: 16.33 s 
2025-08-28 13:48:01.221802:  
2025-08-28 13:48:01.229212: Epoch 147 
2025-08-28 13:48:01.234396: Current learning rate: 0.00867 
2025-08-28 13:48:17.377582: train_loss -0.3547 
2025-08-28 13:48:17.386236: val_loss -0.377 
2025-08-28 13:48:17.390057: Pseudo dice [np.float32(0.527)] 
2025-08-28 13:48:17.398453: Epoch time: 16.16 s 
2025-08-28 13:48:18.092803:  
2025-08-28 13:48:18.101139: Epoch 148 
2025-08-28 13:48:18.107294: Current learning rate: 0.00866 
2025-08-28 13:48:34.573940: train_loss -0.3897 
2025-08-28 13:48:34.582268: val_loss -0.4951 
2025-08-28 13:48:34.586668: Pseudo dice [np.float32(0.6985)] 
2025-08-28 13:48:34.593418: Epoch time: 16.48 s 
2025-08-28 13:48:35.357879:  
2025-08-28 13:48:35.367378: Epoch 149 
2025-08-28 13:48:35.372567: Current learning rate: 0.00865 
2025-08-28 13:48:51.640910: train_loss -0.431 
2025-08-28 13:48:51.645163: val_loss -0.3749 
2025-08-28 13:48:51.653479: Pseudo dice [np.float32(0.622)] 
2025-08-28 13:48:51.659719: Epoch time: 16.29 s 
2025-08-28 13:48:52.680521:  
2025-08-28 13:48:52.688920: Epoch 150 
2025-08-28 13:48:52.695027: Current learning rate: 0.00864 
2025-08-28 13:49:09.016951: train_loss -0.4444 
2025-08-28 13:49:09.027955: val_loss -0.3958 
2025-08-28 13:49:09.033328: Pseudo dice [np.float32(0.518)] 
2025-08-28 13:49:09.039889: Epoch time: 16.34 s 
2025-08-28 13:49:09.754730:  
2025-08-28 13:49:09.766219: Epoch 151 
2025-08-28 13:49:09.777778: Current learning rate: 0.00863 
2025-08-28 13:49:25.825078: train_loss -0.3308 
2025-08-28 13:49:25.833419: val_loss -0.3751 
2025-08-28 13:49:25.837595: Pseudo dice [np.float32(0.6105)] 
2025-08-28 13:49:25.843832: Epoch time: 16.07 s 
2025-08-28 13:49:26.563193:  
2025-08-28 13:49:26.573710: Epoch 152 
2025-08-28 13:49:26.581094: Current learning rate: 0.00862 
2025-08-28 13:49:42.792796: train_loss -0.3991 
2025-08-28 13:49:42.800398: val_loss -0.4319 
2025-08-28 13:49:42.804495: Pseudo dice [np.float32(0.7212)] 
2025-08-28 13:49:42.817106: Epoch time: 16.23 s 
2025-08-28 13:49:43.579225:  
2025-08-28 13:49:43.586555: Epoch 153 
2025-08-28 13:49:43.591716: Current learning rate: 0.00861 
2025-08-28 13:49:59.900992: train_loss -0.3879 
2025-08-28 13:49:59.909110: val_loss -0.3484 
2025-08-28 13:49:59.913537: Pseudo dice [np.float32(0.5965)] 
2025-08-28 13:49:59.921678: Epoch time: 16.32 s 
2025-08-28 13:50:00.627571:  
2025-08-28 13:50:00.636843: Epoch 154 
2025-08-28 13:50:00.643020: Current learning rate: 0.0086 
2025-08-28 13:50:16.375520: train_loss -0.3346 
2025-08-28 13:50:16.384108: val_loss -0.3935 
2025-08-28 13:50:16.388054: Pseudo dice [np.float32(0.6436)] 
2025-08-28 13:50:16.395871: Epoch time: 15.75 s 
2025-08-28 13:50:17.091756:  
2025-08-28 13:50:17.099166: Epoch 155 
2025-08-28 13:50:17.105300: Current learning rate: 0.00859 
2025-08-28 13:50:31.774228: train_loss -0.4259 
2025-08-28 13:50:31.782961: val_loss -0.4357 
2025-08-28 13:50:31.791306: Pseudo dice [np.float32(0.602)] 
2025-08-28 13:50:31.796333: Epoch time: 14.68 s 
2025-08-28 13:50:32.436282:  
2025-08-28 13:50:32.444684: Epoch 156 
2025-08-28 13:50:32.450971: Current learning rate: 0.00858 
2025-08-28 13:50:46.434712: train_loss -0.3795 
2025-08-28 13:50:46.443345: val_loss -0.3834 
2025-08-28 13:50:46.447399: Pseudo dice [np.float32(0.5782)] 
2025-08-28 13:50:46.457742: Epoch time: 14.0 s 
2025-08-28 13:50:47.360479:  
2025-08-28 13:50:47.367879: Epoch 157 
2025-08-28 13:50:47.374155: Current learning rate: 0.00858 
2025-08-28 13:51:01.199565: train_loss -0.4304 
2025-08-28 13:51:01.207791: val_loss -0.2913 
2025-08-28 13:51:01.212195: Pseudo dice [np.float32(0.4721)] 
2025-08-28 13:51:01.218864: Epoch time: 13.84 s 
2025-08-28 13:51:01.849033:  
2025-08-28 13:51:01.858276: Epoch 158 
2025-08-28 13:51:01.863624: Current learning rate: 0.00857 
2025-08-28 13:51:16.560613: train_loss -0.4365 
2025-08-28 13:51:16.568979: val_loss -0.4616 
2025-08-28 13:51:16.573147: Pseudo dice [np.float32(0.6265)] 
2025-08-28 13:51:16.579739: Epoch time: 14.71 s 
2025-08-28 13:51:17.215306:  
2025-08-28 13:51:17.222650: Epoch 159 
2025-08-28 13:51:17.229049: Current learning rate: 0.00856 
2025-08-28 13:51:32.121398: train_loss -0.4252 
2025-08-28 13:51:32.126179: val_loss -0.3253 
2025-08-28 13:51:32.130305: Pseudo dice [np.float32(0.5672)] 
2025-08-28 13:51:32.138661: Epoch time: 14.91 s 
2025-08-28 13:51:32.774820:  
2025-08-28 13:51:32.783073: Epoch 160 
2025-08-28 13:51:32.790346: Current learning rate: 0.00855 
2025-08-28 13:51:47.816916: train_loss -0.4213 
2025-08-28 13:51:47.825222: val_loss -0.344 
2025-08-28 13:51:47.829346: Pseudo dice [np.float32(0.6619)] 
2025-08-28 13:51:47.836628: Epoch time: 15.04 s 
2025-08-28 13:51:48.481997:  
2025-08-28 13:51:48.490579: Epoch 161 
2025-08-28 13:51:48.495578: Current learning rate: 0.00854 
2025-08-28 13:52:03.403348: train_loss -0.3931 
2025-08-28 13:52:03.411577: val_loss -0.4827 
2025-08-28 13:52:03.415752: Pseudo dice [np.float32(0.6858)] 
2025-08-28 13:52:03.425814: Epoch time: 14.92 s 
2025-08-28 13:52:04.071591:  
2025-08-28 13:52:04.078838: Epoch 162 
2025-08-28 13:52:04.084152: Current learning rate: 0.00853 
2025-08-28 13:52:18.710968: train_loss -0.3606 
2025-08-28 13:52:18.722737: val_loss -0.3969 
2025-08-28 13:52:18.726846: Pseudo dice [np.float32(0.6413)] 
2025-08-28 13:52:18.734072: Epoch time: 14.64 s 
2025-08-28 13:52:19.526487:  
2025-08-28 13:52:19.533835: Epoch 163 
2025-08-28 13:52:19.540062: Current learning rate: 0.00852 
2025-08-28 13:52:34.400843: train_loss -0.3796 
2025-08-28 13:52:34.409186: val_loss -0.5263 
2025-08-28 13:52:34.413337: Pseudo dice [np.float32(0.6833)] 
2025-08-28 13:52:34.421732: Epoch time: 14.88 s 
2025-08-28 13:52:35.073392:  
2025-08-28 13:52:35.080538: Epoch 164 
2025-08-28 13:52:35.085872: Current learning rate: 0.00851 
2025-08-28 13:52:50.225082: train_loss -0.3796 
2025-08-28 13:52:50.233318: val_loss -0.3078 
2025-08-28 13:52:50.241688: Pseudo dice [np.float32(0.4575)] 
2025-08-28 13:52:50.246912: Epoch time: 15.15 s 
2025-08-28 13:52:50.869285:  
2025-08-28 13:52:50.877642: Epoch 165 
2025-08-28 13:52:50.882845: Current learning rate: 0.0085 
2025-08-28 13:53:05.928166: train_loss -0.4174 
2025-08-28 13:53:05.936506: val_loss -0.4246 
2025-08-28 13:53:05.940907: Pseudo dice [np.float32(0.6727)] 
2025-08-28 13:53:05.946610: Epoch time: 15.06 s 
2025-08-28 13:53:06.570378:  
2025-08-28 13:53:06.579801: Epoch 166 
2025-08-28 13:53:06.585056: Current learning rate: 0.00849 
2025-08-28 13:53:21.798154: train_loss -0.4483 
2025-08-28 13:53:21.806834: val_loss -0.3884 
2025-08-28 13:53:21.810679: Pseudo dice [np.float32(0.6582)] 
2025-08-28 13:53:21.817596: Epoch time: 15.23 s 
2025-08-28 13:53:22.448645:  
2025-08-28 13:53:22.455988: Epoch 167 
2025-08-28 13:53:22.461177: Current learning rate: 0.00848 
2025-08-28 13:53:37.526351: train_loss -0.3868 
2025-08-28 13:53:37.534696: val_loss -0.4298 
2025-08-28 13:53:37.538821: Pseudo dice [np.float32(0.665)] 
2025-08-28 13:53:37.545736: Epoch time: 15.08 s 
2025-08-28 13:53:38.181018:  
2025-08-28 13:53:38.190549: Epoch 168 
2025-08-28 13:53:38.196726: Current learning rate: 0.00847 
2025-08-28 13:53:53.292095: train_loss -0.4248 
2025-08-28 13:53:53.296267: val_loss -0.5086 
2025-08-28 13:53:53.304641: Pseudo dice [np.float32(0.6656)] 
2025-08-28 13:53:53.309520: Epoch time: 15.11 s 
2025-08-28 13:53:54.091743:  
2025-08-28 13:53:54.099079: Epoch 169 
2025-08-28 13:53:54.104291: Current learning rate: 0.00847 
2025-08-28 13:54:08.498941: train_loss -0.4308 
2025-08-28 13:54:08.507287: val_loss -0.4466 
2025-08-28 13:54:08.511483: Pseudo dice [np.float32(0.6936)] 
2025-08-28 13:54:08.518049: Epoch time: 14.41 s 
2025-08-28 13:54:09.151607:  
2025-08-28 13:54:09.161068: Epoch 170 
2025-08-28 13:54:09.167300: Current learning rate: 0.00846 
2025-08-28 13:54:23.972569: train_loss -0.4848 
2025-08-28 13:54:23.976987: val_loss -0.3895 
2025-08-28 13:54:23.985228: Pseudo dice [np.float32(0.6817)] 
2025-08-28 13:54:23.990638: Epoch time: 14.82 s 
2025-08-28 13:54:24.625402:  
2025-08-28 13:54:24.631592: Epoch 171 
2025-08-28 13:54:24.637946: Current learning rate: 0.00845 
2025-08-28 13:54:40.860695: train_loss -0.4373 
2025-08-28 13:54:40.868822: val_loss -0.366 
2025-08-28 13:54:40.872988: Pseudo dice [np.float32(0.5677)] 
2025-08-28 13:54:40.880141: Epoch time: 16.24 s 
2025-08-28 13:54:41.581799:  
2025-08-28 13:54:41.590282: Epoch 172 
2025-08-28 13:54:41.596507: Current learning rate: 0.00844 
2025-08-28 13:54:58.115246: train_loss -0.3114 
2025-08-28 13:54:58.123498: val_loss -0.3828 
2025-08-28 13:54:58.131390: Pseudo dice [np.float32(0.5895)] 
2025-08-28 13:54:58.136792: Epoch time: 16.54 s 
2025-08-28 13:54:58.824050:  
2025-08-28 13:54:58.831473: Epoch 173 
2025-08-28 13:54:58.837819: Current learning rate: 0.00843 
2025-08-28 13:55:15.495275: train_loss -0.3773 
2025-08-28 13:55:15.507534: val_loss -0.3966 
2025-08-28 13:55:15.511970: Pseudo dice [np.float32(0.6226)] 
2025-08-28 13:55:15.517131: Epoch time: 16.67 s 
2025-08-28 13:55:16.248847:  
2025-08-28 13:55:16.257170: Epoch 174 
2025-08-28 13:55:16.262425: Current learning rate: 0.00842 
2025-08-28 13:55:33.133833: train_loss -0.3719 
2025-08-28 13:55:33.142132: val_loss -0.3497 
2025-08-28 13:55:33.146336: Pseudo dice [np.float32(0.5327)] 
2025-08-28 13:55:33.151466: Epoch time: 16.89 s 
2025-08-28 13:55:34.005079:  
2025-08-28 13:55:34.013706: Epoch 175 
2025-08-28 13:55:34.020699: Current learning rate: 0.00841 
2025-08-28 13:55:51.108303: train_loss -0.4093 
2025-08-28 13:55:51.113912: val_loss -0.4589 
2025-08-28 13:55:51.118066: Pseudo dice [np.float32(0.6447)] 
2025-08-28 13:55:51.126363: Epoch time: 17.11 s 
2025-08-28 13:55:51.813512:  
2025-08-28 13:55:51.820866: Epoch 176 
2025-08-28 13:55:51.826044: Current learning rate: 0.0084 
2025-08-28 13:56:08.556325: train_loss -0.4117 
2025-08-28 13:56:08.564706: val_loss -0.478 
2025-08-28 13:56:08.568878: Pseudo dice [np.float32(0.6873)] 
2025-08-28 13:56:08.576950: Epoch time: 16.74 s 
2025-08-28 13:56:09.247634:  
2025-08-28 13:56:09.255858: Epoch 177 
2025-08-28 13:56:09.262250: Current learning rate: 0.00839 
2025-08-28 13:56:26.245177: train_loss -0.4235 
2025-08-28 13:56:26.253214: val_loss -0.4503 
2025-08-28 13:56:26.257347: Pseudo dice [np.float32(0.6785)] 
2025-08-28 13:56:26.264680: Epoch time: 17.0 s 
2025-08-28 13:56:26.962068:  
2025-08-28 13:56:26.970404: Epoch 178 
2025-08-28 13:56:26.976965: Current learning rate: 0.00838 
2025-08-28 13:56:44.004499: train_loss -0.4269 
2025-08-28 13:56:44.012582: val_loss -0.4227 
2025-08-28 13:56:44.016930: Pseudo dice [np.float32(0.6692)] 
2025-08-28 13:56:44.025083: Epoch time: 17.04 s 
2025-08-28 13:56:44.728829:  
2025-08-28 13:56:44.737831: Epoch 179 
2025-08-28 13:56:44.743475: Current learning rate: 0.00837 
2025-08-28 13:57:01.751485: train_loss -0.4674 
2025-08-28 13:57:01.759487: val_loss -0.4732 
2025-08-28 13:57:01.763669: Pseudo dice [np.float32(0.7028)] 
2025-08-28 13:57:01.770411: Epoch time: 17.02 s 
2025-08-28 13:57:02.473714:  
2025-08-28 13:57:02.484029: Epoch 180 
2025-08-28 13:57:02.492564: Current learning rate: 0.00836 
2025-08-28 13:57:19.214863: train_loss -0.4449 
2025-08-28 13:57:19.226882: val_loss -0.4082 
2025-08-28 13:57:19.231066: Pseudo dice [np.float32(0.5884)] 
2025-08-28 13:57:19.238431: Epoch time: 16.74 s 
2025-08-28 13:57:19.919117:  
2025-08-28 13:57:19.926510: Epoch 181 
2025-08-28 13:57:19.931665: Current learning rate: 0.00836 
2025-08-28 13:57:36.360625: train_loss -0.4517 
2025-08-28 13:57:36.369036: val_loss -0.36 
2025-08-28 13:57:36.373201: Pseudo dice [np.float32(0.5842)] 
2025-08-28 13:57:36.377966: Epoch time: 16.44 s 
2025-08-28 13:57:37.213505:  
2025-08-28 13:57:37.223875: Epoch 182 
2025-08-28 13:57:37.234295: Current learning rate: 0.00835 
2025-08-28 13:57:53.632288: train_loss -0.3721 
2025-08-28 13:57:53.640569: val_loss -0.4125 
2025-08-28 13:57:53.644578: Pseudo dice [np.float32(0.6176)] 
2025-08-28 13:57:53.653668: Epoch time: 16.42 s 
2025-08-28 13:57:54.361870:  
2025-08-28 13:57:54.372414: Epoch 183 
2025-08-28 13:57:54.380428: Current learning rate: 0.00834 
2025-08-28 13:58:10.628199: train_loss -0.4373 
2025-08-28 13:58:10.641039: val_loss -0.4582 
2025-08-28 13:58:10.644891: Pseudo dice [np.float32(0.68)] 
2025-08-28 13:58:10.651103: Epoch time: 16.27 s 
2025-08-28 13:58:11.331081:  
2025-08-28 13:58:11.338337: Epoch 184 
2025-08-28 13:58:11.345595: Current learning rate: 0.00833 
2025-08-28 13:58:28.133988: train_loss -0.4589 
2025-08-28 13:58:28.141591: val_loss -0.3712 
2025-08-28 13:58:28.149902: Pseudo dice [np.float32(0.6155)] 
2025-08-28 13:58:28.156471: Epoch time: 16.8 s 
2025-08-28 13:58:28.851644:  
2025-08-28 13:58:28.859730: Epoch 185 
2025-08-28 13:58:28.866257: Current learning rate: 0.00832 
2025-08-28 13:58:45.162672: train_loss -0.3481 
2025-08-28 13:58:45.171050: val_loss -0.375 
2025-08-28 13:58:45.175624: Pseudo dice [np.float32(0.5975)] 
2025-08-28 13:58:45.182365: Epoch time: 16.31 s 
2025-08-28 13:58:45.869668:  
2025-08-28 13:58:45.877940: Epoch 186 
2025-08-28 13:58:45.883128: Current learning rate: 0.00831 
2025-08-28 13:59:02.642799: train_loss -0.4233 
2025-08-28 13:59:02.651002: val_loss -0.4113 
2025-08-28 13:59:02.655143: Pseudo dice [np.float32(0.5413)] 
2025-08-28 13:59:02.662244: Epoch time: 16.77 s 
2025-08-28 13:59:03.377699:  
2025-08-28 13:59:03.384955: Epoch 187 
2025-08-28 13:59:03.391016: Current learning rate: 0.0083 
2025-08-28 13:59:19.684624: train_loss -0.4035 
2025-08-28 13:59:19.692988: val_loss -0.3396 
2025-08-28 13:59:19.701322: Pseudo dice [np.float32(0.5668)] 
2025-08-28 13:59:19.706659: Epoch time: 16.31 s 
2025-08-28 13:59:20.561547:  
2025-08-28 13:59:20.568801: Epoch 188 
2025-08-28 13:59:20.574120: Current learning rate: 0.00829 
2025-08-28 13:59:37.006504: train_loss -0.3895 
2025-08-28 13:59:37.014437: val_loss -0.4955 
2025-08-28 13:59:37.019056: Pseudo dice [np.float32(0.7044)] 
2025-08-28 13:59:37.025773: Epoch time: 16.45 s 
2025-08-28 13:59:37.706768:  
2025-08-28 13:59:37.715044: Epoch 189 
2025-08-28 13:59:37.720402: Current learning rate: 0.00828 
2025-08-28 13:59:54.236579: train_loss -0.4374 
2025-08-28 13:59:54.244524: val_loss -0.4027 
2025-08-28 13:59:54.248737: Pseudo dice [np.float32(0.6709)] 
2025-08-28 13:59:54.256750: Epoch time: 16.53 s 
2025-08-28 13:59:54.922914:  
2025-08-28 13:59:54.932386: Epoch 190 
2025-08-28 13:59:54.937511: Current learning rate: 0.00827 
2025-08-28 14:00:11.732459: train_loss -0.4698 
2025-08-28 14:00:11.745012: val_loss -0.5168 
2025-08-28 14:00:11.749169: Pseudo dice [np.float32(0.7309)] 
2025-08-28 14:00:11.755398: Epoch time: 16.81 s 
2025-08-28 14:00:12.440444:  
2025-08-28 14:00:12.450937: Epoch 191 
2025-08-28 14:00:12.457075: Current learning rate: 0.00826 
2025-08-28 14:00:29.487678: train_loss -0.3571 
2025-08-28 14:00:29.496220: val_loss -0.4393 
2025-08-28 14:00:29.500489: Pseudo dice [np.float32(0.6382)] 
2025-08-28 14:00:29.508329: Epoch time: 17.05 s 
2025-08-28 14:00:30.208125:  
2025-08-28 14:00:30.216395: Epoch 192 
2025-08-28 14:00:30.221567: Current learning rate: 0.00825 
2025-08-28 14:00:46.876533: train_loss -0.4255 
2025-08-28 14:00:46.884216: val_loss -0.4039 
2025-08-28 14:00:46.888694: Pseudo dice [np.float32(0.6103)] 
2025-08-28 14:00:46.897924: Epoch time: 16.67 s 
2025-08-28 14:00:47.596303:  
2025-08-28 14:00:47.601874: Epoch 193 
2025-08-28 14:00:47.612567: Current learning rate: 0.00824 
2025-08-28 14:01:03.938736: train_loss -0.3849 
2025-08-28 14:01:03.947111: val_loss -0.4237 
2025-08-28 14:01:03.955451: Pseudo dice [np.float32(0.5756)] 
2025-08-28 14:01:03.959667: Epoch time: 16.34 s 
2025-08-28 14:01:04.792590:  
2025-08-28 14:01:04.799943: Epoch 194 
2025-08-28 14:01:04.805197: Current learning rate: 0.00824 
2025-08-28 14:01:21.101692: train_loss -0.365 
2025-08-28 14:01:21.110039: val_loss -0.3948 
2025-08-28 14:01:21.114887: Pseudo dice [np.float32(0.6221)] 
2025-08-28 14:01:21.119572: Epoch time: 16.31 s 
2025-08-28 14:01:21.807619:  
2025-08-28 14:01:21.814828: Epoch 195 
2025-08-28 14:01:21.821100: Current learning rate: 0.00823 
2025-08-28 14:01:38.360592: train_loss -0.338 
2025-08-28 14:01:38.364818: val_loss -0.3273 
2025-08-28 14:01:38.373108: Pseudo dice [np.float32(0.5834)] 
2025-08-28 14:01:38.378360: Epoch time: 16.56 s 
2025-08-28 14:01:39.068387:  
2025-08-28 14:01:39.074332: Epoch 196 
2025-08-28 14:01:39.080336: Current learning rate: 0.00822 
2025-08-28 14:01:55.473547: train_loss -0.4046 
2025-08-28 14:01:55.481896: val_loss -0.3995 
2025-08-28 14:01:55.486070: Pseudo dice [np.float32(0.7281)] 
2025-08-28 14:01:55.491400: Epoch time: 16.41 s 
2025-08-28 14:01:56.176247:  
2025-08-28 14:01:56.183667: Epoch 197 
2025-08-28 14:01:56.188842: Current learning rate: 0.00821 
2025-08-28 14:02:12.194383: train_loss -0.3787 
2025-08-28 14:02:12.202701: val_loss -0.2846 
2025-08-28 14:02:12.206911: Pseudo dice [np.float32(0.496)] 
2025-08-28 14:02:12.214325: Epoch time: 16.02 s 
2025-08-28 14:02:12.894047:  
2025-08-28 14:02:12.902335: Epoch 198 
2025-08-28 14:02:12.908602: Current learning rate: 0.0082 
2025-08-28 14:02:29.253065: train_loss -0.3682 
2025-08-28 14:02:29.261414: val_loss -0.3431 
2025-08-28 14:02:29.265609: Pseudo dice [np.float32(0.6896)] 
2025-08-28 14:02:29.271783: Epoch time: 16.36 s 
2025-08-28 14:02:29.971470:  
2025-08-28 14:02:29.979897: Epoch 199 
2025-08-28 14:02:29.985998: Current learning rate: 0.00819 
2025-08-28 14:02:46.395709: train_loss -0.3864 
2025-08-28 14:02:46.403543: val_loss -0.4217 
2025-08-28 14:02:46.412056: Pseudo dice [np.float32(0.7527)] 
2025-08-28 14:02:46.417429: Epoch time: 16.43 s 
2025-08-28 14:02:47.437736:  
2025-08-28 14:02:47.447336: Epoch 200 
2025-08-28 14:02:47.453422: Current learning rate: 0.00818 
2025-08-28 14:03:04.043992: train_loss -0.3892 
2025-08-28 14:03:04.050320: val_loss -0.3894 
2025-08-28 14:03:04.054506: Pseudo dice [np.float32(0.6588)] 
2025-08-28 14:03:04.062739: Epoch time: 16.61 s 
2025-08-28 14:03:04.750848:  
2025-08-28 14:03:04.759184: Epoch 201 
2025-08-28 14:03:04.764531: Current learning rate: 0.00817 
2025-08-28 14:03:21.330361: train_loss -0.3645 
2025-08-28 14:03:21.342910: val_loss -0.3551 
2025-08-28 14:03:21.346815: Pseudo dice [np.float32(0.5583)] 
2025-08-28 14:03:21.355440: Epoch time: 16.58 s 
2025-08-28 14:03:22.045282:  
2025-08-28 14:03:22.052630: Epoch 202 
2025-08-28 14:03:22.058878: Current learning rate: 0.00816 
2025-08-28 14:03:38.714094: train_loss -0.3756 
2025-08-28 14:03:38.722026: val_loss -0.3165 
2025-08-28 14:03:38.726653: Pseudo dice [np.float32(0.5371)] 
2025-08-28 14:03:38.731904: Epoch time: 16.67 s 
2025-08-28 14:03:39.414669:  
2025-08-28 14:03:39.423057: Epoch 203 
2025-08-28 14:03:39.429310: Current learning rate: 0.00815 
2025-08-28 14:03:55.990795: train_loss -0.4021 
2025-08-28 14:03:55.998043: val_loss -0.4302 
2025-08-28 14:03:56.002532: Pseudo dice [np.float32(0.6777)] 
2025-08-28 14:03:56.010264: Epoch time: 16.58 s 
2025-08-28 14:03:56.709089:  
2025-08-28 14:03:56.718379: Epoch 204 
2025-08-28 14:03:56.725949: Current learning rate: 0.00814 
2025-08-28 14:04:13.395082: train_loss -0.4129 
2025-08-28 14:04:13.407080: val_loss -0.3534 
2025-08-28 14:04:13.411273: Pseudo dice [np.float32(0.5791)] 
2025-08-28 14:04:13.418226: Epoch time: 16.69 s 
2025-08-28 14:04:14.248754:  
2025-08-28 14:04:14.256786: Epoch 205 
2025-08-28 14:04:14.261999: Current learning rate: 0.00813 
2025-08-28 14:04:30.974580: train_loss -0.4268 
2025-08-28 14:04:30.982986: val_loss -0.5238 
2025-08-28 14:04:30.987383: Pseudo dice [np.float32(0.7552)] 
2025-08-28 14:04:30.993568: Epoch time: 16.73 s 
2025-08-28 14:04:31.681543:  
2025-08-28 14:04:31.689867: Epoch 206 
2025-08-28 14:04:31.696064: Current learning rate: 0.00813 
2025-08-28 14:04:48.195946: train_loss -0.3648 
2025-08-28 14:04:48.200170: val_loss -0.1743 
2025-08-28 14:04:48.208531: Pseudo dice [np.float32(0.3529)] 
2025-08-28 14:04:48.213432: Epoch time: 16.52 s 
2025-08-28 14:04:48.879827:  
2025-08-28 14:04:48.887217: Epoch 207 
2025-08-28 14:04:48.893618: Current learning rate: 0.00812 
2025-08-28 14:05:05.584183: train_loss -0.3498 
2025-08-28 14:05:05.592505: val_loss -0.4273 
2025-08-28 14:05:05.596668: Pseudo dice [np.float32(0.7001)] 
2025-08-28 14:05:05.605711: Epoch time: 16.71 s 
2025-08-28 14:05:06.281711:  
2025-08-28 14:05:06.290002: Epoch 208 
2025-08-28 14:05:06.295766: Current learning rate: 0.00811 
2025-08-28 14:05:22.596986: train_loss -0.3909 
2025-08-28 14:05:22.605326: val_loss -0.3186 
2025-08-28 14:05:22.609843: Pseudo dice [np.float32(0.6133)] 
2025-08-28 14:05:22.617913: Epoch time: 16.32 s 
2025-08-28 14:05:23.302935:  
2025-08-28 14:05:23.310104: Epoch 209 
2025-08-28 14:05:23.316365: Current learning rate: 0.0081 
2025-08-28 14:05:40.056097: train_loss -0.4204 
2025-08-28 14:05:40.064417: val_loss -0.4157 
2025-08-28 14:05:40.068581: Pseudo dice [np.float32(0.6386)] 
2025-08-28 14:05:40.076588: Epoch time: 16.75 s 
2025-08-28 14:05:40.752549:  
2025-08-28 14:05:40.759845: Epoch 210 
2025-08-28 14:05:40.766222: Current learning rate: 0.00809 
2025-08-28 14:05:57.532560: train_loss -0.434 
2025-08-28 14:05:57.540216: val_loss -0.3128 
2025-08-28 14:05:57.544637: Pseudo dice [np.float32(0.5512)] 
2025-08-28 14:05:57.550568: Epoch time: 16.78 s 
2025-08-28 14:05:58.229397:  
2025-08-28 14:05:58.237788: Epoch 211 
2025-08-28 14:05:58.242895: Current learning rate: 0.00808 
2025-08-28 14:06:14.949231: train_loss -0.3717 
2025-08-28 14:06:14.957622: val_loss -0.352 
2025-08-28 14:06:14.961792: Pseudo dice [np.float32(0.7022)] 
2025-08-28 14:06:14.967151: Epoch time: 16.72 s 
2025-08-28 14:06:15.660330:  
2025-08-28 14:06:15.668711: Epoch 212 
2025-08-28 14:06:15.674891: Current learning rate: 0.00807 
2025-08-28 14:06:32.658592: train_loss -0.3871 
2025-08-28 14:06:32.666933: val_loss -0.3937 
2025-08-28 14:06:32.675901: Pseudo dice [np.float32(0.6569)] 
2025-08-28 14:06:32.680711: Epoch time: 17.0 s 
2025-08-28 14:06:33.371729:  
2025-08-28 14:06:33.379461: Epoch 213 
2025-08-28 14:06:33.386335: Current learning rate: 0.00806 
2025-08-28 14:06:49.876081: train_loss -0.3846 
2025-08-28 14:06:49.884127: val_loss -0.4102 
2025-08-28 14:06:49.888304: Pseudo dice [np.float32(0.685)] 
2025-08-28 14:06:49.896442: Epoch time: 16.51 s 
2025-08-28 14:06:50.583658:  
2025-08-28 14:06:50.591676: Epoch 214 
2025-08-28 14:06:50.598392: Current learning rate: 0.00805 
2025-08-28 14:07:07.126408: train_loss -0.3969 
2025-08-28 14:07:07.134735: val_loss -0.3828 
2025-08-28 14:07:07.139146: Pseudo dice [np.float32(0.6951)] 
2025-08-28 14:07:07.144971: Epoch time: 16.54 s 
2025-08-28 14:07:07.829318:  
2025-08-28 14:07:07.837404: Epoch 215 
2025-08-28 14:07:07.843616: Current learning rate: 0.00804 
2025-08-28 14:07:24.160141: train_loss -0.375 
2025-08-28 14:07:24.172538: val_loss -0.4461 
2025-08-28 14:07:24.176724: Pseudo dice [np.float32(0.7037)] 
2025-08-28 14:07:24.181666: Epoch time: 16.33 s 
2025-08-28 14:07:24.185797: Yayy! New best EMA pseudo Dice: 0.6442999839782715 
2025-08-28 14:07:25.054664:  
2025-08-28 14:07:25.060803: Epoch 216 
2025-08-28 14:07:25.067096: Current learning rate: 0.00803 
2025-08-28 14:07:41.527342: train_loss -0.4338 
2025-08-28 14:07:41.535716: val_loss -0.3243 
2025-08-28 14:07:41.539911: Pseudo dice [np.float32(0.5051)] 
2025-08-28 14:07:41.548980: Epoch time: 16.47 s 
2025-08-28 14:07:42.237403:  
2025-08-28 14:07:42.245105: Epoch 217 
2025-08-28 14:07:42.250955: Current learning rate: 0.00802 
2025-08-28 14:07:58.715526: train_loss -0.3866 
2025-08-28 14:07:58.720047: val_loss -0.4572 
2025-08-28 14:07:58.727880: Pseudo dice [np.float32(0.6209)] 
2025-08-28 14:07:58.733300: Epoch time: 16.48 s 
2025-08-28 14:07:59.447857:  
2025-08-28 14:07:59.455671: Epoch 218 
2025-08-28 14:07:59.463760: Current learning rate: 0.00801 
2025-08-28 14:08:16.036829: train_loss -0.4006 
2025-08-28 14:08:16.045475: val_loss -0.4394 
2025-08-28 14:08:16.053544: Pseudo dice [np.float32(0.6088)] 
2025-08-28 14:08:16.059977: Epoch time: 16.59 s 
2025-08-28 14:08:16.906371:  
2025-08-28 14:08:16.914756: Epoch 219 
2025-08-28 14:08:16.920842: Current learning rate: 0.00801 
2025-08-28 14:08:33.562637: train_loss -0.4726 
2025-08-28 14:08:33.570977: val_loss -0.3779 
2025-08-28 14:08:33.575174: Pseudo dice [np.float32(0.6637)] 
2025-08-28 14:08:33.583349: Epoch time: 16.66 s 
2025-08-28 14:08:34.275723:  
2025-08-28 14:08:34.283026: Epoch 220 
2025-08-28 14:08:34.289450: Current learning rate: 0.008 
2025-08-28 14:08:50.697382: train_loss -0.3969 
2025-08-28 14:08:50.706333: val_loss -0.5155 
2025-08-28 14:08:50.713777: Pseudo dice [np.float32(0.6942)] 
2025-08-28 14:08:50.720917: Epoch time: 16.42 s 
2025-08-28 14:08:51.360630:  
2025-08-28 14:08:51.367824: Epoch 221 
2025-08-28 14:08:51.373094: Current learning rate: 0.00799 
2025-08-28 14:09:06.734325: train_loss -0.4233 
2025-08-28 14:09:06.734325: val_loss -0.4614 
2025-08-28 14:09:06.742013: Pseudo dice [np.float32(0.7152)] 
2025-08-28 14:09:06.749220: Epoch time: 15.38 s 
2025-08-28 14:09:06.756781: Yayy! New best EMA pseudo Dice: 0.6450999975204468 
2025-08-28 14:09:07.604970:  
2025-08-28 14:09:07.606042: Epoch 222 
2025-08-28 14:09:07.613253: Current learning rate: 0.00798 
2025-08-28 14:09:23.066196: train_loss -0.4308 
2025-08-28 14:09:23.066196: val_loss -0.3338 
2025-08-28 14:09:23.074569: Pseudo dice [np.float32(0.5935)] 
2025-08-28 14:09:23.079267: Epoch time: 15.46 s 
2025-08-28 14:09:23.719234:  
2025-08-28 14:09:23.726742: Epoch 223 
2025-08-28 14:09:23.730994: Current learning rate: 0.00797 
2025-08-28 14:09:39.449812: train_loss -0.4338 
2025-08-28 14:09:39.449812: val_loss -0.5011 
2025-08-28 14:09:39.457582: Pseudo dice [np.float32(0.719)] 
2025-08-28 14:09:39.464855: Epoch time: 15.73 s 
2025-08-28 14:09:39.470412: Yayy! New best EMA pseudo Dice: 0.6478999853134155 
2025-08-28 14:09:40.263639:  
2025-08-28 14:09:40.271870: Epoch 224 
2025-08-28 14:09:40.276072: Current learning rate: 0.00796 
2025-08-28 14:09:55.950056: train_loss -0.4536 
2025-08-28 14:09:55.959107: val_loss -0.3035 
2025-08-28 14:09:55.965638: Pseudo dice [np.float32(0.5887)] 
2025-08-28 14:09:55.971006: Epoch time: 15.69 s 
2025-08-28 14:09:56.750064:  
2025-08-28 14:09:56.758598: Epoch 225 
2025-08-28 14:09:56.762729: Current learning rate: 0.00795 
2025-08-28 14:10:11.769011: train_loss -0.3872 
2025-08-28 14:10:11.769011: val_loss -0.4805 
2025-08-28 14:10:11.777359: Pseudo dice [np.float32(0.6996)] 
2025-08-28 14:10:11.786360: Epoch time: 15.02 s 
2025-08-28 14:10:12.408645:  
2025-08-28 14:10:12.416552: Epoch 226 
2025-08-28 14:10:12.421678: Current learning rate: 0.00794 
2025-08-28 14:10:27.530756: train_loss -0.3837 
2025-08-28 14:10:27.538920: val_loss -0.3563 
2025-08-28 14:10:27.543414: Pseudo dice [np.float32(0.6512)] 
2025-08-28 14:10:27.552084: Epoch time: 15.12 s 
2025-08-28 14:10:27.558134: Yayy! New best EMA pseudo Dice: 0.6481000185012817 
2025-08-28 14:10:28.349145:  
2025-08-28 14:10:28.357491: Epoch 227 
2025-08-28 14:10:28.364737: Current learning rate: 0.00793 
2025-08-28 14:10:43.784750: train_loss -0.4384 
2025-08-28 14:10:43.792949: val_loss -0.4361 
2025-08-28 14:10:43.796835: Pseudo dice [np.float32(0.6368)] 
2025-08-28 14:10:43.804779: Epoch time: 15.44 s 
2025-08-28 14:10:44.416114:  
2025-08-28 14:10:44.422285: Epoch 228 
2025-08-28 14:10:44.428627: Current learning rate: 0.00792 
2025-08-28 14:10:59.375231: train_loss -0.4182 
2025-08-28 14:10:59.383223: val_loss -0.4884 
2025-08-28 14:10:59.387397: Pseudo dice [np.float32(0.7167)] 
2025-08-28 14:10:59.395251: Epoch time: 14.96 s 
2025-08-28 14:10:59.400368: Yayy! New best EMA pseudo Dice: 0.6539000272750854 
2025-08-28 14:11:00.194445:  
2025-08-28 14:11:00.204685: Epoch 229 
2025-08-28 14:11:00.209354: Current learning rate: 0.00791 
2025-08-28 14:11:15.365829: train_loss -0.4139 
2025-08-28 14:11:15.370007: val_loss -0.3707 
2025-08-28 14:11:15.378360: Pseudo dice [np.float32(0.6466)] 
2025-08-28 14:11:15.382389: Epoch time: 15.17 s 
2025-08-28 14:11:15.993553:  
2025-08-28 14:11:16.001981: Epoch 230 
2025-08-28 14:11:16.006994: Current learning rate: 0.0079 
2025-08-28 14:11:31.023178: train_loss -0.4304 
2025-08-28 14:11:31.031562: val_loss -0.3532 
2025-08-28 14:11:31.035712: Pseudo dice [np.float32(0.6125)] 
2025-08-28 14:11:31.043616: Epoch time: 15.03 s 
2025-08-28 14:11:31.655940:  
2025-08-28 14:11:31.664290: Epoch 231 
2025-08-28 14:11:31.671659: Current learning rate: 0.00789 
2025-08-28 14:11:46.897515: train_loss -0.3664 
2025-08-28 14:11:46.905662: val_loss -0.3966 
2025-08-28 14:11:46.910240: Pseudo dice [np.float32(0.6669)] 
2025-08-28 14:11:46.917105: Epoch time: 15.24 s 
2025-08-28 14:11:47.698050:  
2025-08-28 14:11:47.706323: Epoch 232 
2025-08-28 14:11:47.711644: Current learning rate: 0.00789 
2025-08-28 14:12:03.001456: train_loss -0.3647 
2025-08-28 14:12:03.001456: val_loss -0.4463 
2025-08-28 14:12:03.011090: Pseudo dice [np.float32(0.686)] 
2025-08-28 14:12:03.015342: Epoch time: 15.3 s 
2025-08-28 14:12:03.022843: Yayy! New best EMA pseudo Dice: 0.6543999910354614 
2025-08-28 14:12:03.819880:  
2025-08-28 14:12:03.826654: Epoch 233 
2025-08-28 14:12:03.832425: Current learning rate: 0.00788 
2025-08-28 14:12:19.155544: train_loss -0.4112 
2025-08-28 14:12:19.155544: val_loss -0.4781 
2025-08-28 14:12:19.164659: Pseudo dice [np.float32(0.6522)] 
2025-08-28 14:12:19.170419: Epoch time: 15.34 s 
2025-08-28 14:12:19.786930:  
2025-08-28 14:12:19.792677: Epoch 234 
2025-08-28 14:12:19.797075: Current learning rate: 0.00787 
2025-08-28 14:12:35.525066: train_loss -0.4382 
2025-08-28 14:12:35.533646: val_loss -0.4409 
2025-08-28 14:12:35.537629: Pseudo dice [np.float32(0.7202)] 
2025-08-28 14:12:35.546505: Epoch time: 15.74 s 
2025-08-28 14:12:35.551585: Yayy! New best EMA pseudo Dice: 0.6607999801635742 
2025-08-28 14:12:36.375028:  
2025-08-28 14:12:36.380057: Epoch 235 
2025-08-28 14:12:36.384220: Current learning rate: 0.00786 
2025-08-28 14:12:50.957091: train_loss -0.4398 
2025-08-28 14:12:50.961288: val_loss -0.4974 
2025-08-28 14:12:50.969617: Pseudo dice [np.float32(0.732)] 
2025-08-28 14:12:50.974498: Epoch time: 14.59 s 
2025-08-28 14:12:50.978935: Yayy! New best EMA pseudo Dice: 0.667900025844574 
2025-08-28 14:12:51.766308:  
2025-08-28 14:12:51.774587: Epoch 236 
2025-08-28 14:12:51.778659: Current learning rate: 0.00785 
2025-08-28 14:13:06.835611: train_loss -0.4318 
2025-08-28 14:13:06.843816: val_loss -0.4561 
2025-08-28 14:13:06.847979: Pseudo dice [np.float32(0.6862)] 
2025-08-28 14:13:06.855958: Epoch time: 15.07 s 
2025-08-28 14:13:06.861897: Yayy! New best EMA pseudo Dice: 0.669700026512146 
2025-08-28 14:13:07.641402:  
2025-08-28 14:13:07.648741: Epoch 237 
2025-08-28 14:13:07.654908: Current learning rate: 0.00784 
2025-08-28 14:13:22.881729: train_loss -0.4475 
2025-08-28 14:13:22.890148: val_loss -0.4414 
2025-08-28 14:13:22.897183: Pseudo dice [np.float32(0.7035)] 
2025-08-28 14:13:22.901571: Epoch time: 15.24 s 
2025-08-28 14:13:22.906634: Yayy! New best EMA pseudo Dice: 0.6730999946594238 
2025-08-28 14:13:23.711696:  
2025-08-28 14:13:23.718953: Epoch 238 
2025-08-28 14:13:23.724249: Current learning rate: 0.00783 
2025-08-28 14:13:38.296776: train_loss -0.4063 
2025-08-28 14:13:38.304715: val_loss -0.4193 
2025-08-28 14:13:38.309237: Pseudo dice [np.float32(0.658)] 
2025-08-28 14:13:38.316411: Epoch time: 14.59 s 
2025-08-28 14:13:39.076307:  
2025-08-28 14:13:39.084712: Epoch 239 
2025-08-28 14:13:39.088807: Current learning rate: 0.00782 
2025-08-28 14:13:53.783585: train_loss -0.4426 
2025-08-28 14:13:53.783585: val_loss -0.3565 
2025-08-28 14:13:53.790690: Pseudo dice [np.float32(0.6074)] 
2025-08-28 14:13:53.797786: Epoch time: 14.71 s 
2025-08-28 14:13:54.412127:  
2025-08-28 14:13:54.422399: Epoch 240 
2025-08-28 14:13:54.425817: Current learning rate: 0.00781 
2025-08-28 14:14:09.127620: train_loss -0.4691 
2025-08-28 14:14:09.139344: val_loss -0.3352 
2025-08-28 14:14:09.143779: Pseudo dice [np.float32(0.559)] 
2025-08-28 14:14:09.148529: Epoch time: 14.72 s 
2025-08-28 14:14:09.815016:  
2025-08-28 14:14:09.823357: Epoch 241 
2025-08-28 14:14:09.827695: Current learning rate: 0.0078 
2025-08-28 14:14:25.230411: train_loss -0.377 
2025-08-28 14:14:25.238787: val_loss -0.3649 
2025-08-28 14:14:25.242929: Pseudo dice [np.float32(0.6071)] 
2025-08-28 14:14:25.248974: Epoch time: 15.42 s 
2025-08-28 14:14:25.864375:  
2025-08-28 14:14:25.868536: Epoch 242 
2025-08-28 14:14:25.877185: Current learning rate: 0.00779 
2025-08-28 14:14:40.783448: train_loss -0.3933 
2025-08-28 14:14:40.791965: val_loss -0.4269 
2025-08-28 14:14:40.796006: Pseudo dice [np.float32(0.7215)] 
2025-08-28 14:14:40.802007: Epoch time: 14.92 s 
2025-08-28 14:14:41.421550:  
2025-08-28 14:14:41.425743: Epoch 243 
2025-08-28 14:14:41.429902: Current learning rate: 0.00778 
2025-08-28 14:14:57.145803: train_loss -0.4275 
2025-08-28 14:14:57.153956: val_loss -0.4062 
2025-08-28 14:14:57.158329: Pseudo dice [np.float32(0.7076)] 
2025-08-28 14:14:57.166461: Epoch time: 15.73 s 
2025-08-28 14:14:57.779574:  
2025-08-28 14:14:57.787894: Epoch 244 
2025-08-28 14:14:57.792067: Current learning rate: 0.00777 
2025-08-28 14:15:12.369315: train_loss -0.4876 
2025-08-28 14:15:12.377500: val_loss -0.4576 
2025-08-28 14:15:12.381845: Pseudo dice [np.float32(0.677)] 
2025-08-28 14:15:12.390781: Epoch time: 14.59 s 
2025-08-28 14:15:12.999254:  
2025-08-28 14:15:13.007288: Epoch 245 
2025-08-28 14:15:13.011461: Current learning rate: 0.00777 
2025-08-28 14:15:27.534677: train_loss -0.4162 
2025-08-28 14:15:27.542614: val_loss -0.3946 
2025-08-28 14:15:27.546780: Pseudo dice [np.float32(0.667)] 
2025-08-28 14:15:27.555991: Epoch time: 14.54 s 
2025-08-28 14:15:28.335070:  
2025-08-28 14:15:28.343762: Epoch 246 
2025-08-28 14:15:28.347581: Current learning rate: 0.00776 
2025-08-28 14:15:43.638651: train_loss -0.4069 
2025-08-28 14:15:43.646219: val_loss -0.3863 
2025-08-28 14:15:43.654528: Pseudo dice [np.float32(0.6795)] 
2025-08-28 14:15:43.659431: Epoch time: 15.3 s 
2025-08-28 14:15:44.271806:  
2025-08-28 14:15:44.280193: Epoch 247 
2025-08-28 14:15:44.284432: Current learning rate: 0.00775 
2025-08-28 14:15:59.558502: train_loss -0.4054 
2025-08-28 14:15:59.566587: val_loss -0.457 
2025-08-28 14:15:59.570704: Pseudo dice [np.float32(0.7536)] 
2025-08-28 14:15:59.578814: Epoch time: 15.29 s 
2025-08-28 14:15:59.584993: Yayy! New best EMA pseudo Dice: 0.6743000149726868 
2025-08-28 14:16:00.371213:  
2025-08-28 14:16:00.379542: Epoch 248 
2025-08-28 14:16:00.383682: Current learning rate: 0.00774 
2025-08-28 14:16:15.616071: train_loss -0.4207 
2025-08-28 14:16:15.623957: val_loss -0.46 
2025-08-28 14:16:15.628133: Pseudo dice [np.float32(0.7463)] 
2025-08-28 14:16:15.637281: Epoch time: 15.24 s 
2025-08-28 14:16:15.641501: Yayy! New best EMA pseudo Dice: 0.6815000176429749 
2025-08-28 14:16:16.433380:  
2025-08-28 14:16:16.441963: Epoch 249 
2025-08-28 14:16:16.445985: Current learning rate: 0.00773 
2025-08-28 14:16:31.314616: train_loss -0.4028 
2025-08-28 14:16:31.322962: val_loss -0.4761 
2025-08-28 14:16:31.331199: Pseudo dice [np.float32(0.692)] 
2025-08-28 14:16:31.337487: Epoch time: 14.88 s 
2025-08-28 14:16:31.510656: Yayy! New best EMA pseudo Dice: 0.6825000047683716 
2025-08-28 14:16:32.290585:  
2025-08-28 14:16:32.299270: Epoch 250 
2025-08-28 14:16:32.303106: Current learning rate: 0.00772 
2025-08-28 14:16:47.614200: train_loss -0.4339 
2025-08-28 14:16:47.618422: val_loss -0.4388 
2025-08-28 14:16:47.626733: Pseudo dice [np.float32(0.6945)] 
2025-08-28 14:16:47.632840: Epoch time: 15.32 s 
2025-08-28 14:16:47.635918: Yayy! New best EMA pseudo Dice: 0.6837000250816345 
2025-08-28 14:16:48.427519:  
2025-08-28 14:16:48.435884: Epoch 251 
2025-08-28 14:16:48.439948: Current learning rate: 0.00771 
2025-08-28 14:17:03.100501: train_loss -0.3637 
2025-08-28 14:17:03.108872: val_loss -0.3622 
2025-08-28 14:17:03.113089: Pseudo dice [np.float32(0.5409)] 
2025-08-28 14:17:03.122161: Epoch time: 14.67 s 
2025-08-28 14:17:03.922138:  
2025-08-28 14:17:03.930538: Epoch 252 
2025-08-28 14:17:03.934634: Current learning rate: 0.0077 
2025-08-28 14:17:18.682741: train_loss -0.4487 
2025-08-28 14:17:18.695498: val_loss -0.4757 
2025-08-28 14:17:18.699507: Pseudo dice [np.float32(0.6501)] 
2025-08-28 14:17:18.705605: Epoch time: 14.76 s 
2025-08-28 14:17:19.317248:  
2025-08-28 14:17:19.320903: Epoch 253 
2025-08-28 14:17:19.329213: Current learning rate: 0.00769 
2025-08-28 14:17:34.590078: train_loss -0.4503 
2025-08-28 14:17:34.594499: val_loss -0.4798 
2025-08-28 14:17:34.603205: Pseudo dice [np.float32(0.7419)] 
2025-08-28 14:17:34.609973: Epoch time: 15.28 s 
2025-08-28 14:17:35.228438:  
2025-08-28 14:17:35.236752: Epoch 254 
2025-08-28 14:17:35.240832: Current learning rate: 0.00768 
2025-08-28 14:17:49.972301: train_loss -0.424 
2025-08-28 14:17:49.980642: val_loss -0.427 
2025-08-28 14:17:49.984816: Pseudo dice [np.float32(0.7285)] 
2025-08-28 14:17:49.990795: Epoch time: 14.74 s 
2025-08-28 14:17:50.602123:  
2025-08-28 14:17:50.610445: Epoch 255 
2025-08-28 14:17:50.614618: Current learning rate: 0.00767 
2025-08-28 14:18:05.421035: train_loss -0.4604 
2025-08-28 14:18:05.429454: val_loss -0.3799 
2025-08-28 14:18:05.437747: Pseudo dice [np.float32(0.5863)] 
2025-08-28 14:18:05.442072: Epoch time: 14.82 s 
2025-08-28 14:18:06.059190:  
2025-08-28 14:18:06.063354: Epoch 256 
2025-08-28 14:18:06.067523: Current learning rate: 0.00766 
2025-08-28 14:18:21.145072: train_loss -0.4473 
2025-08-28 14:18:21.153786: val_loss -0.4527 
2025-08-28 14:18:21.157968: Pseudo dice [np.float32(0.6669)] 
2025-08-28 14:18:21.166595: Epoch time: 15.09 s 
2025-08-28 14:18:21.812453:  
2025-08-28 14:18:21.816580: Epoch 257 
2025-08-28 14:18:21.824920: Current learning rate: 0.00765 
2025-08-28 14:18:37.227848: train_loss -0.4314 
2025-08-28 14:18:37.236233: val_loss -0.4998 
2025-08-28 14:18:37.240323: Pseudo dice [np.float32(0.7394)] 
2025-08-28 14:18:37.246255: Epoch time: 15.42 s 
2025-08-28 14:18:37.865981:  
2025-08-28 14:18:37.874290: Epoch 258 
2025-08-28 14:18:37.878807: Current learning rate: 0.00764 
2025-08-28 14:18:52.655716: train_loss -0.4453 
2025-08-28 14:18:52.664469: val_loss -0.371 
2025-08-28 14:18:52.672452: Pseudo dice [np.float32(0.7131)] 
2025-08-28 14:18:52.678067: Epoch time: 14.79 s 
2025-08-28 14:18:53.289648:  
2025-08-28 14:18:53.298039: Epoch 259 
2025-08-28 14:18:53.302198: Current learning rate: 0.00764 
2025-08-28 14:19:08.208893: train_loss -0.4246 
2025-08-28 14:19:08.217150: val_loss -0.524 
2025-08-28 14:19:08.221256: Pseudo dice [np.float32(0.7153)] 
2025-08-28 14:19:08.228230: Epoch time: 14.92 s 
2025-08-28 14:19:08.233732: Yayy! New best EMA pseudo Dice: 0.6844000220298767 
2025-08-28 14:19:09.042925:  
2025-08-28 14:19:09.051282: Epoch 260 
2025-08-28 14:19:09.055702: Current learning rate: 0.00763 
2025-08-28 14:19:24.170824: train_loss -0.4676 
2025-08-28 14:19:24.178940: val_loss -0.4448 
2025-08-28 14:19:24.183080: Pseudo dice [np.float32(0.6766)] 
2025-08-28 14:19:24.190956: Epoch time: 15.13 s 
2025-08-28 14:19:24.808638:  
2025-08-28 14:19:24.817011: Epoch 261 
2025-08-28 14:19:24.821161: Current learning rate: 0.00762 
2025-08-28 14:19:41.125097: train_loss -0.4653 
2025-08-28 14:19:41.133644: val_loss -0.3886 
2025-08-28 14:19:41.137500: Pseudo dice [np.float32(0.6067)] 
2025-08-28 14:19:41.145778: Epoch time: 16.32 s 
2025-08-28 14:19:41.783934:  
2025-08-28 14:19:41.788112: Epoch 262 
2025-08-28 14:19:41.796808: Current learning rate: 0.00761 
2025-08-28 14:19:58.492582: train_loss -0.4001 
2025-08-28 14:19:58.500700: val_loss -0.389 
2025-08-28 14:19:58.504854: Pseudo dice [np.float32(0.6074)] 
2025-08-28 14:19:58.513206: Epoch time: 16.71 s 
2025-08-28 14:19:59.147104:  
2025-08-28 14:19:59.155450: Epoch 263 
2025-08-28 14:19:59.159530: Current learning rate: 0.0076 
2025-08-28 14:20:15.483027: train_loss -0.4 
2025-08-28 14:20:15.492633: val_loss -0.4496 
2025-08-28 14:20:15.497147: Pseudo dice [np.float32(0.6569)] 
2025-08-28 14:20:15.503085: Epoch time: 16.34 s 
2025-08-28 14:20:16.143280:  
2025-08-28 14:20:16.151597: Epoch 264 
2025-08-28 14:20:16.155991: Current learning rate: 0.00759 
2025-08-28 14:20:32.780667: train_loss -0.4284 
2025-08-28 14:20:32.784855: val_loss -0.5261 
2025-08-28 14:20:32.793199: Pseudo dice [np.float32(0.7646)] 
2025-08-28 14:20:32.798749: Epoch time: 16.64 s 
2025-08-28 14:20:33.443840:  
2025-08-28 14:20:33.452200: Epoch 265 
2025-08-28 14:20:33.456716: Current learning rate: 0.00758 
2025-08-28 14:20:50.219920: train_loss -0.4306 
2025-08-28 14:20:50.227582: val_loss -0.413 
2025-08-28 14:20:50.231481: Pseudo dice [np.float32(0.5788)] 
2025-08-28 14:20:50.237716: Epoch time: 16.78 s 
2025-08-28 14:20:51.024250:  
2025-08-28 14:20:51.032254: Epoch 266 
2025-08-28 14:20:51.036404: Current learning rate: 0.00757 
2025-08-28 14:21:07.652881: train_loss -0.4483 
2025-08-28 14:21:07.657206: val_loss -0.4156 
2025-08-28 14:21:07.665500: Pseudo dice [np.float32(0.6593)] 
2025-08-28 14:21:07.670553: Epoch time: 16.63 s 
2025-08-28 14:21:08.312331:  
2025-08-28 14:21:08.320279: Epoch 267 
2025-08-28 14:21:08.324795: Current learning rate: 0.00756 
2025-08-28 14:21:24.053558: train_loss -0.4843 
2025-08-28 14:21:24.061059: val_loss -0.4686 
2025-08-28 14:21:24.065221: Pseudo dice [np.float32(0.6754)] 
2025-08-28 14:21:24.073385: Epoch time: 15.75 s 
2025-08-28 14:21:24.720318:  
2025-08-28 14:21:24.724501: Epoch 268 
2025-08-28 14:21:24.732905: Current learning rate: 0.00755 
2025-08-28 14:21:40.110533: train_loss -0.4747 
2025-08-28 14:21:40.118730: val_loss -0.4598 
2025-08-28 14:21:40.122918: Pseudo dice [np.float32(0.7108)] 
2025-08-28 14:21:40.129997: Epoch time: 15.39 s 
2025-08-28 14:21:40.769719:  
2025-08-28 14:21:40.778059: Epoch 269 
2025-08-28 14:21:40.783836: Current learning rate: 0.00754 
2025-08-28 14:21:56.294095: train_loss -0.4415 
2025-08-28 14:21:56.301922: val_loss -0.4874 
2025-08-28 14:21:56.309901: Pseudo dice [np.float32(0.7359)] 
2025-08-28 14:21:56.314149: Epoch time: 15.52 s 
2025-08-28 14:21:56.956484:  
2025-08-28 14:21:56.964730: Epoch 270 
2025-08-28 14:21:56.968932: Current learning rate: 0.00753 
2025-08-28 14:22:12.355103: train_loss -0.4342 
2025-08-28 14:22:12.363450: val_loss -0.4677 
2025-08-28 14:22:12.371803: Pseudo dice [np.float32(0.7324)] 
2025-08-28 14:22:12.376812: Epoch time: 15.4 s 
2025-08-28 14:22:13.022451:  
2025-08-28 14:22:13.030574: Epoch 271 
2025-08-28 14:22:13.035009: Current learning rate: 0.00752 
2025-08-28 14:22:28.655199: train_loss -0.4681 
2025-08-28 14:22:28.663051: val_loss -0.4592 
2025-08-28 14:22:28.667199: Pseudo dice [np.float32(0.6988)] 
2025-08-28 14:22:28.675502: Epoch time: 15.64 s 
2025-08-28 14:22:28.681375: Yayy! New best EMA pseudo Dice: 0.6852999925613403 
2025-08-28 14:22:29.701572:  
2025-08-28 14:22:29.710311: Epoch 272 
2025-08-28 14:22:29.718275: Current learning rate: 0.00751 
2025-08-28 14:22:45.188136: train_loss -0.3997 
2025-08-28 14:22:45.196600: val_loss -0.4041 
2025-08-28 14:22:45.200665: Pseudo dice [np.float32(0.6582)] 
2025-08-28 14:22:45.207736: Epoch time: 15.49 s 
2025-08-28 14:22:45.851056:  
2025-08-28 14:22:45.859407: Epoch 273 
2025-08-28 14:22:45.863500: Current learning rate: 0.00751 
2025-08-28 14:23:01.366454: train_loss -0.4104 
2025-08-28 14:23:01.370697: val_loss -0.4291 
2025-08-28 14:23:01.379057: Pseudo dice [np.float32(0.7289)] 
2025-08-28 14:23:01.383936: Epoch time: 15.52 s 
2025-08-28 14:23:01.388296: Yayy! New best EMA pseudo Dice: 0.6872000098228455 
2025-08-28 14:23:02.208996:  
2025-08-28 14:23:02.217399: Epoch 274 
2025-08-28 14:23:02.225624: Current learning rate: 0.0075 
2025-08-28 14:23:17.808768: train_loss -0.4686 
2025-08-28 14:23:17.816311: val_loss -0.4866 
2025-08-28 14:23:17.824933: Pseudo dice [np.float32(0.7422)] 
2025-08-28 14:23:17.830237: Epoch time: 15.6 s 
2025-08-28 14:23:17.833916: Yayy! New best EMA pseudo Dice: 0.6927000284194946 
2025-08-28 14:23:18.646673:  
2025-08-28 14:23:18.655500: Epoch 275 
2025-08-28 14:23:18.658955: Current learning rate: 0.00749 
2025-08-28 14:23:35.804927: train_loss -0.4724 
2025-08-28 14:23:35.809318: val_loss -0.4545 
2025-08-28 14:23:35.817651: Pseudo dice [np.float32(0.7246)] 
2025-08-28 14:23:35.823076: Epoch time: 17.16 s 
2025-08-28 14:23:35.826849: Yayy! New best EMA pseudo Dice: 0.695900022983551 
2025-08-28 14:23:36.668520:  
2025-08-28 14:23:36.672921: Epoch 276 
2025-08-28 14:23:36.681031: Current learning rate: 0.00748 
2025-08-28 14:23:53.285050: train_loss -0.483 
2025-08-28 14:23:53.293359: val_loss -0.5314 
2025-08-28 14:23:53.297786: Pseudo dice [np.float32(0.7125)] 
2025-08-28 14:23:53.305850: Epoch time: 16.62 s 
2025-08-28 14:23:53.312467: Yayy! New best EMA pseudo Dice: 0.6976000070571899 
2025-08-28 14:23:54.156710:  
2025-08-28 14:23:54.165434: Epoch 277 
2025-08-28 14:23:54.169541: Current learning rate: 0.00747 
2025-08-28 14:24:09.660220: train_loss -0.4231 
2025-08-28 14:24:09.668113: val_loss -0.4245 
2025-08-28 14:24:09.676675: Pseudo dice [np.float32(0.6678)] 
2025-08-28 14:24:09.681338: Epoch time: 15.5 s 
2025-08-28 14:24:10.339713:  
2025-08-28 14:24:10.348176: Epoch 278 
2025-08-28 14:24:10.352621: Current learning rate: 0.00746 
2025-08-28 14:24:25.789228: train_loss -0.4111 
2025-08-28 14:24:25.796948: val_loss -0.409 
2025-08-28 14:24:25.800797: Pseudo dice [np.float32(0.6582)] 
2025-08-28 14:24:25.809236: Epoch time: 15.45 s 
2025-08-28 14:24:26.609940:  
2025-08-28 14:24:26.618504: Epoch 279 
2025-08-28 14:24:26.622393: Current learning rate: 0.00745 
2025-08-28 14:24:42.142316: train_loss -0.4275 
2025-08-28 14:24:42.150743: val_loss -0.5194 
2025-08-28 14:24:42.154927: Pseudo dice [np.float32(0.6987)] 
2025-08-28 14:24:42.160783: Epoch time: 15.53 s 
2025-08-28 14:24:42.801100:  
2025-08-28 14:24:42.805293: Epoch 280 
2025-08-28 14:24:42.813649: Current learning rate: 0.00744 
2025-08-28 14:24:58.266744: train_loss -0.4715 
2025-08-28 14:24:58.274905: val_loss -0.3811 
2025-08-28 14:24:58.283608: Pseudo dice [np.float32(0.5689)] 
2025-08-28 14:24:58.289041: Epoch time: 15.47 s 
2025-08-28 14:24:58.930605:  
2025-08-28 14:24:58.938369: Epoch 281 
2025-08-28 14:24:58.942516: Current learning rate: 0.00743 
2025-08-28 14:25:14.311805: train_loss -0.409 
2025-08-28 14:25:14.324604: val_loss -0.3969 
2025-08-28 14:25:14.328440: Pseudo dice [np.float32(0.6315)] 
2025-08-28 14:25:14.333916: Epoch time: 15.38 s 
2025-08-28 14:25:14.974949:  
2025-08-28 14:25:14.983612: Epoch 282 
2025-08-28 14:25:14.987734: Current learning rate: 0.00742 
2025-08-28 14:25:30.386158: train_loss -0.4486 
2025-08-28 14:25:30.394475: val_loss -0.4506 
2025-08-28 14:25:30.398643: Pseudo dice [np.float32(0.6847)] 
2025-08-28 14:25:30.407823: Epoch time: 15.41 s 
2025-08-28 14:25:31.057662:  
2025-08-28 14:25:31.061828: Epoch 283 
2025-08-28 14:25:31.070171: Current learning rate: 0.00741 
2025-08-28 14:25:46.356597: train_loss -0.4475 
2025-08-28 14:25:46.364870: val_loss -0.4816 
2025-08-28 14:25:46.372943: Pseudo dice [np.float32(0.7416)] 
2025-08-28 14:25:46.377886: Epoch time: 15.3 s 
2025-08-28 14:25:47.015265:  
2025-08-28 14:25:47.023963: Epoch 284 
2025-08-28 14:25:47.027748: Current learning rate: 0.0074 
2025-08-28 14:26:02.501806: train_loss -0.4571 
2025-08-28 14:26:02.505710: val_loss -0.394 
2025-08-28 14:26:02.514042: Pseudo dice [np.float32(0.6838)] 
2025-08-28 14:26:02.520114: Epoch time: 15.49 s 
2025-08-28 14:26:03.314842:  
2025-08-28 14:26:03.323368: Epoch 285 
2025-08-28 14:26:03.327351: Current learning rate: 0.00739 
2025-08-28 14:26:18.563534: train_loss -0.4625 
2025-08-28 14:26:18.571739: val_loss -0.4405 
2025-08-28 14:26:18.575915: Pseudo dice [np.float32(0.7086)] 
2025-08-28 14:26:18.583409: Epoch time: 15.25 s 
2025-08-28 14:26:19.226645:  
2025-08-28 14:26:19.230756: Epoch 286 
2025-08-28 14:26:19.239069: Current learning rate: 0.00738 
2025-08-28 14:26:34.754565: train_loss -0.4992 
2025-08-28 14:26:34.764922: val_loss -0.4722 
2025-08-28 14:26:34.771281: Pseudo dice [np.float32(0.7013)] 
2025-08-28 14:26:34.777424: Epoch time: 15.53 s 
2025-08-28 14:26:35.438547:  
2025-08-28 14:26:35.443094: Epoch 287 
2025-08-28 14:26:35.447225: Current learning rate: 0.00738 
2025-08-28 14:26:50.820607: train_loss -0.4621 
2025-08-28 14:26:50.824782: val_loss -0.4885 
2025-08-28 14:26:50.833125: Pseudo dice [np.float32(0.7473)] 
2025-08-28 14:26:50.838036: Epoch time: 15.39 s 
2025-08-28 14:26:51.487990:  
2025-08-28 14:26:51.496551: Epoch 288 
2025-08-28 14:26:51.500534: Current learning rate: 0.00737 
2025-08-28 14:27:06.812417: train_loss -0.4263 
2025-08-28 14:27:06.820236: val_loss -0.473 
2025-08-28 14:27:06.824064: Pseudo dice [np.float32(0.7216)] 
2025-08-28 14:27:06.832298: Epoch time: 15.32 s 
2025-08-28 14:27:07.474719:  
2025-08-28 14:27:07.483077: Epoch 289 
2025-08-28 14:27:07.487553: Current learning rate: 0.00736 
2025-08-28 14:27:22.915627: train_loss -0.4536 
2025-08-28 14:27:22.923478: val_loss -0.4337 
2025-08-28 14:27:22.932190: Pseudo dice [np.float32(0.6632)] 
2025-08-28 14:27:22.937391: Epoch time: 15.44 s 
2025-08-28 14:27:23.582470:  
2025-08-28 14:27:23.586923: Epoch 290 
2025-08-28 14:27:23.594989: Current learning rate: 0.00735 
2025-08-28 14:27:38.889910: train_loss -0.4478 
2025-08-28 14:27:38.897694: val_loss -0.3828 
2025-08-28 14:27:38.901926: Pseudo dice [np.float32(0.6261)] 
2025-08-28 14:27:38.910203: Epoch time: 15.31 s 
2025-08-28 14:27:39.561290:  
2025-08-28 14:27:39.569254: Epoch 291 
2025-08-28 14:27:39.573451: Current learning rate: 0.00734 
2025-08-28 14:27:54.934642: train_loss -0.4249 
2025-08-28 14:27:54.942951: val_loss -0.4273 
2025-08-28 14:27:54.951381: Pseudo dice [np.float32(0.6053)] 
2025-08-28 14:27:54.956428: Epoch time: 15.38 s 
2025-08-28 14:27:55.768754:  
2025-08-28 14:27:55.777105: Epoch 292 
2025-08-28 14:27:55.781579: Current learning rate: 0.00733 
2025-08-28 14:28:11.138479: train_loss -0.4433 
2025-08-28 14:28:11.146635: val_loss -0.4239 
2025-08-28 14:28:11.154978: Pseudo dice [np.float32(0.6199)] 
2025-08-28 14:28:11.159814: Epoch time: 15.37 s 
2025-08-28 14:28:11.810075:  
2025-08-28 14:28:11.818160: Epoch 293 
2025-08-28 14:28:11.822304: Current learning rate: 0.00732 
2025-08-28 14:28:27.258565: train_loss -0.4523 
2025-08-28 14:28:27.263010: val_loss -0.4026 
2025-08-28 14:28:27.271376: Pseudo dice [np.float32(0.6791)] 
2025-08-28 14:28:27.276446: Epoch time: 15.45 s 
2025-08-28 14:28:27.925840:  
2025-08-28 14:28:27.930003: Epoch 294 
2025-08-28 14:28:27.938398: Current learning rate: 0.00731 
2025-08-28 14:28:43.453958: train_loss -0.47 
2025-08-28 14:28:43.462221: val_loss -0.5099 
2025-08-28 14:28:43.466358: Pseudo dice [np.float32(0.7109)] 
2025-08-28 14:28:43.472467: Epoch time: 15.53 s 
2025-08-28 14:28:44.112855:  
2025-08-28 14:28:44.121203: Epoch 295 
2025-08-28 14:28:44.125642: Current learning rate: 0.0073 
2025-08-28 14:28:59.653712: train_loss -0.4764 
2025-08-28 14:28:59.661740: val_loss -0.4563 
2025-08-28 14:28:59.665974: Pseudo dice [np.float32(0.6617)] 
2025-08-28 14:28:59.673600: Epoch time: 15.54 s 
2025-08-28 14:29:00.320698:  
2025-08-28 14:29:00.329066: Epoch 296 
2025-08-28 14:29:00.333235: Current learning rate: 0.00729 
2025-08-28 14:29:15.790307: train_loss -0.4462 
2025-08-28 14:29:15.798663: val_loss -0.4792 
2025-08-28 14:29:15.802835: Pseudo dice [np.float32(0.782)] 
2025-08-28 14:29:15.810861: Epoch time: 15.47 s 
2025-08-28 14:29:16.453818:  
2025-08-28 14:29:16.461835: Epoch 297 
2025-08-28 14:29:16.466518: Current learning rate: 0.00728 
2025-08-28 14:29:31.919310: train_loss -0.4655 
2025-08-28 14:29:31.927637: val_loss -0.5002 
2025-08-28 14:29:31.931489: Pseudo dice [np.float32(0.7132)] 
2025-08-28 14:29:31.937601: Epoch time: 15.47 s 
2025-08-28 14:29:32.736400:  
2025-08-28 14:29:32.740577: Epoch 298 
2025-08-28 14:29:32.748945: Current learning rate: 0.00727 
2025-08-28 14:29:48.006288: train_loss -0.4457 
2025-08-28 14:29:48.014206: val_loss -0.4394 
2025-08-28 14:29:48.018659: Pseudo dice [np.float32(0.6229)] 
2025-08-28 14:29:48.026573: Epoch time: 15.27 s 
2025-08-28 14:29:48.669270:  
2025-08-28 14:29:48.673400: Epoch 299 
2025-08-28 14:29:48.681805: Current learning rate: 0.00726 
2025-08-28 14:30:04.172128: train_loss -0.4503 
2025-08-28 14:30:04.180661: val_loss -0.4457 
2025-08-28 14:30:04.184750: Pseudo dice [np.float32(0.7013)] 
2025-08-28 14:30:04.191554: Epoch time: 15.51 s 
2025-08-28 14:30:05.039470:  
2025-08-28 14:30:05.047826: Epoch 300 
2025-08-28 14:30:05.052032: Current learning rate: 0.00725 
2025-08-28 14:30:21.143362: train_loss -0.4467 
2025-08-28 14:30:21.151510: val_loss -0.4328 
2025-08-28 14:30:21.159787: Pseudo dice [np.float32(0.6969)] 
2025-08-28 14:30:21.164599: Epoch time: 16.1 s 
2025-08-28 14:30:21.822897:  
2025-08-28 14:30:21.831264: Epoch 301 
2025-08-28 14:30:21.835426: Current learning rate: 0.00724 
2025-08-28 14:30:37.951824: train_loss -0.4676 
2025-08-28 14:30:37.960213: val_loss -0.3957 
2025-08-28 14:30:37.968531: Pseudo dice [np.float32(0.6414)] 
2025-08-28 14:30:37.974864: Epoch time: 16.13 s 
2025-08-28 14:30:38.627156:  
2025-08-28 14:30:38.635520: Epoch 302 
2025-08-28 14:30:38.639697: Current learning rate: 0.00724 
2025-08-28 14:30:54.910413: train_loss -0.473 
2025-08-28 14:30:54.918428: val_loss -0.4489 
2025-08-28 14:30:54.922591: Pseudo dice [np.float32(0.7164)] 
2025-08-28 14:30:54.930834: Epoch time: 16.29 s 
2025-08-28 14:30:55.577446:  
2025-08-28 14:30:55.585780: Epoch 303 
2025-08-28 14:30:55.589947: Current learning rate: 0.00723 
2025-08-28 14:31:12.002629: train_loss -0.4868 
2025-08-28 14:31:12.010502: val_loss -0.4226 
2025-08-28 14:31:12.014661: Pseudo dice [np.float32(0.6312)] 
2025-08-28 14:31:12.023076: Epoch time: 16.43 s 
2025-08-28 14:31:12.677832:  
2025-08-28 14:31:12.686260: Epoch 304 
2025-08-28 14:31:12.690362: Current learning rate: 0.00722 
2025-08-28 14:31:28.798102: train_loss -0.3904 
2025-08-28 14:31:28.806772: val_loss -0.4344 
2025-08-28 14:31:28.810624: Pseudo dice [np.float32(0.6933)] 
2025-08-28 14:31:28.818089: Epoch time: 16.12 s 
2025-08-28 14:31:29.636762:  
2025-08-28 14:31:29.644822: Epoch 305 
2025-08-28 14:31:29.649275: Current learning rate: 0.00721 
2025-08-28 14:31:45.527605: train_loss -0.4788 
2025-08-28 14:31:45.539824: val_loss -0.4504 
2025-08-28 14:31:45.543976: Pseudo dice [np.float32(0.7243)] 
2025-08-28 14:31:45.549271: Epoch time: 15.89 s 
2025-08-28 14:31:46.207469:  
2025-08-28 14:31:46.215529: Epoch 306 
2025-08-28 14:31:46.219661: Current learning rate: 0.0072 
2025-08-28 14:32:02.135913: train_loss -0.445 
2025-08-28 14:32:02.144181: val_loss -0.4093 
2025-08-28 14:32:02.152245: Pseudo dice [np.float32(0.6437)] 
2025-08-28 14:32:02.157258: Epoch time: 15.93 s 
2025-08-28 14:32:02.807079:  
2025-08-28 14:32:02.815431: Epoch 307 
2025-08-28 14:32:02.820131: Current learning rate: 0.00719 
2025-08-28 14:32:18.510489: train_loss -0.4703 
2025-08-28 14:32:18.522739: val_loss -0.4225 
2025-08-28 14:32:18.526921: Pseudo dice [np.float32(0.6944)] 
2025-08-28 14:32:18.533060: Epoch time: 15.7 s 
2025-08-28 14:32:19.190133:  
2025-08-28 14:32:19.198695: Epoch 308 
2025-08-28 14:32:19.202668: Current learning rate: 0.00718 
2025-08-28 14:32:35.206076: train_loss -0.4334 
2025-08-28 14:32:35.214408: val_loss -0.4981 
2025-08-28 14:32:35.218602: Pseudo dice [np.float32(0.7634)] 
2025-08-28 14:32:35.225749: Epoch time: 16.02 s 
2025-08-28 14:32:35.877308:  
2025-08-28 14:32:35.881876: Epoch 309 
2025-08-28 14:32:35.890143: Current learning rate: 0.00717 
2025-08-28 14:32:51.873125: train_loss -0.4565 
2025-08-28 14:32:51.881036: val_loss -0.4114 
2025-08-28 14:32:51.885431: Pseudo dice [np.float32(0.6251)] 
2025-08-28 14:32:51.893928: Epoch time: 16.0 s 
2025-08-28 14:32:52.544250:  
2025-08-28 14:32:52.552887: Epoch 310 
2025-08-28 14:32:52.556713: Current learning rate: 0.00716 
2025-08-28 14:33:08.827383: train_loss -0.4829 
2025-08-28 14:33:08.835476: val_loss -0.3865 
2025-08-28 14:33:08.839917: Pseudo dice [np.float32(0.6174)] 
2025-08-28 14:33:08.847853: Epoch time: 16.29 s 
2025-08-28 14:33:09.653029:  
2025-08-28 14:33:09.665575: Epoch 311 
2025-08-28 14:33:09.669645: Current learning rate: 0.00715 
2025-08-28 14:33:25.698202: train_loss -0.4453 
2025-08-28 14:33:25.706506: val_loss -0.4391 
2025-08-28 14:33:25.710649: Pseudo dice [np.float32(0.6806)] 
2025-08-28 14:33:25.716827: Epoch time: 16.05 s 
2025-08-28 14:33:26.373798:  
2025-08-28 14:33:26.382468: Epoch 312 
2025-08-28 14:33:26.386436: Current learning rate: 0.00714 
2025-08-28 14:33:42.431752: train_loss -0.4675 
2025-08-28 14:33:42.439896: val_loss -0.3773 
2025-08-28 14:33:42.444026: Pseudo dice [np.float32(0.5813)] 
2025-08-28 14:33:42.453254: Epoch time: 16.06 s 
2025-08-28 14:33:43.115505:  
2025-08-28 14:33:43.124183: Epoch 313 
2025-08-28 14:33:43.132263: Current learning rate: 0.00713 
2025-08-28 14:33:59.415486: train_loss -0.4628 
2025-08-28 14:33:59.423746: val_loss -0.4066 
2025-08-28 14:33:59.427847: Pseudo dice [np.float32(0.6265)] 
2025-08-28 14:33:59.435709: Epoch time: 16.3 s 
2025-08-28 14:34:00.094996:  
2025-08-28 14:34:00.103316: Epoch 314 
2025-08-28 14:34:00.107487: Current learning rate: 0.00712 
2025-08-28 14:34:16.194693: train_loss -0.4316 
2025-08-28 14:34:16.203052: val_loss -0.432 
2025-08-28 14:34:16.211083: Pseudo dice [np.float32(0.662)] 
2025-08-28 14:34:16.217252: Epoch time: 16.1 s 
2025-08-28 14:34:16.865949:  
2025-08-28 14:34:16.874352: Epoch 315 
2025-08-28 14:34:16.878510: Current learning rate: 0.00711 
2025-08-28 14:34:32.569128: train_loss -0.4596 
2025-08-28 14:34:32.577410: val_loss -0.4582 
2025-08-28 14:34:32.585747: Pseudo dice [np.float32(0.6768)] 
2025-08-28 14:34:32.591161: Epoch time: 15.7 s 
2025-08-28 14:34:33.240857:  
2025-08-28 14:34:33.248943: Epoch 316 
2025-08-28 14:34:33.253348: Current learning rate: 0.0071 
2025-08-28 14:34:48.810340: train_loss -0.454 
2025-08-28 14:34:48.818774: val_loss -0.4441 
2025-08-28 14:34:48.822918: Pseudo dice [np.float32(0.6798)] 
2025-08-28 14:34:48.828939: Epoch time: 15.57 s 
2025-08-28 14:34:49.523497:  
2025-08-28 14:34:49.527645: Epoch 317 
2025-08-28 14:34:49.536261: Current learning rate: 0.0071 
2025-08-28 14:35:04.980177: train_loss -0.4502 
2025-08-28 14:35:04.985129: val_loss -0.4214 
2025-08-28 14:35:04.993105: Pseudo dice [np.float32(0.6455)] 
2025-08-28 14:35:04.998270: Epoch time: 15.46 s 
2025-08-28 14:35:05.852549:  
2025-08-28 14:35:05.856467: Epoch 318 
2025-08-28 14:35:05.864852: Current learning rate: 0.00709 
2025-08-28 14:35:21.063625: train_loss -0.4261 
2025-08-28 14:35:21.075891: val_loss -0.5052 
2025-08-28 14:35:21.080294: Pseudo dice [np.float32(0.7206)] 
2025-08-28 14:35:21.087224: Epoch time: 15.22 s 
2025-08-28 14:35:21.739025:  
2025-08-28 14:35:21.747370: Epoch 319 
2025-08-28 14:35:21.751879: Current learning rate: 0.00708 
2025-08-28 14:35:37.242124: train_loss -0.4245 
2025-08-28 14:35:37.250352: val_loss -0.4852 
2025-08-28 14:35:37.254495: Pseudo dice [np.float32(0.7007)] 
2025-08-28 14:35:37.263837: Epoch time: 15.5 s 
2025-08-28 14:35:37.921817:  
2025-08-28 14:35:37.925982: Epoch 320 
2025-08-28 14:35:37.934363: Current learning rate: 0.00707 
2025-08-28 14:35:53.312224: train_loss -0.458 
2025-08-28 14:35:53.320560: val_loss -0.3636 
2025-08-28 14:35:53.328509: Pseudo dice [np.float32(0.7098)] 
2025-08-28 14:35:53.333073: Epoch time: 15.39 s 
2025-08-28 14:35:53.979859:  
2025-08-28 14:35:53.987940: Epoch 321 
2025-08-28 14:35:53.992025: Current learning rate: 0.00706 
2025-08-28 14:36:09.507524: train_loss -0.4395 
2025-08-28 14:36:09.515891: val_loss -0.499 
2025-08-28 14:36:09.524278: Pseudo dice [np.float32(0.6577)] 
2025-08-28 14:36:09.529171: Epoch time: 15.53 s 
2025-08-28 14:36:10.179327:  
2025-08-28 14:36:10.187392: Epoch 322 
2025-08-28 14:36:10.191833: Current learning rate: 0.00705 
2025-08-28 14:36:25.815491: train_loss -0.4802 
2025-08-28 14:36:25.824204: val_loss -0.4497 
2025-08-28 14:36:25.828091: Pseudo dice [np.float32(0.6658)] 
2025-08-28 14:36:25.837781: Epoch time: 15.64 s 
2025-08-28 14:36:26.507843:  
2025-08-28 14:36:26.516195: Epoch 323 
2025-08-28 14:36:26.520355: Current learning rate: 0.00704 
2025-08-28 14:36:41.948696: train_loss -0.4955 
2025-08-28 14:36:41.956901: val_loss -0.3902 
2025-08-28 14:36:41.960822: Pseudo dice [np.float32(0.6406)] 
2025-08-28 14:36:41.968962: Epoch time: 15.44 s 
2025-08-28 14:36:42.799149:  
2025-08-28 14:36:42.803790: Epoch 324 
2025-08-28 14:36:42.812028: Current learning rate: 0.00703 
2025-08-28 14:36:58.260329: train_loss -0.45 
2025-08-28 14:36:58.268745: val_loss -0.4932 
2025-08-28 14:36:58.272867: Pseudo dice [np.float32(0.7119)] 
2025-08-28 14:36:58.281263: Epoch time: 15.47 s 
2025-08-28 14:36:58.990244:  
2025-08-28 14:36:58.998624: Epoch 325 
2025-08-28 14:36:59.002960: Current learning rate: 0.00702 
2025-08-28 14:37:14.406335: train_loss -0.5273 
2025-08-28 14:37:14.418160: val_loss -0.468 
2025-08-28 14:37:14.422656: Pseudo dice [np.float32(0.6894)] 
2025-08-28 14:37:14.428563: Epoch time: 15.42 s 
2025-08-28 14:37:15.081318:  
2025-08-28 14:37:15.089696: Epoch 326 
2025-08-28 14:37:15.093868: Current learning rate: 0.00701 
2025-08-28 14:37:30.359175: train_loss -0.479 
2025-08-28 14:37:30.367434: val_loss -0.5115 
2025-08-28 14:37:30.371608: Pseudo dice [np.float32(0.7296)] 
2025-08-28 14:37:30.377750: Epoch time: 15.28 s 
2025-08-28 14:37:31.026617:  
2025-08-28 14:37:31.030874: Epoch 327 
2025-08-28 14:37:31.038952: Current learning rate: 0.007 
2025-08-28 14:37:46.350053: train_loss -0.4676 
2025-08-28 14:37:46.357922: val_loss -0.5196 
2025-08-28 14:37:46.362556: Pseudo dice [np.float32(0.718)] 
2025-08-28 14:37:46.368197: Epoch time: 15.33 s 
2025-08-28 14:37:47.029874:  
2025-08-28 14:37:47.038412: Epoch 328 
2025-08-28 14:37:47.042389: Current learning rate: 0.00699 
2025-08-28 14:38:02.458136: train_loss -0.4396 
2025-08-28 14:38:02.466426: val_loss -0.5685 
2025-08-28 14:38:02.470279: Pseudo dice [np.float32(0.7137)] 
2025-08-28 14:38:02.477481: Epoch time: 15.43 s 
2025-08-28 14:38:03.129294:  
2025-08-28 14:38:03.137669: Epoch 329 
2025-08-28 14:38:03.141781: Current learning rate: 0.00698 
2025-08-28 14:38:18.461315: train_loss -0.4312 
2025-08-28 14:38:18.469599: val_loss -0.4456 
2025-08-28 14:38:18.473765: Pseudo dice [np.float32(0.767)] 
2025-08-28 14:38:18.482258: Epoch time: 15.33 s 
2025-08-28 14:38:19.295540:  
2025-08-28 14:38:19.303806: Epoch 330 
2025-08-28 14:38:19.307950: Current learning rate: 0.00697 
2025-08-28 14:38:34.894423: train_loss -0.4881 
2025-08-28 14:38:34.902673: val_loss -0.4259 
2025-08-28 14:38:34.907142: Pseudo dice [np.float32(0.68)] 
2025-08-28 14:38:34.913237: Epoch time: 15.6 s 
2025-08-28 14:38:35.570364:  
2025-08-28 14:38:35.578353: Epoch 331 
2025-08-28 14:38:35.582501: Current learning rate: 0.00696 
2025-08-28 14:38:51.014993: train_loss -0.5085 
2025-08-28 14:38:51.023357: val_loss -0.4578 
2025-08-28 14:38:51.027142: Pseudo dice [np.float32(0.5834)] 
2025-08-28 14:38:51.034337: Epoch time: 15.44 s 
2025-08-28 14:38:51.698715:  
2025-08-28 14:38:51.707006: Epoch 332 
2025-08-28 14:38:51.711444: Current learning rate: 0.00696 
2025-08-28 14:39:07.302026: train_loss -0.4493 
2025-08-28 14:39:07.310126: val_loss -0.3606 
2025-08-28 14:39:07.314188: Pseudo dice [np.float32(0.5963)] 
2025-08-28 14:39:07.321381: Epoch time: 15.6 s 
2025-08-28 14:39:07.977672:  
2025-08-28 14:39:07.986086: Epoch 333 
2025-08-28 14:39:07.989902: Current learning rate: 0.00695 
2025-08-28 14:39:23.338540: train_loss -0.4208 
2025-08-28 14:39:23.346888: val_loss -0.487 
2025-08-28 14:39:23.351033: Pseudo dice [np.float32(0.6714)] 
2025-08-28 14:39:23.360174: Epoch time: 15.36 s 
2025-08-28 14:39:24.014218:  
2025-08-28 14:39:24.022879: Epoch 334 
2025-08-28 14:39:24.026951: Current learning rate: 0.00694 
2025-08-28 14:39:39.468736: train_loss -0.4766 
2025-08-28 14:39:39.476592: val_loss -0.4842 
2025-08-28 14:39:39.481052: Pseudo dice [np.float32(0.5016)] 
2025-08-28 14:39:39.488785: Epoch time: 15.45 s 
2025-08-28 14:39:40.131406:  
2025-08-28 14:39:40.138621: Epoch 335 
2025-08-28 14:39:40.143919: Current learning rate: 0.00693 
2025-08-28 14:39:54.448634: train_loss -0.4594 
2025-08-28 14:39:54.448634: val_loss -0.4491 
2025-08-28 14:39:54.457097: Pseudo dice [np.float32(0.7378)] 
2025-08-28 14:39:54.464416: Epoch time: 14.32 s 
2025-08-28 14:39:55.108804:  
2025-08-28 14:39:55.117186: Epoch 336 
2025-08-28 14:39:55.124261: Current learning rate: 0.00692 
2025-08-28 14:40:09.217835: train_loss -0.4823 
2025-08-28 14:40:09.226096: val_loss -0.4178 
2025-08-28 14:40:09.234364: Pseudo dice [np.float32(0.6323)] 
2025-08-28 14:40:09.239622: Epoch time: 14.11 s 
2025-08-28 14:40:10.050716:  
2025-08-28 14:40:10.058078: Epoch 337 
2025-08-28 14:40:10.064190: Current learning rate: 0.00691 
2025-08-28 14:40:24.103338: train_loss -0.4911 
2025-08-28 14:40:24.111699: val_loss -0.5622 
2025-08-28 14:40:24.115852: Pseudo dice [np.float32(0.7527)] 
2025-08-28 14:40:24.124285: Epoch time: 14.05 s 
2025-08-28 14:40:24.765357:  
2025-08-28 14:40:24.773704: Epoch 338 
2025-08-28 14:40:24.778867: Current learning rate: 0.0069 
2025-08-28 14:40:38.663713: train_loss -0.5144 
2025-08-28 14:40:38.674062: val_loss -0.4957 
2025-08-28 14:40:38.680392: Pseudo dice [np.float32(0.7333)] 
2025-08-28 14:40:38.684617: Epoch time: 13.9 s 
2025-08-28 14:40:39.336378:  
2025-08-28 14:40:39.343401: Epoch 339 
2025-08-28 14:40:39.348857: Current learning rate: 0.00689 
2025-08-28 14:40:53.395717: train_loss -0.4803 
2025-08-28 14:40:53.403467: val_loss -0.5405 
2025-08-28 14:40:53.407845: Pseudo dice [np.float32(0.7159)] 
2025-08-28 14:40:53.415278: Epoch time: 14.06 s 
2025-08-28 14:40:54.063427:  
2025-08-28 14:40:54.070935: Epoch 340 
2025-08-28 14:40:54.077043: Current learning rate: 0.00688 
2025-08-28 14:41:07.972160: train_loss -0.4885 
2025-08-28 14:41:07.980827: val_loss -0.4346 
2025-08-28 14:41:07.984996: Pseudo dice [np.float32(0.6206)] 
2025-08-28 14:41:07.992469: Epoch time: 13.91 s 
2025-08-28 14:41:08.700561:  
2025-08-28 14:41:08.708246: Epoch 341 
2025-08-28 14:41:08.714397: Current learning rate: 0.00687 
2025-08-28 14:41:22.537003: train_loss -0.4585 
2025-08-28 14:41:22.545041: val_loss -0.4573 
2025-08-28 14:41:22.553439: Pseudo dice [np.float32(0.6717)] 
2025-08-28 14:41:22.557591: Epoch time: 13.84 s 
2025-08-28 14:41:23.211293:  
2025-08-28 14:41:23.218575: Epoch 342 
2025-08-28 14:41:23.224810: Current learning rate: 0.00686 
2025-08-28 14:41:37.001112: train_loss -0.4658 
2025-08-28 14:41:37.009482: val_loss -0.4614 
2025-08-28 14:41:37.017821: Pseudo dice [np.float32(0.6613)] 
2025-08-28 14:41:37.023499: Epoch time: 13.79 s 
2025-08-28 14:41:37.824825:  
2025-08-28 14:41:37.835167: Epoch 343 
2025-08-28 14:41:37.840568: Current learning rate: 0.00685 
2025-08-28 14:41:51.891096: train_loss -0.4496 
2025-08-28 14:41:51.899546: val_loss -0.4336 
2025-08-28 14:41:51.903729: Pseudo dice [np.float32(0.7136)] 
2025-08-28 14:41:51.911937: Epoch time: 14.07 s 
2025-08-28 14:41:52.559374:  
2025-08-28 14:41:52.568837: Epoch 344 
2025-08-28 14:41:52.576049: Current learning rate: 0.00684 
2025-08-28 14:42:06.409779: train_loss -0.4101 
2025-08-28 14:42:06.418016: val_loss -0.4448 
2025-08-28 14:42:06.422050: Pseudo dice [np.float32(0.7062)] 
2025-08-28 14:42:06.428455: Epoch time: 13.85 s 
2025-08-28 14:42:07.070741:  
2025-08-28 14:42:07.079110: Epoch 345 
2025-08-28 14:42:07.084162: Current learning rate: 0.00683 
2025-08-28 14:42:21.160763: train_loss -0.4555 
2025-08-28 14:42:21.170230: val_loss -0.4435 
2025-08-28 14:42:21.174717: Pseudo dice [np.float32(0.7491)] 
2025-08-28 14:42:21.179656: Epoch time: 14.09 s 
2025-08-28 14:42:21.857257:  
2025-08-28 14:42:21.869794: Epoch 346 
2025-08-28 14:42:21.882256: Current learning rate: 0.00682 
2025-08-28 14:42:36.769095: train_loss -0.4461 
2025-08-28 14:42:36.777476: val_loss -0.4726 
2025-08-28 14:42:36.781628: Pseudo dice [np.float32(0.6176)] 
2025-08-28 14:42:36.789664: Epoch time: 14.91 s 
2025-08-28 14:42:37.443741:  
2025-08-28 14:42:37.454362: Epoch 347 
2025-08-28 14:42:37.462609: Current learning rate: 0.00681 
2025-08-28 14:42:52.276271: train_loss -0.5058 
2025-08-28 14:42:52.284616: val_loss -0.5449 
2025-08-28 14:42:52.288792: Pseudo dice [np.float32(0.7795)] 
2025-08-28 14:42:52.297104: Epoch time: 14.83 s 
2025-08-28 14:42:52.947648:  
2025-08-28 14:42:52.957220: Epoch 348 
2025-08-28 14:42:52.965289: Current learning rate: 0.0068 
2025-08-28 14:43:08.259260: train_loss -0.4713 
2025-08-28 14:43:08.268895: val_loss -0.5435 
2025-08-28 14:43:08.271561: Pseudo dice [np.float32(0.7486)] 
2025-08-28 14:43:08.280897: Epoch time: 15.31 s 
2025-08-28 14:43:09.096110:  
2025-08-28 14:43:09.105421: Epoch 349 
2025-08-28 14:43:09.111774: Current learning rate: 0.0068 
2025-08-28 14:43:23.857915: train_loss -0.4855 
2025-08-28 14:43:23.866138: val_loss -0.4447 
2025-08-28 14:43:23.870625: Pseudo dice [np.float32(0.7442)] 
2025-08-28 14:43:23.879024: Epoch time: 14.76 s 
2025-08-28 14:43:24.066373: Yayy! New best EMA pseudo Dice: 0.7008000016212463 
2025-08-28 14:43:24.897428:  
2025-08-28 14:43:24.904553: Epoch 350 
2025-08-28 14:43:24.910878: Current learning rate: 0.00679 
2025-08-28 14:43:40.232495: train_loss -0.4828 
2025-08-28 14:43:40.240876: val_loss -0.4409 
2025-08-28 14:43:40.245004: Pseudo dice [np.float32(0.6532)] 
2025-08-28 14:43:40.251572: Epoch time: 15.34 s 
2025-08-28 14:43:40.905046:  
2025-08-28 14:43:40.912175: Epoch 351 
2025-08-28 14:43:40.917517: Current learning rate: 0.00678 
2025-08-28 14:43:56.548844: train_loss -0.4885 
2025-08-28 14:43:56.557158: val_loss -0.506 
2025-08-28 14:43:56.561303: Pseudo dice [np.float32(0.6968)] 
2025-08-28 14:43:56.569312: Epoch time: 15.64 s 
2025-08-28 14:43:57.307792:  
2025-08-28 14:43:57.317996: Epoch 352 
2025-08-28 14:43:57.324503: Current learning rate: 0.00677 
2025-08-28 14:44:13.978883: train_loss -0.4395 
2025-08-28 14:44:13.987024: val_loss -0.4972 
2025-08-28 14:44:13.996053: Pseudo dice [np.float32(0.6619)] 
2025-08-28 14:44:14.000628: Epoch time: 16.67 s 
2025-08-28 14:44:14.723114:  
2025-08-28 14:44:14.730536: Epoch 353 
2025-08-28 14:44:14.737740: Current learning rate: 0.00676 
2025-08-28 14:44:31.333523: train_loss -0.4619 
2025-08-28 14:44:31.341935: val_loss -0.5342 
2025-08-28 14:44:31.346266: Pseudo dice [np.float32(0.7333)] 
2025-08-28 14:44:31.354127: Epoch time: 16.61 s 
2025-08-28 14:44:32.063301:  
2025-08-28 14:44:32.070619: Epoch 354 
2025-08-28 14:44:32.075799: Current learning rate: 0.00675 
2025-08-28 14:44:48.488146: train_loss -0.4536 
2025-08-28 14:44:48.496483: val_loss -0.3945 
2025-08-28 14:44:48.500671: Pseudo dice [np.float32(0.6588)] 
2025-08-28 14:44:48.504859: Epoch time: 16.43 s 
2025-08-28 14:44:49.382821:  
2025-08-28 14:44:49.392125: Epoch 355 
2025-08-28 14:44:49.399281: Current learning rate: 0.00674 
2025-08-28 14:45:06.322610: train_loss -0.4558 
2025-08-28 14:45:06.330946: val_loss -0.479 
2025-08-28 14:45:06.335159: Pseudo dice [np.float32(0.7424)] 
2025-08-28 14:45:06.342345: Epoch time: 16.94 s 
2025-08-28 14:45:07.049346:  
2025-08-28 14:45:07.057680: Epoch 356 
2025-08-28 14:45:07.064872: Current learning rate: 0.00673 
2025-08-28 14:45:23.619161: train_loss -0.4683 
2025-08-28 14:45:23.627935: val_loss -0.4659 
2025-08-28 14:45:23.635741: Pseudo dice [np.float32(0.7049)] 
2025-08-28 14:45:23.641993: Epoch time: 16.57 s 
2025-08-28 14:45:24.405183:  
2025-08-28 14:45:24.414579: Epoch 357 
2025-08-28 14:45:24.422861: Current learning rate: 0.00672 
2025-08-28 14:45:41.169958: train_loss -0.4713 
2025-08-28 14:45:41.177814: val_loss -0.442 
2025-08-28 14:45:41.182654: Pseudo dice [np.float32(0.6355)] 
2025-08-28 14:45:41.190325: Epoch time: 16.77 s 
2025-08-28 14:45:41.906973:  
2025-08-28 14:45:41.914410: Epoch 358 
2025-08-28 14:45:41.922824: Current learning rate: 0.00671 
2025-08-28 14:45:58.483707: train_loss -0.4264 
2025-08-28 14:45:58.491418: val_loss -0.5365 
2025-08-28 14:45:58.499413: Pseudo dice [np.float32(0.8122)] 
2025-08-28 14:45:58.503913: Epoch time: 16.58 s 
2025-08-28 14:45:58.509063: Yayy! New best EMA pseudo Dice: 0.7042999863624573 
2025-08-28 14:45:59.402637:  
2025-08-28 14:45:59.410950: Epoch 359 
2025-08-28 14:45:59.416950: Current learning rate: 0.0067 
2025-08-28 14:46:16.217667: train_loss -0.4724 
2025-08-28 14:46:16.225751: val_loss -0.4457 
2025-08-28 14:46:16.230163: Pseudo dice [np.float32(0.6747)] 
2025-08-28 14:46:16.236974: Epoch time: 16.82 s 
2025-08-28 14:46:16.936875:  
2025-08-28 14:46:16.944227: Epoch 360 
2025-08-28 14:46:16.949419: Current learning rate: 0.00669 
2025-08-28 14:46:32.796421: train_loss -0.4457 
2025-08-28 14:46:32.804789: val_loss -0.4475 
2025-08-28 14:46:32.813131: Pseudo dice [np.float32(0.689)] 
2025-08-28 14:46:32.819711: Epoch time: 15.86 s 
2025-08-28 14:46:33.624290:  
2025-08-28 14:46:33.633663: Epoch 361 
2025-08-28 14:46:33.638782: Current learning rate: 0.00668 
2025-08-28 14:46:49.041818: train_loss -0.4594 
2025-08-28 14:46:49.046243: val_loss -0.5631 
2025-08-28 14:46:49.054338: Pseudo dice [np.float32(0.7089)] 
2025-08-28 14:46:49.059597: Epoch time: 15.42 s 
2025-08-28 14:46:49.710216:  
2025-08-28 14:46:49.718572: Epoch 362 
2025-08-28 14:46:49.723743: Current learning rate: 0.00667 
2025-08-28 14:47:04.453045: train_loss -0.4851 
2025-08-28 14:47:04.461398: val_loss -0.55 
2025-08-28 14:47:04.465544: Pseudo dice [np.float32(0.7494)] 
2025-08-28 14:47:04.472776: Epoch time: 14.74 s 
2025-08-28 14:47:04.478040: Yayy! New best EMA pseudo Dice: 0.7057999968528748 
2025-08-28 14:47:05.322642:  
2025-08-28 14:47:05.329973: Epoch 363 
2025-08-28 14:47:05.336089: Current learning rate: 0.00666 
2025-08-28 14:47:20.852691: train_loss -0.5167 
2025-08-28 14:47:20.861078: val_loss -0.4667 
2025-08-28 14:47:20.869420: Pseudo dice [np.float32(0.6935)] 
2025-08-28 14:47:20.874079: Epoch time: 15.53 s 
2025-08-28 14:47:21.528280:  
2025-08-28 14:47:21.535593: Epoch 364 
2025-08-28 14:47:21.540833: Current learning rate: 0.00665 
2025-08-28 14:47:36.973337: train_loss -0.5062 
2025-08-28 14:47:36.981411: val_loss -0.4854 
2025-08-28 14:47:36.985527: Pseudo dice [np.float32(0.7274)] 
2025-08-28 14:47:36.992678: Epoch time: 15.45 s 
2025-08-28 14:47:36.998619: Yayy! New best EMA pseudo Dice: 0.7069000005722046 
2025-08-28 14:47:37.829043:  
2025-08-28 14:47:37.839575: Epoch 365 
2025-08-28 14:47:37.845754: Current learning rate: 0.00665 
2025-08-28 14:47:52.859703: train_loss -0.4172 
2025-08-28 14:47:52.868047: val_loss -0.4461 
2025-08-28 14:47:52.872341: Pseudo dice [np.float32(0.6883)] 
2025-08-28 14:47:52.880417: Epoch time: 15.03 s 
2025-08-28 14:47:53.538386:  
2025-08-28 14:47:53.545723: Epoch 366 
2025-08-28 14:47:53.550986: Current learning rate: 0.00664 
2025-08-28 14:48:08.458803: train_loss -0.474 
2025-08-28 14:48:08.466950: val_loss -0.3829 
2025-08-28 14:48:08.471147: Pseudo dice [np.float32(0.5627)] 
2025-08-28 14:48:08.478819: Epoch time: 14.92 s 
2025-08-28 14:48:09.294876:  
2025-08-28 14:48:09.303192: Epoch 367 
2025-08-28 14:48:09.310318: Current learning rate: 0.00663 
2025-08-28 14:48:24.487087: train_loss -0.4972 
2025-08-28 14:48:24.495989: val_loss -0.461 
2025-08-28 14:48:24.499639: Pseudo dice [np.float32(0.6756)] 
2025-08-28 14:48:24.505854: Epoch time: 15.19 s 
2025-08-28 14:48:25.173148:  
2025-08-28 14:48:25.180568: Epoch 368 
2025-08-28 14:48:25.185713: Current learning rate: 0.00662 
2025-08-28 14:48:40.590723: train_loss -0.4645 
2025-08-28 14:48:40.599038: val_loss -0.5022 
2025-08-28 14:48:40.603448: Pseudo dice [np.float32(0.7485)] 
2025-08-28 14:48:40.608473: Epoch time: 15.42 s 
2025-08-28 14:48:41.268373:  
2025-08-28 14:48:41.276729: Epoch 369 
2025-08-28 14:48:41.281896: Current learning rate: 0.00661 
2025-08-28 14:48:56.235678: train_loss -0.489 
2025-08-28 14:48:56.243859: val_loss -0.4433 
2025-08-28 14:48:56.248264: Pseudo dice [np.float32(0.6921)] 
2025-08-28 14:48:56.254287: Epoch time: 14.97 s 
2025-08-28 14:48:56.909998:  
2025-08-28 14:48:56.917356: Epoch 370 
2025-08-28 14:48:56.922519: Current learning rate: 0.0066 
2025-08-28 14:49:12.631244: train_loss -0.4586 
2025-08-28 14:49:12.639354: val_loss -0.4743 
2025-08-28 14:49:12.647714: Pseudo dice [np.float32(0.7309)] 
2025-08-28 14:49:12.652932: Epoch time: 15.72 s 
2025-08-28 14:49:13.326389:  
2025-08-28 14:49:13.334720: Epoch 371 
2025-08-28 14:49:13.339890: Current learning rate: 0.00659 
2025-08-28 14:49:28.751456: train_loss -0.4685 
2025-08-28 14:49:28.759941: val_loss -0.4858 
2025-08-28 14:49:28.764002: Pseudo dice [np.float32(0.7258)] 
2025-08-28 14:49:28.772587: Epoch time: 15.43 s 
2025-08-28 14:49:29.439308:  
2025-08-28 14:49:29.447738: Epoch 372 
2025-08-28 14:49:29.453985: Current learning rate: 0.00658 
2025-08-28 14:49:44.321250: train_loss -0.5008 
2025-08-28 14:49:44.329329: val_loss -0.4354 
2025-08-28 14:49:44.333741: Pseudo dice [np.float32(0.696)] 
2025-08-28 14:49:44.341460: Epoch time: 14.88 s 
2025-08-28 14:49:45.000711:  
2025-08-28 14:49:45.009095: Epoch 373 
2025-08-28 14:49:45.016549: Current learning rate: 0.00657 
2025-08-28 14:50:00.245204: train_loss -0.4733 
2025-08-28 14:50:00.253553: val_loss -0.5453 
2025-08-28 14:50:00.257749: Pseudo dice [np.float32(0.7723)] 
2025-08-28 14:50:00.266116: Epoch time: 15.25 s 
2025-08-28 14:50:00.270568: Yayy! New best EMA pseudo Dice: 0.7078999876976013 
2025-08-28 14:50:01.281679:  
2025-08-28 14:50:01.291158: Epoch 374 
2025-08-28 14:50:01.297296: Current learning rate: 0.00656 
2025-08-28 14:50:16.395098: train_loss -0.5052 
2025-08-28 14:50:16.403020: val_loss -0.5001 
2025-08-28 14:50:16.411671: Pseudo dice [np.float32(0.7305)] 
2025-08-28 14:50:16.416629: Epoch time: 15.12 s 
2025-08-28 14:50:16.422698: Yayy! New best EMA pseudo Dice: 0.710099995136261 
2025-08-28 14:50:17.256927:  
2025-08-28 14:50:17.264281: Epoch 375 
2025-08-28 14:50:17.270367: Current learning rate: 0.00655 
2025-08-28 14:50:32.589619: train_loss -0.4607 
2025-08-28 14:50:32.594183: val_loss -0.4415 
2025-08-28 14:50:32.602544: Pseudo dice [np.float32(0.6256)] 
2025-08-28 14:50:32.606779: Epoch time: 15.33 s 
2025-08-28 14:50:33.335744:  
2025-08-28 14:50:33.345427: Epoch 376 
2025-08-28 14:50:33.352683: Current learning rate: 0.00654 
2025-08-28 14:50:50.186895: train_loss -0.5481 
2025-08-28 14:50:50.195352: val_loss -0.389 
2025-08-28 14:50:50.199264: Pseudo dice [np.float32(0.6271)] 
2025-08-28 14:50:50.207878: Epoch time: 16.85 s 
2025-08-28 14:50:50.918777:  
2025-08-28 14:50:50.926039: Epoch 377 
2025-08-28 14:50:50.931216: Current learning rate: 0.00653 
2025-08-28 14:51:07.737622: train_loss -0.5273 
2025-08-28 14:51:07.745946: val_loss -0.5265 
2025-08-28 14:51:07.754292: Pseudo dice [np.float32(0.6463)] 
2025-08-28 14:51:07.758470: Epoch time: 16.82 s 
2025-08-28 14:51:08.475698:  
2025-08-28 14:51:08.484045: Epoch 378 
2025-08-28 14:51:08.490568: Current learning rate: 0.00652 
2025-08-28 14:51:25.188864: train_loss -0.4894 
2025-08-28 14:51:25.196748: val_loss -0.3553 
2025-08-28 14:51:25.200853: Pseudo dice [np.float32(0.6148)] 
2025-08-28 14:51:25.208620: Epoch time: 16.72 s 
2025-08-28 14:51:25.911911:  
2025-08-28 14:51:25.919275: Epoch 379 
2025-08-28 14:51:25.925429: Current learning rate: 0.00651 
2025-08-28 14:51:42.530662: train_loss -0.4879 
2025-08-28 14:51:42.539006: val_loss -0.4031 
2025-08-28 14:51:42.543188: Pseudo dice [np.float32(0.662)] 
2025-08-28 14:51:42.549427: Epoch time: 16.62 s 
2025-08-28 14:51:43.457644:  
2025-08-28 14:51:43.467012: Epoch 380 
2025-08-28 14:51:43.477434: Current learning rate: 0.0065 
2025-08-28 14:52:00.061414: train_loss -0.5359 
2025-08-28 14:52:00.069330: val_loss -0.5161 
2025-08-28 14:52:00.077396: Pseudo dice [np.float32(0.7413)] 
2025-08-28 14:52:00.082647: Epoch time: 16.6 s 
2025-08-28 14:52:00.798858:  
2025-08-28 14:52:00.808379: Epoch 381 
2025-08-28 14:52:00.818119: Current learning rate: 0.00649 
2025-08-28 14:52:17.444951: train_loss -0.4729 
2025-08-28 14:52:17.457312: val_loss -0.5415 
2025-08-28 14:52:17.461409: Pseudo dice [np.float32(0.736)] 
2025-08-28 14:52:17.468738: Epoch time: 16.65 s 
2025-08-28 14:52:18.186938:  
2025-08-28 14:52:18.195361: Epoch 382 
2025-08-28 14:52:18.204587: Current learning rate: 0.00648 
2025-08-28 14:52:34.666043: train_loss -0.4947 
2025-08-28 14:52:34.674609: val_loss -0.4351 
2025-08-28 14:52:34.678575: Pseudo dice [np.float32(0.6558)] 
2025-08-28 14:52:34.686665: Epoch time: 16.48 s 
2025-08-28 14:52:35.399990:  
2025-08-28 14:52:35.407382: Epoch 383 
2025-08-28 14:52:35.413663: Current learning rate: 0.00648 
2025-08-28 14:52:51.795729: train_loss -0.4639 
2025-08-28 14:52:51.803880: val_loss -0.4776 
2025-08-28 14:52:51.809241: Pseudo dice [np.float32(0.7009)] 
2025-08-28 14:52:51.815135: Epoch time: 16.4 s 
2025-08-28 14:52:52.498361:  
2025-08-28 14:52:52.506702: Epoch 384 
2025-08-28 14:52:52.512929: Current learning rate: 0.00647 
2025-08-28 14:53:07.753396: train_loss -0.4805 
2025-08-28 14:53:07.761576: val_loss -0.4435 
2025-08-28 14:53:07.765741: Pseudo dice [np.float32(0.615)] 
2025-08-28 14:53:07.774129: Epoch time: 15.26 s 
2025-08-28 14:53:08.435273:  
2025-08-28 14:53:08.443548: Epoch 385 
2025-08-28 14:53:08.450811: Current learning rate: 0.00646 
2025-08-28 14:53:22.388753: train_loss -0.4772 
2025-08-28 14:53:22.397027: val_loss -0.4549 
2025-08-28 14:53:22.401519: Pseudo dice [np.float32(0.6937)] 
2025-08-28 14:53:22.410047: Epoch time: 13.96 s 
2025-08-28 14:53:23.221710:  
2025-08-28 14:53:23.230038: Epoch 386 
2025-08-28 14:53:23.235222: Current learning rate: 0.00645 
2025-08-28 14:53:37.104450: train_loss -0.4379 
2025-08-28 14:53:37.111745: val_loss -0.4096 
2025-08-28 14:53:37.115899: Pseudo dice [np.float32(0.6646)] 
2025-08-28 14:53:37.123565: Epoch time: 13.88 s 
2025-08-28 14:53:37.793608:  
2025-08-28 14:53:37.801445: Epoch 387 
2025-08-28 14:53:37.807088: Current learning rate: 0.00644 
2025-08-28 14:53:51.810042: train_loss -0.5071 
2025-08-28 14:53:51.818048: val_loss -0.5576 
2025-08-28 14:53:51.822448: Pseudo dice [np.float32(0.7595)] 
2025-08-28 14:53:51.831025: Epoch time: 14.02 s 
2025-08-28 14:53:52.488476:  
2025-08-28 14:53:52.494881: Epoch 388 
2025-08-28 14:53:52.501001: Current learning rate: 0.00643 
2025-08-28 14:54:06.495327: train_loss -0.4803 
2025-08-28 14:54:06.503570: val_loss -0.466 
2025-08-28 14:54:06.507744: Pseudo dice [np.float32(0.7084)] 
2025-08-28 14:54:06.514879: Epoch time: 14.01 s 
2025-08-28 14:54:07.172950:  
2025-08-28 14:54:07.180262: Epoch 389 
2025-08-28 14:54:07.186455: Current learning rate: 0.00642 
2025-08-28 14:54:21.172503: train_loss -0.5029 
2025-08-28 14:54:21.180724: val_loss -0.5305 
2025-08-28 14:54:21.189045: Pseudo dice [np.float32(0.7418)] 
2025-08-28 14:54:21.194351: Epoch time: 14.0 s 
2025-08-28 14:54:21.890874:  
2025-08-28 14:54:21.901168: Epoch 390 
2025-08-28 14:54:21.909168: Current learning rate: 0.00641 
2025-08-28 14:54:35.862332: train_loss -0.4766 
2025-08-28 14:54:35.870618: val_loss -0.4653 
2025-08-28 14:54:35.874905: Pseudo dice [np.float32(0.7041)] 
2025-08-28 14:54:35.881228: Epoch time: 13.97 s 
2025-08-28 14:54:36.678129:  
2025-08-28 14:54:36.686794: Epoch 391 
2025-08-28 14:54:36.693079: Current learning rate: 0.0064 
2025-08-28 14:54:50.801845: train_loss -0.4823 
2025-08-28 14:54:50.806130: val_loss -0.4215 
2025-08-28 14:54:50.814471: Pseudo dice [np.float32(0.6683)] 
2025-08-28 14:54:50.820751: Epoch time: 14.13 s 
2025-08-28 14:54:51.471346:  
2025-08-28 14:54:51.478726: Epoch 392 
2025-08-28 14:54:51.484860: Current learning rate: 0.00639 
2025-08-28 14:55:05.863045: train_loss -0.5106 
2025-08-28 14:55:05.871185: val_loss -0.4756 
2025-08-28 14:55:05.879581: Pseudo dice [np.float32(0.7305)] 
2025-08-28 14:55:05.884789: Epoch time: 14.39 s 
2025-08-28 14:55:06.546695:  
2025-08-28 14:55:06.554119: Epoch 393 
2025-08-28 14:55:06.560386: Current learning rate: 0.00638 
2025-08-28 14:55:22.104297: train_loss -0.5074 
2025-08-28 14:55:22.112389: val_loss -0.4847 
2025-08-28 14:55:22.121376: Pseudo dice [np.float32(0.7438)] 
2025-08-28 14:55:22.126987: Epoch time: 15.56 s 
2025-08-28 14:55:22.781785:  
2025-08-28 14:55:22.790123: Epoch 394 
2025-08-28 14:55:22.795256: Current learning rate: 0.00637 
2025-08-28 14:55:37.531941: train_loss -0.5087 
2025-08-28 14:55:37.540282: val_loss -0.4748 
2025-08-28 14:55:37.548668: Pseudo dice [np.float32(0.7517)] 
2025-08-28 14:55:37.553893: Epoch time: 14.75 s 
2025-08-28 14:55:38.211624:  
2025-08-28 14:55:38.218992: Epoch 395 
2025-08-28 14:55:38.224221: Current learning rate: 0.00636 
2025-08-28 14:55:53.773866: train_loss -0.5053 
2025-08-28 14:55:53.781567: val_loss -0.4893 
2025-08-28 14:55:53.785701: Pseudo dice [np.float32(0.7147)] 
2025-08-28 14:55:53.793405: Epoch time: 15.56 s 
2025-08-28 14:55:54.459278:  
2025-08-28 14:55:54.467532: Epoch 396 
2025-08-28 14:55:54.473712: Current learning rate: 0.00635 
2025-08-28 14:56:09.855951: train_loss -0.5111 
2025-08-28 14:56:09.864233: val_loss -0.4583 
2025-08-28 14:56:09.868412: Pseudo dice [np.float32(0.6521)] 
2025-08-28 14:56:09.875225: Epoch time: 15.4 s 
2025-08-28 14:56:10.545119:  
2025-08-28 14:56:10.557721: Epoch 397 
2025-08-28 14:56:10.570149: Current learning rate: 0.00634 
2025-08-28 14:56:25.621670: train_loss -0.485 
2025-08-28 14:56:25.630139: val_loss -0.5613 
2025-08-28 14:56:25.634176: Pseudo dice [np.float32(0.7982)] 
2025-08-28 14:56:25.641131: Epoch time: 15.08 s 
2025-08-28 14:56:25.647120: Yayy! New best EMA pseudo Dice: 0.711899995803833 
2025-08-28 14:56:26.672529:  
2025-08-28 14:56:26.680879: Epoch 398 
2025-08-28 14:56:26.688325: Current learning rate: 0.00633 
2025-08-28 14:56:41.258251: train_loss -0.4927 
2025-08-28 14:56:41.266429: val_loss -0.5535 
2025-08-28 14:56:41.270580: Pseudo dice [np.float32(0.7962)] 
2025-08-28 14:56:41.277976: Epoch time: 14.59 s 
2025-08-28 14:56:41.283576: Yayy! New best EMA pseudo Dice: 0.720300018787384 
2025-08-28 14:56:42.112979:  
2025-08-28 14:56:42.122285: Epoch 399 
2025-08-28 14:56:42.129036: Current learning rate: 0.00632 
2025-08-28 14:56:57.670284: train_loss -0.4963 
2025-08-28 14:56:57.678853: val_loss -0.5512 
2025-08-28 14:56:57.682802: Pseudo dice [np.float32(0.6831)] 
2025-08-28 14:56:57.689464: Epoch time: 15.56 s 
2025-08-28 14:56:58.531477:  
2025-08-28 14:56:58.539856: Epoch 400 
2025-08-28 14:56:58.545057: Current learning rate: 0.00631 
2025-08-28 14:57:13.807449: train_loss -0.4901 
2025-08-28 14:57:13.819730: val_loss -0.39 
2025-08-28 14:57:13.823922: Pseudo dice [np.float32(0.6466)] 
2025-08-28 14:57:13.830864: Epoch time: 15.28 s 
2025-08-28 14:57:14.490082:  
2025-08-28 14:57:14.498432: Epoch 401 
2025-08-28 14:57:14.507939: Current learning rate: 0.0063 
2025-08-28 14:57:30.256998: train_loss -0.504 
2025-08-28 14:57:30.265332: val_loss -0.5515 
2025-08-28 14:57:30.269509: Pseudo dice [np.float32(0.7794)] 
2025-08-28 14:57:30.276660: Epoch time: 15.77 s 
2025-08-28 14:57:30.979577:  
2025-08-28 14:57:30.988935: Epoch 402 
2025-08-28 14:57:30.998236: Current learning rate: 0.0063 
2025-08-28 14:57:47.599732: train_loss -0.4519 
2025-08-28 14:57:47.607649: val_loss -0.468 
2025-08-28 14:57:47.611842: Pseudo dice [np.float32(0.6112)] 
2025-08-28 14:57:47.619779: Epoch time: 16.62 s 
2025-08-28 14:57:48.491884:  
2025-08-28 14:57:48.503204: Epoch 403 
2025-08-28 14:57:48.510943: Current learning rate: 0.00629 
2025-08-28 14:58:05.020858: train_loss -0.487 
2025-08-28 14:58:05.029211: val_loss -0.519 
2025-08-28 14:58:05.033368: Pseudo dice [np.float32(0.7618)] 
2025-08-28 14:58:05.040811: Epoch time: 16.53 s 
2025-08-28 14:58:05.772625:  
2025-08-28 14:58:05.781016: Epoch 404 
2025-08-28 14:58:05.789499: Current learning rate: 0.00628 
2025-08-28 14:58:22.458946: train_loss -0.4875 
2025-08-28 14:58:22.467491: val_loss -0.4631 
2025-08-28 14:58:22.471624: Pseudo dice [np.float32(0.6965)] 
2025-08-28 14:58:22.479549: Epoch time: 16.68 s 
2025-08-28 14:58:23.232057:  
2025-08-28 14:58:23.241101: Epoch 405 
2025-08-28 14:58:23.246504: Current learning rate: 0.00627 
2025-08-28 14:58:39.588697: train_loss -0.4924 
2025-08-28 14:58:39.597069: val_loss -0.4369 
2025-08-28 14:58:39.601230: Pseudo dice [np.float32(0.7081)] 
2025-08-28 14:58:39.608487: Epoch time: 16.36 s 
2025-08-28 14:58:40.314318:  
2025-08-28 14:58:40.321640: Epoch 406 
2025-08-28 14:58:40.327110: Current learning rate: 0.00626 
2025-08-28 14:58:56.718466: train_loss -0.5071 
2025-08-28 14:58:56.726706: val_loss -0.4642 
2025-08-28 14:58:56.730850: Pseudo dice [np.float32(0.6825)] 
2025-08-28 14:58:56.736151: Epoch time: 16.41 s 
2025-08-28 14:58:57.467002:  
2025-08-28 14:58:57.477289: Epoch 407 
2025-08-28 14:58:57.485682: Current learning rate: 0.00625 
2025-08-28 14:59:14.310859: train_loss -0.5393 
2025-08-28 14:59:14.323399: val_loss -0.5507 
2025-08-28 14:59:14.327565: Pseudo dice [np.float32(0.7645)] 
2025-08-28 14:59:14.334591: Epoch time: 16.85 s 
2025-08-28 14:59:15.084561:  
2025-08-28 14:59:15.093250: Epoch 408 
2025-08-28 14:59:15.101983: Current learning rate: 0.00624 
2025-08-28 14:59:31.640656: train_loss -0.4791 
2025-08-28 14:59:31.644836: val_loss -0.4794 
2025-08-28 14:59:31.653190: Pseudo dice [np.float32(0.6832)] 
2025-08-28 14:59:31.658441: Epoch time: 16.56 s 
2025-08-28 14:59:32.382013:  
2025-08-28 14:59:32.389274: Epoch 409 
2025-08-28 14:59:32.395481: Current learning rate: 0.00623 
2025-08-28 14:59:48.795673: train_loss -0.4433 
2025-08-28 14:59:48.803377: val_loss -0.5242 
2025-08-28 14:59:48.808063: Pseudo dice [np.float32(0.7342)] 
2025-08-28 14:59:48.813059: Epoch time: 16.42 s 
2025-08-28 14:59:49.691894:  
2025-08-28 14:59:49.700554: Epoch 410 
2025-08-28 14:59:49.708706: Current learning rate: 0.00622 
2025-08-28 15:00:05.858539: train_loss -0.4722 
2025-08-28 15:00:05.868247: val_loss -0.5272 
2025-08-28 15:00:05.874849: Pseudo dice [np.float32(0.7751)] 
2025-08-28 15:00:05.880108: Epoch time: 16.17 s 
2025-08-28 15:00:06.581899:  
2025-08-28 15:00:06.592127: Epoch 411 
2025-08-28 15:00:06.600521: Current learning rate: 0.00621 
2025-08-28 15:00:23.709640: train_loss -0.4869 
2025-08-28 15:00:23.717678: val_loss -0.4932 
2025-08-28 15:00:23.726014: Pseudo dice [np.float32(0.7382)] 
2025-08-28 15:00:23.731258: Epoch time: 17.13 s 
2025-08-28 15:00:23.735013: Yayy! New best EMA pseudo Dice: 0.7206000089645386 
2025-08-28 15:00:24.621395:  
2025-08-28 15:00:24.632447: Epoch 412 
2025-08-28 15:00:24.640413: Current learning rate: 0.0062 
2025-08-28 15:00:41.026571: train_loss -0.4546 
2025-08-28 15:00:41.035011: val_loss -0.4875 
2025-08-28 15:00:41.039327: Pseudo dice [np.float32(0.7059)] 
2025-08-28 15:00:41.045475: Epoch time: 16.41 s 
2025-08-28 15:00:41.743044:  
2025-08-28 15:00:41.753996: Epoch 413 
2025-08-28 15:00:41.760608: Current learning rate: 0.00619 
2025-08-28 15:00:58.431556: train_loss -0.5208 
2025-08-28 15:00:58.440205: val_loss -0.4826 
2025-08-28 15:00:58.444019: Pseudo dice [np.float32(0.739)] 
2025-08-28 15:00:58.451101: Epoch time: 16.69 s 
2025-08-28 15:00:58.457162: Yayy! New best EMA pseudo Dice: 0.7210999727249146 
2025-08-28 15:00:59.354375:  
2025-08-28 15:00:59.364036: Epoch 414 
2025-08-28 15:00:59.371000: Current learning rate: 0.00618 
2025-08-28 15:01:15.215154: train_loss -0.4925 
2025-08-28 15:01:15.223243: val_loss -0.4781 
2025-08-28 15:01:15.227446: Pseudo dice [np.float32(0.6971)] 
2025-08-28 15:01:15.233700: Epoch time: 15.86 s 
2025-08-28 15:01:15.932144:  
2025-08-28 15:01:15.939566: Epoch 415 
2025-08-28 15:01:15.946867: Current learning rate: 0.00617 
2025-08-28 15:01:32.069246: train_loss -0.508 
2025-08-28 15:01:32.077850: val_loss -0.4795 
2025-08-28 15:01:32.081969: Pseudo dice [np.float32(0.6996)] 
2025-08-28 15:01:32.090069: Epoch time: 16.14 s 
2025-08-28 15:01:32.980509:  
2025-08-28 15:01:32.987996: Epoch 416 
2025-08-28 15:01:32.993999: Current learning rate: 0.00616 
2025-08-28 15:01:48.998645: train_loss -0.5257 
2025-08-28 15:01:49.006989: val_loss -0.5098 
2025-08-28 15:01:49.011138: Pseudo dice [np.float32(0.7524)] 
2025-08-28 15:01:49.019111: Epoch time: 16.02 s 
2025-08-28 15:01:49.730634:  
2025-08-28 15:01:49.739881: Epoch 417 
2025-08-28 15:01:49.747425: Current learning rate: 0.00615 
2025-08-28 15:02:05.627993: train_loss -0.4921 
2025-08-28 15:02:05.636125: val_loss -0.4611 
2025-08-28 15:02:05.640249: Pseudo dice [np.float32(0.7407)] 
2025-08-28 15:02:05.647555: Epoch time: 15.9 s 
2025-08-28 15:02:05.652779: Yayy! New best EMA pseudo Dice: 0.7224000096321106 
2025-08-28 15:02:06.534645:  
2025-08-28 15:02:06.543254: Epoch 418 
2025-08-28 15:02:06.552084: Current learning rate: 0.00614 
2025-08-28 15:02:22.519598: train_loss -0.4932 
2025-08-28 15:02:22.528201: val_loss -0.5598 
2025-08-28 15:02:22.532187: Pseudo dice [np.float32(0.6922)] 
2025-08-28 15:02:22.539105: Epoch time: 15.99 s 
2025-08-28 15:02:23.254712:  
2025-08-28 15:02:23.263793: Epoch 419 
2025-08-28 15:02:23.270295: Current learning rate: 0.00613 
2025-08-28 15:02:39.361717: train_loss -0.4899 
2025-08-28 15:02:39.369838: val_loss -0.524 
2025-08-28 15:02:39.374170: Pseudo dice [np.float32(0.7561)] 
2025-08-28 15:02:39.380580: Epoch time: 16.11 s 
2025-08-28 15:02:39.386421: Yayy! New best EMA pseudo Dice: 0.7229999899864197 
2025-08-28 15:02:40.302894:  
2025-08-28 15:02:40.310596: Epoch 420 
2025-08-28 15:02:40.321833: Current learning rate: 0.00612 
2025-08-28 15:02:56.358202: train_loss -0.5108 
2025-08-28 15:02:56.365902: val_loss -0.5203 
2025-08-28 15:02:56.374546: Pseudo dice [np.float32(0.7009)] 
2025-08-28 15:02:56.380515: Epoch time: 16.06 s 
2025-08-28 15:02:57.087265:  
2025-08-28 15:02:57.095677: Epoch 421 
2025-08-28 15:02:57.101677: Current learning rate: 0.00612 
2025-08-28 15:03:12.832713: train_loss -0.5169 
2025-08-28 15:03:12.840675: val_loss -0.5009 
2025-08-28 15:03:12.849423: Pseudo dice [np.float32(0.6651)] 
2025-08-28 15:03:12.854373: Epoch time: 15.75 s 
2025-08-28 15:03:13.703946:  
2025-08-28 15:03:13.712296: Epoch 422 
2025-08-28 15:03:13.721744: Current learning rate: 0.00611 
2025-08-28 15:03:29.524433: train_loss -0.4982 
2025-08-28 15:03:29.532368: val_loss -0.5363 
2025-08-28 15:03:29.536565: Pseudo dice [np.float32(0.7279)] 
2025-08-28 15:03:29.544866: Epoch time: 15.82 s 
2025-08-28 15:03:30.255977:  
2025-08-28 15:03:30.267649: Epoch 423 
2025-08-28 15:03:30.275602: Current learning rate: 0.0061 
2025-08-28 15:03:45.769421: train_loss -0.5329 
2025-08-28 15:03:45.773589: val_loss -0.4332 
2025-08-28 15:03:45.781931: Pseudo dice [np.float32(0.7146)] 
2025-08-28 15:03:45.787179: Epoch time: 15.52 s 
2025-08-28 15:03:46.489425:  
2025-08-28 15:03:46.499241: Epoch 424 
2025-08-28 15:03:46.509025: Current learning rate: 0.00609 
2025-08-28 15:04:02.168589: train_loss -0.5014 
2025-08-28 15:04:02.173595: val_loss -0.5333 
2025-08-28 15:04:02.181626: Pseudo dice [np.float32(0.7397)] 
2025-08-28 15:04:02.186908: Epoch time: 15.68 s 
2025-08-28 15:04:02.897870:  
2025-08-28 15:04:02.908324: Epoch 425 
2025-08-28 15:04:02.914757: Current learning rate: 0.00608 
2025-08-28 15:04:18.369289: train_loss -0.4738 
2025-08-28 15:04:18.376960: val_loss -0.3786 
2025-08-28 15:04:18.385310: Pseudo dice [np.float32(0.664)] 
2025-08-28 15:04:18.390543: Epoch time: 15.47 s 
2025-08-28 15:04:19.093278:  
2025-08-28 15:04:19.104614: Epoch 426 
2025-08-28 15:04:19.114005: Current learning rate: 0.00607 
2025-08-28 15:04:34.735061: train_loss -0.4809 
2025-08-28 15:04:34.743294: val_loss -0.5032 
2025-08-28 15:04:34.747454: Pseudo dice [np.float32(0.712)] 
2025-08-28 15:04:34.754172: Epoch time: 15.64 s 
2025-08-28 15:04:35.457830:  
2025-08-28 15:04:35.465443: Epoch 427 
2025-08-28 15:04:35.474380: Current learning rate: 0.00606 
2025-08-28 15:04:50.904953: train_loss -0.5184 
2025-08-28 15:04:50.909426: val_loss -0.4789 
2025-08-28 15:04:50.917772: Pseudo dice [np.float32(0.636)] 
2025-08-28 15:04:50.921829: Epoch time: 15.45 s 
2025-08-28 15:04:51.640342:  
2025-08-28 15:04:51.649753: Epoch 428 
2025-08-28 15:04:51.656018: Current learning rate: 0.00605 
2025-08-28 15:05:07.150672: train_loss -0.5467 
2025-08-28 15:05:07.158983: val_loss -0.4861 
2025-08-28 15:05:07.163167: Pseudo dice [np.float32(0.7379)] 
2025-08-28 15:05:07.168445: Epoch time: 15.51 s 
2025-08-28 15:05:08.054604:  
2025-08-28 15:05:08.062350: Epoch 429 
2025-08-28 15:05:08.070177: Current learning rate: 0.00604 
2025-08-28 15:05:23.479683: train_loss -0.4748 
2025-08-28 15:05:23.488009: val_loss -0.473 
2025-08-28 15:05:23.491981: Pseudo dice [np.float32(0.692)] 
2025-08-28 15:05:23.499834: Epoch time: 15.43 s 
2025-08-28 15:05:24.197849:  
2025-08-28 15:05:24.206202: Epoch 430 
2025-08-28 15:05:24.213995: Current learning rate: 0.00603 
2025-08-28 15:05:39.604392: train_loss -0.525 
2025-08-28 15:05:39.612826: val_loss -0.4921 
2025-08-28 15:05:39.620978: Pseudo dice [np.float32(0.781)] 
2025-08-28 15:05:39.626850: Epoch time: 15.41 s 
2025-08-28 15:05:40.335645:  
2025-08-28 15:05:40.343120: Epoch 431 
2025-08-28 15:05:40.350274: Current learning rate: 0.00602 
2025-08-28 15:05:55.953450: train_loss -0.4717 
2025-08-28 15:05:55.957787: val_loss -0.4972 
2025-08-28 15:05:55.966061: Pseudo dice [np.float32(0.6514)] 
2025-08-28 15:05:55.971283: Epoch time: 15.62 s 
2025-08-28 15:05:56.677238:  
2025-08-28 15:05:56.685533: Epoch 432 
2025-08-28 15:05:56.692161: Current learning rate: 0.00601 
2025-08-28 15:06:12.011829: train_loss -0.4819 
2025-08-28 15:06:12.023775: val_loss -0.4352 
2025-08-28 15:06:12.027935: Pseudo dice [np.float32(0.6309)] 
2025-08-28 15:06:12.033178: Epoch time: 15.34 s 
2025-08-28 15:06:12.732633:  
2025-08-28 15:06:12.742125: Epoch 433 
2025-08-28 15:06:12.748288: Current learning rate: 0.006 
2025-08-28 15:06:28.348443: train_loss -0.4691 
2025-08-28 15:06:28.356752: val_loss -0.3921 
2025-08-28 15:06:28.360913: Pseudo dice [np.float32(0.5959)] 
2025-08-28 15:06:28.368175: Epoch time: 15.62 s 
2025-08-28 15:06:29.073921:  
2025-08-28 15:06:29.082407: Epoch 434 
2025-08-28 15:06:29.090753: Current learning rate: 0.00599 
2025-08-28 15:06:44.485644: train_loss -0.466 
2025-08-28 15:06:44.493668: val_loss -0.3785 
2025-08-28 15:06:44.501649: Pseudo dice [np.float32(0.587)] 
2025-08-28 15:06:44.506555: Epoch time: 15.41 s 
2025-08-28 15:06:45.226110:  
2025-08-28 15:06:45.233017: Epoch 435 
2025-08-28 15:06:45.240220: Current learning rate: 0.00598 
2025-08-28 15:07:00.835505: train_loss -0.4831 
2025-08-28 15:07:00.843321: val_loss -0.513 
2025-08-28 15:07:00.852024: Pseudo dice [np.float32(0.7267)] 
2025-08-28 15:07:00.856944: Epoch time: 15.61 s 
2025-08-28 15:07:01.716036:  
2025-08-28 15:07:01.724393: Epoch 436 
2025-08-28 15:07:01.731393: Current learning rate: 0.00597 
2025-08-28 15:07:17.076812: train_loss -0.5227 
2025-08-28 15:07:17.084534: val_loss -0.4958 
2025-08-28 15:07:17.092915: Pseudo dice [np.float32(0.6898)] 
2025-08-28 15:07:17.098175: Epoch time: 15.36 s 
2025-08-28 15:07:17.812623:  
2025-08-28 15:07:17.821034: Epoch 437 
2025-08-28 15:07:17.826828: Current learning rate: 0.00596 
2025-08-28 15:07:33.271550: train_loss -0.4913 
2025-08-28 15:07:33.279886: val_loss -0.5314 
2025-08-28 15:07:33.284024: Pseudo dice [np.float32(0.7633)] 
2025-08-28 15:07:33.291859: Epoch time: 15.46 s 
2025-08-28 15:07:34.008799:  
2025-08-28 15:07:34.018006: Epoch 438 
2025-08-28 15:07:34.024768: Current learning rate: 0.00595 
2025-08-28 15:07:49.358626: train_loss -0.5386 
2025-08-28 15:07:49.366794: val_loss -0.5318 
2025-08-28 15:07:49.375465: Pseudo dice [np.float32(0.7241)] 
2025-08-28 15:07:49.381373: Epoch time: 15.35 s 
2025-08-28 15:07:50.071613:  
2025-08-28 15:07:50.082159: Epoch 439 
2025-08-28 15:07:50.090731: Current learning rate: 0.00594 
2025-08-28 15:08:05.749779: train_loss -0.5176 
2025-08-28 15:08:05.758442: val_loss -0.5372 
2025-08-28 15:08:05.762585: Pseudo dice [np.float32(0.7602)] 
2025-08-28 15:08:05.769621: Epoch time: 15.68 s 
2025-08-28 15:08:06.491623:  
2025-08-28 15:08:06.502722: Epoch 440 
2025-08-28 15:08:06.510883: Current learning rate: 0.00593 
2025-08-28 15:08:22.086681: train_loss -0.4772 
2025-08-28 15:08:22.095276: val_loss -0.5401 
2025-08-28 15:08:22.099466: Pseudo dice [np.float32(0.7234)] 
2025-08-28 15:08:22.105749: Epoch time: 15.6 s 
2025-08-28 15:08:22.797976:  
2025-08-28 15:08:22.805422: Epoch 441 
2025-08-28 15:08:22.811683: Current learning rate: 0.00592 
2025-08-28 15:08:38.429214: train_loss -0.49 
2025-08-28 15:08:38.436833: val_loss -0.5596 
2025-08-28 15:08:38.444926: Pseudo dice [np.float32(0.7463)] 
2025-08-28 15:08:38.450204: Epoch time: 15.63 s 
2025-08-28 15:08:39.299871:  
2025-08-28 15:08:39.308291: Epoch 442 
2025-08-28 15:08:39.316509: Current learning rate: 0.00592 
2025-08-28 15:08:54.936483: train_loss -0.5183 
2025-08-28 15:08:54.945091: val_loss -0.5243 
2025-08-28 15:08:54.948966: Pseudo dice [np.float32(0.6487)] 
2025-08-28 15:08:54.959359: Epoch time: 15.64 s 
2025-08-28 15:08:55.626651:  
2025-08-28 15:08:55.634946: Epoch 443 
2025-08-28 15:08:55.642380: Current learning rate: 0.00591 
2025-08-28 15:09:09.722908: train_loss -0.5139 
2025-08-28 15:09:09.734531: val_loss -0.4836 
2025-08-28 15:09:09.738661: Pseudo dice [np.float32(0.6974)] 
2025-08-28 15:09:09.745770: Epoch time: 14.1 s 
2025-08-28 15:09:10.387076:  
2025-08-28 15:09:10.395027: Epoch 444 
2025-08-28 15:09:10.398569: Current learning rate: 0.0059 
2025-08-28 15:09:24.595697: train_loss -0.5103 
2025-08-28 15:09:24.603520: val_loss -0.4544 
2025-08-28 15:09:24.607928: Pseudo dice [np.float32(0.6505)] 
2025-08-28 15:09:24.616975: Epoch time: 14.21 s 
2025-08-28 15:09:25.254143:  
2025-08-28 15:09:25.262439: Epoch 445 
2025-08-28 15:09:25.267696: Current learning rate: 0.00589 
2025-08-28 15:09:39.180743: train_loss -0.5177 
2025-08-28 15:09:39.188919: val_loss -0.5239 
2025-08-28 15:09:39.193092: Pseudo dice [np.float32(0.6561)] 
2025-08-28 15:09:39.199953: Epoch time: 13.93 s 
2025-08-28 15:09:39.838382:  
2025-08-28 15:09:39.846785: Epoch 446 
2025-08-28 15:09:39.851912: Current learning rate: 0.00588 
2025-08-28 15:09:53.937013: train_loss -0.4917 
2025-08-28 15:09:53.945307: val_loss -0.4085 
2025-08-28 15:09:53.949467: Pseudo dice [np.float32(0.7685)] 
2025-08-28 15:09:53.957275: Epoch time: 14.1 s 
2025-08-28 15:09:54.586432:  
2025-08-28 15:09:54.592797: Epoch 447 
2025-08-28 15:09:54.598045: Current learning rate: 0.00587 
2025-08-28 15:10:08.602353: train_loss -0.5224 
2025-08-28 15:10:08.609975: val_loss -0.4708 
2025-08-28 15:10:08.618462: Pseudo dice [np.float32(0.6519)] 
2025-08-28 15:10:08.625342: Epoch time: 14.02 s 
2025-08-28 15:10:09.257461:  
2025-08-28 15:10:09.267936: Epoch 448 
2025-08-28 15:10:09.274223: Current learning rate: 0.00586 
2025-08-28 15:10:23.332956: train_loss -0.5228 
2025-08-28 15:10:23.341327: val_loss -0.4145 
2025-08-28 15:10:23.349689: Pseudo dice [np.float32(0.6705)] 
2025-08-28 15:10:23.353848: Epoch time: 14.08 s 
2025-08-28 15:10:24.196244:  
2025-08-28 15:10:24.207757: Epoch 449 
2025-08-28 15:10:24.214044: Current learning rate: 0.00585 
2025-08-28 15:10:37.919067: train_loss -0.4871 
2025-08-28 15:10:37.926737: val_loss -0.4449 
2025-08-28 15:10:37.930845: Pseudo dice [np.float32(0.6437)] 
2025-08-28 15:10:37.939101: Epoch time: 13.72 s 
2025-08-28 15:10:38.746193:  
2025-08-28 15:10:38.753561: Epoch 450 
2025-08-28 15:10:38.759837: Current learning rate: 0.00584 
2025-08-28 15:10:52.696024: train_loss -0.4858 
2025-08-28 15:10:52.703991: val_loss -0.448 
2025-08-28 15:10:52.708155: Pseudo dice [np.float32(0.6624)] 
2025-08-28 15:10:52.715843: Epoch time: 13.95 s 
2025-08-28 15:10:53.348285:  
2025-08-28 15:10:53.358606: Epoch 451 
2025-08-28 15:10:53.365011: Current learning rate: 0.00583 
2025-08-28 15:11:07.564613: train_loss -0.4827 
2025-08-28 15:11:07.572976: val_loss -0.461 
2025-08-28 15:11:07.577183: Pseudo dice [np.float32(0.6485)] 
2025-08-28 15:11:07.583404: Epoch time: 14.22 s 
2025-08-28 15:11:08.211092:  
2025-08-28 15:11:08.219364: Epoch 452 
2025-08-28 15:11:08.225620: Current learning rate: 0.00582 
2025-08-28 15:11:21.995632: train_loss -0.4834 
2025-08-28 15:11:22.008260: val_loss -0.4462 
2025-08-28 15:11:22.012301: Pseudo dice [np.float32(0.673)] 
2025-08-28 15:11:22.018658: Epoch time: 13.79 s 
2025-08-28 15:11:22.662949:  
2025-08-28 15:11:22.672425: Epoch 453 
2025-08-28 15:11:22.681718: Current learning rate: 0.00581 
2025-08-28 15:11:38.274504: train_loss -0.3821 
2025-08-28 15:11:38.282794: val_loss -0.4647 
2025-08-28 15:11:38.287241: Pseudo dice [np.float32(0.6224)] 
2025-08-28 15:11:38.293629: Epoch time: 15.61 s 
2025-08-28 15:11:38.932282:  
2025-08-28 15:11:38.943132: Epoch 454 
2025-08-28 15:11:38.951234: Current learning rate: 0.0058 
2025-08-28 15:11:54.081924: train_loss -0.5173 
2025-08-28 15:11:54.090240: val_loss -0.4999 
2025-08-28 15:11:54.094404: Pseudo dice [np.float32(0.7337)] 
2025-08-28 15:11:54.103429: Epoch time: 15.15 s 
2025-08-28 15:11:54.742924:  
2025-08-28 15:11:54.750241: Epoch 455 
2025-08-28 15:11:54.756419: Current learning rate: 0.00579 
2025-08-28 15:12:09.997816: train_loss -0.5394 
2025-08-28 15:12:10.010339: val_loss -0.4636 
2025-08-28 15:12:10.014686: Pseudo dice [np.float32(0.6317)] 
2025-08-28 15:12:10.021177: Epoch time: 15.26 s 
2025-08-28 15:12:10.808142:  
2025-08-28 15:12:10.816298: Epoch 456 
2025-08-28 15:12:10.823536: Current learning rate: 0.00578 
2025-08-28 15:12:24.583269: train_loss -0.5132 
2025-08-28 15:12:24.591548: val_loss -0.5158 
2025-08-28 15:12:24.596020: Pseudo dice [np.float32(0.7102)] 
2025-08-28 15:12:24.601999: Epoch time: 13.78 s 
2025-08-28 15:12:25.233824:  
2025-08-28 15:12:25.241035: Epoch 457 
2025-08-28 15:12:25.246248: Current learning rate: 0.00577 
2025-08-28 15:12:39.277235: train_loss -0.5228 
2025-08-28 15:12:39.285419: val_loss -0.4443 
2025-08-28 15:12:39.289543: Pseudo dice [np.float32(0.639)] 
2025-08-28 15:12:39.298290: Epoch time: 14.05 s 
2025-08-28 15:12:39.939048:  
2025-08-28 15:12:39.946395: Epoch 458 
2025-08-28 15:12:39.951546: Current learning rate: 0.00576 
2025-08-28 15:12:54.067124: train_loss -0.4701 
2025-08-28 15:12:54.075167: val_loss -0.4331 
2025-08-28 15:12:54.079592: Pseudo dice [np.float32(0.6156)] 
2025-08-28 15:12:54.088217: Epoch time: 14.13 s 
2025-08-28 15:12:54.720464:  
2025-08-28 15:12:54.727849: Epoch 459 
2025-08-28 15:12:54.733001: Current learning rate: 0.00575 
2025-08-28 15:13:10.024607: train_loss -0.4835 
2025-08-28 15:13:10.032753: val_loss -0.4242 
2025-08-28 15:13:10.036895: Pseudo dice [np.float32(0.7295)] 
2025-08-28 15:13:10.045895: Epoch time: 15.31 s 
2025-08-28 15:13:10.742816:  
2025-08-28 15:13:10.751131: Epoch 460 
2025-08-28 15:13:10.757350: Current learning rate: 0.00574 
2025-08-28 15:13:26.390766: train_loss -0.5113 
2025-08-28 15:13:26.399090: val_loss -0.4944 
2025-08-28 15:13:26.407446: Pseudo dice [np.float32(0.7099)] 
2025-08-28 15:13:26.411625: Epoch time: 15.65 s 
2025-08-28 15:13:27.098643:  
2025-08-28 15:13:27.106029: Epoch 461 
2025-08-28 15:13:27.113330: Current learning rate: 0.00573 
2025-08-28 15:13:42.531754: train_loss -0.4948 
2025-08-28 15:13:42.540224: val_loss -0.3756 
2025-08-28 15:13:42.544291: Pseudo dice [np.float32(0.5791)] 
2025-08-28 15:13:42.550631: Epoch time: 15.43 s 
2025-08-28 15:13:43.235725:  
2025-08-28 15:13:43.244073: Epoch 462 
2025-08-28 15:13:43.249133: Current learning rate: 0.00572 
2025-08-28 15:13:59.086848: train_loss -0.4766 
2025-08-28 15:13:59.094224: val_loss -0.5076 
2025-08-28 15:13:59.102567: Pseudo dice [np.float32(0.7636)] 
2025-08-28 15:13:59.107814: Epoch time: 15.85 s 
2025-08-28 15:13:59.947081:  
2025-08-28 15:13:59.954427: Epoch 463 
2025-08-28 15:13:59.959591: Current learning rate: 0.00571 
2025-08-28 15:14:16.361739: train_loss -0.4895 
2025-08-28 15:14:16.374007: val_loss -0.4673 
2025-08-28 15:14:16.378465: Pseudo dice [np.float32(0.7105)] 
2025-08-28 15:14:16.385345: Epoch time: 16.42 s 
2025-08-28 15:14:17.090279:  
2025-08-28 15:14:17.098601: Epoch 464 
2025-08-28 15:14:17.106019: Current learning rate: 0.0057 
2025-08-28 15:14:33.833322: train_loss -0.5104 
2025-08-28 15:14:33.841395: val_loss -0.4639 
2025-08-28 15:14:33.845828: Pseudo dice [np.float32(0.6971)] 
2025-08-28 15:14:33.852819: Epoch time: 16.75 s 
2025-08-28 15:14:34.540947:  
2025-08-28 15:14:34.548317: Epoch 465 
2025-08-28 15:14:34.554440: Current learning rate: 0.0057 
2025-08-28 15:14:50.825087: train_loss -0.5313 
2025-08-28 15:14:50.829069: val_loss -0.4861 
2025-08-28 15:14:50.837497: Pseudo dice [np.float32(0.6746)] 
2025-08-28 15:14:50.843804: Epoch time: 16.29 s 
2025-08-28 15:14:51.527773:  
2025-08-28 15:14:51.535180: Epoch 466 
2025-08-28 15:14:51.540298: Current learning rate: 0.00569 
2025-08-28 15:15:08.004724: train_loss -0.5583 
2025-08-28 15:15:08.008891: val_loss -0.5936 
2025-08-28 15:15:08.017208: Pseudo dice [np.float32(0.8047)] 
2025-08-28 15:15:08.022470: Epoch time: 16.48 s 
2025-08-28 15:15:08.704325:  
2025-08-28 15:15:08.711595: Epoch 467 
2025-08-28 15:15:08.716734: Current learning rate: 0.00568 
2025-08-28 15:15:25.247140: train_loss -0.549 
2025-08-28 15:15:25.255512: val_loss -0.4936 
2025-08-28 15:15:25.263608: Pseudo dice [np.float32(0.6953)] 
2025-08-28 15:15:25.268825: Epoch time: 16.54 s 
2025-08-28 15:15:25.947418:  
2025-08-28 15:15:25.954809: Epoch 468 
2025-08-28 15:15:25.959944: Current learning rate: 0.00567 
2025-08-28 15:15:42.789514: train_loss -0.534 
2025-08-28 15:15:42.797820: val_loss -0.414 
2025-08-28 15:15:42.802011: Pseudo dice [np.float32(0.6814)] 
2025-08-28 15:15:42.809936: Epoch time: 16.84 s 
2025-08-28 15:15:43.511953:  
2025-08-28 15:15:43.520401: Epoch 469 
2025-08-28 15:15:43.527873: Current learning rate: 0.00566 
2025-08-28 15:16:00.211041: train_loss -0.4917 
2025-08-28 15:16:00.219339: val_loss -0.5603 
2025-08-28 15:16:00.223671: Pseudo dice [np.float32(0.7637)] 
2025-08-28 15:16:00.231390: Epoch time: 16.7 s 
2025-08-28 15:16:01.081571:  
2025-08-28 15:16:01.089944: Epoch 470 
2025-08-28 15:16:01.097296: Current learning rate: 0.00565 
2025-08-28 15:16:17.712164: train_loss -0.5382 
2025-08-28 15:16:17.720137: val_loss -0.5118 
2025-08-28 15:16:17.724292: Pseudo dice [np.float32(0.7395)] 
2025-08-28 15:16:17.732635: Epoch time: 16.63 s 
2025-08-28 15:16:18.416517:  
2025-08-28 15:16:18.422900: Epoch 471 
2025-08-28 15:16:18.428985: Current learning rate: 0.00564 
2025-08-28 15:16:35.004432: train_loss -0.4648 
2025-08-28 15:16:35.012353: val_loss -0.4704 
2025-08-28 15:16:35.016544: Pseudo dice [np.float32(0.7285)] 
2025-08-28 15:16:35.024645: Epoch time: 16.59 s 
2025-08-28 15:16:35.711901:  
2025-08-28 15:16:35.721345: Epoch 472 
2025-08-28 15:16:35.726731: Current learning rate: 0.00563 
2025-08-28 15:16:52.446433: train_loss -0.5189 
2025-08-28 15:16:52.454791: val_loss -0.5038 
2025-08-28 15:16:52.459215: Pseudo dice [np.float32(0.7248)] 
2025-08-28 15:16:52.466367: Epoch time: 16.74 s 
2025-08-28 15:16:53.170026:  
2025-08-28 15:16:53.177504: Epoch 473 
2025-08-28 15:16:53.184620: Current learning rate: 0.00562 
2025-08-28 15:17:09.864081: train_loss -0.5254 
2025-08-28 15:17:09.872170: val_loss -0.5183 
2025-08-28 15:17:09.880359: Pseudo dice [np.float32(0.6804)] 
2025-08-28 15:17:09.884684: Epoch time: 16.7 s 
2025-08-28 15:17:10.588379:  
2025-08-28 15:17:10.596835: Epoch 474 
2025-08-28 15:17:10.604115: Current learning rate: 0.00561 
2025-08-28 15:17:26.655717: train_loss -0.5198 
2025-08-28 15:17:26.663994: val_loss -0.4864 
2025-08-28 15:17:26.668445: Pseudo dice [np.float32(0.6172)] 
2025-08-28 15:17:26.677197: Epoch time: 16.07 s 
2025-08-28 15:17:27.312470:  
2025-08-28 15:17:27.319780: Epoch 475 
2025-08-28 15:17:27.325935: Current learning rate: 0.0056 
2025-08-28 15:17:42.237864: train_loss -0.4769 
2025-08-28 15:17:42.246157: val_loss -0.4698 
2025-08-28 15:17:42.250310: Pseudo dice [np.float32(0.6467)] 
2025-08-28 15:17:42.258917: Epoch time: 14.93 s 
2025-08-28 15:17:42.888368:  
2025-08-28 15:17:42.895693: Epoch 476 
2025-08-28 15:17:42.900802: Current learning rate: 0.00559 
2025-08-28 15:17:58.178857: train_loss -0.47 
2025-08-28 15:17:58.187376: val_loss -0.5205 
2025-08-28 15:17:58.191528: Pseudo dice [np.float32(0.7103)] 
2025-08-28 15:17:58.197338: Epoch time: 15.29 s 
2025-08-28 15:17:58.982887:  
2025-08-28 15:17:58.991956: Epoch 477 
2025-08-28 15:17:58.998213: Current learning rate: 0.00558 
2025-08-28 15:18:13.602647: train_loss -0.5279 
2025-08-28 15:18:13.610795: val_loss -0.5532 
2025-08-28 15:18:13.614965: Pseudo dice [np.float32(0.7282)] 
2025-08-28 15:18:13.624178: Epoch time: 14.62 s 
2025-08-28 15:18:14.265472:  
2025-08-28 15:18:14.273813: Epoch 478 
2025-08-28 15:18:14.279654: Current learning rate: 0.00557 
2025-08-28 15:18:28.317218: train_loss -0.4502 
2025-08-28 15:18:28.325506: val_loss -0.4704 
2025-08-28 15:18:28.329733: Pseudo dice [np.float32(0.6782)] 
2025-08-28 15:18:28.334602: Epoch time: 14.05 s 
2025-08-28 15:18:28.969881:  
2025-08-28 15:18:28.977244: Epoch 479 
2025-08-28 15:18:28.983396: Current learning rate: 0.00556 
2025-08-28 15:18:42.756736: train_loss -0.5073 
2025-08-28 15:18:42.764941: val_loss -0.377 
2025-08-28 15:18:42.769123: Pseudo dice [np.float32(0.5992)] 
2025-08-28 15:18:42.775963: Epoch time: 13.79 s 
2025-08-28 15:18:43.411331:  
2025-08-28 15:18:43.418586: Epoch 480 
2025-08-28 15:18:43.424925: Current learning rate: 0.00555 
2025-08-28 15:18:57.429868: train_loss -0.5091 
2025-08-28 15:18:57.437901: val_loss -0.4358 
2025-08-28 15:18:57.442060: Pseudo dice [np.float32(0.6868)] 
2025-08-28 15:18:57.449868: Epoch time: 14.02 s 
2025-08-28 15:18:58.079102:  
2025-08-28 15:18:58.086395: Epoch 481 
2025-08-28 15:18:58.092570: Current learning rate: 0.00554 
2025-08-28 15:19:12.128450: train_loss -0.5154 
2025-08-28 15:19:12.140085: val_loss -0.5222 
2025-08-28 15:19:12.144559: Pseudo dice [np.float32(0.7533)] 
2025-08-28 15:19:12.151181: Epoch time: 14.05 s 
2025-08-28 15:19:12.805320:  
2025-08-28 15:19:12.813632: Epoch 482 
2025-08-28 15:19:12.819788: Current learning rate: 0.00553 
2025-08-28 15:19:26.871618: train_loss -0.5232 
2025-08-28 15:19:26.879803: val_loss -0.5029 
2025-08-28 15:19:26.883984: Pseudo dice [np.float32(0.6859)] 
2025-08-28 15:19:26.890920: Epoch time: 14.07 s 
2025-08-28 15:19:27.530290:  
2025-08-28 15:19:27.540036: Epoch 483 
2025-08-28 15:19:27.546995: Current learning rate: 0.00552 
2025-08-28 15:19:41.327559: train_loss -0.5494 
2025-08-28 15:19:41.335888: val_loss -0.3775 
2025-08-28 15:19:41.340355: Pseudo dice [np.float32(0.6074)] 
2025-08-28 15:19:41.346041: Epoch time: 13.8 s 
2025-08-28 15:19:42.136559:  
2025-08-28 15:19:42.144969: Epoch 484 
2025-08-28 15:19:42.150240: Current learning rate: 0.00551 
2025-08-28 15:19:56.138458: train_loss -0.4731 
2025-08-28 15:19:56.146531: val_loss -0.4584 
2025-08-28 15:19:56.150697: Pseudo dice [np.float32(0.6947)] 
2025-08-28 15:19:56.159802: Epoch time: 14.0 s 
2025-08-28 15:19:56.809536:  
2025-08-28 15:19:56.816951: Epoch 485 
2025-08-28 15:19:56.822047: Current learning rate: 0.0055 
2025-08-28 15:20:10.673974: train_loss -0.5483 
2025-08-28 15:20:10.686037: val_loss -0.5242 
2025-08-28 15:20:10.690213: Pseudo dice [np.float32(0.6564)] 
2025-08-28 15:20:10.697165: Epoch time: 13.87 s 
2025-08-28 15:20:11.337846:  
2025-08-28 15:20:11.344933: Epoch 486 
2025-08-28 15:20:11.350215: Current learning rate: 0.00549 
2025-08-28 15:20:25.175486: train_loss -0.5172 
2025-08-28 15:20:25.183849: val_loss -0.4434 
2025-08-28 15:20:25.188010: Pseudo dice [np.float32(0.6674)] 
2025-08-28 15:20:25.195864: Epoch time: 13.84 s 
2025-08-28 15:20:25.834442:  
2025-08-28 15:20:25.841755: Epoch 487 
2025-08-28 15:20:25.846891: Current learning rate: 0.00548 
2025-08-28 15:20:39.865597: train_loss -0.5045 
2025-08-28 15:20:39.873507: val_loss -0.5004 
2025-08-28 15:20:39.877677: Pseudo dice [np.float32(0.7199)] 
2025-08-28 15:20:39.886847: Epoch time: 14.03 s 
2025-08-28 15:20:40.523006:  
2025-08-28 15:20:40.530348: Epoch 488 
2025-08-28 15:20:40.536509: Current learning rate: 0.00547 
2025-08-28 15:20:54.458882: train_loss -0.5138 
2025-08-28 15:20:54.467251: val_loss -0.5251 
2025-08-28 15:20:54.471364: Pseudo dice [np.float32(0.7424)] 
2025-08-28 15:20:54.480292: Epoch time: 13.94 s 
2025-08-28 15:20:55.167863:  
2025-08-28 15:20:55.176141: Epoch 489 
2025-08-28 15:20:55.184583: Current learning rate: 0.00546 
2025-08-28 15:21:09.169503: train_loss -0.4942 
2025-08-28 15:21:09.178028: val_loss -0.6244 
2025-08-28 15:21:09.181933: Pseudo dice [np.float32(0.7633)] 
2025-08-28 15:21:09.188908: Epoch time: 14.0 s 
2025-08-28 15:21:09.986740:  
2025-08-28 15:21:09.994096: Epoch 490 
2025-08-28 15:21:09.999311: Current learning rate: 0.00546 
2025-08-28 15:21:23.775924: train_loss -0.4988 
2025-08-28 15:21:23.784023: val_loss -0.4133 
2025-08-28 15:21:23.792966: Pseudo dice [np.float32(0.6741)] 
2025-08-28 15:21:23.798381: Epoch time: 13.79 s 
2025-08-28 15:21:24.433502:  
2025-08-28 15:21:24.440852: Epoch 491 
2025-08-28 15:21:24.446086: Current learning rate: 0.00545 
2025-08-28 15:21:39.570879: train_loss -0.4784 
2025-08-28 15:21:39.578853: val_loss -0.5334 
2025-08-28 15:21:39.583142: Pseudo dice [np.float32(0.722)] 
2025-08-28 15:21:39.588470: Epoch time: 15.14 s 
2025-08-28 15:21:40.276636:  
2025-08-28 15:21:40.284878: Epoch 492 
2025-08-28 15:21:40.293214: Current learning rate: 0.00544 
2025-08-28 15:21:55.957802: train_loss -0.5389 
2025-08-28 15:21:55.966161: val_loss -0.417 
2025-08-28 15:21:55.970356: Pseudo dice [np.float32(0.6332)] 
2025-08-28 15:21:55.977545: Epoch time: 15.68 s 
2025-08-28 15:21:56.681377:  
2025-08-28 15:21:56.688763: Epoch 493 
2025-08-28 15:21:56.694971: Current learning rate: 0.00543 
2025-08-28 15:22:12.115892: train_loss -0.5368 
2025-08-28 15:22:12.123969: val_loss -0.5157 
2025-08-28 15:22:12.132368: Pseudo dice [np.float32(0.6952)] 
2025-08-28 15:22:12.137922: Epoch time: 15.44 s 
2025-08-28 15:22:12.824490:  
2025-08-28 15:22:12.833136: Epoch 494 
2025-08-28 15:22:12.838135: Current learning rate: 0.00542 
2025-08-28 15:22:28.357146: train_loss -0.5285 
2025-08-28 15:22:28.365628: val_loss -0.5908 
2025-08-28 15:22:28.373494: Pseudo dice [np.float32(0.76)] 
2025-08-28 15:22:28.379532: Epoch time: 15.53 s 
2025-08-28 15:22:29.059614:  
2025-08-28 15:22:29.066971: Epoch 495 
2025-08-28 15:22:29.072025: Current learning rate: 0.00541 
2025-08-28 15:22:44.638529: train_loss -0.5324 
2025-08-28 15:22:44.644003: val_loss -0.5204 
2025-08-28 15:22:44.648090: Pseudo dice [np.float32(0.7429)] 
2025-08-28 15:22:44.656496: Epoch time: 15.58 s 
2025-08-28 15:22:45.350868:  
2025-08-28 15:22:45.358245: Epoch 496 
2025-08-28 15:22:45.366501: Current learning rate: 0.0054 
2025-08-28 15:23:01.043597: train_loss -0.5479 
2025-08-28 15:23:01.048125: val_loss -0.5257 
2025-08-28 15:23:01.056162: Pseudo dice [np.float32(0.7235)] 
2025-08-28 15:23:01.061633: Epoch time: 15.69 s 
2025-08-28 15:23:01.893389:  
2025-08-28 15:23:01.900651: Epoch 497 
2025-08-28 15:23:01.905824: Current learning rate: 0.00539 
2025-08-28 15:23:17.499768: train_loss -0.5319 
2025-08-28 15:23:17.510067: val_loss -0.5093 
2025-08-28 15:23:17.514520: Pseudo dice [np.float32(0.6744)] 
2025-08-28 15:23:17.522608: Epoch time: 15.61 s 
2025-08-28 15:23:18.233660:  
2025-08-28 15:23:18.241053: Epoch 498 
2025-08-28 15:23:18.250459: Current learning rate: 0.00538 
2025-08-28 15:23:33.768490: train_loss -0.5299 
2025-08-28 15:23:33.776332: val_loss -0.5026 
2025-08-28 15:23:33.780815: Pseudo dice [np.float32(0.7225)] 
2025-08-28 15:23:33.786569: Epoch time: 15.54 s 
2025-08-28 15:23:34.474829:  
2025-08-28 15:23:34.483268: Epoch 499 
2025-08-28 15:23:34.488350: Current learning rate: 0.00537 
2025-08-28 15:23:49.897071: train_loss -0.4893 
2025-08-28 15:23:49.904902: val_loss -0.5489 
2025-08-28 15:23:49.913593: Pseudo dice [np.float32(0.7791)] 
2025-08-28 15:23:49.918752: Epoch time: 15.42 s 
2025-08-28 15:23:50.792166:  
2025-08-28 15:23:50.799442: Epoch 500 
2025-08-28 15:23:50.804982: Current learning rate: 0.00536 
2025-08-28 15:24:06.421284: train_loss -0.498 
2025-08-28 15:24:06.429734: val_loss -0.4584 
2025-08-28 15:24:06.433895: Pseudo dice [np.float32(0.6832)] 
2025-08-28 15:24:06.440987: Epoch time: 15.63 s 
2025-08-28 15:24:07.133471:  
2025-08-28 15:24:07.140864: Epoch 501 
2025-08-28 15:24:07.147485: Current learning rate: 0.00535 
2025-08-28 15:24:22.512421: train_loss -0.5354 
2025-08-28 15:24:22.521081: val_loss -0.5235 
2025-08-28 15:24:22.524894: Pseudo dice [np.float32(0.743)] 
2025-08-28 15:24:22.534212: Epoch time: 15.38 s 
2025-08-28 15:24:23.226784:  
2025-08-28 15:24:23.235087: Epoch 502 
2025-08-28 15:24:23.241184: Current learning rate: 0.00534 
2025-08-28 15:24:38.753236: train_loss -0.5586 
2025-08-28 15:24:38.757834: val_loss -0.4847 
2025-08-28 15:24:38.766173: Pseudo dice [np.float32(0.6731)] 
2025-08-28 15:24:38.771231: Epoch time: 15.53 s 
2025-08-28 15:24:39.625607:  
2025-08-28 15:24:39.636774: Epoch 503 
2025-08-28 15:24:39.647798: Current learning rate: 0.00533 
2025-08-28 15:24:55.015562: train_loss -0.5025 
2025-08-28 15:24:55.019941: val_loss -0.4071 
2025-08-28 15:24:55.028304: Pseudo dice [np.float32(0.571)] 
2025-08-28 15:24:55.033296: Epoch time: 15.39 s 
2025-08-28 15:24:55.716340:  
2025-08-28 15:24:55.725877: Epoch 504 
2025-08-28 15:24:55.736161: Current learning rate: 0.00532 
2025-08-28 15:25:11.340768: train_loss -0.5384 
2025-08-28 15:25:11.348730: val_loss -0.4722 
2025-08-28 15:25:11.357051: Pseudo dice [np.float32(0.7256)] 
2025-08-28 15:25:11.362595: Epoch time: 15.63 s 
2025-08-28 15:25:12.059773:  
2025-08-28 15:25:12.069142: Epoch 505 
2025-08-28 15:25:12.076543: Current learning rate: 0.00531 
2025-08-28 15:25:27.769874: train_loss -0.5367 
2025-08-28 15:25:27.777620: val_loss -0.447 
2025-08-28 15:25:27.786003: Pseudo dice [np.float32(0.7179)] 
2025-08-28 15:25:27.791022: Epoch time: 15.71 s 
2025-08-28 15:25:28.607465:  
2025-08-28 15:25:28.615810: Epoch 506 
2025-08-28 15:25:28.623185: Current learning rate: 0.0053 
2025-08-28 15:25:44.377545: train_loss -0.5064 
2025-08-28 15:25:44.381712: val_loss -0.466 
2025-08-28 15:25:44.390243: Pseudo dice [np.float32(0.6867)] 
2025-08-28 15:25:44.395559: Epoch time: 15.77 s 
2025-08-28 15:25:45.119796:  
2025-08-28 15:25:45.127050: Epoch 507 
2025-08-28 15:25:45.134243: Current learning rate: 0.00529 
2025-08-28 15:26:00.664711: train_loss -0.5186 
2025-08-28 15:26:00.672965: val_loss -0.5521 
2025-08-28 15:26:00.677368: Pseudo dice [np.float32(0.8191)] 
2025-08-28 15:26:00.684233: Epoch time: 15.55 s 
2025-08-28 15:26:01.425786:  
2025-08-28 15:26:01.433070: Epoch 508 
2025-08-28 15:26:01.439247: Current learning rate: 0.00528 
2025-08-28 15:26:16.793776: train_loss -0.5349 
2025-08-28 15:26:16.801579: val_loss -0.4029 
2025-08-28 15:26:16.809805: Pseudo dice [np.float32(0.6589)] 
2025-08-28 15:26:16.815012: Epoch time: 15.37 s 
2025-08-28 15:26:17.497931:  
2025-08-28 15:26:17.506256: Epoch 509 
2025-08-28 15:26:17.514649: Current learning rate: 0.00527 
2025-08-28 15:26:32.847655: train_loss -0.5102 
2025-08-28 15:26:32.855202: val_loss -0.4908 
2025-08-28 15:26:32.859212: Pseudo dice [np.float32(0.7186)] 
2025-08-28 15:26:32.868648: Epoch time: 15.35 s 
2025-08-28 15:26:33.715332:  
2025-08-28 15:26:33.723655: Epoch 510 
2025-08-28 15:26:33.728831: Current learning rate: 0.00526 
2025-08-28 15:26:48.913548: train_loss -0.52 
2025-08-28 15:26:48.921110: val_loss -0.3705 
2025-08-28 15:26:48.925270: Pseudo dice [np.float32(0.5705)] 
2025-08-28 15:26:48.933742: Epoch time: 15.2 s 
2025-08-28 15:26:49.625951:  
2025-08-28 15:26:49.633170: Epoch 511 
2025-08-28 15:26:49.638362: Current learning rate: 0.00525 
2025-08-28 15:27:05.008414: train_loss -0.5378 
2025-08-28 15:27:05.016837: val_loss -0.4919 
2025-08-28 15:27:05.020528: Pseudo dice [np.float32(0.6701)] 
2025-08-28 15:27:05.029619: Epoch time: 15.38 s 
2025-08-28 15:27:05.701479:  
2025-08-28 15:27:05.709825: Epoch 512 
2025-08-28 15:27:05.715919: Current learning rate: 0.00524 
2025-08-28 15:27:21.069904: train_loss -0.4799 
2025-08-28 15:27:21.078272: val_loss -0.4559 
2025-08-28 15:27:21.082620: Pseudo dice [np.float32(0.7542)] 
2025-08-28 15:27:21.090368: Epoch time: 15.37 s 
2025-08-28 15:27:21.761155:  
2025-08-28 15:27:21.768478: Epoch 513 
2025-08-28 15:27:21.773651: Current learning rate: 0.00523 
2025-08-28 15:27:37.319081: train_loss -0.5125 
2025-08-28 15:27:37.323622: val_loss -0.573 
2025-08-28 15:27:37.332028: Pseudo dice [np.float32(0.724)] 
2025-08-28 15:27:37.337254: Epoch time: 15.56 s 
2025-08-28 15:27:38.020033:  
2025-08-28 15:27:38.028342: Epoch 514 
2025-08-28 15:27:38.034860: Current learning rate: 0.00522 
2025-08-28 15:27:53.748365: train_loss -0.5382 
2025-08-28 15:27:53.757007: val_loss -0.5808 
2025-08-28 15:27:53.765014: Pseudo dice [np.float32(0.7637)] 
2025-08-28 15:27:53.770133: Epoch time: 15.73 s 
2025-08-28 15:27:54.465582:  
2025-08-28 15:27:54.473961: Epoch 515 
2025-08-28 15:27:54.479240: Current learning rate: 0.00521 
2025-08-28 15:28:11.024338: train_loss -0.5191 
2025-08-28 15:28:11.036461: val_loss -0.5157 
2025-08-28 15:28:11.040542: Pseudo dice [np.float32(0.7396)] 
2025-08-28 15:28:11.048731: Epoch time: 16.56 s 
2025-08-28 15:28:11.738155:  
2025-08-28 15:28:11.745364: Epoch 516 
2025-08-28 15:28:11.751679: Current learning rate: 0.0052 
2025-08-28 15:28:27.199196: train_loss -0.4763 
2025-08-28 15:28:27.206765: val_loss -0.484 
2025-08-28 15:28:27.210915: Pseudo dice [np.float32(0.6892)] 
2025-08-28 15:28:27.219313: Epoch time: 15.46 s 
2025-08-28 15:28:28.027320:  
2025-08-28 15:28:28.034647: Epoch 517 
2025-08-28 15:28:28.040791: Current learning rate: 0.00519 
2025-08-28 15:28:43.497754: train_loss -0.5409 
2025-08-28 15:28:43.502188: val_loss -0.4952 
2025-08-28 15:28:43.510683: Pseudo dice [np.float32(0.6509)] 
2025-08-28 15:28:43.515965: Epoch time: 15.47 s 
2025-08-28 15:28:44.221673:  
2025-08-28 15:28:44.229913: Epoch 518 
2025-08-28 15:28:44.239010: Current learning rate: 0.00518 
2025-08-28 15:28:59.526534: train_loss -0.5008 
2025-08-28 15:28:59.535641: val_loss -0.5334 
2025-08-28 15:28:59.543195: Pseudo dice [np.float32(0.7769)] 
2025-08-28 15:28:59.548636: Epoch time: 15.31 s 
2025-08-28 15:29:00.230296:  
2025-08-28 15:29:00.238557: Epoch 519 
2025-08-28 15:29:00.245027: Current learning rate: 0.00518 
2025-08-28 15:29:15.564146: train_loss -0.4843 
2025-08-28 15:29:15.575855: val_loss -0.5173 
2025-08-28 15:29:15.580312: Pseudo dice [np.float32(0.7281)] 
2025-08-28 15:29:15.587149: Epoch time: 15.34 s 
2025-08-28 15:29:16.266151:  
2025-08-28 15:29:16.273397: Epoch 520 
2025-08-28 15:29:16.278583: Current learning rate: 0.00517 
2025-08-28 15:29:31.696160: train_loss -0.5244 
2025-08-28 15:29:31.704457: val_loss -0.5106 
2025-08-28 15:29:31.708845: Pseudo dice [np.float32(0.7121)] 
2025-08-28 15:29:31.715803: Epoch time: 15.43 s 
2025-08-28 15:29:32.388327:  
2025-08-28 15:29:32.395765: Epoch 521 
2025-08-28 15:29:32.402061: Current learning rate: 0.00516 
2025-08-28 15:29:47.958444: train_loss -0.5441 
2025-08-28 15:29:47.966541: val_loss -0.4969 
2025-08-28 15:29:47.970699: Pseudo dice [np.float32(0.7023)] 
2025-08-28 15:29:47.977723: Epoch time: 15.57 s 
2025-08-28 15:29:48.661012:  
2025-08-28 15:29:48.667093: Epoch 522 
2025-08-28 15:29:48.672451: Current learning rate: 0.00515 
2025-08-28 15:30:04.278526: train_loss -0.499 
2025-08-28 15:30:04.287006: val_loss -0.4943 
2025-08-28 15:30:04.291159: Pseudo dice [np.float32(0.6985)] 
2025-08-28 15:30:04.297146: Epoch time: 15.62 s 
2025-08-28 15:30:04.976198:  
2025-08-28 15:30:04.984648: Epoch 523 
2025-08-28 15:30:04.989737: Current learning rate: 0.00514 
2025-08-28 15:30:20.598994: train_loss -0.5382 
2025-08-28 15:30:20.607673: val_loss -0.5567 
2025-08-28 15:30:20.611670: Pseudo dice [np.float32(0.7491)] 
2025-08-28 15:30:20.620016: Epoch time: 15.62 s 
2025-08-28 15:30:21.458280:  
2025-08-28 15:30:21.466554: Epoch 524 
2025-08-28 15:30:21.472338: Current learning rate: 0.00513 
2025-08-28 15:30:37.090884: train_loss -0.5414 
2025-08-28 15:30:37.098916: val_loss -0.4669 
2025-08-28 15:30:37.103026: Pseudo dice [np.float32(0.7427)] 
2025-08-28 15:30:37.111092: Epoch time: 15.63 s 
2025-08-28 15:30:37.793416:  
2025-08-28 15:30:37.800652: Epoch 525 
2025-08-28 15:30:37.806783: Current learning rate: 0.00512 
2025-08-28 15:30:53.273395: train_loss -0.5444 
2025-08-28 15:30:53.281763: val_loss -0.4187 
2025-08-28 15:30:53.285903: Pseudo dice [np.float32(0.6648)] 
2025-08-28 15:30:53.292960: Epoch time: 15.48 s 
2025-08-28 15:30:53.981364:  
2025-08-28 15:30:53.988695: Epoch 526 
2025-08-28 15:30:53.994769: Current learning rate: 0.00511 
2025-08-28 15:31:09.452275: train_loss -0.5697 
2025-08-28 15:31:09.460400: val_loss -0.5259 
2025-08-28 15:31:09.464500: Pseudo dice [np.float32(0.7187)] 
2025-08-28 15:31:09.471696: Epoch time: 15.47 s 
2025-08-28 15:31:10.170893:  
2025-08-28 15:31:10.178604: Epoch 527 
2025-08-28 15:31:10.182416: Current learning rate: 0.0051 
2025-08-28 15:31:25.572475: train_loss -0.5346 
2025-08-28 15:31:25.580645: val_loss -0.5103 
2025-08-28 15:31:25.584807: Pseudo dice [np.float32(0.7228)] 
2025-08-28 15:31:25.593396: Epoch time: 15.4 s 
2025-08-28 15:31:26.277099:  
2025-08-28 15:31:26.284381: Epoch 528 
2025-08-28 15:31:26.289578: Current learning rate: 0.00509 
2025-08-28 15:31:41.847234: train_loss -0.4573 
2025-08-28 15:31:41.855576: val_loss -0.4934 
2025-08-28 15:31:41.859380: Pseudo dice [np.float32(0.6427)] 
2025-08-28 15:31:41.865482: Epoch time: 15.57 s 
2025-08-28 15:31:42.562500:  
2025-08-28 15:31:42.570690: Epoch 529 
2025-08-28 15:31:42.576861: Current learning rate: 0.00508 
2025-08-28 15:31:58.075758: train_loss -0.4877 
2025-08-28 15:31:58.083928: val_loss -0.5054 
2025-08-28 15:31:58.088139: Pseudo dice [np.float32(0.6974)] 
2025-08-28 15:31:58.096151: Epoch time: 15.52 s 
2025-08-28 15:31:58.766847:  
2025-08-28 15:31:58.774152: Epoch 530 
2025-08-28 15:31:58.779356: Current learning rate: 0.00507 
2025-08-28 15:32:14.337972: train_loss -0.5169 
2025-08-28 15:32:14.346328: val_loss -0.497 
2025-08-28 15:32:14.354664: Pseudo dice [np.float32(0.698)] 
2025-08-28 15:32:14.359801: Epoch time: 15.57 s 
2025-08-28 15:32:15.193693:  
2025-08-28 15:32:15.200896: Epoch 531 
2025-08-28 15:32:15.207215: Current learning rate: 0.00506 
2025-08-28 15:32:30.837605: train_loss -0.497 
2025-08-28 15:32:30.845821: val_loss -0.5012 
2025-08-28 15:32:30.849973: Pseudo dice [np.float32(0.7587)] 
2025-08-28 15:32:30.857074: Epoch time: 15.65 s 
2025-08-28 15:32:31.531940:  
2025-08-28 15:32:31.539273: Epoch 532 
2025-08-28 15:32:31.544384: Current learning rate: 0.00505 
2025-08-28 15:32:47.061989: train_loss -0.5273 
2025-08-28 15:32:47.066175: val_loss -0.5406 
2025-08-28 15:32:47.074537: Pseudo dice [np.float32(0.6977)] 
2025-08-28 15:32:47.080705: Epoch time: 15.53 s 
2025-08-28 15:32:47.765758:  
2025-08-28 15:32:47.773563: Epoch 533 
2025-08-28 15:32:47.780455: Current learning rate: 0.00504 
2025-08-28 15:33:03.358403: train_loss -0.534 
2025-08-28 15:33:03.365843: val_loss -0.511 
2025-08-28 15:33:03.369921: Pseudo dice [np.float32(0.801)] 
2025-08-28 15:33:03.378151: Epoch time: 15.59 s 
2025-08-28 15:33:04.068602:  
2025-08-28 15:33:04.078924: Epoch 534 
2025-08-28 15:33:04.087636: Current learning rate: 0.00503 
2025-08-28 15:33:19.637360: train_loss -0.5248 
2025-08-28 15:33:19.648976: val_loss -0.544 
2025-08-28 15:33:19.652884: Pseudo dice [np.float32(0.7148)] 
2025-08-28 15:33:19.660032: Epoch time: 15.57 s 
2025-08-28 15:33:20.334116:  
2025-08-28 15:33:20.342049: Epoch 535 
2025-08-28 15:33:20.347264: Current learning rate: 0.00502 
2025-08-28 15:33:35.835898: train_loss -0.5343 
2025-08-28 15:33:35.844318: val_loss -0.5526 
2025-08-28 15:33:35.852388: Pseudo dice [np.float32(0.7419)] 
2025-08-28 15:33:35.857234: Epoch time: 15.5 s 
2025-08-28 15:33:36.569595:  
2025-08-28 15:33:36.576927: Epoch 536 
2025-08-28 15:33:36.582179: Current learning rate: 0.00501 
2025-08-28 15:33:51.480561: train_loss -0.5703 
2025-08-28 15:33:51.486609: val_loss -0.5294 
2025-08-28 15:33:51.494981: Pseudo dice [np.float32(0.6645)] 
2025-08-28 15:33:51.499853: Epoch time: 14.91 s 
2025-08-28 15:33:52.207338:  
2025-08-28 15:33:52.215620: Epoch 537 
2025-08-28 15:33:52.220744: Current learning rate: 0.005 
2025-08-28 15:34:07.038510: train_loss -0.5508 
2025-08-28 15:34:07.038510: val_loss -0.4959 
2025-08-28 15:34:07.046035: Pseudo dice [np.float32(0.7169)] 
2025-08-28 15:34:07.054006: Epoch time: 14.83 s 
2025-08-28 15:34:07.863499:  
2025-08-28 15:34:07.863499: Epoch 538 
2025-08-28 15:34:07.871833: Current learning rate: 0.00499 
2025-08-28 15:34:21.806580: train_loss -0.555 
2025-08-28 15:34:21.810224: val_loss -0.597 
2025-08-28 15:34:21.814919: Pseudo dice [np.float32(0.7703)] 
2025-08-28 15:34:21.824389: Epoch time: 13.94 s 
2025-08-28 15:34:22.440911:  
2025-08-28 15:34:22.440911: Epoch 539 
2025-08-28 15:34:22.448876: Current learning rate: 0.00498 
2025-08-28 15:34:36.396483: train_loss -0.5061 
2025-08-28 15:34:36.396483: val_loss -0.5167 
2025-08-28 15:34:36.404487: Pseudo dice [np.float32(0.7679)] 
2025-08-28 15:34:36.411398: Epoch time: 13.96 s 
2025-08-28 15:34:36.416974: Yayy! New best EMA pseudo Dice: 0.7250000238418579 
2025-08-28 15:34:37.221947:  
2025-08-28 15:34:37.221947: Epoch 540 
2025-08-28 15:34:37.230308: Current learning rate: 0.00497 
2025-08-28 15:34:51.161042: train_loss -0.5699 
2025-08-28 15:34:51.161042: val_loss -0.4673 
2025-08-28 15:34:51.169462: Pseudo dice [np.float32(0.6513)] 
2025-08-28 15:34:51.176254: Epoch time: 13.94 s 
2025-08-28 15:34:51.794857:  
2025-08-28 15:34:51.799024: Epoch 541 
2025-08-28 15:34:51.803142: Current learning rate: 0.00496 
2025-08-28 15:35:05.638006: train_loss -0.5487 
2025-08-28 15:35:05.638006: val_loss -0.5935 
2025-08-28 15:35:05.646203: Pseudo dice [np.float32(0.7498)] 
2025-08-28 15:35:05.652173: Epoch time: 13.84 s 
2025-08-28 15:35:06.275979:  
2025-08-28 15:35:06.275979: Epoch 542 
2025-08-28 15:35:06.284319: Current learning rate: 0.00495 
2025-08-28 15:35:20.311040: train_loss -0.5602 
2025-08-28 15:35:20.311040: val_loss -0.488 
2025-08-28 15:35:20.321785: Pseudo dice [np.float32(0.7341)] 
2025-08-28 15:35:20.328404: Epoch time: 14.04 s 
2025-08-28 15:35:20.944778:  
2025-08-28 15:35:20.944778: Epoch 543 
2025-08-28 15:35:20.953129: Current learning rate: 0.00494 
2025-08-28 15:35:35.000634: train_loss -0.5449 
2025-08-28 15:35:35.003817: val_loss -0.4915 
2025-08-28 15:35:35.008841: Pseudo dice [np.float32(0.7326)] 
2025-08-28 15:35:35.016681: Epoch time: 14.06 s 
2025-08-28 15:35:35.634480:  
2025-08-28 15:35:35.634480: Epoch 544 
2025-08-28 15:35:35.642792: Current learning rate: 0.00493 
2025-08-28 15:35:49.602567: train_loss -0.5458 
2025-08-28 15:35:49.602567: val_loss -0.4161 
2025-08-28 15:35:49.610907: Pseudo dice [np.float32(0.6527)] 
2025-08-28 15:35:49.618756: Epoch time: 13.97 s 
2025-08-28 15:35:50.390837:  
2025-08-28 15:35:50.390837: Epoch 545 
2025-08-28 15:35:50.399202: Current learning rate: 0.00492 
2025-08-28 15:36:04.079246: train_loss -0.509 
2025-08-28 15:36:04.079567: val_loss -0.5245 
2025-08-28 15:36:04.083780: Pseudo dice [np.float32(0.6961)] 
2025-08-28 15:36:04.092577: Epoch time: 13.69 s 
2025-08-28 15:36:04.717632:  
2025-08-28 15:36:04.717632: Epoch 546 
2025-08-28 15:36:04.721828: Current learning rate: 0.00491 
2025-08-28 15:36:19.957930: train_loss -0.5383 
2025-08-28 15:36:19.957930: val_loss -0.5742 
2025-08-28 15:36:19.966201: Pseudo dice [np.float32(0.7468)] 
2025-08-28 15:36:19.973614: Epoch time: 15.24 s 
2025-08-28 15:36:20.600172:  
2025-08-28 15:36:20.604336: Epoch 547 
2025-08-28 15:36:20.608408: Current learning rate: 0.0049 
2025-08-28 15:36:36.003352: train_loss -0.5139 
2025-08-28 15:36:36.003352: val_loss -0.4892 
2025-08-28 15:36:36.012972: Pseudo dice [np.float32(0.736)] 
2025-08-28 15:36:36.017463: Epoch time: 15.4 s 
2025-08-28 15:36:36.641189:  
2025-08-28 15:36:36.641189: Epoch 548 
2025-08-28 15:36:36.649538: Current learning rate: 0.00489 
2025-08-28 15:36:52.607500: train_loss -0.5254 
2025-08-28 15:36:52.607500: val_loss -0.5226 
2025-08-28 15:36:52.615490: Pseudo dice [np.float32(0.7135)] 
2025-08-28 15:36:52.622406: Epoch time: 15.97 s 
2025-08-28 15:36:53.241104:  
2025-08-28 15:36:53.241104: Epoch 549 
2025-08-28 15:36:53.249421: Current learning rate: 0.00488 
2025-08-28 15:37:08.264673: train_loss -0.521 
2025-08-28 15:37:08.264673: val_loss -0.4652 
2025-08-28 15:37:08.272774: Pseudo dice [np.float32(0.6733)] 
2025-08-28 15:37:08.281124: Epoch time: 15.02 s 
2025-08-28 15:37:09.098584:  
2025-08-28 15:37:09.098584: Epoch 550 
2025-08-28 15:37:09.107630: Current learning rate: 0.00487 
2025-08-28 15:37:24.134676: train_loss -0.5289 
2025-08-28 15:37:24.134676: val_loss -0.4918 
2025-08-28 15:37:24.142862: Pseudo dice [np.float32(0.7246)] 
2025-08-28 15:37:24.150636: Epoch time: 15.04 s 
2025-08-28 15:37:24.939659:  
2025-08-28 15:37:24.939659: Epoch 551 
2025-08-28 15:37:24.948075: Current learning rate: 0.00486 
2025-08-28 15:37:40.121210: train_loss -0.571 
2025-08-28 15:37:40.121210: val_loss -0.5092 
2025-08-28 15:37:40.129585: Pseudo dice [np.float32(0.6982)] 
2025-08-28 15:37:40.138459: Epoch time: 15.18 s 
2025-08-28 15:37:40.767711:  
2025-08-28 15:37:40.767711: Epoch 552 
2025-08-28 15:37:40.776066: Current learning rate: 0.00485 
2025-08-28 15:37:56.033025: train_loss -0.5733 
2025-08-28 15:37:56.033025: val_loss -0.549 
2025-08-28 15:37:56.041536: Pseudo dice [np.float32(0.7376)] 
2025-08-28 15:37:56.049115: Epoch time: 15.27 s 
2025-08-28 15:37:56.671090:  
2025-08-28 15:37:56.671090: Epoch 553 
2025-08-28 15:37:56.679432: Current learning rate: 0.00484 
2025-08-28 15:38:11.686284: train_loss -0.5434 
2025-08-28 15:38:11.686284: val_loss -0.4302 
2025-08-28 15:38:11.699073: Pseudo dice [np.float32(0.7039)] 
2025-08-28 15:38:11.704324: Epoch time: 15.02 s 
2025-08-28 15:38:12.328379:  
2025-08-28 15:38:12.328379: Epoch 554 
2025-08-28 15:38:12.336716: Current learning rate: 0.00484 
2025-08-28 15:38:28.377599: train_loss -0.5261 
2025-08-28 15:38:28.378059: val_loss -0.5232 
2025-08-28 15:38:28.382135: Pseudo dice [np.float32(0.7431)] 
2025-08-28 15:38:28.391450: Epoch time: 16.05 s 
2025-08-28 15:38:29.041203:  
2025-08-28 15:38:29.041203: Epoch 555 
2025-08-28 15:38:29.049248: Current learning rate: 0.00483 
2025-08-28 15:38:45.941441: train_loss -0.5386 
2025-08-28 15:38:45.941441: val_loss -0.5338 
2025-08-28 15:38:45.949483: Pseudo dice [np.float32(0.6951)] 
2025-08-28 15:38:45.958625: Epoch time: 16.9 s 
2025-08-28 15:38:46.608257:  
2025-08-28 15:38:46.609457: Epoch 556 
2025-08-28 15:38:46.616748: Current learning rate: 0.00482 
2025-08-28 15:39:03.521170: train_loss -0.5647 
2025-08-28 15:39:03.525338: val_loss -0.433 
2025-08-28 15:39:03.529826: Pseudo dice [np.float32(0.7193)] 
2025-08-28 15:39:03.537912: Epoch time: 16.92 s 
2025-08-28 15:39:04.184666:  
2025-08-28 15:39:04.188788: Epoch 557 
2025-08-28 15:39:04.192676: Current learning rate: 0.00481 
2025-08-28 15:39:21.209941: train_loss -0.5204 
2025-08-28 15:39:21.209941: val_loss -0.4821 
2025-08-28 15:39:21.218280: Pseudo dice [np.float32(0.7156)] 
2025-08-28 15:39:21.225350: Epoch time: 17.03 s 
2025-08-28 15:39:22.031299:  
2025-08-28 15:39:22.031299: Epoch 558 
2025-08-28 15:39:22.039653: Current learning rate: 0.0048 
2025-08-28 15:39:38.722966: train_loss -0.5299 
2025-08-28 15:39:38.722966: val_loss -0.5272 
2025-08-28 15:39:38.732924: Pseudo dice [np.float32(0.7328)] 
2025-08-28 15:39:38.737480: Epoch time: 16.69 s 
2025-08-28 15:39:39.382007:  
2025-08-28 15:39:39.382007: Epoch 559 
2025-08-28 15:39:39.390385: Current learning rate: 0.00479 
2025-08-28 15:39:55.819446: train_loss -0.5421 
2025-08-28 15:39:55.819446: val_loss -0.5597 
2025-08-28 15:39:55.827601: Pseudo dice [np.float32(0.7868)] 
2025-08-28 15:39:55.833698: Epoch time: 16.44 s 
2025-08-28 15:39:56.478201:  
2025-08-28 15:39:56.478201: Epoch 560 
2025-08-28 15:39:56.486545: Current learning rate: 0.00478 
2025-08-28 15:40:12.965805: train_loss -0.5251 
2025-08-28 15:40:12.965805: val_loss -0.5768 
2025-08-28 15:40:12.974099: Pseudo dice [np.float32(0.7327)] 
2025-08-28 15:40:12.982195: Epoch time: 16.49 s 
2025-08-28 15:40:12.987926: Yayy! New best EMA pseudo Dice: 0.7251999974250793 
2025-08-28 15:40:13.820898:  
2025-08-28 15:40:13.820898: Epoch 561 
2025-08-28 15:40:13.828886: Current learning rate: 0.00477 
2025-08-28 15:40:30.341166: train_loss -0.523 
2025-08-28 15:40:30.341166: val_loss -0.5038 
2025-08-28 15:40:30.349527: Pseudo dice [np.float32(0.7223)] 
2025-08-28 15:40:30.355026: Epoch time: 16.52 s 
2025-08-28 15:40:31.000520:  
2025-08-28 15:40:31.000520: Epoch 562 
2025-08-28 15:40:31.008549: Current learning rate: 0.00476 
2025-08-28 15:40:47.608448: train_loss -0.5592 
2025-08-28 15:40:47.608448: val_loss -0.4167 
2025-08-28 15:40:47.616770: Pseudo dice [np.float32(0.6881)] 
2025-08-28 15:40:47.624912: Epoch time: 16.61 s 
2025-08-28 15:40:48.267401:  
2025-08-28 15:40:48.267401: Epoch 563 
2025-08-28 15:40:48.275760: Current learning rate: 0.00475 
2025-08-28 15:41:04.704622: train_loss -0.5433 
2025-08-28 15:41:04.704622: val_loss -0.5244 
2025-08-28 15:41:04.713045: Pseudo dice [np.float32(0.7993)] 
2025-08-28 15:41:04.719018: Epoch time: 16.44 s 
2025-08-28 15:41:04.726062: Yayy! New best EMA pseudo Dice: 0.7289999723434448 
2025-08-28 15:41:05.568470:  
2025-08-28 15:41:05.571787: Epoch 564 
2025-08-28 15:41:05.576393: Current learning rate: 0.00474 
2025-08-28 15:41:22.397343: train_loss -0.493 
2025-08-28 15:41:22.397343: val_loss -0.5288 
2025-08-28 15:41:22.408282: Pseudo dice [np.float32(0.7303)] 
2025-08-28 15:41:22.413980: Epoch time: 16.83 s 
2025-08-28 15:41:22.419995: Yayy! New best EMA pseudo Dice: 0.7290999889373779 
2025-08-28 15:41:23.437371:  
2025-08-28 15:41:23.438370: Epoch 565 
2025-08-28 15:41:23.444194: Current learning rate: 0.00473 
2025-08-28 15:41:40.049719: train_loss -0.5378 
2025-08-28 15:41:40.049719: val_loss -0.4747 
2025-08-28 15:41:40.056595: Pseudo dice [np.float32(0.6879)] 
2025-08-28 15:41:40.064745: Epoch time: 16.61 s 
2025-08-28 15:41:40.711488:  
2025-08-28 15:41:40.711488: Epoch 566 
2025-08-28 15:41:40.719764: Current learning rate: 0.00472 
2025-08-28 15:41:57.374644: train_loss -0.5057 
2025-08-28 15:41:57.374644: val_loss -0.5135 
2025-08-28 15:41:57.382243: Pseudo dice [np.float32(0.7383)] 
2025-08-28 15:41:57.391457: Epoch time: 16.66 s 
2025-08-28 15:41:58.037078:  
2025-08-28 15:41:58.037078: Epoch 567 
2025-08-28 15:41:58.041221: Current learning rate: 0.00471 
2025-08-28 15:42:14.503989: train_loss -0.4933 
2025-08-28 15:42:14.507714: val_loss -0.4974 
2025-08-28 15:42:14.516018: Pseudo dice [np.float32(0.8091)] 
2025-08-28 15:42:14.522352: Epoch time: 16.47 s 
2025-08-28 15:42:14.528512: Yayy! New best EMA pseudo Dice: 0.7346000075340271 
2025-08-28 15:42:15.366964:  
2025-08-28 15:42:15.366964: Epoch 568 
2025-08-28 15:42:15.375291: Current learning rate: 0.0047 
2025-08-28 15:42:31.946293: train_loss -0.5822 
2025-08-28 15:42:31.946293: val_loss -0.5007 
2025-08-28 15:42:31.954292: Pseudo dice [np.float32(0.7322)] 
2025-08-28 15:42:31.963313: Epoch time: 16.58 s 
2025-08-28 15:42:32.613238:  
2025-08-28 15:42:32.613238: Epoch 569 
2025-08-28 15:42:32.621634: Current learning rate: 0.00469 
2025-08-28 15:42:49.171963: train_loss -0.5491 
2025-08-28 15:42:49.171963: val_loss -0.5738 
2025-08-28 15:42:49.179831: Pseudo dice [np.float32(0.7844)] 
2025-08-28 15:42:49.188084: Epoch time: 16.56 s 
2025-08-28 15:42:49.194118: Yayy! New best EMA pseudo Dice: 0.7394000291824341 
2025-08-28 15:42:50.030172:  
2025-08-28 15:42:50.030931: Epoch 570 
2025-08-28 15:42:50.038977: Current learning rate: 0.00468 
2025-08-28 15:43:06.593067: train_loss -0.5354 
2025-08-28 15:43:06.593067: val_loss -0.4862 
2025-08-28 15:43:06.601386: Pseudo dice [np.float32(0.7022)] 
2025-08-28 15:43:06.607986: Epoch time: 16.57 s 
2025-08-28 15:43:07.414686:  
2025-08-28 15:43:07.414686: Epoch 571 
2025-08-28 15:43:07.423026: Current learning rate: 0.00467 
2025-08-28 15:43:23.714258: train_loss -0.5385 
2025-08-28 15:43:23.714258: val_loss -0.5015 
2025-08-28 15:43:23.726802: Pseudo dice [np.float32(0.7561)] 
2025-08-28 15:43:23.734004: Epoch time: 16.3 s 
2025-08-28 15:43:24.381596:  
2025-08-28 15:43:24.381596: Epoch 572 
2025-08-28 15:43:24.389987: Current learning rate: 0.00466 
2025-08-28 15:43:40.973358: train_loss -0.4842 
2025-08-28 15:43:40.973358: val_loss -0.4016 
2025-08-28 15:43:40.981776: Pseudo dice [np.float32(0.7056)] 
2025-08-28 15:43:40.989854: Epoch time: 16.6 s 
2025-08-28 15:43:41.644703:  
2025-08-28 15:43:41.644703: Epoch 573 
2025-08-28 15:43:41.653043: Current learning rate: 0.00465 
2025-08-28 15:43:58.073733: train_loss -0.5232 
2025-08-28 15:43:58.073733: val_loss -0.53 
2025-08-28 15:43:58.082449: Pseudo dice [np.float32(0.6617)] 
2025-08-28 15:43:58.087970: Epoch time: 16.43 s 
2025-08-28 15:43:58.749528:  
2025-08-28 15:43:58.749528: Epoch 574 
2025-08-28 15:43:58.757586: Current learning rate: 0.00464 
2025-08-28 15:44:15.278235: train_loss -0.519 
2025-08-28 15:44:15.278235: val_loss -0.5466 
2025-08-28 15:44:15.291029: Pseudo dice [np.float32(0.7694)] 
2025-08-28 15:44:15.297199: Epoch time: 16.53 s 
2025-08-28 15:44:15.958073:  
2025-08-28 15:44:15.958073: Epoch 575 
2025-08-28 15:44:15.966458: Current learning rate: 0.00463 
2025-08-28 15:44:32.253531: train_loss -0.5584 
2025-08-28 15:44:32.253531: val_loss -0.5573 
2025-08-28 15:44:32.261952: Pseudo dice [np.float32(0.7619)] 
2025-08-28 15:44:32.269031: Epoch time: 16.3 s 
2025-08-28 15:44:32.925021:  
2025-08-28 15:44:32.925021: Epoch 576 
2025-08-28 15:44:32.933723: Current learning rate: 0.00462 
2025-08-28 15:44:49.358134: train_loss -0.5375 
2025-08-28 15:44:49.358134: val_loss -0.417 
2025-08-28 15:44:49.366759: Pseudo dice [np.float32(0.6847)] 
2025-08-28 15:44:49.374808: Epoch time: 16.44 s 
2025-08-28 15:44:50.029694:  
2025-08-28 15:44:50.029694: Epoch 577 
2025-08-28 15:44:50.038034: Current learning rate: 0.00461 
2025-08-28 15:45:06.825895: train_loss -0.5252 
2025-08-28 15:45:06.829625: val_loss -0.5388 
2025-08-28 15:45:06.834190: Pseudo dice [np.float32(0.6989)] 
2025-08-28 15:45:06.843116: Epoch time: 16.8 s 
2025-08-28 15:45:07.655526:  
2025-08-28 15:45:07.655526: Epoch 578 
2025-08-28 15:45:07.663915: Current learning rate: 0.0046 
2025-08-28 15:45:23.932262: train_loss -0.5183 
2025-08-28 15:45:23.934259: val_loss -0.4937 
2025-08-28 15:45:23.942973: Pseudo dice [np.float32(0.7489)] 
2025-08-28 15:45:23.949642: Epoch time: 16.28 s 
2025-08-28 15:45:24.609994:  
2025-08-28 15:45:24.609994: Epoch 579 
2025-08-28 15:45:24.618406: Current learning rate: 0.00459 
2025-08-28 15:45:40.021214: train_loss -0.516 
2025-08-28 15:45:40.021214: val_loss -0.582 
2025-08-28 15:45:40.029536: Pseudo dice [np.float32(0.7258)] 
2025-08-28 15:45:40.034863: Epoch time: 15.41 s 
2025-08-28 15:45:40.692805:  
2025-08-28 15:45:40.692805: Epoch 580 
2025-08-28 15:45:40.701141: Current learning rate: 0.00458 
2025-08-28 15:45:56.166504: train_loss -0.5404 
2025-08-28 15:45:56.166504: val_loss -0.5808 
2025-08-28 15:45:56.174878: Pseudo dice [np.float32(0.7452)] 
2025-08-28 15:45:56.180956: Epoch time: 15.47 s 
2025-08-28 15:45:56.837950:  
2025-08-28 15:45:56.837950: Epoch 581 
2025-08-28 15:45:56.848211: Current learning rate: 0.00457 
2025-08-28 15:46:10.856309: train_loss -0.5066 
2025-08-28 15:46:10.856309: val_loss -0.4719 
2025-08-28 15:46:10.864491: Pseudo dice [np.float32(0.7043)] 
2025-08-28 15:46:10.872781: Epoch time: 14.02 s 
2025-08-28 15:46:11.520384:  
2025-08-28 15:46:11.520384: Epoch 582 
2025-08-28 15:46:11.530386: Current learning rate: 0.00456 
2025-08-28 15:46:25.370755: train_loss -0.5718 
2025-08-28 15:46:25.370755: val_loss -0.4231 
2025-08-28 15:46:25.378981: Pseudo dice [np.float32(0.7093)] 
2025-08-28 15:46:25.385948: Epoch time: 13.85 s 
2025-08-28 15:46:26.017096:  
2025-08-28 15:46:26.017096: Epoch 583 
2025-08-28 15:46:26.025452: Current learning rate: 0.00455 
2025-08-28 15:46:40.014541: train_loss -0.5238 
2025-08-28 15:46:40.014541: val_loss -0.5156 
2025-08-28 15:46:40.022779: Pseudo dice [np.float32(0.6945)] 
2025-08-28 15:46:40.031715: Epoch time: 14.0 s 
2025-08-28 15:46:40.816616:  
2025-08-28 15:46:40.816616: Epoch 584 
2025-08-28 15:46:40.824684: Current learning rate: 0.00454 
2025-08-28 15:46:54.927530: train_loss -0.5092 
2025-08-28 15:46:54.927530: val_loss -0.5117 
2025-08-28 15:46:54.935959: Pseudo dice [np.float32(0.6885)] 
2025-08-28 15:46:54.941318: Epoch time: 14.11 s 
2025-08-28 15:46:55.585223:  
2025-08-28 15:46:55.585223: Epoch 585 
2025-08-28 15:46:55.593566: Current learning rate: 0.00453 
2025-08-28 15:47:09.289517: train_loss -0.5659 
2025-08-28 15:47:09.289517: val_loss -0.5359 
2025-08-28 15:47:09.298040: Pseudo dice [np.float32(0.7872)] 
2025-08-28 15:47:09.306112: Epoch time: 13.71 s 
2025-08-28 15:47:09.944320:  
2025-08-28 15:47:09.945398: Epoch 586 
2025-08-28 15:47:09.953744: Current learning rate: 0.00452 
2025-08-28 15:47:23.921516: train_loss -0.5446 
2025-08-28 15:47:23.921516: val_loss -0.5761 
2025-08-28 15:47:23.931474: Pseudo dice [np.float32(0.7761)] 
2025-08-28 15:47:23.937034: Epoch time: 13.98 s 
2025-08-28 15:47:24.576684:  
2025-08-28 15:47:24.576684: Epoch 587 
2025-08-28 15:47:24.585028: Current learning rate: 0.00451 
2025-08-28 15:47:38.331499: train_loss -0.5323 
2025-08-28 15:47:38.331499: val_loss -0.5388 
2025-08-28 15:47:38.339335: Pseudo dice [np.float32(0.73)] 
2025-08-28 15:47:38.346387: Epoch time: 13.76 s 
2025-08-28 15:47:38.978570:  
2025-08-28 15:47:38.978570: Epoch 588 
2025-08-28 15:47:38.986941: Current learning rate: 0.0045 
2025-08-28 15:47:52.953879: train_loss -0.5491 
2025-08-28 15:47:52.953879: val_loss -0.417 
2025-08-28 15:47:52.962521: Pseudo dice [np.float32(0.6546)] 
2025-08-28 15:47:52.968158: Epoch time: 13.98 s 
2025-08-28 15:47:53.601479:  
2025-08-28 15:47:53.601479: Epoch 589 
2025-08-28 15:47:53.609831: Current learning rate: 0.00449 
2025-08-28 15:48:07.410168: train_loss -0.5366 
2025-08-28 15:48:07.414175: val_loss -0.4824 
2025-08-28 15:48:07.422539: Pseudo dice [np.float32(0.755)] 
2025-08-28 15:48:07.427918: Epoch time: 13.81 s 
2025-08-28 15:48:08.061781:  
2025-08-28 15:48:08.061781: Epoch 590 
2025-08-28 15:48:08.070100: Current learning rate: 0.00448 
2025-08-28 15:48:22.115439: train_loss -0.535 
2025-08-28 15:48:22.116329: val_loss -0.4629 
2025-08-28 15:48:22.124706: Pseudo dice [np.float32(0.6381)] 
2025-08-28 15:48:22.131048: Epoch time: 14.05 s 
2025-08-28 15:48:22.933794:  
2025-08-28 15:48:22.933794: Epoch 591 
2025-08-28 15:48:22.942218: Current learning rate: 0.00447 
2025-08-28 15:48:37.019278: train_loss -0.497 
2025-08-28 15:48:37.019278: val_loss -0.5094 
2025-08-28 15:48:37.027100: Pseudo dice [np.float32(0.6702)] 
2025-08-28 15:48:37.033062: Epoch time: 14.09 s 
2025-08-28 15:48:37.670484:  
2025-08-28 15:48:37.670484: Epoch 592 
2025-08-28 15:48:37.678835: Current learning rate: 0.00446 
2025-08-28 15:48:52.939196: train_loss -0.5579 
2025-08-28 15:48:52.939196: val_loss -0.5144 
2025-08-28 15:48:52.947120: Pseudo dice [np.float32(0.7404)] 
2025-08-28 15:48:52.956110: Epoch time: 15.27 s 
2025-08-28 15:48:53.595024:  
2025-08-28 15:48:53.595024: Epoch 593 
2025-08-28 15:48:53.603061: Current learning rate: 0.00445 
2025-08-28 15:49:08.337515: train_loss -0.5053 
2025-08-28 15:49:08.337515: val_loss -0.4659 
2025-08-28 15:49:08.345921: Pseudo dice [np.float32(0.7066)] 
2025-08-28 15:49:08.355023: Epoch time: 14.74 s 
2025-08-28 15:49:08.989301:  
2025-08-28 15:49:08.989301: Epoch 594 
2025-08-28 15:49:08.997763: Current learning rate: 0.00444 
2025-08-28 15:49:23.832137: train_loss -0.5187 
2025-08-28 15:49:23.836318: val_loss -0.5567 
2025-08-28 15:49:23.844705: Pseudo dice [np.float32(0.7702)] 
2025-08-28 15:49:23.852734: Epoch time: 14.84 s 
2025-08-28 15:49:24.483887:  
2025-08-28 15:49:24.486981: Epoch 595 
2025-08-28 15:49:24.492190: Current learning rate: 0.00443 
2025-08-28 15:49:40.219931: train_loss -0.5446 
2025-08-28 15:49:40.219931: val_loss -0.4946 
2025-08-28 15:49:40.230213: Pseudo dice [np.float32(0.7224)] 
2025-08-28 15:49:40.235994: Epoch time: 15.74 s 
2025-08-28 15:49:40.875282:  
2025-08-28 15:49:40.875282: Epoch 596 
2025-08-28 15:49:40.883550: Current learning rate: 0.00442 
2025-08-28 15:49:55.389145: train_loss -0.5349 
2025-08-28 15:49:55.389145: val_loss -0.6075 
2025-08-28 15:49:55.397020: Pseudo dice [np.float32(0.7557)] 
2025-08-28 15:49:55.404347: Epoch time: 14.51 s 
2025-08-28 15:49:56.197817:  
2025-08-28 15:49:56.197817: Epoch 597 
2025-08-28 15:49:56.203030: Current learning rate: 0.00441 
2025-08-28 15:50:10.866600: train_loss -0.5555 
2025-08-28 15:50:10.870773: val_loss -0.5035 
2025-08-28 15:50:10.879335: Pseudo dice [np.float32(0.7527)] 
2025-08-28 15:50:10.886473: Epoch time: 14.67 s 
2025-08-28 15:50:11.526680:  
2025-08-28 15:50:11.526680: Epoch 598 
2025-08-28 15:50:11.535025: Current learning rate: 0.0044 
2025-08-28 15:50:26.637385: train_loss -0.5312 
2025-08-28 15:50:26.637385: val_loss -0.5296 
2025-08-28 15:50:26.644870: Pseudo dice [np.float32(0.7378)] 
2025-08-28 15:50:26.651884: Epoch time: 15.11 s 
2025-08-28 15:50:27.287195:  
2025-08-28 15:50:27.288300: Epoch 599 
2025-08-28 15:50:27.295484: Current learning rate: 0.00439 
2025-08-28 15:50:42.047838: train_loss -0.5374 
2025-08-28 15:50:42.047838: val_loss -0.5379 
2025-08-28 15:50:42.057788: Pseudo dice [np.float32(0.7558)] 
2025-08-28 15:50:42.064354: Epoch time: 14.76 s 
2025-08-28 15:50:42.883012:  
2025-08-28 15:50:42.883012: Epoch 600 
2025-08-28 15:50:42.891293: Current learning rate: 0.00438 
2025-08-28 15:50:58.188929: train_loss -0.561 
2025-08-28 15:50:58.188929: val_loss -0.5571 
2025-08-28 15:50:58.197166: Pseudo dice [np.float32(0.719)] 
2025-08-28 15:50:58.205260: Epoch time: 15.31 s 
2025-08-28 15:50:58.847821:  
2025-08-28 15:50:58.848912: Epoch 601 
2025-08-28 15:50:58.856202: Current learning rate: 0.00437 
2025-08-28 15:51:13.954585: train_loss -0.5598 
2025-08-28 15:51:13.954585: val_loss -0.4721 
2025-08-28 15:51:13.964610: Pseudo dice [np.float32(0.7403)] 
2025-08-28 15:51:13.968872: Epoch time: 15.11 s 
2025-08-28 15:51:14.606349:  
2025-08-28 15:51:14.606349: Epoch 602 
2025-08-28 15:51:14.616258: Current learning rate: 0.00436 
2025-08-28 15:51:29.670256: train_loss -0.5527 
2025-08-28 15:51:29.670256: val_loss -0.4985 
2025-08-28 15:51:29.678599: Pseudo dice [np.float32(0.7289)] 
2025-08-28 15:51:29.684669: Epoch time: 15.06 s 
2025-08-28 15:51:30.325300:  
2025-08-28 15:51:30.326299: Epoch 603 
2025-08-28 15:51:30.334496: Current learning rate: 0.00435 
2025-08-28 15:51:44.936125: train_loss -0.5458 
2025-08-28 15:51:44.937159: val_loss -0.5963 
2025-08-28 15:51:44.948392: Pseudo dice [np.float32(0.7641)] 
2025-08-28 15:51:44.958326: Epoch time: 14.61 s 
2025-08-28 15:51:45.841638:  
2025-08-28 15:51:45.844728: Epoch 604 
2025-08-28 15:51:45.850002: Current learning rate: 0.00434 
2025-08-28 15:52:01.047741: train_loss -0.5217 
2025-08-28 15:52:01.047741: val_loss -0.5154 
2025-08-28 15:52:01.056042: Pseudo dice [np.float32(0.7395)] 
2025-08-28 15:52:01.065284: Epoch time: 15.21 s 
2025-08-28 15:52:01.707470:  
2025-08-28 15:52:01.707470: Epoch 605 
2025-08-28 15:52:01.715838: Current learning rate: 0.00433 
2025-08-28 15:52:16.742229: train_loss -0.5414 
2025-08-28 15:52:16.742229: val_loss -0.4892 
2025-08-28 15:52:16.750597: Pseudo dice [np.float32(0.7191)] 
2025-08-28 15:52:16.759752: Epoch time: 15.04 s 
2025-08-28 15:52:17.410698:  
2025-08-28 15:52:17.411042: Epoch 606 
2025-08-28 15:52:17.419021: Current learning rate: 0.00432 
2025-08-28 15:52:32.245428: train_loss -0.4982 
2025-08-28 15:52:32.249467: val_loss -0.518 
2025-08-28 15:52:32.257452: Pseudo dice [np.float32(0.734)] 
2025-08-28 15:52:32.261958: Epoch time: 14.84 s 
2025-08-28 15:52:32.900029:  
2025-08-28 15:52:32.901055: Epoch 607 
2025-08-28 15:52:32.908395: Current learning rate: 0.00431 
2025-08-28 15:52:48.436774: train_loss -0.5565 
2025-08-28 15:52:48.436774: val_loss -0.5369 
2025-08-28 15:52:48.444977: Pseudo dice [np.float32(0.7324)] 
2025-08-28 15:52:48.450717: Epoch time: 15.54 s 
2025-08-28 15:52:49.083936:  
2025-08-28 15:52:49.083936: Epoch 608 
2025-08-28 15:52:49.095448: Current learning rate: 0.0043 
2025-08-28 15:53:04.494879: train_loss -0.5227 
2025-08-28 15:53:04.494879: val_loss -0.5078 
2025-08-28 15:53:04.505126: Pseudo dice [np.float32(0.7351)] 
2025-08-28 15:53:04.510758: Epoch time: 15.41 s 
2025-08-28 15:53:05.149975:  
2025-08-28 15:53:05.149975: Epoch 609 
2025-08-28 15:53:05.158923: Current learning rate: 0.00429 
2025-08-28 15:53:20.827378: train_loss -0.5359 
2025-08-28 15:53:20.827378: val_loss -0.5784 
2025-08-28 15:53:20.835402: Pseudo dice [np.float32(0.7472)] 
2025-08-28 15:53:20.844513: Epoch time: 15.68 s 
2025-08-28 15:53:21.494404:  
2025-08-28 15:53:21.494404: Epoch 610 
2025-08-28 15:53:21.499661: Current learning rate: 0.00429 
2025-08-28 15:53:35.896549: train_loss -0.554 
2025-08-28 15:53:35.896549: val_loss -0.5084 
2025-08-28 15:53:35.906159: Pseudo dice [np.float32(0.772)] 
2025-08-28 15:53:35.910476: Epoch time: 14.41 s 
2025-08-28 15:53:36.556344:  
2025-08-28 15:53:36.556344: Epoch 611 
2025-08-28 15:53:36.564691: Current learning rate: 0.00428 
2025-08-28 15:53:51.658131: train_loss -0.4817 
2025-08-28 15:53:51.658131: val_loss -0.6039 
2025-08-28 15:53:51.666467: Pseudo dice [np.float32(0.7832)] 
2025-08-28 15:53:51.672082: Epoch time: 15.1 s 
2025-08-28 15:53:51.678158: Yayy! New best EMA pseudo Dice: 0.7427999973297119 
2025-08-28 15:53:52.497277:  
2025-08-28 15:53:52.497277: Epoch 612 
2025-08-28 15:53:52.506143: Current learning rate: 0.00427 
2025-08-28 15:54:07.290117: train_loss -0.5572 
2025-08-28 15:54:07.290117: val_loss -0.4893 
2025-08-28 15:54:07.298719: Pseudo dice [np.float32(0.7296)] 
2025-08-28 15:54:07.307601: Epoch time: 14.79 s 
2025-08-28 15:54:07.946044:  
2025-08-28 15:54:07.946044: Epoch 613 
2025-08-28 15:54:07.954361: Current learning rate: 0.00426 
2025-08-28 15:54:21.971780: train_loss -0.5614 
2025-08-28 15:54:21.971780: val_loss -0.4536 
2025-08-28 15:54:21.979794: Pseudo dice [np.float32(0.6912)] 
2025-08-28 15:54:21.989022: Epoch time: 14.03 s 
2025-08-28 15:54:22.623211:  
2025-08-28 15:54:22.623211: Epoch 614 
2025-08-28 15:54:22.632443: Current learning rate: 0.00425 
2025-08-28 15:54:36.490501: train_loss -0.5426 
2025-08-28 15:54:36.490501: val_loss -0.5384 
2025-08-28 15:54:36.498446: Pseudo dice [np.float32(0.7702)] 
2025-08-28 15:54:36.503774: Epoch time: 13.87 s 
2025-08-28 15:54:37.141847:  
2025-08-28 15:54:37.144911: Epoch 615 
2025-08-28 15:54:37.150189: Current learning rate: 0.00424 
2025-08-28 15:54:51.001134: train_loss -0.5567 
2025-08-28 15:54:51.001134: val_loss -0.5158 
2025-08-28 15:54:51.008756: Pseudo dice [np.float32(0.7073)] 
2025-08-28 15:54:51.017816: Epoch time: 13.86 s 
2025-08-28 15:54:51.656302:  
2025-08-28 15:54:51.656302: Epoch 616 
2025-08-28 15:54:51.664679: Current learning rate: 0.00423 
2025-08-28 15:55:05.665720: train_loss -0.5594 
2025-08-28 15:55:05.665720: val_loss -0.5138 
2025-08-28 15:55:05.673420: Pseudo dice [np.float32(0.7321)] 
2025-08-28 15:55:05.681495: Epoch time: 14.01 s 
2025-08-28 15:55:06.466982:  
2025-08-28 15:55:06.466982: Epoch 617 
2025-08-28 15:55:06.475287: Current learning rate: 0.00422 
2025-08-28 15:55:20.450856: train_loss -0.5109 
2025-08-28 15:55:20.450856: val_loss -0.4382 
2025-08-28 15:55:20.459677: Pseudo dice [np.float32(0.6448)] 
2025-08-28 15:55:20.468386: Epoch time: 13.98 s 
2025-08-28 15:55:21.106579:  
2025-08-28 15:55:21.106579: Epoch 618 
2025-08-28 15:55:21.114914: Current learning rate: 0.00421 
2025-08-28 15:55:34.961205: train_loss -0.5352 
2025-08-28 15:55:34.961205: val_loss -0.5 
2025-08-28 15:55:34.970870: Pseudo dice [np.float32(0.6995)] 
2025-08-28 15:55:34.975221: Epoch time: 13.85 s 
2025-08-28 15:55:35.625225:  
2025-08-28 15:55:35.625225: Epoch 619 
2025-08-28 15:55:35.633527: Current learning rate: 0.0042 
2025-08-28 15:55:49.821793: train_loss -0.5563 
2025-08-28 15:55:49.821793: val_loss -0.5209 
2025-08-28 15:55:49.829978: Pseudo dice [np.float32(0.7543)] 
2025-08-28 15:55:49.837898: Epoch time: 14.2 s 
2025-08-28 15:55:50.476456:  
2025-08-28 15:55:50.477525: Epoch 620 
2025-08-28 15:55:50.484797: Current learning rate: 0.00419 
2025-08-28 15:56:04.307186: train_loss -0.5026 
2025-08-28 15:56:04.307186: val_loss -0.5137 
2025-08-28 15:56:04.315545: Pseudo dice [np.float32(0.665)] 
2025-08-28 15:56:04.322255: Epoch time: 13.83 s 
2025-08-28 15:56:04.958638:  
2025-08-28 15:56:04.958638: Epoch 621 
2025-08-28 15:56:04.967002: Current learning rate: 0.00418 
2025-08-28 15:56:18.771362: train_loss -0.5264 
2025-08-28 15:56:18.771362: val_loss -0.6254 
2025-08-28 15:56:18.779996: Pseudo dice [np.float32(0.813)] 
2025-08-28 15:56:18.786732: Epoch time: 13.81 s 
2025-08-28 15:56:19.438645:  
2025-08-28 15:56:19.438645: Epoch 622 
2025-08-28 15:56:19.443960: Current learning rate: 0.00417 
2025-08-28 15:56:34.608404: train_loss -0.561 
2025-08-28 15:56:34.608404: val_loss -0.5208 
2025-08-28 15:56:34.616639: Pseudo dice [np.float32(0.6998)] 
2025-08-28 15:56:34.622182: Epoch time: 15.17 s 
2025-08-28 15:56:35.300390:  
2025-08-28 15:56:35.300390: Epoch 623 
2025-08-28 15:56:35.308748: Current learning rate: 0.00416 
2025-08-28 15:56:50.674134: train_loss -0.5452 
2025-08-28 15:56:50.674134: val_loss -0.549 
2025-08-28 15:56:50.682417: Pseudo dice [np.float32(0.7912)] 
2025-08-28 15:56:50.689720: Epoch time: 15.38 s 
2025-08-28 15:56:51.526717:  
2025-08-28 15:56:51.526717: Epoch 624 
2025-08-28 15:56:51.534373: Current learning rate: 0.00415 
2025-08-28 15:57:07.165742: train_loss -0.5463 
2025-08-28 15:57:07.165742: val_loss -0.5098 
2025-08-28 15:57:07.176471: Pseudo dice [np.float32(0.6638)] 
2025-08-28 15:57:07.182153: Epoch time: 15.64 s 
2025-08-28 15:57:07.858980:  
2025-08-28 15:57:07.858980: Epoch 625 
2025-08-28 15:57:07.867336: Current learning rate: 0.00414 
2025-08-28 15:57:23.490860: train_loss -0.5483 
2025-08-28 15:57:23.494665: val_loss -0.5198 
2025-08-28 15:57:23.502675: Pseudo dice [np.float32(0.7303)] 
2025-08-28 15:57:23.510664: Epoch time: 15.63 s 
2025-08-28 15:57:24.221288:  
2025-08-28 15:57:24.221288: Epoch 626 
2025-08-28 15:57:24.229515: Current learning rate: 0.00413 
2025-08-28 15:57:39.760011: train_loss -0.5427 
2025-08-28 15:57:39.760569: val_loss -0.572 
2025-08-28 15:57:39.765146: Pseudo dice [np.float32(0.7612)] 
2025-08-28 15:57:39.774462: Epoch time: 15.54 s 
2025-08-28 15:57:40.481842:  
2025-08-28 15:57:40.482298: Epoch 627 
2025-08-28 15:57:40.492262: Current learning rate: 0.00412 
2025-08-28 15:57:56.031188: train_loss -0.5618 
2025-08-28 15:57:56.031188: val_loss -0.5562 
2025-08-28 15:57:56.039350: Pseudo dice [np.float32(0.7449)] 
2025-08-28 15:57:56.047381: Epoch time: 15.55 s 
2025-08-28 15:57:56.720248:  
2025-08-28 15:57:56.720248: Epoch 628 
2025-08-28 15:57:56.727525: Current learning rate: 0.00411 
2025-08-28 15:58:12.306155: train_loss -0.5551 
2025-08-28 15:58:12.306155: val_loss -0.4874 
2025-08-28 15:58:12.318121: Pseudo dice [np.float32(0.7308)] 
2025-08-28 15:58:12.323137: Epoch time: 15.59 s 
2025-08-28 15:58:13.002094:  
2025-08-28 15:58:13.003228: Epoch 629 
2025-08-28 15:58:13.010427: Current learning rate: 0.0041 
2025-08-28 15:58:28.426143: train_loss -0.5606 
2025-08-28 15:58:28.426143: val_loss -0.4822 
2025-08-28 15:58:28.434557: Pseudo dice [np.float32(0.6533)] 
2025-08-28 15:58:28.440246: Epoch time: 15.43 s 
2025-08-28 15:58:29.278052:  
2025-08-28 15:58:29.278052: Epoch 630 
2025-08-28 15:58:29.286113: Current learning rate: 0.00409 
2025-08-28 15:58:44.670648: train_loss -0.5879 
2025-08-28 15:58:44.671227: val_loss -0.5664 
2025-08-28 15:58:44.675427: Pseudo dice [np.float32(0.7785)] 
2025-08-28 15:58:44.684684: Epoch time: 15.39 s 
2025-08-28 15:58:45.369569:  
2025-08-28 15:58:45.369569: Epoch 631 
2025-08-28 15:58:45.377198: Current learning rate: 0.00408 
2025-08-28 15:59:00.612116: train_loss -0.5147 
2025-08-28 15:59:00.612116: val_loss -0.6124 
2025-08-28 15:59:00.620751: Pseudo dice [np.float32(0.756)] 
2025-08-28 15:59:00.626363: Epoch time: 15.24 s 
2025-08-28 15:59:01.263833:  
2025-08-28 15:59:01.266912: Epoch 632 
2025-08-28 15:59:01.272545: Current learning rate: 0.00407 
2025-08-28 15:59:16.569776: train_loss -0.5133 
2025-08-28 15:59:16.569776: val_loss -0.575 
2025-08-28 15:59:16.582211: Pseudo dice [np.float32(0.6994)] 
2025-08-28 15:59:16.588405: Epoch time: 15.31 s 
2025-08-28 15:59:17.225573:  
2025-08-28 15:59:17.225573: Epoch 633 
2025-08-28 15:59:17.233943: Current learning rate: 0.00406 
2025-08-28 15:59:32.202235: train_loss -0.5448 
2025-08-28 15:59:32.202235: val_loss -0.5238 
2025-08-28 15:59:32.210580: Pseudo dice [np.float32(0.7322)] 
2025-08-28 15:59:32.215724: Epoch time: 14.98 s 
2025-08-28 15:59:32.870389:  
2025-08-28 15:59:32.870769: Epoch 634 
2025-08-28 15:59:32.877632: Current learning rate: 0.00405 
2025-08-28 15:59:48.572671: train_loss -0.5452 
2025-08-28 15:59:48.576646: val_loss -0.5438 
2025-08-28 15:59:48.581112: Pseudo dice [np.float32(0.7506)] 
2025-08-28 15:59:48.590476: Epoch time: 15.71 s 
2025-08-28 15:59:49.240895:  
2025-08-28 15:59:49.240895: Epoch 635 
2025-08-28 15:59:49.250030: Current learning rate: 0.00404 
2025-08-28 16:00:04.163588: train_loss -0.5636 
2025-08-28 16:00:04.163588: val_loss -0.5423 
2025-08-28 16:00:04.179070: Pseudo dice [np.float32(0.7785)] 
2025-08-28 16:00:04.185633: Epoch time: 14.92 s 
2025-08-28 16:00:04.835626:  
2025-08-28 16:00:04.835626: Epoch 636 
2025-08-28 16:00:04.843944: Current learning rate: 0.00403 
2025-08-28 16:00:20.270777: train_loss -0.5674 
2025-08-28 16:00:20.270777: val_loss -0.5852 
2025-08-28 16:00:20.282665: Pseudo dice [np.float32(0.7521)] 
2025-08-28 16:00:20.288297: Epoch time: 15.44 s 
2025-08-28 16:00:21.104964:  
2025-08-28 16:00:21.104964: Epoch 637 
2025-08-28 16:00:21.113309: Current learning rate: 0.00402 
2025-08-28 16:00:36.632963: train_loss -0.5181 
2025-08-28 16:00:36.637109: val_loss -0.5172 
2025-08-28 16:00:36.641557: Pseudo dice [np.float32(0.7414)] 
2025-08-28 16:00:36.650405: Epoch time: 15.53 s 
2025-08-28 16:00:37.296122:  
2025-08-28 16:00:37.297218: Epoch 638 
2025-08-28 16:00:37.304454: Current learning rate: 0.00401 
2025-08-28 16:00:52.073383: train_loss -0.5476 
2025-08-28 16:00:52.077137: val_loss -0.5324 
2025-08-28 16:00:52.081711: Pseudo dice [np.float32(0.8121)] 
2025-08-28 16:00:52.090570: Epoch time: 14.78 s 
2025-08-28 16:00:52.096630: Yayy! New best EMA pseudo Dice: 0.7454000115394592 
2025-08-28 16:00:52.921539:  
2025-08-28 16:00:52.921539: Epoch 639 
2025-08-28 16:00:52.929832: Current learning rate: 0.004 
2025-08-28 16:01:08.260589: train_loss -0.5081 
2025-08-28 16:01:08.260589: val_loss -0.5467 
2025-08-28 16:01:08.270352: Pseudo dice [np.float32(0.7194)] 
2025-08-28 16:01:08.275624: Epoch time: 15.34 s 
2025-08-28 16:01:08.920437:  
2025-08-28 16:01:08.920437: Epoch 640 
2025-08-28 16:01:08.930849: Current learning rate: 0.00399 
2025-08-28 16:01:22.749810: train_loss -0.5512 
2025-08-28 16:01:22.749810: val_loss -0.5631 
2025-08-28 16:01:22.758160: Pseudo dice [np.float32(0.7187)] 
2025-08-28 16:01:22.767260: Epoch time: 13.83 s 
2025-08-28 16:01:23.425492:  
2025-08-28 16:01:23.425492: Epoch 641 
2025-08-28 16:01:23.433768: Current learning rate: 0.00398 
2025-08-28 16:01:38.915937: train_loss -0.5154 
2025-08-28 16:01:38.915937: val_loss -0.5167 
2025-08-28 16:01:38.924303: Pseudo dice [np.float32(0.7283)] 
2025-08-28 16:01:38.934124: Epoch time: 15.49 s 
2025-08-28 16:01:39.588544:  
2025-08-28 16:01:39.588544: Epoch 642 
2025-08-28 16:01:39.596909: Current learning rate: 0.00397 
2025-08-28 16:01:54.502350: train_loss -0.5416 
2025-08-28 16:01:54.502350: val_loss -0.4752 
2025-08-28 16:01:54.510696: Pseudo dice [np.float32(0.6674)] 
2025-08-28 16:01:54.520837: Epoch time: 14.91 s 
2025-08-28 16:01:55.319833:  
2025-08-28 16:01:55.319833: Epoch 643 
2025-08-28 16:01:55.328174: Current learning rate: 0.00396 
2025-08-28 16:02:10.718855: train_loss -0.5291 
2025-08-28 16:02:10.718855: val_loss -0.4722 
2025-08-28 16:02:10.731068: Pseudo dice [np.float32(0.6448)] 
2025-08-28 16:02:10.736535: Epoch time: 15.4 s 
2025-08-28 16:02:11.377524:  
2025-08-28 16:02:11.377524: Epoch 644 
2025-08-28 16:02:11.386395: Current learning rate: 0.00395 
2025-08-28 16:02:26.475929: train_loss -0.5097 
2025-08-28 16:02:26.475929: val_loss -0.4931 
2025-08-28 16:02:26.484591: Pseudo dice [np.float32(0.7442)] 
2025-08-28 16:02:26.490156: Epoch time: 15.1 s 
2025-08-28 16:02:27.143913:  
2025-08-28 16:02:27.143913: Epoch 645 
2025-08-28 16:02:27.152261: Current learning rate: 0.00394 
2025-08-28 16:02:42.066513: train_loss -0.5741 
2025-08-28 16:02:42.070898: val_loss -0.5311 
2025-08-28 16:02:42.075135: Pseudo dice [np.float32(0.7873)] 
2025-08-28 16:02:42.084051: Epoch time: 14.92 s 
2025-08-28 16:02:42.717157:  
2025-08-28 16:02:42.717157: Epoch 646 
2025-08-28 16:02:42.725523: Current learning rate: 0.00393 
2025-08-28 16:02:58.074149: train_loss -0.5286 
2025-08-28 16:02:58.074149: val_loss -0.6003 
2025-08-28 16:02:58.084464: Pseudo dice [np.float32(0.7623)] 
2025-08-28 16:02:58.091501: Epoch time: 15.36 s 
2025-08-28 16:02:58.733148:  
2025-08-28 16:02:58.733148: Epoch 647 
2025-08-28 16:02:58.741478: Current learning rate: 0.00392 
2025-08-28 16:03:14.256980: train_loss -0.5513 
2025-08-28 16:03:14.256980: val_loss -0.5123 
2025-08-28 16:03:14.269534: Pseudo dice [np.float32(0.7423)] 
2025-08-28 16:03:14.275407: Epoch time: 15.52 s 
2025-08-28 16:03:14.911815:  
2025-08-28 16:03:14.911815: Epoch 648 
2025-08-28 16:03:14.920055: Current learning rate: 0.00391 
2025-08-28 16:03:30.247923: train_loss -0.5345 
2025-08-28 16:03:30.247923: val_loss -0.4856 
2025-08-28 16:03:30.259906: Pseudo dice [np.float32(0.7503)] 
2025-08-28 16:03:30.265421: Epoch time: 15.34 s 
2025-08-28 16:03:30.911136:  
2025-08-28 16:03:30.911136: Epoch 649 
2025-08-28 16:03:30.919684: Current learning rate: 0.0039 
2025-08-28 16:03:46.343192: train_loss -0.5229 
2025-08-28 16:03:46.343192: val_loss -0.5201 
2025-08-28 16:03:46.351507: Pseudo dice [np.float32(0.7531)] 
2025-08-28 16:03:46.357432: Epoch time: 15.43 s 
2025-08-28 16:03:47.369195:  
2025-08-28 16:03:47.373397: Epoch 650 
2025-08-28 16:03:47.377536: Current learning rate: 0.00389 
2025-08-28 16:04:02.692888: train_loss -0.5613 
2025-08-28 16:04:02.692888: val_loss -0.5844 
2025-08-28 16:04:02.701161: Pseudo dice [np.float32(0.7551)] 
2025-08-28 16:04:02.710010: Epoch time: 15.32 s 
2025-08-28 16:04:03.347645:  
2025-08-28 16:04:03.347645: Epoch 651 
2025-08-28 16:04:03.355978: Current learning rate: 0.00388 
2025-08-28 16:04:18.579825: train_loss -0.5483 
2025-08-28 16:04:18.579825: val_loss -0.5011 
2025-08-28 16:04:18.588113: Pseudo dice [np.float32(0.682)] 
2025-08-28 16:04:18.596741: Epoch time: 15.23 s 
2025-08-28 16:04:19.238544:  
2025-08-28 16:04:19.238544: Epoch 652 
2025-08-28 16:04:19.246841: Current learning rate: 0.00387 
2025-08-28 16:04:34.202202: train_loss -0.5229 
2025-08-28 16:04:34.202202: val_loss -0.4704 
2025-08-28 16:04:34.207619: Pseudo dice [np.float32(0.762)] 
2025-08-28 16:04:34.216625: Epoch time: 14.96 s 
2025-08-28 16:04:34.854087:  
2025-08-28 16:04:34.854087: Epoch 653 
2025-08-28 16:04:34.865060: Current learning rate: 0.00386 
2025-08-28 16:04:50.374006: train_loss -0.5458 
2025-08-28 16:04:50.374006: val_loss -0.5588 
2025-08-28 16:04:50.382855: Pseudo dice [np.float32(0.7341)] 
2025-08-28 16:04:50.388147: Epoch time: 15.52 s 
2025-08-28 16:04:51.028859:  
2025-08-28 16:04:51.028859: Epoch 654 
2025-08-28 16:04:51.036928: Current learning rate: 0.00385 
2025-08-28 16:05:05.939824: train_loss -0.5531 
2025-08-28 16:05:05.939824: val_loss -0.548 
2025-08-28 16:05:05.947654: Pseudo dice [np.float32(0.7759)] 
2025-08-28 16:05:05.953654: Epoch time: 14.91 s 
2025-08-28 16:05:06.595223:  
2025-08-28 16:05:06.595223: Epoch 655 
2025-08-28 16:05:06.603561: Current learning rate: 0.00384 
2025-08-28 16:05:22.297285: train_loss -0.564 
2025-08-28 16:05:22.297285: val_loss -0.5861 
2025-08-28 16:05:22.305706: Pseudo dice [np.float32(0.7613)] 
2025-08-28 16:05:22.315270: Epoch time: 15.7 s 
2025-08-28 16:05:22.995843:  
2025-08-28 16:05:23.012229: Epoch 656 
2025-08-28 16:05:23.028103: Current learning rate: 0.00383 
2025-08-28 16:05:38.142667: train_loss -0.5869 
2025-08-28 16:05:38.151979: val_loss -0.5037 
2025-08-28 16:05:38.159263: Pseudo dice [np.float32(0.7486)] 
2025-08-28 16:05:38.164371: Epoch time: 15.15 s 
2025-08-28 16:05:39.008657:  
2025-08-28 16:05:39.016041: Epoch 657 
2025-08-28 16:05:39.022153: Current learning rate: 0.00382 
2025-08-28 16:05:54.644032: train_loss -0.5149 
2025-08-28 16:05:54.650465: val_loss -0.561 
2025-08-28 16:05:54.654579: Pseudo dice [np.float32(0.7701)] 
2025-08-28 16:05:54.663598: Epoch time: 15.64 s 
2025-08-28 16:05:54.668618: Yayy! New best EMA pseudo Dice: 0.7459999918937683 
2025-08-28 16:05:55.514788:  
2025-08-28 16:05:55.524145: Epoch 658 
2025-08-28 16:05:55.530335: Current learning rate: 0.00381 
2025-08-28 16:06:10.407843: train_loss -0.5329 
2025-08-28 16:06:10.416204: val_loss -0.4912 
2025-08-28 16:06:10.420322: Pseudo dice [np.float32(0.7432)] 
2025-08-28 16:06:10.427367: Epoch time: 14.9 s 
2025-08-28 16:06:11.082568:  
2025-08-28 16:06:11.090673: Epoch 659 
2025-08-28 16:06:11.095826: Current learning rate: 0.0038 
2025-08-28 16:06:25.860765: train_loss -0.542 
2025-08-28 16:06:25.869080: val_loss -0.5754 
2025-08-28 16:06:25.873240: Pseudo dice [np.float32(0.7653)] 
2025-08-28 16:06:25.881607: Epoch time: 14.78 s 
2025-08-28 16:06:25.886559: Yayy! New best EMA pseudo Dice: 0.7476999759674072 
2025-08-28 16:06:26.717855:  
2025-08-28 16:06:26.725187: Epoch 660 
2025-08-28 16:06:26.731276: Current learning rate: 0.00379 
2025-08-28 16:06:42.306327: train_loss -0.552 
2025-08-28 16:06:42.310574: val_loss -0.6137 
2025-08-28 16:06:42.318845: Pseudo dice [np.float32(0.7928)] 
2025-08-28 16:06:42.324188: Epoch time: 15.59 s 
2025-08-28 16:06:42.327910: Yayy! New best EMA pseudo Dice: 0.7522000074386597 
2025-08-28 16:06:43.163362:  
2025-08-28 16:06:43.170712: Epoch 661 
2025-08-28 16:06:43.175881: Current learning rate: 0.00378 
2025-08-28 16:06:58.330315: train_loss -0.5428 
2025-08-28 16:06:58.334850: val_loss -0.5236 
2025-08-28 16:06:58.343193: Pseudo dice [np.float32(0.7494)] 
2025-08-28 16:06:58.349256: Epoch time: 15.17 s 
2025-08-28 16:06:59.006166:  
2025-08-28 16:06:59.014528: Epoch 662 
2025-08-28 16:06:59.019933: Current learning rate: 0.00377 
2025-08-28 16:07:13.950428: train_loss -0.5335 
2025-08-28 16:07:13.958764: val_loss -0.5429 
2025-08-28 16:07:13.967424: Pseudo dice [np.float32(0.74)] 
2025-08-28 16:07:13.972505: Epoch time: 14.95 s 
2025-08-28 16:07:14.763731:  
2025-08-28 16:07:14.773236: Epoch 663 
2025-08-28 16:07:14.779339: Current learning rate: 0.00376 
2025-08-28 16:07:29.533373: train_loss -0.5407 
2025-08-28 16:07:29.540993: val_loss -0.5304 
2025-08-28 16:07:29.545515: Pseudo dice [np.float32(0.731)] 
2025-08-28 16:07:29.552202: Epoch time: 14.77 s 
2025-08-28 16:07:30.203989:  
2025-08-28 16:07:30.212341: Epoch 664 
2025-08-28 16:07:30.218747: Current learning rate: 0.00375 
2025-08-28 16:07:44.802071: train_loss -0.543 
2025-08-28 16:07:44.810411: val_loss -0.538 
2025-08-28 16:07:44.818754: Pseudo dice [np.float32(0.7356)] 
2025-08-28 16:07:44.824124: Epoch time: 14.6 s 
2025-08-28 16:07:45.470437:  
2025-08-28 16:07:45.478888: Epoch 665 
2025-08-28 16:07:45.484978: Current learning rate: 0.00374 
2025-08-28 16:07:59.817079: train_loss -0.5325 
2025-08-28 16:07:59.825430: val_loss -0.5365 
2025-08-28 16:07:59.829631: Pseudo dice [np.float32(0.692)] 
2025-08-28 16:07:59.837907: Epoch time: 14.35 s 
2025-08-28 16:08:00.484290:  
2025-08-28 16:08:00.491544: Epoch 666 
2025-08-28 16:08:00.496716: Current learning rate: 0.00373 
2025-08-28 16:08:15.203478: train_loss -0.5354 
2025-08-28 16:08:15.215757: val_loss -0.5441 
2025-08-28 16:08:15.220197: Pseudo dice [np.float32(0.7797)] 
2025-08-28 16:08:15.227010: Epoch time: 14.72 s 
2025-08-28 16:08:15.875738:  
2025-08-28 16:08:15.885176: Epoch 667 
2025-08-28 16:08:15.892421: Current learning rate: 0.00372 
2025-08-28 16:08:31.039933: train_loss -0.5638 
2025-08-28 16:08:31.048245: val_loss -0.5459 
2025-08-28 16:08:31.052405: Pseudo dice [np.float32(0.7533)] 
2025-08-28 16:08:31.058500: Epoch time: 15.17 s 
2025-08-28 16:08:31.717668:  
2025-08-28 16:08:31.727964: Epoch 668 
2025-08-28 16:08:31.734270: Current learning rate: 0.00371 
2025-08-28 16:08:45.946470: train_loss -0.5888 
2025-08-28 16:08:45.954772: val_loss -0.5448 
2025-08-28 16:08:45.958879: Pseudo dice [np.float32(0.7939)] 
2025-08-28 16:08:45.968053: Epoch time: 14.23 s 
2025-08-28 16:08:46.619948:  
2025-08-28 16:08:46.628303: Epoch 669 
2025-08-28 16:08:46.633486: Current learning rate: 0.0037 
2025-08-28 16:09:02.233790: train_loss -0.5241 
2025-08-28 16:09:02.241893: val_loss -0.4287 
2025-08-28 16:09:02.246046: Pseudo dice [np.float32(0.7088)] 
2025-08-28 16:09:02.254976: Epoch time: 15.62 s 
2025-08-28 16:09:03.077068:  
2025-08-28 16:09:03.085498: Epoch 670 
2025-08-28 16:09:03.092890: Current learning rate: 0.00369 
2025-08-28 16:09:17.695138: train_loss -0.5254 
2025-08-28 16:09:17.707321: val_loss -0.4145 
2025-08-28 16:09:17.711795: Pseudo dice [np.float32(0.6644)] 
2025-08-28 16:09:17.719480: Epoch time: 14.62 s 
2025-08-28 16:09:18.374514:  
2025-08-28 16:09:18.384072: Epoch 671 
2025-08-28 16:09:18.389222: Current learning rate: 0.00368 
2025-08-28 16:09:32.542972: train_loss -0.5586 
2025-08-28 16:09:32.551324: val_loss -0.4947 
2025-08-28 16:09:32.555493: Pseudo dice [np.float32(0.6918)] 
2025-08-28 16:09:32.563415: Epoch time: 14.17 s 
2025-08-28 16:09:33.231008:  
2025-08-28 16:09:33.238322: Epoch 672 
2025-08-28 16:09:33.245661: Current learning rate: 0.00367 
2025-08-28 16:09:48.375327: train_loss -0.5511 
2025-08-28 16:09:48.383934: val_loss -0.5963 
2025-08-28 16:09:48.388058: Pseudo dice [np.float32(0.7565)] 
2025-08-28 16:09:48.397425: Epoch time: 15.15 s 
2025-08-28 16:09:49.044770:  
2025-08-28 16:09:49.053173: Epoch 673 
2025-08-28 16:09:49.059245: Current learning rate: 0.00366 
2025-08-28 16:10:04.575087: train_loss -0.5638 
2025-08-28 16:10:04.583309: val_loss -0.5733 
2025-08-28 16:10:04.587680: Pseudo dice [np.float32(0.7762)] 
2025-08-28 16:10:04.596369: Epoch time: 15.53 s 
2025-08-28 16:10:05.258893:  
2025-08-28 16:10:05.268386: Epoch 674 
2025-08-28 16:10:05.273502: Current learning rate: 0.00365 
2025-08-28 16:10:20.332320: train_loss -0.5275 
2025-08-28 16:10:20.344851: val_loss -0.5769 
2025-08-28 16:10:20.349017: Pseudo dice [np.float32(0.782)] 
2025-08-28 16:10:20.357089: Epoch time: 15.08 s 
2025-08-28 16:10:21.031886:  
2025-08-28 16:10:21.040321: Epoch 675 
2025-08-28 16:10:21.046583: Current learning rate: 0.00364 
2025-08-28 16:10:36.114759: train_loss -0.5308 
2025-08-28 16:10:36.123091: val_loss -0.5077 
2025-08-28 16:10:36.127221: Pseudo dice [np.float32(0.724)] 
2025-08-28 16:10:36.134300: Epoch time: 15.08 s 
2025-08-28 16:10:36.934222:  
2025-08-28 16:10:36.942590: Epoch 676 
2025-08-28 16:10:36.947818: Current learning rate: 0.00363 
2025-08-28 16:10:51.726149: train_loss -0.5153 
2025-08-28 16:10:51.734762: val_loss -0.5655 
2025-08-28 16:10:51.743402: Pseudo dice [np.float32(0.7386)] 
2025-08-28 16:10:51.748724: Epoch time: 14.79 s 
2025-08-28 16:10:52.417425:  
2025-08-28 16:10:52.424701: Epoch 677 
2025-08-28 16:10:52.429927: Current learning rate: 0.00362 
2025-08-28 16:11:06.536755: train_loss -0.5089 
2025-08-28 16:11:06.545121: val_loss -0.4972 
2025-08-28 16:11:06.549278: Pseudo dice [np.float32(0.7455)] 
2025-08-28 16:11:06.558843: Epoch time: 14.12 s 
2025-08-28 16:11:07.224934:  
2025-08-28 16:11:07.233221: Epoch 678 
2025-08-28 16:11:07.240499: Current learning rate: 0.00361 
2025-08-28 16:11:22.006363: train_loss -0.5763 
2025-08-28 16:11:22.014735: val_loss -0.4953 
2025-08-28 16:11:22.023073: Pseudo dice [np.float32(0.7011)] 
2025-08-28 16:11:22.027975: Epoch time: 14.78 s 
2025-08-28 16:11:22.691446:  
2025-08-28 16:11:22.699906: Epoch 679 
2025-08-28 16:11:22.705942: Current learning rate: 0.0036 
2025-08-28 16:11:37.864188: train_loss -0.5376 
2025-08-28 16:11:37.872253: val_loss -0.4496 
2025-08-28 16:11:37.880945: Pseudo dice [np.float32(0.7338)] 
2025-08-28 16:11:37.886710: Epoch time: 15.17 s 
2025-08-28 16:11:38.589451:  
2025-08-28 16:11:38.597764: Epoch 680 
2025-08-28 16:11:38.605133: Current learning rate: 0.00359 
2025-08-28 16:11:53.854950: train_loss -0.52 
2025-08-28 16:11:53.859656: val_loss -0.4458 
2025-08-28 16:11:53.867378: Pseudo dice [np.float32(0.6944)] 
2025-08-28 16:11:53.873325: Epoch time: 15.27 s 
2025-08-28 16:11:54.520037:  
2025-08-28 16:11:54.527436: Epoch 681 
2025-08-28 16:11:54.533551: Current learning rate: 0.00358 
2025-08-28 16:12:09.779200: train_loss -0.5332 
2025-08-28 16:12:09.787423: val_loss -0.5147 
2025-08-28 16:12:09.791543: Pseudo dice [np.float32(0.6672)] 
2025-08-28 16:12:09.800755: Epoch time: 15.26 s 
2025-08-28 16:12:10.449418:  
2025-08-28 16:12:10.457836: Epoch 682 
2025-08-28 16:12:10.464186: Current learning rate: 0.00357 
2025-08-28 16:12:25.570109: train_loss -0.5685 
2025-08-28 16:12:25.578195: val_loss -0.5487 
2025-08-28 16:12:25.582345: Pseudo dice [np.float32(0.7175)] 
2025-08-28 16:12:25.589254: Epoch time: 15.12 s 
2025-08-28 16:12:26.401913:  
2025-08-28 16:12:26.412256: Epoch 683 
2025-08-28 16:12:26.419554: Current learning rate: 0.00356 
2025-08-28 16:12:41.306344: train_loss -0.5577 
2025-08-28 16:12:41.314574: val_loss -0.3823 
2025-08-28 16:12:41.319024: Pseudo dice [np.float32(0.6964)] 
2025-08-28 16:12:41.328032: Epoch time: 14.91 s 
2025-08-28 16:12:41.983063:  
2025-08-28 16:12:41.990244: Epoch 684 
2025-08-28 16:12:41.995595: Current learning rate: 0.00355 
2025-08-28 16:12:57.117964: train_loss -0.5243 
2025-08-28 16:12:57.122189: val_loss -0.5411 
2025-08-28 16:12:57.130525: Pseudo dice [np.float32(0.8034)] 
2025-08-28 16:12:57.136601: Epoch time: 15.14 s 
2025-08-28 16:12:57.795752:  
2025-08-28 16:12:57.804052: Epoch 685 
2025-08-28 16:12:57.809191: Current learning rate: 0.00354 
2025-08-28 16:13:13.054837: train_loss -0.5533 
2025-08-28 16:13:13.059211: val_loss -0.4627 
2025-08-28 16:13:13.067273: Pseudo dice [np.float32(0.7031)] 
2025-08-28 16:13:13.073203: Epoch time: 15.26 s 
2025-08-28 16:13:13.729285:  
2025-08-28 16:13:13.738736: Epoch 686 
2025-08-28 16:13:13.745956: Current learning rate: 0.00353 
2025-08-28 16:13:29.220889: train_loss -0.5859 
2025-08-28 16:13:29.225050: val_loss -0.6171 
2025-08-28 16:13:29.233385: Pseudo dice [np.float32(0.8018)] 
2025-08-28 16:13:29.238800: Epoch time: 15.49 s 
2025-08-28 16:13:29.887129:  
2025-08-28 16:13:29.894391: Epoch 687 
2025-08-28 16:13:29.900623: Current learning rate: 0.00352 
2025-08-28 16:13:44.861502: train_loss -0.5459 
2025-08-28 16:13:44.869823: val_loss -0.5562 
2025-08-28 16:13:44.873952: Pseudo dice [np.float32(0.7182)] 
2025-08-28 16:13:44.882869: Epoch time: 14.98 s 
2025-08-28 16:13:45.540261:  
2025-08-28 16:13:45.548568: Epoch 688 
2025-08-28 16:13:45.553671: Current learning rate: 0.00351 
2025-08-28 16:14:01.415557: train_loss -0.5856 
2025-08-28 16:14:01.423890: val_loss -0.5723 
2025-08-28 16:14:01.428049: Pseudo dice [np.float32(0.7486)] 
2025-08-28 16:14:01.436996: Epoch time: 15.88 s 
2025-08-28 16:14:02.237134:  
2025-08-28 16:14:02.245337: Epoch 689 
2025-08-28 16:14:02.250682: Current learning rate: 0.0035 
2025-08-28 16:14:17.444275: train_loss -0.5346 
2025-08-28 16:14:17.453373: val_loss -0.4537 
2025-08-28 16:14:17.460692: Pseudo dice [np.float32(0.7078)] 
2025-08-28 16:14:17.466964: Epoch time: 15.21 s 
2025-08-28 16:14:18.119589:  
2025-08-28 16:14:18.126869: Epoch 690 
2025-08-28 16:14:18.132032: Current learning rate: 0.00349 
2025-08-28 16:14:33.009759: train_loss -0.5529 
2025-08-28 16:14:33.017884: val_loss -0.5142 
2025-08-28 16:14:33.025884: Pseudo dice [np.float32(0.7724)] 
2025-08-28 16:14:33.030417: Epoch time: 14.89 s 
2025-08-28 16:14:33.686325:  
2025-08-28 16:14:33.695594: Epoch 691 
2025-08-28 16:14:33.700741: Current learning rate: 0.00348 
2025-08-28 16:14:48.850366: train_loss -0.5682 
2025-08-28 16:14:48.858710: val_loss -0.5026 
2025-08-28 16:14:48.867041: Pseudo dice [np.float32(0.7129)] 
2025-08-28 16:14:48.874914: Epoch time: 15.17 s 
2025-08-28 16:14:49.532296:  
2025-08-28 16:14:49.540568: Epoch 692 
2025-08-28 16:14:49.545788: Current learning rate: 0.00346 
2025-08-28 16:15:06.025869: train_loss -0.5563 
2025-08-28 16:15:06.034827: val_loss -0.5746 
2025-08-28 16:15:06.042847: Pseudo dice [np.float32(0.7451)] 
2025-08-28 16:15:06.047933: Epoch time: 16.49 s 
2025-08-28 16:15:06.779690:  
2025-08-28 16:15:06.791157: Epoch 693 
2025-08-28 16:15:06.801419: Current learning rate: 0.00345 
2025-08-28 16:15:23.381145: train_loss -0.5267 
2025-08-28 16:15:23.389032: val_loss -0.4468 
2025-08-28 16:15:23.393170: Pseudo dice [np.float32(0.6773)] 
2025-08-28 16:15:23.401349: Epoch time: 16.6 s 
2025-08-28 16:15:24.127837:  
2025-08-28 16:15:24.138709: Epoch 694 
2025-08-28 16:15:24.148631: Current learning rate: 0.00344 
2025-08-28 16:15:40.714931: train_loss -0.5598 
2025-08-28 16:15:40.723027: val_loss -0.5078 
2025-08-28 16:15:40.727189: Pseudo dice [np.float32(0.6466)] 
2025-08-28 16:15:40.734365: Epoch time: 16.59 s 
2025-08-28 16:15:41.446575:  
2025-08-28 16:15:41.454005: Epoch 695 
2025-08-28 16:15:41.460162: Current learning rate: 0.00343 
2025-08-28 16:15:58.261414: train_loss -0.5695 
2025-08-28 16:15:58.274180: val_loss -0.4162 
2025-08-28 16:15:58.278302: Pseudo dice [np.float32(0.6491)] 
2025-08-28 16:15:58.284289: Epoch time: 16.82 s 
2025-08-28 16:15:59.148660:  
2025-08-28 16:15:59.156015: Epoch 696 
2025-08-28 16:15:59.162143: Current learning rate: 0.00342 
2025-08-28 16:16:15.966864: train_loss -0.5694 
2025-08-28 16:16:15.974880: val_loss -0.5822 
2025-08-28 16:16:15.983196: Pseudo dice [np.float32(0.7654)] 
2025-08-28 16:16:15.989814: Epoch time: 16.82 s 
2025-08-28 16:16:16.684910:  
2025-08-28 16:16:16.694221: Epoch 697 
2025-08-28 16:16:16.701706: Current learning rate: 0.00341 
2025-08-28 16:16:33.763523: train_loss -0.4707 
2025-08-28 16:16:33.771778: val_loss -0.4452 
2025-08-28 16:16:33.775925: Pseudo dice [np.float32(0.6488)] 
2025-08-28 16:16:33.783052: Epoch time: 17.08 s 
2025-08-28 16:16:34.480965:  
2025-08-28 16:16:34.489085: Epoch 698 
2025-08-28 16:16:34.497422: Current learning rate: 0.0034 
2025-08-28 16:16:51.514542: train_loss -0.552 
2025-08-28 16:16:51.527226: val_loss -0.5364 
2025-08-28 16:16:51.531166: Pseudo dice [np.float32(0.6942)] 
2025-08-28 16:16:51.539162: Epoch time: 17.04 s 
2025-08-28 16:16:52.256871:  
2025-08-28 16:16:52.266306: Epoch 699 
2025-08-28 16:16:52.271419: Current learning rate: 0.00339 
2025-08-28 16:17:09.315569: train_loss -0.5305 
2025-08-28 16:17:09.323695: val_loss -0.4858 
2025-08-28 16:17:09.328185: Pseudo dice [np.float32(0.7664)] 
2025-08-28 16:17:09.333603: Epoch time: 17.06 s 
2025-08-28 16:17:10.240412:  
2025-08-28 16:17:10.248771: Epoch 700 
2025-08-28 16:17:10.255031: Current learning rate: 0.00338 
2025-08-28 16:17:27.208444: train_loss -0.4861 
2025-08-28 16:17:27.217171: val_loss -0.4654 
2025-08-28 16:17:27.225139: Pseudo dice [np.float32(0.6797)] 
2025-08-28 16:17:27.231402: Epoch time: 16.97 s 
2025-08-28 16:17:27.933999:  
2025-08-28 16:17:27.942383: Epoch 701 
2025-08-28 16:17:27.948710: Current learning rate: 0.00337 
2025-08-28 16:17:44.859392: train_loss -0.5063 
2025-08-28 16:17:44.867973: val_loss -0.5274 
2025-08-28 16:17:44.871942: Pseudo dice [np.float32(0.7498)] 
2025-08-28 16:17:44.879150: Epoch time: 16.93 s 
2025-08-28 16:17:45.727969:  
2025-08-28 16:17:45.737658: Epoch 702 
2025-08-28 16:17:45.743557: Current learning rate: 0.00336 
2025-08-28 16:18:02.418610: train_loss -0.5721 
2025-08-28 16:18:02.426955: val_loss -0.5799 
2025-08-28 16:18:02.435298: Pseudo dice [np.float32(0.7335)] 
2025-08-28 16:18:02.440621: Epoch time: 16.69 s 
2025-08-28 16:18:03.137056:  
2025-08-28 16:18:03.147324: Epoch 703 
2025-08-28 16:18:03.154692: Current learning rate: 0.00335 
2025-08-28 16:18:19.786167: train_loss -0.562 
2025-08-28 16:18:19.796498: val_loss -0.4937 
2025-08-28 16:18:19.802611: Pseudo dice [np.float32(0.7517)] 
2025-08-28 16:18:19.808822: Epoch time: 16.65 s 
2025-08-28 16:18:20.511548:  
2025-08-28 16:18:20.519941: Epoch 704 
2025-08-28 16:18:20.525228: Current learning rate: 0.00334 
2025-08-28 16:18:35.801898: train_loss -0.5656 
2025-08-28 16:18:35.810258: val_loss -0.5978 
2025-08-28 16:18:35.814441: Pseudo dice [np.float32(0.7539)] 
2025-08-28 16:18:35.822325: Epoch time: 15.29 s 
2025-08-28 16:18:36.485857:  
2025-08-28 16:18:36.495333: Epoch 705 
2025-08-28 16:18:36.501462: Current learning rate: 0.00333 
2025-08-28 16:18:51.834877: train_loss -0.5274 
2025-08-28 16:18:51.842933: val_loss -0.5758 
2025-08-28 16:18:51.847083: Pseudo dice [np.float32(0.7705)] 
2025-08-28 16:18:51.855510: Epoch time: 15.35 s 
2025-08-28 16:18:52.503013:  
2025-08-28 16:18:52.511389: Epoch 706 
2025-08-28 16:18:52.517431: Current learning rate: 0.00332 
2025-08-28 16:19:06.578838: train_loss -0.5821 
2025-08-28 16:19:06.586817: val_loss -0.5819 
2025-08-28 16:19:06.591014: Pseudo dice [np.float32(0.7551)] 
2025-08-28 16:19:06.599768: Epoch time: 14.08 s 
2025-08-28 16:19:07.252063:  
2025-08-28 16:19:07.259340: Epoch 707 
2025-08-28 16:19:07.264498: Current learning rate: 0.00331 
2025-08-28 16:19:21.284848: train_loss -0.5058 
2025-08-28 16:19:21.293263: val_loss -0.5186 
2025-08-28 16:19:21.297570: Pseudo dice [np.float32(0.7251)] 
2025-08-28 16:19:21.304093: Epoch time: 14.03 s 
2025-08-28 16:19:22.121100:  
2025-08-28 16:19:22.129417: Epoch 708 
2025-08-28 16:19:22.135507: Current learning rate: 0.0033 
2025-08-28 16:19:37.321769: train_loss -0.5474 
2025-08-28 16:19:37.330013: val_loss -0.4945 
2025-08-28 16:19:37.334426: Pseudo dice [np.float32(0.71)] 
2025-08-28 16:19:37.343133: Epoch time: 15.2 s 
2025-08-28 16:19:38.000344:  
2025-08-28 16:19:38.007694: Epoch 709 
2025-08-28 16:19:38.013848: Current learning rate: 0.00329 
2025-08-28 16:19:53.058364: train_loss -0.5632 
2025-08-28 16:19:53.070741: val_loss -0.6001 
2025-08-28 16:19:53.074912: Pseudo dice [np.float32(0.7704)] 
2025-08-28 16:19:53.082752: Epoch time: 15.06 s 
2025-08-28 16:19:53.748532:  
2025-08-28 16:19:53.756822: Epoch 710 
2025-08-28 16:19:53.764124: Current learning rate: 0.00328 
2025-08-28 16:20:08.502889: train_loss -0.5551 
2025-08-28 16:20:08.511137: val_loss -0.5369 
2025-08-28 16:20:08.515694: Pseudo dice [np.float32(0.7643)] 
2025-08-28 16:20:08.523137: Epoch time: 14.76 s 
2025-08-28 16:20:09.184715:  
2025-08-28 16:20:09.194009: Epoch 711 
2025-08-28 16:20:09.200361: Current learning rate: 0.00327 
2025-08-28 16:20:23.989081: train_loss -0.5718 
2025-08-28 16:20:23.997469: val_loss -0.4862 
2025-08-28 16:20:24.001580: Pseudo dice [np.float32(0.6652)] 
2025-08-28 16:20:24.010692: Epoch time: 14.81 s 
2025-08-28 16:20:24.695214:  
2025-08-28 16:20:24.702174: Epoch 712 
2025-08-28 16:20:24.707486: Current learning rate: 0.00326 
2025-08-28 16:20:39.608930: train_loss -0.5615 
2025-08-28 16:20:39.617432: val_loss -0.542 
2025-08-28 16:20:39.621591: Pseudo dice [np.float32(0.7721)] 
2025-08-28 16:20:39.628421: Epoch time: 14.92 s 
2025-08-28 16:20:40.301026:  
2025-08-28 16:20:40.309373: Epoch 713 
2025-08-28 16:20:40.314729: Current learning rate: 0.00325 
2025-08-28 16:20:55.237205: train_loss -0.5421 
2025-08-28 16:20:55.249467: val_loss -0.5573 
2025-08-28 16:20:55.253675: Pseudo dice [np.float32(0.7496)] 
2025-08-28 16:20:55.260715: Epoch time: 14.94 s 
2025-08-28 16:20:55.924966:  
2025-08-28 16:20:55.933315: Epoch 714 
2025-08-28 16:20:55.939700: Current learning rate: 0.00324 
2025-08-28 16:21:11.039056: train_loss -0.5773 
2025-08-28 16:21:11.044426: val_loss -0.5007 
2025-08-28 16:21:11.048578: Pseudo dice [np.float32(0.6739)] 
2025-08-28 16:21:11.058001: Epoch time: 15.12 s 
2025-08-28 16:21:11.875464:  
2025-08-28 16:21:11.885746: Epoch 715 
2025-08-28 16:21:11.892080: Current learning rate: 0.00323 
2025-08-28 16:21:27.077136: train_loss -0.5643 
2025-08-28 16:21:27.085404: val_loss -0.5653 
2025-08-28 16:21:27.089606: Pseudo dice [np.float32(0.7627)] 
2025-08-28 16:21:27.096464: Epoch time: 15.2 s 
2025-08-28 16:21:27.748524:  
2025-08-28 16:21:27.756779: Epoch 716 
2025-08-28 16:21:27.762136: Current learning rate: 0.00322 
2025-08-28 16:21:42.763578: train_loss -0.5909 
2025-08-28 16:21:42.771922: val_loss -0.5099 
2025-08-28 16:21:42.776346: Pseudo dice [np.float32(0.6696)] 
2025-08-28 16:21:42.783066: Epoch time: 15.02 s 
2025-08-28 16:21:43.443377:  
2025-08-28 16:21:43.451694: Epoch 717 
2025-08-28 16:21:43.457962: Current learning rate: 0.00321 
2025-08-28 16:21:58.291550: train_loss -0.5405 
2025-08-28 16:21:58.299949: val_loss -0.5392 
2025-08-28 16:21:58.304089: Pseudo dice [np.float32(0.7216)] 
2025-08-28 16:21:58.312473: Epoch time: 14.85 s 
2025-08-28 16:21:58.972496:  
2025-08-28 16:21:58.981761: Epoch 718 
2025-08-28 16:21:58.987945: Current learning rate: 0.0032 
2025-08-28 16:22:13.809351: train_loss -0.5759 
2025-08-28 16:22:13.815467: val_loss -0.5351 
2025-08-28 16:22:13.824109: Pseudo dice [np.float32(0.7147)] 
2025-08-28 16:22:13.829213: Epoch time: 14.84 s 
2025-08-28 16:22:14.503443:  
2025-08-28 16:22:14.513043: Epoch 719 
2025-08-28 16:22:14.519109: Current learning rate: 0.00319 
2025-08-28 16:22:30.524214: train_loss -0.5656 
2025-08-28 16:22:30.532101: val_loss -0.5266 
2025-08-28 16:22:30.540475: Pseudo dice [np.float32(0.7503)] 
2025-08-28 16:22:30.545912: Epoch time: 16.02 s 
2025-08-28 16:22:31.263985:  
2025-08-28 16:22:31.272368: Epoch 720 
2025-08-28 16:22:31.277591: Current learning rate: 0.00318 
2025-08-28 16:22:47.841043: train_loss -0.5553 
2025-08-28 16:22:47.849378: val_loss -0.599 
2025-08-28 16:22:47.853555: Pseudo dice [np.float32(0.7733)] 
2025-08-28 16:22:47.861591: Epoch time: 16.58 s 
2025-08-28 16:22:48.578169:  
2025-08-28 16:22:48.586680: Epoch 721 
2025-08-28 16:22:48.593775: Current learning rate: 0.00317 
2025-08-28 16:23:04.920889: train_loss -0.5469 
2025-08-28 16:23:04.928943: val_loss -0.5879 
2025-08-28 16:23:04.937587: Pseudo dice [np.float32(0.7522)] 
2025-08-28 16:23:04.943434: Epoch time: 16.34 s 
2025-08-28 16:23:05.827652:  
2025-08-28 16:23:05.835005: Epoch 722 
2025-08-28 16:23:05.840232: Current learning rate: 0.00316 
2025-08-28 16:23:22.605143: train_loss -0.5514 
2025-08-28 16:23:22.613229: val_loss -0.552 
2025-08-28 16:23:22.617795: Pseudo dice [np.float32(0.7797)] 
2025-08-28 16:23:22.626234: Epoch time: 16.78 s 
2025-08-28 16:23:23.381813:  
2025-08-28 16:23:23.391016: Epoch 723 
2025-08-28 16:23:23.397264: Current learning rate: 0.00315 
2025-08-28 16:23:40.089061: train_loss -0.5781 
2025-08-28 16:23:40.097368: val_loss -0.5579 
2025-08-28 16:23:40.101533: Pseudo dice [np.float32(0.7881)] 
2025-08-28 16:23:40.110567: Epoch time: 16.71 s 
2025-08-28 16:23:40.826199:  
2025-08-28 16:23:40.835455: Epoch 724 
2025-08-28 16:23:40.843967: Current learning rate: 0.00314 
2025-08-28 16:23:57.485627: train_loss -0.5703 
2025-08-28 16:23:57.493959: val_loss -0.5018 
2025-08-28 16:23:57.498069: Pseudo dice [np.float32(0.6698)] 
2025-08-28 16:23:57.507337: Epoch time: 16.66 s 
2025-08-28 16:23:58.294583:  
2025-08-28 16:23:58.305082: Epoch 725 
2025-08-28 16:23:58.313499: Current learning rate: 0.00313 
2025-08-28 16:24:15.397772: train_loss -0.5466 
2025-08-28 16:24:15.406771: val_loss -0.6015 
2025-08-28 16:24:15.412855: Pseudo dice [np.float32(0.7476)] 
2025-08-28 16:24:15.418852: Epoch time: 17.1 s 
2025-08-28 16:24:16.150598:  
2025-08-28 16:24:16.161598: Epoch 726 
2025-08-28 16:24:16.169599: Current learning rate: 0.00312 
2025-08-28 16:24:33.364139: train_loss -0.5302 
2025-08-28 16:24:33.371677: val_loss -0.4919 
2025-08-28 16:24:33.375575: Pseudo dice [np.float32(0.6936)] 
2025-08-28 16:24:33.383993: Epoch time: 17.22 s 
2025-08-28 16:24:34.132370:  
2025-08-28 16:24:34.141368: Epoch 727 
2025-08-28 16:24:34.152370: Current learning rate: 0.00311 
2025-08-28 16:24:51.286580: train_loss -0.5394 
2025-08-28 16:24:51.297624: val_loss -0.5276 
2025-08-28 16:24:51.301793: Pseudo dice [np.float32(0.7126)] 
2025-08-28 16:24:51.309748: Epoch time: 17.16 s 
2025-08-28 16:24:52.175627:  
2025-08-28 16:24:52.187020: Epoch 728 
2025-08-28 16:24:52.194218: Current learning rate: 0.0031 
2025-08-28 16:25:08.948550: train_loss -0.548 
2025-08-28 16:25:08.956923: val_loss -0.608 
2025-08-28 16:25:08.961067: Pseudo dice [np.float32(0.753)] 
2025-08-28 16:25:08.970086: Epoch time: 16.78 s 
2025-08-28 16:25:09.683641:  
2025-08-28 16:25:09.693065: Epoch 729 
2025-08-28 16:25:09.699176: Current learning rate: 0.00309 
2025-08-28 16:25:26.261680: train_loss -0.5821 
2025-08-28 16:25:26.270073: val_loss -0.5815 
2025-08-28 16:25:26.278687: Pseudo dice [np.float32(0.7849)] 
2025-08-28 16:25:26.283247: Epoch time: 16.58 s 
2025-08-28 16:25:27.081396:  
2025-08-28 16:25:27.091675: Epoch 730 
2025-08-28 16:25:27.101252: Current learning rate: 0.00308 
2025-08-28 16:25:43.941748: train_loss -0.5643 
2025-08-28 16:25:43.950245: val_loss -0.5937 
2025-08-28 16:25:43.954329: Pseudo dice [np.float32(0.7231)] 
2025-08-28 16:25:43.961802: Epoch time: 16.86 s 
2025-08-28 16:25:44.690426:  
2025-08-28 16:25:44.697818: Epoch 731 
2025-08-28 16:25:44.703934: Current learning rate: 0.00307 
2025-08-28 16:26:01.471830: train_loss -0.5337 
2025-08-28 16:26:01.480164: val_loss -0.5427 
2025-08-28 16:26:01.488534: Pseudo dice [np.float32(0.736)] 
2025-08-28 16:26:01.494712: Epoch time: 16.78 s 
2025-08-28 16:26:02.199580:  
2025-08-28 16:26:02.208035: Epoch 732 
2025-08-28 16:26:02.213140: Current learning rate: 0.00306 
2025-08-28 16:26:18.756039: train_loss -0.5677 
2025-08-28 16:26:18.764094: val_loss -0.5914 
2025-08-28 16:26:18.772754: Pseudo dice [np.float32(0.734)] 
2025-08-28 16:26:18.778425: Epoch time: 16.56 s 
2025-08-28 16:26:19.486761:  
2025-08-28 16:26:19.495041: Epoch 733 
2025-08-28 16:26:19.503452: Current learning rate: 0.00305 
2025-08-28 16:26:36.248196: train_loss -0.5624 
2025-08-28 16:26:36.256690: val_loss -0.5604 
2025-08-28 16:26:36.264933: Pseudo dice [np.float32(0.7389)] 
2025-08-28 16:26:36.270223: Epoch time: 16.76 s 
2025-08-28 16:26:37.119844:  
2025-08-28 16:26:37.128110: Epoch 734 
2025-08-28 16:26:37.137693: Current learning rate: 0.00304 
2025-08-28 16:26:53.778255: train_loss -0.5846 
2025-08-28 16:26:53.786594: val_loss -0.5495 
2025-08-28 16:26:53.794890: Pseudo dice [np.float32(0.7833)] 
2025-08-28 16:26:53.800272: Epoch time: 16.66 s 
2025-08-28 16:26:54.504969:  
2025-08-28 16:26:54.513289: Epoch 735 
2025-08-28 16:26:54.518524: Current learning rate: 0.00303 
2025-08-28 16:27:11.299849: train_loss -0.5981 
2025-08-28 16:27:11.308203: val_loss -0.5476 
2025-08-28 16:27:11.312407: Pseudo dice [np.float32(0.7493)] 
2025-08-28 16:27:11.319401: Epoch time: 16.8 s 
2025-08-28 16:27:12.042109:  
2025-08-28 16:27:12.050552: Epoch 736 
2025-08-28 16:27:12.055814: Current learning rate: 0.00302 
2025-08-28 16:27:28.775764: train_loss -0.5261 
2025-08-28 16:27:28.784070: val_loss -0.5243 
2025-08-28 16:27:28.788252: Pseudo dice [np.float32(0.7325)] 
2025-08-28 16:27:28.796583: Epoch time: 16.73 s 
2025-08-28 16:27:29.506546:  
2025-08-28 16:27:29.518039: Epoch 737 
2025-08-28 16:27:29.524281: Current learning rate: 0.00301 
2025-08-28 16:27:46.289232: train_loss -0.5537 
2025-08-28 16:27:46.299958: val_loss -0.5465 
2025-08-28 16:27:46.305642: Pseudo dice [np.float32(0.741)] 
2025-08-28 16:27:46.312889: Epoch time: 16.78 s 
2025-08-28 16:27:47.021960:  
2025-08-28 16:27:47.033491: Epoch 738 
2025-08-28 16:27:47.040823: Current learning rate: 0.003 
2025-08-28 16:28:03.681353: train_loss -0.5536 
2025-08-28 16:28:03.693881: val_loss -0.538 
2025-08-28 16:28:03.698046: Pseudo dice [np.float32(0.7544)] 
2025-08-28 16:28:03.704284: Epoch time: 16.66 s 
2025-08-28 16:28:04.432028:  
2025-08-28 16:28:04.443345: Epoch 739 
2025-08-28 16:28:04.455051: Current learning rate: 0.00299 
2025-08-28 16:28:21.470220: train_loss -0.575 
2025-08-28 16:28:21.478262: val_loss -0.6101 
2025-08-28 16:28:21.486603: Pseudo dice [np.float32(0.7698)] 
2025-08-28 16:28:21.491998: Epoch time: 17.04 s 
2025-08-28 16:28:22.195557:  
2025-08-28 16:28:22.205998: Epoch 740 
2025-08-28 16:28:22.214369: Current learning rate: 0.00297 
2025-08-28 16:28:38.987736: train_loss -0.6027 
2025-08-28 16:28:38.995757: val_loss -0.5477 
2025-08-28 16:28:38.999960: Pseudo dice [np.float32(0.7666)] 
2025-08-28 16:28:39.009096: Epoch time: 16.79 s 
2025-08-28 16:28:39.885143:  
2025-08-28 16:28:39.893665: Epoch 741 
2025-08-28 16:28:39.898726: Current learning rate: 0.00296 
2025-08-28 16:28:56.826241: train_loss -0.5775 
2025-08-28 16:28:56.838563: val_loss -0.5216 
2025-08-28 16:28:56.842761: Pseudo dice [np.float32(0.7283)] 
2025-08-28 16:28:56.850743: Epoch time: 16.94 s 
2025-08-28 16:28:57.576621:  
2025-08-28 16:28:57.587114: Epoch 742 
2025-08-28 16:28:57.593393: Current learning rate: 0.00295 
2025-08-28 16:29:14.439559: train_loss -0.5614 
2025-08-28 16:29:14.447901: val_loss -0.488 
2025-08-28 16:29:14.452178: Pseudo dice [np.float32(0.7386)] 
2025-08-28 16:29:14.461213: Epoch time: 16.86 s 
2025-08-28 16:29:15.168253:  
2025-08-28 16:29:15.177552: Epoch 743 
2025-08-28 16:29:15.182885: Current learning rate: 0.00294 
2025-08-28 16:29:31.894583: train_loss -0.5716 
2025-08-28 16:29:31.903091: val_loss -0.539 
2025-08-28 16:29:31.906920: Pseudo dice [np.float32(0.6864)] 
2025-08-28 16:29:31.914894: Epoch time: 16.73 s 
2025-08-28 16:29:32.619013:  
2025-08-28 16:29:32.629525: Epoch 744 
2025-08-28 16:29:32.638843: Current learning rate: 0.00293 
2025-08-28 16:29:49.245615: train_loss -0.5242 
2025-08-28 16:29:49.253397: val_loss -0.5125 
2025-08-28 16:29:49.262106: Pseudo dice [np.float32(0.7324)] 
2025-08-28 16:29:49.267378: Epoch time: 16.63 s 
2025-08-28 16:29:50.009320:  
2025-08-28 16:29:50.017735: Epoch 745 
2025-08-28 16:29:50.022843: Current learning rate: 0.00292 
2025-08-28 16:30:06.804266: train_loss -0.5569 
2025-08-28 16:30:06.816740: val_loss -0.5914 
2025-08-28 16:30:06.821229: Pseudo dice [np.float32(0.7919)] 
2025-08-28 16:30:06.827952: Epoch time: 16.8 s 
2025-08-28 16:30:07.545560:  
2025-08-28 16:30:07.554967: Epoch 746 
2025-08-28 16:30:07.562395: Current learning rate: 0.00291 
2025-08-28 16:30:24.249023: train_loss -0.5748 
2025-08-28 16:30:24.259180: val_loss -0.4679 
2025-08-28 16:30:24.263321: Pseudo dice [np.float32(0.6528)] 
2025-08-28 16:30:24.270417: Epoch time: 16.7 s 
2025-08-28 16:30:25.138100:  
2025-08-28 16:30:25.149625: Epoch 747 
2025-08-28 16:30:25.156810: Current learning rate: 0.0029 
2025-08-28 16:30:41.806157: train_loss -0.5558 
2025-08-28 16:30:41.814182: val_loss -0.5589 
2025-08-28 16:30:41.823223: Pseudo dice [np.float32(0.7255)] 
2025-08-28 16:30:41.828798: Epoch time: 16.67 s 
2025-08-28 16:30:42.550279:  
2025-08-28 16:30:42.560765: Epoch 748 
2025-08-28 16:30:42.567005: Current learning rate: 0.00289 
2025-08-28 16:30:59.252467: train_loss -0.5656 
2025-08-28 16:30:59.265522: val_loss -0.6257 
2025-08-28 16:30:59.269155: Pseudo dice [np.float32(0.7557)] 
2025-08-28 16:30:59.277418: Epoch time: 16.7 s 
2025-08-28 16:30:59.983339:  
2025-08-28 16:30:59.990529: Epoch 749 
2025-08-28 16:30:59.996864: Current learning rate: 0.00288 
2025-08-28 16:31:16.978467: train_loss -0.5631 
2025-08-28 16:31:16.986806: val_loss -0.5748 
2025-08-28 16:31:16.990947: Pseudo dice [np.float32(0.7636)] 
2025-08-28 16:31:16.997023: Epoch time: 17.0 s 
2025-08-28 16:31:17.911797:  
2025-08-28 16:31:17.920986: Epoch 750 
2025-08-28 16:31:17.927337: Current learning rate: 0.00287 
2025-08-28 16:31:34.858796: train_loss -0.5685 
2025-08-28 16:31:34.867190: val_loss -0.5458 
2025-08-28 16:31:34.871327: Pseudo dice [np.float32(0.6684)] 
2025-08-28 16:31:34.879407: Epoch time: 16.95 s 
2025-08-28 16:31:35.602288:  
2025-08-28 16:31:35.610594: Epoch 751 
2025-08-28 16:31:35.616857: Current learning rate: 0.00286 
2025-08-28 16:31:52.572370: train_loss -0.573 
2025-08-28 16:31:52.584854: val_loss -0.5727 
2025-08-28 16:31:52.589031: Pseudo dice [np.float32(0.7556)] 
2025-08-28 16:31:52.597042: Epoch time: 16.97 s 
2025-08-28 16:31:53.300060:  
2025-08-28 16:31:53.309476: Epoch 752 
2025-08-28 16:31:53.314571: Current learning rate: 0.00285 
2025-08-28 16:32:10.344231: train_loss -0.5934 
2025-08-28 16:32:10.352593: val_loss -0.563 
2025-08-28 16:32:10.361234: Pseudo dice [np.float32(0.712)] 
2025-08-28 16:32:10.368206: Epoch time: 17.05 s 
2025-08-28 16:32:11.251518:  
2025-08-28 16:32:11.260670: Epoch 753 
2025-08-28 16:32:11.265809: Current learning rate: 0.00284 
2025-08-28 16:32:27.899397: train_loss -0.5896 
2025-08-28 16:32:27.907607: val_loss -0.5576 
2025-08-28 16:32:27.915987: Pseudo dice [np.float32(0.7353)] 
2025-08-28 16:32:27.921826: Epoch time: 16.65 s 
2025-08-28 16:32:28.638562:  
2025-08-28 16:32:28.647839: Epoch 754 
2025-08-28 16:32:28.653076: Current learning rate: 0.00283 
2025-08-28 16:32:45.470950: train_loss -0.5518 
2025-08-28 16:32:45.479346: val_loss -0.5786 
2025-08-28 16:32:45.483486: Pseudo dice [np.float32(0.8093)] 
2025-08-28 16:32:45.498501: Epoch time: 16.83 s 
2025-08-28 16:32:46.259080:  
2025-08-28 16:32:46.267432: Epoch 755 
2025-08-28 16:32:46.272778: Current learning rate: 0.00282 
2025-08-28 16:33:02.804955: train_loss -0.571 
2025-08-28 16:33:02.813266: val_loss -0.4393 
2025-08-28 16:33:02.821642: Pseudo dice [np.float32(0.6533)] 
2025-08-28 16:33:02.827013: Epoch time: 16.55 s 
2025-08-28 16:33:03.535851:  
2025-08-28 16:33:03.544192: Epoch 756 
2025-08-28 16:33:03.549389: Current learning rate: 0.00281 
2025-08-28 16:33:20.476736: train_loss -0.5654 
2025-08-28 16:33:20.485083: val_loss -0.4961 
2025-08-28 16:33:20.493428: Pseudo dice [np.float32(0.7568)] 
2025-08-28 16:33:20.500187: Epoch time: 16.94 s 
2025-08-28 16:33:21.202414:  
2025-08-28 16:33:21.211836: Epoch 757 
2025-08-28 16:33:21.217994: Current learning rate: 0.0028 
2025-08-28 16:33:37.865127: train_loss -0.5793 
2025-08-28 16:33:37.873373: val_loss -0.5099 
2025-08-28 16:33:37.877461: Pseudo dice [np.float32(0.7723)] 
2025-08-28 16:33:37.884915: Epoch time: 16.66 s 
2025-08-28 16:33:38.592687:  
2025-08-28 16:33:38.601069: Epoch 758 
2025-08-28 16:33:38.607231: Current learning rate: 0.00279 
2025-08-28 16:33:55.528400: train_loss -0.5768 
2025-08-28 16:33:55.536736: val_loss -0.601 
2025-08-28 16:33:55.545109: Pseudo dice [np.float32(0.7754)] 
2025-08-28 16:33:55.551322: Epoch time: 16.94 s 
2025-08-28 16:33:56.284432:  
2025-08-28 16:33:56.293689: Epoch 759 
2025-08-28 16:33:56.299852: Current learning rate: 0.00278 
2025-08-28 16:34:13.020869: train_loss -0.5676 
2025-08-28 16:34:13.033376: val_loss -0.5116 
2025-08-28 16:34:13.037581: Pseudo dice [np.float32(0.7416)] 
2025-08-28 16:34:13.045532: Epoch time: 16.74 s 
2025-08-28 16:34:13.910361:  
2025-08-28 16:34:13.918609: Epoch 760 
2025-08-28 16:34:13.924824: Current learning rate: 0.00277 
2025-08-28 16:34:30.809858: train_loss -0.5684 
2025-08-28 16:34:30.818257: val_loss -0.549 
2025-08-28 16:34:30.826612: Pseudo dice [np.float32(0.7566)] 
2025-08-28 16:34:30.835466: Epoch time: 16.9 s 
2025-08-28 16:34:31.553875:  
2025-08-28 16:34:31.562693: Epoch 761 
2025-08-28 16:34:31.568483: Current learning rate: 0.00276 
2025-08-28 16:34:48.243536: train_loss -0.5598 
2025-08-28 16:34:48.251903: val_loss -0.4815 
2025-08-28 16:34:48.256255: Pseudo dice [np.float32(0.6626)] 
2025-08-28 16:34:48.262491: Epoch time: 16.69 s 
2025-08-28 16:34:48.977490:  
2025-08-28 16:34:48.987944: Epoch 762 
2025-08-28 16:34:48.993182: Current learning rate: 0.00275 
2025-08-28 16:35:05.598661: train_loss -0.589 
2025-08-28 16:35:05.606708: val_loss -0.5224 
2025-08-28 16:35:05.611287: Pseudo dice [np.float32(0.7537)] 
2025-08-28 16:35:05.620492: Epoch time: 16.62 s 
2025-08-28 16:35:06.332357:  
2025-08-28 16:35:06.339715: Epoch 763 
2025-08-28 16:35:06.345958: Current learning rate: 0.00274 
2025-08-28 16:35:22.994986: train_loss -0.5548 
2025-08-28 16:35:23.003193: val_loss -0.5726 
2025-08-28 16:35:23.012116: Pseudo dice [np.float32(0.709)] 
2025-08-28 16:35:23.017663: Epoch time: 16.66 s 
2025-08-28 16:35:23.749852:  
2025-08-28 16:35:23.759556: Epoch 764 
2025-08-28 16:35:23.770602: Current learning rate: 0.00273 
2025-08-28 16:35:40.912822: train_loss -0.5597 
2025-08-28 16:35:40.921100: val_loss -0.6 
2025-08-28 16:35:40.929471: Pseudo dice [np.float32(0.7805)] 
2025-08-28 16:35:40.934825: Epoch time: 17.17 s 
2025-08-28 16:35:41.657252:  
2025-08-28 16:35:41.667603: Epoch 765 
2025-08-28 16:35:41.673943: Current learning rate: 0.00272 
2025-08-28 16:35:58.251079: train_loss -0.5593 
2025-08-28 16:35:58.263450: val_loss -0.5657 
2025-08-28 16:35:58.267590: Pseudo dice [np.float32(0.7341)] 
2025-08-28 16:35:58.276688: Epoch time: 16.6 s 
2025-08-28 16:35:59.153961:  
2025-08-28 16:35:59.165814: Epoch 766 
2025-08-28 16:35:59.172690: Current learning rate: 0.00271 
2025-08-28 16:36:15.847739: train_loss -0.5854 
2025-08-28 16:36:15.855983: val_loss -0.6227 
2025-08-28 16:36:15.860158: Pseudo dice [np.float32(0.7597)] 
2025-08-28 16:36:15.867247: Epoch time: 16.69 s 
2025-08-28 16:36:16.585861:  
2025-08-28 16:36:16.594066: Epoch 767 
2025-08-28 16:36:16.601407: Current learning rate: 0.0027 
2025-08-28 16:36:33.244426: train_loss -0.5213 
2025-08-28 16:36:33.252534: val_loss -0.5038 
2025-08-28 16:36:33.256934: Pseudo dice [np.float32(0.7305)] 
2025-08-28 16:36:33.265087: Epoch time: 16.66 s 
2025-08-28 16:36:33.997001:  
2025-08-28 16:36:34.005382: Epoch 768 
2025-08-28 16:36:34.011528: Current learning rate: 0.00268 
2025-08-28 16:36:50.578730: train_loss -0.5484 
2025-08-28 16:36:50.586552: val_loss -0.4966 
2025-08-28 16:36:50.594814: Pseudo dice [np.float32(0.7087)] 
2025-08-28 16:36:50.599913: Epoch time: 16.58 s 
2025-08-28 16:36:51.325730:  
2025-08-28 16:36:51.335157: Epoch 769 
2025-08-28 16:36:51.342187: Current learning rate: 0.00267 
2025-08-28 16:37:07.824720: train_loss -0.6079 
2025-08-28 16:37:07.832916: val_loss -0.5697 
2025-08-28 16:37:07.841037: Pseudo dice [np.float32(0.8198)] 
2025-08-28 16:37:07.846164: Epoch time: 16.5 s 
2025-08-28 16:37:08.556539:  
2025-08-28 16:37:08.564783: Epoch 770 
2025-08-28 16:37:08.570049: Current learning rate: 0.00266 
2025-08-28 16:37:24.595417: train_loss -0.612 
2025-08-28 16:37:24.607709: val_loss -0.5979 
2025-08-28 16:37:24.612383: Pseudo dice [np.float32(0.8063)] 
2025-08-28 16:37:24.618524: Epoch time: 16.04 s 
2025-08-28 16:37:25.361701:  
2025-08-28 16:37:25.371096: Epoch 771 
2025-08-28 16:37:25.377376: Current learning rate: 0.00265 
2025-08-28 16:37:41.850220: train_loss -0.5426 
2025-08-28 16:37:41.858564: val_loss -0.5698 
2025-08-28 16:37:41.862718: Pseudo dice [np.float32(0.7831)] 
2025-08-28 16:37:41.871783: Epoch time: 16.49 s 
2025-08-28 16:37:41.877836: Yayy! New best EMA pseudo Dice: 0.7540000081062317 
2025-08-28 16:37:42.937595:  
2025-08-28 16:37:42.945943: Epoch 772 
2025-08-28 16:37:42.951168: Current learning rate: 0.00264 
2025-08-28 16:37:59.350960: train_loss -0.5966 
2025-08-28 16:37:59.359323: val_loss -0.536 
2025-08-28 16:37:59.367650: Pseudo dice [np.float32(0.7169)] 
2025-08-28 16:37:59.373788: Epoch time: 16.41 s 
2025-08-28 16:38:00.107968:  
2025-08-28 16:38:00.116945: Epoch 773 
2025-08-28 16:38:00.123600: Current learning rate: 0.00263 
2025-08-28 16:38:16.684952: train_loss -0.5363 
2025-08-28 16:38:16.693283: val_loss -0.5466 
2025-08-28 16:38:16.697765: Pseudo dice [np.float32(0.7711)] 
2025-08-28 16:38:16.703547: Epoch time: 16.58 s 
2025-08-28 16:38:17.435596:  
2025-08-28 16:38:17.445925: Epoch 774 
2025-08-28 16:38:17.456329: Current learning rate: 0.00262 
2025-08-28 16:38:33.910462: train_loss -0.5721 
2025-08-28 16:38:33.918832: val_loss -0.583 
2025-08-28 16:38:33.927156: Pseudo dice [np.float32(0.7545)] 
2025-08-28 16:38:33.932563: Epoch time: 16.48 s 
2025-08-28 16:38:34.645621:  
2025-08-28 16:38:34.652822: Epoch 775 
2025-08-28 16:38:34.658149: Current learning rate: 0.00261 
2025-08-28 16:38:51.578853: train_loss -0.5875 
2025-08-28 16:38:51.591071: val_loss -0.648 
2025-08-28 16:38:51.595263: Pseudo dice [np.float32(0.7482)] 
2025-08-28 16:38:51.603023: Epoch time: 16.94 s 
2025-08-28 16:38:52.269283:  
2025-08-28 16:38:52.279831: Epoch 776 
2025-08-28 16:38:52.285980: Current learning rate: 0.0026 
2025-08-28 16:39:07.557015: train_loss -0.5842 
2025-08-28 16:39:07.566571: val_loss -0.5136 
2025-08-28 16:39:07.569930: Pseudo dice [np.float32(0.6918)] 
2025-08-28 16:39:07.578436: Epoch time: 15.29 s 
2025-08-28 16:39:08.241617:  
2025-08-28 16:39:08.250000: Epoch 777 
2025-08-28 16:39:08.255077: Current learning rate: 0.00259 
2025-08-28 16:39:23.427066: train_loss -0.5943 
2025-08-28 16:39:23.435414: val_loss -0.5186 
2025-08-28 16:39:23.439659: Pseudo dice [np.float32(0.7495)] 
2025-08-28 16:39:23.446339: Epoch time: 15.19 s 
2025-08-28 16:39:24.268940:  
2025-08-28 16:39:24.278413: Epoch 778 
2025-08-28 16:39:24.284587: Current learning rate: 0.00258 
2025-08-28 16:39:39.013542: train_loss -0.5951 
2025-08-28 16:39:39.021773: val_loss -0.5583 
2025-08-28 16:39:39.029653: Pseudo dice [np.float32(0.7828)] 
2025-08-28 16:39:39.034885: Epoch time: 14.75 s 
2025-08-28 16:39:39.699975:  
2025-08-28 16:39:39.709316: Epoch 779 
2025-08-28 16:39:39.718762: Current learning rate: 0.00257 
2025-08-28 16:39:54.674882: train_loss -0.5552 
2025-08-28 16:39:54.683303: val_loss -0.5631 
2025-08-28 16:39:54.687470: Pseudo dice [np.float32(0.722)] 
2025-08-28 16:39:54.694842: Epoch time: 14.98 s 
2025-08-28 16:39:55.377288:  
2025-08-28 16:39:55.385496: Epoch 780 
2025-08-28 16:39:55.391627: Current learning rate: 0.00256 
2025-08-28 16:40:11.629284: train_loss -0.6011 
2025-08-28 16:40:11.637688: val_loss -0.5724 
2025-08-28 16:40:11.646103: Pseudo dice [np.float32(0.7914)] 
2025-08-28 16:40:11.651688: Epoch time: 16.25 s 
2025-08-28 16:40:12.316920:  
2025-08-28 16:40:12.325247: Epoch 781 
2025-08-28 16:40:12.330585: Current learning rate: 0.00255 
2025-08-28 16:40:26.552514: train_loss -0.5728 
2025-08-28 16:40:26.560916: val_loss -0.5438 
2025-08-28 16:40:26.565117: Pseudo dice [np.float32(0.7559)] 
2025-08-28 16:40:26.572965: Epoch time: 14.24 s 
2025-08-28 16:40:27.237172:  
2025-08-28 16:40:27.245507: Epoch 782 
2025-08-28 16:40:27.253248: Current learning rate: 0.00254 
2025-08-28 16:40:42.193313: train_loss -0.6301 
2025-08-28 16:40:42.205662: val_loss -0.6359 
2025-08-28 16:40:42.209811: Pseudo dice [np.float32(0.7533)] 
2025-08-28 16:40:42.216593: Epoch time: 14.96 s 
2025-08-28 16:40:42.875610:  
2025-08-28 16:40:42.885086: Epoch 783 
2025-08-28 16:40:42.892255: Current learning rate: 0.00253 
2025-08-28 16:40:58.104841: train_loss -0.5772 
2025-08-28 16:40:58.113211: val_loss -0.6304 
2025-08-28 16:40:58.121144: Pseudo dice [np.float32(0.7745)] 
2025-08-28 16:40:58.126692: Epoch time: 15.23 s 
2025-08-28 16:40:58.130410: Yayy! New best EMA pseudo Dice: 0.7544999718666077 
2025-08-28 16:40:59.140799:  
2025-08-28 16:40:59.150405: Epoch 784 
2025-08-28 16:40:59.156529: Current learning rate: 0.00252 
2025-08-28 16:41:14.187655: train_loss -0.5956 
2025-08-28 16:41:14.196049: val_loss -0.5 
2025-08-28 16:41:14.204338: Pseudo dice [np.float32(0.7286)] 
2025-08-28 16:41:14.210233: Epoch time: 15.05 s 
2025-08-28 16:41:14.874451:  
2025-08-28 16:41:14.882439: Epoch 785 
2025-08-28 16:41:14.888857: Current learning rate: 0.00251 
2025-08-28 16:41:29.765725: train_loss -0.5484 
2025-08-28 16:41:29.774135: val_loss -0.5337 
2025-08-28 16:41:29.778204: Pseudo dice [np.float32(0.7336)] 
2025-08-28 16:41:29.787105: Epoch time: 14.89 s 
2025-08-28 16:41:30.450232:  
2025-08-28 16:41:30.460779: Epoch 786 
2025-08-28 16:41:30.467978: Current learning rate: 0.0025 
2025-08-28 16:41:45.539780: train_loss -0.5635 
2025-08-28 16:41:45.548130: val_loss -0.6438 
2025-08-28 16:41:45.552275: Pseudo dice [np.float32(0.8353)] 
2025-08-28 16:41:45.558486: Epoch time: 15.09 s 
2025-08-28 16:41:45.565195: Yayy! New best EMA pseudo Dice: 0.7585999965667725 
2025-08-28 16:41:46.428685:  
2025-08-28 16:41:46.438073: Epoch 787 
2025-08-28 16:41:46.446606: Current learning rate: 0.00249 
2025-08-28 16:42:00.955124: train_loss -0.5979 
2025-08-28 16:42:00.967711: val_loss -0.5415 
2025-08-28 16:42:00.971954: Pseudo dice [np.float32(0.716)] 
2025-08-28 16:42:00.979824: Epoch time: 14.53 s 
2025-08-28 16:42:01.646872:  
2025-08-28 16:42:01.655238: Epoch 788 
2025-08-28 16:42:01.660561: Current learning rate: 0.00248 
2025-08-28 16:42:15.861614: train_loss -0.586 
2025-08-28 16:42:15.870012: val_loss -0.5739 
2025-08-28 16:42:15.874200: Pseudo dice [np.float32(0.794)] 
2025-08-28 16:42:15.880039: Epoch time: 14.22 s 
2025-08-28 16:42:16.555859:  
2025-08-28 16:42:16.564953: Epoch 789 
2025-08-28 16:42:16.570122: Current learning rate: 0.00247 
2025-08-28 16:42:31.961089: train_loss -0.5664 
2025-08-28 16:42:31.969478: val_loss -0.5706 
2025-08-28 16:42:31.978339: Pseudo dice [np.float32(0.7522)] 
2025-08-28 16:42:31.983924: Epoch time: 15.41 s 
2025-08-28 16:42:32.804217:  
2025-08-28 16:42:32.813643: Epoch 790 
2025-08-28 16:42:32.820833: Current learning rate: 0.00245 
2025-08-28 16:42:47.660125: train_loss -0.5626 
2025-08-28 16:42:47.668572: val_loss -0.5763 
2025-08-28 16:42:47.672715: Pseudo dice [np.float32(0.7646)] 
2025-08-28 16:42:47.679263: Epoch time: 14.86 s 
2025-08-28 16:42:48.355006:  
2025-08-28 16:42:48.365535: Epoch 791 
2025-08-28 16:42:48.371675: Current learning rate: 0.00244 
2025-08-28 16:43:03.217295: train_loss -0.5516 
2025-08-28 16:43:03.225677: val_loss -0.6031 
2025-08-28 16:43:03.229825: Pseudo dice [np.float32(0.7345)] 
2025-08-28 16:43:03.238706: Epoch time: 14.86 s 
2025-08-28 16:43:03.898676:  
2025-08-28 16:43:03.908051: Epoch 792 
2025-08-28 16:43:03.913183: Current learning rate: 0.00243 
2025-08-28 16:43:18.928931: train_loss -0.5731 
2025-08-28 16:43:18.937200: val_loss -0.5799 
2025-08-28 16:43:18.941325: Pseudo dice [np.float32(0.7548)] 
2025-08-28 16:43:18.949932: Epoch time: 15.03 s 
2025-08-28 16:43:19.662274:  
2025-08-28 16:43:19.669596: Epoch 793 
2025-08-28 16:43:19.674798: Current learning rate: 0.00242 
2025-08-28 16:43:34.377578: train_loss -0.5845 
2025-08-28 16:43:34.386014: val_loss -0.5338 
2025-08-28 16:43:34.390148: Pseudo dice [np.float32(0.6898)] 
2025-08-28 16:43:34.398940: Epoch time: 14.72 s 
2025-08-28 16:43:35.081839:  
2025-08-28 16:43:35.090275: Epoch 794 
2025-08-28 16:43:35.096536: Current learning rate: 0.00241 
2025-08-28 16:43:49.280082: train_loss -0.5934 
2025-08-28 16:43:49.288347: val_loss -0.5615 
2025-08-28 16:43:49.296153: Pseudo dice [np.float32(0.6954)] 
2025-08-28 16:43:49.301708: Epoch time: 14.2 s 
2025-08-28 16:43:49.974841:  
2025-08-28 16:43:49.982399: Epoch 795 
2025-08-28 16:43:49.988361: Current learning rate: 0.0024 
2025-08-28 16:44:05.053948: train_loss -0.5794 
2025-08-28 16:44:05.066786: val_loss -0.5911 
2025-08-28 16:44:05.073485: Pseudo dice [np.float32(0.8104)] 
2025-08-28 16:44:05.078899: Epoch time: 15.08 s 
2025-08-28 16:44:05.894973:  
2025-08-28 16:44:05.905632: Epoch 796 
2025-08-28 16:44:05.915760: Current learning rate: 0.00239 
2025-08-28 16:44:21.833250: train_loss -0.5704 
2025-08-28 16:44:21.841547: val_loss -0.5665 
2025-08-28 16:44:21.845783: Pseudo dice [np.float32(0.7751)] 
2025-08-28 16:44:21.854003: Epoch time: 15.94 s 
2025-08-28 16:44:22.575062:  
2025-08-28 16:44:22.584683: Epoch 797 
2025-08-28 16:44:22.590746: Current learning rate: 0.00238 
2025-08-28 16:44:38.405028: train_loss -0.5586 
2025-08-28 16:44:38.412384: val_loss -0.566 
2025-08-28 16:44:38.420088: Pseudo dice [np.float32(0.7265)] 
2025-08-28 16:44:38.425856: Epoch time: 15.83 s 
2025-08-28 16:44:39.232528:  
2025-08-28 16:44:39.242178: Epoch 798 
2025-08-28 16:44:39.249872: Current learning rate: 0.00237 
2025-08-28 16:44:55.623268: train_loss -0.5892 
2025-08-28 16:44:55.633672: val_loss -0.5302 
2025-08-28 16:44:55.637997: Pseudo dice [np.float32(0.7298)] 
2025-08-28 16:44:55.645676: Epoch time: 16.39 s 
2025-08-28 16:44:56.379685:  
2025-08-28 16:44:56.388015: Epoch 799 
2025-08-28 16:44:56.395375: Current learning rate: 0.00236 
2025-08-28 16:45:12.934565: train_loss -0.619 
2025-08-28 16:45:12.942696: val_loss -0.4789 
2025-08-28 16:45:12.950436: Pseudo dice [np.float32(0.7569)] 
2025-08-28 16:45:12.955703: Epoch time: 16.56 s 
2025-08-28 16:45:13.911531:  
2025-08-28 16:45:13.922545: Epoch 800 
2025-08-28 16:45:13.927211: Current learning rate: 0.00235 
2025-08-28 16:45:30.284518: train_loss -0.5969 
2025-08-28 16:45:30.293340: val_loss -0.5314 
2025-08-28 16:45:30.297469: Pseudo dice [np.float32(0.7228)] 
2025-08-28 16:45:30.305459: Epoch time: 16.37 s 
2025-08-28 16:45:31.069522:  
2025-08-28 16:45:31.080519: Epoch 801 
2025-08-28 16:45:31.090535: Current learning rate: 0.00234 
2025-08-28 16:45:47.431411: train_loss -0.5941 
2025-08-28 16:45:47.439677: val_loss -0.4889 
2025-08-28 16:45:47.443789: Pseudo dice [np.float32(0.7603)] 
2025-08-28 16:45:47.451598: Epoch time: 16.36 s 
2025-08-28 16:45:48.359701:  
2025-08-28 16:45:48.373740: Epoch 802 
2025-08-28 16:45:48.387021: Current learning rate: 0.00233 
2025-08-28 16:46:04.394041: train_loss -0.5957 
2025-08-28 16:46:04.406529: val_loss -0.4973 
2025-08-28 16:46:04.410732: Pseudo dice [np.float32(0.7195)] 
2025-08-28 16:46:04.419938: Epoch time: 16.04 s 
2025-08-28 16:46:05.154647:  
2025-08-28 16:46:05.162984: Epoch 803 
2025-08-28 16:46:05.169199: Current learning rate: 0.00232 
2025-08-28 16:46:21.127279: train_loss -0.5919 
2025-08-28 16:46:21.135798: val_loss -0.4442 
2025-08-28 16:46:21.144115: Pseudo dice [np.float32(0.6778)] 
2025-08-28 16:46:21.149204: Epoch time: 15.97 s 
2025-08-28 16:46:21.933607:  
2025-08-28 16:46:21.942275: Epoch 804 
2025-08-28 16:46:21.950608: Current learning rate: 0.00231 
2025-08-28 16:46:37.947872: train_loss -0.5746 
2025-08-28 16:46:37.956227: val_loss -0.5618 
2025-08-28 16:46:37.960865: Pseudo dice [np.float32(0.747)] 
2025-08-28 16:46:37.966531: Epoch time: 16.02 s 
2025-08-28 16:46:38.739218:  
2025-08-28 16:46:38.750670: Epoch 805 
2025-08-28 16:46:38.761042: Current learning rate: 0.0023 
2025-08-28 16:46:54.619284: train_loss -0.5748 
2025-08-28 16:46:54.631725: val_loss -0.4938 
2025-08-28 16:46:54.635881: Pseudo dice [np.float32(0.5944)] 
2025-08-28 16:46:54.643764: Epoch time: 15.88 s 
2025-08-28 16:46:55.375658:  
2025-08-28 16:46:55.384938: Epoch 806 
2025-08-28 16:46:55.392381: Current learning rate: 0.00229 
2025-08-28 16:47:10.701276: train_loss -0.587 
2025-08-28 16:47:10.710432: val_loss -0.5716 
2025-08-28 16:47:10.714492: Pseudo dice [np.float32(0.7855)] 
2025-08-28 16:47:10.721562: Epoch time: 15.33 s 
2025-08-28 16:47:11.469878:  
2025-08-28 16:47:11.479522: Epoch 807 
2025-08-28 16:47:11.487626: Current learning rate: 0.00228 
2025-08-28 16:47:27.256576: train_loss -0.6009 
2025-08-28 16:47:27.264311: val_loss -0.5799 
2025-08-28 16:47:27.272099: Pseudo dice [np.float32(0.7592)] 
2025-08-28 16:47:27.277269: Epoch time: 15.79 s 
2025-08-28 16:47:28.012357:  
2025-08-28 16:47:28.022817: Epoch 808 
2025-08-28 16:47:28.030818: Current learning rate: 0.00226 
2025-08-28 16:47:43.684773: train_loss -0.572 
2025-08-28 16:47:43.693086: val_loss -0.598 
2025-08-28 16:47:43.697326: Pseudo dice [np.float32(0.7859)] 
2025-08-28 16:47:43.704104: Epoch time: 15.67 s 
2025-08-28 16:47:44.597492:  
2025-08-28 16:47:44.606226: Epoch 809 
2025-08-28 16:47:44.613317: Current learning rate: 0.00225 
2025-08-28 16:48:00.343580: train_loss -0.5945 
2025-08-28 16:48:00.355681: val_loss -0.6547 
2025-08-28 16:48:00.364000: Pseudo dice [np.float32(0.7965)] 
2025-08-28 16:48:00.369093: Epoch time: 15.75 s 
2025-08-28 16:48:01.099599:  
2025-08-28 16:48:01.108971: Epoch 810 
2025-08-28 16:48:01.115248: Current learning rate: 0.00224 
2025-08-28 16:48:16.811933: train_loss -0.5809 
2025-08-28 16:48:16.817961: val_loss -0.593 
2025-08-28 16:48:16.825696: Pseudo dice [np.float32(0.7851)] 
2025-08-28 16:48:16.831418: Epoch time: 15.71 s 
2025-08-28 16:48:17.573538:  
2025-08-28 16:48:17.582791: Epoch 811 
2025-08-28 16:48:17.587840: Current learning rate: 0.00223 
2025-08-28 16:48:33.226132: train_loss -0.5523 
2025-08-28 16:48:33.236375: val_loss -0.5393 
2025-08-28 16:48:33.242721: Pseudo dice [np.float32(0.7237)] 
2025-08-28 16:48:33.247761: Epoch time: 15.65 s 
2025-08-28 16:48:33.980280:  
2025-08-28 16:48:33.990755: Epoch 812 
2025-08-28 16:48:33.996871: Current learning rate: 0.00222 
2025-08-28 16:48:49.679900: train_loss -0.5807 
2025-08-28 16:48:49.688347: val_loss -0.5649 
2025-08-28 16:48:49.692252: Pseudo dice [np.float32(0.7021)] 
2025-08-28 16:48:49.700195: Epoch time: 15.7 s 
2025-08-28 16:48:50.435330:  
2025-08-28 16:48:50.444695: Epoch 813 
2025-08-28 16:48:50.455368: Current learning rate: 0.00221 
2025-08-28 16:49:05.508856: train_loss -0.5857 
2025-08-28 16:49:05.520640: val_loss -0.5425 
2025-08-28 16:49:05.529017: Pseudo dice [np.float32(0.7434)] 
2025-08-28 16:49:05.534740: Epoch time: 15.08 s 
2025-08-28 16:49:06.219701:  
2025-08-28 16:49:06.229147: Epoch 814 
2025-08-28 16:49:06.235401: Current learning rate: 0.0022 
2025-08-28 16:49:20.773283: train_loss -0.5266 
2025-08-28 16:49:20.781662: val_loss -0.6085 
2025-08-28 16:49:20.785804: Pseudo dice [np.float32(0.7798)] 
2025-08-28 16:49:20.791653: Epoch time: 14.55 s 
2025-08-28 16:49:21.624780:  
2025-08-28 16:49:21.634200: Epoch 815 
2025-08-28 16:49:21.641457: Current learning rate: 0.00219 
2025-08-28 16:49:36.526648: train_loss -0.5978 
2025-08-28 16:49:36.534910: val_loss -0.517 
2025-08-28 16:49:36.539046: Pseudo dice [np.float32(0.6783)] 
2025-08-28 16:49:36.547263: Epoch time: 14.9 s 
2025-08-28 16:49:37.226708:  
2025-08-28 16:49:37.237256: Epoch 816 
2025-08-28 16:49:37.243346: Current learning rate: 0.00218 
2025-08-28 16:49:52.851490: train_loss -0.5654 
2025-08-28 16:49:52.863806: val_loss -0.5449 
2025-08-28 16:49:52.867923: Pseudo dice [np.float32(0.7931)] 
2025-08-28 16:49:52.874802: Epoch time: 15.63 s 
2025-08-28 16:49:53.551280:  
2025-08-28 16:49:53.561788: Epoch 817 
2025-08-28 16:49:53.570248: Current learning rate: 0.00217 
2025-08-28 16:50:08.392462: train_loss -0.5744 
2025-08-28 16:50:08.400301: val_loss -0.493 
2025-08-28 16:50:08.408603: Pseudo dice [np.float32(0.744)] 
2025-08-28 16:50:08.416157: Epoch time: 14.84 s 
2025-08-28 16:50:09.098153:  
2025-08-28 16:50:09.106514: Epoch 818 
2025-08-28 16:50:09.111756: Current learning rate: 0.00216 
2025-08-28 16:50:24.390975: train_loss -0.5869 
2025-08-28 16:50:24.399322: val_loss -0.5704 
2025-08-28 16:50:24.407271: Pseudo dice [np.float32(0.7695)] 
2025-08-28 16:50:24.412372: Epoch time: 15.29 s 
2025-08-28 16:50:25.082797:  
2025-08-28 16:50:25.091227: Epoch 819 
2025-08-28 16:50:25.099624: Current learning rate: 0.00215 
2025-08-28 16:50:40.269470: train_loss -0.5893 
2025-08-28 16:50:40.277732: val_loss -0.5705 
2025-08-28 16:50:40.286111: Pseudo dice [np.float32(0.767)] 
2025-08-28 16:50:40.291286: Epoch time: 15.19 s 
2025-08-28 16:50:40.950783:  
2025-08-28 16:50:40.959146: Epoch 820 
2025-08-28 16:50:40.966481: Current learning rate: 0.00214 
2025-08-28 16:50:56.556692: train_loss -0.5889 
2025-08-28 16:50:56.564860: val_loss -0.5724 
2025-08-28 16:50:56.573329: Pseudo dice [np.float32(0.716)] 
2025-08-28 16:50:56.578220: Epoch time: 15.61 s 
2025-08-28 16:50:57.373346:  
2025-08-28 16:50:57.381709: Epoch 821 
2025-08-28 16:50:57.388121: Current learning rate: 0.00213 
2025-08-28 16:51:11.317622: train_loss -0.5777 
2025-08-28 16:51:11.329094: val_loss -0.4986 
2025-08-28 16:51:11.333701: Pseudo dice [np.float32(0.7234)] 
2025-08-28 16:51:11.339586: Epoch time: 13.95 s 
2025-08-28 16:51:11.983806:  
2025-08-28 16:51:11.993296: Epoch 822 
2025-08-28 16:51:12.000446: Current learning rate: 0.00212 
2025-08-28 16:51:26.051955: train_loss -0.5544 
2025-08-28 16:51:26.060491: val_loss -0.5574 
2025-08-28 16:51:26.065058: Pseudo dice [np.float32(0.7053)] 
2025-08-28 16:51:26.071736: Epoch time: 14.07 s 
2025-08-28 16:51:26.720509:  
2025-08-28 16:51:26.729832: Epoch 823 
2025-08-28 16:51:26.735025: Current learning rate: 0.0021 
2025-08-28 16:51:40.671388: train_loss -0.5834 
2025-08-28 16:51:40.679878: val_loss -0.605 
2025-08-28 16:51:40.688158: Pseudo dice [np.float32(0.7772)] 
2025-08-28 16:51:40.695925: Epoch time: 13.95 s 
2025-08-28 16:51:41.347593:  
2025-08-28 16:51:41.358935: Epoch 824 
2025-08-28 16:51:41.369449: Current learning rate: 0.00209 
2025-08-28 16:51:55.331852: train_loss -0.5815 
2025-08-28 16:51:55.340182: val_loss -0.5049 
2025-08-28 16:51:55.348191: Pseudo dice [np.float32(0.7497)] 
2025-08-28 16:51:55.353222: Epoch time: 13.99 s 
2025-08-28 16:51:56.003923:  
2025-08-28 16:51:56.012249: Epoch 825 
2025-08-28 16:51:56.017393: Current learning rate: 0.00208 
2025-08-28 16:52:10.129842: train_loss -0.5817 
2025-08-28 16:52:10.138204: val_loss -0.4834 
2025-08-28 16:52:10.145821: Pseudo dice [np.float32(0.6348)] 
2025-08-28 16:52:10.151368: Epoch time: 14.13 s 
2025-08-28 16:52:10.810375:  
2025-08-28 16:52:10.818128: Epoch 826 
2025-08-28 16:52:10.824255: Current learning rate: 0.00207 
2025-08-28 16:52:24.544778: train_loss -0.6053 
2025-08-28 16:52:24.552622: val_loss -0.5921 
2025-08-28 16:52:24.561133: Pseudo dice [np.float32(0.7183)] 
2025-08-28 16:52:24.566819: Epoch time: 13.74 s 
2025-08-28 16:52:25.213219:  
2025-08-28 16:52:25.222626: Epoch 827 
2025-08-28 16:52:25.228897: Current learning rate: 0.00206 
2025-08-28 16:52:39.162897: train_loss -0.6158 
2025-08-28 16:52:39.171456: val_loss -0.565 
2025-08-28 16:52:39.175599: Pseudo dice [np.float32(0.8184)] 
2025-08-28 16:52:39.183392: Epoch time: 13.95 s 
2025-08-28 16:52:40.003976:  
2025-08-28 16:52:40.013330: Epoch 828 
2025-08-28 16:52:40.021815: Current learning rate: 0.00205 
2025-08-28 16:52:53.977955: train_loss -0.5517 
2025-08-28 16:52:53.986210: val_loss -0.5706 
2025-08-28 16:52:53.994584: Pseudo dice [np.float32(0.7737)] 
2025-08-28 16:52:54.000376: Epoch time: 13.98 s 
2025-08-28 16:52:54.636256:  
2025-08-28 16:52:54.643602: Epoch 829 
2025-08-28 16:52:54.649936: Current learning rate: 0.00204 
2025-08-28 16:53:08.597255: train_loss -0.5909 
2025-08-28 16:53:08.604926: val_loss -0.5289 
2025-08-28 16:53:08.613002: Pseudo dice [np.float32(0.6721)] 
2025-08-28 16:53:08.618522: Epoch time: 13.96 s 
2025-08-28 16:53:09.268691:  
2025-08-28 16:53:09.275877: Epoch 830 
2025-08-28 16:53:09.282236: Current learning rate: 0.00203 
2025-08-28 16:53:23.291092: train_loss -0.5904 
2025-08-28 16:53:23.298775: val_loss -0.6422 
2025-08-28 16:53:23.307099: Pseudo dice [np.float32(0.7873)] 
2025-08-28 16:53:23.312626: Epoch time: 14.02 s 
2025-08-28 16:53:23.960347:  
2025-08-28 16:53:23.968734: Epoch 831 
2025-08-28 16:53:23.976068: Current learning rate: 0.00202 
2025-08-28 16:53:37.917716: train_loss -0.5538 
2025-08-28 16:53:37.925943: val_loss -0.4771 
2025-08-28 16:53:37.930138: Pseudo dice [np.float32(0.7239)] 
2025-08-28 16:53:37.937728: Epoch time: 13.96 s 
2025-08-28 16:53:38.585554:  
2025-08-28 16:53:38.593820: Epoch 832 
2025-08-28 16:53:38.602163: Current learning rate: 0.00201 
2025-08-28 16:53:52.648737: train_loss -0.5683 
2025-08-28 16:53:52.660991: val_loss -0.5127 
2025-08-28 16:53:52.665704: Pseudo dice [np.float32(0.7577)] 
2025-08-28 16:53:52.671387: Epoch time: 14.07 s 
2025-08-28 16:53:53.332363:  
2025-08-28 16:53:53.343868: Epoch 833 
2025-08-28 16:53:53.350230: Current learning rate: 0.002 
2025-08-28 16:54:07.054988: train_loss -0.6121 
2025-08-28 16:54:07.063388: val_loss -0.5781 
2025-08-28 16:54:07.067584: Pseudo dice [np.float32(0.7198)] 
2025-08-28 16:54:07.074276: Epoch time: 13.72 s 
2025-08-28 16:54:07.717549:  
2025-08-28 16:54:07.724876: Epoch 834 
2025-08-28 16:54:07.731339: Current learning rate: 0.00199 
2025-08-28 16:54:21.686278: train_loss -0.6066 
2025-08-28 16:54:21.694592: val_loss -0.4916 
2025-08-28 16:54:21.702992: Pseudo dice [np.float32(0.7687)] 
2025-08-28 16:54:21.708703: Epoch time: 13.97 s 
2025-08-28 16:54:22.518857:  
2025-08-28 16:54:22.529339: Epoch 835 
2025-08-28 16:54:22.535501: Current learning rate: 0.00198 
2025-08-28 16:54:36.663980: train_loss -0.5617 
2025-08-28 16:54:36.672163: val_loss -0.525 
2025-08-28 16:54:36.676312: Pseudo dice [np.float32(0.7106)] 
2025-08-28 16:54:36.684116: Epoch time: 14.15 s 
2025-08-28 16:54:37.324267:  
2025-08-28 16:54:37.333642: Epoch 836 
2025-08-28 16:54:37.339942: Current learning rate: 0.00196 
2025-08-28 16:54:51.099212: train_loss -0.5891 
2025-08-28 16:54:51.108275: val_loss -0.5771 
2025-08-28 16:54:51.111549: Pseudo dice [np.float32(0.7112)] 
2025-08-28 16:54:51.120146: Epoch time: 13.78 s 
2025-08-28 16:54:51.768854:  
2025-08-28 16:54:51.777201: Epoch 837 
2025-08-28 16:54:51.782348: Current learning rate: 0.00195 
2025-08-28 16:55:05.863665: train_loss -0.5293 
2025-08-28 16:55:05.876272: val_loss -0.6148 
2025-08-28 16:55:05.880876: Pseudo dice [np.float32(0.7361)] 
2025-08-28 16:55:05.888211: Epoch time: 14.1 s 
2025-08-28 16:55:06.538857:  
2025-08-28 16:55:06.549415: Epoch 838 
2025-08-28 16:55:06.555458: Current learning rate: 0.00194 
2025-08-28 16:55:20.553448: train_loss -0.6068 
2025-08-28 16:55:20.561902: val_loss -0.6008 
2025-08-28 16:55:20.565957: Pseudo dice [np.float32(0.812)] 
2025-08-28 16:55:20.573471: Epoch time: 14.02 s 
2025-08-28 16:55:21.225858:  
2025-08-28 16:55:21.234773: Epoch 839 
2025-08-28 16:55:21.240940: Current learning rate: 0.00193 
2025-08-28 16:55:35.046037: train_loss -0.5944 
2025-08-28 16:55:35.051168: val_loss -0.5364 
2025-08-28 16:55:35.059471: Pseudo dice [np.float32(0.7267)] 
2025-08-28 16:55:35.066698: Epoch time: 13.82 s 
2025-08-28 16:55:35.712752:  
2025-08-28 16:55:35.721185: Epoch 840 
2025-08-28 16:55:35.727458: Current learning rate: 0.00192 
2025-08-28 16:55:49.549684: train_loss -0.5863 
2025-08-28 16:55:49.557342: val_loss -0.5648 
2025-08-28 16:55:49.565700: Pseudo dice [np.float32(0.714)] 
2025-08-28 16:55:49.570794: Epoch time: 13.84 s 
2025-08-28 16:55:50.220598:  
2025-08-28 16:55:50.230395: Epoch 841 
2025-08-28 16:55:50.237775: Current learning rate: 0.00191 
2025-08-28 16:56:04.230362: train_loss -0.598 
2025-08-28 16:56:04.238751: val_loss -0.5849 
2025-08-28 16:56:04.247069: Pseudo dice [np.float32(0.7588)] 
2025-08-28 16:56:04.252192: Epoch time: 14.01 s 
2025-08-28 16:56:05.060860:  
2025-08-28 16:56:05.070223: Epoch 842 
2025-08-28 16:56:05.076466: Current learning rate: 0.0019 
2025-08-28 16:56:19.003811: train_loss -0.5808 
2025-08-28 16:56:19.011995: val_loss -0.4406 
2025-08-28 16:56:19.019620: Pseudo dice [np.float32(0.6704)] 
2025-08-28 16:56:19.024748: Epoch time: 13.94 s 
2025-08-28 16:56:19.676597:  
2025-08-28 16:56:19.685805: Epoch 843 
2025-08-28 16:56:19.691032: Current learning rate: 0.00189 
2025-08-28 16:56:33.560550: train_loss -0.586 
2025-08-28 16:56:33.568009: val_loss -0.5079 
2025-08-28 16:56:33.575676: Pseudo dice [np.float32(0.6944)] 
2025-08-28 16:56:33.581034: Epoch time: 13.89 s 
2025-08-28 16:56:34.224310:  
2025-08-28 16:56:34.234716: Epoch 844 
2025-08-28 16:56:34.242166: Current learning rate: 0.00188 
2025-08-28 16:56:48.387331: train_loss -0.6068 
2025-08-28 16:56:48.398565: val_loss -0.5549 
2025-08-28 16:56:48.403559: Pseudo dice [np.float32(0.7952)] 
2025-08-28 16:56:48.412506: Epoch time: 14.16 s 
2025-08-28 16:56:49.064146:  
2025-08-28 16:56:49.073475: Epoch 845 
2025-08-28 16:56:49.078652: Current learning rate: 0.00187 
2025-08-28 16:57:03.044801: train_loss -0.5866 
2025-08-28 16:57:03.055764: val_loss -0.4837 
2025-08-28 16:57:03.059920: Pseudo dice [np.float32(0.6999)] 
2025-08-28 16:57:03.066504: Epoch time: 13.98 s 
2025-08-28 16:57:03.709924:  
2025-08-28 16:57:03.718257: Epoch 846 
2025-08-28 16:57:03.727809: Current learning rate: 0.00186 
2025-08-28 16:57:17.607847: train_loss -0.5886 
2025-08-28 16:57:17.616256: val_loss -0.6019 
2025-08-28 16:57:17.624001: Pseudo dice [np.float32(0.7714)] 
2025-08-28 16:57:17.629830: Epoch time: 13.9 s 
2025-08-28 16:57:18.291169:  
2025-08-28 16:57:18.301669: Epoch 847 
2025-08-28 16:57:18.307822: Current learning rate: 0.00185 
2025-08-28 16:57:32.159801: train_loss -0.5973 
2025-08-28 16:57:32.168171: val_loss -0.5294 
2025-08-28 16:57:32.172410: Pseudo dice [np.float32(0.7364)] 
2025-08-28 16:57:32.179062: Epoch time: 13.87 s 
2025-08-28 16:57:32.826478:  
2025-08-28 16:57:32.833912: Epoch 848 
2025-08-28 16:57:32.840211: Current learning rate: 0.00184 
2025-08-28 16:57:46.733114: train_loss -0.5995 
2025-08-28 16:57:46.741107: val_loss -0.5983 
2025-08-28 16:57:46.748759: Pseudo dice [np.float32(0.7248)] 
2025-08-28 16:57:46.754071: Epoch time: 13.91 s 
2025-08-28 16:57:47.561104:  
2025-08-28 16:57:47.569447: Epoch 849 
2025-08-28 16:57:47.578706: Current learning rate: 0.00182 
2025-08-28 16:58:01.484975: train_loss -0.5724 
2025-08-28 16:58:01.497386: val_loss -0.4541 
2025-08-28 16:58:01.501500: Pseudo dice [np.float32(0.6647)] 
2025-08-28 16:58:01.508380: Epoch time: 13.92 s 
2025-08-28 16:58:02.352954:  
2025-08-28 16:58:02.361696: Epoch 850 
2025-08-28 16:58:02.368464: Current learning rate: 0.00181 
2025-08-28 16:58:17.430030: train_loss -0.6057 
2025-08-28 16:58:17.438352: val_loss -0.5645 
2025-08-28 16:58:17.442515: Pseudo dice [np.float32(0.7653)] 
2025-08-28 16:58:17.450437: Epoch time: 15.08 s 
2025-08-28 16:58:18.097937:  
2025-08-28 16:58:18.107175: Epoch 851 
2025-08-28 16:58:18.113368: Current learning rate: 0.0018 
2025-08-28 16:58:33.950849: train_loss -0.5963 
2025-08-28 16:58:33.958935: val_loss -0.5174 
2025-08-28 16:58:33.966758: Pseudo dice [np.float32(0.712)] 
2025-08-28 16:58:33.971932: Epoch time: 15.85 s 
2025-08-28 16:58:34.642375:  
2025-08-28 16:58:34.650734: Epoch 852 
2025-08-28 16:58:34.657083: Current learning rate: 0.00179 
2025-08-28 16:58:51.364075: train_loss -0.582 
2025-08-28 16:58:51.372300: val_loss -0.6403 
2025-08-28 16:58:51.380066: Pseudo dice [np.float32(0.7749)] 
2025-08-28 16:58:51.385799: Epoch time: 16.72 s 
2025-08-28 16:58:52.075466:  
2025-08-28 16:58:52.084853: Epoch 853 
2025-08-28 16:58:52.092129: Current learning rate: 0.00178 
2025-08-28 16:59:09.044183: train_loss -0.5944 
2025-08-28 16:59:09.056774: val_loss -0.6238 
2025-08-28 16:59:09.060932: Pseudo dice [np.float32(0.7801)] 
2025-08-28 16:59:09.068633: Epoch time: 16.97 s 
2025-08-28 16:59:09.758749:  
2025-08-28 16:59:09.769195: Epoch 854 
2025-08-28 16:59:09.776461: Current learning rate: 0.00177 
2025-08-28 16:59:26.624094: train_loss -0.5898 
2025-08-28 16:59:26.632357: val_loss -0.5433 
2025-08-28 16:59:26.636554: Pseudo dice [np.float32(0.6532)] 
2025-08-28 16:59:26.644328: Epoch time: 16.87 s 
2025-08-28 16:59:27.324186:  
2025-08-28 16:59:27.334743: Epoch 855 
2025-08-28 16:59:27.341981: Current learning rate: 0.00176 
2025-08-28 16:59:44.201084: train_loss -0.5846 
2025-08-28 16:59:44.208328: val_loss -0.5219 
2025-08-28 16:59:44.216160: Pseudo dice [np.float32(0.775)] 
2025-08-28 16:59:44.221314: Epoch time: 16.88 s 
2025-08-28 16:59:45.072854:  
2025-08-28 16:59:45.082646: Epoch 856 
2025-08-28 16:59:45.088860: Current learning rate: 0.00175 
2025-08-28 17:00:01.733459: train_loss -0.5891 
2025-08-28 17:00:01.742403: val_loss -0.538 
2025-08-28 17:00:01.750699: Pseudo dice [np.float32(0.7112)] 
2025-08-28 17:00:01.756567: Epoch time: 16.66 s 
2025-08-28 17:00:02.447936:  
2025-08-28 17:00:02.457220: Epoch 857 
2025-08-28 17:00:02.462363: Current learning rate: 0.00174 
2025-08-28 17:00:19.292727: train_loss -0.588 
2025-08-28 17:00:19.301749: val_loss -0.5535 
2025-08-28 17:00:19.305842: Pseudo dice [np.float32(0.7569)] 
2025-08-28 17:00:19.313349: Epoch time: 16.85 s 
2025-08-28 17:00:19.994527:  
2025-08-28 17:00:20.001715: Epoch 858 
2025-08-28 17:00:20.007051: Current learning rate: 0.00173 
2025-08-28 17:00:36.694072: train_loss -0.582 
2025-08-28 17:00:36.702410: val_loss -0.5765 
2025-08-28 17:00:36.706469: Pseudo dice [np.float32(0.739)] 
2025-08-28 17:00:36.713469: Epoch time: 16.7 s 
2025-08-28 17:00:37.427548:  
2025-08-28 17:00:37.437766: Epoch 859 
2025-08-28 17:00:37.444164: Current learning rate: 0.00172 
2025-08-28 17:00:54.303337: train_loss -0.5989 
2025-08-28 17:00:54.315746: val_loss -0.5908 
2025-08-28 17:00:54.319880: Pseudo dice [np.float32(0.7884)] 
2025-08-28 17:00:54.327822: Epoch time: 16.88 s 
2025-08-28 17:00:55.035727:  
2025-08-28 17:00:55.044130: Epoch 860 
2025-08-28 17:00:55.050370: Current learning rate: 0.0017 
2025-08-28 17:01:11.954345: train_loss -0.5913 
2025-08-28 17:01:11.962779: val_loss -0.6241 
2025-08-28 17:01:11.966697: Pseudo dice [np.float32(0.7851)] 
2025-08-28 17:01:11.976140: Epoch time: 16.92 s 
2025-08-28 17:01:12.672365:  
2025-08-28 17:01:12.681560: Epoch 861 
2025-08-28 17:01:12.688684: Current learning rate: 0.00169 
2025-08-28 17:01:29.230115: train_loss -0.6348 
2025-08-28 17:01:29.238122: val_loss -0.5238 
2025-08-28 17:01:29.242251: Pseudo dice [np.float32(0.6994)] 
2025-08-28 17:01:29.250279: Epoch time: 16.56 s 
2025-08-28 17:01:29.934005:  
2025-08-28 17:01:29.942352: Epoch 862 
2025-08-28 17:01:29.947736: Current learning rate: 0.00168 
2025-08-28 17:01:46.581000: train_loss -0.575 
2025-08-28 17:01:46.592500: val_loss -0.4353 
2025-08-28 17:01:46.599669: Pseudo dice [np.float32(0.594)] 
2025-08-28 17:01:46.608046: Epoch time: 16.65 s 
2025-08-28 17:01:47.482684:  
2025-08-28 17:01:47.493176: Epoch 863 
2025-08-28 17:01:47.501657: Current learning rate: 0.00167 
2025-08-28 17:02:04.064993: train_loss -0.5976 
2025-08-28 17:02:04.077235: val_loss -0.6002 
2025-08-28 17:02:04.084845: Pseudo dice [np.float32(0.7618)] 
2025-08-28 17:02:04.091193: Epoch time: 16.58 s 
2025-08-28 17:02:04.807487:  
2025-08-28 17:02:04.816855: Epoch 864 
2025-08-28 17:02:04.822003: Current learning rate: 0.00166 
2025-08-28 17:02:21.390606: train_loss -0.6148 
2025-08-28 17:02:21.398774: val_loss -0.5036 
2025-08-28 17:02:21.402770: Pseudo dice [np.float32(0.7334)] 
2025-08-28 17:02:21.411695: Epoch time: 16.59 s 
2025-08-28 17:02:22.107023:  
2025-08-28 17:02:22.117468: Epoch 865 
2025-08-28 17:02:22.125808: Current learning rate: 0.00165 
2025-08-28 17:02:38.670194: train_loss -0.6128 
2025-08-28 17:02:38.678294: val_loss -0.5246 
2025-08-28 17:02:38.682453: Pseudo dice [np.float32(0.7566)] 
2025-08-28 17:02:38.689272: Epoch time: 16.57 s 
2025-08-28 17:02:39.409731:  
2025-08-28 17:02:39.418055: Epoch 866 
2025-08-28 17:02:39.423223: Current learning rate: 0.00164 
2025-08-28 17:02:56.020103: train_loss -0.6048 
2025-08-28 17:02:56.028974: val_loss -0.5978 
2025-08-28 17:02:56.033130: Pseudo dice [np.float32(0.8004)] 
2025-08-28 17:02:56.041069: Epoch time: 16.61 s 
2025-08-28 17:02:56.742711:  
2025-08-28 17:02:56.752103: Epoch 867 
2025-08-28 17:02:56.758174: Current learning rate: 0.00163 
2025-08-28 17:03:12.979479: train_loss -0.6019 
2025-08-28 17:03:12.987564: val_loss -0.5322 
2025-08-28 17:03:12.995259: Pseudo dice [np.float32(0.7473)] 
2025-08-28 17:03:12.999635: Epoch time: 16.24 s 
2025-08-28 17:03:13.706534:  
2025-08-28 17:03:13.715777: Epoch 868 
2025-08-28 17:03:13.720949: Current learning rate: 0.00162 
2025-08-28 17:03:30.271727: train_loss -0.6126 
2025-08-28 17:03:30.279749: val_loss -0.5861 
2025-08-28 17:03:30.287573: Pseudo dice [np.float32(0.7432)] 
2025-08-28 17:03:30.292869: Epoch time: 16.57 s 
2025-08-28 17:03:31.007056:  
2025-08-28 17:03:31.016391: Epoch 869 
2025-08-28 17:03:31.023774: Current learning rate: 0.00161 
2025-08-28 17:03:47.471519: train_loss -0.614 
2025-08-28 17:03:47.480451: val_loss -0.5118 
2025-08-28 17:03:47.484702: Pseudo dice [np.float32(0.702)] 
2025-08-28 17:03:47.491720: Epoch time: 16.47 s 
2025-08-28 17:03:48.199224:  
2025-08-28 17:03:48.207621: Epoch 870 
2025-08-28 17:03:48.212841: Current learning rate: 0.00159 
2025-08-28 17:04:04.931261: train_loss -0.5878 
2025-08-28 17:04:04.943635: val_loss -0.5601 
2025-08-28 17:04:04.947868: Pseudo dice [np.float32(0.753)] 
2025-08-28 17:04:04.956687: Epoch time: 16.73 s 
2025-08-28 17:04:05.704263:  
2025-08-28 17:04:05.717327: Epoch 871 
2025-08-28 17:04:05.728181: Current learning rate: 0.00158 
2025-08-28 17:04:22.210967: train_loss -0.5658 
2025-08-28 17:04:22.219261: val_loss -0.535 
2025-08-28 17:04:22.223520: Pseudo dice [np.float32(0.7618)] 
2025-08-28 17:04:22.230384: Epoch time: 16.51 s 
2025-08-28 17:04:22.959929:  
2025-08-28 17:04:22.968250: Epoch 872 
2025-08-28 17:04:22.974647: Current learning rate: 0.00157 
2025-08-28 17:04:39.674044: train_loss -0.6155 
2025-08-28 17:04:39.682471: val_loss -0.5734 
2025-08-28 17:04:39.686813: Pseudo dice [np.float32(0.727)] 
2025-08-28 17:04:39.693984: Epoch time: 16.72 s 
2025-08-28 17:04:40.405633:  
2025-08-28 17:04:40.415942: Epoch 873 
2025-08-28 17:04:40.424346: Current learning rate: 0.00156 
2025-08-28 17:04:57.112382: train_loss -0.6317 
2025-08-28 17:04:57.124906: val_loss -0.4941 
2025-08-28 17:04:57.129222: Pseudo dice [np.float32(0.639)] 
2025-08-28 17:04:57.138545: Epoch time: 16.71 s 
2025-08-28 17:04:57.886530:  
2025-08-28 17:04:57.906812: Epoch 874 
2025-08-28 17:04:57.916837: Current learning rate: 0.00155 
2025-08-28 17:05:14.862830: train_loss -0.6088 
2025-08-28 17:05:14.871676: val_loss -0.5541 
2025-08-28 17:05:14.875756: Pseudo dice [np.float32(0.7978)] 
2025-08-28 17:05:14.883601: Epoch time: 16.98 s 
2025-08-28 17:05:15.593795:  
2025-08-28 17:05:15.603238: Epoch 875 
2025-08-28 17:05:15.611723: Current learning rate: 0.00154 
2025-08-28 17:05:32.170719: train_loss -0.6025 
2025-08-28 17:05:32.176544: val_loss -0.5986 
2025-08-28 17:05:32.184954: Pseudo dice [np.float32(0.7493)] 
2025-08-28 17:05:32.192949: Epoch time: 16.58 s 
2025-08-28 17:05:33.053899:  
2025-08-28 17:05:33.064349: Epoch 876 
2025-08-28 17:05:33.074805: Current learning rate: 0.00153 
2025-08-28 17:05:49.431307: train_loss -0.6032 
2025-08-28 17:05:49.439458: val_loss -0.5052 
2025-08-28 17:05:49.443720: Pseudo dice [np.float32(0.7746)] 
2025-08-28 17:05:49.451547: Epoch time: 16.38 s 
2025-08-28 17:05:50.153378:  
2025-08-28 17:05:50.164824: Epoch 877 
2025-08-28 17:05:50.174372: Current learning rate: 0.00152 
2025-08-28 17:06:06.656971: train_loss -0.6266 
2025-08-28 17:06:06.668786: val_loss -0.5487 
2025-08-28 17:06:06.673468: Pseudo dice [np.float32(0.7339)] 
2025-08-28 17:06:06.680440: Epoch time: 16.51 s 
2025-08-28 17:06:07.385009:  
2025-08-28 17:06:07.394557: Epoch 878 
2025-08-28 17:06:07.405229: Current learning rate: 0.00151 
2025-08-28 17:06:24.032394: train_loss -0.5678 
2025-08-28 17:06:24.040867: val_loss -0.5936 
2025-08-28 17:06:24.044956: Pseudo dice [np.float32(0.7285)] 
2025-08-28 17:06:24.051942: Epoch time: 16.65 s 
2025-08-28 17:06:24.754538:  
2025-08-28 17:06:24.764845: Epoch 879 
2025-08-28 17:06:24.771176: Current learning rate: 0.00149 
2025-08-28 17:06:41.558198: train_loss -0.5819 
2025-08-28 17:06:41.566780: val_loss -0.5393 
2025-08-28 17:06:41.570827: Pseudo dice [np.float32(0.7549)] 
2025-08-28 17:06:41.579608: Epoch time: 16.81 s 
2025-08-28 17:06:42.282350:  
2025-08-28 17:06:42.291677: Epoch 880 
2025-08-28 17:06:42.300841: Current learning rate: 0.00148 
2025-08-28 17:06:59.238318: train_loss -0.5717 
2025-08-28 17:06:59.246698: val_loss -0.5432 
2025-08-28 17:06:59.254696: Pseudo dice [np.float32(0.662)] 
2025-08-28 17:06:59.259821: Epoch time: 16.96 s 
2025-08-28 17:06:59.957322:  
2025-08-28 17:06:59.965766: Epoch 881 
2025-08-28 17:06:59.971853: Current learning rate: 0.00147 
2025-08-28 17:07:16.926966: train_loss -0.5715 
2025-08-28 17:07:16.935347: val_loss -0.5143 
2025-08-28 17:07:16.939452: Pseudo dice [np.float32(0.6848)] 
2025-08-28 17:07:16.946232: Epoch time: 16.97 s 
2025-08-28 17:07:17.674000:  
2025-08-28 17:07:17.681206: Epoch 882 
2025-08-28 17:07:17.688648: Current learning rate: 0.00146 
2025-08-28 17:07:34.244131: train_loss -0.5372 
2025-08-28 17:07:34.252594: val_loss -0.6339 
2025-08-28 17:07:34.256715: Pseudo dice [np.float32(0.7669)] 
2025-08-28 17:07:34.263800: Epoch time: 16.57 s 
2025-08-28 17:07:34.967257:  
2025-08-28 17:07:34.977617: Epoch 883 
2025-08-28 17:07:34.984943: Current learning rate: 0.00145 
2025-08-28 17:07:51.653583: train_loss -0.623 
2025-08-28 17:07:51.661685: val_loss -0.5382 
2025-08-28 17:07:51.665939: Pseudo dice [np.float32(0.7698)] 
2025-08-28 17:07:51.673703: Epoch time: 16.69 s 
2025-08-28 17:07:52.533914:  
2025-08-28 17:07:52.543137: Epoch 884 
2025-08-28 17:07:52.548293: Current learning rate: 0.00144 
2025-08-28 17:08:08.828754: train_loss -0.5932 
2025-08-28 17:08:08.836983: val_loss -0.6382 
2025-08-28 17:08:08.844926: Pseudo dice [np.float32(0.7879)] 
2025-08-28 17:08:08.850040: Epoch time: 16.3 s 
2025-08-28 17:08:09.558117:  
2025-08-28 17:08:09.567233: Epoch 885 
2025-08-28 17:08:09.575872: Current learning rate: 0.00143 
2025-08-28 17:08:26.033657: train_loss -0.567 
2025-08-28 17:08:26.041781: val_loss -0.6046 
2025-08-28 17:08:26.045956: Pseudo dice [np.float32(0.7781)] 
2025-08-28 17:08:26.053783: Epoch time: 16.48 s 
2025-08-28 17:08:26.762472:  
2025-08-28 17:08:26.772960: Epoch 886 
2025-08-28 17:08:26.783700: Current learning rate: 0.00142 
2025-08-28 17:08:43.229163: train_loss -0.5974 
2025-08-28 17:08:43.233953: val_loss -0.5915 
2025-08-28 17:08:43.242289: Pseudo dice [np.float32(0.7638)] 
2025-08-28 17:08:43.247501: Epoch time: 16.47 s 
2025-08-28 17:08:43.944548:  
2025-08-28 17:08:43.952808: Epoch 887 
2025-08-28 17:08:43.958964: Current learning rate: 0.00141 
2025-08-28 17:09:00.421950: train_loss -0.5841 
2025-08-28 17:09:00.434370: val_loss -0.5893 
2025-08-28 17:09:00.438518: Pseudo dice [np.float32(0.7571)] 
2025-08-28 17:09:00.447402: Epoch time: 16.48 s 
2025-08-28 17:09:01.156465:  
2025-08-28 17:09:01.163646: Epoch 888 
2025-08-28 17:09:01.168978: Current learning rate: 0.00139 
2025-08-28 17:09:17.747091: train_loss -0.6154 
2025-08-28 17:09:17.756290: val_loss -0.6261 
2025-08-28 17:09:17.763759: Pseudo dice [np.float32(0.7666)] 
2025-08-28 17:09:17.770316: Epoch time: 16.59 s 
2025-08-28 17:09:18.489986:  
2025-08-28 17:09:18.499785: Epoch 889 
2025-08-28 17:09:18.510345: Current learning rate: 0.00138 
2025-08-28 17:09:35.452631: train_loss -0.5799 
2025-08-28 17:09:35.461293: val_loss -0.6469 
2025-08-28 17:09:35.469413: Pseudo dice [np.float32(0.8337)] 
2025-08-28 17:09:35.474578: Epoch time: 16.96 s 
2025-08-28 17:09:36.183206:  
2025-08-28 17:09:36.191477: Epoch 890 
2025-08-28 17:09:36.197623: Current learning rate: 0.00137 
2025-08-28 17:09:53.157867: train_loss -0.6191 
2025-08-28 17:09:53.166250: val_loss -0.5832 
2025-08-28 17:09:53.174512: Pseudo dice [np.float32(0.8264)] 
2025-08-28 17:09:53.179716: Epoch time: 16.98 s 
2025-08-28 17:09:53.183580: Yayy! New best EMA pseudo Dice: 0.7648000121116638 
2025-08-28 17:09:54.112465:  
2025-08-28 17:09:54.121983: Epoch 891 
2025-08-28 17:09:54.125982: Current learning rate: 0.00136 
2025-08-28 17:10:10.466829: train_loss -0.6208 
2025-08-28 17:10:10.475191: val_loss -0.6274 
2025-08-28 17:10:10.479491: Pseudo dice [np.float32(0.7525)] 
2025-08-28 17:10:10.488407: Epoch time: 16.36 s 
2025-08-28 17:10:11.149207:  
2025-08-28 17:10:11.159800: Epoch 892 
2025-08-28 17:10:11.166864: Current learning rate: 0.00135 
2025-08-28 17:10:26.786478: train_loss -0.5919 
2025-08-28 17:10:26.786478: val_loss -0.5714 
2025-08-28 17:10:26.795129: Pseudo dice [np.float32(0.7483)] 
2025-08-28 17:10:26.800306: Epoch time: 15.64 s 
2025-08-28 17:10:27.434114:  
2025-08-28 17:10:27.442462: Epoch 893 
2025-08-28 17:10:27.450723: Current learning rate: 0.00134 
2025-08-28 17:10:42.591119: train_loss -0.6066 
2025-08-28 17:10:42.592119: val_loss -0.5889 
2025-08-28 17:10:42.600410: Pseudo dice [np.float32(0.7743)] 
2025-08-28 17:10:42.607409: Epoch time: 15.16 s 
2025-08-28 17:10:43.244878:  
2025-08-28 17:10:43.253212: Epoch 894 
2025-08-28 17:10:43.257328: Current learning rate: 0.00133 
2025-08-28 17:10:58.052146: train_loss -0.5864 
2025-08-28 17:10:58.060571: val_loss -0.5655 
2025-08-28 17:10:58.068878: Pseudo dice [np.float32(0.7827)] 
2025-08-28 17:10:58.074033: Epoch time: 14.81 s 
2025-08-28 17:10:58.080315: Yayy! New best EMA pseudo Dice: 0.7652000188827515 
2025-08-28 17:10:58.920851:  
2025-08-28 17:10:58.929181: Epoch 895 
2025-08-28 17:10:58.936534: Current learning rate: 0.00132 
2025-08-28 17:11:14.151431: train_loss -0.6028 
2025-08-28 17:11:14.151431: val_loss -0.562 
2025-08-28 17:11:14.159679: Pseudo dice [np.float32(0.7357)] 
2025-08-28 17:11:14.166428: Epoch time: 15.23 s 
2025-08-28 17:11:14.797675:  
2025-08-28 17:11:14.806281: Epoch 896 
2025-08-28 17:11:14.810121: Current learning rate: 0.0013 
2025-08-28 17:11:29.783701: train_loss -0.5896 
2025-08-28 17:11:29.791838: val_loss -0.6204 
2025-08-28 17:11:29.799625: Pseudo dice [np.float32(0.8235)] 
2025-08-28 17:11:29.805358: Epoch time: 14.99 s 
2025-08-28 17:11:29.809305: Yayy! New best EMA pseudo Dice: 0.7684000134468079 
2025-08-28 17:11:30.784002:  
2025-08-28 17:11:30.792348: Epoch 897 
2025-08-28 17:11:30.797101: Current learning rate: 0.00129 
2025-08-28 17:11:45.841418: train_loss -0.6147 
2025-08-28 17:11:45.849549: val_loss -0.5707 
2025-08-28 17:11:45.853683: Pseudo dice [np.float32(0.7785)] 
2025-08-28 17:11:45.861560: Epoch time: 15.06 s 
2025-08-28 17:11:45.866704: Yayy! New best EMA pseudo Dice: 0.7694000005722046 
2025-08-28 17:11:46.675394:  
2025-08-28 17:11:46.683785: Epoch 898 
2025-08-28 17:11:46.692137: Current learning rate: 0.00128 
2025-08-28 17:12:02.616629: train_loss -0.5953 
2025-08-28 17:12:02.628854: val_loss -0.5267 
2025-08-28 17:12:02.633001: Pseudo dice [np.float32(0.7617)] 
2025-08-28 17:12:02.640816: Epoch time: 15.94 s 
2025-08-28 17:12:03.279521:  
2025-08-28 17:12:03.287886: Epoch 899 
2025-08-28 17:12:03.292068: Current learning rate: 0.00127 
2025-08-28 17:12:18.123439: train_loss -0.6354 
2025-08-28 17:12:18.131918: val_loss -0.5342 
2025-08-28 17:12:18.140215: Pseudo dice [np.float32(0.7897)] 
2025-08-28 17:12:18.145752: Epoch time: 14.85 s 
2025-08-28 17:12:18.368855: Yayy! New best EMA pseudo Dice: 0.7706999778747559 
2025-08-28 17:12:19.178135:  
2025-08-28 17:12:19.182934: Epoch 900 
2025-08-28 17:12:19.191337: Current learning rate: 0.00126 
2025-08-28 17:12:32.967839: train_loss -0.5929 
2025-08-28 17:12:32.975830: val_loss -0.5698 
2025-08-28 17:12:32.980220: Pseudo dice [np.float32(0.7777)] 
2025-08-28 17:12:32.988923: Epoch time: 13.79 s 
2025-08-28 17:12:32.993340: Yayy! New best EMA pseudo Dice: 0.771399974822998 
2025-08-28 17:12:33.809897:  
2025-08-28 17:12:33.818273: Epoch 901 
2025-08-28 17:12:33.826818: Current learning rate: 0.00125 
2025-08-28 17:12:48.491227: train_loss -0.6236 
2025-08-28 17:12:48.499687: val_loss -0.4767 
2025-08-28 17:12:48.503802: Pseudo dice [np.float32(0.713)] 
2025-08-28 17:12:48.512498: Epoch time: 14.68 s 
2025-08-28 17:12:49.150259:  
2025-08-28 17:12:49.154480: Epoch 902 
2025-08-28 17:12:49.162946: Current learning rate: 0.00124 
2025-08-28 17:13:03.152072: train_loss -0.6229 
2025-08-28 17:13:03.164315: val_loss -0.5171 
2025-08-28 17:13:03.168464: Pseudo dice [np.float32(0.7924)] 
2025-08-28 17:13:03.174338: Epoch time: 14.01 s 
2025-08-28 17:13:03.960181:  
2025-08-28 17:13:03.968617: Epoch 903 
2025-08-28 17:13:03.973366: Current learning rate: 0.00122 
2025-08-28 17:13:18.237087: train_loss -0.5718 
2025-08-28 17:13:18.245348: val_loss -0.5425 
2025-08-28 17:13:18.250214: Pseudo dice [np.float32(0.7394)] 
2025-08-28 17:13:18.255963: Epoch time: 14.28 s 
2025-08-28 17:13:18.884176:  
2025-08-28 17:13:18.892653: Epoch 904 
2025-08-28 17:13:18.900328: Current learning rate: 0.00121 
2025-08-28 17:13:33.832318: train_loss -0.6087 
2025-08-28 17:13:33.840759: val_loss -0.6601 
2025-08-28 17:13:33.849062: Pseudo dice [np.float32(0.7869)] 
2025-08-28 17:13:33.854337: Epoch time: 14.95 s 
2025-08-28 17:13:34.478900:  
2025-08-28 17:13:34.487266: Epoch 905 
2025-08-28 17:13:34.491374: Current learning rate: 0.0012 
2025-08-28 17:13:49.530886: train_loss -0.6217 
2025-08-28 17:13:49.539097: val_loss -0.6081 
2025-08-28 17:13:49.543883: Pseudo dice [np.float32(0.7942)] 
2025-08-28 17:13:49.550699: Epoch time: 15.05 s 
2025-08-28 17:13:50.177921:  
2025-08-28 17:13:50.186235: Epoch 906 
2025-08-28 17:13:50.193912: Current learning rate: 0.00119 
2025-08-28 17:14:04.863850: train_loss -0.5804 
2025-08-28 17:14:04.875960: val_loss -0.5803 
2025-08-28 17:14:04.880345: Pseudo dice [np.float32(0.7903)] 
2025-08-28 17:14:04.886711: Epoch time: 14.69 s 
2025-08-28 17:14:04.892938: Yayy! New best EMA pseudo Dice: 0.7721999883651733 
2025-08-28 17:14:05.701742:  
2025-08-28 17:14:05.710044: Epoch 907 
2025-08-28 17:14:05.717812: Current learning rate: 0.00118 
2025-08-28 17:14:20.929292: train_loss -0.6022 
2025-08-28 17:14:20.937734: val_loss -0.5597 
2025-08-28 17:14:20.946075: Pseudo dice [np.float32(0.7646)] 
2025-08-28 17:14:20.951977: Epoch time: 15.23 s 
2025-08-28 17:14:21.584274:  
2025-08-28 17:14:21.592906: Epoch 908 
2025-08-28 17:14:21.600960: Current learning rate: 0.00117 
2025-08-28 17:14:36.048741: train_loss -0.6311 
2025-08-28 17:14:36.057108: val_loss -0.5131 
2025-08-28 17:14:36.065496: Pseudo dice [np.float32(0.6715)] 
2025-08-28 17:14:36.073261: Epoch time: 14.46 s 
2025-08-28 17:14:36.711860:  
2025-08-28 17:14:36.720213: Epoch 909 
2025-08-28 17:14:36.728580: Current learning rate: 0.00116 
2025-08-28 17:14:50.629947: train_loss -0.5775 
2025-08-28 17:14:50.638227: val_loss -0.6086 
2025-08-28 17:14:50.642416: Pseudo dice [np.float32(0.7684)] 
2025-08-28 17:14:50.649070: Epoch time: 13.92 s 
2025-08-28 17:14:51.434935:  
2025-08-28 17:14:51.443213: Epoch 910 
2025-08-28 17:14:51.450974: Current learning rate: 0.00115 
2025-08-28 17:15:05.215624: train_loss -0.5865 
2025-08-28 17:15:05.227803: val_loss -0.5863 
2025-08-28 17:15:05.231989: Pseudo dice [np.float32(0.7644)] 
2025-08-28 17:15:05.238655: Epoch time: 13.78 s 
2025-08-28 17:15:05.865973:  
2025-08-28 17:15:05.874417: Epoch 911 
2025-08-28 17:15:05.882705: Current learning rate: 0.00113 
2025-08-28 17:15:19.725839: train_loss -0.6439 
2025-08-28 17:15:19.734045: val_loss -0.6596 
2025-08-28 17:15:19.741752: Pseudo dice [np.float32(0.7741)] 
2025-08-28 17:15:19.747078: Epoch time: 13.86 s 
2025-08-28 17:15:20.372123:  
2025-08-28 17:15:20.380424: Epoch 912 
2025-08-28 17:15:20.384593: Current learning rate: 0.00112 
2025-08-28 17:15:34.502389: train_loss -0.6414 
2025-08-28 17:15:34.510653: val_loss -0.5247 
2025-08-28 17:15:34.515447: Pseudo dice [np.float32(0.7693)] 
2025-08-28 17:15:34.520130: Epoch time: 14.13 s 
2025-08-28 17:15:35.152809:  
2025-08-28 17:15:35.157619: Epoch 913 
2025-08-28 17:15:35.165995: Current learning rate: 0.00111 
2025-08-28 17:15:49.888422: train_loss -0.5959 
2025-08-28 17:15:49.896862: val_loss -0.5027 
2025-08-28 17:15:49.901653: Pseudo dice [np.float32(0.6342)] 
2025-08-28 17:15:49.908390: Epoch time: 14.74 s 
2025-08-28 17:15:50.535554:  
2025-08-28 17:15:50.543879: Epoch 914 
2025-08-28 17:15:50.551582: Current learning rate: 0.0011 
2025-08-28 17:16:05.804383: train_loss -0.6368 
2025-08-28 17:16:05.813263: val_loss -0.6069 
2025-08-28 17:16:05.821012: Pseudo dice [np.float32(0.7959)] 
2025-08-28 17:16:05.827245: Epoch time: 15.27 s 
2025-08-28 17:16:06.463904:  
2025-08-28 17:16:06.472288: Epoch 915 
2025-08-28 17:16:06.479961: Current learning rate: 0.00109 
2025-08-28 17:16:21.508237: train_loss -0.6263 
2025-08-28 17:16:21.516786: val_loss -0.5757 
2025-08-28 17:16:21.524901: Pseudo dice [np.float32(0.6825)] 
2025-08-28 17:16:21.531687: Epoch time: 15.04 s 
2025-08-28 17:16:22.183244:  
2025-08-28 17:16:22.191602: Epoch 916 
2025-08-28 17:16:22.196386: Current learning rate: 0.00108 
2025-08-28 17:16:37.048562: train_loss -0.6008 
2025-08-28 17:16:37.057052: val_loss -0.6013 
2025-08-28 17:16:37.064705: Pseudo dice [np.float32(0.7557)] 
2025-08-28 17:16:37.070376: Epoch time: 14.87 s 
2025-08-28 17:16:37.857823:  
2025-08-28 17:16:37.866095: Epoch 917 
2025-08-28 17:16:37.870305: Current learning rate: 0.00106 
2025-08-28 17:16:53.431722: train_loss -0.6209 
2025-08-28 17:16:53.440082: val_loss -0.5394 
2025-08-28 17:16:53.448341: Pseudo dice [np.float32(0.7072)] 
2025-08-28 17:16:53.454009: Epoch time: 15.57 s 
2025-08-28 17:16:54.083759:  
2025-08-28 17:16:54.092124: Epoch 918 
2025-08-28 17:16:54.098295: Current learning rate: 0.00105 
2025-08-28 17:17:09.176775: train_loss -0.5993 
2025-08-28 17:17:09.188431: val_loss -0.5466 
2025-08-28 17:17:09.193305: Pseudo dice [np.float32(0.7811)] 
2025-08-28 17:17:09.199251: Epoch time: 15.09 s 
2025-08-28 17:17:09.827359:  
2025-08-28 17:17:09.839034: Epoch 919 
2025-08-28 17:17:09.843858: Current learning rate: 0.00104 
2025-08-28 17:17:25.117534: train_loss -0.5843 
2025-08-28 17:17:25.126057: val_loss -0.6249 
2025-08-28 17:17:25.134157: Pseudo dice [np.float32(0.8009)] 
2025-08-28 17:17:25.139450: Epoch time: 15.29 s 
2025-08-28 17:17:25.772200:  
2025-08-28 17:17:25.780998: Epoch 920 
2025-08-28 17:17:25.788975: Current learning rate: 0.00103 
2025-08-28 17:17:40.991801: train_loss -0.6233 
2025-08-28 17:17:40.999937: val_loss -0.5974 
2025-08-28 17:17:41.007690: Pseudo dice [np.float32(0.744)] 
2025-08-28 17:17:41.013047: Epoch time: 15.22 s 
2025-08-28 17:17:41.646482:  
2025-08-28 17:17:41.654812: Epoch 921 
2025-08-28 17:17:41.659102: Current learning rate: 0.00102 
2025-08-28 17:17:57.015430: train_loss -0.5843 
2025-08-28 17:17:57.024390: val_loss -0.5173 
2025-08-28 17:17:57.032098: Pseudo dice [np.float32(0.7354)] 
2025-08-28 17:17:57.037697: Epoch time: 15.37 s 
2025-08-28 17:17:57.670848:  
2025-08-28 17:17:57.679092: Epoch 922 
2025-08-28 17:17:57.686643: Current learning rate: 0.00101 
2025-08-28 17:18:12.626841: train_loss -0.605 
2025-08-28 17:18:12.635815: val_loss -0.6226 
2025-08-28 17:18:12.639928: Pseudo dice [np.float32(0.8086)] 
2025-08-28 17:18:12.646679: Epoch time: 14.96 s 
2025-08-28 17:18:13.282180:  
2025-08-28 17:18:13.290550: Epoch 923 
2025-08-28 17:18:13.298928: Current learning rate: 0.001 
2025-08-28 17:18:28.263899: train_loss -0.617 
2025-08-28 17:18:28.272215: val_loss -0.5507 
2025-08-28 17:18:28.276411: Pseudo dice [np.float32(0.7531)] 
2025-08-28 17:18:28.285158: Epoch time: 14.98 s 
2025-08-28 17:18:29.081276:  
2025-08-28 17:18:29.089626: Epoch 924 
2025-08-28 17:18:29.093798: Current learning rate: 0.00098 
2025-08-28 17:18:44.688060: train_loss -0.6052 
2025-08-28 17:18:44.692751: val_loss -0.5841 
2025-08-28 17:18:44.701010: Pseudo dice [np.float32(0.754)] 
2025-08-28 17:18:44.706455: Epoch time: 15.61 s 
2025-08-28 17:18:45.334998:  
2025-08-28 17:18:45.343430: Epoch 925 
2025-08-28 17:18:45.347773: Current learning rate: 0.00097 
2025-08-28 17:19:00.399961: train_loss -0.6182 
2025-08-28 17:19:00.412581: val_loss -0.5419 
2025-08-28 17:19:00.416859: Pseudo dice [np.float32(0.7564)] 
2025-08-28 17:19:00.424660: Epoch time: 15.06 s 
2025-08-28 17:19:01.059036:  
2025-08-28 17:19:01.067507: Epoch 926 
2025-08-28 17:19:01.071519: Current learning rate: 0.00096 
2025-08-28 17:19:16.416120: train_loss -0.6224 
2025-08-28 17:19:16.424458: val_loss -0.5615 
2025-08-28 17:19:16.428520: Pseudo dice [np.float32(0.7478)] 
2025-08-28 17:19:16.436304: Epoch time: 15.36 s 
2025-08-28 17:19:17.066652:  
2025-08-28 17:19:17.074987: Epoch 927 
2025-08-28 17:19:17.079214: Current learning rate: 0.00095 
2025-08-28 17:19:32.373872: train_loss -0.6296 
2025-08-28 17:19:32.382010: val_loss -0.5058 
2025-08-28 17:19:32.386562: Pseudo dice [np.float32(0.7849)] 
2025-08-28 17:19:32.395116: Epoch time: 15.31 s 
2025-08-28 17:19:33.032677:  
2025-08-28 17:19:33.041040: Epoch 928 
2025-08-28 17:19:33.048795: Current learning rate: 0.00094 
2025-08-28 17:19:48.087888: train_loss -0.6254 
2025-08-28 17:19:48.100118: val_loss -0.5657 
2025-08-28 17:19:48.109696: Pseudo dice [np.float32(0.8039)] 
2025-08-28 17:19:48.117987: Epoch time: 15.06 s 
2025-08-28 17:19:48.773285:  
2025-08-28 17:19:48.781938: Epoch 929 
2025-08-28 17:19:48.785887: Current learning rate: 0.00092 
2025-08-28 17:20:03.759375: train_loss -0.6162 
2025-08-28 17:20:03.771095: val_loss -0.5877 
2025-08-28 17:20:03.775889: Pseudo dice [np.float32(0.7327)] 
2025-08-28 17:20:03.781589: Epoch time: 14.99 s 
2025-08-28 17:20:04.572472:  
2025-08-28 17:20:04.584449: Epoch 930 
2025-08-28 17:20:04.589216: Current learning rate: 0.00091 
2025-08-28 17:20:19.550632: train_loss -0.6225 
2025-08-28 17:20:19.558509: val_loss -0.5846 
2025-08-28 17:20:19.565944: Pseudo dice [np.float32(0.7471)] 
2025-08-28 17:20:19.571246: Epoch time: 14.98 s 
2025-08-28 17:20:20.204675:  
2025-08-28 17:20:20.213182: Epoch 931 
2025-08-28 17:20:20.217309: Current learning rate: 0.0009 
2025-08-28 17:20:35.761892: train_loss -0.6348 
2025-08-28 17:20:35.770335: val_loss -0.6444 
2025-08-28 17:20:35.774512: Pseudo dice [np.float32(0.7658)] 
2025-08-28 17:20:35.782181: Epoch time: 15.56 s 
2025-08-28 17:20:36.408342:  
2025-08-28 17:20:36.416698: Epoch 932 
2025-08-28 17:20:36.424663: Current learning rate: 0.00089 
2025-08-28 17:20:51.502889: train_loss -0.5953 
2025-08-28 17:20:51.511045: val_loss -0.5585 
2025-08-28 17:20:51.515177: Pseudo dice [np.float32(0.7917)] 
2025-08-28 17:20:51.523069: Epoch time: 15.09 s 
2025-08-28 17:20:52.157454:  
2025-08-28 17:20:52.165838: Epoch 933 
2025-08-28 17:20:52.173443: Current learning rate: 0.00088 
2025-08-28 17:21:07.722975: train_loss -0.6463 
2025-08-28 17:21:07.731371: val_loss -0.5969 
2025-08-28 17:21:07.739048: Pseudo dice [np.float32(0.7185)] 
2025-08-28 17:21:07.744826: Epoch time: 15.57 s 
2025-08-28 17:21:08.377885:  
2025-08-28 17:21:08.385665: Epoch 934 
2025-08-28 17:21:08.390888: Current learning rate: 0.00087 
2025-08-28 17:21:23.805787: train_loss -0.5802 
2025-08-28 17:21:23.814163: val_loss -0.5893 
2025-08-28 17:21:23.818320: Pseudo dice [np.float32(0.739)] 
2025-08-28 17:21:23.825166: Epoch time: 15.43 s 
2025-08-28 17:21:24.460528:  
2025-08-28 17:21:24.468890: Epoch 935 
2025-08-28 17:21:24.477211: Current learning rate: 0.00085 
2025-08-28 17:21:39.563197: train_loss -0.6198 
2025-08-28 17:21:39.571529: val_loss -0.5203 
2025-08-28 17:21:39.575673: Pseudo dice [np.float32(0.7118)] 
2025-08-28 17:21:39.581576: Epoch time: 15.1 s 
2025-08-28 17:21:40.213810:  
2025-08-28 17:21:40.222129: Epoch 936 
2025-08-28 17:21:40.226326: Current learning rate: 0.00084 
2025-08-28 17:21:55.395740: train_loss -0.603 
2025-08-28 17:21:55.403869: val_loss -0.6456 
2025-08-28 17:21:55.412246: Pseudo dice [np.float32(0.7764)] 
2025-08-28 17:21:55.419014: Epoch time: 15.18 s 
2025-08-28 17:21:56.058821:  
2025-08-28 17:21:56.067180: Epoch 937 
2025-08-28 17:21:56.071320: Current learning rate: 0.00083 
2025-08-28 17:22:11.386079: train_loss -0.6134 
2025-08-28 17:22:11.394961: val_loss -0.5239 
2025-08-28 17:22:11.399123: Pseudo dice [np.float32(0.7439)] 
2025-08-28 17:22:11.405166: Epoch time: 15.33 s 
2025-08-28 17:22:12.208169:  
2025-08-28 17:22:12.216525: Epoch 938 
2025-08-28 17:22:12.220772: Current learning rate: 0.00082 
2025-08-28 17:22:27.898854: train_loss -0.6198 
2025-08-28 17:22:27.907265: val_loss -0.6145 
2025-08-28 17:22:27.911375: Pseudo dice [np.float32(0.8012)] 
2025-08-28 17:22:27.919105: Epoch time: 15.69 s 
2025-08-28 17:22:28.553156:  
2025-08-28 17:22:28.557856: Epoch 939 
2025-08-28 17:22:28.566235: Current learning rate: 0.00081 
2025-08-28 17:22:43.606250: train_loss -0.6051 
2025-08-28 17:22:43.614541: val_loss -0.6802 
2025-08-28 17:22:43.618699: Pseudo dice [np.float32(0.7929)] 
2025-08-28 17:22:43.626554: Epoch time: 15.06 s 
2025-08-28 17:22:44.260975:  
2025-08-28 17:22:44.269551: Epoch 940 
2025-08-28 17:22:44.276980: Current learning rate: 0.00079 
2025-08-28 17:23:01.090397: train_loss -0.6287 
2025-08-28 17:23:01.103109: val_loss -0.5955 
2025-08-28 17:23:01.107113: Pseudo dice [np.float32(0.756)] 
2025-08-28 17:23:01.114011: Epoch time: 16.83 s 
2025-08-28 17:23:01.766072:  
2025-08-28 17:23:01.774473: Epoch 941 
2025-08-28 17:23:01.778530: Current learning rate: 0.00078 
2025-08-28 17:23:18.870060: train_loss -0.6309 
2025-08-28 17:23:18.878418: val_loss -0.6022 
2025-08-28 17:23:18.883228: Pseudo dice [np.float32(0.794)] 
2025-08-28 17:23:18.888900: Epoch time: 17.1 s 
2025-08-28 17:23:19.541969:  
2025-08-28 17:23:19.550418: Epoch 942 
2025-08-28 17:23:19.554837: Current learning rate: 0.00077 
2025-08-28 17:23:36.305199: train_loss -0.6346 
2025-08-28 17:23:36.313034: val_loss -0.567 
2025-08-28 17:23:36.321526: Pseudo dice [np.float32(0.7488)] 
2025-08-28 17:23:36.327201: Epoch time: 16.77 s 
2025-08-28 17:23:36.980598:  
2025-08-28 17:23:36.988750: Epoch 943 
2025-08-28 17:23:36.993044: Current learning rate: 0.00076 
2025-08-28 17:23:53.942609: train_loss -0.6324 
2025-08-28 17:23:53.950917: val_loss -0.5891 
2025-08-28 17:23:53.955708: Pseudo dice [np.float32(0.7697)] 
2025-08-28 17:23:53.961597: Epoch time: 16.96 s 
2025-08-28 17:23:54.660793:  
2025-08-28 17:23:54.673366: Epoch 944 
2025-08-28 17:23:54.681822: Current learning rate: 0.00075 
2025-08-28 17:24:11.473333: train_loss -0.646 
2025-08-28 17:24:11.481596: val_loss -0.5701 
2025-08-28 17:24:11.489886: Pseudo dice [np.float32(0.774)] 
2025-08-28 17:24:11.494574: Epoch time: 16.81 s 
2025-08-28 17:24:12.315494:  
2025-08-28 17:24:12.323308: Epoch 945 
2025-08-28 17:24:12.328227: Current learning rate: 0.00074 
2025-08-28 17:24:29.157599: train_loss -0.6091 
2025-08-28 17:24:29.165749: val_loss -0.5876 
2025-08-28 17:24:29.173588: Pseudo dice [np.float32(0.7119)] 
2025-08-28 17:24:29.179385: Epoch time: 16.85 s 
2025-08-28 17:24:29.837341:  
2025-08-28 17:24:29.845898: Epoch 946 
2025-08-28 17:24:29.853425: Current learning rate: 0.00072 
2025-08-28 17:24:46.845447: train_loss -0.6567 
2025-08-28 17:24:46.853763: val_loss -0.5304 
2025-08-28 17:24:46.858559: Pseudo dice [np.float32(0.8009)] 
2025-08-28 17:24:46.864388: Epoch time: 17.01 s 
2025-08-28 17:24:47.521884:  
2025-08-28 17:24:47.529430: Epoch 947 
2025-08-28 17:24:47.534208: Current learning rate: 0.00071 
2025-08-28 17:25:04.034062: train_loss -0.6138 
2025-08-28 17:25:04.045703: val_loss -0.5921 
2025-08-28 17:25:04.050623: Pseudo dice [np.float32(0.7726)] 
2025-08-28 17:25:04.057904: Epoch time: 16.52 s 
2025-08-28 17:25:04.722468:  
2025-08-28 17:25:04.730542: Epoch 948 
2025-08-28 17:25:04.734576: Current learning rate: 0.0007 
2025-08-28 17:25:21.455560: train_loss -0.5879 
2025-08-28 17:25:21.463958: val_loss -0.6168 
2025-08-28 17:25:21.471583: Pseudo dice [np.float32(0.7912)] 
2025-08-28 17:25:21.476892: Epoch time: 16.73 s 
2025-08-28 17:25:22.143134:  
2025-08-28 17:25:22.147885: Epoch 949 
2025-08-28 17:25:22.155723: Current learning rate: 0.00069 
2025-08-28 17:25:38.836084: train_loss -0.6512 
2025-08-28 17:25:38.843676: val_loss -0.5937 
2025-08-28 17:25:38.847795: Pseudo dice [np.float32(0.7706)] 
2025-08-28 17:25:38.855753: Epoch time: 16.7 s 
2025-08-28 17:25:39.711385:  
2025-08-28 17:25:39.719493: Epoch 950 
2025-08-28 17:25:39.723858: Current learning rate: 0.00067 
2025-08-28 17:25:56.281896: train_loss -0.6407 
2025-08-28 17:25:56.290356: val_loss -0.6212 
2025-08-28 17:25:56.298729: Pseudo dice [np.float32(0.8052)] 
2025-08-28 17:25:56.303331: Epoch time: 16.57 s 
2025-08-28 17:25:57.111865:  
2025-08-28 17:25:57.120333: Epoch 951 
2025-08-28 17:25:57.124518: Current learning rate: 0.00066 
2025-08-28 17:26:14.008033: train_loss -0.6335 
2025-08-28 17:26:14.016393: val_loss -0.5906 
2025-08-28 17:26:14.024004: Pseudo dice [np.float32(0.7756)] 
2025-08-28 17:26:14.028348: Epoch time: 16.9 s 
2025-08-28 17:26:14.683549:  
2025-08-28 17:26:14.691970: Epoch 952 
2025-08-28 17:26:14.699588: Current learning rate: 0.00065 
2025-08-28 17:26:31.016777: train_loss -0.6436 
2025-08-28 17:26:31.025176: val_loss -0.5873 
2025-08-28 17:26:31.032716: Pseudo dice [np.float32(0.7184)] 
2025-08-28 17:26:31.038553: Epoch time: 16.33 s 
2025-08-28 17:26:31.692257:  
2025-08-28 17:26:31.700603: Epoch 953 
2025-08-28 17:26:31.704805: Current learning rate: 0.00064 
2025-08-28 17:26:48.404648: train_loss -0.6356 
2025-08-28 17:26:48.413304: val_loss -0.5196 
2025-08-28 17:26:48.417310: Pseudo dice [np.float32(0.7077)] 
2025-08-28 17:26:48.423652: Epoch time: 16.71 s 
2025-08-28 17:26:49.088493:  
2025-08-28 17:26:49.093048: Epoch 954 
2025-08-28 17:26:49.101092: Current learning rate: 0.00063 
2025-08-28 17:27:05.897442: train_loss -0.6131 
2025-08-28 17:27:05.909956: val_loss -0.6445 
2025-08-28 17:27:05.913988: Pseudo dice [np.float32(0.8381)] 
2025-08-28 17:27:05.920779: Epoch time: 16.81 s 
2025-08-28 17:27:06.597957:  
2025-08-28 17:27:06.606581: Epoch 955 
2025-08-28 17:27:06.614024: Current learning rate: 0.00061 
2025-08-28 17:27:23.439848: train_loss -0.6396 
2025-08-28 17:27:23.448204: val_loss -0.6005 
2025-08-28 17:27:23.452616: Pseudo dice [np.float32(0.7715)] 
2025-08-28 17:27:23.460232: Epoch time: 16.84 s 
2025-08-28 17:27:24.128028:  
2025-08-28 17:27:24.136398: Epoch 956 
2025-08-28 17:27:24.140523: Current learning rate: 0.0006 
2025-08-28 17:27:40.595340: train_loss -0.6071 
2025-08-28 17:27:40.602792: val_loss -0.598 
2025-08-28 17:27:40.611412: Pseudo dice [np.float32(0.7818)] 
2025-08-28 17:27:40.617085: Epoch time: 16.47 s 
2025-08-28 17:27:41.278532:  
2025-08-28 17:27:41.286813: Epoch 957 
2025-08-28 17:27:41.290921: Current learning rate: 0.00059 
2025-08-28 17:27:58.099432: train_loss -0.6486 
2025-08-28 17:27:58.111903: val_loss -0.6023 
2025-08-28 17:27:58.116082: Pseudo dice [np.float32(0.7712)] 
2025-08-28 17:27:58.122773: Epoch time: 16.82 s 
2025-08-28 17:27:58.950130:  
2025-08-28 17:27:58.957878: Epoch 958 
2025-08-28 17:27:58.962863: Current learning rate: 0.00058 
2025-08-28 17:28:15.858829: train_loss -0.6287 
2025-08-28 17:28:15.867223: val_loss -0.6143 
2025-08-28 17:28:15.871340: Pseudo dice [np.float32(0.7726)] 
2025-08-28 17:28:15.878108: Epoch time: 16.91 s 
2025-08-28 17:28:16.563759:  
2025-08-28 17:28:16.572037: Epoch 959 
2025-08-28 17:28:16.576351: Current learning rate: 0.00056 
2025-08-28 17:28:33.155108: train_loss -0.6225 
2025-08-28 17:28:33.163563: val_loss -0.5788 
2025-08-28 17:28:33.167796: Pseudo dice [np.float32(0.7151)] 
2025-08-28 17:28:33.176497: Epoch time: 16.59 s 
2025-08-28 17:28:33.843332:  
2025-08-28 17:28:33.851842: Epoch 960 
2025-08-28 17:28:33.855892: Current learning rate: 0.00055 
2025-08-28 17:28:50.401733: train_loss -0.6062 
2025-08-28 17:28:50.410015: val_loss -0.5669 
2025-08-28 17:28:50.417664: Pseudo dice [np.float32(0.8037)] 
2025-08-28 17:28:50.422948: Epoch time: 16.56 s 
2025-08-28 17:28:51.090010:  
2025-08-28 17:28:51.097573: Epoch 961 
2025-08-28 17:28:51.102353: Current learning rate: 0.00054 
2025-08-28 17:29:07.768920: train_loss -0.61 
2025-08-28 17:29:07.777144: val_loss -0.55 
2025-08-28 17:29:07.785078: Pseudo dice [np.float32(0.7232)] 
2025-08-28 17:29:07.791611: Epoch time: 16.68 s 
2025-08-28 17:29:08.461578:  
2025-08-28 17:29:08.469695: Epoch 962 
2025-08-28 17:29:08.473844: Current learning rate: 0.00053 
2025-08-28 17:29:25.049100: train_loss -0.6388 
2025-08-28 17:29:25.057073: val_loss -0.5638 
2025-08-28 17:29:25.061232: Pseudo dice [np.float32(0.7528)] 
2025-08-28 17:29:25.069055: Epoch time: 16.59 s 
2025-08-28 17:29:25.745236:  
2025-08-28 17:29:25.753483: Epoch 963 
2025-08-28 17:29:25.757891: Current learning rate: 0.00051 
2025-08-28 17:29:42.336165: train_loss -0.656 
2025-08-28 17:29:42.344568: val_loss -0.6106 
2025-08-28 17:29:42.349268: Pseudo dice [np.float32(0.7906)] 
2025-08-28 17:29:42.356106: Epoch time: 16.59 s 
2025-08-28 17:29:43.024863:  
2025-08-28 17:29:43.033373: Epoch 964 
2025-08-28 17:29:43.041116: Current learning rate: 0.0005 
2025-08-28 17:29:59.920450: train_loss -0.6421 
2025-08-28 17:29:59.930268: val_loss -0.563 
2025-08-28 17:29:59.937106: Pseudo dice [np.float32(0.7603)] 
2025-08-28 17:29:59.943287: Epoch time: 16.9 s 
2025-08-28 17:30:00.908776:  
2025-08-28 17:30:00.917304: Epoch 965 
2025-08-28 17:30:00.922265: Current learning rate: 0.00049 
2025-08-28 17:30:16.787905: train_loss -0.6168 
2025-08-28 17:30:16.796167: val_loss -0.6103 
2025-08-28 17:30:16.803942: Pseudo dice [np.float32(0.7927)] 
2025-08-28 17:30:16.809625: Epoch time: 15.88 s 
2025-08-28 17:30:17.450905:  
2025-08-28 17:30:17.459401: Epoch 966 
2025-08-28 17:30:17.463530: Current learning rate: 0.00048 
2025-08-28 17:30:32.495262: train_loss -0.6382 
2025-08-28 17:30:32.503565: val_loss -0.6143 
2025-08-28 17:30:32.511923: Pseudo dice [np.float32(0.7312)] 
2025-08-28 17:30:32.518645: Epoch time: 15.05 s 
2025-08-28 17:30:33.162574:  
2025-08-28 17:30:33.170885: Epoch 967 
2025-08-28 17:30:33.179249: Current learning rate: 0.00046 
2025-08-28 17:30:48.902720: train_loss -0.6316 
2025-08-28 17:30:48.904272: val_loss -0.6211 
2025-08-28 17:30:48.912142: Pseudo dice [np.float32(0.7226)] 
2025-08-28 17:30:48.918059: Epoch time: 15.74 s 
2025-08-28 17:30:49.594827:  
2025-08-28 17:30:49.594827: Epoch 968 
2025-08-28 17:30:49.604347: Current learning rate: 0.00045 
2025-08-28 17:31:04.260111: train_loss -0.6138 
2025-08-28 17:31:04.260111: val_loss -0.6066 
2025-08-28 17:31:04.272162: Pseudo dice [np.float32(0.7846)] 
2025-08-28 17:31:04.277479: Epoch time: 14.67 s 
2025-08-28 17:31:04.964950:  
2025-08-28 17:31:04.969235: Epoch 969 
2025-08-28 17:31:04.977589: Current learning rate: 0.00044 
2025-08-28 17:31:19.250169: train_loss -0.6334 
2025-08-28 17:31:19.250169: val_loss -0.5222 
2025-08-28 17:31:19.257922: Pseudo dice [np.float32(0.7157)] 
2025-08-28 17:31:19.264210: Epoch time: 14.29 s 
2025-08-28 17:31:19.977421:  
2025-08-28 17:31:19.988690: Epoch 970 
2025-08-28 17:31:19.996054: Current learning rate: 0.00043 
2025-08-28 17:31:34.665194: train_loss -0.6326 
2025-08-28 17:31:34.673386: val_loss -0.6507 
2025-08-28 17:31:34.682189: Pseudo dice [np.float32(0.7279)] 
2025-08-28 17:31:34.687878: Epoch time: 14.69 s 
2025-08-28 17:31:35.428172:  
2025-08-28 17:31:35.437614: Epoch 971 
2025-08-28 17:31:35.447087: Current learning rate: 0.00041 
2025-08-28 17:31:49.596614: train_loss -0.6175 
2025-08-28 17:31:49.604957: val_loss -0.5804 
2025-08-28 17:31:49.613333: Pseudo dice [np.float32(0.7805)] 
2025-08-28 17:31:49.621266: Epoch time: 14.17 s 
2025-08-28 17:31:50.270167:  
2025-08-28 17:31:50.278555: Epoch 972 
2025-08-28 17:31:50.283636: Current learning rate: 0.0004 
2025-08-28 17:32:04.307344: train_loss -0.5992 
2025-08-28 17:32:04.315485: val_loss -0.6065 
2025-08-28 17:32:04.323797: Pseudo dice [np.float32(0.7653)] 
2025-08-28 17:32:04.328738: Epoch time: 14.04 s 
2025-08-28 17:32:04.986860:  
2025-08-28 17:32:04.995195: Epoch 973 
2025-08-28 17:32:05.001479: Current learning rate: 0.00039 
2025-08-28 17:32:19.151361: train_loss -0.6216 
2025-08-28 17:32:19.159466: val_loss -0.6173 
2025-08-28 17:32:19.163644: Pseudo dice [np.float32(0.7597)] 
2025-08-28 17:32:19.170439: Epoch time: 14.17 s 
2025-08-28 17:32:19.823714:  
2025-08-28 17:32:19.830847: Epoch 974 
2025-08-28 17:32:19.836157: Current learning rate: 0.00037 
2025-08-28 17:32:33.657466: train_loss -0.627 
2025-08-28 17:32:33.665613: val_loss -0.6096 
2025-08-28 17:32:33.673937: Pseudo dice [np.float32(0.8272)] 
2025-08-28 17:32:33.679867: Epoch time: 13.84 s 
2025-08-28 17:32:34.341220:  
2025-08-28 17:32:34.352656: Epoch 975 
2025-08-28 17:32:34.359989: Current learning rate: 0.00036 
2025-08-28 17:32:48.156127: train_loss -0.6347 
2025-08-28 17:32:48.167793: val_loss -0.6222 
2025-08-28 17:32:48.171766: Pseudo dice [np.float32(0.7893)] 
2025-08-28 17:32:48.179219: Epoch time: 13.82 s 
2025-08-28 17:32:48.842124:  
2025-08-28 17:32:48.851508: Epoch 976 
2025-08-28 17:32:48.859839: Current learning rate: 0.00035 
2025-08-28 17:33:02.840831: train_loss -0.6285 
2025-08-28 17:33:02.853222: val_loss -0.5053 
2025-08-28 17:33:02.857235: Pseudo dice [np.float32(0.7113)] 
2025-08-28 17:33:02.865073: Epoch time: 14.0 s 
2025-08-28 17:33:03.513076:  
2025-08-28 17:33:03.520353: Epoch 977 
2025-08-28 17:33:03.526578: Current learning rate: 0.00034 
2025-08-28 17:33:17.534677: train_loss -0.6018 
2025-08-28 17:33:17.542763: val_loss -0.5931 
2025-08-28 17:33:17.546891: Pseudo dice [np.float32(0.7503)] 
2025-08-28 17:33:17.554760: Epoch time: 14.02 s 
2025-08-28 17:33:18.212118:  
2025-08-28 17:33:18.220406: Epoch 978 
2025-08-28 17:33:18.226601: Current learning rate: 0.00032 
2025-08-28 17:33:32.161670: train_loss -0.6554 
2025-08-28 17:33:32.169867: val_loss -0.5667 
2025-08-28 17:33:32.178526: Pseudo dice [np.float32(0.797)] 
2025-08-28 17:33:32.183593: Epoch time: 13.95 s 
2025-08-28 17:33:32.980115:  
2025-08-28 17:33:32.988392: Epoch 979 
2025-08-28 17:33:32.994487: Current learning rate: 0.00031 
2025-08-28 17:33:47.956435: train_loss -0.6252 
2025-08-28 17:33:47.968656: val_loss -0.6406 
2025-08-28 17:33:47.973137: Pseudo dice [np.float32(0.7799)] 
2025-08-28 17:33:47.978964: Epoch time: 14.98 s 
2025-08-28 17:33:48.634113:  
2025-08-28 17:33:48.642445: Epoch 980 
2025-08-28 17:33:48.648619: Current learning rate: 0.0003 
2025-08-28 17:34:03.505296: train_loss -0.6287 
2025-08-28 17:34:03.513918: val_loss -0.6256 
2025-08-28 17:34:03.521992: Pseudo dice [np.float32(0.7863)] 
2025-08-28 17:34:03.528202: Epoch time: 14.87 s 
2025-08-28 17:34:04.190302:  
2025-08-28 17:34:04.198670: Epoch 981 
2025-08-28 17:34:04.204912: Current learning rate: 0.00028 
2025-08-28 17:34:19.313440: train_loss -0.6218 
2025-08-28 17:34:19.324890: val_loss -0.609 
2025-08-28 17:34:19.329461: Pseudo dice [np.float32(0.775)] 
2025-08-28 17:34:19.336295: Epoch time: 15.13 s 
2025-08-28 17:34:19.993613:  
2025-08-28 17:34:20.002951: Epoch 982 
2025-08-28 17:34:20.008110: Current learning rate: 0.00027 
2025-08-28 17:34:35.195320: train_loss -0.6461 
2025-08-28 17:34:35.203596: val_loss -0.5372 
2025-08-28 17:34:35.207787: Pseudo dice [np.float32(0.7504)] 
2025-08-28 17:34:35.215708: Epoch time: 15.2 s 
2025-08-28 17:34:35.873936:  
2025-08-28 17:34:35.882345: Epoch 983 
2025-08-28 17:34:35.887471: Current learning rate: 0.00026 
2025-08-28 17:34:50.527221: train_loss -0.6474 
2025-08-28 17:34:50.535588: val_loss -0.597 
2025-08-28 17:34:50.543939: Pseudo dice [np.float32(0.7865)] 
2025-08-28 17:34:50.549826: Epoch time: 14.66 s 
2025-08-28 17:34:51.208090:  
2025-08-28 17:34:51.216887: Epoch 984 
2025-08-28 17:34:51.221669: Current learning rate: 0.00024 
2025-08-28 17:35:06.306522: train_loss -0.6577 
2025-08-28 17:35:06.313715: val_loss -0.5775 
2025-08-28 17:35:06.322078: Pseudo dice [np.float32(0.8188)] 
2025-08-28 17:35:06.328071: Epoch time: 15.1 s 
2025-08-28 17:35:06.335002: Yayy! New best EMA pseudo Dice: 0.7738999724388123 
2025-08-28 17:35:07.182372:  
2025-08-28 17:35:07.191687: Epoch 985 
2025-08-28 17:35:07.196856: Current learning rate: 0.00023 
2025-08-28 17:35:22.379872: train_loss -0.6624 
2025-08-28 17:35:22.388232: val_loss -0.5574 
2025-08-28 17:35:22.396849: Pseudo dice [np.float32(0.8082)] 
2025-08-28 17:35:22.401909: Epoch time: 15.2 s 
2025-08-28 17:35:22.408059: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-08-28 17:35:23.418231:  
2025-08-28 17:35:23.426567: Epoch 986 
2025-08-28 17:35:23.431910: Current learning rate: 0.00021 
2025-08-28 17:35:39.755516: train_loss -0.6107 
2025-08-28 17:35:39.763913: val_loss -0.6282 
2025-08-28 17:35:39.768087: Pseudo dice [np.float32(0.7489)] 
2025-08-28 17:35:39.775123: Epoch time: 16.34 s 
2025-08-28 17:35:40.507676:  
2025-08-28 17:35:40.515607: Epoch 987 
2025-08-28 17:35:40.522815: Current learning rate: 0.0002 
2025-08-28 17:35:57.318891: train_loss -0.6825 
2025-08-28 17:35:57.331416: val_loss -0.5497 
2025-08-28 17:35:57.335588: Pseudo dice [np.float32(0.7813)] 
2025-08-28 17:35:57.342736: Epoch time: 16.81 s 
2025-08-28 17:35:58.048753:  
2025-08-28 17:35:58.056011: Epoch 988 
2025-08-28 17:35:58.062347: Current learning rate: 0.00019 
2025-08-28 17:36:14.778189: train_loss -0.6312 
2025-08-28 17:36:14.786348: val_loss -0.5924 
2025-08-28 17:36:14.790509: Pseudo dice [np.float32(0.8073)] 
2025-08-28 17:36:14.797743: Epoch time: 16.73 s 
2025-08-28 17:36:14.803418: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2025-08-28 17:36:15.722306:  
2025-08-28 17:36:15.731431: Epoch 989 
2025-08-28 17:36:15.737534: Current learning rate: 0.00017 
2025-08-28 17:36:31.605559: train_loss -0.6592 
2025-08-28 17:36:31.611461: val_loss -0.6343 
2025-08-28 17:36:31.619814: Pseudo dice [np.float32(0.7856)] 
2025-08-28 17:36:31.627044: Epoch time: 15.88 s 
2025-08-28 17:36:31.633675: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-08-28 17:36:32.548865:  
2025-08-28 17:36:32.557097: Epoch 990 
2025-08-28 17:36:32.563419: Current learning rate: 0.00016 
2025-08-28 17:36:48.478301: train_loss -0.6575 
2025-08-28 17:36:48.486670: val_loss -0.5677 
2025-08-28 17:36:48.494999: Pseudo dice [np.float32(0.7547)] 
2025-08-28 17:36:48.501092: Epoch time: 15.93 s 
2025-08-28 17:36:49.208072:  
2025-08-28 17:36:49.216457: Epoch 991 
2025-08-28 17:36:49.222795: Current learning rate: 0.00014 
2025-08-28 17:37:05.186680: train_loss -0.6419 
2025-08-28 17:37:05.199193: val_loss -0.6499 
2025-08-28 17:37:05.203367: Pseudo dice [np.float32(0.8048)] 
2025-08-28 17:37:05.209732: Epoch time: 15.98 s 
2025-08-28 17:37:05.217253: Yayy! New best EMA pseudo Dice: 0.7795000076293945 
2025-08-28 17:37:06.249050:  
2025-08-28 17:37:06.256427: Epoch 992 
2025-08-28 17:37:06.261591: Current learning rate: 0.00013 
2025-08-28 17:37:22.958636: train_loss -0.6487 
2025-08-28 17:37:22.970959: val_loss -0.5923 
2025-08-28 17:37:22.975234: Pseudo dice [np.float32(0.7215)] 
2025-08-28 17:37:22.982479: Epoch time: 16.71 s 
2025-08-28 17:37:23.687462:  
2025-08-28 17:37:23.696739: Epoch 993 
2025-08-28 17:37:23.702051: Current learning rate: 0.00011 
2025-08-28 17:37:40.576157: train_loss -0.633 
2025-08-28 17:37:40.584497: val_loss -0.5949 
2025-08-28 17:37:40.588658: Pseudo dice [np.float32(0.746)] 
2025-08-28 17:37:40.597852: Epoch time: 16.89 s 
2025-08-28 17:37:41.295611:  
2025-08-28 17:37:41.302920: Epoch 994 
2025-08-28 17:37:41.308129: Current learning rate: 0.0001 
2025-08-28 17:37:58.043636: train_loss -0.6307 
2025-08-28 17:37:58.056149: val_loss -0.5951 
2025-08-28 17:37:58.060292: Pseudo dice [np.float32(0.763)] 
2025-08-28 17:37:58.069361: Epoch time: 16.75 s 
2025-08-28 17:37:58.767137:  
2025-08-28 17:37:58.775535: Epoch 995 
2025-08-28 17:37:58.780698: Current learning rate: 8e-05 
2025-08-28 17:38:15.723782: train_loss -0.6371 
2025-08-28 17:38:15.736296: val_loss -0.5858 
2025-08-28 17:38:15.745075: Pseudo dice [np.float32(0.7578)] 
2025-08-28 17:38:15.756587: Epoch time: 16.96 s 
2025-08-28 17:38:16.515014:  
2025-08-28 17:38:16.522402: Epoch 996 
2025-08-28 17:38:16.527626: Current learning rate: 7e-05 
2025-08-28 17:38:33.266482: train_loss -0.6402 
2025-08-28 17:38:33.274946: val_loss -0.6342 
2025-08-28 17:38:33.282999: Pseudo dice [np.float32(0.8117)] 
2025-08-28 17:38:33.287888: Epoch time: 16.75 s 
2025-08-28 17:38:34.016932:  
2025-08-28 17:38:34.027331: Epoch 997 
2025-08-28 17:38:34.034760: Current learning rate: 5e-05 
2025-08-28 17:38:51.046513: train_loss -0.6169 
2025-08-28 17:38:51.054836: val_loss -0.5876 
2025-08-28 17:38:51.063229: Pseudo dice [np.float32(0.7418)] 
2025-08-28 17:38:51.069544: Epoch time: 17.03 s 
2025-08-28 17:38:51.945348:  
2025-08-28 17:38:51.953572: Epoch 998 
2025-08-28 17:38:51.960937: Current learning rate: 4e-05 
2025-08-28 17:39:08.551466: train_loss -0.6434 
2025-08-28 17:39:08.559811: val_loss -0.5027 
2025-08-28 17:39:08.568441: Pseudo dice [np.float32(0.7296)] 
2025-08-28 17:39:08.575314: Epoch time: 16.61 s 
2025-08-28 17:39:09.264521:  
2025-08-28 17:39:09.272951: Epoch 999 
2025-08-28 17:39:09.279206: Current learning rate: 2e-05 
2025-08-28 17:39:26.256931: train_loss -0.6358 
2025-08-28 17:39:26.264967: val_loss -0.5914 
2025-08-28 17:39:26.273682: Pseudo dice [np.float32(0.8126)] 
2025-08-28 17:39:26.278929: Epoch time: 16.99 s 
2025-08-28 17:39:27.228962: Training done. 
2025-08-28 17:39:27.507173: Using splits from existing split file: C:\Users\super\Desktop\Cursor Projects\FYP\nnUNet_preprocessed\Dataset201_ATLAS2\splits_final.json 
2025-08-28 17:39:27.530412: The split file contains 5 splits. 
2025-08-28 17:39:27.541252: Desired fold for training: 3 
2025-08-28 17:39:27.549108: This split has 524 training and 131 validation cases. 
2025-08-28 17:39:27.558541: predicting sub-r001s002 
2025-08-28 17:39:27.808248: sub-r001s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:39:37.801500: predicting sub-r001s008 
2025-08-28 17:39:38.014234: sub-r001s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:39:48.670675: predicting sub-r001s009 
2025-08-28 17:39:48.895933: sub-r001s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:39:59.060243: predicting sub-r001s014 
2025-08-28 17:39:59.268764: sub-r001s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:40:09.729076: predicting sub-r001s015 
2025-08-28 17:40:09.933634: sub-r001s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:40:20.085660: predicting sub-r001s016 
2025-08-28 17:40:20.285613: sub-r001s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:40:30.934147: predicting sub-r001s022 
2025-08-28 17:40:31.163187: sub-r001s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:40:41.214694: predicting sub-r001s027 
2025-08-28 17:40:41.423357: sub-r001s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:40:52.154975: predicting sub-r001s039 
2025-08-28 17:40:52.380624: sub-r001s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:02.356758: predicting sub-r002s002 
2025-08-28 17:41:02.598664: sub-r002s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:12.500203: predicting sub-r002s005 
2025-08-28 17:41:12.752723: sub-r002s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:21.817850: predicting sub-r002s007 
2025-08-28 17:41:22.030491: sub-r002s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:32.578277: predicting sub-r002s008 
2025-08-28 17:41:32.774649: sub-r002s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:42.421880: predicting sub-r002s010 
2025-08-28 17:41:42.630599: sub-r002s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:41:52.123152: predicting sub-r002s012 
2025-08-28 17:41:52.360860: sub-r002s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:01.661778: predicting sub-r003s004 
2025-08-28 17:42:01.895365: sub-r003s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:12.330991: predicting sub-r003s012 
2025-08-28 17:42:12.539375: sub-r003s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:22.524545: predicting sub-r003s013 
2025-08-28 17:42:22.741224: sub-r003s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:32.534132: predicting sub-r004s010 
2025-08-28 17:42:32.742823: sub-r004s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:42.181407: predicting sub-r004s015 
2025-08-28 17:42:42.389954: sub-r004s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:42:52.445851: predicting sub-r004s016 
2025-08-28 17:42:52.654704: sub-r004s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:02.681082: predicting sub-r004s018 
2025-08-28 17:43:02.923005: sub-r004s018, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:13.950935: predicting sub-r004s031 
2025-08-28 17:43:14.163381: sub-r004s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:23.685400: predicting sub-r004s034 
2025-08-28 17:43:23.893948: sub-r004s034, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:34.567353: predicting sub-r005s031 
2025-08-28 17:43:34.771452: sub-r005s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:44.406349: predicting sub-r005s073 
2025-08-28 17:43:44.631281: sub-r005s073, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:43:55.016848: predicting sub-r005s076 
2025-08-28 17:43:55.267128: sub-r005s076, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:05.114223: predicting sub-r009s003 
2025-08-28 17:44:05.335304: sub-r009s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:15.407846: predicting sub-r009s008 
2025-08-28 17:44:15.616389: sub-r009s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:24.909228: predicting sub-r009s012 
2025-08-28 17:44:25.138427: sub-r009s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:35.623843: predicting sub-r009s022 
2025-08-28 17:44:35.840732: sub-r009s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:45.521255: predicting sub-r009s024 
2025-08-28 17:44:45.742322: sub-r009s024, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:44:56.419599: predicting sub-r009s025 
2025-08-28 17:44:56.649016: sub-r009s025, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:06.563253: predicting sub-r009s028 
2025-08-28 17:45:06.792476: sub-r009s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:16.527419: predicting sub-r009s030 
2025-08-28 17:45:16.748275: sub-r009s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:26.841863: predicting sub-r009s032 
2025-08-28 17:45:27.062722: sub-r009s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:37.324281: predicting sub-r009s035 
2025-08-28 17:45:37.564875: sub-r009s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:47.199666: predicting sub-r009s051 
2025-08-28 17:45:47.412186: sub-r009s051, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:45:57.476529: predicting sub-r009s056 
2025-08-28 17:45:57.709949: sub-r009s056, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:06.326932: predicting sub-r009s057 
2025-08-28 17:46:06.564638: sub-r009s057, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:16.616337: predicting sub-r009s060 
2025-08-28 17:46:16.849912: sub-r009s060, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:25.533602: predicting sub-r009s061 
2025-08-28 17:46:25.754647: sub-r009s061, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:35.885703: predicting sub-r009s066 
2025-08-28 17:46:36.110805: sub-r009s066, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:44.994663: predicting sub-r009s079 
2025-08-28 17:46:45.228239: sub-r009s079, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:46:55.525961: predicting sub-r009s092 
2025-08-28 17:46:55.764279: sub-r009s092, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:04.455772: predicting sub-r009s094 
2025-08-28 17:47:04.664318: sub-r009s094, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:15.112482: predicting sub-r009s102 
2025-08-28 17:47:15.329132: sub-r009s102, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:23.921038: predicting sub-r009s103 
2025-08-28 17:47:24.133774: sub-r009s103, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:34.494370: predicting sub-r009s113 
2025-08-28 17:47:34.719338: sub-r009s113, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:44.153687: predicting sub-r009s118 
2025-08-28 17:47:44.374798: sub-r009s118, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:47:54.943944: predicting sub-r010s005 
2025-08-28 17:47:55.169365: sub-r010s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:03.777524: predicting sub-r010s013 
2025-08-28 17:48:03.998541: sub-r010s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:13.174365: predicting sub-r010s021 
2025-08-28 17:48:13.407946: sub-r010s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:23.676891: predicting sub-r010s022 
2025-08-28 17:48:23.901783: sub-r010s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:34.274608: predicting sub-r010s032 
2025-08-28 17:48:34.504024: sub-r010s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:43.179249: predicting sub-r011s011 
2025-08-28 17:48:43.417078: sub-r011s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:48:54.128009: predicting sub-r011s014 
2025-08-28 17:48:54.352975: sub-r011s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:03.078376: predicting sub-r011s020 
2025-08-28 17:49:03.311938: sub-r011s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:13.484470: predicting sub-r011s022 
2025-08-28 17:49:13.714218: sub-r011s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:22.643747: predicting sub-r014s015 
2025-08-28 17:49:22.877349: sub-r014s015, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:33.133409: predicting sub-r018s007 
2025-08-28 17:49:33.367549: sub-r018s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:42.013285: predicting sub-r018s008 
2025-08-28 17:49:42.221651: sub-r018s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:49:51.017994: predicting sub-r018s012 
2025-08-28 17:49:51.280730: sub-r018s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:01.524227: predicting sub-r019s008 
2025-08-28 17:50:01.812462: sub-r019s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:11.246451: predicting sub-r019s010 
2025-08-28 17:50:11.484187: sub-r019s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:21.932123: predicting sub-r023s002 
2025-08-28 17:50:22.153165: sub-r023s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:31.971233: predicting sub-r023s003 
2025-08-28 17:50:32.184038: sub-r023s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:42.106434: predicting sub-r024s002 
2025-08-28 17:50:42.331697: sub-r024s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:50:51.795293: predicting sub-r024s011 
2025-08-28 17:50:52.024707: sub-r024s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:02.422769: predicting sub-r027s009 
2025-08-28 17:51:02.660285: sub-r027s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:12.136672: predicting sub-r027s035 
2025-08-28 17:51:12.361648: sub-r027s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:22.117087: predicting sub-r027s042 
2025-08-28 17:51:22.359783: sub-r027s042, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:31.685099: predicting sub-r028s004 
2025-08-28 17:51:31.906108: sub-r028s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:42.466667: predicting sub-r029s004 
2025-08-28 17:51:42.691965: sub-r029s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:51:51.938700: predicting sub-r029s010 
2025-08-28 17:51:52.176409: sub-r029s010, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:02.720299: predicting sub-r031s002 
2025-08-28 17:52:02.966335: sub-r031s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:13.080631: predicting sub-r031s003 
2025-08-28 17:52:13.301653: sub-r031s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:23.069866: predicting sub-r031s007 
2025-08-28 17:52:23.278286: sub-r031s007, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:32.370987: predicting sub-r031s020 
2025-08-28 17:52:32.591768: sub-r031s020, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:42.847757: predicting sub-r031s021 
2025-08-28 17:52:43.064952: sub-r031s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:52:52.365904: predicting sub-r031s030 
2025-08-28 17:52:52.578355: sub-r031s030, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:03.097479: predicting sub-r031s031 
2025-08-28 17:53:03.339513: sub-r031s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:12.498139: predicting sub-r031s032 
2025-08-28 17:53:12.719304: sub-r031s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:23.092165: predicting sub-r031s036 
2025-08-28 17:53:23.309099: sub-r031s036, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:32.906039: predicting sub-r034s006 
2025-08-28 17:53:33.119121: sub-r034s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:43.249801: predicting sub-r034s009 
2025-08-28 17:53:43.470850: sub-r034s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:53:52.918096: predicting sub-r034s037 
2025-08-28 17:53:53.134668: sub-r034s037, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:03.708015: predicting sub-r034s039 
2025-08-28 17:54:03.957956: sub-r034s039, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:13.283943: predicting sub-r035s006 
2025-08-28 17:54:13.505033: sub-r035s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:24.078178: predicting sub-r035s011 
2025-08-28 17:54:24.311967: sub-r035s011, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:33.587782: predicting sub-r035s012 
2025-08-28 17:54:33.808607: sub-r035s012, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:44.423733: predicting sub-r035s013 
2025-08-28 17:54:44.652790: sub-r035s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:54:54.045830: predicting sub-r038s005 
2025-08-28 17:54:54.245740: sub-r038s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:04.539208: predicting sub-r038s035 
2025-08-28 17:55:04.802050: sub-r038s035, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:14.641053: predicting sub-r038s061 
2025-08-28 17:55:14.845411: sub-r038s061, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:25.226552: predicting sub-r038s065 
2025-08-28 17:55:25.451830: sub-r038s065, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:35.320206: predicting sub-r038s067 
2025-08-28 17:55:35.553586: sub-r038s067, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:45.084177: predicting sub-r038s085 
2025-08-28 17:55:45.305083: sub-r038s085, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:55:54.230765: predicting sub-r039s002 
2025-08-28 17:55:54.468307: sub-r039s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:04.490826: predicting sub-r040s016 
2025-08-28 17:56:04.736885: sub-r040s016, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:14.275573: predicting sub-r040s022 
2025-08-28 17:56:14.513374: sub-r040s022, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:24.406383: predicting sub-r040s046 
2025-08-28 17:56:24.631750: sub-r040s046, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:34.712909: predicting sub-r040s049 
2025-08-28 17:56:34.942023: sub-r040s049, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:44.630834: predicting sub-r040s054 
2025-08-28 17:56:44.860318: sub-r040s054, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:56:54.549304: predicting sub-r040s056 
2025-08-28 17:56:54.795239: sub-r040s056, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:04.790816: predicting sub-r040s059 
2025-08-28 17:57:05.013782: sub-r040s059, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:14.640075: predicting sub-r040s063 
2025-08-28 17:57:14.869456: sub-r040s063, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:25.339534: predicting sub-r040s070 
2025-08-28 17:57:25.559290: sub-r040s070, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:35.381484: predicting sub-r040s074 
2025-08-28 17:57:35.619287: sub-r040s074, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:45.545866: predicting sub-r040s075 
2025-08-28 17:57:45.758813: sub-r040s075, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:57:55.689325: predicting sub-r040s085 
2025-08-28 17:57:55.956275: sub-r040s085, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:06.137256: predicting sub-r042s001 
2025-08-28 17:58:06.383347: sub-r042s001, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:15.817761: predicting sub-r042s032 
2025-08-28 17:58:16.034637: sub-r042s032, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:26.470136: predicting sub-r042s033 
2025-08-28 17:58:26.691114: sub-r042s033, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:36.713670: predicting sub-r044s003 
2025-08-28 17:58:36.951367: sub-r044s003, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:46.873989: predicting sub-r045s002 
2025-08-28 17:58:47.094832: sub-r045s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:58:56.174989: predicting sub-r046s008 
2025-08-28 17:58:56.429181: sub-r046s008, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:06.831202: predicting sub-r047s013 
2025-08-28 17:59:07.056478: sub-r047s013, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:16.265616: predicting sub-r047s021 
2025-08-28 17:59:16.474216: sub-r047s021, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:26.967946: predicting sub-r047s027 
2025-08-28 17:59:27.193447: sub-r047s027, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:36.485801: predicting sub-r047s038 
2025-08-28 17:59:36.698500: sub-r047s038, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:47.180823: predicting sub-r048s004 
2025-08-28 17:59:47.392539: sub-r048s004, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 17:59:56.501452: predicting sub-r048s014 
2025-08-28 17:59:56.751861: sub-r048s014, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:06.791306: predicting sub-r048s043 
2025-08-28 18:00:07.037127: sub-r048s043, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:16.125200: predicting sub-r049s028 
2025-08-28 18:00:16.341008: sub-r049s028, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:26.648390: predicting sub-r050s005 
2025-08-28 18:00:26.877791: sub-r050s005, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:36.445903: predicting sub-r050s006 
2025-08-28 18:00:36.675065: sub-r050s006, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:47.164704: predicting sub-r050s009 
2025-08-28 18:00:47.410798: sub-r050s009, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:00:56.803487: predicting sub-r052s002 
2025-08-28 18:00:57.049648: sub-r052s002, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:01:07.593415: predicting sub-r052s029 
2025-08-28 18:01:07.831170: sub-r052s029, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:01:17.056530: predicting sub-r052s031 
2025-08-28 18:01:17.278092: sub-r052s031, shape torch.Size([1, 189, 233, 197]), rank 0 
2025-08-28 18:01:36.760028: Validation complete 
2025-08-28 18:01:36.768401: Mean Validation Dice:  0.5194869076666156 
